# coding=utf-8
# *** WARNING: this file was generated by the Pulumi Terraform Bridge (tfgen) Tool. ***
# *** Do not edit by hand unless you're certain you know what you are doing! ***

import copy
import warnings
import pulumi
import pulumi.runtime
from typing import Any, Mapping, Optional, Sequence, Union, overload
from . import _utilities
from . import outputs

__all__ = [
    'AccessControlRuleSetGrantRule',
    'ArtifactAllowlistArtifactMatcher',
    'ClusterAutoscale',
    'ClusterAwsAttributes',
    'ClusterAzureAttributes',
    'ClusterAzureAttributesLogAnalyticsInfo',
    'ClusterClusterLogConf',
    'ClusterClusterLogConfDbfs',
    'ClusterClusterLogConfS3',
    'ClusterClusterMountInfo',
    'ClusterClusterMountInfoNetworkFilesystemInfo',
    'ClusterDockerImage',
    'ClusterDockerImageBasicAuth',
    'ClusterGcpAttributes',
    'ClusterInitScript',
    'ClusterInitScriptAbfss',
    'ClusterInitScriptDbfs',
    'ClusterInitScriptFile',
    'ClusterInitScriptGcs',
    'ClusterInitScriptS3',
    'ClusterInitScriptVolumes',
    'ClusterInitScriptWorkspace',
    'ClusterLibrary',
    'ClusterLibraryCran',
    'ClusterLibraryMaven',
    'ClusterLibraryPypi',
    'ClusterPolicyLibrary',
    'ClusterPolicyLibraryCran',
    'ClusterPolicyLibraryMaven',
    'ClusterPolicyLibraryPypi',
    'ClusterWorkloadType',
    'ClusterWorkloadTypeClients',
    'DefaultNamespaceSettingNamespace',
    'ExternalLocationEncryptionDetails',
    'ExternalLocationEncryptionDetailsSseEncryptionDetails',
    'GrantsGrant',
    'InstancePoolAwsAttributes',
    'InstancePoolAzureAttributes',
    'InstancePoolDiskSpec',
    'InstancePoolDiskSpecDiskType',
    'InstancePoolGcpAttributes',
    'InstancePoolInstancePoolFleetAttributes',
    'InstancePoolInstancePoolFleetAttributesFleetOnDemandOption',
    'InstancePoolInstancePoolFleetAttributesFleetSpotOption',
    'InstancePoolInstancePoolFleetAttributesLaunchTemplateOverride',
    'InstancePoolPreloadedDockerImage',
    'InstancePoolPreloadedDockerImageBasicAuth',
    'JobCompute',
    'JobComputeSpec',
    'JobContinuous',
    'JobDbtTask',
    'JobDeployment',
    'JobEmailNotifications',
    'JobGitSource',
    'JobGitSourceJobSource',
    'JobHealth',
    'JobHealthRule',
    'JobJobCluster',
    'JobJobClusterNewCluster',
    'JobJobClusterNewClusterAutoscale',
    'JobJobClusterNewClusterAwsAttributes',
    'JobJobClusterNewClusterAzureAttributes',
    'JobJobClusterNewClusterClusterLogConf',
    'JobJobClusterNewClusterClusterLogConfDbfs',
    'JobJobClusterNewClusterClusterLogConfS3',
    'JobJobClusterNewClusterClusterMountInfo',
    'JobJobClusterNewClusterClusterMountInfoNetworkFilesystemInfo',
    'JobJobClusterNewClusterDockerImage',
    'JobJobClusterNewClusterDockerImageBasicAuth',
    'JobJobClusterNewClusterGcpAttributes',
    'JobJobClusterNewClusterInitScript',
    'JobJobClusterNewClusterInitScriptAbfss',
    'JobJobClusterNewClusterInitScriptDbfs',
    'JobJobClusterNewClusterInitScriptFile',
    'JobJobClusterNewClusterInitScriptGcs',
    'JobJobClusterNewClusterInitScriptS3',
    'JobJobClusterNewClusterInitScriptVolumes',
    'JobJobClusterNewClusterInitScriptWorkspace',
    'JobJobClusterNewClusterWorkloadType',
    'JobJobClusterNewClusterWorkloadTypeClients',
    'JobLibrary',
    'JobLibraryCran',
    'JobLibraryMaven',
    'JobLibraryPypi',
    'JobNewCluster',
    'JobNewClusterAutoscale',
    'JobNewClusterAwsAttributes',
    'JobNewClusterAzureAttributes',
    'JobNewClusterClusterLogConf',
    'JobNewClusterClusterLogConfDbfs',
    'JobNewClusterClusterLogConfS3',
    'JobNewClusterClusterMountInfo',
    'JobNewClusterClusterMountInfoNetworkFilesystemInfo',
    'JobNewClusterDockerImage',
    'JobNewClusterDockerImageBasicAuth',
    'JobNewClusterGcpAttributes',
    'JobNewClusterInitScript',
    'JobNewClusterInitScriptAbfss',
    'JobNewClusterInitScriptDbfs',
    'JobNewClusterInitScriptFile',
    'JobNewClusterInitScriptGcs',
    'JobNewClusterInitScriptS3',
    'JobNewClusterInitScriptVolumes',
    'JobNewClusterInitScriptWorkspace',
    'JobNewClusterWorkloadType',
    'JobNewClusterWorkloadTypeClients',
    'JobNotebookTask',
    'JobNotificationSettings',
    'JobParameter',
    'JobPipelineTask',
    'JobPythonWheelTask',
    'JobQueue',
    'JobRunAs',
    'JobRunJobTask',
    'JobSchedule',
    'JobSparkJarTask',
    'JobSparkPythonTask',
    'JobSparkSubmitTask',
    'JobTask',
    'JobTaskConditionTask',
    'JobTaskDbtTask',
    'JobTaskDependsOn',
    'JobTaskEmailNotifications',
    'JobTaskForEachTask',
    'JobTaskForEachTaskTask',
    'JobTaskForEachTaskTaskConditionTask',
    'JobTaskForEachTaskTaskDbtTask',
    'JobTaskForEachTaskTaskDependsOn',
    'JobTaskForEachTaskTaskEmailNotifications',
    'JobTaskForEachTaskTaskHealth',
    'JobTaskForEachTaskTaskHealthRule',
    'JobTaskForEachTaskTaskLibrary',
    'JobTaskForEachTaskTaskLibraryCran',
    'JobTaskForEachTaskTaskLibraryMaven',
    'JobTaskForEachTaskTaskLibraryPypi',
    'JobTaskForEachTaskTaskNewCluster',
    'JobTaskForEachTaskTaskNewClusterAutoscale',
    'JobTaskForEachTaskTaskNewClusterAwsAttributes',
    'JobTaskForEachTaskTaskNewClusterAzureAttributes',
    'JobTaskForEachTaskTaskNewClusterClusterLogConf',
    'JobTaskForEachTaskTaskNewClusterClusterLogConfDbfs',
    'JobTaskForEachTaskTaskNewClusterClusterLogConfS3',
    'JobTaskForEachTaskTaskNewClusterClusterMountInfo',
    'JobTaskForEachTaskTaskNewClusterClusterMountInfoNetworkFilesystemInfo',
    'JobTaskForEachTaskTaskNewClusterDockerImage',
    'JobTaskForEachTaskTaskNewClusterDockerImageBasicAuth',
    'JobTaskForEachTaskTaskNewClusterGcpAttributes',
    'JobTaskForEachTaskTaskNewClusterInitScript',
    'JobTaskForEachTaskTaskNewClusterInitScriptAbfss',
    'JobTaskForEachTaskTaskNewClusterInitScriptDbfs',
    'JobTaskForEachTaskTaskNewClusterInitScriptFile',
    'JobTaskForEachTaskTaskNewClusterInitScriptGcs',
    'JobTaskForEachTaskTaskNewClusterInitScriptS3',
    'JobTaskForEachTaskTaskNewClusterInitScriptVolumes',
    'JobTaskForEachTaskTaskNewClusterInitScriptWorkspace',
    'JobTaskForEachTaskTaskNewClusterWorkloadType',
    'JobTaskForEachTaskTaskNewClusterWorkloadTypeClients',
    'JobTaskForEachTaskTaskNotebookTask',
    'JobTaskForEachTaskTaskNotificationSettings',
    'JobTaskForEachTaskTaskPipelineTask',
    'JobTaskForEachTaskTaskPythonWheelTask',
    'JobTaskForEachTaskTaskRunJobTask',
    'JobTaskForEachTaskTaskSparkJarTask',
    'JobTaskForEachTaskTaskSparkPythonTask',
    'JobTaskForEachTaskTaskSparkSubmitTask',
    'JobTaskForEachTaskTaskSqlTask',
    'JobTaskForEachTaskTaskSqlTaskAlert',
    'JobTaskForEachTaskTaskSqlTaskAlertSubscription',
    'JobTaskForEachTaskTaskSqlTaskDashboard',
    'JobTaskForEachTaskTaskSqlTaskDashboardSubscription',
    'JobTaskForEachTaskTaskSqlTaskFile',
    'JobTaskForEachTaskTaskSqlTaskQuery',
    'JobTaskForEachTaskTaskWebhookNotifications',
    'JobTaskForEachTaskTaskWebhookNotificationsOnDurationWarningThresholdExceeded',
    'JobTaskForEachTaskTaskWebhookNotificationsOnFailure',
    'JobTaskForEachTaskTaskWebhookNotificationsOnStart',
    'JobTaskForEachTaskTaskWebhookNotificationsOnSuccess',
    'JobTaskHealth',
    'JobTaskHealthRule',
    'JobTaskLibrary',
    'JobTaskLibraryCran',
    'JobTaskLibraryMaven',
    'JobTaskLibraryPypi',
    'JobTaskNewCluster',
    'JobTaskNewClusterAutoscale',
    'JobTaskNewClusterAwsAttributes',
    'JobTaskNewClusterAzureAttributes',
    'JobTaskNewClusterClusterLogConf',
    'JobTaskNewClusterClusterLogConfDbfs',
    'JobTaskNewClusterClusterLogConfS3',
    'JobTaskNewClusterClusterMountInfo',
    'JobTaskNewClusterClusterMountInfoNetworkFilesystemInfo',
    'JobTaskNewClusterDockerImage',
    'JobTaskNewClusterDockerImageBasicAuth',
    'JobTaskNewClusterGcpAttributes',
    'JobTaskNewClusterInitScript',
    'JobTaskNewClusterInitScriptAbfss',
    'JobTaskNewClusterInitScriptDbfs',
    'JobTaskNewClusterInitScriptFile',
    'JobTaskNewClusterInitScriptGcs',
    'JobTaskNewClusterInitScriptS3',
    'JobTaskNewClusterInitScriptVolumes',
    'JobTaskNewClusterInitScriptWorkspace',
    'JobTaskNewClusterWorkloadType',
    'JobTaskNewClusterWorkloadTypeClients',
    'JobTaskNotebookTask',
    'JobTaskNotificationSettings',
    'JobTaskPipelineTask',
    'JobTaskPythonWheelTask',
    'JobTaskRunJobTask',
    'JobTaskSparkJarTask',
    'JobTaskSparkPythonTask',
    'JobTaskSparkSubmitTask',
    'JobTaskSqlTask',
    'JobTaskSqlTaskAlert',
    'JobTaskSqlTaskAlertSubscription',
    'JobTaskSqlTaskDashboard',
    'JobTaskSqlTaskDashboardSubscription',
    'JobTaskSqlTaskFile',
    'JobTaskSqlTaskQuery',
    'JobTaskWebhookNotifications',
    'JobTaskWebhookNotificationsOnDurationWarningThresholdExceeded',
    'JobTaskWebhookNotificationsOnFailure',
    'JobTaskWebhookNotificationsOnStart',
    'JobTaskWebhookNotificationsOnSuccess',
    'JobTrigger',
    'JobTriggerFileArrival',
    'JobWebhookNotifications',
    'JobWebhookNotificationsOnDurationWarningThresholdExceeded',
    'JobWebhookNotificationsOnFailure',
    'JobWebhookNotificationsOnStart',
    'JobWebhookNotificationsOnSuccess',
    'LibraryCran',
    'LibraryMaven',
    'LibraryPypi',
    'MetastoreDataAccessAwsIamRole',
    'MetastoreDataAccessAzureManagedIdentity',
    'MetastoreDataAccessAzureServicePrincipal',
    'MetastoreDataAccessDatabricksGcpServiceAccount',
    'MetastoreDataAccessGcpServiceAccountKey',
    'MlflowModelTag',
    'MlflowWebhookHttpUrlSpec',
    'MlflowWebhookJobSpec',
    'ModelServingConfig',
    'ModelServingConfigAutoCaptureConfig',
    'ModelServingConfigServedModel',
    'ModelServingConfigTrafficConfig',
    'ModelServingConfigTrafficConfigRoute',
    'ModelServingRateLimit',
    'ModelServingTag',
    'MountAbfs',
    'MountAdl',
    'MountGs',
    'MountS3',
    'MountWasb',
    'MwsCustomerManagedKeysAwsKeyInfo',
    'MwsCustomerManagedKeysGcpKeyInfo',
    'MwsNetworksErrorMessage',
    'MwsNetworksGcpNetworkInfo',
    'MwsNetworksVpcEndpoints',
    'MwsVpcEndpointGcpVpcEndpointInfo',
    'MwsWorkspacesCloudResourceContainer',
    'MwsWorkspacesCloudResourceContainerGcp',
    'MwsWorkspacesExternalCustomerInfo',
    'MwsWorkspacesGcpManagedNetworkConfig',
    'MwsWorkspacesGkeConfig',
    'MwsWorkspacesToken',
    'PermissionsAccessControl',
    'PipelineCluster',
    'PipelineClusterAutoscale',
    'PipelineClusterAwsAttributes',
    'PipelineClusterAzureAttributes',
    'PipelineClusterClusterLogConf',
    'PipelineClusterClusterLogConfDbfs',
    'PipelineClusterClusterLogConfS3',
    'PipelineClusterGcpAttributes',
    'PipelineClusterInitScript',
    'PipelineClusterInitScriptAbfss',
    'PipelineClusterInitScriptDbfs',
    'PipelineClusterInitScriptFile',
    'PipelineClusterInitScriptGcs',
    'PipelineClusterInitScriptS3',
    'PipelineClusterInitScriptVolumes',
    'PipelineClusterInitScriptWorkspace',
    'PipelineFilters',
    'PipelineLibrary',
    'PipelineLibraryFile',
    'PipelineLibraryMaven',
    'PipelineLibraryNotebook',
    'PipelineNotification',
    'RecipientIpAccessList',
    'RecipientToken',
    'RepoSparseCheckout',
    'RestrictWorkspaceAdminsSettingRestrictWorkspaceAdmins',
    'SecretScopeKeyvaultMetadata',
    'ShareObject',
    'ShareObjectPartition',
    'ShareObjectPartitionValue',
    'SqlAlertOptions',
    'SqlEndpointChannel',
    'SqlEndpointHealth',
    'SqlEndpointHealthFailureReason',
    'SqlEndpointOdbcParams',
    'SqlEndpointTags',
    'SqlEndpointTagsCustomTag',
    'SqlPermissionsPrivilegeAssignment',
    'SqlQueryParameter',
    'SqlQueryParameterDate',
    'SqlQueryParameterDateRange',
    'SqlQueryParameterDateRangeRange',
    'SqlQueryParameterDatetime',
    'SqlQueryParameterDatetimeRange',
    'SqlQueryParameterDatetimeRangeRange',
    'SqlQueryParameterDatetimesec',
    'SqlQueryParameterDatetimesecRange',
    'SqlQueryParameterDatetimesecRangeRange',
    'SqlQueryParameterEnum',
    'SqlQueryParameterEnumMultiple',
    'SqlQueryParameterNumber',
    'SqlQueryParameterQuery',
    'SqlQueryParameterQueryMultiple',
    'SqlQueryParameterText',
    'SqlQuerySchedule',
    'SqlQueryScheduleContinuous',
    'SqlQueryScheduleDaily',
    'SqlQueryScheduleWeekly',
    'SqlTableColumn',
    'SqlWidgetParameter',
    'SqlWidgetPosition',
    'StorageCredentialAwsIamRole',
    'StorageCredentialAzureManagedIdentity',
    'StorageCredentialAzureServicePrincipal',
    'StorageCredentialDatabricksGcpServiceAccount',
    'StorageCredentialGcpServiceAccountKey',
    'TableColumn',
    'VectorSearchEndpointEndpointStatus',
    'GetClusterClusterInfoResult',
    'GetClusterClusterInfoAutoscaleResult',
    'GetClusterClusterInfoAwsAttributesResult',
    'GetClusterClusterInfoAzureAttributesResult',
    'GetClusterClusterInfoClusterLogConfResult',
    'GetClusterClusterInfoClusterLogConfDbfsResult',
    'GetClusterClusterInfoClusterLogConfS3Result',
    'GetClusterClusterInfoClusterLogStatusResult',
    'GetClusterClusterInfoDockerImageResult',
    'GetClusterClusterInfoDockerImageBasicAuthResult',
    'GetClusterClusterInfoDriverResult',
    'GetClusterClusterInfoDriverNodeAwsAttributesResult',
    'GetClusterClusterInfoExecutorResult',
    'GetClusterClusterInfoExecutorNodeAwsAttributesResult',
    'GetClusterClusterInfoGcpAttributesResult',
    'GetClusterClusterInfoInitScriptResult',
    'GetClusterClusterInfoInitScriptAbfssResult',
    'GetClusterClusterInfoInitScriptDbfsResult',
    'GetClusterClusterInfoInitScriptFileResult',
    'GetClusterClusterInfoInitScriptGcsResult',
    'GetClusterClusterInfoInitScriptS3Result',
    'GetClusterClusterInfoInitScriptVolumesResult',
    'GetClusterClusterInfoInitScriptWorkspaceResult',
    'GetClusterClusterInfoTerminationReasonResult',
    'GetCurrentMetastoreMetastoreInfoResult',
    'GetDbfsFilePathsPathListResult',
    'GetInstancePoolPoolInfoResult',
    'GetInstancePoolPoolInfoAwsAttributesResult',
    'GetInstancePoolPoolInfoAzureAttributesResult',
    'GetInstancePoolPoolInfoDiskSpecResult',
    'GetInstancePoolPoolInfoDiskSpecDiskTypeResult',
    'GetInstancePoolPoolInfoGcpAttributesResult',
    'GetInstancePoolPoolInfoInstancePoolFleetAttributeResult',
    'GetInstancePoolPoolInfoInstancePoolFleetAttributeFleetOnDemandOptionResult',
    'GetInstancePoolPoolInfoInstancePoolFleetAttributeFleetSpotOptionResult',
    'GetInstancePoolPoolInfoInstancePoolFleetAttributeLaunchTemplateOverrideResult',
    'GetInstancePoolPoolInfoPreloadedDockerImageResult',
    'GetInstancePoolPoolInfoPreloadedDockerImageBasicAuthResult',
    'GetInstancePoolPoolInfoStatsResult',
    'GetInstanceProfilesInstanceProfileResult',
    'GetJobJobSettingsResult',
    'GetJobJobSettingsSettingsResult',
    'GetJobJobSettingsSettingsComputeResult',
    'GetJobJobSettingsSettingsComputeSpecResult',
    'GetJobJobSettingsSettingsContinuousResult',
    'GetJobJobSettingsSettingsDbtTaskResult',
    'GetJobJobSettingsSettingsDeploymentResult',
    'GetJobJobSettingsSettingsEmailNotificationsResult',
    'GetJobJobSettingsSettingsGitSourceResult',
    'GetJobJobSettingsSettingsGitSourceJobSourceResult',
    'GetJobJobSettingsSettingsHealthResult',
    'GetJobJobSettingsSettingsHealthRuleResult',
    'GetJobJobSettingsSettingsJobClusterResult',
    'GetJobJobSettingsSettingsJobClusterNewClusterResult',
    'GetJobJobSettingsSettingsJobClusterNewClusterAutoscaleResult',
    'GetJobJobSettingsSettingsJobClusterNewClusterAwsAttributesResult',
    'GetJobJobSettingsSettingsJobClusterNewClusterAzureAttributesResult',
    'GetJobJobSettingsSettingsJobClusterNewClusterClusterLogConfResult',
    'GetJobJobSettingsSettingsJobClusterNewClusterClusterLogConfDbfsResult',
    'GetJobJobSettingsSettingsJobClusterNewClusterClusterLogConfS3Result',
    'GetJobJobSettingsSettingsJobClusterNewClusterClusterMountInfoResult',
    'GetJobJobSettingsSettingsJobClusterNewClusterClusterMountInfoNetworkFilesystemInfoResult',
    'GetJobJobSettingsSettingsJobClusterNewClusterDockerImageResult',
    'GetJobJobSettingsSettingsJobClusterNewClusterDockerImageBasicAuthResult',
    'GetJobJobSettingsSettingsJobClusterNewClusterGcpAttributesResult',
    'GetJobJobSettingsSettingsJobClusterNewClusterInitScriptResult',
    'GetJobJobSettingsSettingsJobClusterNewClusterInitScriptAbfssResult',
    'GetJobJobSettingsSettingsJobClusterNewClusterInitScriptDbfsResult',
    'GetJobJobSettingsSettingsJobClusterNewClusterInitScriptFileResult',
    'GetJobJobSettingsSettingsJobClusterNewClusterInitScriptGcsResult',
    'GetJobJobSettingsSettingsJobClusterNewClusterInitScriptS3Result',
    'GetJobJobSettingsSettingsJobClusterNewClusterInitScriptVolumesResult',
    'GetJobJobSettingsSettingsJobClusterNewClusterInitScriptWorkspaceResult',
    'GetJobJobSettingsSettingsJobClusterNewClusterWorkloadTypeResult',
    'GetJobJobSettingsSettingsJobClusterNewClusterWorkloadTypeClientsResult',
    'GetJobJobSettingsSettingsLibraryResult',
    'GetJobJobSettingsSettingsLibraryCranResult',
    'GetJobJobSettingsSettingsLibraryMavenResult',
    'GetJobJobSettingsSettingsLibraryPypiResult',
    'GetJobJobSettingsSettingsNewClusterResult',
    'GetJobJobSettingsSettingsNewClusterAutoscaleResult',
    'GetJobJobSettingsSettingsNewClusterAwsAttributesResult',
    'GetJobJobSettingsSettingsNewClusterAzureAttributesResult',
    'GetJobJobSettingsSettingsNewClusterClusterLogConfResult',
    'GetJobJobSettingsSettingsNewClusterClusterLogConfDbfsResult',
    'GetJobJobSettingsSettingsNewClusterClusterLogConfS3Result',
    'GetJobJobSettingsSettingsNewClusterClusterMountInfoResult',
    'GetJobJobSettingsSettingsNewClusterClusterMountInfoNetworkFilesystemInfoResult',
    'GetJobJobSettingsSettingsNewClusterDockerImageResult',
    'GetJobJobSettingsSettingsNewClusterDockerImageBasicAuthResult',
    'GetJobJobSettingsSettingsNewClusterGcpAttributesResult',
    'GetJobJobSettingsSettingsNewClusterInitScriptResult',
    'GetJobJobSettingsSettingsNewClusterInitScriptAbfssResult',
    'GetJobJobSettingsSettingsNewClusterInitScriptDbfsResult',
    'GetJobJobSettingsSettingsNewClusterInitScriptFileResult',
    'GetJobJobSettingsSettingsNewClusterInitScriptGcsResult',
    'GetJobJobSettingsSettingsNewClusterInitScriptS3Result',
    'GetJobJobSettingsSettingsNewClusterInitScriptVolumesResult',
    'GetJobJobSettingsSettingsNewClusterInitScriptWorkspaceResult',
    'GetJobJobSettingsSettingsNewClusterWorkloadTypeResult',
    'GetJobJobSettingsSettingsNewClusterWorkloadTypeClientsResult',
    'GetJobJobSettingsSettingsNotebookTaskResult',
    'GetJobJobSettingsSettingsNotificationSettingsResult',
    'GetJobJobSettingsSettingsParameterResult',
    'GetJobJobSettingsSettingsPipelineTaskResult',
    'GetJobJobSettingsSettingsPythonWheelTaskResult',
    'GetJobJobSettingsSettingsQueueResult',
    'GetJobJobSettingsSettingsRunAsResult',
    'GetJobJobSettingsSettingsRunJobTaskResult',
    'GetJobJobSettingsSettingsScheduleResult',
    'GetJobJobSettingsSettingsSparkJarTaskResult',
    'GetJobJobSettingsSettingsSparkPythonTaskResult',
    'GetJobJobSettingsSettingsSparkSubmitTaskResult',
    'GetJobJobSettingsSettingsTaskResult',
    'GetJobJobSettingsSettingsTaskConditionTaskResult',
    'GetJobJobSettingsSettingsTaskDbtTaskResult',
    'GetJobJobSettingsSettingsTaskDependsOnResult',
    'GetJobJobSettingsSettingsTaskEmailNotificationsResult',
    'GetJobJobSettingsSettingsTaskForEachTaskResult',
    'GetJobJobSettingsSettingsTaskForEachTaskTaskResult',
    'GetJobJobSettingsSettingsTaskForEachTaskTaskConditionTaskResult',
    'GetJobJobSettingsSettingsTaskForEachTaskTaskDbtTaskResult',
    'GetJobJobSettingsSettingsTaskForEachTaskTaskDependsOnResult',
    'GetJobJobSettingsSettingsTaskForEachTaskTaskEmailNotificationsResult',
    'GetJobJobSettingsSettingsTaskForEachTaskTaskHealthResult',
    'GetJobJobSettingsSettingsTaskForEachTaskTaskHealthRuleResult',
    'GetJobJobSettingsSettingsTaskForEachTaskTaskLibraryResult',
    'GetJobJobSettingsSettingsTaskForEachTaskTaskLibraryCranResult',
    'GetJobJobSettingsSettingsTaskForEachTaskTaskLibraryMavenResult',
    'GetJobJobSettingsSettingsTaskForEachTaskTaskLibraryPypiResult',
    'GetJobJobSettingsSettingsTaskForEachTaskTaskNewClusterResult',
    'GetJobJobSettingsSettingsTaskForEachTaskTaskNewClusterAutoscaleResult',
    'GetJobJobSettingsSettingsTaskForEachTaskTaskNewClusterAwsAttributesResult',
    'GetJobJobSettingsSettingsTaskForEachTaskTaskNewClusterAzureAttributesResult',
    'GetJobJobSettingsSettingsTaskForEachTaskTaskNewClusterClusterLogConfResult',
    'GetJobJobSettingsSettingsTaskForEachTaskTaskNewClusterClusterLogConfDbfsResult',
    'GetJobJobSettingsSettingsTaskForEachTaskTaskNewClusterClusterLogConfS3Result',
    'GetJobJobSettingsSettingsTaskForEachTaskTaskNewClusterClusterMountInfoResult',
    'GetJobJobSettingsSettingsTaskForEachTaskTaskNewClusterClusterMountInfoNetworkFilesystemInfoResult',
    'GetJobJobSettingsSettingsTaskForEachTaskTaskNewClusterDockerImageResult',
    'GetJobJobSettingsSettingsTaskForEachTaskTaskNewClusterDockerImageBasicAuthResult',
    'GetJobJobSettingsSettingsTaskForEachTaskTaskNewClusterGcpAttributesResult',
    'GetJobJobSettingsSettingsTaskForEachTaskTaskNewClusterInitScriptResult',
    'GetJobJobSettingsSettingsTaskForEachTaskTaskNewClusterInitScriptAbfssResult',
    'GetJobJobSettingsSettingsTaskForEachTaskTaskNewClusterInitScriptDbfsResult',
    'GetJobJobSettingsSettingsTaskForEachTaskTaskNewClusterInitScriptFileResult',
    'GetJobJobSettingsSettingsTaskForEachTaskTaskNewClusterInitScriptGcsResult',
    'GetJobJobSettingsSettingsTaskForEachTaskTaskNewClusterInitScriptS3Result',
    'GetJobJobSettingsSettingsTaskForEachTaskTaskNewClusterInitScriptVolumesResult',
    'GetJobJobSettingsSettingsTaskForEachTaskTaskNewClusterInitScriptWorkspaceResult',
    'GetJobJobSettingsSettingsTaskForEachTaskTaskNewClusterWorkloadTypeResult',
    'GetJobJobSettingsSettingsTaskForEachTaskTaskNewClusterWorkloadTypeClientsResult',
    'GetJobJobSettingsSettingsTaskForEachTaskTaskNotebookTaskResult',
    'GetJobJobSettingsSettingsTaskForEachTaskTaskNotificationSettingsResult',
    'GetJobJobSettingsSettingsTaskForEachTaskTaskPipelineTaskResult',
    'GetJobJobSettingsSettingsTaskForEachTaskTaskPythonWheelTaskResult',
    'GetJobJobSettingsSettingsTaskForEachTaskTaskRunJobTaskResult',
    'GetJobJobSettingsSettingsTaskForEachTaskTaskSparkJarTaskResult',
    'GetJobJobSettingsSettingsTaskForEachTaskTaskSparkPythonTaskResult',
    'GetJobJobSettingsSettingsTaskForEachTaskTaskSparkSubmitTaskResult',
    'GetJobJobSettingsSettingsTaskForEachTaskTaskSqlTaskResult',
    'GetJobJobSettingsSettingsTaskForEachTaskTaskSqlTaskAlertResult',
    'GetJobJobSettingsSettingsTaskForEachTaskTaskSqlTaskAlertSubscriptionResult',
    'GetJobJobSettingsSettingsTaskForEachTaskTaskSqlTaskDashboardResult',
    'GetJobJobSettingsSettingsTaskForEachTaskTaskSqlTaskDashboardSubscriptionResult',
    'GetJobJobSettingsSettingsTaskForEachTaskTaskSqlTaskFileResult',
    'GetJobJobSettingsSettingsTaskForEachTaskTaskSqlTaskQueryResult',
    'GetJobJobSettingsSettingsTaskForEachTaskTaskWebhookNotificationsResult',
    'GetJobJobSettingsSettingsTaskForEachTaskTaskWebhookNotificationsOnDurationWarningThresholdExceededResult',
    'GetJobJobSettingsSettingsTaskForEachTaskTaskWebhookNotificationsOnFailureResult',
    'GetJobJobSettingsSettingsTaskForEachTaskTaskWebhookNotificationsOnStartResult',
    'GetJobJobSettingsSettingsTaskForEachTaskTaskWebhookNotificationsOnSuccessResult',
    'GetJobJobSettingsSettingsTaskHealthResult',
    'GetJobJobSettingsSettingsTaskHealthRuleResult',
    'GetJobJobSettingsSettingsTaskLibraryResult',
    'GetJobJobSettingsSettingsTaskLibraryCranResult',
    'GetJobJobSettingsSettingsTaskLibraryMavenResult',
    'GetJobJobSettingsSettingsTaskLibraryPypiResult',
    'GetJobJobSettingsSettingsTaskNewClusterResult',
    'GetJobJobSettingsSettingsTaskNewClusterAutoscaleResult',
    'GetJobJobSettingsSettingsTaskNewClusterAwsAttributesResult',
    'GetJobJobSettingsSettingsTaskNewClusterAzureAttributesResult',
    'GetJobJobSettingsSettingsTaskNewClusterClusterLogConfResult',
    'GetJobJobSettingsSettingsTaskNewClusterClusterLogConfDbfsResult',
    'GetJobJobSettingsSettingsTaskNewClusterClusterLogConfS3Result',
    'GetJobJobSettingsSettingsTaskNewClusterClusterMountInfoResult',
    'GetJobJobSettingsSettingsTaskNewClusterClusterMountInfoNetworkFilesystemInfoResult',
    'GetJobJobSettingsSettingsTaskNewClusterDockerImageResult',
    'GetJobJobSettingsSettingsTaskNewClusterDockerImageBasicAuthResult',
    'GetJobJobSettingsSettingsTaskNewClusterGcpAttributesResult',
    'GetJobJobSettingsSettingsTaskNewClusterInitScriptResult',
    'GetJobJobSettingsSettingsTaskNewClusterInitScriptAbfssResult',
    'GetJobJobSettingsSettingsTaskNewClusterInitScriptDbfsResult',
    'GetJobJobSettingsSettingsTaskNewClusterInitScriptFileResult',
    'GetJobJobSettingsSettingsTaskNewClusterInitScriptGcsResult',
    'GetJobJobSettingsSettingsTaskNewClusterInitScriptS3Result',
    'GetJobJobSettingsSettingsTaskNewClusterInitScriptVolumesResult',
    'GetJobJobSettingsSettingsTaskNewClusterInitScriptWorkspaceResult',
    'GetJobJobSettingsSettingsTaskNewClusterWorkloadTypeResult',
    'GetJobJobSettingsSettingsTaskNewClusterWorkloadTypeClientsResult',
    'GetJobJobSettingsSettingsTaskNotebookTaskResult',
    'GetJobJobSettingsSettingsTaskNotificationSettingsResult',
    'GetJobJobSettingsSettingsTaskPipelineTaskResult',
    'GetJobJobSettingsSettingsTaskPythonWheelTaskResult',
    'GetJobJobSettingsSettingsTaskRunJobTaskResult',
    'GetJobJobSettingsSettingsTaskSparkJarTaskResult',
    'GetJobJobSettingsSettingsTaskSparkPythonTaskResult',
    'GetJobJobSettingsSettingsTaskSparkSubmitTaskResult',
    'GetJobJobSettingsSettingsTaskSqlTaskResult',
    'GetJobJobSettingsSettingsTaskSqlTaskAlertResult',
    'GetJobJobSettingsSettingsTaskSqlTaskAlertSubscriptionResult',
    'GetJobJobSettingsSettingsTaskSqlTaskDashboardResult',
    'GetJobJobSettingsSettingsTaskSqlTaskDashboardSubscriptionResult',
    'GetJobJobSettingsSettingsTaskSqlTaskFileResult',
    'GetJobJobSettingsSettingsTaskSqlTaskQueryResult',
    'GetJobJobSettingsSettingsTaskWebhookNotificationsResult',
    'GetJobJobSettingsSettingsTaskWebhookNotificationsOnDurationWarningThresholdExceededResult',
    'GetJobJobSettingsSettingsTaskWebhookNotificationsOnFailureResult',
    'GetJobJobSettingsSettingsTaskWebhookNotificationsOnStartResult',
    'GetJobJobSettingsSettingsTaskWebhookNotificationsOnSuccessResult',
    'GetJobJobSettingsSettingsTriggerResult',
    'GetJobJobSettingsSettingsTriggerFileArrivalResult',
    'GetJobJobSettingsSettingsWebhookNotificationsResult',
    'GetJobJobSettingsSettingsWebhookNotificationsOnDurationWarningThresholdExceededResult',
    'GetJobJobSettingsSettingsWebhookNotificationsOnFailureResult',
    'GetJobJobSettingsSettingsWebhookNotificationsOnStartResult',
    'GetJobJobSettingsSettingsWebhookNotificationsOnSuccessResult',
    'GetMetastoreMetastoreInfoResult',
    'GetMlflowModelLatestVersionResult',
    'GetMlflowModelLatestVersionTagResult',
    'GetMlflowModelTagResult',
    'GetNotebookPathsNotebookPathListResult',
    'GetShareObjectResult',
    'GetShareObjectPartitionResult',
    'GetShareObjectPartitionValueResult',
    'GetSqlWarehouseChannelResult',
    'GetSqlWarehouseHealthResult',
    'GetSqlWarehouseHealthFailureReasonResult',
    'GetSqlWarehouseOdbcParamsResult',
    'GetSqlWarehouseTagsResult',
    'GetSqlWarehouseTagsCustomTagResult',
    'GetStorageCredentialStorageCredentialInfoResult',
    'GetStorageCredentialStorageCredentialInfoAwsIamRoleResult',
    'GetStorageCredentialStorageCredentialInfoAzureManagedIdentityResult',
    'GetStorageCredentialStorageCredentialInfoAzureServicePrincipalResult',
    'GetStorageCredentialStorageCredentialInfoCloudflareApiTokenResult',
    'GetStorageCredentialStorageCredentialInfoDatabricksGcpServiceAccountResult',
]

@pulumi.output_type
class AccessControlRuleSetGrantRule(dict):
    def __init__(__self__, *,
                 role: str,
                 principals: Optional[Sequence[str]] = None):
        """
        :param str role: Role to be granted. The supported roles are listed below. For more information about these roles, refer to [service principal roles](https://docs.databricks.com/security/auth-authz/access-control/service-principal-acl.html#service-principal-roles), [group roles](https://docs.databricks.com/en/administration-guide/users-groups/groups.html#manage-roles-on-an-account-group-using-the-workspace-admin-settings-page) or [marketplace roles](https://docs.databricks.com/en/marketplace/get-started-provider.html#assign-the-marketplace-admin-role).
               * `roles/servicePrincipal.manager` - Manager of a service principal.
               * `roles/servicePrincipal.user` - User of a service principal.
               * `roles/group.manager` - Manager of a group.
               * `roles/marketplace.admin` - Admin of marketplace.
        :param Sequence[str] principals: a list of principals who are granted a role. The following format is supported:
               * `users/{username}` (also exposed as `acl_principal_id` attribute of `User` resource).
               * `groups/{groupname}` (also exposed as `acl_principal_id` attribute of `Group` resource).
               * `servicePrincipals/{applicationId}` (also exposed as `acl_principal_id` attribute of `ServicePrincipal` resource).
        """
        pulumi.set(__self__, "role", role)
        if principals is not None:
            pulumi.set(__self__, "principals", principals)

    @property
    @pulumi.getter
    def role(self) -> str:
        """
        Role to be granted. The supported roles are listed below. For more information about these roles, refer to [service principal roles](https://docs.databricks.com/security/auth-authz/access-control/service-principal-acl.html#service-principal-roles), [group roles](https://docs.databricks.com/en/administration-guide/users-groups/groups.html#manage-roles-on-an-account-group-using-the-workspace-admin-settings-page) or [marketplace roles](https://docs.databricks.com/en/marketplace/get-started-provider.html#assign-the-marketplace-admin-role).
        * `roles/servicePrincipal.manager` - Manager of a service principal.
        * `roles/servicePrincipal.user` - User of a service principal.
        * `roles/group.manager` - Manager of a group.
        * `roles/marketplace.admin` - Admin of marketplace.
        """
        return pulumi.get(self, "role")

    @property
    @pulumi.getter
    def principals(self) -> Optional[Sequence[str]]:
        """
        a list of principals who are granted a role. The following format is supported:
        * `users/{username}` (also exposed as `acl_principal_id` attribute of `User` resource).
        * `groups/{groupname}` (also exposed as `acl_principal_id` attribute of `Group` resource).
        * `servicePrincipals/{applicationId}` (also exposed as `acl_principal_id` attribute of `ServicePrincipal` resource).
        """
        return pulumi.get(self, "principals")


@pulumi.output_type
class ArtifactAllowlistArtifactMatcher(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "matchType":
            suggest = "match_type"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ArtifactAllowlistArtifactMatcher. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ArtifactAllowlistArtifactMatcher.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ArtifactAllowlistArtifactMatcher.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 artifact: str,
                 match_type: str):
        """
        :param str artifact: The artifact path or maven coordinate.
        :param str match_type: The pattern matching type of the artifact. Only `PREFIX_MATCH` is supported.
        """
        pulumi.set(__self__, "artifact", artifact)
        pulumi.set(__self__, "match_type", match_type)

    @property
    @pulumi.getter
    def artifact(self) -> str:
        """
        The artifact path or maven coordinate.
        """
        return pulumi.get(self, "artifact")

    @property
    @pulumi.getter(name="matchType")
    def match_type(self) -> str:
        """
        The pattern matching type of the artifact. Only `PREFIX_MATCH` is supported.
        """
        return pulumi.get(self, "match_type")


@pulumi.output_type
class ClusterAutoscale(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "maxWorkers":
            suggest = "max_workers"
        elif key == "minWorkers":
            suggest = "min_workers"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterAutoscale. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterAutoscale.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterAutoscale.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 max_workers: Optional[int] = None,
                 min_workers: Optional[int] = None):
        """
        :param int max_workers: The maximum number of workers to which the cluster can scale up when overloaded. max_workers must be strictly greater than min_workers.
               
               When using a [Single Node cluster](https://docs.databricks.com/clusters/single-node.html), `num_workers` needs to be `0`. It can be set to `0` explicitly, or simply not specified, as it defaults to `0`.  When `num_workers` is `0`, provider checks for presence of the required Spark configurations:
               
               * `spark.master` must have prefix `local`, like `local[*]`
               * `spark.databricks.cluster.profile` must have value `singleNode`
               
               and also `custom_tag` entry:
               
               * `"ResourceClass" = "SingleNode"`
               
               The following example demonstrates how to create an single node cluster:
               
               <!--Start PulumiCodeChooser -->
               ```python
               import pulumi
               import pulumi_databricks as databricks
               
               smallest = databricks.get_node_type(local_disk=True)
               latest_lts = databricks.get_spark_version(long_term_support=True)
               single_node = databricks.Cluster("singleNode",
                   cluster_name="Single Node",
                   spark_version=latest_lts.id,
                   node_type_id=smallest.id,
                   autotermination_minutes=20,
                   spark_conf={
                       "spark.databricks.cluster.profile": "singleNode",
                       "spark.master": "local[*]",
                   },
                   custom_tags={
                       "ResourceClass": "SingleNode",
                   })
               ```
               <!--End PulumiCodeChooser -->
        :param int min_workers: The minimum number of workers to which the cluster can scale down when underutilized. It is also the initial number of workers the cluster will have after creation.
        """
        if max_workers is not None:
            pulumi.set(__self__, "max_workers", max_workers)
        if min_workers is not None:
            pulumi.set(__self__, "min_workers", min_workers)

    @property
    @pulumi.getter(name="maxWorkers")
    def max_workers(self) -> Optional[int]:
        """
        The maximum number of workers to which the cluster can scale up when overloaded. max_workers must be strictly greater than min_workers.

        When using a [Single Node cluster](https://docs.databricks.com/clusters/single-node.html), `num_workers` needs to be `0`. It can be set to `0` explicitly, or simply not specified, as it defaults to `0`.  When `num_workers` is `0`, provider checks for presence of the required Spark configurations:

        * `spark.master` must have prefix `local`, like `local[*]`
        * `spark.databricks.cluster.profile` must have value `singleNode`

        and also `custom_tag` entry:

        * `"ResourceClass" = "SingleNode"`

        The following example demonstrates how to create an single node cluster:

        <!--Start PulumiCodeChooser -->
        ```python
        import pulumi
        import pulumi_databricks as databricks

        smallest = databricks.get_node_type(local_disk=True)
        latest_lts = databricks.get_spark_version(long_term_support=True)
        single_node = databricks.Cluster("singleNode",
            cluster_name="Single Node",
            spark_version=latest_lts.id,
            node_type_id=smallest.id,
            autotermination_minutes=20,
            spark_conf={
                "spark.databricks.cluster.profile": "singleNode",
                "spark.master": "local[*]",
            },
            custom_tags={
                "ResourceClass": "SingleNode",
            })
        ```
        <!--End PulumiCodeChooser -->
        """
        return pulumi.get(self, "max_workers")

    @property
    @pulumi.getter(name="minWorkers")
    def min_workers(self) -> Optional[int]:
        """
        The minimum number of workers to which the cluster can scale down when underutilized. It is also the initial number of workers the cluster will have after creation.
        """
        return pulumi.get(self, "min_workers")


@pulumi.output_type
class ClusterAwsAttributes(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "ebsVolumeCount":
            suggest = "ebs_volume_count"
        elif key == "ebsVolumeIops":
            suggest = "ebs_volume_iops"
        elif key == "ebsVolumeSize":
            suggest = "ebs_volume_size"
        elif key == "ebsVolumeThroughput":
            suggest = "ebs_volume_throughput"
        elif key == "ebsVolumeType":
            suggest = "ebs_volume_type"
        elif key == "firstOnDemand":
            suggest = "first_on_demand"
        elif key == "instanceProfileArn":
            suggest = "instance_profile_arn"
        elif key == "spotBidPricePercent":
            suggest = "spot_bid_price_percent"
        elif key == "zoneId":
            suggest = "zone_id"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterAwsAttributes. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterAwsAttributes.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterAwsAttributes.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 availability: Optional[str] = None,
                 ebs_volume_count: Optional[int] = None,
                 ebs_volume_iops: Optional[int] = None,
                 ebs_volume_size: Optional[int] = None,
                 ebs_volume_throughput: Optional[int] = None,
                 ebs_volume_type: Optional[str] = None,
                 first_on_demand: Optional[int] = None,
                 instance_profile_arn: Optional[str] = None,
                 spot_bid_price_percent: Optional[int] = None,
                 zone_id: Optional[str] = None):
        """
        :param str availability: Availability type used for all subsequent nodes past the `first_on_demand` ones. Valid values are `SPOT`, `SPOT_WITH_FALLBACK` and `ON_DEMAND`. Note: If `first_on_demand` is zero, this availability type will be used for the entire cluster. Backend default value is `SPOT_WITH_FALLBACK` and could change in the future
        :param int ebs_volume_count: The number of volumes launched for each instance. You can choose up to 10 volumes. This feature is only enabled for supported node types. Legacy node types cannot specify custom EBS volumes. For node types with no instance store, at least one EBS volume needs to be specified; otherwise, cluster creation will fail. These EBS volumes will be mounted at /ebs0, /ebs1, and etc. Instance store volumes will be mounted at /local_disk0, /local_disk1, and etc. If EBS volumes are attached, Databricks will configure Spark to use only the EBS volumes for scratch storage because heterogeneously sized scratch devices can lead to inefficient disk utilization. If no EBS volumes are attached, Databricks will configure Spark to use instance store volumes. If EBS volumes are specified, then the Spark configuration spark.local.dir will be overridden.
        :param int ebs_volume_size: The size of each EBS volume (in GiB) launched for each instance. For general purpose SSD, this value must be within the range 100 - 4096. For throughput optimized HDD, this value must be within the range 500 - 4096. Custom EBS volumes cannot be specified for the legacy node types (memory-optimized and compute-optimized).
        :param str ebs_volume_type: The type of EBS volumes that will be launched with this cluster. Valid values are `GENERAL_PURPOSE_SSD` or `THROUGHPUT_OPTIMIZED_HDD`. Use this option only if you're not picking *Delta Optimized `i3.*`* node types.
        :param int first_on_demand: The first `first_on_demand` nodes of the cluster will be placed on on-demand instances. If this value is greater than 0, the cluster driver node will be placed on an on-demand instance. If this value is greater than or equal to the current cluster size, all nodes will be placed on on-demand instances. If this value is less than the current cluster size, `first_on_demand` nodes will be placed on on-demand instances, and the remainder will be placed on availability instances. This value does not affect cluster size and cannot be mutated over the lifetime of a cluster. Backend default value is `1` and could change in the future
        :param int spot_bid_price_percent: The max price for AWS spot instances, as a percentage of the corresponding instance type’s on-demand price. For example, if this field is set to 50, and the cluster needs a new `i3.xlarge` spot instance, then the max price is half of the price of on-demand `i3.xlarge` instances. Similarly, if this field is set to 200, the max price is twice the price of on-demand `i3.xlarge` instances. If not specified, the default value is `100`. When spot instances are requested for this cluster, only spot instances whose max price percentage matches this field will be considered. For safety, we enforce this field to be no more than `10000`.
        :param str zone_id: Identifier for the availability zone/datacenter in which the cluster resides. This string will be of a form like `us-west-2a`. The provided availability zone must be in the same region as the Databricks deployment. For example, `us-west-2a` is not a valid zone ID if the Databricks deployment resides in the `us-east-1` region. Enable automatic availability zone selection ("Auto-AZ"), by setting the value `auto`. Databricks selects the AZ based on available IPs in the workspace subnets and retries in other availability zones if AWS returns insufficient capacity errors.
        """
        if availability is not None:
            pulumi.set(__self__, "availability", availability)
        if ebs_volume_count is not None:
            pulumi.set(__self__, "ebs_volume_count", ebs_volume_count)
        if ebs_volume_iops is not None:
            pulumi.set(__self__, "ebs_volume_iops", ebs_volume_iops)
        if ebs_volume_size is not None:
            pulumi.set(__self__, "ebs_volume_size", ebs_volume_size)
        if ebs_volume_throughput is not None:
            pulumi.set(__self__, "ebs_volume_throughput", ebs_volume_throughput)
        if ebs_volume_type is not None:
            pulumi.set(__self__, "ebs_volume_type", ebs_volume_type)
        if first_on_demand is not None:
            pulumi.set(__self__, "first_on_demand", first_on_demand)
        if instance_profile_arn is not None:
            pulumi.set(__self__, "instance_profile_arn", instance_profile_arn)
        if spot_bid_price_percent is not None:
            pulumi.set(__self__, "spot_bid_price_percent", spot_bid_price_percent)
        if zone_id is not None:
            pulumi.set(__self__, "zone_id", zone_id)

    @property
    @pulumi.getter
    def availability(self) -> Optional[str]:
        """
        Availability type used for all subsequent nodes past the `first_on_demand` ones. Valid values are `SPOT`, `SPOT_WITH_FALLBACK` and `ON_DEMAND`. Note: If `first_on_demand` is zero, this availability type will be used for the entire cluster. Backend default value is `SPOT_WITH_FALLBACK` and could change in the future
        """
        return pulumi.get(self, "availability")

    @property
    @pulumi.getter(name="ebsVolumeCount")
    def ebs_volume_count(self) -> Optional[int]:
        """
        The number of volumes launched for each instance. You can choose up to 10 volumes. This feature is only enabled for supported node types. Legacy node types cannot specify custom EBS volumes. For node types with no instance store, at least one EBS volume needs to be specified; otherwise, cluster creation will fail. These EBS volumes will be mounted at /ebs0, /ebs1, and etc. Instance store volumes will be mounted at /local_disk0, /local_disk1, and etc. If EBS volumes are attached, Databricks will configure Spark to use only the EBS volumes for scratch storage because heterogeneously sized scratch devices can lead to inefficient disk utilization. If no EBS volumes are attached, Databricks will configure Spark to use instance store volumes. If EBS volumes are specified, then the Spark configuration spark.local.dir will be overridden.
        """
        return pulumi.get(self, "ebs_volume_count")

    @property
    @pulumi.getter(name="ebsVolumeIops")
    def ebs_volume_iops(self) -> Optional[int]:
        return pulumi.get(self, "ebs_volume_iops")

    @property
    @pulumi.getter(name="ebsVolumeSize")
    def ebs_volume_size(self) -> Optional[int]:
        """
        The size of each EBS volume (in GiB) launched for each instance. For general purpose SSD, this value must be within the range 100 - 4096. For throughput optimized HDD, this value must be within the range 500 - 4096. Custom EBS volumes cannot be specified for the legacy node types (memory-optimized and compute-optimized).
        """
        return pulumi.get(self, "ebs_volume_size")

    @property
    @pulumi.getter(name="ebsVolumeThroughput")
    def ebs_volume_throughput(self) -> Optional[int]:
        return pulumi.get(self, "ebs_volume_throughput")

    @property
    @pulumi.getter(name="ebsVolumeType")
    def ebs_volume_type(self) -> Optional[str]:
        """
        The type of EBS volumes that will be launched with this cluster. Valid values are `GENERAL_PURPOSE_SSD` or `THROUGHPUT_OPTIMIZED_HDD`. Use this option only if you're not picking *Delta Optimized `i3.*`* node types.
        """
        return pulumi.get(self, "ebs_volume_type")

    @property
    @pulumi.getter(name="firstOnDemand")
    def first_on_demand(self) -> Optional[int]:
        """
        The first `first_on_demand` nodes of the cluster will be placed on on-demand instances. If this value is greater than 0, the cluster driver node will be placed on an on-demand instance. If this value is greater than or equal to the current cluster size, all nodes will be placed on on-demand instances. If this value is less than the current cluster size, `first_on_demand` nodes will be placed on on-demand instances, and the remainder will be placed on availability instances. This value does not affect cluster size and cannot be mutated over the lifetime of a cluster. Backend default value is `1` and could change in the future
        """
        return pulumi.get(self, "first_on_demand")

    @property
    @pulumi.getter(name="instanceProfileArn")
    def instance_profile_arn(self) -> Optional[str]:
        return pulumi.get(self, "instance_profile_arn")

    @property
    @pulumi.getter(name="spotBidPricePercent")
    def spot_bid_price_percent(self) -> Optional[int]:
        """
        The max price for AWS spot instances, as a percentage of the corresponding instance type’s on-demand price. For example, if this field is set to 50, and the cluster needs a new `i3.xlarge` spot instance, then the max price is half of the price of on-demand `i3.xlarge` instances. Similarly, if this field is set to 200, the max price is twice the price of on-demand `i3.xlarge` instances. If not specified, the default value is `100`. When spot instances are requested for this cluster, only spot instances whose max price percentage matches this field will be considered. For safety, we enforce this field to be no more than `10000`.
        """
        return pulumi.get(self, "spot_bid_price_percent")

    @property
    @pulumi.getter(name="zoneId")
    def zone_id(self) -> Optional[str]:
        """
        Identifier for the availability zone/datacenter in which the cluster resides. This string will be of a form like `us-west-2a`. The provided availability zone must be in the same region as the Databricks deployment. For example, `us-west-2a` is not a valid zone ID if the Databricks deployment resides in the `us-east-1` region. Enable automatic availability zone selection ("Auto-AZ"), by setting the value `auto`. Databricks selects the AZ based on available IPs in the workspace subnets and retries in other availability zones if AWS returns insufficient capacity errors.
        """
        return pulumi.get(self, "zone_id")


@pulumi.output_type
class ClusterAzureAttributes(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "firstOnDemand":
            suggest = "first_on_demand"
        elif key == "logAnalyticsInfo":
            suggest = "log_analytics_info"
        elif key == "spotBidMaxPrice":
            suggest = "spot_bid_max_price"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterAzureAttributes. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterAzureAttributes.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterAzureAttributes.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 availability: Optional[str] = None,
                 first_on_demand: Optional[int] = None,
                 log_analytics_info: Optional['outputs.ClusterAzureAttributesLogAnalyticsInfo'] = None,
                 spot_bid_max_price: Optional[float] = None):
        """
        :param str availability: Availability type used for all subsequent nodes past the `first_on_demand` ones. Valid values are `SPOT_AZURE`, `SPOT_WITH_FALLBACK_AZURE`, and `ON_DEMAND_AZURE`. Note: If `first_on_demand` is zero, this availability type will be used for the entire cluster.
        :param int first_on_demand: The first `first_on_demand` nodes of the cluster will be placed on on-demand instances. If this value is greater than 0, the cluster driver node will be placed on an on-demand instance. If this value is greater than or equal to the current cluster size, all nodes will be placed on on-demand instances. If this value is less than the current cluster size, `first_on_demand` nodes will be placed on on-demand instances, and the remainder will be placed on availability instances. This value does not affect cluster size and cannot be mutated over the lifetime of a cluster.
        :param float spot_bid_max_price: The max price for Azure spot instances.  Use `-1` to specify the lowest price.
        """
        if availability is not None:
            pulumi.set(__self__, "availability", availability)
        if first_on_demand is not None:
            pulumi.set(__self__, "first_on_demand", first_on_demand)
        if log_analytics_info is not None:
            pulumi.set(__self__, "log_analytics_info", log_analytics_info)
        if spot_bid_max_price is not None:
            pulumi.set(__self__, "spot_bid_max_price", spot_bid_max_price)

    @property
    @pulumi.getter
    def availability(self) -> Optional[str]:
        """
        Availability type used for all subsequent nodes past the `first_on_demand` ones. Valid values are `SPOT_AZURE`, `SPOT_WITH_FALLBACK_AZURE`, and `ON_DEMAND_AZURE`. Note: If `first_on_demand` is zero, this availability type will be used for the entire cluster.
        """
        return pulumi.get(self, "availability")

    @property
    @pulumi.getter(name="firstOnDemand")
    def first_on_demand(self) -> Optional[int]:
        """
        The first `first_on_demand` nodes of the cluster will be placed on on-demand instances. If this value is greater than 0, the cluster driver node will be placed on an on-demand instance. If this value is greater than or equal to the current cluster size, all nodes will be placed on on-demand instances. If this value is less than the current cluster size, `first_on_demand` nodes will be placed on on-demand instances, and the remainder will be placed on availability instances. This value does not affect cluster size and cannot be mutated over the lifetime of a cluster.
        """
        return pulumi.get(self, "first_on_demand")

    @property
    @pulumi.getter(name="logAnalyticsInfo")
    def log_analytics_info(self) -> Optional['outputs.ClusterAzureAttributesLogAnalyticsInfo']:
        return pulumi.get(self, "log_analytics_info")

    @property
    @pulumi.getter(name="spotBidMaxPrice")
    def spot_bid_max_price(self) -> Optional[float]:
        """
        The max price for Azure spot instances.  Use `-1` to specify the lowest price.
        """
        return pulumi.get(self, "spot_bid_max_price")


@pulumi.output_type
class ClusterAzureAttributesLogAnalyticsInfo(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "logAnalyticsPrimaryKey":
            suggest = "log_analytics_primary_key"
        elif key == "logAnalyticsWorkspaceId":
            suggest = "log_analytics_workspace_id"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterAzureAttributesLogAnalyticsInfo. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterAzureAttributesLogAnalyticsInfo.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterAzureAttributesLogAnalyticsInfo.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 log_analytics_primary_key: Optional[str] = None,
                 log_analytics_workspace_id: Optional[str] = None):
        if log_analytics_primary_key is not None:
            pulumi.set(__self__, "log_analytics_primary_key", log_analytics_primary_key)
        if log_analytics_workspace_id is not None:
            pulumi.set(__self__, "log_analytics_workspace_id", log_analytics_workspace_id)

    @property
    @pulumi.getter(name="logAnalyticsPrimaryKey")
    def log_analytics_primary_key(self) -> Optional[str]:
        return pulumi.get(self, "log_analytics_primary_key")

    @property
    @pulumi.getter(name="logAnalyticsWorkspaceId")
    def log_analytics_workspace_id(self) -> Optional[str]:
        return pulumi.get(self, "log_analytics_workspace_id")


@pulumi.output_type
class ClusterClusterLogConf(dict):
    def __init__(__self__, *,
                 dbfs: Optional['outputs.ClusterClusterLogConfDbfs'] = None,
                 s3: Optional['outputs.ClusterClusterLogConfS3'] = None):
        if dbfs is not None:
            pulumi.set(__self__, "dbfs", dbfs)
        if s3 is not None:
            pulumi.set(__self__, "s3", s3)

    @property
    @pulumi.getter
    def dbfs(self) -> Optional['outputs.ClusterClusterLogConfDbfs']:
        return pulumi.get(self, "dbfs")

    @property
    @pulumi.getter
    def s3(self) -> Optional['outputs.ClusterClusterLogConfS3']:
        return pulumi.get(self, "s3")


@pulumi.output_type
class ClusterClusterLogConfDbfs(dict):
    def __init__(__self__, *,
                 destination: str):
        """
        :param str destination: S3 destination, e.g., `s3://my-bucket/some-prefix` You must configure the cluster with an instance profile, and the instance profile must have write access to the destination. You cannot use AWS keys.
        """
        pulumi.set(__self__, "destination", destination)

    @property
    @pulumi.getter
    def destination(self) -> str:
        """
        S3 destination, e.g., `s3://my-bucket/some-prefix` You must configure the cluster with an instance profile, and the instance profile must have write access to the destination. You cannot use AWS keys.
        """
        return pulumi.get(self, "destination")


@pulumi.output_type
class ClusterClusterLogConfS3(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "cannedAcl":
            suggest = "canned_acl"
        elif key == "enableEncryption":
            suggest = "enable_encryption"
        elif key == "encryptionType":
            suggest = "encryption_type"
        elif key == "kmsKey":
            suggest = "kms_key"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterClusterLogConfS3. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterClusterLogConfS3.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterClusterLogConfS3.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 destination: str,
                 canned_acl: Optional[str] = None,
                 enable_encryption: Optional[bool] = None,
                 encryption_type: Optional[str] = None,
                 endpoint: Optional[str] = None,
                 kms_key: Optional[str] = None,
                 region: Optional[str] = None):
        """
        :param str destination: S3 destination, e.g., `s3://my-bucket/some-prefix` You must configure the cluster with an instance profile, and the instance profile must have write access to the destination. You cannot use AWS keys.
        :param str canned_acl: Set canned access control list, e.g. `bucket-owner-full-control`. If `canned_cal` is set, the cluster instance profile must have `s3:PutObjectAcl` permission on the destination bucket and prefix. The full list of possible canned ACLs can be found [here](https://docs.aws.amazon.com/AmazonS3/latest/dev/acl-overview.html#canned-acl). By default, only the object owner gets full control. If you are using a cross-account role for writing data, you may want to set `bucket-owner-full-control` to make bucket owners able to read the logs.
        :param bool enable_encryption: Enable server-side encryption, false by default.
        :param str encryption_type: The encryption type, it could be `sse-s3` or `sse-kms`. It is used only when encryption is enabled, and the default type is `sse-s3`.
        :param str endpoint: S3 endpoint, e.g. <https://s3-us-west-2.amazonaws.com>. Either `region` or `endpoint` needs to be set. If both are set, the endpoint is used.
        :param str kms_key: KMS key used if encryption is enabled and encryption type is set to `sse-kms`.
        :param str region: S3 region, e.g. `us-west-2`. Either `region` or `endpoint` must be set. If both are set, the endpoint is used.
        """
        pulumi.set(__self__, "destination", destination)
        if canned_acl is not None:
            pulumi.set(__self__, "canned_acl", canned_acl)
        if enable_encryption is not None:
            pulumi.set(__self__, "enable_encryption", enable_encryption)
        if encryption_type is not None:
            pulumi.set(__self__, "encryption_type", encryption_type)
        if endpoint is not None:
            pulumi.set(__self__, "endpoint", endpoint)
        if kms_key is not None:
            pulumi.set(__self__, "kms_key", kms_key)
        if region is not None:
            pulumi.set(__self__, "region", region)

    @property
    @pulumi.getter
    def destination(self) -> str:
        """
        S3 destination, e.g., `s3://my-bucket/some-prefix` You must configure the cluster with an instance profile, and the instance profile must have write access to the destination. You cannot use AWS keys.
        """
        return pulumi.get(self, "destination")

    @property
    @pulumi.getter(name="cannedAcl")
    def canned_acl(self) -> Optional[str]:
        """
        Set canned access control list, e.g. `bucket-owner-full-control`. If `canned_cal` is set, the cluster instance profile must have `s3:PutObjectAcl` permission on the destination bucket and prefix. The full list of possible canned ACLs can be found [here](https://docs.aws.amazon.com/AmazonS3/latest/dev/acl-overview.html#canned-acl). By default, only the object owner gets full control. If you are using a cross-account role for writing data, you may want to set `bucket-owner-full-control` to make bucket owners able to read the logs.
        """
        return pulumi.get(self, "canned_acl")

    @property
    @pulumi.getter(name="enableEncryption")
    def enable_encryption(self) -> Optional[bool]:
        """
        Enable server-side encryption, false by default.
        """
        return pulumi.get(self, "enable_encryption")

    @property
    @pulumi.getter(name="encryptionType")
    def encryption_type(self) -> Optional[str]:
        """
        The encryption type, it could be `sse-s3` or `sse-kms`. It is used only when encryption is enabled, and the default type is `sse-s3`.
        """
        return pulumi.get(self, "encryption_type")

    @property
    @pulumi.getter
    def endpoint(self) -> Optional[str]:
        """
        S3 endpoint, e.g. <https://s3-us-west-2.amazonaws.com>. Either `region` or `endpoint` needs to be set. If both are set, the endpoint is used.
        """
        return pulumi.get(self, "endpoint")

    @property
    @pulumi.getter(name="kmsKey")
    def kms_key(self) -> Optional[str]:
        """
        KMS key used if encryption is enabled and encryption type is set to `sse-kms`.
        """
        return pulumi.get(self, "kms_key")

    @property
    @pulumi.getter
    def region(self) -> Optional[str]:
        """
        S3 region, e.g. `us-west-2`. Either `region` or `endpoint` must be set. If both are set, the endpoint is used.
        """
        return pulumi.get(self, "region")


@pulumi.output_type
class ClusterClusterMountInfo(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "localMountDirPath":
            suggest = "local_mount_dir_path"
        elif key == "networkFilesystemInfo":
            suggest = "network_filesystem_info"
        elif key == "remoteMountDirPath":
            suggest = "remote_mount_dir_path"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterClusterMountInfo. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterClusterMountInfo.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterClusterMountInfo.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 local_mount_dir_path: str,
                 network_filesystem_info: 'outputs.ClusterClusterMountInfoNetworkFilesystemInfo',
                 remote_mount_dir_path: Optional[str] = None):
        """
        :param str local_mount_dir_path: path inside the Spark container.
               
               For example, you can mount Azure Data Lake Storage container using the following code:
               
               <!--Start PulumiCodeChooser -->
               ```python
               import pulumi
               import pulumi_databricks as databricks
               
               storage_account = "ewfw3ggwegwg"
               storage_container = "test"
               with_nfs = databricks.Cluster("withNfs", cluster_mount_infos=[databricks.ClusterClusterMountInfoArgs(
                   local_mount_dir_path="/mnt/nfs-test",
                   network_filesystem_info=databricks.ClusterClusterMountInfoNetworkFilesystemInfoArgs(
                       mount_options="sec=sys,vers=3,nolock,proto=tcp",
                       server_address=f"{storage_account}.blob.core.windows.net",
                   ),
                   remote_mount_dir_path=f"{storage_account}/{storage_container}",
               )])
               ```
               <!--End PulumiCodeChooser -->
        :param 'ClusterClusterMountInfoNetworkFilesystemInfoArgs' network_filesystem_info: block specifying connection. It consists of:
        :param str remote_mount_dir_path: string specifying path to mount on the remote service.
        """
        pulumi.set(__self__, "local_mount_dir_path", local_mount_dir_path)
        pulumi.set(__self__, "network_filesystem_info", network_filesystem_info)
        if remote_mount_dir_path is not None:
            pulumi.set(__self__, "remote_mount_dir_path", remote_mount_dir_path)

    @property
    @pulumi.getter(name="localMountDirPath")
    def local_mount_dir_path(self) -> str:
        """
        path inside the Spark container.

        For example, you can mount Azure Data Lake Storage container using the following code:

        <!--Start PulumiCodeChooser -->
        ```python
        import pulumi
        import pulumi_databricks as databricks

        storage_account = "ewfw3ggwegwg"
        storage_container = "test"
        with_nfs = databricks.Cluster("withNfs", cluster_mount_infos=[databricks.ClusterClusterMountInfoArgs(
            local_mount_dir_path="/mnt/nfs-test",
            network_filesystem_info=databricks.ClusterClusterMountInfoNetworkFilesystemInfoArgs(
                mount_options="sec=sys,vers=3,nolock,proto=tcp",
                server_address=f"{storage_account}.blob.core.windows.net",
            ),
            remote_mount_dir_path=f"{storage_account}/{storage_container}",
        )])
        ```
        <!--End PulumiCodeChooser -->
        """
        return pulumi.get(self, "local_mount_dir_path")

    @property
    @pulumi.getter(name="networkFilesystemInfo")
    def network_filesystem_info(self) -> 'outputs.ClusterClusterMountInfoNetworkFilesystemInfo':
        """
        block specifying connection. It consists of:
        """
        return pulumi.get(self, "network_filesystem_info")

    @property
    @pulumi.getter(name="remoteMountDirPath")
    def remote_mount_dir_path(self) -> Optional[str]:
        """
        string specifying path to mount on the remote service.
        """
        return pulumi.get(self, "remote_mount_dir_path")


@pulumi.output_type
class ClusterClusterMountInfoNetworkFilesystemInfo(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "serverAddress":
            suggest = "server_address"
        elif key == "mountOptions":
            suggest = "mount_options"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterClusterMountInfoNetworkFilesystemInfo. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterClusterMountInfoNetworkFilesystemInfo.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterClusterMountInfoNetworkFilesystemInfo.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 server_address: str,
                 mount_options: Optional[str] = None):
        """
        :param str server_address: host name.
        :param str mount_options: string that will be passed as options passed to the `mount` command.
        """
        pulumi.set(__self__, "server_address", server_address)
        if mount_options is not None:
            pulumi.set(__self__, "mount_options", mount_options)

    @property
    @pulumi.getter(name="serverAddress")
    def server_address(self) -> str:
        """
        host name.
        """
        return pulumi.get(self, "server_address")

    @property
    @pulumi.getter(name="mountOptions")
    def mount_options(self) -> Optional[str]:
        """
        string that will be passed as options passed to the `mount` command.
        """
        return pulumi.get(self, "mount_options")


@pulumi.output_type
class ClusterDockerImage(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "basicAuth":
            suggest = "basic_auth"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterDockerImage. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterDockerImage.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterDockerImage.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 url: str,
                 basic_auth: Optional['outputs.ClusterDockerImageBasicAuth'] = None):
        """
        :param str url: URL for the Docker image
        :param 'ClusterDockerImageBasicAuthArgs' basic_auth: `basic_auth.username` and `basic_auth.password` for Docker repository. Docker registry credentials are encrypted when they are stored in Databricks internal storage and when they are passed to a registry upon fetching Docker images at cluster launch. However, other authenticated and authorized API users of this workspace can access the username and password.
               
               Example usage with azurerm_container_registry, that you can adapt to your specific use-case:
               
               <!--Start PulumiCodeChooser -->
               ```python
               import pulumi
               import pulumi_databricks as databricks
               import pulumi_docker as docker
               
               thisdocker_registry_image = docker.index.Docker_registry_image("thisdocker_registry_image",
                   name=f{azurerm_container_registry.this.login_server}/sample:latest,
                   build=[{}])
               this_cluster = databricks.Cluster("thisCluster", docker_image=databricks.ClusterDockerImageArgs(
                   url=thisdocker_registry_image["name"],
                   basic_auth=databricks.ClusterDockerImageBasicAuthArgs(
                       username=azurerm_container_registry["this"]["admin_username"],
                       password=azurerm_container_registry["this"]["admin_password"],
                   ),
               ))
               ```
               <!--End PulumiCodeChooser -->
        """
        pulumi.set(__self__, "url", url)
        if basic_auth is not None:
            pulumi.set(__self__, "basic_auth", basic_auth)

    @property
    @pulumi.getter
    def url(self) -> str:
        """
        URL for the Docker image
        """
        return pulumi.get(self, "url")

    @property
    @pulumi.getter(name="basicAuth")
    def basic_auth(self) -> Optional['outputs.ClusterDockerImageBasicAuth']:
        """
        `basic_auth.username` and `basic_auth.password` for Docker repository. Docker registry credentials are encrypted when they are stored in Databricks internal storage and when they are passed to a registry upon fetching Docker images at cluster launch. However, other authenticated and authorized API users of this workspace can access the username and password.

        Example usage with azurerm_container_registry, that you can adapt to your specific use-case:

        <!--Start PulumiCodeChooser -->
        ```python
        import pulumi
        import pulumi_databricks as databricks
        import pulumi_docker as docker

        thisdocker_registry_image = docker.index.Docker_registry_image("thisdocker_registry_image",
            name=f{azurerm_container_registry.this.login_server}/sample:latest,
            build=[{}])
        this_cluster = databricks.Cluster("thisCluster", docker_image=databricks.ClusterDockerImageArgs(
            url=thisdocker_registry_image["name"],
            basic_auth=databricks.ClusterDockerImageBasicAuthArgs(
                username=azurerm_container_registry["this"]["admin_username"],
                password=azurerm_container_registry["this"]["admin_password"],
            ),
        ))
        ```
        <!--End PulumiCodeChooser -->
        """
        return pulumi.get(self, "basic_auth")


@pulumi.output_type
class ClusterDockerImageBasicAuth(dict):
    def __init__(__self__, *,
                 password: str,
                 username: str):
        pulumi.set(__self__, "password", password)
        pulumi.set(__self__, "username", username)

    @property
    @pulumi.getter
    def password(self) -> str:
        return pulumi.get(self, "password")

    @property
    @pulumi.getter
    def username(self) -> str:
        return pulumi.get(self, "username")


@pulumi.output_type
class ClusterGcpAttributes(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "bootDiskSize":
            suggest = "boot_disk_size"
        elif key == "googleServiceAccount":
            suggest = "google_service_account"
        elif key == "localSsdCount":
            suggest = "local_ssd_count"
        elif key == "usePreemptibleExecutors":
            suggest = "use_preemptible_executors"
        elif key == "zoneId":
            suggest = "zone_id"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterGcpAttributes. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterGcpAttributes.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterGcpAttributes.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 availability: Optional[str] = None,
                 boot_disk_size: Optional[int] = None,
                 google_service_account: Optional[str] = None,
                 local_ssd_count: Optional[int] = None,
                 use_preemptible_executors: Optional[bool] = None,
                 zone_id: Optional[str] = None):
        """
        :param str availability: Availability type used for all nodes. Valid values are `PREEMPTIBLE_GCP`, `PREEMPTIBLE_WITH_FALLBACK_GCP` and `ON_DEMAND_GCP`, default: `ON_DEMAND_GCP`.
        :param int boot_disk_size: Boot disk size in GB
        :param str google_service_account: Google Service Account email address that the cluster uses to authenticate with Google Identity. This field is used for authentication with the GCS and BigQuery data sources.
        :param int local_ssd_count: Number of local SSD disks (each is 375GB in size) that will be attached to each node of the cluster.
        :param bool use_preemptible_executors: if we should use preemptible executors ([GCP documentation](https://cloud.google.com/compute/docs/instances/preemptible)). *Warning: this field is deprecated in favor of `availability`, and will be removed soon.*
        :param str zone_id: Identifier for the availability zone in which the cluster resides. This can be one of the following:
        """
        if availability is not None:
            pulumi.set(__self__, "availability", availability)
        if boot_disk_size is not None:
            pulumi.set(__self__, "boot_disk_size", boot_disk_size)
        if google_service_account is not None:
            pulumi.set(__self__, "google_service_account", google_service_account)
        if local_ssd_count is not None:
            pulumi.set(__self__, "local_ssd_count", local_ssd_count)
        if use_preemptible_executors is not None:
            pulumi.set(__self__, "use_preemptible_executors", use_preemptible_executors)
        if zone_id is not None:
            pulumi.set(__self__, "zone_id", zone_id)

    @property
    @pulumi.getter
    def availability(self) -> Optional[str]:
        """
        Availability type used for all nodes. Valid values are `PREEMPTIBLE_GCP`, `PREEMPTIBLE_WITH_FALLBACK_GCP` and `ON_DEMAND_GCP`, default: `ON_DEMAND_GCP`.
        """
        return pulumi.get(self, "availability")

    @property
    @pulumi.getter(name="bootDiskSize")
    def boot_disk_size(self) -> Optional[int]:
        """
        Boot disk size in GB
        """
        return pulumi.get(self, "boot_disk_size")

    @property
    @pulumi.getter(name="googleServiceAccount")
    def google_service_account(self) -> Optional[str]:
        """
        Google Service Account email address that the cluster uses to authenticate with Google Identity. This field is used for authentication with the GCS and BigQuery data sources.
        """
        return pulumi.get(self, "google_service_account")

    @property
    @pulumi.getter(name="localSsdCount")
    def local_ssd_count(self) -> Optional[int]:
        """
        Number of local SSD disks (each is 375GB in size) that will be attached to each node of the cluster.
        """
        return pulumi.get(self, "local_ssd_count")

    @property
    @pulumi.getter(name="usePreemptibleExecutors")
    def use_preemptible_executors(self) -> Optional[bool]:
        """
        if we should use preemptible executors ([GCP documentation](https://cloud.google.com/compute/docs/instances/preemptible)). *Warning: this field is deprecated in favor of `availability`, and will be removed soon.*
        """
        return pulumi.get(self, "use_preemptible_executors")

    @property
    @pulumi.getter(name="zoneId")
    def zone_id(self) -> Optional[str]:
        """
        Identifier for the availability zone in which the cluster resides. This can be one of the following:
        """
        return pulumi.get(self, "zone_id")


@pulumi.output_type
class ClusterInitScript(dict):
    def __init__(__self__, *,
                 abfss: Optional['outputs.ClusterInitScriptAbfss'] = None,
                 dbfs: Optional['outputs.ClusterInitScriptDbfs'] = None,
                 file: Optional['outputs.ClusterInitScriptFile'] = None,
                 gcs: Optional['outputs.ClusterInitScriptGcs'] = None,
                 s3: Optional['outputs.ClusterInitScriptS3'] = None,
                 volumes: Optional['outputs.ClusterInitScriptVolumes'] = None,
                 workspace: Optional['outputs.ClusterInitScriptWorkspace'] = None):
        if abfss is not None:
            pulumi.set(__self__, "abfss", abfss)
        if dbfs is not None:
            pulumi.set(__self__, "dbfs", dbfs)
        if file is not None:
            pulumi.set(__self__, "file", file)
        if gcs is not None:
            pulumi.set(__self__, "gcs", gcs)
        if s3 is not None:
            pulumi.set(__self__, "s3", s3)
        if volumes is not None:
            pulumi.set(__self__, "volumes", volumes)
        if workspace is not None:
            pulumi.set(__self__, "workspace", workspace)

    @property
    @pulumi.getter
    def abfss(self) -> Optional['outputs.ClusterInitScriptAbfss']:
        return pulumi.get(self, "abfss")

    @property
    @pulumi.getter
    def dbfs(self) -> Optional['outputs.ClusterInitScriptDbfs']:
        warnings.warn("""For init scripts use 'volumes', 'workspace' or cloud storage location instead of 'dbfs'.""", DeprecationWarning)
        pulumi.log.warn("""dbfs is deprecated: For init scripts use 'volumes', 'workspace' or cloud storage location instead of 'dbfs'.""")

        return pulumi.get(self, "dbfs")

    @property
    @pulumi.getter
    def file(self) -> Optional['outputs.ClusterInitScriptFile']:
        return pulumi.get(self, "file")

    @property
    @pulumi.getter
    def gcs(self) -> Optional['outputs.ClusterInitScriptGcs']:
        return pulumi.get(self, "gcs")

    @property
    @pulumi.getter
    def s3(self) -> Optional['outputs.ClusterInitScriptS3']:
        return pulumi.get(self, "s3")

    @property
    @pulumi.getter
    def volumes(self) -> Optional['outputs.ClusterInitScriptVolumes']:
        return pulumi.get(self, "volumes")

    @property
    @pulumi.getter
    def workspace(self) -> Optional['outputs.ClusterInitScriptWorkspace']:
        return pulumi.get(self, "workspace")


@pulumi.output_type
class ClusterInitScriptAbfss(dict):
    def __init__(__self__, *,
                 destination: str):
        """
        :param str destination: S3 destination, e.g., `s3://my-bucket/some-prefix` You must configure the cluster with an instance profile, and the instance profile must have write access to the destination. You cannot use AWS keys.
        """
        pulumi.set(__self__, "destination", destination)

    @property
    @pulumi.getter
    def destination(self) -> str:
        """
        S3 destination, e.g., `s3://my-bucket/some-prefix` You must configure the cluster with an instance profile, and the instance profile must have write access to the destination. You cannot use AWS keys.
        """
        return pulumi.get(self, "destination")


@pulumi.output_type
class ClusterInitScriptDbfs(dict):
    def __init__(__self__, *,
                 destination: str):
        """
        :param str destination: S3 destination, e.g., `s3://my-bucket/some-prefix` You must configure the cluster with an instance profile, and the instance profile must have write access to the destination. You cannot use AWS keys.
        """
        pulumi.set(__self__, "destination", destination)

    @property
    @pulumi.getter
    def destination(self) -> str:
        """
        S3 destination, e.g., `s3://my-bucket/some-prefix` You must configure the cluster with an instance profile, and the instance profile must have write access to the destination. You cannot use AWS keys.
        """
        return pulumi.get(self, "destination")


@pulumi.output_type
class ClusterInitScriptFile(dict):
    def __init__(__self__, *,
                 destination: str):
        """
        :param str destination: S3 destination, e.g., `s3://my-bucket/some-prefix` You must configure the cluster with an instance profile, and the instance profile must have write access to the destination. You cannot use AWS keys.
        """
        pulumi.set(__self__, "destination", destination)

    @property
    @pulumi.getter
    def destination(self) -> str:
        """
        S3 destination, e.g., `s3://my-bucket/some-prefix` You must configure the cluster with an instance profile, and the instance profile must have write access to the destination. You cannot use AWS keys.
        """
        return pulumi.get(self, "destination")


@pulumi.output_type
class ClusterInitScriptGcs(dict):
    def __init__(__self__, *,
                 destination: str):
        """
        :param str destination: S3 destination, e.g., `s3://my-bucket/some-prefix` You must configure the cluster with an instance profile, and the instance profile must have write access to the destination. You cannot use AWS keys.
        """
        pulumi.set(__self__, "destination", destination)

    @property
    @pulumi.getter
    def destination(self) -> str:
        """
        S3 destination, e.g., `s3://my-bucket/some-prefix` You must configure the cluster with an instance profile, and the instance profile must have write access to the destination. You cannot use AWS keys.
        """
        return pulumi.get(self, "destination")


@pulumi.output_type
class ClusterInitScriptS3(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "cannedAcl":
            suggest = "canned_acl"
        elif key == "enableEncryption":
            suggest = "enable_encryption"
        elif key == "encryptionType":
            suggest = "encryption_type"
        elif key == "kmsKey":
            suggest = "kms_key"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterInitScriptS3. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterInitScriptS3.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterInitScriptS3.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 destination: str,
                 canned_acl: Optional[str] = None,
                 enable_encryption: Optional[bool] = None,
                 encryption_type: Optional[str] = None,
                 endpoint: Optional[str] = None,
                 kms_key: Optional[str] = None,
                 region: Optional[str] = None):
        """
        :param str destination: S3 destination, e.g., `s3://my-bucket/some-prefix` You must configure the cluster with an instance profile, and the instance profile must have write access to the destination. You cannot use AWS keys.
        :param str canned_acl: Set canned access control list, e.g. `bucket-owner-full-control`. If `canned_cal` is set, the cluster instance profile must have `s3:PutObjectAcl` permission on the destination bucket and prefix. The full list of possible canned ACLs can be found [here](https://docs.aws.amazon.com/AmazonS3/latest/dev/acl-overview.html#canned-acl). By default, only the object owner gets full control. If you are using a cross-account role for writing data, you may want to set `bucket-owner-full-control` to make bucket owners able to read the logs.
        :param bool enable_encryption: Enable server-side encryption, false by default.
        :param str encryption_type: The encryption type, it could be `sse-s3` or `sse-kms`. It is used only when encryption is enabled, and the default type is `sse-s3`.
        :param str endpoint: S3 endpoint, e.g. <https://s3-us-west-2.amazonaws.com>. Either `region` or `endpoint` needs to be set. If both are set, the endpoint is used.
        :param str kms_key: KMS key used if encryption is enabled and encryption type is set to `sse-kms`.
        :param str region: S3 region, e.g. `us-west-2`. Either `region` or `endpoint` must be set. If both are set, the endpoint is used.
        """
        pulumi.set(__self__, "destination", destination)
        if canned_acl is not None:
            pulumi.set(__self__, "canned_acl", canned_acl)
        if enable_encryption is not None:
            pulumi.set(__self__, "enable_encryption", enable_encryption)
        if encryption_type is not None:
            pulumi.set(__self__, "encryption_type", encryption_type)
        if endpoint is not None:
            pulumi.set(__self__, "endpoint", endpoint)
        if kms_key is not None:
            pulumi.set(__self__, "kms_key", kms_key)
        if region is not None:
            pulumi.set(__self__, "region", region)

    @property
    @pulumi.getter
    def destination(self) -> str:
        """
        S3 destination, e.g., `s3://my-bucket/some-prefix` You must configure the cluster with an instance profile, and the instance profile must have write access to the destination. You cannot use AWS keys.
        """
        return pulumi.get(self, "destination")

    @property
    @pulumi.getter(name="cannedAcl")
    def canned_acl(self) -> Optional[str]:
        """
        Set canned access control list, e.g. `bucket-owner-full-control`. If `canned_cal` is set, the cluster instance profile must have `s3:PutObjectAcl` permission on the destination bucket and prefix. The full list of possible canned ACLs can be found [here](https://docs.aws.amazon.com/AmazonS3/latest/dev/acl-overview.html#canned-acl). By default, only the object owner gets full control. If you are using a cross-account role for writing data, you may want to set `bucket-owner-full-control` to make bucket owners able to read the logs.
        """
        return pulumi.get(self, "canned_acl")

    @property
    @pulumi.getter(name="enableEncryption")
    def enable_encryption(self) -> Optional[bool]:
        """
        Enable server-side encryption, false by default.
        """
        return pulumi.get(self, "enable_encryption")

    @property
    @pulumi.getter(name="encryptionType")
    def encryption_type(self) -> Optional[str]:
        """
        The encryption type, it could be `sse-s3` or `sse-kms`. It is used only when encryption is enabled, and the default type is `sse-s3`.
        """
        return pulumi.get(self, "encryption_type")

    @property
    @pulumi.getter
    def endpoint(self) -> Optional[str]:
        """
        S3 endpoint, e.g. <https://s3-us-west-2.amazonaws.com>. Either `region` or `endpoint` needs to be set. If both are set, the endpoint is used.
        """
        return pulumi.get(self, "endpoint")

    @property
    @pulumi.getter(name="kmsKey")
    def kms_key(self) -> Optional[str]:
        """
        KMS key used if encryption is enabled and encryption type is set to `sse-kms`.
        """
        return pulumi.get(self, "kms_key")

    @property
    @pulumi.getter
    def region(self) -> Optional[str]:
        """
        S3 region, e.g. `us-west-2`. Either `region` or `endpoint` must be set. If both are set, the endpoint is used.
        """
        return pulumi.get(self, "region")


@pulumi.output_type
class ClusterInitScriptVolumes(dict):
    def __init__(__self__, *,
                 destination: str):
        """
        :param str destination: S3 destination, e.g., `s3://my-bucket/some-prefix` You must configure the cluster with an instance profile, and the instance profile must have write access to the destination. You cannot use AWS keys.
        """
        pulumi.set(__self__, "destination", destination)

    @property
    @pulumi.getter
    def destination(self) -> str:
        """
        S3 destination, e.g., `s3://my-bucket/some-prefix` You must configure the cluster with an instance profile, and the instance profile must have write access to the destination. You cannot use AWS keys.
        """
        return pulumi.get(self, "destination")


@pulumi.output_type
class ClusterInitScriptWorkspace(dict):
    def __init__(__self__, *,
                 destination: str):
        """
        :param str destination: S3 destination, e.g., `s3://my-bucket/some-prefix` You must configure the cluster with an instance profile, and the instance profile must have write access to the destination. You cannot use AWS keys.
        """
        pulumi.set(__self__, "destination", destination)

    @property
    @pulumi.getter
    def destination(self) -> str:
        """
        S3 destination, e.g., `s3://my-bucket/some-prefix` You must configure the cluster with an instance profile, and the instance profile must have write access to the destination. You cannot use AWS keys.
        """
        return pulumi.get(self, "destination")


@pulumi.output_type
class ClusterLibrary(dict):
    def __init__(__self__, *,
                 cran: Optional['outputs.ClusterLibraryCran'] = None,
                 egg: Optional[str] = None,
                 jar: Optional[str] = None,
                 maven: Optional['outputs.ClusterLibraryMaven'] = None,
                 pypi: Optional['outputs.ClusterLibraryPypi'] = None,
                 whl: Optional[str] = None):
        if cran is not None:
            pulumi.set(__self__, "cran", cran)
        if egg is not None:
            pulumi.set(__self__, "egg", egg)
        if jar is not None:
            pulumi.set(__self__, "jar", jar)
        if maven is not None:
            pulumi.set(__self__, "maven", maven)
        if pypi is not None:
            pulumi.set(__self__, "pypi", pypi)
        if whl is not None:
            pulumi.set(__self__, "whl", whl)

    @property
    @pulumi.getter
    def cran(self) -> Optional['outputs.ClusterLibraryCran']:
        return pulumi.get(self, "cran")

    @property
    @pulumi.getter
    def egg(self) -> Optional[str]:
        return pulumi.get(self, "egg")

    @property
    @pulumi.getter
    def jar(self) -> Optional[str]:
        return pulumi.get(self, "jar")

    @property
    @pulumi.getter
    def maven(self) -> Optional['outputs.ClusterLibraryMaven']:
        return pulumi.get(self, "maven")

    @property
    @pulumi.getter
    def pypi(self) -> Optional['outputs.ClusterLibraryPypi']:
        return pulumi.get(self, "pypi")

    @property
    @pulumi.getter
    def whl(self) -> Optional[str]:
        return pulumi.get(self, "whl")


@pulumi.output_type
class ClusterLibraryCran(dict):
    def __init__(__self__, *,
                 package: str,
                 repo: Optional[str] = None):
        pulumi.set(__self__, "package", package)
        if repo is not None:
            pulumi.set(__self__, "repo", repo)

    @property
    @pulumi.getter
    def package(self) -> str:
        return pulumi.get(self, "package")

    @property
    @pulumi.getter
    def repo(self) -> Optional[str]:
        return pulumi.get(self, "repo")


@pulumi.output_type
class ClusterLibraryMaven(dict):
    def __init__(__self__, *,
                 coordinates: str,
                 exclusions: Optional[Sequence[str]] = None,
                 repo: Optional[str] = None):
        pulumi.set(__self__, "coordinates", coordinates)
        if exclusions is not None:
            pulumi.set(__self__, "exclusions", exclusions)
        if repo is not None:
            pulumi.set(__self__, "repo", repo)

    @property
    @pulumi.getter
    def coordinates(self) -> str:
        return pulumi.get(self, "coordinates")

    @property
    @pulumi.getter
    def exclusions(self) -> Optional[Sequence[str]]:
        return pulumi.get(self, "exclusions")

    @property
    @pulumi.getter
    def repo(self) -> Optional[str]:
        return pulumi.get(self, "repo")


@pulumi.output_type
class ClusterLibraryPypi(dict):
    def __init__(__self__, *,
                 package: str,
                 repo: Optional[str] = None):
        pulumi.set(__self__, "package", package)
        if repo is not None:
            pulumi.set(__self__, "repo", repo)

    @property
    @pulumi.getter
    def package(self) -> str:
        return pulumi.get(self, "package")

    @property
    @pulumi.getter
    def repo(self) -> Optional[str]:
        return pulumi.get(self, "repo")


@pulumi.output_type
class ClusterPolicyLibrary(dict):
    def __init__(__self__, *,
                 cran: Optional['outputs.ClusterPolicyLibraryCran'] = None,
                 egg: Optional[str] = None,
                 jar: Optional[str] = None,
                 maven: Optional['outputs.ClusterPolicyLibraryMaven'] = None,
                 pypi: Optional['outputs.ClusterPolicyLibraryPypi'] = None,
                 whl: Optional[str] = None):
        if cran is not None:
            pulumi.set(__self__, "cran", cran)
        if egg is not None:
            pulumi.set(__self__, "egg", egg)
        if jar is not None:
            pulumi.set(__self__, "jar", jar)
        if maven is not None:
            pulumi.set(__self__, "maven", maven)
        if pypi is not None:
            pulumi.set(__self__, "pypi", pypi)
        if whl is not None:
            pulumi.set(__self__, "whl", whl)

    @property
    @pulumi.getter
    def cran(self) -> Optional['outputs.ClusterPolicyLibraryCran']:
        return pulumi.get(self, "cran")

    @property
    @pulumi.getter
    def egg(self) -> Optional[str]:
        return pulumi.get(self, "egg")

    @property
    @pulumi.getter
    def jar(self) -> Optional[str]:
        return pulumi.get(self, "jar")

    @property
    @pulumi.getter
    def maven(self) -> Optional['outputs.ClusterPolicyLibraryMaven']:
        return pulumi.get(self, "maven")

    @property
    @pulumi.getter
    def pypi(self) -> Optional['outputs.ClusterPolicyLibraryPypi']:
        return pulumi.get(self, "pypi")

    @property
    @pulumi.getter
    def whl(self) -> Optional[str]:
        return pulumi.get(self, "whl")


@pulumi.output_type
class ClusterPolicyLibraryCran(dict):
    def __init__(__self__, *,
                 package: str,
                 repo: Optional[str] = None):
        pulumi.set(__self__, "package", package)
        if repo is not None:
            pulumi.set(__self__, "repo", repo)

    @property
    @pulumi.getter
    def package(self) -> str:
        return pulumi.get(self, "package")

    @property
    @pulumi.getter
    def repo(self) -> Optional[str]:
        return pulumi.get(self, "repo")


@pulumi.output_type
class ClusterPolicyLibraryMaven(dict):
    def __init__(__self__, *,
                 coordinates: str,
                 exclusions: Optional[Sequence[str]] = None,
                 repo: Optional[str] = None):
        pulumi.set(__self__, "coordinates", coordinates)
        if exclusions is not None:
            pulumi.set(__self__, "exclusions", exclusions)
        if repo is not None:
            pulumi.set(__self__, "repo", repo)

    @property
    @pulumi.getter
    def coordinates(self) -> str:
        return pulumi.get(self, "coordinates")

    @property
    @pulumi.getter
    def exclusions(self) -> Optional[Sequence[str]]:
        return pulumi.get(self, "exclusions")

    @property
    @pulumi.getter
    def repo(self) -> Optional[str]:
        return pulumi.get(self, "repo")


@pulumi.output_type
class ClusterPolicyLibraryPypi(dict):
    def __init__(__self__, *,
                 package: str,
                 repo: Optional[str] = None):
        pulumi.set(__self__, "package", package)
        if repo is not None:
            pulumi.set(__self__, "repo", repo)

    @property
    @pulumi.getter
    def package(self) -> str:
        return pulumi.get(self, "package")

    @property
    @pulumi.getter
    def repo(self) -> Optional[str]:
        return pulumi.get(self, "repo")


@pulumi.output_type
class ClusterWorkloadType(dict):
    def __init__(__self__, *,
                 clients: 'outputs.ClusterWorkloadTypeClients'):
        pulumi.set(__self__, "clients", clients)

    @property
    @pulumi.getter
    def clients(self) -> 'outputs.ClusterWorkloadTypeClients':
        return pulumi.get(self, "clients")


@pulumi.output_type
class ClusterWorkloadTypeClients(dict):
    def __init__(__self__, *,
                 jobs: Optional[bool] = None,
                 notebooks: Optional[bool] = None):
        """
        :param bool jobs: boolean flag defining if it's possible to run Databricks Jobs on this cluster. Default: `true`.
               
               <!--Start PulumiCodeChooser -->
               ```python
               import pulumi
               import pulumi_databricks as databricks
               
               with_nfs = databricks.Cluster("withNfs", workload_type=databricks.ClusterWorkloadTypeArgs(
                   clients=databricks.ClusterWorkloadTypeClientsArgs(
                       jobs=False,
                       notebooks=True,
                   ),
               ))
               ```
               <!--End PulumiCodeChooser -->
        :param bool notebooks: boolean flag defining if it's possible to run notebooks on this cluster. Default: `true`.
        """
        if jobs is not None:
            pulumi.set(__self__, "jobs", jobs)
        if notebooks is not None:
            pulumi.set(__self__, "notebooks", notebooks)

    @property
    @pulumi.getter
    def jobs(self) -> Optional[bool]:
        """
        boolean flag defining if it's possible to run Databricks Jobs on this cluster. Default: `true`.

        <!--Start PulumiCodeChooser -->
        ```python
        import pulumi
        import pulumi_databricks as databricks

        with_nfs = databricks.Cluster("withNfs", workload_type=databricks.ClusterWorkloadTypeArgs(
            clients=databricks.ClusterWorkloadTypeClientsArgs(
                jobs=False,
                notebooks=True,
            ),
        ))
        ```
        <!--End PulumiCodeChooser -->
        """
        return pulumi.get(self, "jobs")

    @property
    @pulumi.getter
    def notebooks(self) -> Optional[bool]:
        """
        boolean flag defining if it's possible to run notebooks on this cluster. Default: `true`.
        """
        return pulumi.get(self, "notebooks")


@pulumi.output_type
class DefaultNamespaceSettingNamespace(dict):
    def __init__(__self__, *,
                 value: Optional[str] = None):
        """
        :param str value: The value for the setting.
        """
        if value is not None:
            pulumi.set(__self__, "value", value)

    @property
    @pulumi.getter
    def value(self) -> Optional[str]:
        """
        The value for the setting.
        """
        return pulumi.get(self, "value")


@pulumi.output_type
class ExternalLocationEncryptionDetails(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "sseEncryptionDetails":
            suggest = "sse_encryption_details"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ExternalLocationEncryptionDetails. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ExternalLocationEncryptionDetails.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ExternalLocationEncryptionDetails.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 sse_encryption_details: Optional['outputs.ExternalLocationEncryptionDetailsSseEncryptionDetails'] = None):
        if sse_encryption_details is not None:
            pulumi.set(__self__, "sse_encryption_details", sse_encryption_details)

    @property
    @pulumi.getter(name="sseEncryptionDetails")
    def sse_encryption_details(self) -> Optional['outputs.ExternalLocationEncryptionDetailsSseEncryptionDetails']:
        return pulumi.get(self, "sse_encryption_details")


@pulumi.output_type
class ExternalLocationEncryptionDetailsSseEncryptionDetails(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "awsKmsKeyArn":
            suggest = "aws_kms_key_arn"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ExternalLocationEncryptionDetailsSseEncryptionDetails. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ExternalLocationEncryptionDetailsSseEncryptionDetails.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ExternalLocationEncryptionDetailsSseEncryptionDetails.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 algorithm: Optional[str] = None,
                 aws_kms_key_arn: Optional[str] = None):
        if algorithm is not None:
            pulumi.set(__self__, "algorithm", algorithm)
        if aws_kms_key_arn is not None:
            pulumi.set(__self__, "aws_kms_key_arn", aws_kms_key_arn)

    @property
    @pulumi.getter
    def algorithm(self) -> Optional[str]:
        return pulumi.get(self, "algorithm")

    @property
    @pulumi.getter(name="awsKmsKeyArn")
    def aws_kms_key_arn(self) -> Optional[str]:
        return pulumi.get(self, "aws_kms_key_arn")


@pulumi.output_type
class GrantsGrant(dict):
    def __init__(__self__, *,
                 principal: str,
                 privileges: Sequence[str]):
        pulumi.set(__self__, "principal", principal)
        pulumi.set(__self__, "privileges", privileges)

    @property
    @pulumi.getter
    def principal(self) -> str:
        return pulumi.get(self, "principal")

    @property
    @pulumi.getter
    def privileges(self) -> Sequence[str]:
        return pulumi.get(self, "privileges")


@pulumi.output_type
class InstancePoolAwsAttributes(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "spotBidPricePercent":
            suggest = "spot_bid_price_percent"
        elif key == "zoneId":
            suggest = "zone_id"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in InstancePoolAwsAttributes. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        InstancePoolAwsAttributes.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        InstancePoolAwsAttributes.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 availability: Optional[str] = None,
                 spot_bid_price_percent: Optional[int] = None,
                 zone_id: Optional[str] = None):
        """
        :param str availability: (String) Availability type used for all instances in the pool. Only `ON_DEMAND` and `SPOT` are supported.
        :param int spot_bid_price_percent: (Integer) The max price for AWS spot instances, as a percentage of the corresponding instance type’s on-demand price. For example, if this field is set to 50, and the instance pool needs a new i3.xlarge spot instance, then the max price is half of the price of on-demand i3.xlarge instances. Similarly, if this field is set to 200, the max price is twice the price of on-demand i3.xlarge instances. If not specified, the *default value is 100*. When spot instances are requested for this instance pool, only spot instances whose max price percentage matches this field are considered. *For safety, this field cannot be greater than 10000.*
        :param str zone_id: (String) Identifier for the availability zone/datacenter in which the instance pool resides. This string is of the form like `"us-west-2a"`. The provided availability zone must be in the same region as the Databricks deployment. For example, `"us-west-2a"` is not a valid zone ID if the Databricks deployment resides in the `"us-east-1"` region. If not specified, a default zone is used. You can find the list of available zones as well as the default value by using the [List Zones API](https://docs.databricks.com/dev-tools/api/latest/clusters.html#clusterclusterservicelistavailablezones).
        """
        if availability is not None:
            pulumi.set(__self__, "availability", availability)
        if spot_bid_price_percent is not None:
            pulumi.set(__self__, "spot_bid_price_percent", spot_bid_price_percent)
        if zone_id is not None:
            pulumi.set(__self__, "zone_id", zone_id)

    @property
    @pulumi.getter
    def availability(self) -> Optional[str]:
        """
        (String) Availability type used for all instances in the pool. Only `ON_DEMAND` and `SPOT` are supported.
        """
        return pulumi.get(self, "availability")

    @property
    @pulumi.getter(name="spotBidPricePercent")
    def spot_bid_price_percent(self) -> Optional[int]:
        """
        (Integer) The max price for AWS spot instances, as a percentage of the corresponding instance type’s on-demand price. For example, if this field is set to 50, and the instance pool needs a new i3.xlarge spot instance, then the max price is half of the price of on-demand i3.xlarge instances. Similarly, if this field is set to 200, the max price is twice the price of on-demand i3.xlarge instances. If not specified, the *default value is 100*. When spot instances are requested for this instance pool, only spot instances whose max price percentage matches this field are considered. *For safety, this field cannot be greater than 10000.*
        """
        return pulumi.get(self, "spot_bid_price_percent")

    @property
    @pulumi.getter(name="zoneId")
    def zone_id(self) -> Optional[str]:
        """
        (String) Identifier for the availability zone/datacenter in which the instance pool resides. This string is of the form like `"us-west-2a"`. The provided availability zone must be in the same region as the Databricks deployment. For example, `"us-west-2a"` is not a valid zone ID if the Databricks deployment resides in the `"us-east-1"` region. If not specified, a default zone is used. You can find the list of available zones as well as the default value by using the [List Zones API](https://docs.databricks.com/dev-tools/api/latest/clusters.html#clusterclusterservicelistavailablezones).
        """
        return pulumi.get(self, "zone_id")


@pulumi.output_type
class InstancePoolAzureAttributes(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "spotBidMaxPrice":
            suggest = "spot_bid_max_price"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in InstancePoolAzureAttributes. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        InstancePoolAzureAttributes.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        InstancePoolAzureAttributes.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 availability: Optional[str] = None,
                 spot_bid_max_price: Optional[float] = None):
        """
        :param str availability: Availability type used for all nodes. Valid values are `SPOT_AZURE` and `ON_DEMAND_AZURE`.
        :param float spot_bid_max_price: The max price for Azure spot instances.  Use `-1` to specify the lowest price.
        """
        if availability is not None:
            pulumi.set(__self__, "availability", availability)
        if spot_bid_max_price is not None:
            pulumi.set(__self__, "spot_bid_max_price", spot_bid_max_price)

    @property
    @pulumi.getter
    def availability(self) -> Optional[str]:
        """
        Availability type used for all nodes. Valid values are `SPOT_AZURE` and `ON_DEMAND_AZURE`.
        """
        return pulumi.get(self, "availability")

    @property
    @pulumi.getter(name="spotBidMaxPrice")
    def spot_bid_max_price(self) -> Optional[float]:
        """
        The max price for Azure spot instances.  Use `-1` to specify the lowest price.
        """
        return pulumi.get(self, "spot_bid_max_price")


@pulumi.output_type
class InstancePoolDiskSpec(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "diskCount":
            suggest = "disk_count"
        elif key == "diskSize":
            suggest = "disk_size"
        elif key == "diskType":
            suggest = "disk_type"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in InstancePoolDiskSpec. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        InstancePoolDiskSpec.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        InstancePoolDiskSpec.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 disk_count: Optional[int] = None,
                 disk_size: Optional[int] = None,
                 disk_type: Optional['outputs.InstancePoolDiskSpecDiskType'] = None):
        """
        :param int disk_count: (Integer) The number of disks to attach to each instance. This feature is only enabled for supported node types. Users can choose up to the limit of the disks supported by the node type. For node types with no local disk, at least one disk needs to be specified.
        :param int disk_size: (Integer) The size of each disk (in GiB) to attach.
        """
        if disk_count is not None:
            pulumi.set(__self__, "disk_count", disk_count)
        if disk_size is not None:
            pulumi.set(__self__, "disk_size", disk_size)
        if disk_type is not None:
            pulumi.set(__self__, "disk_type", disk_type)

    @property
    @pulumi.getter(name="diskCount")
    def disk_count(self) -> Optional[int]:
        """
        (Integer) The number of disks to attach to each instance. This feature is only enabled for supported node types. Users can choose up to the limit of the disks supported by the node type. For node types with no local disk, at least one disk needs to be specified.
        """
        return pulumi.get(self, "disk_count")

    @property
    @pulumi.getter(name="diskSize")
    def disk_size(self) -> Optional[int]:
        """
        (Integer) The size of each disk (in GiB) to attach.
        """
        return pulumi.get(self, "disk_size")

    @property
    @pulumi.getter(name="diskType")
    def disk_type(self) -> Optional['outputs.InstancePoolDiskSpecDiskType']:
        return pulumi.get(self, "disk_type")


@pulumi.output_type
class InstancePoolDiskSpecDiskType(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "azureDiskVolumeType":
            suggest = "azure_disk_volume_type"
        elif key == "ebsVolumeType":
            suggest = "ebs_volume_type"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in InstancePoolDiskSpecDiskType. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        InstancePoolDiskSpecDiskType.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        InstancePoolDiskSpecDiskType.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 azure_disk_volume_type: Optional[str] = None,
                 ebs_volume_type: Optional[str] = None):
        if azure_disk_volume_type is not None:
            pulumi.set(__self__, "azure_disk_volume_type", azure_disk_volume_type)
        if ebs_volume_type is not None:
            pulumi.set(__self__, "ebs_volume_type", ebs_volume_type)

    @property
    @pulumi.getter(name="azureDiskVolumeType")
    def azure_disk_volume_type(self) -> Optional[str]:
        return pulumi.get(self, "azure_disk_volume_type")

    @property
    @pulumi.getter(name="ebsVolumeType")
    def ebs_volume_type(self) -> Optional[str]:
        return pulumi.get(self, "ebs_volume_type")


@pulumi.output_type
class InstancePoolGcpAttributes(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "gcpAvailability":
            suggest = "gcp_availability"
        elif key == "localSsdCount":
            suggest = "local_ssd_count"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in InstancePoolGcpAttributes. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        InstancePoolGcpAttributes.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        InstancePoolGcpAttributes.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 gcp_availability: Optional[str] = None,
                 local_ssd_count: Optional[int] = None):
        """
        :param str gcp_availability: Availability type used for all nodes. Valid values are `PREEMPTIBLE_GCP`, `PREEMPTIBLE_WITH_FALLBACK_GCP` and `ON_DEMAND_GCP`, default: `ON_DEMAND_GCP`.
        :param int local_ssd_count: Number of local SSD disks (each is 375GB in size) that will be attached to each node of the cluster.
        """
        if gcp_availability is not None:
            pulumi.set(__self__, "gcp_availability", gcp_availability)
        if local_ssd_count is not None:
            pulumi.set(__self__, "local_ssd_count", local_ssd_count)

    @property
    @pulumi.getter(name="gcpAvailability")
    def gcp_availability(self) -> Optional[str]:
        """
        Availability type used for all nodes. Valid values are `PREEMPTIBLE_GCP`, `PREEMPTIBLE_WITH_FALLBACK_GCP` and `ON_DEMAND_GCP`, default: `ON_DEMAND_GCP`.
        """
        return pulumi.get(self, "gcp_availability")

    @property
    @pulumi.getter(name="localSsdCount")
    def local_ssd_count(self) -> Optional[int]:
        """
        Number of local SSD disks (each is 375GB in size) that will be attached to each node of the cluster.
        """
        return pulumi.get(self, "local_ssd_count")


@pulumi.output_type
class InstancePoolInstancePoolFleetAttributes(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "launchTemplateOverrides":
            suggest = "launch_template_overrides"
        elif key == "fleetOnDemandOption":
            suggest = "fleet_on_demand_option"
        elif key == "fleetSpotOption":
            suggest = "fleet_spot_option"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in InstancePoolInstancePoolFleetAttributes. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        InstancePoolInstancePoolFleetAttributes.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        InstancePoolInstancePoolFleetAttributes.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 launch_template_overrides: Sequence['outputs.InstancePoolInstancePoolFleetAttributesLaunchTemplateOverride'],
                 fleet_on_demand_option: Optional['outputs.InstancePoolInstancePoolFleetAttributesFleetOnDemandOption'] = None,
                 fleet_spot_option: Optional['outputs.InstancePoolInstancePoolFleetAttributesFleetSpotOption'] = None):
        pulumi.set(__self__, "launch_template_overrides", launch_template_overrides)
        if fleet_on_demand_option is not None:
            pulumi.set(__self__, "fleet_on_demand_option", fleet_on_demand_option)
        if fleet_spot_option is not None:
            pulumi.set(__self__, "fleet_spot_option", fleet_spot_option)

    @property
    @pulumi.getter(name="launchTemplateOverrides")
    def launch_template_overrides(self) -> Sequence['outputs.InstancePoolInstancePoolFleetAttributesLaunchTemplateOverride']:
        return pulumi.get(self, "launch_template_overrides")

    @property
    @pulumi.getter(name="fleetOnDemandOption")
    def fleet_on_demand_option(self) -> Optional['outputs.InstancePoolInstancePoolFleetAttributesFleetOnDemandOption']:
        return pulumi.get(self, "fleet_on_demand_option")

    @property
    @pulumi.getter(name="fleetSpotOption")
    def fleet_spot_option(self) -> Optional['outputs.InstancePoolInstancePoolFleetAttributesFleetSpotOption']:
        return pulumi.get(self, "fleet_spot_option")


@pulumi.output_type
class InstancePoolInstancePoolFleetAttributesFleetOnDemandOption(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "allocationStrategy":
            suggest = "allocation_strategy"
        elif key == "instancePoolsToUseCount":
            suggest = "instance_pools_to_use_count"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in InstancePoolInstancePoolFleetAttributesFleetOnDemandOption. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        InstancePoolInstancePoolFleetAttributesFleetOnDemandOption.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        InstancePoolInstancePoolFleetAttributesFleetOnDemandOption.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 allocation_strategy: str,
                 instance_pools_to_use_count: Optional[int] = None):
        pulumi.set(__self__, "allocation_strategy", allocation_strategy)
        if instance_pools_to_use_count is not None:
            pulumi.set(__self__, "instance_pools_to_use_count", instance_pools_to_use_count)

    @property
    @pulumi.getter(name="allocationStrategy")
    def allocation_strategy(self) -> str:
        return pulumi.get(self, "allocation_strategy")

    @property
    @pulumi.getter(name="instancePoolsToUseCount")
    def instance_pools_to_use_count(self) -> Optional[int]:
        return pulumi.get(self, "instance_pools_to_use_count")


@pulumi.output_type
class InstancePoolInstancePoolFleetAttributesFleetSpotOption(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "allocationStrategy":
            suggest = "allocation_strategy"
        elif key == "instancePoolsToUseCount":
            suggest = "instance_pools_to_use_count"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in InstancePoolInstancePoolFleetAttributesFleetSpotOption. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        InstancePoolInstancePoolFleetAttributesFleetSpotOption.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        InstancePoolInstancePoolFleetAttributesFleetSpotOption.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 allocation_strategy: str,
                 instance_pools_to_use_count: Optional[int] = None):
        pulumi.set(__self__, "allocation_strategy", allocation_strategy)
        if instance_pools_to_use_count is not None:
            pulumi.set(__self__, "instance_pools_to_use_count", instance_pools_to_use_count)

    @property
    @pulumi.getter(name="allocationStrategy")
    def allocation_strategy(self) -> str:
        return pulumi.get(self, "allocation_strategy")

    @property
    @pulumi.getter(name="instancePoolsToUseCount")
    def instance_pools_to_use_count(self) -> Optional[int]:
        return pulumi.get(self, "instance_pools_to_use_count")


@pulumi.output_type
class InstancePoolInstancePoolFleetAttributesLaunchTemplateOverride(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "availabilityZone":
            suggest = "availability_zone"
        elif key == "instanceType":
            suggest = "instance_type"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in InstancePoolInstancePoolFleetAttributesLaunchTemplateOverride. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        InstancePoolInstancePoolFleetAttributesLaunchTemplateOverride.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        InstancePoolInstancePoolFleetAttributesLaunchTemplateOverride.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 availability_zone: str,
                 instance_type: str):
        pulumi.set(__self__, "availability_zone", availability_zone)
        pulumi.set(__self__, "instance_type", instance_type)

    @property
    @pulumi.getter(name="availabilityZone")
    def availability_zone(self) -> str:
        return pulumi.get(self, "availability_zone")

    @property
    @pulumi.getter(name="instanceType")
    def instance_type(self) -> str:
        return pulumi.get(self, "instance_type")


@pulumi.output_type
class InstancePoolPreloadedDockerImage(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "basicAuth":
            suggest = "basic_auth"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in InstancePoolPreloadedDockerImage. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        InstancePoolPreloadedDockerImage.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        InstancePoolPreloadedDockerImage.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 url: str,
                 basic_auth: Optional['outputs.InstancePoolPreloadedDockerImageBasicAuth'] = None):
        """
        :param str url: URL for the Docker image
        :param 'InstancePoolPreloadedDockerImageBasicAuthArgs' basic_auth: `basic_auth.username` and `basic_auth.password` for Docker repository. Docker registry credentials are encrypted when they are stored in Databricks internal storage and when they are passed to a registry upon fetching Docker images at cluster launch. However, other authenticated and authorized API users of this workspace can access the username and password.
               
               Example usage with azurerm_container_registry, that you can adapt to your specific use-case:
               
               <!--Start PulumiCodeChooser -->
               ```python
               import pulumi
               import pulumi_databricks as databricks
               import pulumi_docker as docker
               
               thisdocker_registry_image = docker.index.Docker_registry_image("thisdocker_registry_image",
                   name=f{azurerm_container_registry.this.login_server}/sample:latest,
                   build=[{}])
               this_instance_pool = databricks.InstancePool("thisInstancePool", preloaded_docker_images=[databricks.InstancePoolPreloadedDockerImageArgs(
                   url=thisdocker_registry_image["name"],
                   basic_auth=databricks.InstancePoolPreloadedDockerImageBasicAuthArgs(
                       username=azurerm_container_registry["this"]["admin_username"],
                       password=azurerm_container_registry["this"]["admin_password"],
                   ),
               )])
               ```
               <!--End PulumiCodeChooser -->
        """
        pulumi.set(__self__, "url", url)
        if basic_auth is not None:
            pulumi.set(__self__, "basic_auth", basic_auth)

    @property
    @pulumi.getter
    def url(self) -> str:
        """
        URL for the Docker image
        """
        return pulumi.get(self, "url")

    @property
    @pulumi.getter(name="basicAuth")
    def basic_auth(self) -> Optional['outputs.InstancePoolPreloadedDockerImageBasicAuth']:
        """
        `basic_auth.username` and `basic_auth.password` for Docker repository. Docker registry credentials are encrypted when they are stored in Databricks internal storage and when they are passed to a registry upon fetching Docker images at cluster launch. However, other authenticated and authorized API users of this workspace can access the username and password.

        Example usage with azurerm_container_registry, that you can adapt to your specific use-case:

        <!--Start PulumiCodeChooser -->
        ```python
        import pulumi
        import pulumi_databricks as databricks
        import pulumi_docker as docker

        thisdocker_registry_image = docker.index.Docker_registry_image("thisdocker_registry_image",
            name=f{azurerm_container_registry.this.login_server}/sample:latest,
            build=[{}])
        this_instance_pool = databricks.InstancePool("thisInstancePool", preloaded_docker_images=[databricks.InstancePoolPreloadedDockerImageArgs(
            url=thisdocker_registry_image["name"],
            basic_auth=databricks.InstancePoolPreloadedDockerImageBasicAuthArgs(
                username=azurerm_container_registry["this"]["admin_username"],
                password=azurerm_container_registry["this"]["admin_password"],
            ),
        )])
        ```
        <!--End PulumiCodeChooser -->
        """
        return pulumi.get(self, "basic_auth")


@pulumi.output_type
class InstancePoolPreloadedDockerImageBasicAuth(dict):
    def __init__(__self__, *,
                 password: str,
                 username: str):
        pulumi.set(__self__, "password", password)
        pulumi.set(__self__, "username", username)

    @property
    @pulumi.getter
    def password(self) -> str:
        return pulumi.get(self, "password")

    @property
    @pulumi.getter
    def username(self) -> str:
        return pulumi.get(self, "username")


@pulumi.output_type
class JobCompute(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "computeKey":
            suggest = "compute_key"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in JobCompute. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        JobCompute.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        JobCompute.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 compute_key: Optional[str] = None,
                 spec: Optional['outputs.JobComputeSpec'] = None):
        if compute_key is not None:
            pulumi.set(__self__, "compute_key", compute_key)
        if spec is not None:
            pulumi.set(__self__, "spec", spec)

    @property
    @pulumi.getter(name="computeKey")
    def compute_key(self) -> Optional[str]:
        return pulumi.get(self, "compute_key")

    @property
    @pulumi.getter
    def spec(self) -> Optional['outputs.JobComputeSpec']:
        return pulumi.get(self, "spec")


@pulumi.output_type
class JobComputeSpec(dict):
    def __init__(__self__, *,
                 kind: Optional[str] = None):
        if kind is not None:
            pulumi.set(__self__, "kind", kind)

    @property
    @pulumi.getter
    def kind(self) -> Optional[str]:
        return pulumi.get(self, "kind")


@pulumi.output_type
class JobContinuous(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "pauseStatus":
            suggest = "pause_status"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in JobContinuous. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        JobContinuous.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        JobContinuous.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 pause_status: Optional[str] = None):
        """
        :param str pause_status: Indicate whether this continuous job is paused or not. Either `PAUSED` or `UNPAUSED`. When the `pause_status` field is omitted in the block, the server will default to using `UNPAUSED` as a value for `pause_status`.
        """
        if pause_status is not None:
            pulumi.set(__self__, "pause_status", pause_status)

    @property
    @pulumi.getter(name="pauseStatus")
    def pause_status(self) -> Optional[str]:
        """
        Indicate whether this continuous job is paused or not. Either `PAUSED` or `UNPAUSED`. When the `pause_status` field is omitted in the block, the server will default to using `UNPAUSED` as a value for `pause_status`.
        """
        return pulumi.get(self, "pause_status")


@pulumi.output_type
class JobDbtTask(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "profilesDirectory":
            suggest = "profiles_directory"
        elif key == "projectDirectory":
            suggest = "project_directory"
        elif key == "warehouseId":
            suggest = "warehouse_id"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in JobDbtTask. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        JobDbtTask.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        JobDbtTask.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 commands: Sequence[str],
                 catalog: Optional[str] = None,
                 profiles_directory: Optional[str] = None,
                 project_directory: Optional[str] = None,
                 schema: Optional[str] = None,
                 source: Optional[str] = None,
                 warehouse_id: Optional[str] = None):
        """
        :param Sequence[str] commands: (Array) Series of dbt commands to execute in sequence. Every command must start with "dbt".
        :param str catalog: The name of the catalog to use inside Unity Catalog.
        :param str profiles_directory: The relative path to the directory in the repository specified by `git_source` where dbt should look in for the `profiles.yml` file. If not specified, defaults to the repository's root directory. Equivalent to passing `--profile-dir` to a dbt command.
        :param str project_directory: The path where dbt should look for `dbt_project.yml`. Equivalent to passing `--project-dir` to the dbt CLI.
               * If `source` is `GIT`: Relative path to the directory in the repository specified in the `git_source` block. Defaults to the repository's root directory when not specified.
               * If `source` is `WORKSPACE`: Absolute path to the folder in the workspace.
        :param str schema: The name of the schema dbt should run in. Defaults to `default`.
        :param str source: The source of the project. Possible values are `WORKSPACE` and `GIT`.  Defaults to `GIT` if a `git_source` block is present in the job definition.
        :param str warehouse_id: The ID of the SQL warehouse that dbt should execute against.
               
               You also need to include a `git_source` block to configure the repository that contains the dbt project.
        """
        pulumi.set(__self__, "commands", commands)
        if catalog is not None:
            pulumi.set(__self__, "catalog", catalog)
        if profiles_directory is not None:
            pulumi.set(__self__, "profiles_directory", profiles_directory)
        if project_directory is not None:
            pulumi.set(__self__, "project_directory", project_directory)
        if schema is not None:
            pulumi.set(__self__, "schema", schema)
        if source is not None:
            pulumi.set(__self__, "source", source)
        if warehouse_id is not None:
            pulumi.set(__self__, "warehouse_id", warehouse_id)

    @property
    @pulumi.getter
    def commands(self) -> Sequence[str]:
        """
        (Array) Series of dbt commands to execute in sequence. Every command must start with "dbt".
        """
        return pulumi.get(self, "commands")

    @property
    @pulumi.getter
    def catalog(self) -> Optional[str]:
        """
        The name of the catalog to use inside Unity Catalog.
        """
        return pulumi.get(self, "catalog")

    @property
    @pulumi.getter(name="profilesDirectory")
    def profiles_directory(self) -> Optional[str]:
        """
        The relative path to the directory in the repository specified by `git_source` where dbt should look in for the `profiles.yml` file. If not specified, defaults to the repository's root directory. Equivalent to passing `--profile-dir` to a dbt command.
        """
        return pulumi.get(self, "profiles_directory")

    @property
    @pulumi.getter(name="projectDirectory")
    def project_directory(self) -> Optional[str]:
        """
        The path where dbt should look for `dbt_project.yml`. Equivalent to passing `--project-dir` to the dbt CLI.
        * If `source` is `GIT`: Relative path to the directory in the repository specified in the `git_source` block. Defaults to the repository's root directory when not specified.
        * If `source` is `WORKSPACE`: Absolute path to the folder in the workspace.
        """
        return pulumi.get(self, "project_directory")

    @property
    @pulumi.getter
    def schema(self) -> Optional[str]:
        """
        The name of the schema dbt should run in. Defaults to `default`.
        """
        return pulumi.get(self, "schema")

    @property
    @pulumi.getter
    def source(self) -> Optional[str]:
        """
        The source of the project. Possible values are `WORKSPACE` and `GIT`.  Defaults to `GIT` if a `git_source` block is present in the job definition.
        """
        return pulumi.get(self, "source")

    @property
    @pulumi.getter(name="warehouseId")
    def warehouse_id(self) -> Optional[str]:
        """
        The ID of the SQL warehouse that dbt should execute against.

        You also need to include a `git_source` block to configure the repository that contains the dbt project.
        """
        return pulumi.get(self, "warehouse_id")


@pulumi.output_type
class JobDeployment(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "metadataFilePath":
            suggest = "metadata_file_path"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in JobDeployment. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        JobDeployment.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        JobDeployment.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 kind: str,
                 metadata_file_path: Optional[str] = None):
        pulumi.set(__self__, "kind", kind)
        if metadata_file_path is not None:
            pulumi.set(__self__, "metadata_file_path", metadata_file_path)

    @property
    @pulumi.getter
    def kind(self) -> str:
        return pulumi.get(self, "kind")

    @property
    @pulumi.getter(name="metadataFilePath")
    def metadata_file_path(self) -> Optional[str]:
        return pulumi.get(self, "metadata_file_path")


@pulumi.output_type
class JobEmailNotifications(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "noAlertForSkippedRuns":
            suggest = "no_alert_for_skipped_runs"
        elif key == "onDurationWarningThresholdExceededs":
            suggest = "on_duration_warning_threshold_exceededs"
        elif key == "onFailures":
            suggest = "on_failures"
        elif key == "onStarts":
            suggest = "on_starts"
        elif key == "onSuccesses":
            suggest = "on_successes"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in JobEmailNotifications. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        JobEmailNotifications.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        JobEmailNotifications.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 no_alert_for_skipped_runs: Optional[bool] = None,
                 on_duration_warning_threshold_exceededs: Optional[Sequence[str]] = None,
                 on_failures: Optional[Sequence[str]] = None,
                 on_starts: Optional[Sequence[str]] = None,
                 on_successes: Optional[Sequence[str]] = None):
        """
        :param bool no_alert_for_skipped_runs: (Bool) don't send alert for skipped runs. (It's recommended to use the corresponding setting in the `notification_settings` configuration block).
        :param Sequence[str] on_duration_warning_threshold_exceededs: (List) list of emails to notify when the duration of a run exceeds the threshold specified by the `RUN_DURATION_SECONDS` metric in the `health` block.
        :param Sequence[str] on_failures: (List) list of emails to notify when the run fails.
        :param Sequence[str] on_starts: (List) list of emails to notify when the run starts.
        :param Sequence[str] on_successes: (List) list of emails to notify when the run completes successfully.
        """
        if no_alert_for_skipped_runs is not None:
            pulumi.set(__self__, "no_alert_for_skipped_runs", no_alert_for_skipped_runs)
        if on_duration_warning_threshold_exceededs is not None:
            pulumi.set(__self__, "on_duration_warning_threshold_exceededs", on_duration_warning_threshold_exceededs)
        if on_failures is not None:
            pulumi.set(__self__, "on_failures", on_failures)
        if on_starts is not None:
            pulumi.set(__self__, "on_starts", on_starts)
        if on_successes is not None:
            pulumi.set(__self__, "on_successes", on_successes)

    @property
    @pulumi.getter(name="noAlertForSkippedRuns")
    def no_alert_for_skipped_runs(self) -> Optional[bool]:
        """
        (Bool) don't send alert for skipped runs. (It's recommended to use the corresponding setting in the `notification_settings` configuration block).
        """
        return pulumi.get(self, "no_alert_for_skipped_runs")

    @property
    @pulumi.getter(name="onDurationWarningThresholdExceededs")
    def on_duration_warning_threshold_exceededs(self) -> Optional[Sequence[str]]:
        """
        (List) list of emails to notify when the duration of a run exceeds the threshold specified by the `RUN_DURATION_SECONDS` metric in the `health` block.
        """
        return pulumi.get(self, "on_duration_warning_threshold_exceededs")

    @property
    @pulumi.getter(name="onFailures")
    def on_failures(self) -> Optional[Sequence[str]]:
        """
        (List) list of emails to notify when the run fails.
        """
        return pulumi.get(self, "on_failures")

    @property
    @pulumi.getter(name="onStarts")
    def on_starts(self) -> Optional[Sequence[str]]:
        """
        (List) list of emails to notify when the run starts.
        """
        return pulumi.get(self, "on_starts")

    @property
    @pulumi.getter(name="onSuccesses")
    def on_successes(self) -> Optional[Sequence[str]]:
        """
        (List) list of emails to notify when the run completes successfully.
        """
        return pulumi.get(self, "on_successes")


@pulumi.output_type
class JobGitSource(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "jobSource":
            suggest = "job_source"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in JobGitSource. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        JobGitSource.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        JobGitSource.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 url: str,
                 branch: Optional[str] = None,
                 commit: Optional[str] = None,
                 job_source: Optional['outputs.JobGitSourceJobSource'] = None,
                 provider: Optional[str] = None,
                 tag: Optional[str] = None):
        """
        :param str url: URL of the Git repository to use.
        :param str branch: name of the Git branch to use. Conflicts with `tag` and `commit`.
        :param str commit: hash of Git commit to use. Conflicts with `branch` and `tag`.
        :param str provider: case insensitive name of the Git provider.  Following values are supported right now (could be a subject for change, consult [Repos API documentation](https://docs.databricks.com/dev-tools/api/latest/repos.html)): `gitHub`, `gitHubEnterprise`, `bitbucketCloud`, `bitbucketServer`, `azureDevOpsServices`, `gitLab`, `gitLabEnterpriseEdition`.
        :param str tag: name of the Git branch to use. Conflicts with `branch` and `commit`.
        """
        pulumi.set(__self__, "url", url)
        if branch is not None:
            pulumi.set(__self__, "branch", branch)
        if commit is not None:
            pulumi.set(__self__, "commit", commit)
        if job_source is not None:
            pulumi.set(__self__, "job_source", job_source)
        if provider is not None:
            pulumi.set(__self__, "provider", provider)
        if tag is not None:
            pulumi.set(__self__, "tag", tag)

    @property
    @pulumi.getter
    def url(self) -> str:
        """
        URL of the Git repository to use.
        """
        return pulumi.get(self, "url")

    @property
    @pulumi.getter
    def branch(self) -> Optional[str]:
        """
        name of the Git branch to use. Conflicts with `tag` and `commit`.
        """
        return pulumi.get(self, "branch")

    @property
    @pulumi.getter
    def commit(self) -> Optional[str]:
        """
        hash of Git commit to use. Conflicts with `branch` and `tag`.
        """
        return pulumi.get(self, "commit")

    @property
    @pulumi.getter(name="jobSource")
    def job_source(self) -> Optional['outputs.JobGitSourceJobSource']:
        return pulumi.get(self, "job_source")

    @property
    @pulumi.getter
    def provider(self) -> Optional[str]:
        """
        case insensitive name of the Git provider.  Following values are supported right now (could be a subject for change, consult [Repos API documentation](https://docs.databricks.com/dev-tools/api/latest/repos.html)): `gitHub`, `gitHubEnterprise`, `bitbucketCloud`, `bitbucketServer`, `azureDevOpsServices`, `gitLab`, `gitLabEnterpriseEdition`.
        """
        return pulumi.get(self, "provider")

    @property
    @pulumi.getter
    def tag(self) -> Optional[str]:
        """
        name of the Git branch to use. Conflicts with `branch` and `commit`.
        """
        return pulumi.get(self, "tag")


@pulumi.output_type
class JobGitSourceJobSource(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "importFromGitBranch":
            suggest = "import_from_git_branch"
        elif key == "jobConfigPath":
            suggest = "job_config_path"
        elif key == "dirtyState":
            suggest = "dirty_state"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in JobGitSourceJobSource. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        JobGitSourceJobSource.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        JobGitSourceJobSource.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 import_from_git_branch: str,
                 job_config_path: str,
                 dirty_state: Optional[str] = None):
        pulumi.set(__self__, "import_from_git_branch", import_from_git_branch)
        pulumi.set(__self__, "job_config_path", job_config_path)
        if dirty_state is not None:
            pulumi.set(__self__, "dirty_state", dirty_state)

    @property
    @pulumi.getter(name="importFromGitBranch")
    def import_from_git_branch(self) -> str:
        return pulumi.get(self, "import_from_git_branch")

    @property
    @pulumi.getter(name="jobConfigPath")
    def job_config_path(self) -> str:
        return pulumi.get(self, "job_config_path")

    @property
    @pulumi.getter(name="dirtyState")
    def dirty_state(self) -> Optional[str]:
        return pulumi.get(self, "dirty_state")


@pulumi.output_type
class JobHealth(dict):
    def __init__(__self__, *,
                 rules: Sequence['outputs.JobHealthRule']):
        """
        :param Sequence['JobHealthRuleArgs'] rules: list of rules that are represented as objects with the following attributes:
        """
        pulumi.set(__self__, "rules", rules)

    @property
    @pulumi.getter
    def rules(self) -> Sequence['outputs.JobHealthRule']:
        """
        list of rules that are represented as objects with the following attributes:
        """
        return pulumi.get(self, "rules")


@pulumi.output_type
class JobHealthRule(dict):
    def __init__(__self__, *,
                 metric: Optional[str] = None,
                 op: Optional[str] = None,
                 value: Optional[int] = None):
        """
        :param str metric: string specifying the metric to check.  The only supported metric is `RUN_DURATION_SECONDS` (check [Jobs REST API documentation](https://docs.databricks.com/api/workspace/jobs/create) for the latest information).
        :param str op: The string specifying the operation used to compare operands.  Currently, following operators are supported: `EQUAL_TO`, `GREATER_THAN`, `GREATER_THAN_OR_EQUAL`, `LESS_THAN`, `LESS_THAN_OR_EQUAL`, `NOT_EQUAL`. (Check the [API docs](https://docs.databricks.com/api/workspace/jobs/create) for the latest information).
               
               This task does not require a cluster to execute and does not support retries or notifications.
        :param int value: integer value used to compare to the given metric.
        """
        if metric is not None:
            pulumi.set(__self__, "metric", metric)
        if op is not None:
            pulumi.set(__self__, "op", op)
        if value is not None:
            pulumi.set(__self__, "value", value)

    @property
    @pulumi.getter
    def metric(self) -> Optional[str]:
        """
        string specifying the metric to check.  The only supported metric is `RUN_DURATION_SECONDS` (check [Jobs REST API documentation](https://docs.databricks.com/api/workspace/jobs/create) for the latest information).
        """
        return pulumi.get(self, "metric")

    @property
    @pulumi.getter
    def op(self) -> Optional[str]:
        """
        The string specifying the operation used to compare operands.  Currently, following operators are supported: `EQUAL_TO`, `GREATER_THAN`, `GREATER_THAN_OR_EQUAL`, `LESS_THAN`, `LESS_THAN_OR_EQUAL`, `NOT_EQUAL`. (Check the [API docs](https://docs.databricks.com/api/workspace/jobs/create) for the latest information).

        This task does not require a cluster to execute and does not support retries or notifications.
        """
        return pulumi.get(self, "op")

    @property
    @pulumi.getter
    def value(self) -> Optional[int]:
        """
        integer value used to compare to the given metric.
        """
        return pulumi.get(self, "value")


@pulumi.output_type
class JobJobCluster(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "jobClusterKey":
            suggest = "job_cluster_key"
        elif key == "newCluster":
            suggest = "new_cluster"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in JobJobCluster. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        JobJobCluster.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        JobJobCluster.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 job_cluster_key: Optional[str] = None,
                 new_cluster: Optional['outputs.JobJobClusterNewCluster'] = None):
        """
        :param str job_cluster_key: Identifier that can be referenced in `task` block, so that cluster is shared between tasks
        :param 'JobJobClusterNewClusterArgs' new_cluster: Same set of parameters as for Cluster resource.
        """
        if job_cluster_key is not None:
            pulumi.set(__self__, "job_cluster_key", job_cluster_key)
        if new_cluster is not None:
            pulumi.set(__self__, "new_cluster", new_cluster)

    @property
    @pulumi.getter(name="jobClusterKey")
    def job_cluster_key(self) -> Optional[str]:
        """
        Identifier that can be referenced in `task` block, so that cluster is shared between tasks
        """
        return pulumi.get(self, "job_cluster_key")

    @property
    @pulumi.getter(name="newCluster")
    def new_cluster(self) -> Optional['outputs.JobJobClusterNewCluster']:
        """
        Same set of parameters as for Cluster resource.
        """
        return pulumi.get(self, "new_cluster")


@pulumi.output_type
class JobJobClusterNewCluster(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "sparkVersion":
            suggest = "spark_version"
        elif key == "applyPolicyDefaultValues":
            suggest = "apply_policy_default_values"
        elif key == "autoterminationMinutes":
            suggest = "autotermination_minutes"
        elif key == "awsAttributes":
            suggest = "aws_attributes"
        elif key == "azureAttributes":
            suggest = "azure_attributes"
        elif key == "clusterId":
            suggest = "cluster_id"
        elif key == "clusterLogConf":
            suggest = "cluster_log_conf"
        elif key == "clusterMountInfos":
            suggest = "cluster_mount_infos"
        elif key == "clusterName":
            suggest = "cluster_name"
        elif key == "customTags":
            suggest = "custom_tags"
        elif key == "dataSecurityMode":
            suggest = "data_security_mode"
        elif key == "dockerImage":
            suggest = "docker_image"
        elif key == "driverInstancePoolId":
            suggest = "driver_instance_pool_id"
        elif key == "driverNodeTypeId":
            suggest = "driver_node_type_id"
        elif key == "enableElasticDisk":
            suggest = "enable_elastic_disk"
        elif key == "enableLocalDiskEncryption":
            suggest = "enable_local_disk_encryption"
        elif key == "gcpAttributes":
            suggest = "gcp_attributes"
        elif key == "idempotencyToken":
            suggest = "idempotency_token"
        elif key == "initScripts":
            suggest = "init_scripts"
        elif key == "instancePoolId":
            suggest = "instance_pool_id"
        elif key == "nodeTypeId":
            suggest = "node_type_id"
        elif key == "numWorkers":
            suggest = "num_workers"
        elif key == "policyId":
            suggest = "policy_id"
        elif key == "runtimeEngine":
            suggest = "runtime_engine"
        elif key == "singleUserName":
            suggest = "single_user_name"
        elif key == "sparkConf":
            suggest = "spark_conf"
        elif key == "sparkEnvVars":
            suggest = "spark_env_vars"
        elif key == "sshPublicKeys":
            suggest = "ssh_public_keys"
        elif key == "workloadType":
            suggest = "workload_type"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in JobJobClusterNewCluster. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        JobJobClusterNewCluster.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        JobJobClusterNewCluster.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 spark_version: str,
                 apply_policy_default_values: Optional[bool] = None,
                 autoscale: Optional['outputs.JobJobClusterNewClusterAutoscale'] = None,
                 autotermination_minutes: Optional[int] = None,
                 aws_attributes: Optional['outputs.JobJobClusterNewClusterAwsAttributes'] = None,
                 azure_attributes: Optional['outputs.JobJobClusterNewClusterAzureAttributes'] = None,
                 cluster_id: Optional[str] = None,
                 cluster_log_conf: Optional['outputs.JobJobClusterNewClusterClusterLogConf'] = None,
                 cluster_mount_infos: Optional[Sequence['outputs.JobJobClusterNewClusterClusterMountInfo']] = None,
                 cluster_name: Optional[str] = None,
                 custom_tags: Optional[Mapping[str, Any]] = None,
                 data_security_mode: Optional[str] = None,
                 docker_image: Optional['outputs.JobJobClusterNewClusterDockerImage'] = None,
                 driver_instance_pool_id: Optional[str] = None,
                 driver_node_type_id: Optional[str] = None,
                 enable_elastic_disk: Optional[bool] = None,
                 enable_local_disk_encryption: Optional[bool] = None,
                 gcp_attributes: Optional['outputs.JobJobClusterNewClusterGcpAttributes'] = None,
                 idempotency_token: Optional[str] = None,
                 init_scripts: Optional[Sequence['outputs.JobJobClusterNewClusterInitScript']] = None,
                 instance_pool_id: Optional[str] = None,
                 node_type_id: Optional[str] = None,
                 num_workers: Optional[int] = None,
                 policy_id: Optional[str] = None,
                 runtime_engine: Optional[str] = None,
                 single_user_name: Optional[str] = None,
                 spark_conf: Optional[Mapping[str, Any]] = None,
                 spark_env_vars: Optional[Mapping[str, Any]] = None,
                 ssh_public_keys: Optional[Sequence[str]] = None,
                 workload_type: Optional['outputs.JobJobClusterNewClusterWorkloadType'] = None):
        pulumi.set(__self__, "spark_version", spark_version)
        if apply_policy_default_values is not None:
            pulumi.set(__self__, "apply_policy_default_values", apply_policy_default_values)
        if autoscale is not None:
            pulumi.set(__self__, "autoscale", autoscale)
        if autotermination_minutes is not None:
            pulumi.set(__self__, "autotermination_minutes", autotermination_minutes)
        if aws_attributes is not None:
            pulumi.set(__self__, "aws_attributes", aws_attributes)
        if azure_attributes is not None:
            pulumi.set(__self__, "azure_attributes", azure_attributes)
        if cluster_id is not None:
            pulumi.set(__self__, "cluster_id", cluster_id)
        if cluster_log_conf is not None:
            pulumi.set(__self__, "cluster_log_conf", cluster_log_conf)
        if cluster_mount_infos is not None:
            pulumi.set(__self__, "cluster_mount_infos", cluster_mount_infos)
        if cluster_name is not None:
            pulumi.set(__self__, "cluster_name", cluster_name)
        if custom_tags is not None:
            pulumi.set(__self__, "custom_tags", custom_tags)
        if data_security_mode is not None:
            pulumi.set(__self__, "data_security_mode", data_security_mode)
        if docker_image is not None:
            pulumi.set(__self__, "docker_image", docker_image)
        if driver_instance_pool_id is not None:
            pulumi.set(__self__, "driver_instance_pool_id", driver_instance_pool_id)
        if driver_node_type_id is not None:
            pulumi.set(__self__, "driver_node_type_id", driver_node_type_id)
        if enable_elastic_disk is not None:
            pulumi.set(__self__, "enable_elastic_disk", enable_elastic_disk)
        if enable_local_disk_encryption is not None:
            pulumi.set(__self__, "enable_local_disk_encryption", enable_local_disk_encryption)
        if gcp_attributes is not None:
            pulumi.set(__self__, "gcp_attributes", gcp_attributes)
        if idempotency_token is not None:
            pulumi.set(__self__, "idempotency_token", idempotency_token)
        if init_scripts is not None:
            pulumi.set(__self__, "init_scripts", init_scripts)
        if instance_pool_id is not None:
            pulumi.set(__self__, "instance_pool_id", instance_pool_id)
        if node_type_id is not None:
            pulumi.set(__self__, "node_type_id", node_type_id)
        if num_workers is not None:
            pulumi.set(__self__, "num_workers", num_workers)
        if policy_id is not None:
            pulumi.set(__self__, "policy_id", policy_id)
        if runtime_engine is not None:
            pulumi.set(__self__, "runtime_engine", runtime_engine)
        if single_user_name is not None:
            pulumi.set(__self__, "single_user_name", single_user_name)
        if spark_conf is not None:
            pulumi.set(__self__, "spark_conf", spark_conf)
        if spark_env_vars is not None:
            pulumi.set(__self__, "spark_env_vars", spark_env_vars)
        if ssh_public_keys is not None:
            pulumi.set(__self__, "ssh_public_keys", ssh_public_keys)
        if workload_type is not None:
            pulumi.set(__self__, "workload_type", workload_type)

    @property
    @pulumi.getter(name="sparkVersion")
    def spark_version(self) -> str:
        return pulumi.get(self, "spark_version")

    @property
    @pulumi.getter(name="applyPolicyDefaultValues")
    def apply_policy_default_values(self) -> Optional[bool]:
        return pulumi.get(self, "apply_policy_default_values")

    @property
    @pulumi.getter
    def autoscale(self) -> Optional['outputs.JobJobClusterNewClusterAutoscale']:
        return pulumi.get(self, "autoscale")

    @property
    @pulumi.getter(name="autoterminationMinutes")
    def autotermination_minutes(self) -> Optional[int]:
        return pulumi.get(self, "autotermination_minutes")

    @property
    @pulumi.getter(name="awsAttributes")
    def aws_attributes(self) -> Optional['outputs.JobJobClusterNewClusterAwsAttributes']:
        return pulumi.get(self, "aws_attributes")

    @property
    @pulumi.getter(name="azureAttributes")
    def azure_attributes(self) -> Optional['outputs.JobJobClusterNewClusterAzureAttributes']:
        return pulumi.get(self, "azure_attributes")

    @property
    @pulumi.getter(name="clusterId")
    def cluster_id(self) -> Optional[str]:
        return pulumi.get(self, "cluster_id")

    @property
    @pulumi.getter(name="clusterLogConf")
    def cluster_log_conf(self) -> Optional['outputs.JobJobClusterNewClusterClusterLogConf']:
        return pulumi.get(self, "cluster_log_conf")

    @property
    @pulumi.getter(name="clusterMountInfos")
    def cluster_mount_infos(self) -> Optional[Sequence['outputs.JobJobClusterNewClusterClusterMountInfo']]:
        return pulumi.get(self, "cluster_mount_infos")

    @property
    @pulumi.getter(name="clusterName")
    def cluster_name(self) -> Optional[str]:
        return pulumi.get(self, "cluster_name")

    @property
    @pulumi.getter(name="customTags")
    def custom_tags(self) -> Optional[Mapping[str, Any]]:
        return pulumi.get(self, "custom_tags")

    @property
    @pulumi.getter(name="dataSecurityMode")
    def data_security_mode(self) -> Optional[str]:
        return pulumi.get(self, "data_security_mode")

    @property
    @pulumi.getter(name="dockerImage")
    def docker_image(self) -> Optional['outputs.JobJobClusterNewClusterDockerImage']:
        return pulumi.get(self, "docker_image")

    @property
    @pulumi.getter(name="driverInstancePoolId")
    def driver_instance_pool_id(self) -> Optional[str]:
        return pulumi.get(self, "driver_instance_pool_id")

    @property
    @pulumi.getter(name="driverNodeTypeId")
    def driver_node_type_id(self) -> Optional[str]:
        return pulumi.get(self, "driver_node_type_id")

    @property
    @pulumi.getter(name="enableElasticDisk")
    def enable_elastic_disk(self) -> Optional[bool]:
        return pulumi.get(self, "enable_elastic_disk")

    @property
    @pulumi.getter(name="enableLocalDiskEncryption")
    def enable_local_disk_encryption(self) -> Optional[bool]:
        return pulumi.get(self, "enable_local_disk_encryption")

    @property
    @pulumi.getter(name="gcpAttributes")
    def gcp_attributes(self) -> Optional['outputs.JobJobClusterNewClusterGcpAttributes']:
        return pulumi.get(self, "gcp_attributes")

    @property
    @pulumi.getter(name="idempotencyToken")
    def idempotency_token(self) -> Optional[str]:
        return pulumi.get(self, "idempotency_token")

    @property
    @pulumi.getter(name="initScripts")
    def init_scripts(self) -> Optional[Sequence['outputs.JobJobClusterNewClusterInitScript']]:
        return pulumi.get(self, "init_scripts")

    @property
    @pulumi.getter(name="instancePoolId")
    def instance_pool_id(self) -> Optional[str]:
        return pulumi.get(self, "instance_pool_id")

    @property
    @pulumi.getter(name="nodeTypeId")
    def node_type_id(self) -> Optional[str]:
        return pulumi.get(self, "node_type_id")

    @property
    @pulumi.getter(name="numWorkers")
    def num_workers(self) -> Optional[int]:
        return pulumi.get(self, "num_workers")

    @property
    @pulumi.getter(name="policyId")
    def policy_id(self) -> Optional[str]:
        return pulumi.get(self, "policy_id")

    @property
    @pulumi.getter(name="runtimeEngine")
    def runtime_engine(self) -> Optional[str]:
        return pulumi.get(self, "runtime_engine")

    @property
    @pulumi.getter(name="singleUserName")
    def single_user_name(self) -> Optional[str]:
        return pulumi.get(self, "single_user_name")

    @property
    @pulumi.getter(name="sparkConf")
    def spark_conf(self) -> Optional[Mapping[str, Any]]:
        return pulumi.get(self, "spark_conf")

    @property
    @pulumi.getter(name="sparkEnvVars")
    def spark_env_vars(self) -> Optional[Mapping[str, Any]]:
        return pulumi.get(self, "spark_env_vars")

    @property
    @pulumi.getter(name="sshPublicKeys")
    def ssh_public_keys(self) -> Optional[Sequence[str]]:
        return pulumi.get(self, "ssh_public_keys")

    @property
    @pulumi.getter(name="workloadType")
    def workload_type(self) -> Optional['outputs.JobJobClusterNewClusterWorkloadType']:
        return pulumi.get(self, "workload_type")


@pulumi.output_type
class JobJobClusterNewClusterAutoscale(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "maxWorkers":
            suggest = "max_workers"
        elif key == "minWorkers":
            suggest = "min_workers"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in JobJobClusterNewClusterAutoscale. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        JobJobClusterNewClusterAutoscale.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        JobJobClusterNewClusterAutoscale.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 max_workers: Optional[int] = None,
                 min_workers: Optional[int] = None):
        if max_workers is not None:
            pulumi.set(__self__, "max_workers", max_workers)
        if min_workers is not None:
            pulumi.set(__self__, "min_workers", min_workers)

    @property
    @pulumi.getter(name="maxWorkers")
    def max_workers(self) -> Optional[int]:
        return pulumi.get(self, "max_workers")

    @property
    @pulumi.getter(name="minWorkers")
    def min_workers(self) -> Optional[int]:
        return pulumi.get(self, "min_workers")


@pulumi.output_type
class JobJobClusterNewClusterAwsAttributes(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "ebsVolumeCount":
            suggest = "ebs_volume_count"
        elif key == "ebsVolumeSize":
            suggest = "ebs_volume_size"
        elif key == "ebsVolumeType":
            suggest = "ebs_volume_type"
        elif key == "firstOnDemand":
            suggest = "first_on_demand"
        elif key == "instanceProfileArn":
            suggest = "instance_profile_arn"
        elif key == "spotBidPricePercent":
            suggest = "spot_bid_price_percent"
        elif key == "zoneId":
            suggest = "zone_id"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in JobJobClusterNewClusterAwsAttributes. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        JobJobClusterNewClusterAwsAttributes.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        JobJobClusterNewClusterAwsAttributes.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 availability: Optional[str] = None,
                 ebs_volume_count: Optional[int] = None,
                 ebs_volume_size: Optional[int] = None,
                 ebs_volume_type: Optional[str] = None,
                 first_on_demand: Optional[int] = None,
                 instance_profile_arn: Optional[str] = None,
                 spot_bid_price_percent: Optional[int] = None,
                 zone_id: Optional[str] = None):
        if availability is not None:
            pulumi.set(__self__, "availability", availability)
        if ebs_volume_count is not None:
            pulumi.set(__self__, "ebs_volume_count", ebs_volume_count)
        if ebs_volume_size is not None:
            pulumi.set(__self__, "ebs_volume_size", ebs_volume_size)
        if ebs_volume_type is not None:
            pulumi.set(__self__, "ebs_volume_type", ebs_volume_type)
        if first_on_demand is not None:
            pulumi.set(__self__, "first_on_demand", first_on_demand)
        if instance_profile_arn is not None:
            pulumi.set(__self__, "instance_profile_arn", instance_profile_arn)
        if spot_bid_price_percent is not None:
            pulumi.set(__self__, "spot_bid_price_percent", spot_bid_price_percent)
        if zone_id is not None:
            pulumi.set(__self__, "zone_id", zone_id)

    @property
    @pulumi.getter
    def availability(self) -> Optional[str]:
        return pulumi.get(self, "availability")

    @property
    @pulumi.getter(name="ebsVolumeCount")
    def ebs_volume_count(self) -> Optional[int]:
        return pulumi.get(self, "ebs_volume_count")

    @property
    @pulumi.getter(name="ebsVolumeSize")
    def ebs_volume_size(self) -> Optional[int]:
        return pulumi.get(self, "ebs_volume_size")

    @property
    @pulumi.getter(name="ebsVolumeType")
    def ebs_volume_type(self) -> Optional[str]:
        return pulumi.get(self, "ebs_volume_type")

    @property
    @pulumi.getter(name="firstOnDemand")
    def first_on_demand(self) -> Optional[int]:
        return pulumi.get(self, "first_on_demand")

    @property
    @pulumi.getter(name="instanceProfileArn")
    def instance_profile_arn(self) -> Optional[str]:
        return pulumi.get(self, "instance_profile_arn")

    @property
    @pulumi.getter(name="spotBidPricePercent")
    def spot_bid_price_percent(self) -> Optional[int]:
        return pulumi.get(self, "spot_bid_price_percent")

    @property
    @pulumi.getter(name="zoneId")
    def zone_id(self) -> Optional[str]:
        return pulumi.get(self, "zone_id")


@pulumi.output_type
class JobJobClusterNewClusterAzureAttributes(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "firstOnDemand":
            suggest = "first_on_demand"
        elif key == "spotBidMaxPrice":
            suggest = "spot_bid_max_price"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in JobJobClusterNewClusterAzureAttributes. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        JobJobClusterNewClusterAzureAttributes.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        JobJobClusterNewClusterAzureAttributes.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 availability: Optional[str] = None,
                 first_on_demand: Optional[int] = None,
                 spot_bid_max_price: Optional[float] = None):
        if availability is not None:
            pulumi.set(__self__, "availability", availability)
        if first_on_demand is not None:
            pulumi.set(__self__, "first_on_demand", first_on_demand)
        if spot_bid_max_price is not None:
            pulumi.set(__self__, "spot_bid_max_price", spot_bid_max_price)

    @property
    @pulumi.getter
    def availability(self) -> Optional[str]:
        return pulumi.get(self, "availability")

    @property
    @pulumi.getter(name="firstOnDemand")
    def first_on_demand(self) -> Optional[int]:
        return pulumi.get(self, "first_on_demand")

    @property
    @pulumi.getter(name="spotBidMaxPrice")
    def spot_bid_max_price(self) -> Optional[float]:
        return pulumi.get(self, "spot_bid_max_price")


@pulumi.output_type
class JobJobClusterNewClusterClusterLogConf(dict):
    def __init__(__self__, *,
                 dbfs: Optional['outputs.JobJobClusterNewClusterClusterLogConfDbfs'] = None,
                 s3: Optional['outputs.JobJobClusterNewClusterClusterLogConfS3'] = None):
        if dbfs is not None:
            pulumi.set(__self__, "dbfs", dbfs)
        if s3 is not None:
            pulumi.set(__self__, "s3", s3)

    @property
    @pulumi.getter
    def dbfs(self) -> Optional['outputs.JobJobClusterNewClusterClusterLogConfDbfs']:
        return pulumi.get(self, "dbfs")

    @property
    @pulumi.getter
    def s3(self) -> Optional['outputs.JobJobClusterNewClusterClusterLogConfS3']:
        return pulumi.get(self, "s3")


@pulumi.output_type
class JobJobClusterNewClusterClusterLogConfDbfs(dict):
    def __init__(__self__, *,
                 destination: str):
        pulumi.set(__self__, "destination", destination)

    @property
    @pulumi.getter
    def destination(self) -> str:
        return pulumi.get(self, "destination")


@pulumi.output_type
class JobJobClusterNewClusterClusterLogConfS3(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "cannedAcl":
            suggest = "canned_acl"
        elif key == "enableEncryption":
            suggest = "enable_encryption"
        elif key == "encryptionType":
            suggest = "encryption_type"
        elif key == "kmsKey":
            suggest = "kms_key"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in JobJobClusterNewClusterClusterLogConfS3. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        JobJobClusterNewClusterClusterLogConfS3.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        JobJobClusterNewClusterClusterLogConfS3.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 destination: str,
                 canned_acl: Optional[str] = None,
                 enable_encryption: Optional[bool] = None,
                 encryption_type: Optional[str] = None,
                 endpoint: Optional[str] = None,
                 kms_key: Optional[str] = None,
                 region: Optional[str] = None):
        pulumi.set(__self__, "destination", destination)
        if canned_acl is not None:
            pulumi.set(__self__, "canned_acl", canned_acl)
        if enable_encryption is not None:
            pulumi.set(__self__, "enable_encryption", enable_encryption)
        if encryption_type is not None:
            pulumi.set(__self__, "encryption_type", encryption_type)
        if endpoint is not None:
            pulumi.set(__self__, "endpoint", endpoint)
        if kms_key is not None:
            pulumi.set(__self__, "kms_key", kms_key)
        if region is not None:
            pulumi.set(__self__, "region", region)

    @property
    @pulumi.getter
    def destination(self) -> str:
        return pulumi.get(self, "destination")

    @property
    @pulumi.getter(name="cannedAcl")
    def canned_acl(self) -> Optional[str]:
        return pulumi.get(self, "canned_acl")

    @property
    @pulumi.getter(name="enableEncryption")
    def enable_encryption(self) -> Optional[bool]:
        return pulumi.get(self, "enable_encryption")

    @property
    @pulumi.getter(name="encryptionType")
    def encryption_type(self) -> Optional[str]:
        return pulumi.get(self, "encryption_type")

    @property
    @pulumi.getter
    def endpoint(self) -> Optional[str]:
        return pulumi.get(self, "endpoint")

    @property
    @pulumi.getter(name="kmsKey")
    def kms_key(self) -> Optional[str]:
        return pulumi.get(self, "kms_key")

    @property
    @pulumi.getter
    def region(self) -> Optional[str]:
        return pulumi.get(self, "region")


@pulumi.output_type
class JobJobClusterNewClusterClusterMountInfo(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "localMountDirPath":
            suggest = "local_mount_dir_path"
        elif key == "networkFilesystemInfo":
            suggest = "network_filesystem_info"
        elif key == "remoteMountDirPath":
            suggest = "remote_mount_dir_path"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in JobJobClusterNewClusterClusterMountInfo. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        JobJobClusterNewClusterClusterMountInfo.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        JobJobClusterNewClusterClusterMountInfo.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 local_mount_dir_path: str,
                 network_filesystem_info: 'outputs.JobJobClusterNewClusterClusterMountInfoNetworkFilesystemInfo',
                 remote_mount_dir_path: Optional[str] = None):
        pulumi.set(__self__, "local_mount_dir_path", local_mount_dir_path)
        pulumi.set(__self__, "network_filesystem_info", network_filesystem_info)
        if remote_mount_dir_path is not None:
            pulumi.set(__self__, "remote_mount_dir_path", remote_mount_dir_path)

    @property
    @pulumi.getter(name="localMountDirPath")
    def local_mount_dir_path(self) -> str:
        return pulumi.get(self, "local_mount_dir_path")

    @property
    @pulumi.getter(name="networkFilesystemInfo")
    def network_filesystem_info(self) -> 'outputs.JobJobClusterNewClusterClusterMountInfoNetworkFilesystemInfo':
        return pulumi.get(self, "network_filesystem_info")

    @property
    @pulumi.getter(name="remoteMountDirPath")
    def remote_mount_dir_path(self) -> Optional[str]:
        return pulumi.get(self, "remote_mount_dir_path")


@pulumi.output_type
class JobJobClusterNewClusterClusterMountInfoNetworkFilesystemInfo(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "serverAddress":
            suggest = "server_address"
        elif key == "mountOptions":
            suggest = "mount_options"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in JobJobClusterNewClusterClusterMountInfoNetworkFilesystemInfo. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        JobJobClusterNewClusterClusterMountInfoNetworkFilesystemInfo.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        JobJobClusterNewClusterClusterMountInfoNetworkFilesystemInfo.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 server_address: str,
                 mount_options: Optional[str] = None):
        pulumi.set(__self__, "server_address", server_address)
        if mount_options is not None:
            pulumi.set(__self__, "mount_options", mount_options)

    @property
    @pulumi.getter(name="serverAddress")
    def server_address(self) -> str:
        return pulumi.get(self, "server_address")

    @property
    @pulumi.getter(name="mountOptions")
    def mount_options(self) -> Optional[str]:
        return pulumi.get(self, "mount_options")


@pulumi.output_type
class JobJobClusterNewClusterDockerImage(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "basicAuth":
            suggest = "basic_auth"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in JobJobClusterNewClusterDockerImage. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        JobJobClusterNewClusterDockerImage.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        JobJobClusterNewClusterDockerImage.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 url: str,
                 basic_auth: Optional['outputs.JobJobClusterNewClusterDockerImageBasicAuth'] = None):
        """
        :param str url: URL of the Git repository to use.
        """
        pulumi.set(__self__, "url", url)
        if basic_auth is not None:
            pulumi.set(__self__, "basic_auth", basic_auth)

    @property
    @pulumi.getter
    def url(self) -> str:
        """
        URL of the Git repository to use.
        """
        return pulumi.get(self, "url")

    @property
    @pulumi.getter(name="basicAuth")
    def basic_auth(self) -> Optional['outputs.JobJobClusterNewClusterDockerImageBasicAuth']:
        return pulumi.get(self, "basic_auth")


@pulumi.output_type
class JobJobClusterNewClusterDockerImageBasicAuth(dict):
    def __init__(__self__, *,
                 password: str,
                 username: str):
        pulumi.set(__self__, "password", password)
        pulumi.set(__self__, "username", username)

    @property
    @pulumi.getter
    def password(self) -> str:
        return pulumi.get(self, "password")

    @property
    @pulumi.getter
    def username(self) -> str:
        return pulumi.get(self, "username")


@pulumi.output_type
class JobJobClusterNewClusterGcpAttributes(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "bootDiskSize":
            suggest = "boot_disk_size"
        elif key == "googleServiceAccount":
            suggest = "google_service_account"
        elif key == "localSsdCount":
            suggest = "local_ssd_count"
        elif key == "usePreemptibleExecutors":
            suggest = "use_preemptible_executors"
        elif key == "zoneId":
            suggest = "zone_id"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in JobJobClusterNewClusterGcpAttributes. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        JobJobClusterNewClusterGcpAttributes.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        JobJobClusterNewClusterGcpAttributes.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 availability: Optional[str] = None,
                 boot_disk_size: Optional[int] = None,
                 google_service_account: Optional[str] = None,
                 local_ssd_count: Optional[int] = None,
                 use_preemptible_executors: Optional[bool] = None,
                 zone_id: Optional[str] = None):
        if availability is not None:
            pulumi.set(__self__, "availability", availability)
        if boot_disk_size is not None:
            pulumi.set(__self__, "boot_disk_size", boot_disk_size)
        if google_service_account is not None:
            pulumi.set(__self__, "google_service_account", google_service_account)
        if local_ssd_count is not None:
            pulumi.set(__self__, "local_ssd_count", local_ssd_count)
        if use_preemptible_executors is not None:
            pulumi.set(__self__, "use_preemptible_executors", use_preemptible_executors)
        if zone_id is not None:
            pulumi.set(__self__, "zone_id", zone_id)

    @property
    @pulumi.getter
    def availability(self) -> Optional[str]:
        return pulumi.get(self, "availability")

    @property
    @pulumi.getter(name="bootDiskSize")
    def boot_disk_size(self) -> Optional[int]:
        return pulumi.get(self, "boot_disk_size")

    @property
    @pulumi.getter(name="googleServiceAccount")
    def google_service_account(self) -> Optional[str]:
        return pulumi.get(self, "google_service_account")

    @property
    @pulumi.getter(name="localSsdCount")
    def local_ssd_count(self) -> Optional[int]:
        return pulumi.get(self, "local_ssd_count")

    @property
    @pulumi.getter(name="usePreemptibleExecutors")
    def use_preemptible_executors(self) -> Optional[bool]:
        return pulumi.get(self, "use_preemptible_executors")

    @property
    @pulumi.getter(name="zoneId")
    def zone_id(self) -> Optional[str]:
        return pulumi.get(self, "zone_id")


@pulumi.output_type
class JobJobClusterNewClusterInitScript(dict):
    def __init__(__self__, *,
                 abfss: Optional['outputs.JobJobClusterNewClusterInitScriptAbfss'] = None,
                 dbfs: Optional['outputs.JobJobClusterNewClusterInitScriptDbfs'] = None,
                 file: Optional['outputs.JobJobClusterNewClusterInitScriptFile'] = None,
                 gcs: Optional['outputs.JobJobClusterNewClusterInitScriptGcs'] = None,
                 s3: Optional['outputs.JobJobClusterNewClusterInitScriptS3'] = None,
                 volumes: Optional['outputs.JobJobClusterNewClusterInitScriptVolumes'] = None,
                 workspace: Optional['outputs.JobJobClusterNewClusterInitScriptWorkspace'] = None):
        """
        :param 'JobJobClusterNewClusterInitScriptFileArgs' file: block consisting of single string fields:
        """
        if abfss is not None:
            pulumi.set(__self__, "abfss", abfss)
        if dbfs is not None:
            pulumi.set(__self__, "dbfs", dbfs)
        if file is not None:
            pulumi.set(__self__, "file", file)
        if gcs is not None:
            pulumi.set(__self__, "gcs", gcs)
        if s3 is not None:
            pulumi.set(__self__, "s3", s3)
        if volumes is not None:
            pulumi.set(__self__, "volumes", volumes)
        if workspace is not None:
            pulumi.set(__self__, "workspace", workspace)

    @property
    @pulumi.getter
    def abfss(self) -> Optional['outputs.JobJobClusterNewClusterInitScriptAbfss']:
        return pulumi.get(self, "abfss")

    @property
    @pulumi.getter
    def dbfs(self) -> Optional['outputs.JobJobClusterNewClusterInitScriptDbfs']:
        warnings.warn("""For init scripts use 'volumes', 'workspace' or cloud storage location instead of 'dbfs'.""", DeprecationWarning)
        pulumi.log.warn("""dbfs is deprecated: For init scripts use 'volumes', 'workspace' or cloud storage location instead of 'dbfs'.""")

        return pulumi.get(self, "dbfs")

    @property
    @pulumi.getter
    def file(self) -> Optional['outputs.JobJobClusterNewClusterInitScriptFile']:
        """
        block consisting of single string fields:
        """
        return pulumi.get(self, "file")

    @property
    @pulumi.getter
    def gcs(self) -> Optional['outputs.JobJobClusterNewClusterInitScriptGcs']:
        return pulumi.get(self, "gcs")

    @property
    @pulumi.getter
    def s3(self) -> Optional['outputs.JobJobClusterNewClusterInitScriptS3']:
        return pulumi.get(self, "s3")

    @property
    @pulumi.getter
    def volumes(self) -> Optional['outputs.JobJobClusterNewClusterInitScriptVolumes']:
        return pulumi.get(self, "volumes")

    @property
    @pulumi.getter
    def workspace(self) -> Optional['outputs.JobJobClusterNewClusterInitScriptWorkspace']:
        return pulumi.get(self, "workspace")


@pulumi.output_type
class JobJobClusterNewClusterInitScriptAbfss(dict):
    def __init__(__self__, *,
                 destination: str):
        pulumi.set(__self__, "destination", destination)

    @property
    @pulumi.getter
    def destination(self) -> str:
        return pulumi.get(self, "destination")


@pulumi.output_type
class JobJobClusterNewClusterInitScriptDbfs(dict):
    def __init__(__self__, *,
                 destination: str):
        pulumi.set(__self__, "destination", destination)

    @property
    @pulumi.getter
    def destination(self) -> str:
        return pulumi.get(self, "destination")


@pulumi.output_type
class JobJobClusterNewClusterInitScriptFile(dict):
    def __init__(__self__, *,
                 destination: str):
        pulumi.set(__self__, "destination", destination)

    @property
    @pulumi.getter
    def destination(self) -> str:
        return pulumi.get(self, "destination")


@pulumi.output_type
class JobJobClusterNewClusterInitScriptGcs(dict):
    def __init__(__self__, *,
                 destination: str):
        pulumi.set(__self__, "destination", destination)

    @property
    @pulumi.getter
    def destination(self) -> str:
        return pulumi.get(self, "destination")


@pulumi.output_type
class JobJobClusterNewClusterInitScriptS3(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "cannedAcl":
            suggest = "canned_acl"
        elif key == "enableEncryption":
            suggest = "enable_encryption"
        elif key == "encryptionType":
            suggest = "encryption_type"
        elif key == "kmsKey":
            suggest = "kms_key"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in JobJobClusterNewClusterInitScriptS3. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        JobJobClusterNewClusterInitScriptS3.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        JobJobClusterNewClusterInitScriptS3.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 destination: str,
                 canned_acl: Optional[str] = None,
                 enable_encryption: Optional[bool] = None,
                 encryption_type: Optional[str] = None,
                 endpoint: Optional[str] = None,
                 kms_key: Optional[str] = None,
                 region: Optional[str] = None):
        pulumi.set(__self__, "destination", destination)
        if canned_acl is not None:
            pulumi.set(__self__, "canned_acl", canned_acl)
        if enable_encryption is not None:
            pulumi.set(__self__, "enable_encryption", enable_encryption)
        if encryption_type is not None:
            pulumi.set(__self__, "encryption_type", encryption_type)
        if endpoint is not None:
            pulumi.set(__self__, "endpoint", endpoint)
        if kms_key is not None:
            pulumi.set(__self__, "kms_key", kms_key)
        if region is not None:
            pulumi.set(__self__, "region", region)

    @property
    @pulumi.getter
    def destination(self) -> str:
        return pulumi.get(self, "destination")

    @property
    @pulumi.getter(name="cannedAcl")
    def canned_acl(self) -> Optional[str]:
        return pulumi.get(self, "canned_acl")

    @property
    @pulumi.getter(name="enableEncryption")
    def enable_encryption(self) -> Optional[bool]:
        return pulumi.get(self, "enable_encryption")

    @property
    @pulumi.getter(name="encryptionType")
    def encryption_type(self) -> Optional[str]:
        return pulumi.get(self, "encryption_type")

    @property
    @pulumi.getter
    def endpoint(self) -> Optional[str]:
        return pulumi.get(self, "endpoint")

    @property
    @pulumi.getter(name="kmsKey")
    def kms_key(self) -> Optional[str]:
        return pulumi.get(self, "kms_key")

    @property
    @pulumi.getter
    def region(self) -> Optional[str]:
        return pulumi.get(self, "region")


@pulumi.output_type
class JobJobClusterNewClusterInitScriptVolumes(dict):
    def __init__(__self__, *,
                 destination: str):
        pulumi.set(__self__, "destination", destination)

    @property
    @pulumi.getter
    def destination(self) -> str:
        return pulumi.get(self, "destination")


@pulumi.output_type
class JobJobClusterNewClusterInitScriptWorkspace(dict):
    def __init__(__self__, *,
                 destination: str):
        pulumi.set(__self__, "destination", destination)

    @property
    @pulumi.getter
    def destination(self) -> str:
        return pulumi.get(self, "destination")


@pulumi.output_type
class JobJobClusterNewClusterWorkloadType(dict):
    def __init__(__self__, *,
                 clients: 'outputs.JobJobClusterNewClusterWorkloadTypeClients'):
        pulumi.set(__self__, "clients", clients)

    @property
    @pulumi.getter
    def clients(self) -> 'outputs.JobJobClusterNewClusterWorkloadTypeClients':
        return pulumi.get(self, "clients")


@pulumi.output_type
class JobJobClusterNewClusterWorkloadTypeClients(dict):
    def __init__(__self__, *,
                 jobs: Optional[bool] = None,
                 notebooks: Optional[bool] = None):
        if jobs is not None:
            pulumi.set(__self__, "jobs", jobs)
        if notebooks is not None:
            pulumi.set(__self__, "notebooks", notebooks)

    @property
    @pulumi.getter
    def jobs(self) -> Optional[bool]:
        return pulumi.get(self, "jobs")

    @property
    @pulumi.getter
    def notebooks(self) -> Optional[bool]:
        return pulumi.get(self, "notebooks")


@pulumi.output_type
class JobLibrary(dict):
    def __init__(__self__, *,
                 cran: Optional['outputs.JobLibraryCran'] = None,
                 egg: Optional[str] = None,
                 jar: Optional[str] = None,
                 maven: Optional['outputs.JobLibraryMaven'] = None,
                 pypi: Optional['outputs.JobLibraryPypi'] = None,
                 whl: Optional[str] = None):
        if cran is not None:
            pulumi.set(__self__, "cran", cran)
        if egg is not None:
            pulumi.set(__self__, "egg", egg)
        if jar is not None:
            pulumi.set(__self__, "jar", jar)
        if maven is not None:
            pulumi.set(__self__, "maven", maven)
        if pypi is not None:
            pulumi.set(__self__, "pypi", pypi)
        if whl is not None:
            pulumi.set(__self__, "whl", whl)

    @property
    @pulumi.getter
    def cran(self) -> Optional['outputs.JobLibraryCran']:
        return pulumi.get(self, "cran")

    @property
    @pulumi.getter
    def egg(self) -> Optional[str]:
        return pulumi.get(self, "egg")

    @property
    @pulumi.getter
    def jar(self) -> Optional[str]:
        return pulumi.get(self, "jar")

    @property
    @pulumi.getter
    def maven(self) -> Optional['outputs.JobLibraryMaven']:
        return pulumi.get(self, "maven")

    @property
    @pulumi.getter
    def pypi(self) -> Optional['outputs.JobLibraryPypi']:
        return pulumi.get(self, "pypi")

    @property
    @pulumi.getter
    def whl(self) -> Optional[str]:
        return pulumi.get(self, "whl")


@pulumi.output_type
class JobLibraryCran(dict):
    def __init__(__self__, *,
                 package: str,
                 repo: Optional[str] = None):
        pulumi.set(__self__, "package", package)
        if repo is not None:
            pulumi.set(__self__, "repo", repo)

    @property
    @pulumi.getter
    def package(self) -> str:
        return pulumi.get(self, "package")

    @property
    @pulumi.getter
    def repo(self) -> Optional[str]:
        return pulumi.get(self, "repo")


@pulumi.output_type
class JobLibraryMaven(dict):
    def __init__(__self__, *,
                 coordinates: str,
                 exclusions: Optional[Sequence[str]] = None,
                 repo: Optional[str] = None):
        pulumi.set(__self__, "coordinates", coordinates)
        if exclusions is not None:
            pulumi.set(__self__, "exclusions", exclusions)
        if repo is not None:
            pulumi.set(__self__, "repo", repo)

    @property
    @pulumi.getter
    def coordinates(self) -> str:
        return pulumi.get(self, "coordinates")

    @property
    @pulumi.getter
    def exclusions(self) -> Optional[Sequence[str]]:
        return pulumi.get(self, "exclusions")

    @property
    @pulumi.getter
    def repo(self) -> Optional[str]:
        return pulumi.get(self, "repo")


@pulumi.output_type
class JobLibraryPypi(dict):
    def __init__(__self__, *,
                 package: str,
                 repo: Optional[str] = None):
        pulumi.set(__self__, "package", package)
        if repo is not None:
            pulumi.set(__self__, "repo", repo)

    @property
    @pulumi.getter
    def package(self) -> str:
        return pulumi.get(self, "package")

    @property
    @pulumi.getter
    def repo(self) -> Optional[str]:
        return pulumi.get(self, "repo")


@pulumi.output_type
class JobNewCluster(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "sparkVersion":
            suggest = "spark_version"
        elif key == "applyPolicyDefaultValues":
            suggest = "apply_policy_default_values"
        elif key == "autoterminationMinutes":
            suggest = "autotermination_minutes"
        elif key == "awsAttributes":
            suggest = "aws_attributes"
        elif key == "azureAttributes":
            suggest = "azure_attributes"
        elif key == "clusterId":
            suggest = "cluster_id"
        elif key == "clusterLogConf":
            suggest = "cluster_log_conf"
        elif key == "clusterMountInfos":
            suggest = "cluster_mount_infos"
        elif key == "clusterName":
            suggest = "cluster_name"
        elif key == "customTags":
            suggest = "custom_tags"
        elif key == "dataSecurityMode":
            suggest = "data_security_mode"
        elif key == "dockerImage":
            suggest = "docker_image"
        elif key == "driverInstancePoolId":
            suggest = "driver_instance_pool_id"
        elif key == "driverNodeTypeId":
            suggest = "driver_node_type_id"
        elif key == "enableElasticDisk":
            suggest = "enable_elastic_disk"
        elif key == "enableLocalDiskEncryption":
            suggest = "enable_local_disk_encryption"
        elif key == "gcpAttributes":
            suggest = "gcp_attributes"
        elif key == "idempotencyToken":
            suggest = "idempotency_token"
        elif key == "initScripts":
            suggest = "init_scripts"
        elif key == "instancePoolId":
            suggest = "instance_pool_id"
        elif key == "nodeTypeId":
            suggest = "node_type_id"
        elif key == "numWorkers":
            suggest = "num_workers"
        elif key == "policyId":
            suggest = "policy_id"
        elif key == "runtimeEngine":
            suggest = "runtime_engine"
        elif key == "singleUserName":
            suggest = "single_user_name"
        elif key == "sparkConf":
            suggest = "spark_conf"
        elif key == "sparkEnvVars":
            suggest = "spark_env_vars"
        elif key == "sshPublicKeys":
            suggest = "ssh_public_keys"
        elif key == "workloadType":
            suggest = "workload_type"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in JobNewCluster. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        JobNewCluster.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        JobNewCluster.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 spark_version: str,
                 apply_policy_default_values: Optional[bool] = None,
                 autoscale: Optional['outputs.JobNewClusterAutoscale'] = None,
                 autotermination_minutes: Optional[int] = None,
                 aws_attributes: Optional['outputs.JobNewClusterAwsAttributes'] = None,
                 azure_attributes: Optional['outputs.JobNewClusterAzureAttributes'] = None,
                 cluster_id: Optional[str] = None,
                 cluster_log_conf: Optional['outputs.JobNewClusterClusterLogConf'] = None,
                 cluster_mount_infos: Optional[Sequence['outputs.JobNewClusterClusterMountInfo']] = None,
                 cluster_name: Optional[str] = None,
                 custom_tags: Optional[Mapping[str, Any]] = None,
                 data_security_mode: Optional[str] = None,
                 docker_image: Optional['outputs.JobNewClusterDockerImage'] = None,
                 driver_instance_pool_id: Optional[str] = None,
                 driver_node_type_id: Optional[str] = None,
                 enable_elastic_disk: Optional[bool] = None,
                 enable_local_disk_encryption: Optional[bool] = None,
                 gcp_attributes: Optional['outputs.JobNewClusterGcpAttributes'] = None,
                 idempotency_token: Optional[str] = None,
                 init_scripts: Optional[Sequence['outputs.JobNewClusterInitScript']] = None,
                 instance_pool_id: Optional[str] = None,
                 node_type_id: Optional[str] = None,
                 num_workers: Optional[int] = None,
                 policy_id: Optional[str] = None,
                 runtime_engine: Optional[str] = None,
                 single_user_name: Optional[str] = None,
                 spark_conf: Optional[Mapping[str, Any]] = None,
                 spark_env_vars: Optional[Mapping[str, Any]] = None,
                 ssh_public_keys: Optional[Sequence[str]] = None,
                 workload_type: Optional['outputs.JobNewClusterWorkloadType'] = None):
        pulumi.set(__self__, "spark_version", spark_version)
        if apply_policy_default_values is not None:
            pulumi.set(__self__, "apply_policy_default_values", apply_policy_default_values)
        if autoscale is not None:
            pulumi.set(__self__, "autoscale", autoscale)
        if autotermination_minutes is not None:
            pulumi.set(__self__, "autotermination_minutes", autotermination_minutes)
        if aws_attributes is not None:
            pulumi.set(__self__, "aws_attributes", aws_attributes)
        if azure_attributes is not None:
            pulumi.set(__self__, "azure_attributes", azure_attributes)
        if cluster_id is not None:
            pulumi.set(__self__, "cluster_id", cluster_id)
        if cluster_log_conf is not None:
            pulumi.set(__self__, "cluster_log_conf", cluster_log_conf)
        if cluster_mount_infos is not None:
            pulumi.set(__self__, "cluster_mount_infos", cluster_mount_infos)
        if cluster_name is not None:
            pulumi.set(__self__, "cluster_name", cluster_name)
        if custom_tags is not None:
            pulumi.set(__self__, "custom_tags", custom_tags)
        if data_security_mode is not None:
            pulumi.set(__self__, "data_security_mode", data_security_mode)
        if docker_image is not None:
            pulumi.set(__self__, "docker_image", docker_image)
        if driver_instance_pool_id is not None:
            pulumi.set(__self__, "driver_instance_pool_id", driver_instance_pool_id)
        if driver_node_type_id is not None:
            pulumi.set(__self__, "driver_node_type_id", driver_node_type_id)
        if enable_elastic_disk is not None:
            pulumi.set(__self__, "enable_elastic_disk", enable_elastic_disk)
        if enable_local_disk_encryption is not None:
            pulumi.set(__self__, "enable_local_disk_encryption", enable_local_disk_encryption)
        if gcp_attributes is not None:
            pulumi.set(__self__, "gcp_attributes", gcp_attributes)
        if idempotency_token is not None:
            pulumi.set(__self__, "idempotency_token", idempotency_token)
        if init_scripts is not None:
            pulumi.set(__self__, "init_scripts", init_scripts)
        if instance_pool_id is not None:
            pulumi.set(__self__, "instance_pool_id", instance_pool_id)
        if node_type_id is not None:
            pulumi.set(__self__, "node_type_id", node_type_id)
        if num_workers is not None:
            pulumi.set(__self__, "num_workers", num_workers)
        if policy_id is not None:
            pulumi.set(__self__, "policy_id", policy_id)
        if runtime_engine is not None:
            pulumi.set(__self__, "runtime_engine", runtime_engine)
        if single_user_name is not None:
            pulumi.set(__self__, "single_user_name", single_user_name)
        if spark_conf is not None:
            pulumi.set(__self__, "spark_conf", spark_conf)
        if spark_env_vars is not None:
            pulumi.set(__self__, "spark_env_vars", spark_env_vars)
        if ssh_public_keys is not None:
            pulumi.set(__self__, "ssh_public_keys", ssh_public_keys)
        if workload_type is not None:
            pulumi.set(__self__, "workload_type", workload_type)

    @property
    @pulumi.getter(name="sparkVersion")
    def spark_version(self) -> str:
        return pulumi.get(self, "spark_version")

    @property
    @pulumi.getter(name="applyPolicyDefaultValues")
    def apply_policy_default_values(self) -> Optional[bool]:
        return pulumi.get(self, "apply_policy_default_values")

    @property
    @pulumi.getter
    def autoscale(self) -> Optional['outputs.JobNewClusterAutoscale']:
        return pulumi.get(self, "autoscale")

    @property
    @pulumi.getter(name="autoterminationMinutes")
    def autotermination_minutes(self) -> Optional[int]:
        return pulumi.get(self, "autotermination_minutes")

    @property
    @pulumi.getter(name="awsAttributes")
    def aws_attributes(self) -> Optional['outputs.JobNewClusterAwsAttributes']:
        return pulumi.get(self, "aws_attributes")

    @property
    @pulumi.getter(name="azureAttributes")
    def azure_attributes(self) -> Optional['outputs.JobNewClusterAzureAttributes']:
        return pulumi.get(self, "azure_attributes")

    @property
    @pulumi.getter(name="clusterId")
    def cluster_id(self) -> Optional[str]:
        return pulumi.get(self, "cluster_id")

    @property
    @pulumi.getter(name="clusterLogConf")
    def cluster_log_conf(self) -> Optional['outputs.JobNewClusterClusterLogConf']:
        return pulumi.get(self, "cluster_log_conf")

    @property
    @pulumi.getter(name="clusterMountInfos")
    def cluster_mount_infos(self) -> Optional[Sequence['outputs.JobNewClusterClusterMountInfo']]:
        return pulumi.get(self, "cluster_mount_infos")

    @property
    @pulumi.getter(name="clusterName")
    def cluster_name(self) -> Optional[str]:
        return pulumi.get(self, "cluster_name")

    @property
    @pulumi.getter(name="customTags")
    def custom_tags(self) -> Optional[Mapping[str, Any]]:
        return pulumi.get(self, "custom_tags")

    @property
    @pulumi.getter(name="dataSecurityMode")
    def data_security_mode(self) -> Optional[str]:
        return pulumi.get(self, "data_security_mode")

    @property
    @pulumi.getter(name="dockerImage")
    def docker_image(self) -> Optional['outputs.JobNewClusterDockerImage']:
        return pulumi.get(self, "docker_image")

    @property
    @pulumi.getter(name="driverInstancePoolId")
    def driver_instance_pool_id(self) -> Optional[str]:
        return pulumi.get(self, "driver_instance_pool_id")

    @property
    @pulumi.getter(name="driverNodeTypeId")
    def driver_node_type_id(self) -> Optional[str]:
        return pulumi.get(self, "driver_node_type_id")

    @property
    @pulumi.getter(name="enableElasticDisk")
    def enable_elastic_disk(self) -> Optional[bool]:
        return pulumi.get(self, "enable_elastic_disk")

    @property
    @pulumi.getter(name="enableLocalDiskEncryption")
    def enable_local_disk_encryption(self) -> Optional[bool]:
        return pulumi.get(self, "enable_local_disk_encryption")

    @property
    @pulumi.getter(name="gcpAttributes")
    def gcp_attributes(self) -> Optional['outputs.JobNewClusterGcpAttributes']:
        return pulumi.get(self, "gcp_attributes")

    @property
    @pulumi.getter(name="idempotencyToken")
    def idempotency_token(self) -> Optional[str]:
        return pulumi.get(self, "idempotency_token")

    @property
    @pulumi.getter(name="initScripts")
    def init_scripts(self) -> Optional[Sequence['outputs.JobNewClusterInitScript']]:
        return pulumi.get(self, "init_scripts")

    @property
    @pulumi.getter(name="instancePoolId")
    def instance_pool_id(self) -> Optional[str]:
        return pulumi.get(self, "instance_pool_id")

    @property
    @pulumi.getter(name="nodeTypeId")
    def node_type_id(self) -> Optional[str]:
        return pulumi.get(self, "node_type_id")

    @property
    @pulumi.getter(name="numWorkers")
    def num_workers(self) -> Optional[int]:
        return pulumi.get(self, "num_workers")

    @property
    @pulumi.getter(name="policyId")
    def policy_id(self) -> Optional[str]:
        return pulumi.get(self, "policy_id")

    @property
    @pulumi.getter(name="runtimeEngine")
    def runtime_engine(self) -> Optional[str]:
        return pulumi.get(self, "runtime_engine")

    @property
    @pulumi.getter(name="singleUserName")
    def single_user_name(self) -> Optional[str]:
        return pulumi.get(self, "single_user_name")

    @property
    @pulumi.getter(name="sparkConf")
    def spark_conf(self) -> Optional[Mapping[str, Any]]:
        return pulumi.get(self, "spark_conf")

    @property
    @pulumi.getter(name="sparkEnvVars")
    def spark_env_vars(self) -> Optional[Mapping[str, Any]]:
        return pulumi.get(self, "spark_env_vars")

    @property
    @pulumi.getter(name="sshPublicKeys")
    def ssh_public_keys(self) -> Optional[Sequence[str]]:
        return pulumi.get(self, "ssh_public_keys")

    @property
    @pulumi.getter(name="workloadType")
    def workload_type(self) -> Optional['outputs.JobNewClusterWorkloadType']:
        return pulumi.get(self, "workload_type")


@pulumi.output_type
class JobNewClusterAutoscale(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "maxWorkers":
            suggest = "max_workers"
        elif key == "minWorkers":
            suggest = "min_workers"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in JobNewClusterAutoscale. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        JobNewClusterAutoscale.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        JobNewClusterAutoscale.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 max_workers: Optional[int] = None,
                 min_workers: Optional[int] = None):
        if max_workers is not None:
            pulumi.set(__self__, "max_workers", max_workers)
        if min_workers is not None:
            pulumi.set(__self__, "min_workers", min_workers)

    @property
    @pulumi.getter(name="maxWorkers")
    def max_workers(self) -> Optional[int]:
        return pulumi.get(self, "max_workers")

    @property
    @pulumi.getter(name="minWorkers")
    def min_workers(self) -> Optional[int]:
        return pulumi.get(self, "min_workers")


@pulumi.output_type
class JobNewClusterAwsAttributes(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "ebsVolumeCount":
            suggest = "ebs_volume_count"
        elif key == "ebsVolumeSize":
            suggest = "ebs_volume_size"
        elif key == "ebsVolumeType":
            suggest = "ebs_volume_type"
        elif key == "firstOnDemand":
            suggest = "first_on_demand"
        elif key == "instanceProfileArn":
            suggest = "instance_profile_arn"
        elif key == "spotBidPricePercent":
            suggest = "spot_bid_price_percent"
        elif key == "zoneId":
            suggest = "zone_id"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in JobNewClusterAwsAttributes. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        JobNewClusterAwsAttributes.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        JobNewClusterAwsAttributes.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 availability: Optional[str] = None,
                 ebs_volume_count: Optional[int] = None,
                 ebs_volume_size: Optional[int] = None,
                 ebs_volume_type: Optional[str] = None,
                 first_on_demand: Optional[int] = None,
                 instance_profile_arn: Optional[str] = None,
                 spot_bid_price_percent: Optional[int] = None,
                 zone_id: Optional[str] = None):
        if availability is not None:
            pulumi.set(__self__, "availability", availability)
        if ebs_volume_count is not None:
            pulumi.set(__self__, "ebs_volume_count", ebs_volume_count)
        if ebs_volume_size is not None:
            pulumi.set(__self__, "ebs_volume_size", ebs_volume_size)
        if ebs_volume_type is not None:
            pulumi.set(__self__, "ebs_volume_type", ebs_volume_type)
        if first_on_demand is not None:
            pulumi.set(__self__, "first_on_demand", first_on_demand)
        if instance_profile_arn is not None:
            pulumi.set(__self__, "instance_profile_arn", instance_profile_arn)
        if spot_bid_price_percent is not None:
            pulumi.set(__self__, "spot_bid_price_percent", spot_bid_price_percent)
        if zone_id is not None:
            pulumi.set(__self__, "zone_id", zone_id)

    @property
    @pulumi.getter
    def availability(self) -> Optional[str]:
        return pulumi.get(self, "availability")

    @property
    @pulumi.getter(name="ebsVolumeCount")
    def ebs_volume_count(self) -> Optional[int]:
        return pulumi.get(self, "ebs_volume_count")

    @property
    @pulumi.getter(name="ebsVolumeSize")
    def ebs_volume_size(self) -> Optional[int]:
        return pulumi.get(self, "ebs_volume_size")

    @property
    @pulumi.getter(name="ebsVolumeType")
    def ebs_volume_type(self) -> Optional[str]:
        return pulumi.get(self, "ebs_volume_type")

    @property
    @pulumi.getter(name="firstOnDemand")
    def first_on_demand(self) -> Optional[int]:
        return pulumi.get(self, "first_on_demand")

    @property
    @pulumi.getter(name="instanceProfileArn")
    def instance_profile_arn(self) -> Optional[str]:
        return pulumi.get(self, "instance_profile_arn")

    @property
    @pulumi.getter(name="spotBidPricePercent")
    def spot_bid_price_percent(self) -> Optional[int]:
        return pulumi.get(self, "spot_bid_price_percent")

    @property
    @pulumi.getter(name="zoneId")
    def zone_id(self) -> Optional[str]:
        return pulumi.get(self, "zone_id")


@pulumi.output_type
class JobNewClusterAzureAttributes(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "firstOnDemand":
            suggest = "first_on_demand"
        elif key == "spotBidMaxPrice":
            suggest = "spot_bid_max_price"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in JobNewClusterAzureAttributes. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        JobNewClusterAzureAttributes.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        JobNewClusterAzureAttributes.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 availability: Optional[str] = None,
                 first_on_demand: Optional[int] = None,
                 spot_bid_max_price: Optional[float] = None):
        if availability is not None:
            pulumi.set(__self__, "availability", availability)
        if first_on_demand is not None:
            pulumi.set(__self__, "first_on_demand", first_on_demand)
        if spot_bid_max_price is not None:
            pulumi.set(__self__, "spot_bid_max_price", spot_bid_max_price)

    @property
    @pulumi.getter
    def availability(self) -> Optional[str]:
        return pulumi.get(self, "availability")

    @property
    @pulumi.getter(name="firstOnDemand")
    def first_on_demand(self) -> Optional[int]:
        return pulumi.get(self, "first_on_demand")

    @property
    @pulumi.getter(name="spotBidMaxPrice")
    def spot_bid_max_price(self) -> Optional[float]:
        return pulumi.get(self, "spot_bid_max_price")


@pulumi.output_type
class JobNewClusterClusterLogConf(dict):
    def __init__(__self__, *,
                 dbfs: Optional['outputs.JobNewClusterClusterLogConfDbfs'] = None,
                 s3: Optional['outputs.JobNewClusterClusterLogConfS3'] = None):
        if dbfs is not None:
            pulumi.set(__self__, "dbfs", dbfs)
        if s3 is not None:
            pulumi.set(__self__, "s3", s3)

    @property
    @pulumi.getter
    def dbfs(self) -> Optional['outputs.JobNewClusterClusterLogConfDbfs']:
        return pulumi.get(self, "dbfs")

    @property
    @pulumi.getter
    def s3(self) -> Optional['outputs.JobNewClusterClusterLogConfS3']:
        return pulumi.get(self, "s3")


@pulumi.output_type
class JobNewClusterClusterLogConfDbfs(dict):
    def __init__(__self__, *,
                 destination: str):
        pulumi.set(__self__, "destination", destination)

    @property
    @pulumi.getter
    def destination(self) -> str:
        return pulumi.get(self, "destination")


@pulumi.output_type
class JobNewClusterClusterLogConfS3(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "cannedAcl":
            suggest = "canned_acl"
        elif key == "enableEncryption":
            suggest = "enable_encryption"
        elif key == "encryptionType":
            suggest = "encryption_type"
        elif key == "kmsKey":
            suggest = "kms_key"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in JobNewClusterClusterLogConfS3. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        JobNewClusterClusterLogConfS3.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        JobNewClusterClusterLogConfS3.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 destination: str,
                 canned_acl: Optional[str] = None,
                 enable_encryption: Optional[bool] = None,
                 encryption_type: Optional[str] = None,
                 endpoint: Optional[str] = None,
                 kms_key: Optional[str] = None,
                 region: Optional[str] = None):
        pulumi.set(__self__, "destination", destination)
        if canned_acl is not None:
            pulumi.set(__self__, "canned_acl", canned_acl)
        if enable_encryption is not None:
            pulumi.set(__self__, "enable_encryption", enable_encryption)
        if encryption_type is not None:
            pulumi.set(__self__, "encryption_type", encryption_type)
        if endpoint is not None:
            pulumi.set(__self__, "endpoint", endpoint)
        if kms_key is not None:
            pulumi.set(__self__, "kms_key", kms_key)
        if region is not None:
            pulumi.set(__self__, "region", region)

    @property
    @pulumi.getter
    def destination(self) -> str:
        return pulumi.get(self, "destination")

    @property
    @pulumi.getter(name="cannedAcl")
    def canned_acl(self) -> Optional[str]:
        return pulumi.get(self, "canned_acl")

    @property
    @pulumi.getter(name="enableEncryption")
    def enable_encryption(self) -> Optional[bool]:
        return pulumi.get(self, "enable_encryption")

    @property
    @pulumi.getter(name="encryptionType")
    def encryption_type(self) -> Optional[str]:
        return pulumi.get(self, "encryption_type")

    @property
    @pulumi.getter
    def endpoint(self) -> Optional[str]:
        return pulumi.get(self, "endpoint")

    @property
    @pulumi.getter(name="kmsKey")
    def kms_key(self) -> Optional[str]:
        return pulumi.get(self, "kms_key")

    @property
    @pulumi.getter
    def region(self) -> Optional[str]:
        return pulumi.get(self, "region")


@pulumi.output_type
class JobNewClusterClusterMountInfo(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "localMountDirPath":
            suggest = "local_mount_dir_path"
        elif key == "networkFilesystemInfo":
            suggest = "network_filesystem_info"
        elif key == "remoteMountDirPath":
            suggest = "remote_mount_dir_path"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in JobNewClusterClusterMountInfo. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        JobNewClusterClusterMountInfo.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        JobNewClusterClusterMountInfo.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 local_mount_dir_path: str,
                 network_filesystem_info: 'outputs.JobNewClusterClusterMountInfoNetworkFilesystemInfo',
                 remote_mount_dir_path: Optional[str] = None):
        pulumi.set(__self__, "local_mount_dir_path", local_mount_dir_path)
        pulumi.set(__self__, "network_filesystem_info", network_filesystem_info)
        if remote_mount_dir_path is not None:
            pulumi.set(__self__, "remote_mount_dir_path", remote_mount_dir_path)

    @property
    @pulumi.getter(name="localMountDirPath")
    def local_mount_dir_path(self) -> str:
        return pulumi.get(self, "local_mount_dir_path")

    @property
    @pulumi.getter(name="networkFilesystemInfo")
    def network_filesystem_info(self) -> 'outputs.JobNewClusterClusterMountInfoNetworkFilesystemInfo':
        return pulumi.get(self, "network_filesystem_info")

    @property
    @pulumi.getter(name="remoteMountDirPath")
    def remote_mount_dir_path(self) -> Optional[str]:
        return pulumi.get(self, "remote_mount_dir_path")


@pulumi.output_type
class JobNewClusterClusterMountInfoNetworkFilesystemInfo(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "serverAddress":
            suggest = "server_address"
        elif key == "mountOptions":
            suggest = "mount_options"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in JobNewClusterClusterMountInfoNetworkFilesystemInfo. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        JobNewClusterClusterMountInfoNetworkFilesystemInfo.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        JobNewClusterClusterMountInfoNetworkFilesystemInfo.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 server_address: str,
                 mount_options: Optional[str] = None):
        pulumi.set(__self__, "server_address", server_address)
        if mount_options is not None:
            pulumi.set(__self__, "mount_options", mount_options)

    @property
    @pulumi.getter(name="serverAddress")
    def server_address(self) -> str:
        return pulumi.get(self, "server_address")

    @property
    @pulumi.getter(name="mountOptions")
    def mount_options(self) -> Optional[str]:
        return pulumi.get(self, "mount_options")


@pulumi.output_type
class JobNewClusterDockerImage(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "basicAuth":
            suggest = "basic_auth"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in JobNewClusterDockerImage. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        JobNewClusterDockerImage.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        JobNewClusterDockerImage.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 url: str,
                 basic_auth: Optional['outputs.JobNewClusterDockerImageBasicAuth'] = None):
        """
        :param str url: URL of the Git repository to use.
        """
        pulumi.set(__self__, "url", url)
        if basic_auth is not None:
            pulumi.set(__self__, "basic_auth", basic_auth)

    @property
    @pulumi.getter
    def url(self) -> str:
        """
        URL of the Git repository to use.
        """
        return pulumi.get(self, "url")

    @property
    @pulumi.getter(name="basicAuth")
    def basic_auth(self) -> Optional['outputs.JobNewClusterDockerImageBasicAuth']:
        return pulumi.get(self, "basic_auth")


@pulumi.output_type
class JobNewClusterDockerImageBasicAuth(dict):
    def __init__(__self__, *,
                 password: str,
                 username: str):
        pulumi.set(__self__, "password", password)
        pulumi.set(__self__, "username", username)

    @property
    @pulumi.getter
    def password(self) -> str:
        return pulumi.get(self, "password")

    @property
    @pulumi.getter
    def username(self) -> str:
        return pulumi.get(self, "username")


@pulumi.output_type
class JobNewClusterGcpAttributes(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "bootDiskSize":
            suggest = "boot_disk_size"
        elif key == "googleServiceAccount":
            suggest = "google_service_account"
        elif key == "localSsdCount":
            suggest = "local_ssd_count"
        elif key == "usePreemptibleExecutors":
            suggest = "use_preemptible_executors"
        elif key == "zoneId":
            suggest = "zone_id"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in JobNewClusterGcpAttributes. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        JobNewClusterGcpAttributes.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        JobNewClusterGcpAttributes.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 availability: Optional[str] = None,
                 boot_disk_size: Optional[int] = None,
                 google_service_account: Optional[str] = None,
                 local_ssd_count: Optional[int] = None,
                 use_preemptible_executors: Optional[bool] = None,
                 zone_id: Optional[str] = None):
        if availability is not None:
            pulumi.set(__self__, "availability", availability)
        if boot_disk_size is not None:
            pulumi.set(__self__, "boot_disk_size", boot_disk_size)
        if google_service_account is not None:
            pulumi.set(__self__, "google_service_account", google_service_account)
        if local_ssd_count is not None:
            pulumi.set(__self__, "local_ssd_count", local_ssd_count)
        if use_preemptible_executors is not None:
            pulumi.set(__self__, "use_preemptible_executors", use_preemptible_executors)
        if zone_id is not None:
            pulumi.set(__self__, "zone_id", zone_id)

    @property
    @pulumi.getter
    def availability(self) -> Optional[str]:
        return pulumi.get(self, "availability")

    @property
    @pulumi.getter(name="bootDiskSize")
    def boot_disk_size(self) -> Optional[int]:
        return pulumi.get(self, "boot_disk_size")

    @property
    @pulumi.getter(name="googleServiceAccount")
    def google_service_account(self) -> Optional[str]:
        return pulumi.get(self, "google_service_account")

    @property
    @pulumi.getter(name="localSsdCount")
    def local_ssd_count(self) -> Optional[int]:
        return pulumi.get(self, "local_ssd_count")

    @property
    @pulumi.getter(name="usePreemptibleExecutors")
    def use_preemptible_executors(self) -> Optional[bool]:
        return pulumi.get(self, "use_preemptible_executors")

    @property
    @pulumi.getter(name="zoneId")
    def zone_id(self) -> Optional[str]:
        return pulumi.get(self, "zone_id")


@pulumi.output_type
class JobNewClusterInitScript(dict):
    def __init__(__self__, *,
                 abfss: Optional['outputs.JobNewClusterInitScriptAbfss'] = None,
                 dbfs: Optional['outputs.JobNewClusterInitScriptDbfs'] = None,
                 file: Optional['outputs.JobNewClusterInitScriptFile'] = None,
                 gcs: Optional['outputs.JobNewClusterInitScriptGcs'] = None,
                 s3: Optional['outputs.JobNewClusterInitScriptS3'] = None,
                 volumes: Optional['outputs.JobNewClusterInitScriptVolumes'] = None,
                 workspace: Optional['outputs.JobNewClusterInitScriptWorkspace'] = None):
        """
        :param 'JobNewClusterInitScriptFileArgs' file: block consisting of single string fields:
        """
        if abfss is not None:
            pulumi.set(__self__, "abfss", abfss)
        if dbfs is not None:
            pulumi.set(__self__, "dbfs", dbfs)
        if file is not None:
            pulumi.set(__self__, "file", file)
        if gcs is not None:
            pulumi.set(__self__, "gcs", gcs)
        if s3 is not None:
            pulumi.set(__self__, "s3", s3)
        if volumes is not None:
            pulumi.set(__self__, "volumes", volumes)
        if workspace is not None:
            pulumi.set(__self__, "workspace", workspace)

    @property
    @pulumi.getter
    def abfss(self) -> Optional['outputs.JobNewClusterInitScriptAbfss']:
        return pulumi.get(self, "abfss")

    @property
    @pulumi.getter
    def dbfs(self) -> Optional['outputs.JobNewClusterInitScriptDbfs']:
        warnings.warn("""For init scripts use 'volumes', 'workspace' or cloud storage location instead of 'dbfs'.""", DeprecationWarning)
        pulumi.log.warn("""dbfs is deprecated: For init scripts use 'volumes', 'workspace' or cloud storage location instead of 'dbfs'.""")

        return pulumi.get(self, "dbfs")

    @property
    @pulumi.getter
    def file(self) -> Optional['outputs.JobNewClusterInitScriptFile']:
        """
        block consisting of single string fields:
        """
        return pulumi.get(self, "file")

    @property
    @pulumi.getter
    def gcs(self) -> Optional['outputs.JobNewClusterInitScriptGcs']:
        return pulumi.get(self, "gcs")

    @property
    @pulumi.getter
    def s3(self) -> Optional['outputs.JobNewClusterInitScriptS3']:
        return pulumi.get(self, "s3")

    @property
    @pulumi.getter
    def volumes(self) -> Optional['outputs.JobNewClusterInitScriptVolumes']:
        return pulumi.get(self, "volumes")

    @property
    @pulumi.getter
    def workspace(self) -> Optional['outputs.JobNewClusterInitScriptWorkspace']:
        return pulumi.get(self, "workspace")


@pulumi.output_type
class JobNewClusterInitScriptAbfss(dict):
    def __init__(__self__, *,
                 destination: str):
        pulumi.set(__self__, "destination", destination)

    @property
    @pulumi.getter
    def destination(self) -> str:
        return pulumi.get(self, "destination")


@pulumi.output_type
class JobNewClusterInitScriptDbfs(dict):
    def __init__(__self__, *,
                 destination: str):
        pulumi.set(__self__, "destination", destination)

    @property
    @pulumi.getter
    def destination(self) -> str:
        return pulumi.get(self, "destination")


@pulumi.output_type
class JobNewClusterInitScriptFile(dict):
    def __init__(__self__, *,
                 destination: str):
        pulumi.set(__self__, "destination", destination)

    @property
    @pulumi.getter
    def destination(self) -> str:
        return pulumi.get(self, "destination")


@pulumi.output_type
class JobNewClusterInitScriptGcs(dict):
    def __init__(__self__, *,
                 destination: str):
        pulumi.set(__self__, "destination", destination)

    @property
    @pulumi.getter
    def destination(self) -> str:
        return pulumi.get(self, "destination")


@pulumi.output_type
class JobNewClusterInitScriptS3(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "cannedAcl":
            suggest = "canned_acl"
        elif key == "enableEncryption":
            suggest = "enable_encryption"
        elif key == "encryptionType":
            suggest = "encryption_type"
        elif key == "kmsKey":
            suggest = "kms_key"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in JobNewClusterInitScriptS3. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        JobNewClusterInitScriptS3.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        JobNewClusterInitScriptS3.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 destination: str,
                 canned_acl: Optional[str] = None,
                 enable_encryption: Optional[bool] = None,
                 encryption_type: Optional[str] = None,
                 endpoint: Optional[str] = None,
                 kms_key: Optional[str] = None,
                 region: Optional[str] = None):
        pulumi.set(__self__, "destination", destination)
        if canned_acl is not None:
            pulumi.set(__self__, "canned_acl", canned_acl)
        if enable_encryption is not None:
            pulumi.set(__self__, "enable_encryption", enable_encryption)
        if encryption_type is not None:
            pulumi.set(__self__, "encryption_type", encryption_type)
        if endpoint is not None:
            pulumi.set(__self__, "endpoint", endpoint)
        if kms_key is not None:
            pulumi.set(__self__, "kms_key", kms_key)
        if region is not None:
            pulumi.set(__self__, "region", region)

    @property
    @pulumi.getter
    def destination(self) -> str:
        return pulumi.get(self, "destination")

    @property
    @pulumi.getter(name="cannedAcl")
    def canned_acl(self) -> Optional[str]:
        return pulumi.get(self, "canned_acl")

    @property
    @pulumi.getter(name="enableEncryption")
    def enable_encryption(self) -> Optional[bool]:
        return pulumi.get(self, "enable_encryption")

    @property
    @pulumi.getter(name="encryptionType")
    def encryption_type(self) -> Optional[str]:
        return pulumi.get(self, "encryption_type")

    @property
    @pulumi.getter
    def endpoint(self) -> Optional[str]:
        return pulumi.get(self, "endpoint")

    @property
    @pulumi.getter(name="kmsKey")
    def kms_key(self) -> Optional[str]:
        return pulumi.get(self, "kms_key")

    @property
    @pulumi.getter
    def region(self) -> Optional[str]:
        return pulumi.get(self, "region")


@pulumi.output_type
class JobNewClusterInitScriptVolumes(dict):
    def __init__(__self__, *,
                 destination: str):
        pulumi.set(__self__, "destination", destination)

    @property
    @pulumi.getter
    def destination(self) -> str:
        return pulumi.get(self, "destination")


@pulumi.output_type
class JobNewClusterInitScriptWorkspace(dict):
    def __init__(__self__, *,
                 destination: str):
        pulumi.set(__self__, "destination", destination)

    @property
    @pulumi.getter
    def destination(self) -> str:
        return pulumi.get(self, "destination")


@pulumi.output_type
class JobNewClusterWorkloadType(dict):
    def __init__(__self__, *,
                 clients: 'outputs.JobNewClusterWorkloadTypeClients'):
        pulumi.set(__self__, "clients", clients)

    @property
    @pulumi.getter
    def clients(self) -> 'outputs.JobNewClusterWorkloadTypeClients':
        return pulumi.get(self, "clients")


@pulumi.output_type
class JobNewClusterWorkloadTypeClients(dict):
    def __init__(__self__, *,
                 jobs: Optional[bool] = None,
                 notebooks: Optional[bool] = None):
        if jobs is not None:
            pulumi.set(__self__, "jobs", jobs)
        if notebooks is not None:
            pulumi.set(__self__, "notebooks", notebooks)

    @property
    @pulumi.getter
    def jobs(self) -> Optional[bool]:
        return pulumi.get(self, "jobs")

    @property
    @pulumi.getter
    def notebooks(self) -> Optional[bool]:
        return pulumi.get(self, "notebooks")


@pulumi.output_type
class JobNotebookTask(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "notebookPath":
            suggest = "notebook_path"
        elif key == "baseParameters":
            suggest = "base_parameters"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in JobNotebookTask. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        JobNotebookTask.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        JobNotebookTask.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 notebook_path: str,
                 base_parameters: Optional[Mapping[str, Any]] = None,
                 source: Optional[str] = None):
        """
        :param str notebook_path: The path of the Notebook to be run in the Databricks workspace or remote repository. For notebooks stored in the Databricks workspace, the path must be absolute and begin with a slash. For notebooks stored in a remote repository, the path must be relative. This field is required.
        :param Mapping[str, Any] base_parameters: (Map) Base parameters to be used for each run of this job. If the run is initiated by a call to run-now with parameters specified, the two parameters maps will be merged. If the same key is specified in base_parameters and in run-now, the value from run-now will be used. If the notebook takes a parameter that is not specified in the job’s base_parameters or the run-now override parameters, the default value from the notebook will be used. Retrieve these parameters in a notebook using `dbutils.widgets.get`.
        :param str source: Location type of the notebook, can only be `WORKSPACE` or `GIT`. When set to `WORKSPACE`, the notebook will be retrieved from the local Databricks workspace. When set to `GIT`, the notebook will be retrieved from a Git repository defined in `git_source`. If the value is empty, the task will use `GIT` if `git_source` is defined and `WORKSPACE` otherwise.
        """
        pulumi.set(__self__, "notebook_path", notebook_path)
        if base_parameters is not None:
            pulumi.set(__self__, "base_parameters", base_parameters)
        if source is not None:
            pulumi.set(__self__, "source", source)

    @property
    @pulumi.getter(name="notebookPath")
    def notebook_path(self) -> str:
        """
        The path of the Notebook to be run in the Databricks workspace or remote repository. For notebooks stored in the Databricks workspace, the path must be absolute and begin with a slash. For notebooks stored in a remote repository, the path must be relative. This field is required.
        """
        return pulumi.get(self, "notebook_path")

    @property
    @pulumi.getter(name="baseParameters")
    def base_parameters(self) -> Optional[Mapping[str, Any]]:
        """
        (Map) Base parameters to be used for each run of this job. If the run is initiated by a call to run-now with parameters specified, the two parameters maps will be merged. If the same key is specified in base_parameters and in run-now, the value from run-now will be used. If the notebook takes a parameter that is not specified in the job’s base_parameters or the run-now override parameters, the default value from the notebook will be used. Retrieve these parameters in a notebook using `dbutils.widgets.get`.
        """
        return pulumi.get(self, "base_parameters")

    @property
    @pulumi.getter
    def source(self) -> Optional[str]:
        """
        Location type of the notebook, can only be `WORKSPACE` or `GIT`. When set to `WORKSPACE`, the notebook will be retrieved from the local Databricks workspace. When set to `GIT`, the notebook will be retrieved from a Git repository defined in `git_source`. If the value is empty, the task will use `GIT` if `git_source` is defined and `WORKSPACE` otherwise.
        """
        return pulumi.get(self, "source")


@pulumi.output_type
class JobNotificationSettings(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "noAlertForCanceledRuns":
            suggest = "no_alert_for_canceled_runs"
        elif key == "noAlertForSkippedRuns":
            suggest = "no_alert_for_skipped_runs"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in JobNotificationSettings. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        JobNotificationSettings.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        JobNotificationSettings.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 no_alert_for_canceled_runs: Optional[bool] = None,
                 no_alert_for_skipped_runs: Optional[bool] = None):
        """
        :param bool no_alert_for_canceled_runs: (Bool) don't send alert for cancelled runs.
        :param bool no_alert_for_skipped_runs: (Bool) don't send alert for skipped runs.
        """
        if no_alert_for_canceled_runs is not None:
            pulumi.set(__self__, "no_alert_for_canceled_runs", no_alert_for_canceled_runs)
        if no_alert_for_skipped_runs is not None:
            pulumi.set(__self__, "no_alert_for_skipped_runs", no_alert_for_skipped_runs)

    @property
    @pulumi.getter(name="noAlertForCanceledRuns")
    def no_alert_for_canceled_runs(self) -> Optional[bool]:
        """
        (Bool) don't send alert for cancelled runs.
        """
        return pulumi.get(self, "no_alert_for_canceled_runs")

    @property
    @pulumi.getter(name="noAlertForSkippedRuns")
    def no_alert_for_skipped_runs(self) -> Optional[bool]:
        """
        (Bool) don't send alert for skipped runs.
        """
        return pulumi.get(self, "no_alert_for_skipped_runs")


@pulumi.output_type
class JobParameter(dict):
    def __init__(__self__, *,
                 default: str,
                 name: str):
        """
        :param str default: Default value of the parameter.
        :param str name: The name of the defined parameter. May only contain alphanumeric characters, `_`, `-`, and `.`.
        """
        pulumi.set(__self__, "default", default)
        pulumi.set(__self__, "name", name)

    @property
    @pulumi.getter
    def default(self) -> str:
        """
        Default value of the parameter.
        """
        return pulumi.get(self, "default")

    @property
    @pulumi.getter
    def name(self) -> str:
        """
        The name of the defined parameter. May only contain alphanumeric characters, `_`, `-`, and `.`.
        """
        return pulumi.get(self, "name")


@pulumi.output_type
class JobPipelineTask(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "pipelineId":
            suggest = "pipeline_id"
        elif key == "fullRefresh":
            suggest = "full_refresh"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in JobPipelineTask. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        JobPipelineTask.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        JobPipelineTask.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 pipeline_id: str,
                 full_refresh: Optional[bool] = None):
        """
        :param str pipeline_id: The pipeline's unique ID.
        :param bool full_refresh: (Bool) Specifies if there should be full refresh of the pipeline.
               
               > **Note** The following configuration blocks are only supported inside a `task` block
        """
        pulumi.set(__self__, "pipeline_id", pipeline_id)
        if full_refresh is not None:
            pulumi.set(__self__, "full_refresh", full_refresh)

    @property
    @pulumi.getter(name="pipelineId")
    def pipeline_id(self) -> str:
        """
        The pipeline's unique ID.
        """
        return pulumi.get(self, "pipeline_id")

    @property
    @pulumi.getter(name="fullRefresh")
    def full_refresh(self) -> Optional[bool]:
        """
        (Bool) Specifies if there should be full refresh of the pipeline.

        > **Note** The following configuration blocks are only supported inside a `task` block
        """
        return pulumi.get(self, "full_refresh")


@pulumi.output_type
class JobPythonWheelTask(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "entryPoint":
            suggest = "entry_point"
        elif key == "namedParameters":
            suggest = "named_parameters"
        elif key == "packageName":
            suggest = "package_name"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in JobPythonWheelTask. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        JobPythonWheelTask.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        JobPythonWheelTask.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 entry_point: Optional[str] = None,
                 named_parameters: Optional[Mapping[str, Any]] = None,
                 package_name: Optional[str] = None,
                 parameters: Optional[Sequence[str]] = None):
        """
        :param str entry_point: Python function as entry point for the task
        :param Mapping[str, Any] named_parameters: Named parameters for the task
        :param str package_name: Name of Python package
        :param Sequence[str] parameters: Parameters for the task
        """
        if entry_point is not None:
            pulumi.set(__self__, "entry_point", entry_point)
        if named_parameters is not None:
            pulumi.set(__self__, "named_parameters", named_parameters)
        if package_name is not None:
            pulumi.set(__self__, "package_name", package_name)
        if parameters is not None:
            pulumi.set(__self__, "parameters", parameters)

    @property
    @pulumi.getter(name="entryPoint")
    def entry_point(self) -> Optional[str]:
        """
        Python function as entry point for the task
        """
        return pulumi.get(self, "entry_point")

    @property
    @pulumi.getter(name="namedParameters")
    def named_parameters(self) -> Optional[Mapping[str, Any]]:
        """
        Named parameters for the task
        """
        return pulumi.get(self, "named_parameters")

    @property
    @pulumi.getter(name="packageName")
    def package_name(self) -> Optional[str]:
        """
        Name of Python package
        """
        return pulumi.get(self, "package_name")

    @property
    @pulumi.getter
    def parameters(self) -> Optional[Sequence[str]]:
        """
        Parameters for the task
        """
        return pulumi.get(self, "parameters")


@pulumi.output_type
class JobQueue(dict):
    def __init__(__self__, *,
                 enabled: bool):
        """
        :param bool enabled: If true, enable queueing for the job.
        """
        pulumi.set(__self__, "enabled", enabled)

    @property
    @pulumi.getter
    def enabled(self) -> bool:
        """
        If true, enable queueing for the job.
        """
        return pulumi.get(self, "enabled")


@pulumi.output_type
class JobRunAs(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "servicePrincipalName":
            suggest = "service_principal_name"
        elif key == "userName":
            suggest = "user_name"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in JobRunAs. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        JobRunAs.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        JobRunAs.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 service_principal_name: Optional[str] = None,
                 user_name: Optional[str] = None):
        """
        :param str service_principal_name: The application ID of an active service principal. Setting this field requires the `servicePrincipal/user` role.
               
               Example:
               
               <!--Start PulumiCodeChooser -->
               ```python
               import pulumi
               import pulumi_databricks as databricks
               
               this = databricks.Job("this", run_as=databricks.JobRunAsArgs(
                   service_principal_name="8d23ae77-912e-4a19-81e4-b9c3f5cc9349",
               ))
               ```
               <!--End PulumiCodeChooser -->
        :param str user_name: The email of an active workspace user. Non-admin users can only set this field to their own email.
        """
        if service_principal_name is not None:
            pulumi.set(__self__, "service_principal_name", service_principal_name)
        if user_name is not None:
            pulumi.set(__self__, "user_name", user_name)

    @property
    @pulumi.getter(name="servicePrincipalName")
    def service_principal_name(self) -> Optional[str]:
        """
        The application ID of an active service principal. Setting this field requires the `servicePrincipal/user` role.

        Example:

        <!--Start PulumiCodeChooser -->
        ```python
        import pulumi
        import pulumi_databricks as databricks

        this = databricks.Job("this", run_as=databricks.JobRunAsArgs(
            service_principal_name="8d23ae77-912e-4a19-81e4-b9c3f5cc9349",
        ))
        ```
        <!--End PulumiCodeChooser -->
        """
        return pulumi.get(self, "service_principal_name")

    @property
    @pulumi.getter(name="userName")
    def user_name(self) -> Optional[str]:
        """
        The email of an active workspace user. Non-admin users can only set this field to their own email.
        """
        return pulumi.get(self, "user_name")


@pulumi.output_type
class JobRunJobTask(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "jobId":
            suggest = "job_id"
        elif key == "jobParameters":
            suggest = "job_parameters"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in JobRunJobTask. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        JobRunJobTask.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        JobRunJobTask.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 job_id: int,
                 job_parameters: Optional[Mapping[str, Any]] = None):
        """
        :param int job_id: (String) ID of the job
        :param Mapping[str, Any] job_parameters: (Map) Job parameters for the task
        """
        pulumi.set(__self__, "job_id", job_id)
        if job_parameters is not None:
            pulumi.set(__self__, "job_parameters", job_parameters)

    @property
    @pulumi.getter(name="jobId")
    def job_id(self) -> int:
        """
        (String) ID of the job
        """
        return pulumi.get(self, "job_id")

    @property
    @pulumi.getter(name="jobParameters")
    def job_parameters(self) -> Optional[Mapping[str, Any]]:
        """
        (Map) Job parameters for the task
        """
        return pulumi.get(self, "job_parameters")


@pulumi.output_type
class JobSchedule(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "quartzCronExpression":
            suggest = "quartz_cron_expression"
        elif key == "timezoneId":
            suggest = "timezone_id"
        elif key == "pauseStatus":
            suggest = "pause_status"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in JobSchedule. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        JobSchedule.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        JobSchedule.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 quartz_cron_expression: str,
                 timezone_id: str,
                 pause_status: Optional[str] = None):
        """
        :param str quartz_cron_expression: A [Cron expression using Quartz syntax](http://www.quartz-scheduler.org/documentation/quartz-2.3.0/tutorials/crontrigger.html) that describes the schedule for a job. This field is required.
        :param str timezone_id: A Java timezone ID. The schedule for a job will be resolved with respect to this timezone. See Java TimeZone for details. This field is required.
        :param str pause_status: Indicate whether this schedule is paused or not. Either `PAUSED` or `UNPAUSED`. When the `pause_status` field is omitted and a schedule is provided, the server will default to using `UNPAUSED` as a value for `pause_status`.
        """
        pulumi.set(__self__, "quartz_cron_expression", quartz_cron_expression)
        pulumi.set(__self__, "timezone_id", timezone_id)
        if pause_status is not None:
            pulumi.set(__self__, "pause_status", pause_status)

    @property
    @pulumi.getter(name="quartzCronExpression")
    def quartz_cron_expression(self) -> str:
        """
        A [Cron expression using Quartz syntax](http://www.quartz-scheduler.org/documentation/quartz-2.3.0/tutorials/crontrigger.html) that describes the schedule for a job. This field is required.
        """
        return pulumi.get(self, "quartz_cron_expression")

    @property
    @pulumi.getter(name="timezoneId")
    def timezone_id(self) -> str:
        """
        A Java timezone ID. The schedule for a job will be resolved with respect to this timezone. See Java TimeZone for details. This field is required.
        """
        return pulumi.get(self, "timezone_id")

    @property
    @pulumi.getter(name="pauseStatus")
    def pause_status(self) -> Optional[str]:
        """
        Indicate whether this schedule is paused or not. Either `PAUSED` or `UNPAUSED`. When the `pause_status` field is omitted and a schedule is provided, the server will default to using `UNPAUSED` as a value for `pause_status`.
        """
        return pulumi.get(self, "pause_status")


@pulumi.output_type
class JobSparkJarTask(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "jarUri":
            suggest = "jar_uri"
        elif key == "mainClassName":
            suggest = "main_class_name"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in JobSparkJarTask. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        JobSparkJarTask.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        JobSparkJarTask.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 jar_uri: Optional[str] = None,
                 main_class_name: Optional[str] = None,
                 parameters: Optional[Sequence[str]] = None):
        """
        :param str main_class_name: The full name of the class containing the main method to be executed. This class must be contained in a JAR provided as a library. The code should use `SparkContext.getOrCreate` to obtain a Spark context; otherwise, runs of the job will fail.
        :param Sequence[str] parameters: (List) Parameters passed to the main method.
        """
        if jar_uri is not None:
            pulumi.set(__self__, "jar_uri", jar_uri)
        if main_class_name is not None:
            pulumi.set(__self__, "main_class_name", main_class_name)
        if parameters is not None:
            pulumi.set(__self__, "parameters", parameters)

    @property
    @pulumi.getter(name="jarUri")
    def jar_uri(self) -> Optional[str]:
        return pulumi.get(self, "jar_uri")

    @property
    @pulumi.getter(name="mainClassName")
    def main_class_name(self) -> Optional[str]:
        """
        The full name of the class containing the main method to be executed. This class must be contained in a JAR provided as a library. The code should use `SparkContext.getOrCreate` to obtain a Spark context; otherwise, runs of the job will fail.
        """
        return pulumi.get(self, "main_class_name")

    @property
    @pulumi.getter
    def parameters(self) -> Optional[Sequence[str]]:
        """
        (List) Parameters passed to the main method.
        """
        return pulumi.get(self, "parameters")


@pulumi.output_type
class JobSparkPythonTask(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "pythonFile":
            suggest = "python_file"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in JobSparkPythonTask. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        JobSparkPythonTask.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        JobSparkPythonTask.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 python_file: str,
                 parameters: Optional[Sequence[str]] = None,
                 source: Optional[str] = None):
        """
        :param str python_file: The URI of the Python file to be executed. databricks_dbfs_file, cloud file URIs (e.g. `s3:/`, `abfss:/`, `gs:/`), workspace paths and remote repository are supported. For Python files stored in the Databricks workspace, the path must be absolute and begin with `/Repos`. For files stored in a remote repository, the path must be relative. This field is required.
        :param Sequence[str] parameters: (List) Command line parameters passed to the Python file.
        :param str source: Location type of the Python file, can only be `GIT`. When set to `GIT`, the Python file will be retrieved from a Git repository defined in `git_source`.
        """
        pulumi.set(__self__, "python_file", python_file)
        if parameters is not None:
            pulumi.set(__self__, "parameters", parameters)
        if source is not None:
            pulumi.set(__self__, "source", source)

    @property
    @pulumi.getter(name="pythonFile")
    def python_file(self) -> str:
        """
        The URI of the Python file to be executed. databricks_dbfs_file, cloud file URIs (e.g. `s3:/`, `abfss:/`, `gs:/`), workspace paths and remote repository are supported. For Python files stored in the Databricks workspace, the path must be absolute and begin with `/Repos`. For files stored in a remote repository, the path must be relative. This field is required.
        """
        return pulumi.get(self, "python_file")

    @property
    @pulumi.getter
    def parameters(self) -> Optional[Sequence[str]]:
        """
        (List) Command line parameters passed to the Python file.
        """
        return pulumi.get(self, "parameters")

    @property
    @pulumi.getter
    def source(self) -> Optional[str]:
        """
        Location type of the Python file, can only be `GIT`. When set to `GIT`, the Python file will be retrieved from a Git repository defined in `git_source`.
        """
        return pulumi.get(self, "source")


@pulumi.output_type
class JobSparkSubmitTask(dict):
    def __init__(__self__, *,
                 parameters: Optional[Sequence[str]] = None):
        """
        :param Sequence[str] parameters: (List) Command-line parameters passed to spark submit.
        """
        if parameters is not None:
            pulumi.set(__self__, "parameters", parameters)

    @property
    @pulumi.getter
    def parameters(self) -> Optional[Sequence[str]]:
        """
        (List) Command-line parameters passed to spark submit.
        """
        return pulumi.get(self, "parameters")


@pulumi.output_type
class JobTask(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "computeKey":
            suggest = "compute_key"
        elif key == "conditionTask":
            suggest = "condition_task"
        elif key == "dbtTask":
            suggest = "dbt_task"
        elif key == "dependsOns":
            suggest = "depends_ons"
        elif key == "emailNotifications":
            suggest = "email_notifications"
        elif key == "existingClusterId":
            suggest = "existing_cluster_id"
        elif key == "forEachTask":
            suggest = "for_each_task"
        elif key == "jobClusterKey":
            suggest = "job_cluster_key"
        elif key == "maxRetries":
            suggest = "max_retries"
        elif key == "minRetryIntervalMillis":
            suggest = "min_retry_interval_millis"
        elif key == "newCluster":
            suggest = "new_cluster"
        elif key == "notebookTask":
            suggest = "notebook_task"
        elif key == "notificationSettings":
            suggest = "notification_settings"
        elif key == "pipelineTask":
            suggest = "pipeline_task"
        elif key == "pythonWheelTask":
            suggest = "python_wheel_task"
        elif key == "retryOnTimeout":
            suggest = "retry_on_timeout"
        elif key == "runIf":
            suggest = "run_if"
        elif key == "runJobTask":
            suggest = "run_job_task"
        elif key == "sparkJarTask":
            suggest = "spark_jar_task"
        elif key == "sparkPythonTask":
            suggest = "spark_python_task"
        elif key == "sparkSubmitTask":
            suggest = "spark_submit_task"
        elif key == "sqlTask":
            suggest = "sql_task"
        elif key == "taskKey":
            suggest = "task_key"
        elif key == "timeoutSeconds":
            suggest = "timeout_seconds"
        elif key == "webhookNotifications":
            suggest = "webhook_notifications"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in JobTask. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        JobTask.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        JobTask.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 compute_key: Optional[str] = None,
                 condition_task: Optional['outputs.JobTaskConditionTask'] = None,
                 dbt_task: Optional['outputs.JobTaskDbtTask'] = None,
                 depends_ons: Optional[Sequence['outputs.JobTaskDependsOn']] = None,
                 description: Optional[str] = None,
                 email_notifications: Optional['outputs.JobTaskEmailNotifications'] = None,
                 existing_cluster_id: Optional[str] = None,
                 for_each_task: Optional['outputs.JobTaskForEachTask'] = None,
                 health: Optional['outputs.JobTaskHealth'] = None,
                 job_cluster_key: Optional[str] = None,
                 libraries: Optional[Sequence['outputs.JobTaskLibrary']] = None,
                 max_retries: Optional[int] = None,
                 min_retry_interval_millis: Optional[int] = None,
                 new_cluster: Optional['outputs.JobTaskNewCluster'] = None,
                 notebook_task: Optional['outputs.JobTaskNotebookTask'] = None,
                 notification_settings: Optional['outputs.JobTaskNotificationSettings'] = None,
                 pipeline_task: Optional['outputs.JobTaskPipelineTask'] = None,
                 python_wheel_task: Optional['outputs.JobTaskPythonWheelTask'] = None,
                 retry_on_timeout: Optional[bool] = None,
                 run_if: Optional[str] = None,
                 run_job_task: Optional['outputs.JobTaskRunJobTask'] = None,
                 spark_jar_task: Optional['outputs.JobTaskSparkJarTask'] = None,
                 spark_python_task: Optional['outputs.JobTaskSparkPythonTask'] = None,
                 spark_submit_task: Optional['outputs.JobTaskSparkSubmitTask'] = None,
                 sql_task: Optional['outputs.JobTaskSqlTask'] = None,
                 task_key: Optional[str] = None,
                 timeout_seconds: Optional[int] = None,
                 webhook_notifications: Optional['outputs.JobTaskWebhookNotifications'] = None):
        """
        :param Sequence['JobTaskDependsOnArgs'] depends_ons: block specifying dependency(-ies) for a given task.
        :param str description: An optional description for the job. The maximum length is 1024 characters in UTF-8 encoding.
        :param 'JobTaskEmailNotificationsArgs' email_notifications: (List) An optional set of email addresses notified when this task begins, completes or fails. The default behavior is to not send any emails. This field is a block and is documented below.
        :param 'JobTaskHealthArgs' health: block described below that specifies health conditions for a given task.
        :param str job_cluster_key: Identifier that can be referenced in `task` block, so that cluster is shared between tasks
        :param Sequence['JobTaskLibraryArgs'] libraries: (Set) An optional list of libraries to be installed on the cluster that will execute the job. Please consult libraries section for Cluster resource.
        :param int max_retries: (Integer) An optional maximum number of times to retry an unsuccessful run. A run is considered to be unsuccessful if it completes with a `FAILED` or `INTERNAL_ERROR` lifecycle state. The value -1 means to retry indefinitely and the value 0 means to never retry. The default behavior is to never retry. A run can have the following lifecycle state: `PENDING`, `RUNNING`, `TERMINATING`, `TERMINATED`, `SKIPPED` or `INTERNAL_ERROR`.
        :param int min_retry_interval_millis: (Integer) An optional minimal interval in milliseconds between the start of the failed run and the subsequent retry run. The default behavior is that unsuccessful runs are immediately retried.
        :param 'JobTaskNewClusterArgs' new_cluster: Same set of parameters as for Cluster resource.
        :param 'JobTaskNotificationSettingsArgs' notification_settings: An optional block controlling the notification settings on the job level (described below).
        :param bool retry_on_timeout: (Bool) An optional policy to specify whether to retry a job when it times out. The default behavior is to not retry on timeout.
        :param str run_if: An optional value indicating the condition that determines whether the task should be run once its dependencies have been completed. When omitted, defaults to `ALL_SUCCESS`.
        :param str task_key: string specifying an unique key for a given task.
               * `*_task` - (Required) one of the specific task blocks described below:
        :param int timeout_seconds: (Integer) An optional timeout applied to each run of this job. The default behavior is to have no timeout.
        :param 'JobTaskWebhookNotificationsArgs' webhook_notifications: (List) An optional set of system destinations (for example, webhook destinations or Slack) to be notified when runs of this task begins, completes or fails. The default behavior is to not send any notifications. This field is a block and is documented below.
        """
        if compute_key is not None:
            pulumi.set(__self__, "compute_key", compute_key)
        if condition_task is not None:
            pulumi.set(__self__, "condition_task", condition_task)
        if dbt_task is not None:
            pulumi.set(__self__, "dbt_task", dbt_task)
        if depends_ons is not None:
            pulumi.set(__self__, "depends_ons", depends_ons)
        if description is not None:
            pulumi.set(__self__, "description", description)
        if email_notifications is not None:
            pulumi.set(__self__, "email_notifications", email_notifications)
        if existing_cluster_id is not None:
            pulumi.set(__self__, "existing_cluster_id", existing_cluster_id)
        if for_each_task is not None:
            pulumi.set(__self__, "for_each_task", for_each_task)
        if health is not None:
            pulumi.set(__self__, "health", health)
        if job_cluster_key is not None:
            pulumi.set(__self__, "job_cluster_key", job_cluster_key)
        if libraries is not None:
            pulumi.set(__self__, "libraries", libraries)
        if max_retries is not None:
            pulumi.set(__self__, "max_retries", max_retries)
        if min_retry_interval_millis is not None:
            pulumi.set(__self__, "min_retry_interval_millis", min_retry_interval_millis)
        if new_cluster is not None:
            pulumi.set(__self__, "new_cluster", new_cluster)
        if notebook_task is not None:
            pulumi.set(__self__, "notebook_task", notebook_task)
        if notification_settings is not None:
            pulumi.set(__self__, "notification_settings", notification_settings)
        if pipeline_task is not None:
            pulumi.set(__self__, "pipeline_task", pipeline_task)
        if python_wheel_task is not None:
            pulumi.set(__self__, "python_wheel_task", python_wheel_task)
        if retry_on_timeout is not None:
            pulumi.set(__self__, "retry_on_timeout", retry_on_timeout)
        if run_if is not None:
            pulumi.set(__self__, "run_if", run_if)
        if run_job_task is not None:
            pulumi.set(__self__, "run_job_task", run_job_task)
        if spark_jar_task is not None:
            pulumi.set(__self__, "spark_jar_task", spark_jar_task)
        if spark_python_task is not None:
            pulumi.set(__self__, "spark_python_task", spark_python_task)
        if spark_submit_task is not None:
            pulumi.set(__self__, "spark_submit_task", spark_submit_task)
        if sql_task is not None:
            pulumi.set(__self__, "sql_task", sql_task)
        if task_key is not None:
            pulumi.set(__self__, "task_key", task_key)
        if timeout_seconds is not None:
            pulumi.set(__self__, "timeout_seconds", timeout_seconds)
        if webhook_notifications is not None:
            pulumi.set(__self__, "webhook_notifications", webhook_notifications)

    @property
    @pulumi.getter(name="computeKey")
    def compute_key(self) -> Optional[str]:
        return pulumi.get(self, "compute_key")

    @property
    @pulumi.getter(name="conditionTask")
    def condition_task(self) -> Optional['outputs.JobTaskConditionTask']:
        return pulumi.get(self, "condition_task")

    @property
    @pulumi.getter(name="dbtTask")
    def dbt_task(self) -> Optional['outputs.JobTaskDbtTask']:
        return pulumi.get(self, "dbt_task")

    @property
    @pulumi.getter(name="dependsOns")
    def depends_ons(self) -> Optional[Sequence['outputs.JobTaskDependsOn']]:
        """
        block specifying dependency(-ies) for a given task.
        """
        return pulumi.get(self, "depends_ons")

    @property
    @pulumi.getter
    def description(self) -> Optional[str]:
        """
        An optional description for the job. The maximum length is 1024 characters in UTF-8 encoding.
        """
        return pulumi.get(self, "description")

    @property
    @pulumi.getter(name="emailNotifications")
    def email_notifications(self) -> Optional['outputs.JobTaskEmailNotifications']:
        """
        (List) An optional set of email addresses notified when this task begins, completes or fails. The default behavior is to not send any emails. This field is a block and is documented below.
        """
        return pulumi.get(self, "email_notifications")

    @property
    @pulumi.getter(name="existingClusterId")
    def existing_cluster_id(self) -> Optional[str]:
        return pulumi.get(self, "existing_cluster_id")

    @property
    @pulumi.getter(name="forEachTask")
    def for_each_task(self) -> Optional['outputs.JobTaskForEachTask']:
        return pulumi.get(self, "for_each_task")

    @property
    @pulumi.getter
    def health(self) -> Optional['outputs.JobTaskHealth']:
        """
        block described below that specifies health conditions for a given task.
        """
        return pulumi.get(self, "health")

    @property
    @pulumi.getter(name="jobClusterKey")
    def job_cluster_key(self) -> Optional[str]:
        """
        Identifier that can be referenced in `task` block, so that cluster is shared between tasks
        """
        return pulumi.get(self, "job_cluster_key")

    @property
    @pulumi.getter
    def libraries(self) -> Optional[Sequence['outputs.JobTaskLibrary']]:
        """
        (Set) An optional list of libraries to be installed on the cluster that will execute the job. Please consult libraries section for Cluster resource.
        """
        return pulumi.get(self, "libraries")

    @property
    @pulumi.getter(name="maxRetries")
    def max_retries(self) -> Optional[int]:
        """
        (Integer) An optional maximum number of times to retry an unsuccessful run. A run is considered to be unsuccessful if it completes with a `FAILED` or `INTERNAL_ERROR` lifecycle state. The value -1 means to retry indefinitely and the value 0 means to never retry. The default behavior is to never retry. A run can have the following lifecycle state: `PENDING`, `RUNNING`, `TERMINATING`, `TERMINATED`, `SKIPPED` or `INTERNAL_ERROR`.
        """
        return pulumi.get(self, "max_retries")

    @property
    @pulumi.getter(name="minRetryIntervalMillis")
    def min_retry_interval_millis(self) -> Optional[int]:
        """
        (Integer) An optional minimal interval in milliseconds between the start of the failed run and the subsequent retry run. The default behavior is that unsuccessful runs are immediately retried.
        """
        return pulumi.get(self, "min_retry_interval_millis")

    @property
    @pulumi.getter(name="newCluster")
    def new_cluster(self) -> Optional['outputs.JobTaskNewCluster']:
        """
        Same set of parameters as for Cluster resource.
        """
        return pulumi.get(self, "new_cluster")

    @property
    @pulumi.getter(name="notebookTask")
    def notebook_task(self) -> Optional['outputs.JobTaskNotebookTask']:
        return pulumi.get(self, "notebook_task")

    @property
    @pulumi.getter(name="notificationSettings")
    def notification_settings(self) -> Optional['outputs.JobTaskNotificationSettings']:
        """
        An optional block controlling the notification settings on the job level (described below).
        """
        return pulumi.get(self, "notification_settings")

    @property
    @pulumi.getter(name="pipelineTask")
    def pipeline_task(self) -> Optional['outputs.JobTaskPipelineTask']:
        return pulumi.get(self, "pipeline_task")

    @property
    @pulumi.getter(name="pythonWheelTask")
    def python_wheel_task(self) -> Optional['outputs.JobTaskPythonWheelTask']:
        return pulumi.get(self, "python_wheel_task")

    @property
    @pulumi.getter(name="retryOnTimeout")
    def retry_on_timeout(self) -> Optional[bool]:
        """
        (Bool) An optional policy to specify whether to retry a job when it times out. The default behavior is to not retry on timeout.
        """
        return pulumi.get(self, "retry_on_timeout")

    @property
    @pulumi.getter(name="runIf")
    def run_if(self) -> Optional[str]:
        """
        An optional value indicating the condition that determines whether the task should be run once its dependencies have been completed. When omitted, defaults to `ALL_SUCCESS`.
        """
        return pulumi.get(self, "run_if")

    @property
    @pulumi.getter(name="runJobTask")
    def run_job_task(self) -> Optional['outputs.JobTaskRunJobTask']:
        return pulumi.get(self, "run_job_task")

    @property
    @pulumi.getter(name="sparkJarTask")
    def spark_jar_task(self) -> Optional['outputs.JobTaskSparkJarTask']:
        return pulumi.get(self, "spark_jar_task")

    @property
    @pulumi.getter(name="sparkPythonTask")
    def spark_python_task(self) -> Optional['outputs.JobTaskSparkPythonTask']:
        return pulumi.get(self, "spark_python_task")

    @property
    @pulumi.getter(name="sparkSubmitTask")
    def spark_submit_task(self) -> Optional['outputs.JobTaskSparkSubmitTask']:
        return pulumi.get(self, "spark_submit_task")

    @property
    @pulumi.getter(name="sqlTask")
    def sql_task(self) -> Optional['outputs.JobTaskSqlTask']:
        return pulumi.get(self, "sql_task")

    @property
    @pulumi.getter(name="taskKey")
    def task_key(self) -> Optional[str]:
        """
        string specifying an unique key for a given task.
        * `*_task` - (Required) one of the specific task blocks described below:
        """
        return pulumi.get(self, "task_key")

    @property
    @pulumi.getter(name="timeoutSeconds")
    def timeout_seconds(self) -> Optional[int]:
        """
        (Integer) An optional timeout applied to each run of this job. The default behavior is to have no timeout.
        """
        return pulumi.get(self, "timeout_seconds")

    @property
    @pulumi.getter(name="webhookNotifications")
    def webhook_notifications(self) -> Optional['outputs.JobTaskWebhookNotifications']:
        """
        (List) An optional set of system destinations (for example, webhook destinations or Slack) to be notified when runs of this task begins, completes or fails. The default behavior is to not send any notifications. This field is a block and is documented below.
        """
        return pulumi.get(self, "webhook_notifications")


@pulumi.output_type
class JobTaskConditionTask(dict):
    def __init__(__self__, *,
                 left: Optional[str] = None,
                 op: Optional[str] = None,
                 right: Optional[str] = None):
        """
        :param str left: The left operand of the condition task. It could be a string value, job state, or a parameter reference.
        :param str op: The string specifying the operation used to compare operands.  Currently, following operators are supported: `EQUAL_TO`, `GREATER_THAN`, `GREATER_THAN_OR_EQUAL`, `LESS_THAN`, `LESS_THAN_OR_EQUAL`, `NOT_EQUAL`. (Check the [API docs](https://docs.databricks.com/api/workspace/jobs/create) for the latest information).
               
               This task does not require a cluster to execute and does not support retries or notifications.
        :param str right: The right operand of the condition task. It could be a string value, job state, or parameter reference.
        """
        if left is not None:
            pulumi.set(__self__, "left", left)
        if op is not None:
            pulumi.set(__self__, "op", op)
        if right is not None:
            pulumi.set(__self__, "right", right)

    @property
    @pulumi.getter
    def left(self) -> Optional[str]:
        """
        The left operand of the condition task. It could be a string value, job state, or a parameter reference.
        """
        return pulumi.get(self, "left")

    @property
    @pulumi.getter
    def op(self) -> Optional[str]:
        """
        The string specifying the operation used to compare operands.  Currently, following operators are supported: `EQUAL_TO`, `GREATER_THAN`, `GREATER_THAN_OR_EQUAL`, `LESS_THAN`, `LESS_THAN_OR_EQUAL`, `NOT_EQUAL`. (Check the [API docs](https://docs.databricks.com/api/workspace/jobs/create) for the latest information).

        This task does not require a cluster to execute and does not support retries or notifications.
        """
        return pulumi.get(self, "op")

    @property
    @pulumi.getter
    def right(self) -> Optional[str]:
        """
        The right operand of the condition task. It could be a string value, job state, or parameter reference.
        """
        return pulumi.get(self, "right")


@pulumi.output_type
class JobTaskDbtTask(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "profilesDirectory":
            suggest = "profiles_directory"
        elif key == "projectDirectory":
            suggest = "project_directory"
        elif key == "warehouseId":
            suggest = "warehouse_id"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in JobTaskDbtTask. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        JobTaskDbtTask.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        JobTaskDbtTask.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 commands: Sequence[str],
                 catalog: Optional[str] = None,
                 profiles_directory: Optional[str] = None,
                 project_directory: Optional[str] = None,
                 schema: Optional[str] = None,
                 source: Optional[str] = None,
                 warehouse_id: Optional[str] = None):
        """
        :param Sequence[str] commands: (Array) Series of dbt commands to execute in sequence. Every command must start with "dbt".
        :param str catalog: The name of the catalog to use inside Unity Catalog.
        :param str profiles_directory: The relative path to the directory in the repository specified by `git_source` where dbt should look in for the `profiles.yml` file. If not specified, defaults to the repository's root directory. Equivalent to passing `--profile-dir` to a dbt command.
        :param str project_directory: The path where dbt should look for `dbt_project.yml`. Equivalent to passing `--project-dir` to the dbt CLI.
               * If `source` is `GIT`: Relative path to the directory in the repository specified in the `git_source` block. Defaults to the repository's root directory when not specified.
               * If `source` is `WORKSPACE`: Absolute path to the folder in the workspace.
        :param str schema: The name of the schema dbt should run in. Defaults to `default`.
        :param str source: The source of the project. Possible values are `WORKSPACE` and `GIT`.  Defaults to `GIT` if a `git_source` block is present in the job definition.
        :param str warehouse_id: The ID of the SQL warehouse that dbt should execute against.
               
               You also need to include a `git_source` block to configure the repository that contains the dbt project.
        """
        pulumi.set(__self__, "commands", commands)
        if catalog is not None:
            pulumi.set(__self__, "catalog", catalog)
        if profiles_directory is not None:
            pulumi.set(__self__, "profiles_directory", profiles_directory)
        if project_directory is not None:
            pulumi.set(__self__, "project_directory", project_directory)
        if schema is not None:
            pulumi.set(__self__, "schema", schema)
        if source is not None:
            pulumi.set(__self__, "source", source)
        if warehouse_id is not None:
            pulumi.set(__self__, "warehouse_id", warehouse_id)

    @property
    @pulumi.getter
    def commands(self) -> Sequence[str]:
        """
        (Array) Series of dbt commands to execute in sequence. Every command must start with "dbt".
        """
        return pulumi.get(self, "commands")

    @property
    @pulumi.getter
    def catalog(self) -> Optional[str]:
        """
        The name of the catalog to use inside Unity Catalog.
        """
        return pulumi.get(self, "catalog")

    @property
    @pulumi.getter(name="profilesDirectory")
    def profiles_directory(self) -> Optional[str]:
        """
        The relative path to the directory in the repository specified by `git_source` where dbt should look in for the `profiles.yml` file. If not specified, defaults to the repository's root directory. Equivalent to passing `--profile-dir` to a dbt command.
        """
        return pulumi.get(self, "profiles_directory")

    @property
    @pulumi.getter(name="projectDirectory")
    def project_directory(self) -> Optional[str]:
        """
        The path where dbt should look for `dbt_project.yml`. Equivalent to passing `--project-dir` to the dbt CLI.
        * If `source` is `GIT`: Relative path to the directory in the repository specified in the `git_source` block. Defaults to the repository's root directory when not specified.
        * If `source` is `WORKSPACE`: Absolute path to the folder in the workspace.
        """
        return pulumi.get(self, "project_directory")

    @property
    @pulumi.getter
    def schema(self) -> Optional[str]:
        """
        The name of the schema dbt should run in. Defaults to `default`.
        """
        return pulumi.get(self, "schema")

    @property
    @pulumi.getter
    def source(self) -> Optional[str]:
        """
        The source of the project. Possible values are `WORKSPACE` and `GIT`.  Defaults to `GIT` if a `git_source` block is present in the job definition.
        """
        return pulumi.get(self, "source")

    @property
    @pulumi.getter(name="warehouseId")
    def warehouse_id(self) -> Optional[str]:
        """
        The ID of the SQL warehouse that dbt should execute against.

        You also need to include a `git_source` block to configure the repository that contains the dbt project.
        """
        return pulumi.get(self, "warehouse_id")


@pulumi.output_type
class JobTaskDependsOn(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "taskKey":
            suggest = "task_key"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in JobTaskDependsOn. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        JobTaskDependsOn.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        JobTaskDependsOn.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 task_key: str,
                 outcome: Optional[str] = None):
        """
        :param str task_key: The name of the task this task depends on.
        :param str outcome: Can only be specified on condition task dependencies. The outcome of the dependent task that must be met for this task to run. Possible values are `"true"` or `"false"`.
        """
        pulumi.set(__self__, "task_key", task_key)
        if outcome is not None:
            pulumi.set(__self__, "outcome", outcome)

    @property
    @pulumi.getter(name="taskKey")
    def task_key(self) -> str:
        """
        The name of the task this task depends on.
        """
        return pulumi.get(self, "task_key")

    @property
    @pulumi.getter
    def outcome(self) -> Optional[str]:
        """
        Can only be specified on condition task dependencies. The outcome of the dependent task that must be met for this task to run. Possible values are `"true"` or `"false"`.
        """
        return pulumi.get(self, "outcome")


@pulumi.output_type
class JobTaskEmailNotifications(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "onDurationWarningThresholdExceededs":
            suggest = "on_duration_warning_threshold_exceededs"
        elif key == "onFailures":
            suggest = "on_failures"
        elif key == "onStarts":
            suggest = "on_starts"
        elif key == "onSuccesses":
            suggest = "on_successes"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in JobTaskEmailNotifications. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        JobTaskEmailNotifications.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        JobTaskEmailNotifications.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 on_duration_warning_threshold_exceededs: Optional[Sequence[str]] = None,
                 on_failures: Optional[Sequence[str]] = None,
                 on_starts: Optional[Sequence[str]] = None,
                 on_successes: Optional[Sequence[str]] = None):
        """
        :param Sequence[str] on_duration_warning_threshold_exceededs: (List) list of emails to notify when the duration of a run exceeds the threshold specified by the `RUN_DURATION_SECONDS` metric in the `health` block.
        :param Sequence[str] on_failures: (List) list of emails to notify when the run fails.
        :param Sequence[str] on_starts: (List) list of emails to notify when the run starts.
        :param Sequence[str] on_successes: (List) list of emails to notify when the run completes successfully.
        """
        if on_duration_warning_threshold_exceededs is not None:
            pulumi.set(__self__, "on_duration_warning_threshold_exceededs", on_duration_warning_threshold_exceededs)
        if on_failures is not None:
            pulumi.set(__self__, "on_failures", on_failures)
        if on_starts is not None:
            pulumi.set(__self__, "on_starts", on_starts)
        if on_successes is not None:
            pulumi.set(__self__, "on_successes", on_successes)

    @property
    @pulumi.getter(name="onDurationWarningThresholdExceededs")
    def on_duration_warning_threshold_exceededs(self) -> Optional[Sequence[str]]:
        """
        (List) list of emails to notify when the duration of a run exceeds the threshold specified by the `RUN_DURATION_SECONDS` metric in the `health` block.
        """
        return pulumi.get(self, "on_duration_warning_threshold_exceededs")

    @property
    @pulumi.getter(name="onFailures")
    def on_failures(self) -> Optional[Sequence[str]]:
        """
        (List) list of emails to notify when the run fails.
        """
        return pulumi.get(self, "on_failures")

    @property
    @pulumi.getter(name="onStarts")
    def on_starts(self) -> Optional[Sequence[str]]:
        """
        (List) list of emails to notify when the run starts.
        """
        return pulumi.get(self, "on_starts")

    @property
    @pulumi.getter(name="onSuccesses")
    def on_successes(self) -> Optional[Sequence[str]]:
        """
        (List) list of emails to notify when the run completes successfully.
        """
        return pulumi.get(self, "on_successes")


@pulumi.output_type
class JobTaskForEachTask(dict):
    def __init__(__self__, *,
                 inputs: str,
                 task: 'outputs.JobTaskForEachTaskTask',
                 concurrency: Optional[int] = None):
        """
        :param str inputs: (String) Array for task to iterate on. This can be a JSON string or a reference to an array parameter.
        :param 'JobTaskForEachTaskTaskArgs' task: Task to run against the `inputs` list.
        :param int concurrency: Controls the number of active iteration task runs. Default is 20, maximum allowed is 100.
        """
        pulumi.set(__self__, "inputs", inputs)
        pulumi.set(__self__, "task", task)
        if concurrency is not None:
            pulumi.set(__self__, "concurrency", concurrency)

    @property
    @pulumi.getter
    def inputs(self) -> str:
        """
        (String) Array for task to iterate on. This can be a JSON string or a reference to an array parameter.
        """
        return pulumi.get(self, "inputs")

    @property
    @pulumi.getter
    def task(self) -> 'outputs.JobTaskForEachTaskTask':
        """
        Task to run against the `inputs` list.
        """
        return pulumi.get(self, "task")

    @property
    @pulumi.getter
    def concurrency(self) -> Optional[int]:
        """
        Controls the number of active iteration task runs. Default is 20, maximum allowed is 100.
        """
        return pulumi.get(self, "concurrency")


@pulumi.output_type
class JobTaskForEachTaskTask(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "computeKey":
            suggest = "compute_key"
        elif key == "conditionTask":
            suggest = "condition_task"
        elif key == "dbtTask":
            suggest = "dbt_task"
        elif key == "dependsOns":
            suggest = "depends_ons"
        elif key == "emailNotifications":
            suggest = "email_notifications"
        elif key == "existingClusterId":
            suggest = "existing_cluster_id"
        elif key == "jobClusterKey":
            suggest = "job_cluster_key"
        elif key == "maxRetries":
            suggest = "max_retries"
        elif key == "minRetryIntervalMillis":
            suggest = "min_retry_interval_millis"
        elif key == "newCluster":
            suggest = "new_cluster"
        elif key == "notebookTask":
            suggest = "notebook_task"
        elif key == "notificationSettings":
            suggest = "notification_settings"
        elif key == "pipelineTask":
            suggest = "pipeline_task"
        elif key == "pythonWheelTask":
            suggest = "python_wheel_task"
        elif key == "retryOnTimeout":
            suggest = "retry_on_timeout"
        elif key == "runIf":
            suggest = "run_if"
        elif key == "runJobTask":
            suggest = "run_job_task"
        elif key == "sparkJarTask":
            suggest = "spark_jar_task"
        elif key == "sparkPythonTask":
            suggest = "spark_python_task"
        elif key == "sparkSubmitTask":
            suggest = "spark_submit_task"
        elif key == "sqlTask":
            suggest = "sql_task"
        elif key == "taskKey":
            suggest = "task_key"
        elif key == "timeoutSeconds":
            suggest = "timeout_seconds"
        elif key == "webhookNotifications":
            suggest = "webhook_notifications"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in JobTaskForEachTaskTask. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        JobTaskForEachTaskTask.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        JobTaskForEachTaskTask.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 compute_key: Optional[str] = None,
                 condition_task: Optional['outputs.JobTaskForEachTaskTaskConditionTask'] = None,
                 dbt_task: Optional['outputs.JobTaskForEachTaskTaskDbtTask'] = None,
                 depends_ons: Optional[Sequence['outputs.JobTaskForEachTaskTaskDependsOn']] = None,
                 description: Optional[str] = None,
                 email_notifications: Optional['outputs.JobTaskForEachTaskTaskEmailNotifications'] = None,
                 existing_cluster_id: Optional[str] = None,
                 health: Optional['outputs.JobTaskForEachTaskTaskHealth'] = None,
                 job_cluster_key: Optional[str] = None,
                 libraries: Optional[Sequence['outputs.JobTaskForEachTaskTaskLibrary']] = None,
                 max_retries: Optional[int] = None,
                 min_retry_interval_millis: Optional[int] = None,
                 new_cluster: Optional['outputs.JobTaskForEachTaskTaskNewCluster'] = None,
                 notebook_task: Optional['outputs.JobTaskForEachTaskTaskNotebookTask'] = None,
                 notification_settings: Optional['outputs.JobTaskForEachTaskTaskNotificationSettings'] = None,
                 pipeline_task: Optional['outputs.JobTaskForEachTaskTaskPipelineTask'] = None,
                 python_wheel_task: Optional['outputs.JobTaskForEachTaskTaskPythonWheelTask'] = None,
                 retry_on_timeout: Optional[bool] = None,
                 run_if: Optional[str] = None,
                 run_job_task: Optional['outputs.JobTaskForEachTaskTaskRunJobTask'] = None,
                 spark_jar_task: Optional['outputs.JobTaskForEachTaskTaskSparkJarTask'] = None,
                 spark_python_task: Optional['outputs.JobTaskForEachTaskTaskSparkPythonTask'] = None,
                 spark_submit_task: Optional['outputs.JobTaskForEachTaskTaskSparkSubmitTask'] = None,
                 sql_task: Optional['outputs.JobTaskForEachTaskTaskSqlTask'] = None,
                 task_key: Optional[str] = None,
                 timeout_seconds: Optional[int] = None,
                 webhook_notifications: Optional['outputs.JobTaskForEachTaskTaskWebhookNotifications'] = None):
        """
        :param Sequence['JobTaskForEachTaskTaskDependsOnArgs'] depends_ons: block specifying dependency(-ies) for a given task.
        :param str description: An optional description for the job. The maximum length is 1024 characters in UTF-8 encoding.
        :param 'JobTaskForEachTaskTaskEmailNotificationsArgs' email_notifications: (List) An optional set of email addresses notified when this task begins, completes or fails. The default behavior is to not send any emails. This field is a block and is documented below.
        :param 'JobTaskForEachTaskTaskHealthArgs' health: block described below that specifies health conditions for a given task.
        :param str job_cluster_key: Identifier that can be referenced in `task` block, so that cluster is shared between tasks
        :param Sequence['JobTaskForEachTaskTaskLibraryArgs'] libraries: (Set) An optional list of libraries to be installed on the cluster that will execute the job. Please consult libraries section for Cluster resource.
        :param int max_retries: (Integer) An optional maximum number of times to retry an unsuccessful run. A run is considered to be unsuccessful if it completes with a `FAILED` or `INTERNAL_ERROR` lifecycle state. The value -1 means to retry indefinitely and the value 0 means to never retry. The default behavior is to never retry. A run can have the following lifecycle state: `PENDING`, `RUNNING`, `TERMINATING`, `TERMINATED`, `SKIPPED` or `INTERNAL_ERROR`.
        :param int min_retry_interval_millis: (Integer) An optional minimal interval in milliseconds between the start of the failed run and the subsequent retry run. The default behavior is that unsuccessful runs are immediately retried.
        :param 'JobTaskForEachTaskTaskNewClusterArgs' new_cluster: Same set of parameters as for Cluster resource.
        :param 'JobTaskForEachTaskTaskNotificationSettingsArgs' notification_settings: An optional block controlling the notification settings on the job level (described below).
        :param bool retry_on_timeout: (Bool) An optional policy to specify whether to retry a job when it times out. The default behavior is to not retry on timeout.
        :param str run_if: An optional value indicating the condition that determines whether the task should be run once its dependencies have been completed. When omitted, defaults to `ALL_SUCCESS`.
        :param str task_key: string specifying an unique key for a given task.
               * `*_task` - (Required) one of the specific task blocks described below:
        :param int timeout_seconds: (Integer) An optional timeout applied to each run of this job. The default behavior is to have no timeout.
        :param 'JobTaskForEachTaskTaskWebhookNotificationsArgs' webhook_notifications: (List) An optional set of system destinations (for example, webhook destinations or Slack) to be notified when runs of this task begins, completes or fails. The default behavior is to not send any notifications. This field is a block and is documented below.
        """
        if compute_key is not None:
            pulumi.set(__self__, "compute_key", compute_key)
        if condition_task is not None:
            pulumi.set(__self__, "condition_task", condition_task)
        if dbt_task is not None:
            pulumi.set(__self__, "dbt_task", dbt_task)
        if depends_ons is not None:
            pulumi.set(__self__, "depends_ons", depends_ons)
        if description is not None:
            pulumi.set(__self__, "description", description)
        if email_notifications is not None:
            pulumi.set(__self__, "email_notifications", email_notifications)
        if existing_cluster_id is not None:
            pulumi.set(__self__, "existing_cluster_id", existing_cluster_id)
        if health is not None:
            pulumi.set(__self__, "health", health)
        if job_cluster_key is not None:
            pulumi.set(__self__, "job_cluster_key", job_cluster_key)
        if libraries is not None:
            pulumi.set(__self__, "libraries", libraries)
        if max_retries is not None:
            pulumi.set(__self__, "max_retries", max_retries)
        if min_retry_interval_millis is not None:
            pulumi.set(__self__, "min_retry_interval_millis", min_retry_interval_millis)
        if new_cluster is not None:
            pulumi.set(__self__, "new_cluster", new_cluster)
        if notebook_task is not None:
            pulumi.set(__self__, "notebook_task", notebook_task)
        if notification_settings is not None:
            pulumi.set(__self__, "notification_settings", notification_settings)
        if pipeline_task is not None:
            pulumi.set(__self__, "pipeline_task", pipeline_task)
        if python_wheel_task is not None:
            pulumi.set(__self__, "python_wheel_task", python_wheel_task)
        if retry_on_timeout is not None:
            pulumi.set(__self__, "retry_on_timeout", retry_on_timeout)
        if run_if is not None:
            pulumi.set(__self__, "run_if", run_if)
        if run_job_task is not None:
            pulumi.set(__self__, "run_job_task", run_job_task)
        if spark_jar_task is not None:
            pulumi.set(__self__, "spark_jar_task", spark_jar_task)
        if spark_python_task is not None:
            pulumi.set(__self__, "spark_python_task", spark_python_task)
        if spark_submit_task is not None:
            pulumi.set(__self__, "spark_submit_task", spark_submit_task)
        if sql_task is not None:
            pulumi.set(__self__, "sql_task", sql_task)
        if task_key is not None:
            pulumi.set(__self__, "task_key", task_key)
        if timeout_seconds is not None:
            pulumi.set(__self__, "timeout_seconds", timeout_seconds)
        if webhook_notifications is not None:
            pulumi.set(__self__, "webhook_notifications", webhook_notifications)

    @property
    @pulumi.getter(name="computeKey")
    def compute_key(self) -> Optional[str]:
        return pulumi.get(self, "compute_key")

    @property
    @pulumi.getter(name="conditionTask")
    def condition_task(self) -> Optional['outputs.JobTaskForEachTaskTaskConditionTask']:
        return pulumi.get(self, "condition_task")

    @property
    @pulumi.getter(name="dbtTask")
    def dbt_task(self) -> Optional['outputs.JobTaskForEachTaskTaskDbtTask']:
        return pulumi.get(self, "dbt_task")

    @property
    @pulumi.getter(name="dependsOns")
    def depends_ons(self) -> Optional[Sequence['outputs.JobTaskForEachTaskTaskDependsOn']]:
        """
        block specifying dependency(-ies) for a given task.
        """
        return pulumi.get(self, "depends_ons")

    @property
    @pulumi.getter
    def description(self) -> Optional[str]:
        """
        An optional description for the job. The maximum length is 1024 characters in UTF-8 encoding.
        """
        return pulumi.get(self, "description")

    @property
    @pulumi.getter(name="emailNotifications")
    def email_notifications(self) -> Optional['outputs.JobTaskForEachTaskTaskEmailNotifications']:
        """
        (List) An optional set of email addresses notified when this task begins, completes or fails. The default behavior is to not send any emails. This field is a block and is documented below.
        """
        return pulumi.get(self, "email_notifications")

    @property
    @pulumi.getter(name="existingClusterId")
    def existing_cluster_id(self) -> Optional[str]:
        return pulumi.get(self, "existing_cluster_id")

    @property
    @pulumi.getter
    def health(self) -> Optional['outputs.JobTaskForEachTaskTaskHealth']:
        """
        block described below that specifies health conditions for a given task.
        """
        return pulumi.get(self, "health")

    @property
    @pulumi.getter(name="jobClusterKey")
    def job_cluster_key(self) -> Optional[str]:
        """
        Identifier that can be referenced in `task` block, so that cluster is shared between tasks
        """
        return pulumi.get(self, "job_cluster_key")

    @property
    @pulumi.getter
    def libraries(self) -> Optional[Sequence['outputs.JobTaskForEachTaskTaskLibrary']]:
        """
        (Set) An optional list of libraries to be installed on the cluster that will execute the job. Please consult libraries section for Cluster resource.
        """
        return pulumi.get(self, "libraries")

    @property
    @pulumi.getter(name="maxRetries")
    def max_retries(self) -> Optional[int]:
        """
        (Integer) An optional maximum number of times to retry an unsuccessful run. A run is considered to be unsuccessful if it completes with a `FAILED` or `INTERNAL_ERROR` lifecycle state. The value -1 means to retry indefinitely and the value 0 means to never retry. The default behavior is to never retry. A run can have the following lifecycle state: `PENDING`, `RUNNING`, `TERMINATING`, `TERMINATED`, `SKIPPED` or `INTERNAL_ERROR`.
        """
        return pulumi.get(self, "max_retries")

    @property
    @pulumi.getter(name="minRetryIntervalMillis")
    def min_retry_interval_millis(self) -> Optional[int]:
        """
        (Integer) An optional minimal interval in milliseconds between the start of the failed run and the subsequent retry run. The default behavior is that unsuccessful runs are immediately retried.
        """
        return pulumi.get(self, "min_retry_interval_millis")

    @property
    @pulumi.getter(name="newCluster")
    def new_cluster(self) -> Optional['outputs.JobTaskForEachTaskTaskNewCluster']:
        """
        Same set of parameters as for Cluster resource.
        """
        return pulumi.get(self, "new_cluster")

    @property
    @pulumi.getter(name="notebookTask")
    def notebook_task(self) -> Optional['outputs.JobTaskForEachTaskTaskNotebookTask']:
        return pulumi.get(self, "notebook_task")

    @property
    @pulumi.getter(name="notificationSettings")
    def notification_settings(self) -> Optional['outputs.JobTaskForEachTaskTaskNotificationSettings']:
        """
        An optional block controlling the notification settings on the job level (described below).
        """
        return pulumi.get(self, "notification_settings")

    @property
    @pulumi.getter(name="pipelineTask")
    def pipeline_task(self) -> Optional['outputs.JobTaskForEachTaskTaskPipelineTask']:
        return pulumi.get(self, "pipeline_task")

    @property
    @pulumi.getter(name="pythonWheelTask")
    def python_wheel_task(self) -> Optional['outputs.JobTaskForEachTaskTaskPythonWheelTask']:
        return pulumi.get(self, "python_wheel_task")

    @property
    @pulumi.getter(name="retryOnTimeout")
    def retry_on_timeout(self) -> Optional[bool]:
        """
        (Bool) An optional policy to specify whether to retry a job when it times out. The default behavior is to not retry on timeout.
        """
        return pulumi.get(self, "retry_on_timeout")

    @property
    @pulumi.getter(name="runIf")
    def run_if(self) -> Optional[str]:
        """
        An optional value indicating the condition that determines whether the task should be run once its dependencies have been completed. When omitted, defaults to `ALL_SUCCESS`.
        """
        return pulumi.get(self, "run_if")

    @property
    @pulumi.getter(name="runJobTask")
    def run_job_task(self) -> Optional['outputs.JobTaskForEachTaskTaskRunJobTask']:
        return pulumi.get(self, "run_job_task")

    @property
    @pulumi.getter(name="sparkJarTask")
    def spark_jar_task(self) -> Optional['outputs.JobTaskForEachTaskTaskSparkJarTask']:
        return pulumi.get(self, "spark_jar_task")

    @property
    @pulumi.getter(name="sparkPythonTask")
    def spark_python_task(self) -> Optional['outputs.JobTaskForEachTaskTaskSparkPythonTask']:
        return pulumi.get(self, "spark_python_task")

    @property
    @pulumi.getter(name="sparkSubmitTask")
    def spark_submit_task(self) -> Optional['outputs.JobTaskForEachTaskTaskSparkSubmitTask']:
        return pulumi.get(self, "spark_submit_task")

    @property
    @pulumi.getter(name="sqlTask")
    def sql_task(self) -> Optional['outputs.JobTaskForEachTaskTaskSqlTask']:
        return pulumi.get(self, "sql_task")

    @property
    @pulumi.getter(name="taskKey")
    def task_key(self) -> Optional[str]:
        """
        string specifying an unique key for a given task.
        * `*_task` - (Required) one of the specific task blocks described below:
        """
        return pulumi.get(self, "task_key")

    @property
    @pulumi.getter(name="timeoutSeconds")
    def timeout_seconds(self) -> Optional[int]:
        """
        (Integer) An optional timeout applied to each run of this job. The default behavior is to have no timeout.
        """
        return pulumi.get(self, "timeout_seconds")

    @property
    @pulumi.getter(name="webhookNotifications")
    def webhook_notifications(self) -> Optional['outputs.JobTaskForEachTaskTaskWebhookNotifications']:
        """
        (List) An optional set of system destinations (for example, webhook destinations or Slack) to be notified when runs of this task begins, completes or fails. The default behavior is to not send any notifications. This field is a block and is documented below.
        """
        return pulumi.get(self, "webhook_notifications")


@pulumi.output_type
class JobTaskForEachTaskTaskConditionTask(dict):
    def __init__(__self__, *,
                 left: Optional[str] = None,
                 op: Optional[str] = None,
                 right: Optional[str] = None):
        """
        :param str left: The left operand of the condition task. It could be a string value, job state, or a parameter reference.
        :param str op: The string specifying the operation used to compare operands.  Currently, following operators are supported: `EQUAL_TO`, `GREATER_THAN`, `GREATER_THAN_OR_EQUAL`, `LESS_THAN`, `LESS_THAN_OR_EQUAL`, `NOT_EQUAL`. (Check the [API docs](https://docs.databricks.com/api/workspace/jobs/create) for the latest information).
               
               This task does not require a cluster to execute and does not support retries or notifications.
        :param str right: The right operand of the condition task. It could be a string value, job state, or parameter reference.
        """
        if left is not None:
            pulumi.set(__self__, "left", left)
        if op is not None:
            pulumi.set(__self__, "op", op)
        if right is not None:
            pulumi.set(__self__, "right", right)

    @property
    @pulumi.getter
    def left(self) -> Optional[str]:
        """
        The left operand of the condition task. It could be a string value, job state, or a parameter reference.
        """
        return pulumi.get(self, "left")

    @property
    @pulumi.getter
    def op(self) -> Optional[str]:
        """
        The string specifying the operation used to compare operands.  Currently, following operators are supported: `EQUAL_TO`, `GREATER_THAN`, `GREATER_THAN_OR_EQUAL`, `LESS_THAN`, `LESS_THAN_OR_EQUAL`, `NOT_EQUAL`. (Check the [API docs](https://docs.databricks.com/api/workspace/jobs/create) for the latest information).

        This task does not require a cluster to execute and does not support retries or notifications.
        """
        return pulumi.get(self, "op")

    @property
    @pulumi.getter
    def right(self) -> Optional[str]:
        """
        The right operand of the condition task. It could be a string value, job state, or parameter reference.
        """
        return pulumi.get(self, "right")


@pulumi.output_type
class JobTaskForEachTaskTaskDbtTask(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "profilesDirectory":
            suggest = "profiles_directory"
        elif key == "projectDirectory":
            suggest = "project_directory"
        elif key == "warehouseId":
            suggest = "warehouse_id"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in JobTaskForEachTaskTaskDbtTask. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        JobTaskForEachTaskTaskDbtTask.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        JobTaskForEachTaskTaskDbtTask.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 commands: Sequence[str],
                 catalog: Optional[str] = None,
                 profiles_directory: Optional[str] = None,
                 project_directory: Optional[str] = None,
                 schema: Optional[str] = None,
                 source: Optional[str] = None,
                 warehouse_id: Optional[str] = None):
        """
        :param Sequence[str] commands: (Array) Series of dbt commands to execute in sequence. Every command must start with "dbt".
        :param str catalog: The name of the catalog to use inside Unity Catalog.
        :param str profiles_directory: The relative path to the directory in the repository specified by `git_source` where dbt should look in for the `profiles.yml` file. If not specified, defaults to the repository's root directory. Equivalent to passing `--profile-dir` to a dbt command.
        :param str project_directory: The path where dbt should look for `dbt_project.yml`. Equivalent to passing `--project-dir` to the dbt CLI.
               * If `source` is `GIT`: Relative path to the directory in the repository specified in the `git_source` block. Defaults to the repository's root directory when not specified.
               * If `source` is `WORKSPACE`: Absolute path to the folder in the workspace.
        :param str schema: The name of the schema dbt should run in. Defaults to `default`.
        :param str source: The source of the project. Possible values are `WORKSPACE` and `GIT`.  Defaults to `GIT` if a `git_source` block is present in the job definition.
        :param str warehouse_id: The ID of the SQL warehouse that dbt should execute against.
               
               You also need to include a `git_source` block to configure the repository that contains the dbt project.
        """
        pulumi.set(__self__, "commands", commands)
        if catalog is not None:
            pulumi.set(__self__, "catalog", catalog)
        if profiles_directory is not None:
            pulumi.set(__self__, "profiles_directory", profiles_directory)
        if project_directory is not None:
            pulumi.set(__self__, "project_directory", project_directory)
        if schema is not None:
            pulumi.set(__self__, "schema", schema)
        if source is not None:
            pulumi.set(__self__, "source", source)
        if warehouse_id is not None:
            pulumi.set(__self__, "warehouse_id", warehouse_id)

    @property
    @pulumi.getter
    def commands(self) -> Sequence[str]:
        """
        (Array) Series of dbt commands to execute in sequence. Every command must start with "dbt".
        """
        return pulumi.get(self, "commands")

    @property
    @pulumi.getter
    def catalog(self) -> Optional[str]:
        """
        The name of the catalog to use inside Unity Catalog.
        """
        return pulumi.get(self, "catalog")

    @property
    @pulumi.getter(name="profilesDirectory")
    def profiles_directory(self) -> Optional[str]:
        """
        The relative path to the directory in the repository specified by `git_source` where dbt should look in for the `profiles.yml` file. If not specified, defaults to the repository's root directory. Equivalent to passing `--profile-dir` to a dbt command.
        """
        return pulumi.get(self, "profiles_directory")

    @property
    @pulumi.getter(name="projectDirectory")
    def project_directory(self) -> Optional[str]:
        """
        The path where dbt should look for `dbt_project.yml`. Equivalent to passing `--project-dir` to the dbt CLI.
        * If `source` is `GIT`: Relative path to the directory in the repository specified in the `git_source` block. Defaults to the repository's root directory when not specified.
        * If `source` is `WORKSPACE`: Absolute path to the folder in the workspace.
        """
        return pulumi.get(self, "project_directory")

    @property
    @pulumi.getter
    def schema(self) -> Optional[str]:
        """
        The name of the schema dbt should run in. Defaults to `default`.
        """
        return pulumi.get(self, "schema")

    @property
    @pulumi.getter
    def source(self) -> Optional[str]:
        """
        The source of the project. Possible values are `WORKSPACE` and `GIT`.  Defaults to `GIT` if a `git_source` block is present in the job definition.
        """
        return pulumi.get(self, "source")

    @property
    @pulumi.getter(name="warehouseId")
    def warehouse_id(self) -> Optional[str]:
        """
        The ID of the SQL warehouse that dbt should execute against.

        You also need to include a `git_source` block to configure the repository that contains the dbt project.
        """
        return pulumi.get(self, "warehouse_id")


@pulumi.output_type
class JobTaskForEachTaskTaskDependsOn(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "taskKey":
            suggest = "task_key"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in JobTaskForEachTaskTaskDependsOn. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        JobTaskForEachTaskTaskDependsOn.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        JobTaskForEachTaskTaskDependsOn.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 task_key: str,
                 outcome: Optional[str] = None):
        """
        :param str task_key: The name of the task this task depends on.
        :param str outcome: Can only be specified on condition task dependencies. The outcome of the dependent task that must be met for this task to run. Possible values are `"true"` or `"false"`.
        """
        pulumi.set(__self__, "task_key", task_key)
        if outcome is not None:
            pulumi.set(__self__, "outcome", outcome)

    @property
    @pulumi.getter(name="taskKey")
    def task_key(self) -> str:
        """
        The name of the task this task depends on.
        """
        return pulumi.get(self, "task_key")

    @property
    @pulumi.getter
    def outcome(self) -> Optional[str]:
        """
        Can only be specified on condition task dependencies. The outcome of the dependent task that must be met for this task to run. Possible values are `"true"` or `"false"`.
        """
        return pulumi.get(self, "outcome")


@pulumi.output_type
class JobTaskForEachTaskTaskEmailNotifications(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "onDurationWarningThresholdExceededs":
            suggest = "on_duration_warning_threshold_exceededs"
        elif key == "onFailures":
            suggest = "on_failures"
        elif key == "onStarts":
            suggest = "on_starts"
        elif key == "onSuccesses":
            suggest = "on_successes"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in JobTaskForEachTaskTaskEmailNotifications. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        JobTaskForEachTaskTaskEmailNotifications.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        JobTaskForEachTaskTaskEmailNotifications.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 on_duration_warning_threshold_exceededs: Optional[Sequence[str]] = None,
                 on_failures: Optional[Sequence[str]] = None,
                 on_starts: Optional[Sequence[str]] = None,
                 on_successes: Optional[Sequence[str]] = None):
        """
        :param Sequence[str] on_duration_warning_threshold_exceededs: (List) list of emails to notify when the duration of a run exceeds the threshold specified by the `RUN_DURATION_SECONDS` metric in the `health` block.
        :param Sequence[str] on_failures: (List) list of emails to notify when the run fails.
        :param Sequence[str] on_starts: (List) list of emails to notify when the run starts.
        :param Sequence[str] on_successes: (List) list of emails to notify when the run completes successfully.
        """
        if on_duration_warning_threshold_exceededs is not None:
            pulumi.set(__self__, "on_duration_warning_threshold_exceededs", on_duration_warning_threshold_exceededs)
        if on_failures is not None:
            pulumi.set(__self__, "on_failures", on_failures)
        if on_starts is not None:
            pulumi.set(__self__, "on_starts", on_starts)
        if on_successes is not None:
            pulumi.set(__self__, "on_successes", on_successes)

    @property
    @pulumi.getter(name="onDurationWarningThresholdExceededs")
    def on_duration_warning_threshold_exceededs(self) -> Optional[Sequence[str]]:
        """
        (List) list of emails to notify when the duration of a run exceeds the threshold specified by the `RUN_DURATION_SECONDS` metric in the `health` block.
        """
        return pulumi.get(self, "on_duration_warning_threshold_exceededs")

    @property
    @pulumi.getter(name="onFailures")
    def on_failures(self) -> Optional[Sequence[str]]:
        """
        (List) list of emails to notify when the run fails.
        """
        return pulumi.get(self, "on_failures")

    @property
    @pulumi.getter(name="onStarts")
    def on_starts(self) -> Optional[Sequence[str]]:
        """
        (List) list of emails to notify when the run starts.
        """
        return pulumi.get(self, "on_starts")

    @property
    @pulumi.getter(name="onSuccesses")
    def on_successes(self) -> Optional[Sequence[str]]:
        """
        (List) list of emails to notify when the run completes successfully.
        """
        return pulumi.get(self, "on_successes")


@pulumi.output_type
class JobTaskForEachTaskTaskHealth(dict):
    def __init__(__self__, *,
                 rules: Sequence['outputs.JobTaskForEachTaskTaskHealthRule']):
        """
        :param Sequence['JobTaskForEachTaskTaskHealthRuleArgs'] rules: list of rules that are represented as objects with the following attributes:
        """
        pulumi.set(__self__, "rules", rules)

    @property
    @pulumi.getter
    def rules(self) -> Sequence['outputs.JobTaskForEachTaskTaskHealthRule']:
        """
        list of rules that are represented as objects with the following attributes:
        """
        return pulumi.get(self, "rules")


@pulumi.output_type
class JobTaskForEachTaskTaskHealthRule(dict):
    def __init__(__self__, *,
                 metric: Optional[str] = None,
                 op: Optional[str] = None,
                 value: Optional[int] = None):
        """
        :param str metric: string specifying the metric to check.  The only supported metric is `RUN_DURATION_SECONDS` (check [Jobs REST API documentation](https://docs.databricks.com/api/workspace/jobs/create) for the latest information).
        :param str op: The string specifying the operation used to compare operands.  Currently, following operators are supported: `EQUAL_TO`, `GREATER_THAN`, `GREATER_THAN_OR_EQUAL`, `LESS_THAN`, `LESS_THAN_OR_EQUAL`, `NOT_EQUAL`. (Check the [API docs](https://docs.databricks.com/api/workspace/jobs/create) for the latest information).
               
               This task does not require a cluster to execute and does not support retries or notifications.
        :param int value: integer value used to compare to the given metric.
        """
        if metric is not None:
            pulumi.set(__self__, "metric", metric)
        if op is not None:
            pulumi.set(__self__, "op", op)
        if value is not None:
            pulumi.set(__self__, "value", value)

    @property
    @pulumi.getter
    def metric(self) -> Optional[str]:
        """
        string specifying the metric to check.  The only supported metric is `RUN_DURATION_SECONDS` (check [Jobs REST API documentation](https://docs.databricks.com/api/workspace/jobs/create) for the latest information).
        """
        return pulumi.get(self, "metric")

    @property
    @pulumi.getter
    def op(self) -> Optional[str]:
        """
        The string specifying the operation used to compare operands.  Currently, following operators are supported: `EQUAL_TO`, `GREATER_THAN`, `GREATER_THAN_OR_EQUAL`, `LESS_THAN`, `LESS_THAN_OR_EQUAL`, `NOT_EQUAL`. (Check the [API docs](https://docs.databricks.com/api/workspace/jobs/create) for the latest information).

        This task does not require a cluster to execute and does not support retries or notifications.
        """
        return pulumi.get(self, "op")

    @property
    @pulumi.getter
    def value(self) -> Optional[int]:
        """
        integer value used to compare to the given metric.
        """
        return pulumi.get(self, "value")


@pulumi.output_type
class JobTaskForEachTaskTaskLibrary(dict):
    def __init__(__self__, *,
                 cran: Optional['outputs.JobTaskForEachTaskTaskLibraryCran'] = None,
                 egg: Optional[str] = None,
                 jar: Optional[str] = None,
                 maven: Optional['outputs.JobTaskForEachTaskTaskLibraryMaven'] = None,
                 pypi: Optional['outputs.JobTaskForEachTaskTaskLibraryPypi'] = None,
                 whl: Optional[str] = None):
        if cran is not None:
            pulumi.set(__self__, "cran", cran)
        if egg is not None:
            pulumi.set(__self__, "egg", egg)
        if jar is not None:
            pulumi.set(__self__, "jar", jar)
        if maven is not None:
            pulumi.set(__self__, "maven", maven)
        if pypi is not None:
            pulumi.set(__self__, "pypi", pypi)
        if whl is not None:
            pulumi.set(__self__, "whl", whl)

    @property
    @pulumi.getter
    def cran(self) -> Optional['outputs.JobTaskForEachTaskTaskLibraryCran']:
        return pulumi.get(self, "cran")

    @property
    @pulumi.getter
    def egg(self) -> Optional[str]:
        return pulumi.get(self, "egg")

    @property
    @pulumi.getter
    def jar(self) -> Optional[str]:
        return pulumi.get(self, "jar")

    @property
    @pulumi.getter
    def maven(self) -> Optional['outputs.JobTaskForEachTaskTaskLibraryMaven']:
        return pulumi.get(self, "maven")

    @property
    @pulumi.getter
    def pypi(self) -> Optional['outputs.JobTaskForEachTaskTaskLibraryPypi']:
        return pulumi.get(self, "pypi")

    @property
    @pulumi.getter
    def whl(self) -> Optional[str]:
        return pulumi.get(self, "whl")


@pulumi.output_type
class JobTaskForEachTaskTaskLibraryCran(dict):
    def __init__(__self__, *,
                 package: str,
                 repo: Optional[str] = None):
        pulumi.set(__self__, "package", package)
        if repo is not None:
            pulumi.set(__self__, "repo", repo)

    @property
    @pulumi.getter
    def package(self) -> str:
        return pulumi.get(self, "package")

    @property
    @pulumi.getter
    def repo(self) -> Optional[str]:
        return pulumi.get(self, "repo")


@pulumi.output_type
class JobTaskForEachTaskTaskLibraryMaven(dict):
    def __init__(__self__, *,
                 coordinates: str,
                 exclusions: Optional[Sequence[str]] = None,
                 repo: Optional[str] = None):
        pulumi.set(__self__, "coordinates", coordinates)
        if exclusions is not None:
            pulumi.set(__self__, "exclusions", exclusions)
        if repo is not None:
            pulumi.set(__self__, "repo", repo)

    @property
    @pulumi.getter
    def coordinates(self) -> str:
        return pulumi.get(self, "coordinates")

    @property
    @pulumi.getter
    def exclusions(self) -> Optional[Sequence[str]]:
        return pulumi.get(self, "exclusions")

    @property
    @pulumi.getter
    def repo(self) -> Optional[str]:
        return pulumi.get(self, "repo")


@pulumi.output_type
class JobTaskForEachTaskTaskLibraryPypi(dict):
    def __init__(__self__, *,
                 package: str,
                 repo: Optional[str] = None):
        pulumi.set(__self__, "package", package)
        if repo is not None:
            pulumi.set(__self__, "repo", repo)

    @property
    @pulumi.getter
    def package(self) -> str:
        return pulumi.get(self, "package")

    @property
    @pulumi.getter
    def repo(self) -> Optional[str]:
        return pulumi.get(self, "repo")


@pulumi.output_type
class JobTaskForEachTaskTaskNewCluster(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "numWorkers":
            suggest = "num_workers"
        elif key == "sparkVersion":
            suggest = "spark_version"
        elif key == "applyPolicyDefaultValues":
            suggest = "apply_policy_default_values"
        elif key == "autoterminationMinutes":
            suggest = "autotermination_minutes"
        elif key == "awsAttributes":
            suggest = "aws_attributes"
        elif key == "azureAttributes":
            suggest = "azure_attributes"
        elif key == "clusterId":
            suggest = "cluster_id"
        elif key == "clusterLogConf":
            suggest = "cluster_log_conf"
        elif key == "clusterMountInfos":
            suggest = "cluster_mount_infos"
        elif key == "clusterName":
            suggest = "cluster_name"
        elif key == "customTags":
            suggest = "custom_tags"
        elif key == "dataSecurityMode":
            suggest = "data_security_mode"
        elif key == "dockerImage":
            suggest = "docker_image"
        elif key == "driverInstancePoolId":
            suggest = "driver_instance_pool_id"
        elif key == "driverNodeTypeId":
            suggest = "driver_node_type_id"
        elif key == "enableElasticDisk":
            suggest = "enable_elastic_disk"
        elif key == "enableLocalDiskEncryption":
            suggest = "enable_local_disk_encryption"
        elif key == "gcpAttributes":
            suggest = "gcp_attributes"
        elif key == "idempotencyToken":
            suggest = "idempotency_token"
        elif key == "initScripts":
            suggest = "init_scripts"
        elif key == "instancePoolId":
            suggest = "instance_pool_id"
        elif key == "nodeTypeId":
            suggest = "node_type_id"
        elif key == "policyId":
            suggest = "policy_id"
        elif key == "runtimeEngine":
            suggest = "runtime_engine"
        elif key == "singleUserName":
            suggest = "single_user_name"
        elif key == "sparkConf":
            suggest = "spark_conf"
        elif key == "sparkEnvVars":
            suggest = "spark_env_vars"
        elif key == "sshPublicKeys":
            suggest = "ssh_public_keys"
        elif key == "workloadType":
            suggest = "workload_type"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in JobTaskForEachTaskTaskNewCluster. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        JobTaskForEachTaskTaskNewCluster.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        JobTaskForEachTaskTaskNewCluster.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 num_workers: int,
                 spark_version: str,
                 apply_policy_default_values: Optional[bool] = None,
                 autoscale: Optional['outputs.JobTaskForEachTaskTaskNewClusterAutoscale'] = None,
                 autotermination_minutes: Optional[int] = None,
                 aws_attributes: Optional['outputs.JobTaskForEachTaskTaskNewClusterAwsAttributes'] = None,
                 azure_attributes: Optional['outputs.JobTaskForEachTaskTaskNewClusterAzureAttributes'] = None,
                 cluster_id: Optional[str] = None,
                 cluster_log_conf: Optional['outputs.JobTaskForEachTaskTaskNewClusterClusterLogConf'] = None,
                 cluster_mount_infos: Optional[Sequence['outputs.JobTaskForEachTaskTaskNewClusterClusterMountInfo']] = None,
                 cluster_name: Optional[str] = None,
                 custom_tags: Optional[Mapping[str, Any]] = None,
                 data_security_mode: Optional[str] = None,
                 docker_image: Optional['outputs.JobTaskForEachTaskTaskNewClusterDockerImage'] = None,
                 driver_instance_pool_id: Optional[str] = None,
                 driver_node_type_id: Optional[str] = None,
                 enable_elastic_disk: Optional[bool] = None,
                 enable_local_disk_encryption: Optional[bool] = None,
                 gcp_attributes: Optional['outputs.JobTaskForEachTaskTaskNewClusterGcpAttributes'] = None,
                 idempotency_token: Optional[str] = None,
                 init_scripts: Optional[Sequence['outputs.JobTaskForEachTaskTaskNewClusterInitScript']] = None,
                 instance_pool_id: Optional[str] = None,
                 node_type_id: Optional[str] = None,
                 policy_id: Optional[str] = None,
                 runtime_engine: Optional[str] = None,
                 single_user_name: Optional[str] = None,
                 spark_conf: Optional[Mapping[str, Any]] = None,
                 spark_env_vars: Optional[Mapping[str, Any]] = None,
                 ssh_public_keys: Optional[Sequence[str]] = None,
                 workload_type: Optional['outputs.JobTaskForEachTaskTaskNewClusterWorkloadType'] = None):
        pulumi.set(__self__, "num_workers", num_workers)
        pulumi.set(__self__, "spark_version", spark_version)
        if apply_policy_default_values is not None:
            pulumi.set(__self__, "apply_policy_default_values", apply_policy_default_values)
        if autoscale is not None:
            pulumi.set(__self__, "autoscale", autoscale)
        if autotermination_minutes is not None:
            pulumi.set(__self__, "autotermination_minutes", autotermination_minutes)
        if aws_attributes is not None:
            pulumi.set(__self__, "aws_attributes", aws_attributes)
        if azure_attributes is not None:
            pulumi.set(__self__, "azure_attributes", azure_attributes)
        if cluster_id is not None:
            pulumi.set(__self__, "cluster_id", cluster_id)
        if cluster_log_conf is not None:
            pulumi.set(__self__, "cluster_log_conf", cluster_log_conf)
        if cluster_mount_infos is not None:
            pulumi.set(__self__, "cluster_mount_infos", cluster_mount_infos)
        if cluster_name is not None:
            pulumi.set(__self__, "cluster_name", cluster_name)
        if custom_tags is not None:
            pulumi.set(__self__, "custom_tags", custom_tags)
        if data_security_mode is not None:
            pulumi.set(__self__, "data_security_mode", data_security_mode)
        if docker_image is not None:
            pulumi.set(__self__, "docker_image", docker_image)
        if driver_instance_pool_id is not None:
            pulumi.set(__self__, "driver_instance_pool_id", driver_instance_pool_id)
        if driver_node_type_id is not None:
            pulumi.set(__self__, "driver_node_type_id", driver_node_type_id)
        if enable_elastic_disk is not None:
            pulumi.set(__self__, "enable_elastic_disk", enable_elastic_disk)
        if enable_local_disk_encryption is not None:
            pulumi.set(__self__, "enable_local_disk_encryption", enable_local_disk_encryption)
        if gcp_attributes is not None:
            pulumi.set(__self__, "gcp_attributes", gcp_attributes)
        if idempotency_token is not None:
            pulumi.set(__self__, "idempotency_token", idempotency_token)
        if init_scripts is not None:
            pulumi.set(__self__, "init_scripts", init_scripts)
        if instance_pool_id is not None:
            pulumi.set(__self__, "instance_pool_id", instance_pool_id)
        if node_type_id is not None:
            pulumi.set(__self__, "node_type_id", node_type_id)
        if policy_id is not None:
            pulumi.set(__self__, "policy_id", policy_id)
        if runtime_engine is not None:
            pulumi.set(__self__, "runtime_engine", runtime_engine)
        if single_user_name is not None:
            pulumi.set(__self__, "single_user_name", single_user_name)
        if spark_conf is not None:
            pulumi.set(__self__, "spark_conf", spark_conf)
        if spark_env_vars is not None:
            pulumi.set(__self__, "spark_env_vars", spark_env_vars)
        if ssh_public_keys is not None:
            pulumi.set(__self__, "ssh_public_keys", ssh_public_keys)
        if workload_type is not None:
            pulumi.set(__self__, "workload_type", workload_type)

    @property
    @pulumi.getter(name="numWorkers")
    def num_workers(self) -> int:
        return pulumi.get(self, "num_workers")

    @property
    @pulumi.getter(name="sparkVersion")
    def spark_version(self) -> str:
        return pulumi.get(self, "spark_version")

    @property
    @pulumi.getter(name="applyPolicyDefaultValues")
    def apply_policy_default_values(self) -> Optional[bool]:
        return pulumi.get(self, "apply_policy_default_values")

    @property
    @pulumi.getter
    def autoscale(self) -> Optional['outputs.JobTaskForEachTaskTaskNewClusterAutoscale']:
        return pulumi.get(self, "autoscale")

    @property
    @pulumi.getter(name="autoterminationMinutes")
    def autotermination_minutes(self) -> Optional[int]:
        return pulumi.get(self, "autotermination_minutes")

    @property
    @pulumi.getter(name="awsAttributes")
    def aws_attributes(self) -> Optional['outputs.JobTaskForEachTaskTaskNewClusterAwsAttributes']:
        return pulumi.get(self, "aws_attributes")

    @property
    @pulumi.getter(name="azureAttributes")
    def azure_attributes(self) -> Optional['outputs.JobTaskForEachTaskTaskNewClusterAzureAttributes']:
        return pulumi.get(self, "azure_attributes")

    @property
    @pulumi.getter(name="clusterId")
    def cluster_id(self) -> Optional[str]:
        return pulumi.get(self, "cluster_id")

    @property
    @pulumi.getter(name="clusterLogConf")
    def cluster_log_conf(self) -> Optional['outputs.JobTaskForEachTaskTaskNewClusterClusterLogConf']:
        return pulumi.get(self, "cluster_log_conf")

    @property
    @pulumi.getter(name="clusterMountInfos")
    def cluster_mount_infos(self) -> Optional[Sequence['outputs.JobTaskForEachTaskTaskNewClusterClusterMountInfo']]:
        return pulumi.get(self, "cluster_mount_infos")

    @property
    @pulumi.getter(name="clusterName")
    def cluster_name(self) -> Optional[str]:
        return pulumi.get(self, "cluster_name")

    @property
    @pulumi.getter(name="customTags")
    def custom_tags(self) -> Optional[Mapping[str, Any]]:
        return pulumi.get(self, "custom_tags")

    @property
    @pulumi.getter(name="dataSecurityMode")
    def data_security_mode(self) -> Optional[str]:
        return pulumi.get(self, "data_security_mode")

    @property
    @pulumi.getter(name="dockerImage")
    def docker_image(self) -> Optional['outputs.JobTaskForEachTaskTaskNewClusterDockerImage']:
        return pulumi.get(self, "docker_image")

    @property
    @pulumi.getter(name="driverInstancePoolId")
    def driver_instance_pool_id(self) -> Optional[str]:
        return pulumi.get(self, "driver_instance_pool_id")

    @property
    @pulumi.getter(name="driverNodeTypeId")
    def driver_node_type_id(self) -> Optional[str]:
        return pulumi.get(self, "driver_node_type_id")

    @property
    @pulumi.getter(name="enableElasticDisk")
    def enable_elastic_disk(self) -> Optional[bool]:
        return pulumi.get(self, "enable_elastic_disk")

    @property
    @pulumi.getter(name="enableLocalDiskEncryption")
    def enable_local_disk_encryption(self) -> Optional[bool]:
        return pulumi.get(self, "enable_local_disk_encryption")

    @property
    @pulumi.getter(name="gcpAttributes")
    def gcp_attributes(self) -> Optional['outputs.JobTaskForEachTaskTaskNewClusterGcpAttributes']:
        return pulumi.get(self, "gcp_attributes")

    @property
    @pulumi.getter(name="idempotencyToken")
    def idempotency_token(self) -> Optional[str]:
        return pulumi.get(self, "idempotency_token")

    @property
    @pulumi.getter(name="initScripts")
    def init_scripts(self) -> Optional[Sequence['outputs.JobTaskForEachTaskTaskNewClusterInitScript']]:
        return pulumi.get(self, "init_scripts")

    @property
    @pulumi.getter(name="instancePoolId")
    def instance_pool_id(self) -> Optional[str]:
        return pulumi.get(self, "instance_pool_id")

    @property
    @pulumi.getter(name="nodeTypeId")
    def node_type_id(self) -> Optional[str]:
        return pulumi.get(self, "node_type_id")

    @property
    @pulumi.getter(name="policyId")
    def policy_id(self) -> Optional[str]:
        return pulumi.get(self, "policy_id")

    @property
    @pulumi.getter(name="runtimeEngine")
    def runtime_engine(self) -> Optional[str]:
        return pulumi.get(self, "runtime_engine")

    @property
    @pulumi.getter(name="singleUserName")
    def single_user_name(self) -> Optional[str]:
        return pulumi.get(self, "single_user_name")

    @property
    @pulumi.getter(name="sparkConf")
    def spark_conf(self) -> Optional[Mapping[str, Any]]:
        return pulumi.get(self, "spark_conf")

    @property
    @pulumi.getter(name="sparkEnvVars")
    def spark_env_vars(self) -> Optional[Mapping[str, Any]]:
        return pulumi.get(self, "spark_env_vars")

    @property
    @pulumi.getter(name="sshPublicKeys")
    def ssh_public_keys(self) -> Optional[Sequence[str]]:
        return pulumi.get(self, "ssh_public_keys")

    @property
    @pulumi.getter(name="workloadType")
    def workload_type(self) -> Optional['outputs.JobTaskForEachTaskTaskNewClusterWorkloadType']:
        return pulumi.get(self, "workload_type")


@pulumi.output_type
class JobTaskForEachTaskTaskNewClusterAutoscale(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "maxWorkers":
            suggest = "max_workers"
        elif key == "minWorkers":
            suggest = "min_workers"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in JobTaskForEachTaskTaskNewClusterAutoscale. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        JobTaskForEachTaskTaskNewClusterAutoscale.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        JobTaskForEachTaskTaskNewClusterAutoscale.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 max_workers: Optional[int] = None,
                 min_workers: Optional[int] = None):
        if max_workers is not None:
            pulumi.set(__self__, "max_workers", max_workers)
        if min_workers is not None:
            pulumi.set(__self__, "min_workers", min_workers)

    @property
    @pulumi.getter(name="maxWorkers")
    def max_workers(self) -> Optional[int]:
        return pulumi.get(self, "max_workers")

    @property
    @pulumi.getter(name="minWorkers")
    def min_workers(self) -> Optional[int]:
        return pulumi.get(self, "min_workers")


@pulumi.output_type
class JobTaskForEachTaskTaskNewClusterAwsAttributes(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "ebsVolumeCount":
            suggest = "ebs_volume_count"
        elif key == "ebsVolumeSize":
            suggest = "ebs_volume_size"
        elif key == "ebsVolumeType":
            suggest = "ebs_volume_type"
        elif key == "firstOnDemand":
            suggest = "first_on_demand"
        elif key == "instanceProfileArn":
            suggest = "instance_profile_arn"
        elif key == "spotBidPricePercent":
            suggest = "spot_bid_price_percent"
        elif key == "zoneId":
            suggest = "zone_id"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in JobTaskForEachTaskTaskNewClusterAwsAttributes. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        JobTaskForEachTaskTaskNewClusterAwsAttributes.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        JobTaskForEachTaskTaskNewClusterAwsAttributes.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 availability: Optional[str] = None,
                 ebs_volume_count: Optional[int] = None,
                 ebs_volume_size: Optional[int] = None,
                 ebs_volume_type: Optional[str] = None,
                 first_on_demand: Optional[int] = None,
                 instance_profile_arn: Optional[str] = None,
                 spot_bid_price_percent: Optional[int] = None,
                 zone_id: Optional[str] = None):
        if availability is not None:
            pulumi.set(__self__, "availability", availability)
        if ebs_volume_count is not None:
            pulumi.set(__self__, "ebs_volume_count", ebs_volume_count)
        if ebs_volume_size is not None:
            pulumi.set(__self__, "ebs_volume_size", ebs_volume_size)
        if ebs_volume_type is not None:
            pulumi.set(__self__, "ebs_volume_type", ebs_volume_type)
        if first_on_demand is not None:
            pulumi.set(__self__, "first_on_demand", first_on_demand)
        if instance_profile_arn is not None:
            pulumi.set(__self__, "instance_profile_arn", instance_profile_arn)
        if spot_bid_price_percent is not None:
            pulumi.set(__self__, "spot_bid_price_percent", spot_bid_price_percent)
        if zone_id is not None:
            pulumi.set(__self__, "zone_id", zone_id)

    @property
    @pulumi.getter
    def availability(self) -> Optional[str]:
        return pulumi.get(self, "availability")

    @property
    @pulumi.getter(name="ebsVolumeCount")
    def ebs_volume_count(self) -> Optional[int]:
        return pulumi.get(self, "ebs_volume_count")

    @property
    @pulumi.getter(name="ebsVolumeSize")
    def ebs_volume_size(self) -> Optional[int]:
        return pulumi.get(self, "ebs_volume_size")

    @property
    @pulumi.getter(name="ebsVolumeType")
    def ebs_volume_type(self) -> Optional[str]:
        return pulumi.get(self, "ebs_volume_type")

    @property
    @pulumi.getter(name="firstOnDemand")
    def first_on_demand(self) -> Optional[int]:
        return pulumi.get(self, "first_on_demand")

    @property
    @pulumi.getter(name="instanceProfileArn")
    def instance_profile_arn(self) -> Optional[str]:
        return pulumi.get(self, "instance_profile_arn")

    @property
    @pulumi.getter(name="spotBidPricePercent")
    def spot_bid_price_percent(self) -> Optional[int]:
        return pulumi.get(self, "spot_bid_price_percent")

    @property
    @pulumi.getter(name="zoneId")
    def zone_id(self) -> Optional[str]:
        return pulumi.get(self, "zone_id")


@pulumi.output_type
class JobTaskForEachTaskTaskNewClusterAzureAttributes(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "firstOnDemand":
            suggest = "first_on_demand"
        elif key == "spotBidMaxPrice":
            suggest = "spot_bid_max_price"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in JobTaskForEachTaskTaskNewClusterAzureAttributes. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        JobTaskForEachTaskTaskNewClusterAzureAttributes.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        JobTaskForEachTaskTaskNewClusterAzureAttributes.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 availability: Optional[str] = None,
                 first_on_demand: Optional[int] = None,
                 spot_bid_max_price: Optional[float] = None):
        if availability is not None:
            pulumi.set(__self__, "availability", availability)
        if first_on_demand is not None:
            pulumi.set(__self__, "first_on_demand", first_on_demand)
        if spot_bid_max_price is not None:
            pulumi.set(__self__, "spot_bid_max_price", spot_bid_max_price)

    @property
    @pulumi.getter
    def availability(self) -> Optional[str]:
        return pulumi.get(self, "availability")

    @property
    @pulumi.getter(name="firstOnDemand")
    def first_on_demand(self) -> Optional[int]:
        return pulumi.get(self, "first_on_demand")

    @property
    @pulumi.getter(name="spotBidMaxPrice")
    def spot_bid_max_price(self) -> Optional[float]:
        return pulumi.get(self, "spot_bid_max_price")


@pulumi.output_type
class JobTaskForEachTaskTaskNewClusterClusterLogConf(dict):
    def __init__(__self__, *,
                 dbfs: Optional['outputs.JobTaskForEachTaskTaskNewClusterClusterLogConfDbfs'] = None,
                 s3: Optional['outputs.JobTaskForEachTaskTaskNewClusterClusterLogConfS3'] = None):
        if dbfs is not None:
            pulumi.set(__self__, "dbfs", dbfs)
        if s3 is not None:
            pulumi.set(__self__, "s3", s3)

    @property
    @pulumi.getter
    def dbfs(self) -> Optional['outputs.JobTaskForEachTaskTaskNewClusterClusterLogConfDbfs']:
        return pulumi.get(self, "dbfs")

    @property
    @pulumi.getter
    def s3(self) -> Optional['outputs.JobTaskForEachTaskTaskNewClusterClusterLogConfS3']:
        return pulumi.get(self, "s3")


@pulumi.output_type
class JobTaskForEachTaskTaskNewClusterClusterLogConfDbfs(dict):
    def __init__(__self__, *,
                 destination: str):
        pulumi.set(__self__, "destination", destination)

    @property
    @pulumi.getter
    def destination(self) -> str:
        return pulumi.get(self, "destination")


@pulumi.output_type
class JobTaskForEachTaskTaskNewClusterClusterLogConfS3(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "cannedAcl":
            suggest = "canned_acl"
        elif key == "enableEncryption":
            suggest = "enable_encryption"
        elif key == "encryptionType":
            suggest = "encryption_type"
        elif key == "kmsKey":
            suggest = "kms_key"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in JobTaskForEachTaskTaskNewClusterClusterLogConfS3. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        JobTaskForEachTaskTaskNewClusterClusterLogConfS3.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        JobTaskForEachTaskTaskNewClusterClusterLogConfS3.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 destination: str,
                 canned_acl: Optional[str] = None,
                 enable_encryption: Optional[bool] = None,
                 encryption_type: Optional[str] = None,
                 endpoint: Optional[str] = None,
                 kms_key: Optional[str] = None,
                 region: Optional[str] = None):
        pulumi.set(__self__, "destination", destination)
        if canned_acl is not None:
            pulumi.set(__self__, "canned_acl", canned_acl)
        if enable_encryption is not None:
            pulumi.set(__self__, "enable_encryption", enable_encryption)
        if encryption_type is not None:
            pulumi.set(__self__, "encryption_type", encryption_type)
        if endpoint is not None:
            pulumi.set(__self__, "endpoint", endpoint)
        if kms_key is not None:
            pulumi.set(__self__, "kms_key", kms_key)
        if region is not None:
            pulumi.set(__self__, "region", region)

    @property
    @pulumi.getter
    def destination(self) -> str:
        return pulumi.get(self, "destination")

    @property
    @pulumi.getter(name="cannedAcl")
    def canned_acl(self) -> Optional[str]:
        return pulumi.get(self, "canned_acl")

    @property
    @pulumi.getter(name="enableEncryption")
    def enable_encryption(self) -> Optional[bool]:
        return pulumi.get(self, "enable_encryption")

    @property
    @pulumi.getter(name="encryptionType")
    def encryption_type(self) -> Optional[str]:
        return pulumi.get(self, "encryption_type")

    @property
    @pulumi.getter
    def endpoint(self) -> Optional[str]:
        return pulumi.get(self, "endpoint")

    @property
    @pulumi.getter(name="kmsKey")
    def kms_key(self) -> Optional[str]:
        return pulumi.get(self, "kms_key")

    @property
    @pulumi.getter
    def region(self) -> Optional[str]:
        return pulumi.get(self, "region")


@pulumi.output_type
class JobTaskForEachTaskTaskNewClusterClusterMountInfo(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "localMountDirPath":
            suggest = "local_mount_dir_path"
        elif key == "networkFilesystemInfo":
            suggest = "network_filesystem_info"
        elif key == "remoteMountDirPath":
            suggest = "remote_mount_dir_path"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in JobTaskForEachTaskTaskNewClusterClusterMountInfo. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        JobTaskForEachTaskTaskNewClusterClusterMountInfo.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        JobTaskForEachTaskTaskNewClusterClusterMountInfo.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 local_mount_dir_path: str,
                 network_filesystem_info: 'outputs.JobTaskForEachTaskTaskNewClusterClusterMountInfoNetworkFilesystemInfo',
                 remote_mount_dir_path: Optional[str] = None):
        pulumi.set(__self__, "local_mount_dir_path", local_mount_dir_path)
        pulumi.set(__self__, "network_filesystem_info", network_filesystem_info)
        if remote_mount_dir_path is not None:
            pulumi.set(__self__, "remote_mount_dir_path", remote_mount_dir_path)

    @property
    @pulumi.getter(name="localMountDirPath")
    def local_mount_dir_path(self) -> str:
        return pulumi.get(self, "local_mount_dir_path")

    @property
    @pulumi.getter(name="networkFilesystemInfo")
    def network_filesystem_info(self) -> 'outputs.JobTaskForEachTaskTaskNewClusterClusterMountInfoNetworkFilesystemInfo':
        return pulumi.get(self, "network_filesystem_info")

    @property
    @pulumi.getter(name="remoteMountDirPath")
    def remote_mount_dir_path(self) -> Optional[str]:
        return pulumi.get(self, "remote_mount_dir_path")


@pulumi.output_type
class JobTaskForEachTaskTaskNewClusterClusterMountInfoNetworkFilesystemInfo(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "serverAddress":
            suggest = "server_address"
        elif key == "mountOptions":
            suggest = "mount_options"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in JobTaskForEachTaskTaskNewClusterClusterMountInfoNetworkFilesystemInfo. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        JobTaskForEachTaskTaskNewClusterClusterMountInfoNetworkFilesystemInfo.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        JobTaskForEachTaskTaskNewClusterClusterMountInfoNetworkFilesystemInfo.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 server_address: str,
                 mount_options: Optional[str] = None):
        pulumi.set(__self__, "server_address", server_address)
        if mount_options is not None:
            pulumi.set(__self__, "mount_options", mount_options)

    @property
    @pulumi.getter(name="serverAddress")
    def server_address(self) -> str:
        return pulumi.get(self, "server_address")

    @property
    @pulumi.getter(name="mountOptions")
    def mount_options(self) -> Optional[str]:
        return pulumi.get(self, "mount_options")


@pulumi.output_type
class JobTaskForEachTaskTaskNewClusterDockerImage(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "basicAuth":
            suggest = "basic_auth"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in JobTaskForEachTaskTaskNewClusterDockerImage. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        JobTaskForEachTaskTaskNewClusterDockerImage.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        JobTaskForEachTaskTaskNewClusterDockerImage.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 url: str,
                 basic_auth: Optional['outputs.JobTaskForEachTaskTaskNewClusterDockerImageBasicAuth'] = None):
        """
        :param str url: URL of the Git repository to use.
        """
        pulumi.set(__self__, "url", url)
        if basic_auth is not None:
            pulumi.set(__self__, "basic_auth", basic_auth)

    @property
    @pulumi.getter
    def url(self) -> str:
        """
        URL of the Git repository to use.
        """
        return pulumi.get(self, "url")

    @property
    @pulumi.getter(name="basicAuth")
    def basic_auth(self) -> Optional['outputs.JobTaskForEachTaskTaskNewClusterDockerImageBasicAuth']:
        return pulumi.get(self, "basic_auth")


@pulumi.output_type
class JobTaskForEachTaskTaskNewClusterDockerImageBasicAuth(dict):
    def __init__(__self__, *,
                 password: str,
                 username: str):
        pulumi.set(__self__, "password", password)
        pulumi.set(__self__, "username", username)

    @property
    @pulumi.getter
    def password(self) -> str:
        return pulumi.get(self, "password")

    @property
    @pulumi.getter
    def username(self) -> str:
        return pulumi.get(self, "username")


@pulumi.output_type
class JobTaskForEachTaskTaskNewClusterGcpAttributes(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "bootDiskSize":
            suggest = "boot_disk_size"
        elif key == "googleServiceAccount":
            suggest = "google_service_account"
        elif key == "localSsdCount":
            suggest = "local_ssd_count"
        elif key == "usePreemptibleExecutors":
            suggest = "use_preemptible_executors"
        elif key == "zoneId":
            suggest = "zone_id"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in JobTaskForEachTaskTaskNewClusterGcpAttributes. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        JobTaskForEachTaskTaskNewClusterGcpAttributes.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        JobTaskForEachTaskTaskNewClusterGcpAttributes.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 availability: Optional[str] = None,
                 boot_disk_size: Optional[int] = None,
                 google_service_account: Optional[str] = None,
                 local_ssd_count: Optional[int] = None,
                 use_preemptible_executors: Optional[bool] = None,
                 zone_id: Optional[str] = None):
        if availability is not None:
            pulumi.set(__self__, "availability", availability)
        if boot_disk_size is not None:
            pulumi.set(__self__, "boot_disk_size", boot_disk_size)
        if google_service_account is not None:
            pulumi.set(__self__, "google_service_account", google_service_account)
        if local_ssd_count is not None:
            pulumi.set(__self__, "local_ssd_count", local_ssd_count)
        if use_preemptible_executors is not None:
            pulumi.set(__self__, "use_preemptible_executors", use_preemptible_executors)
        if zone_id is not None:
            pulumi.set(__self__, "zone_id", zone_id)

    @property
    @pulumi.getter
    def availability(self) -> Optional[str]:
        return pulumi.get(self, "availability")

    @property
    @pulumi.getter(name="bootDiskSize")
    def boot_disk_size(self) -> Optional[int]:
        return pulumi.get(self, "boot_disk_size")

    @property
    @pulumi.getter(name="googleServiceAccount")
    def google_service_account(self) -> Optional[str]:
        return pulumi.get(self, "google_service_account")

    @property
    @pulumi.getter(name="localSsdCount")
    def local_ssd_count(self) -> Optional[int]:
        return pulumi.get(self, "local_ssd_count")

    @property
    @pulumi.getter(name="usePreemptibleExecutors")
    def use_preemptible_executors(self) -> Optional[bool]:
        return pulumi.get(self, "use_preemptible_executors")

    @property
    @pulumi.getter(name="zoneId")
    def zone_id(self) -> Optional[str]:
        return pulumi.get(self, "zone_id")


@pulumi.output_type
class JobTaskForEachTaskTaskNewClusterInitScript(dict):
    def __init__(__self__, *,
                 abfss: Optional['outputs.JobTaskForEachTaskTaskNewClusterInitScriptAbfss'] = None,
                 dbfs: Optional['outputs.JobTaskForEachTaskTaskNewClusterInitScriptDbfs'] = None,
                 file: Optional['outputs.JobTaskForEachTaskTaskNewClusterInitScriptFile'] = None,
                 gcs: Optional['outputs.JobTaskForEachTaskTaskNewClusterInitScriptGcs'] = None,
                 s3: Optional['outputs.JobTaskForEachTaskTaskNewClusterInitScriptS3'] = None,
                 volumes: Optional['outputs.JobTaskForEachTaskTaskNewClusterInitScriptVolumes'] = None,
                 workspace: Optional['outputs.JobTaskForEachTaskTaskNewClusterInitScriptWorkspace'] = None):
        """
        :param 'JobTaskForEachTaskTaskNewClusterInitScriptFileArgs' file: block consisting of single string fields:
        """
        if abfss is not None:
            pulumi.set(__self__, "abfss", abfss)
        if dbfs is not None:
            pulumi.set(__self__, "dbfs", dbfs)
        if file is not None:
            pulumi.set(__self__, "file", file)
        if gcs is not None:
            pulumi.set(__self__, "gcs", gcs)
        if s3 is not None:
            pulumi.set(__self__, "s3", s3)
        if volumes is not None:
            pulumi.set(__self__, "volumes", volumes)
        if workspace is not None:
            pulumi.set(__self__, "workspace", workspace)

    @property
    @pulumi.getter
    def abfss(self) -> Optional['outputs.JobTaskForEachTaskTaskNewClusterInitScriptAbfss']:
        return pulumi.get(self, "abfss")

    @property
    @pulumi.getter
    def dbfs(self) -> Optional['outputs.JobTaskForEachTaskTaskNewClusterInitScriptDbfs']:
        return pulumi.get(self, "dbfs")

    @property
    @pulumi.getter
    def file(self) -> Optional['outputs.JobTaskForEachTaskTaskNewClusterInitScriptFile']:
        """
        block consisting of single string fields:
        """
        return pulumi.get(self, "file")

    @property
    @pulumi.getter
    def gcs(self) -> Optional['outputs.JobTaskForEachTaskTaskNewClusterInitScriptGcs']:
        return pulumi.get(self, "gcs")

    @property
    @pulumi.getter
    def s3(self) -> Optional['outputs.JobTaskForEachTaskTaskNewClusterInitScriptS3']:
        return pulumi.get(self, "s3")

    @property
    @pulumi.getter
    def volumes(self) -> Optional['outputs.JobTaskForEachTaskTaskNewClusterInitScriptVolumes']:
        return pulumi.get(self, "volumes")

    @property
    @pulumi.getter
    def workspace(self) -> Optional['outputs.JobTaskForEachTaskTaskNewClusterInitScriptWorkspace']:
        return pulumi.get(self, "workspace")


@pulumi.output_type
class JobTaskForEachTaskTaskNewClusterInitScriptAbfss(dict):
    def __init__(__self__, *,
                 destination: str):
        pulumi.set(__self__, "destination", destination)

    @property
    @pulumi.getter
    def destination(self) -> str:
        return pulumi.get(self, "destination")


@pulumi.output_type
class JobTaskForEachTaskTaskNewClusterInitScriptDbfs(dict):
    def __init__(__self__, *,
                 destination: str):
        pulumi.set(__self__, "destination", destination)

    @property
    @pulumi.getter
    def destination(self) -> str:
        return pulumi.get(self, "destination")


@pulumi.output_type
class JobTaskForEachTaskTaskNewClusterInitScriptFile(dict):
    def __init__(__self__, *,
                 destination: str):
        pulumi.set(__self__, "destination", destination)

    @property
    @pulumi.getter
    def destination(self) -> str:
        return pulumi.get(self, "destination")


@pulumi.output_type
class JobTaskForEachTaskTaskNewClusterInitScriptGcs(dict):
    def __init__(__self__, *,
                 destination: str):
        pulumi.set(__self__, "destination", destination)

    @property
    @pulumi.getter
    def destination(self) -> str:
        return pulumi.get(self, "destination")


@pulumi.output_type
class JobTaskForEachTaskTaskNewClusterInitScriptS3(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "cannedAcl":
            suggest = "canned_acl"
        elif key == "enableEncryption":
            suggest = "enable_encryption"
        elif key == "encryptionType":
            suggest = "encryption_type"
        elif key == "kmsKey":
            suggest = "kms_key"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in JobTaskForEachTaskTaskNewClusterInitScriptS3. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        JobTaskForEachTaskTaskNewClusterInitScriptS3.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        JobTaskForEachTaskTaskNewClusterInitScriptS3.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 destination: str,
                 canned_acl: Optional[str] = None,
                 enable_encryption: Optional[bool] = None,
                 encryption_type: Optional[str] = None,
                 endpoint: Optional[str] = None,
                 kms_key: Optional[str] = None,
                 region: Optional[str] = None):
        pulumi.set(__self__, "destination", destination)
        if canned_acl is not None:
            pulumi.set(__self__, "canned_acl", canned_acl)
        if enable_encryption is not None:
            pulumi.set(__self__, "enable_encryption", enable_encryption)
        if encryption_type is not None:
            pulumi.set(__self__, "encryption_type", encryption_type)
        if endpoint is not None:
            pulumi.set(__self__, "endpoint", endpoint)
        if kms_key is not None:
            pulumi.set(__self__, "kms_key", kms_key)
        if region is not None:
            pulumi.set(__self__, "region", region)

    @property
    @pulumi.getter
    def destination(self) -> str:
        return pulumi.get(self, "destination")

    @property
    @pulumi.getter(name="cannedAcl")
    def canned_acl(self) -> Optional[str]:
        return pulumi.get(self, "canned_acl")

    @property
    @pulumi.getter(name="enableEncryption")
    def enable_encryption(self) -> Optional[bool]:
        return pulumi.get(self, "enable_encryption")

    @property
    @pulumi.getter(name="encryptionType")
    def encryption_type(self) -> Optional[str]:
        return pulumi.get(self, "encryption_type")

    @property
    @pulumi.getter
    def endpoint(self) -> Optional[str]:
        return pulumi.get(self, "endpoint")

    @property
    @pulumi.getter(name="kmsKey")
    def kms_key(self) -> Optional[str]:
        return pulumi.get(self, "kms_key")

    @property
    @pulumi.getter
    def region(self) -> Optional[str]:
        return pulumi.get(self, "region")


@pulumi.output_type
class JobTaskForEachTaskTaskNewClusterInitScriptVolumes(dict):
    def __init__(__self__, *,
                 destination: str):
        pulumi.set(__self__, "destination", destination)

    @property
    @pulumi.getter
    def destination(self) -> str:
        return pulumi.get(self, "destination")


@pulumi.output_type
class JobTaskForEachTaskTaskNewClusterInitScriptWorkspace(dict):
    def __init__(__self__, *,
                 destination: str):
        pulumi.set(__self__, "destination", destination)

    @property
    @pulumi.getter
    def destination(self) -> str:
        return pulumi.get(self, "destination")


@pulumi.output_type
class JobTaskForEachTaskTaskNewClusterWorkloadType(dict):
    def __init__(__self__, *,
                 clients: 'outputs.JobTaskForEachTaskTaskNewClusterWorkloadTypeClients'):
        pulumi.set(__self__, "clients", clients)

    @property
    @pulumi.getter
    def clients(self) -> 'outputs.JobTaskForEachTaskTaskNewClusterWorkloadTypeClients':
        return pulumi.get(self, "clients")


@pulumi.output_type
class JobTaskForEachTaskTaskNewClusterWorkloadTypeClients(dict):
    def __init__(__self__, *,
                 jobs: Optional[bool] = None,
                 notebooks: Optional[bool] = None):
        if jobs is not None:
            pulumi.set(__self__, "jobs", jobs)
        if notebooks is not None:
            pulumi.set(__self__, "notebooks", notebooks)

    @property
    @pulumi.getter
    def jobs(self) -> Optional[bool]:
        return pulumi.get(self, "jobs")

    @property
    @pulumi.getter
    def notebooks(self) -> Optional[bool]:
        return pulumi.get(self, "notebooks")


@pulumi.output_type
class JobTaskForEachTaskTaskNotebookTask(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "notebookPath":
            suggest = "notebook_path"
        elif key == "baseParameters":
            suggest = "base_parameters"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in JobTaskForEachTaskTaskNotebookTask. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        JobTaskForEachTaskTaskNotebookTask.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        JobTaskForEachTaskTaskNotebookTask.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 notebook_path: str,
                 base_parameters: Optional[Mapping[str, Any]] = None,
                 source: Optional[str] = None):
        """
        :param str notebook_path: The path of the Notebook to be run in the Databricks workspace or remote repository. For notebooks stored in the Databricks workspace, the path must be absolute and begin with a slash. For notebooks stored in a remote repository, the path must be relative. This field is required.
        :param Mapping[str, Any] base_parameters: (Map) Base parameters to be used for each run of this job. If the run is initiated by a call to run-now with parameters specified, the two parameters maps will be merged. If the same key is specified in base_parameters and in run-now, the value from run-now will be used. If the notebook takes a parameter that is not specified in the job’s base_parameters or the run-now override parameters, the default value from the notebook will be used. Retrieve these parameters in a notebook using `dbutils.widgets.get`.
        :param str source: Location type of the notebook, can only be `WORKSPACE` or `GIT`. When set to `WORKSPACE`, the notebook will be retrieved from the local Databricks workspace. When set to `GIT`, the notebook will be retrieved from a Git repository defined in `git_source`. If the value is empty, the task will use `GIT` if `git_source` is defined and `WORKSPACE` otherwise.
        """
        pulumi.set(__self__, "notebook_path", notebook_path)
        if base_parameters is not None:
            pulumi.set(__self__, "base_parameters", base_parameters)
        if source is not None:
            pulumi.set(__self__, "source", source)

    @property
    @pulumi.getter(name="notebookPath")
    def notebook_path(self) -> str:
        """
        The path of the Notebook to be run in the Databricks workspace or remote repository. For notebooks stored in the Databricks workspace, the path must be absolute and begin with a slash. For notebooks stored in a remote repository, the path must be relative. This field is required.
        """
        return pulumi.get(self, "notebook_path")

    @property
    @pulumi.getter(name="baseParameters")
    def base_parameters(self) -> Optional[Mapping[str, Any]]:
        """
        (Map) Base parameters to be used for each run of this job. If the run is initiated by a call to run-now with parameters specified, the two parameters maps will be merged. If the same key is specified in base_parameters and in run-now, the value from run-now will be used. If the notebook takes a parameter that is not specified in the job’s base_parameters or the run-now override parameters, the default value from the notebook will be used. Retrieve these parameters in a notebook using `dbutils.widgets.get`.
        """
        return pulumi.get(self, "base_parameters")

    @property
    @pulumi.getter
    def source(self) -> Optional[str]:
        """
        Location type of the notebook, can only be `WORKSPACE` or `GIT`. When set to `WORKSPACE`, the notebook will be retrieved from the local Databricks workspace. When set to `GIT`, the notebook will be retrieved from a Git repository defined in `git_source`. If the value is empty, the task will use `GIT` if `git_source` is defined and `WORKSPACE` otherwise.
        """
        return pulumi.get(self, "source")


@pulumi.output_type
class JobTaskForEachTaskTaskNotificationSettings(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "alertOnLastAttempt":
            suggest = "alert_on_last_attempt"
        elif key == "noAlertForCanceledRuns":
            suggest = "no_alert_for_canceled_runs"
        elif key == "noAlertForSkippedRuns":
            suggest = "no_alert_for_skipped_runs"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in JobTaskForEachTaskTaskNotificationSettings. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        JobTaskForEachTaskTaskNotificationSettings.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        JobTaskForEachTaskTaskNotificationSettings.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 alert_on_last_attempt: Optional[bool] = None,
                 no_alert_for_canceled_runs: Optional[bool] = None,
                 no_alert_for_skipped_runs: Optional[bool] = None):
        """
        :param bool alert_on_last_attempt: (Bool) do not send notifications to recipients specified in `on_start` for the retried runs and do not send notifications to recipients specified in `on_failure` until the last retry of the run.
        :param bool no_alert_for_canceled_runs: (Bool) don't send alert for cancelled runs.
        :param bool no_alert_for_skipped_runs: (Bool) don't send alert for skipped runs.
        """
        if alert_on_last_attempt is not None:
            pulumi.set(__self__, "alert_on_last_attempt", alert_on_last_attempt)
        if no_alert_for_canceled_runs is not None:
            pulumi.set(__self__, "no_alert_for_canceled_runs", no_alert_for_canceled_runs)
        if no_alert_for_skipped_runs is not None:
            pulumi.set(__self__, "no_alert_for_skipped_runs", no_alert_for_skipped_runs)

    @property
    @pulumi.getter(name="alertOnLastAttempt")
    def alert_on_last_attempt(self) -> Optional[bool]:
        """
        (Bool) do not send notifications to recipients specified in `on_start` for the retried runs and do not send notifications to recipients specified in `on_failure` until the last retry of the run.
        """
        return pulumi.get(self, "alert_on_last_attempt")

    @property
    @pulumi.getter(name="noAlertForCanceledRuns")
    def no_alert_for_canceled_runs(self) -> Optional[bool]:
        """
        (Bool) don't send alert for cancelled runs.
        """
        return pulumi.get(self, "no_alert_for_canceled_runs")

    @property
    @pulumi.getter(name="noAlertForSkippedRuns")
    def no_alert_for_skipped_runs(self) -> Optional[bool]:
        """
        (Bool) don't send alert for skipped runs.
        """
        return pulumi.get(self, "no_alert_for_skipped_runs")


@pulumi.output_type
class JobTaskForEachTaskTaskPipelineTask(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "pipelineId":
            suggest = "pipeline_id"
        elif key == "fullRefresh":
            suggest = "full_refresh"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in JobTaskForEachTaskTaskPipelineTask. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        JobTaskForEachTaskTaskPipelineTask.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        JobTaskForEachTaskTaskPipelineTask.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 pipeline_id: str,
                 full_refresh: Optional[bool] = None):
        """
        :param str pipeline_id: The pipeline's unique ID.
        :param bool full_refresh: (Bool) Specifies if there should be full refresh of the pipeline.
               
               > **Note** The following configuration blocks are only supported inside a `task` block
        """
        pulumi.set(__self__, "pipeline_id", pipeline_id)
        if full_refresh is not None:
            pulumi.set(__self__, "full_refresh", full_refresh)

    @property
    @pulumi.getter(name="pipelineId")
    def pipeline_id(self) -> str:
        """
        The pipeline's unique ID.
        """
        return pulumi.get(self, "pipeline_id")

    @property
    @pulumi.getter(name="fullRefresh")
    def full_refresh(self) -> Optional[bool]:
        """
        (Bool) Specifies if there should be full refresh of the pipeline.

        > **Note** The following configuration blocks are only supported inside a `task` block
        """
        return pulumi.get(self, "full_refresh")


@pulumi.output_type
class JobTaskForEachTaskTaskPythonWheelTask(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "entryPoint":
            suggest = "entry_point"
        elif key == "namedParameters":
            suggest = "named_parameters"
        elif key == "packageName":
            suggest = "package_name"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in JobTaskForEachTaskTaskPythonWheelTask. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        JobTaskForEachTaskTaskPythonWheelTask.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        JobTaskForEachTaskTaskPythonWheelTask.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 entry_point: Optional[str] = None,
                 named_parameters: Optional[Mapping[str, Any]] = None,
                 package_name: Optional[str] = None,
                 parameters: Optional[Sequence[str]] = None):
        """
        :param str entry_point: Python function as entry point for the task
        :param Mapping[str, Any] named_parameters: Named parameters for the task
        :param str package_name: Name of Python package
        :param Sequence[str] parameters: Parameters for the task
        """
        if entry_point is not None:
            pulumi.set(__self__, "entry_point", entry_point)
        if named_parameters is not None:
            pulumi.set(__self__, "named_parameters", named_parameters)
        if package_name is not None:
            pulumi.set(__self__, "package_name", package_name)
        if parameters is not None:
            pulumi.set(__self__, "parameters", parameters)

    @property
    @pulumi.getter(name="entryPoint")
    def entry_point(self) -> Optional[str]:
        """
        Python function as entry point for the task
        """
        return pulumi.get(self, "entry_point")

    @property
    @pulumi.getter(name="namedParameters")
    def named_parameters(self) -> Optional[Mapping[str, Any]]:
        """
        Named parameters for the task
        """
        return pulumi.get(self, "named_parameters")

    @property
    @pulumi.getter(name="packageName")
    def package_name(self) -> Optional[str]:
        """
        Name of Python package
        """
        return pulumi.get(self, "package_name")

    @property
    @pulumi.getter
    def parameters(self) -> Optional[Sequence[str]]:
        """
        Parameters for the task
        """
        return pulumi.get(self, "parameters")


@pulumi.output_type
class JobTaskForEachTaskTaskRunJobTask(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "jobId":
            suggest = "job_id"
        elif key == "jobParameters":
            suggest = "job_parameters"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in JobTaskForEachTaskTaskRunJobTask. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        JobTaskForEachTaskTaskRunJobTask.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        JobTaskForEachTaskTaskRunJobTask.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 job_id: int,
                 job_parameters: Optional[Mapping[str, Any]] = None):
        """
        :param int job_id: (String) ID of the job
        :param Mapping[str, Any] job_parameters: (Map) Job parameters for the task
        """
        pulumi.set(__self__, "job_id", job_id)
        if job_parameters is not None:
            pulumi.set(__self__, "job_parameters", job_parameters)

    @property
    @pulumi.getter(name="jobId")
    def job_id(self) -> int:
        """
        (String) ID of the job
        """
        return pulumi.get(self, "job_id")

    @property
    @pulumi.getter(name="jobParameters")
    def job_parameters(self) -> Optional[Mapping[str, Any]]:
        """
        (Map) Job parameters for the task
        """
        return pulumi.get(self, "job_parameters")


@pulumi.output_type
class JobTaskForEachTaskTaskSparkJarTask(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "jarUri":
            suggest = "jar_uri"
        elif key == "mainClassName":
            suggest = "main_class_name"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in JobTaskForEachTaskTaskSparkJarTask. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        JobTaskForEachTaskTaskSparkJarTask.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        JobTaskForEachTaskTaskSparkJarTask.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 jar_uri: Optional[str] = None,
                 main_class_name: Optional[str] = None,
                 parameters: Optional[Sequence[str]] = None):
        """
        :param str main_class_name: The full name of the class containing the main method to be executed. This class must be contained in a JAR provided as a library. The code should use `SparkContext.getOrCreate` to obtain a Spark context; otherwise, runs of the job will fail.
        :param Sequence[str] parameters: (List) Parameters passed to the main method.
        """
        if jar_uri is not None:
            pulumi.set(__self__, "jar_uri", jar_uri)
        if main_class_name is not None:
            pulumi.set(__self__, "main_class_name", main_class_name)
        if parameters is not None:
            pulumi.set(__self__, "parameters", parameters)

    @property
    @pulumi.getter(name="jarUri")
    def jar_uri(self) -> Optional[str]:
        return pulumi.get(self, "jar_uri")

    @property
    @pulumi.getter(name="mainClassName")
    def main_class_name(self) -> Optional[str]:
        """
        The full name of the class containing the main method to be executed. This class must be contained in a JAR provided as a library. The code should use `SparkContext.getOrCreate` to obtain a Spark context; otherwise, runs of the job will fail.
        """
        return pulumi.get(self, "main_class_name")

    @property
    @pulumi.getter
    def parameters(self) -> Optional[Sequence[str]]:
        """
        (List) Parameters passed to the main method.
        """
        return pulumi.get(self, "parameters")


@pulumi.output_type
class JobTaskForEachTaskTaskSparkPythonTask(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "pythonFile":
            suggest = "python_file"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in JobTaskForEachTaskTaskSparkPythonTask. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        JobTaskForEachTaskTaskSparkPythonTask.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        JobTaskForEachTaskTaskSparkPythonTask.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 python_file: str,
                 parameters: Optional[Sequence[str]] = None,
                 source: Optional[str] = None):
        """
        :param str python_file: The URI of the Python file to be executed. databricks_dbfs_file, cloud file URIs (e.g. `s3:/`, `abfss:/`, `gs:/`), workspace paths and remote repository are supported. For Python files stored in the Databricks workspace, the path must be absolute and begin with `/Repos`. For files stored in a remote repository, the path must be relative. This field is required.
        :param Sequence[str] parameters: (List) Command line parameters passed to the Python file.
        :param str source: Location type of the Python file, can only be `GIT`. When set to `GIT`, the Python file will be retrieved from a Git repository defined in `git_source`.
        """
        pulumi.set(__self__, "python_file", python_file)
        if parameters is not None:
            pulumi.set(__self__, "parameters", parameters)
        if source is not None:
            pulumi.set(__self__, "source", source)

    @property
    @pulumi.getter(name="pythonFile")
    def python_file(self) -> str:
        """
        The URI of the Python file to be executed. databricks_dbfs_file, cloud file URIs (e.g. `s3:/`, `abfss:/`, `gs:/`), workspace paths and remote repository are supported. For Python files stored in the Databricks workspace, the path must be absolute and begin with `/Repos`. For files stored in a remote repository, the path must be relative. This field is required.
        """
        return pulumi.get(self, "python_file")

    @property
    @pulumi.getter
    def parameters(self) -> Optional[Sequence[str]]:
        """
        (List) Command line parameters passed to the Python file.
        """
        return pulumi.get(self, "parameters")

    @property
    @pulumi.getter
    def source(self) -> Optional[str]:
        """
        Location type of the Python file, can only be `GIT`. When set to `GIT`, the Python file will be retrieved from a Git repository defined in `git_source`.
        """
        return pulumi.get(self, "source")


@pulumi.output_type
class JobTaskForEachTaskTaskSparkSubmitTask(dict):
    def __init__(__self__, *,
                 parameters: Optional[Sequence[str]] = None):
        """
        :param Sequence[str] parameters: (List) Command-line parameters passed to spark submit.
        """
        if parameters is not None:
            pulumi.set(__self__, "parameters", parameters)

    @property
    @pulumi.getter
    def parameters(self) -> Optional[Sequence[str]]:
        """
        (List) Command-line parameters passed to spark submit.
        """
        return pulumi.get(self, "parameters")


@pulumi.output_type
class JobTaskForEachTaskTaskSqlTask(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "warehouseId":
            suggest = "warehouse_id"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in JobTaskForEachTaskTaskSqlTask. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        JobTaskForEachTaskTaskSqlTask.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        JobTaskForEachTaskTaskSqlTask.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 alert: Optional['outputs.JobTaskForEachTaskTaskSqlTaskAlert'] = None,
                 dashboard: Optional['outputs.JobTaskForEachTaskTaskSqlTaskDashboard'] = None,
                 file: Optional['outputs.JobTaskForEachTaskTaskSqlTaskFile'] = None,
                 parameters: Optional[Mapping[str, Any]] = None,
                 query: Optional['outputs.JobTaskForEachTaskTaskSqlTaskQuery'] = None,
                 warehouse_id: Optional[str] = None):
        """
        :param 'JobTaskForEachTaskTaskSqlTaskAlertArgs' alert: block consisting of following fields:
        :param 'JobTaskForEachTaskTaskSqlTaskDashboardArgs' dashboard: block consisting of following fields:
        :param 'JobTaskForEachTaskTaskSqlTaskFileArgs' file: block consisting of single string fields:
        :param Mapping[str, Any] parameters: (Map) parameters to be used for each run of this task. The SQL alert task does not support custom parameters.
        :param 'JobTaskForEachTaskTaskSqlTaskQueryArgs' query: block consisting of single string field: `query_id` - identifier of the Databricks SQL Query (databricks_sql_query).
        :param str warehouse_id: ID of the (the databricks_sql_endpoint) that will be used to execute the task.  Only Serverless & Pro warehouses are supported right now.
        """
        if alert is not None:
            pulumi.set(__self__, "alert", alert)
        if dashboard is not None:
            pulumi.set(__self__, "dashboard", dashboard)
        if file is not None:
            pulumi.set(__self__, "file", file)
        if parameters is not None:
            pulumi.set(__self__, "parameters", parameters)
        if query is not None:
            pulumi.set(__self__, "query", query)
        if warehouse_id is not None:
            pulumi.set(__self__, "warehouse_id", warehouse_id)

    @property
    @pulumi.getter
    def alert(self) -> Optional['outputs.JobTaskForEachTaskTaskSqlTaskAlert']:
        """
        block consisting of following fields:
        """
        return pulumi.get(self, "alert")

    @property
    @pulumi.getter
    def dashboard(self) -> Optional['outputs.JobTaskForEachTaskTaskSqlTaskDashboard']:
        """
        block consisting of following fields:
        """
        return pulumi.get(self, "dashboard")

    @property
    @pulumi.getter
    def file(self) -> Optional['outputs.JobTaskForEachTaskTaskSqlTaskFile']:
        """
        block consisting of single string fields:
        """
        return pulumi.get(self, "file")

    @property
    @pulumi.getter
    def parameters(self) -> Optional[Mapping[str, Any]]:
        """
        (Map) parameters to be used for each run of this task. The SQL alert task does not support custom parameters.
        """
        return pulumi.get(self, "parameters")

    @property
    @pulumi.getter
    def query(self) -> Optional['outputs.JobTaskForEachTaskTaskSqlTaskQuery']:
        """
        block consisting of single string field: `query_id` - identifier of the Databricks SQL Query (databricks_sql_query).
        """
        return pulumi.get(self, "query")

    @property
    @pulumi.getter(name="warehouseId")
    def warehouse_id(self) -> Optional[str]:
        """
        ID of the (the databricks_sql_endpoint) that will be used to execute the task.  Only Serverless & Pro warehouses are supported right now.
        """
        return pulumi.get(self, "warehouse_id")


@pulumi.output_type
class JobTaskForEachTaskTaskSqlTaskAlert(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "alertId":
            suggest = "alert_id"
        elif key == "pauseSubscriptions":
            suggest = "pause_subscriptions"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in JobTaskForEachTaskTaskSqlTaskAlert. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        JobTaskForEachTaskTaskSqlTaskAlert.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        JobTaskForEachTaskTaskSqlTaskAlert.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 alert_id: str,
                 subscriptions: Sequence['outputs.JobTaskForEachTaskTaskSqlTaskAlertSubscription'],
                 pause_subscriptions: Optional[bool] = None):
        """
        :param str alert_id: (String) identifier of the Databricks SQL Alert.
        :param Sequence['JobTaskForEachTaskTaskSqlTaskAlertSubscriptionArgs'] subscriptions: a list of subscription blocks consisting out of one of the required fields: `user_name` for user emails or `destination_id` - for Alert destination's identifier.
        :param bool pause_subscriptions: flag that specifies if subscriptions are paused or not.
        """
        pulumi.set(__self__, "alert_id", alert_id)
        pulumi.set(__self__, "subscriptions", subscriptions)
        if pause_subscriptions is not None:
            pulumi.set(__self__, "pause_subscriptions", pause_subscriptions)

    @property
    @pulumi.getter(name="alertId")
    def alert_id(self) -> str:
        """
        (String) identifier of the Databricks SQL Alert.
        """
        return pulumi.get(self, "alert_id")

    @property
    @pulumi.getter
    def subscriptions(self) -> Sequence['outputs.JobTaskForEachTaskTaskSqlTaskAlertSubscription']:
        """
        a list of subscription blocks consisting out of one of the required fields: `user_name` for user emails or `destination_id` - for Alert destination's identifier.
        """
        return pulumi.get(self, "subscriptions")

    @property
    @pulumi.getter(name="pauseSubscriptions")
    def pause_subscriptions(self) -> Optional[bool]:
        """
        flag that specifies if subscriptions are paused or not.
        """
        return pulumi.get(self, "pause_subscriptions")


@pulumi.output_type
class JobTaskForEachTaskTaskSqlTaskAlertSubscription(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "destinationId":
            suggest = "destination_id"
        elif key == "userName":
            suggest = "user_name"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in JobTaskForEachTaskTaskSqlTaskAlertSubscription. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        JobTaskForEachTaskTaskSqlTaskAlertSubscription.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        JobTaskForEachTaskTaskSqlTaskAlertSubscription.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 destination_id: Optional[str] = None,
                 user_name: Optional[str] = None):
        """
        :param str user_name: The email of an active workspace user. Non-admin users can only set this field to their own email.
        """
        if destination_id is not None:
            pulumi.set(__self__, "destination_id", destination_id)
        if user_name is not None:
            pulumi.set(__self__, "user_name", user_name)

    @property
    @pulumi.getter(name="destinationId")
    def destination_id(self) -> Optional[str]:
        return pulumi.get(self, "destination_id")

    @property
    @pulumi.getter(name="userName")
    def user_name(self) -> Optional[str]:
        """
        The email of an active workspace user. Non-admin users can only set this field to their own email.
        """
        return pulumi.get(self, "user_name")


@pulumi.output_type
class JobTaskForEachTaskTaskSqlTaskDashboard(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "dashboardId":
            suggest = "dashboard_id"
        elif key == "customSubject":
            suggest = "custom_subject"
        elif key == "pauseSubscriptions":
            suggest = "pause_subscriptions"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in JobTaskForEachTaskTaskSqlTaskDashboard. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        JobTaskForEachTaskTaskSqlTaskDashboard.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        JobTaskForEachTaskTaskSqlTaskDashboard.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 dashboard_id: str,
                 custom_subject: Optional[str] = None,
                 pause_subscriptions: Optional[bool] = None,
                 subscriptions: Optional[Sequence['outputs.JobTaskForEachTaskTaskSqlTaskDashboardSubscription']] = None):
        """
        :param str dashboard_id: (String) identifier of the Databricks SQL Dashboard databricks_sql_dashboard.
        :param str custom_subject: string specifying a custom subject of email sent.
        :param bool pause_subscriptions: flag that specifies if subscriptions are paused or not.
        :param Sequence['JobTaskForEachTaskTaskSqlTaskDashboardSubscriptionArgs'] subscriptions: a list of subscription blocks consisting out of one of the required fields: `user_name` for user emails or `destination_id` - for Alert destination's identifier.
        """
        pulumi.set(__self__, "dashboard_id", dashboard_id)
        if custom_subject is not None:
            pulumi.set(__self__, "custom_subject", custom_subject)
        if pause_subscriptions is not None:
            pulumi.set(__self__, "pause_subscriptions", pause_subscriptions)
        if subscriptions is not None:
            pulumi.set(__self__, "subscriptions", subscriptions)

    @property
    @pulumi.getter(name="dashboardId")
    def dashboard_id(self) -> str:
        """
        (String) identifier of the Databricks SQL Dashboard databricks_sql_dashboard.
        """
        return pulumi.get(self, "dashboard_id")

    @property
    @pulumi.getter(name="customSubject")
    def custom_subject(self) -> Optional[str]:
        """
        string specifying a custom subject of email sent.
        """
        return pulumi.get(self, "custom_subject")

    @property
    @pulumi.getter(name="pauseSubscriptions")
    def pause_subscriptions(self) -> Optional[bool]:
        """
        flag that specifies if subscriptions are paused or not.
        """
        return pulumi.get(self, "pause_subscriptions")

    @property
    @pulumi.getter
    def subscriptions(self) -> Optional[Sequence['outputs.JobTaskForEachTaskTaskSqlTaskDashboardSubscription']]:
        """
        a list of subscription blocks consisting out of one of the required fields: `user_name` for user emails or `destination_id` - for Alert destination's identifier.
        """
        return pulumi.get(self, "subscriptions")


@pulumi.output_type
class JobTaskForEachTaskTaskSqlTaskDashboardSubscription(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "destinationId":
            suggest = "destination_id"
        elif key == "userName":
            suggest = "user_name"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in JobTaskForEachTaskTaskSqlTaskDashboardSubscription. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        JobTaskForEachTaskTaskSqlTaskDashboardSubscription.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        JobTaskForEachTaskTaskSqlTaskDashboardSubscription.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 destination_id: Optional[str] = None,
                 user_name: Optional[str] = None):
        """
        :param str user_name: The email of an active workspace user. Non-admin users can only set this field to their own email.
        """
        if destination_id is not None:
            pulumi.set(__self__, "destination_id", destination_id)
        if user_name is not None:
            pulumi.set(__self__, "user_name", user_name)

    @property
    @pulumi.getter(name="destinationId")
    def destination_id(self) -> Optional[str]:
        return pulumi.get(self, "destination_id")

    @property
    @pulumi.getter(name="userName")
    def user_name(self) -> Optional[str]:
        """
        The email of an active workspace user. Non-admin users can only set this field to their own email.
        """
        return pulumi.get(self, "user_name")


@pulumi.output_type
class JobTaskForEachTaskTaskSqlTaskFile(dict):
    def __init__(__self__, *,
                 path: str,
                 source: Optional[str] = None):
        """
        :param str path: If `source` is `GIT`: Relative path to the file in the repository specified in the `git_source` block with SQL commands to execute. If `source` is `WORKSPACE`: Absolute path to the file in the workspace with SQL commands to execute.
               
               Example
               
               <!--Start PulumiCodeChooser -->
               ```python
               import pulumi
               import pulumi_databricks as databricks
               
               sql_aggregation_job = databricks.Job("sqlAggregationJob", tasks=[
                   databricks.JobTaskArgs(
                       task_key="run_agg_query",
                       sql_task=databricks.JobTaskSqlTaskArgs(
                           warehouse_id=databricks_sql_endpoint["sql_job_warehouse"]["id"],
                           query=databricks.JobTaskSqlTaskQueryArgs(
                               query_id=databricks_sql_query["agg_query"]["id"],
                           ),
                       ),
                   ),
                   databricks.JobTaskArgs(
                       task_key="run_dashboard",
                       sql_task=databricks.JobTaskSqlTaskArgs(
                           warehouse_id=databricks_sql_endpoint["sql_job_warehouse"]["id"],
                           dashboard=databricks.JobTaskSqlTaskDashboardArgs(
                               dashboard_id=databricks_sql_dashboard["dash"]["id"],
                               subscriptions=[databricks.JobTaskSqlTaskDashboardSubscriptionArgs(
                                   user_name="user@domain.com",
                               )],
                           ),
                       ),
                   ),
                   databricks.JobTaskArgs(
                       task_key="run_alert",
                       sql_task=databricks.JobTaskSqlTaskArgs(
                           warehouse_id=databricks_sql_endpoint["sql_job_warehouse"]["id"],
                           alert=databricks.JobTaskSqlTaskAlertArgs(
                               alert_id=databricks_sql_alert["alert"]["id"],
                               subscriptions=[databricks.JobTaskSqlTaskAlertSubscriptionArgs(
                                   user_name="user@domain.com",
                               )],
                           ),
                       ),
                   ),
               ])
               ```
               <!--End PulumiCodeChooser -->
        :param str source: The source of the project. Possible values are `WORKSPACE` and `GIT`.  Defaults to `GIT` if a `git_source` block is present in the job definition.
        """
        pulumi.set(__self__, "path", path)
        if source is not None:
            pulumi.set(__self__, "source", source)

    @property
    @pulumi.getter
    def path(self) -> str:
        """
        If `source` is `GIT`: Relative path to the file in the repository specified in the `git_source` block with SQL commands to execute. If `source` is `WORKSPACE`: Absolute path to the file in the workspace with SQL commands to execute.

        Example

        <!--Start PulumiCodeChooser -->
        ```python
        import pulumi
        import pulumi_databricks as databricks

        sql_aggregation_job = databricks.Job("sqlAggregationJob", tasks=[
            databricks.JobTaskArgs(
                task_key="run_agg_query",
                sql_task=databricks.JobTaskSqlTaskArgs(
                    warehouse_id=databricks_sql_endpoint["sql_job_warehouse"]["id"],
                    query=databricks.JobTaskSqlTaskQueryArgs(
                        query_id=databricks_sql_query["agg_query"]["id"],
                    ),
                ),
            ),
            databricks.JobTaskArgs(
                task_key="run_dashboard",
                sql_task=databricks.JobTaskSqlTaskArgs(
                    warehouse_id=databricks_sql_endpoint["sql_job_warehouse"]["id"],
                    dashboard=databricks.JobTaskSqlTaskDashboardArgs(
                        dashboard_id=databricks_sql_dashboard["dash"]["id"],
                        subscriptions=[databricks.JobTaskSqlTaskDashboardSubscriptionArgs(
                            user_name="user@domain.com",
                        )],
                    ),
                ),
            ),
            databricks.JobTaskArgs(
                task_key="run_alert",
                sql_task=databricks.JobTaskSqlTaskArgs(
                    warehouse_id=databricks_sql_endpoint["sql_job_warehouse"]["id"],
                    alert=databricks.JobTaskSqlTaskAlertArgs(
                        alert_id=databricks_sql_alert["alert"]["id"],
                        subscriptions=[databricks.JobTaskSqlTaskAlertSubscriptionArgs(
                            user_name="user@domain.com",
                        )],
                    ),
                ),
            ),
        ])
        ```
        <!--End PulumiCodeChooser -->
        """
        return pulumi.get(self, "path")

    @property
    @pulumi.getter
    def source(self) -> Optional[str]:
        """
        The source of the project. Possible values are `WORKSPACE` and `GIT`.  Defaults to `GIT` if a `git_source` block is present in the job definition.
        """
        return pulumi.get(self, "source")


@pulumi.output_type
class JobTaskForEachTaskTaskSqlTaskQuery(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "queryId":
            suggest = "query_id"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in JobTaskForEachTaskTaskSqlTaskQuery. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        JobTaskForEachTaskTaskSqlTaskQuery.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        JobTaskForEachTaskTaskSqlTaskQuery.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 query_id: str):
        pulumi.set(__self__, "query_id", query_id)

    @property
    @pulumi.getter(name="queryId")
    def query_id(self) -> str:
        return pulumi.get(self, "query_id")


@pulumi.output_type
class JobTaskForEachTaskTaskWebhookNotifications(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "onDurationWarningThresholdExceededs":
            suggest = "on_duration_warning_threshold_exceededs"
        elif key == "onFailures":
            suggest = "on_failures"
        elif key == "onStarts":
            suggest = "on_starts"
        elif key == "onSuccesses":
            suggest = "on_successes"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in JobTaskForEachTaskTaskWebhookNotifications. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        JobTaskForEachTaskTaskWebhookNotifications.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        JobTaskForEachTaskTaskWebhookNotifications.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 on_duration_warning_threshold_exceededs: Optional[Sequence['outputs.JobTaskForEachTaskTaskWebhookNotificationsOnDurationWarningThresholdExceeded']] = None,
                 on_failures: Optional[Sequence['outputs.JobTaskForEachTaskTaskWebhookNotificationsOnFailure']] = None,
                 on_starts: Optional[Sequence['outputs.JobTaskForEachTaskTaskWebhookNotificationsOnStart']] = None,
                 on_successes: Optional[Sequence['outputs.JobTaskForEachTaskTaskWebhookNotificationsOnSuccess']] = None):
        """
        :param Sequence['JobTaskForEachTaskTaskWebhookNotificationsOnDurationWarningThresholdExceededArgs'] on_duration_warning_threshold_exceededs: (List) list of notification IDs to call when the duration of a run exceeds the threshold specified by the `RUN_DURATION_SECONDS` metric in the `health` block.
               
               Note that the `id` is not to be confused with the name of the alert destination. The `id` can be retrieved through the API or the URL of Databricks UI `https://<workspace host>/sql/destinations/<notification id>?o=<workspace id>`
               
               Example
               
               <!--Start PulumiCodeChooser -->
               ```python
               import pulumi
               ```
               <!--End PulumiCodeChooser -->
        :param Sequence['JobTaskForEachTaskTaskWebhookNotificationsOnFailureArgs'] on_failures: (List) list of notification IDs to call when the run fails. A maximum of 3 destinations can be specified.
        :param Sequence['JobTaskForEachTaskTaskWebhookNotificationsOnStartArgs'] on_starts: (List) list of notification IDs to call when the run starts. A maximum of 3 destinations can be specified.
        :param Sequence['JobTaskForEachTaskTaskWebhookNotificationsOnSuccessArgs'] on_successes: (List) list of notification IDs to call when the run completes successfully. A maximum of 3 destinations can be specified.
        """
        if on_duration_warning_threshold_exceededs is not None:
            pulumi.set(__self__, "on_duration_warning_threshold_exceededs", on_duration_warning_threshold_exceededs)
        if on_failures is not None:
            pulumi.set(__self__, "on_failures", on_failures)
        if on_starts is not None:
            pulumi.set(__self__, "on_starts", on_starts)
        if on_successes is not None:
            pulumi.set(__self__, "on_successes", on_successes)

    @property
    @pulumi.getter(name="onDurationWarningThresholdExceededs")
    def on_duration_warning_threshold_exceededs(self) -> Optional[Sequence['outputs.JobTaskForEachTaskTaskWebhookNotificationsOnDurationWarningThresholdExceeded']]:
        """
        (List) list of notification IDs to call when the duration of a run exceeds the threshold specified by the `RUN_DURATION_SECONDS` metric in the `health` block.

        Note that the `id` is not to be confused with the name of the alert destination. The `id` can be retrieved through the API or the URL of Databricks UI `https://<workspace host>/sql/destinations/<notification id>?o=<workspace id>`

        Example

        <!--Start PulumiCodeChooser -->
        ```python
        import pulumi
        ```
        <!--End PulumiCodeChooser -->
        """
        return pulumi.get(self, "on_duration_warning_threshold_exceededs")

    @property
    @pulumi.getter(name="onFailures")
    def on_failures(self) -> Optional[Sequence['outputs.JobTaskForEachTaskTaskWebhookNotificationsOnFailure']]:
        """
        (List) list of notification IDs to call when the run fails. A maximum of 3 destinations can be specified.
        """
        return pulumi.get(self, "on_failures")

    @property
    @pulumi.getter(name="onStarts")
    def on_starts(self) -> Optional[Sequence['outputs.JobTaskForEachTaskTaskWebhookNotificationsOnStart']]:
        """
        (List) list of notification IDs to call when the run starts. A maximum of 3 destinations can be specified.
        """
        return pulumi.get(self, "on_starts")

    @property
    @pulumi.getter(name="onSuccesses")
    def on_successes(self) -> Optional[Sequence['outputs.JobTaskForEachTaskTaskWebhookNotificationsOnSuccess']]:
        """
        (List) list of notification IDs to call when the run completes successfully. A maximum of 3 destinations can be specified.
        """
        return pulumi.get(self, "on_successes")


@pulumi.output_type
class JobTaskForEachTaskTaskWebhookNotificationsOnDurationWarningThresholdExceeded(dict):
    def __init__(__self__, *,
                 id: Optional[str] = None):
        """
        :param str id: ID of the system notification that is notified when an event defined in `webhook_notifications` is triggered.
               
               > **Note** The following configuration blocks can be standalone or nested inside a `task` block
        """
        if id is not None:
            pulumi.set(__self__, "id", id)

    @property
    @pulumi.getter
    def id(self) -> Optional[str]:
        """
        ID of the system notification that is notified when an event defined in `webhook_notifications` is triggered.

        > **Note** The following configuration blocks can be standalone or nested inside a `task` block
        """
        return pulumi.get(self, "id")


@pulumi.output_type
class JobTaskForEachTaskTaskWebhookNotificationsOnFailure(dict):
    def __init__(__self__, *,
                 id: Optional[str] = None):
        """
        :param str id: ID of the system notification that is notified when an event defined in `webhook_notifications` is triggered.
               
               > **Note** The following configuration blocks can be standalone or nested inside a `task` block
        """
        if id is not None:
            pulumi.set(__self__, "id", id)

    @property
    @pulumi.getter
    def id(self) -> Optional[str]:
        """
        ID of the system notification that is notified when an event defined in `webhook_notifications` is triggered.

        > **Note** The following configuration blocks can be standalone or nested inside a `task` block
        """
        return pulumi.get(self, "id")


@pulumi.output_type
class JobTaskForEachTaskTaskWebhookNotificationsOnStart(dict):
    def __init__(__self__, *,
                 id: Optional[str] = None):
        """
        :param str id: ID of the system notification that is notified when an event defined in `webhook_notifications` is triggered.
               
               > **Note** The following configuration blocks can be standalone or nested inside a `task` block
        """
        if id is not None:
            pulumi.set(__self__, "id", id)

    @property
    @pulumi.getter
    def id(self) -> Optional[str]:
        """
        ID of the system notification that is notified when an event defined in `webhook_notifications` is triggered.

        > **Note** The following configuration blocks can be standalone or nested inside a `task` block
        """
        return pulumi.get(self, "id")


@pulumi.output_type
class JobTaskForEachTaskTaskWebhookNotificationsOnSuccess(dict):
    def __init__(__self__, *,
                 id: Optional[str] = None):
        """
        :param str id: ID of the system notification that is notified when an event defined in `webhook_notifications` is triggered.
               
               > **Note** The following configuration blocks can be standalone or nested inside a `task` block
        """
        if id is not None:
            pulumi.set(__self__, "id", id)

    @property
    @pulumi.getter
    def id(self) -> Optional[str]:
        """
        ID of the system notification that is notified when an event defined in `webhook_notifications` is triggered.

        > **Note** The following configuration blocks can be standalone or nested inside a `task` block
        """
        return pulumi.get(self, "id")


@pulumi.output_type
class JobTaskHealth(dict):
    def __init__(__self__, *,
                 rules: Sequence['outputs.JobTaskHealthRule']):
        """
        :param Sequence['JobTaskHealthRuleArgs'] rules: list of rules that are represented as objects with the following attributes:
        """
        pulumi.set(__self__, "rules", rules)

    @property
    @pulumi.getter
    def rules(self) -> Sequence['outputs.JobTaskHealthRule']:
        """
        list of rules that are represented as objects with the following attributes:
        """
        return pulumi.get(self, "rules")


@pulumi.output_type
class JobTaskHealthRule(dict):
    def __init__(__self__, *,
                 metric: Optional[str] = None,
                 op: Optional[str] = None,
                 value: Optional[int] = None):
        """
        :param str metric: string specifying the metric to check.  The only supported metric is `RUN_DURATION_SECONDS` (check [Jobs REST API documentation](https://docs.databricks.com/api/workspace/jobs/create) for the latest information).
        :param str op: The string specifying the operation used to compare operands.  Currently, following operators are supported: `EQUAL_TO`, `GREATER_THAN`, `GREATER_THAN_OR_EQUAL`, `LESS_THAN`, `LESS_THAN_OR_EQUAL`, `NOT_EQUAL`. (Check the [API docs](https://docs.databricks.com/api/workspace/jobs/create) for the latest information).
               
               This task does not require a cluster to execute and does not support retries or notifications.
        :param int value: integer value used to compare to the given metric.
        """
        if metric is not None:
            pulumi.set(__self__, "metric", metric)
        if op is not None:
            pulumi.set(__self__, "op", op)
        if value is not None:
            pulumi.set(__self__, "value", value)

    @property
    @pulumi.getter
    def metric(self) -> Optional[str]:
        """
        string specifying the metric to check.  The only supported metric is `RUN_DURATION_SECONDS` (check [Jobs REST API documentation](https://docs.databricks.com/api/workspace/jobs/create) for the latest information).
        """
        return pulumi.get(self, "metric")

    @property
    @pulumi.getter
    def op(self) -> Optional[str]:
        """
        The string specifying the operation used to compare operands.  Currently, following operators are supported: `EQUAL_TO`, `GREATER_THAN`, `GREATER_THAN_OR_EQUAL`, `LESS_THAN`, `LESS_THAN_OR_EQUAL`, `NOT_EQUAL`. (Check the [API docs](https://docs.databricks.com/api/workspace/jobs/create) for the latest information).

        This task does not require a cluster to execute and does not support retries or notifications.
        """
        return pulumi.get(self, "op")

    @property
    @pulumi.getter
    def value(self) -> Optional[int]:
        """
        integer value used to compare to the given metric.
        """
        return pulumi.get(self, "value")


@pulumi.output_type
class JobTaskLibrary(dict):
    def __init__(__self__, *,
                 cran: Optional['outputs.JobTaskLibraryCran'] = None,
                 egg: Optional[str] = None,
                 jar: Optional[str] = None,
                 maven: Optional['outputs.JobTaskLibraryMaven'] = None,
                 pypi: Optional['outputs.JobTaskLibraryPypi'] = None,
                 whl: Optional[str] = None):
        if cran is not None:
            pulumi.set(__self__, "cran", cran)
        if egg is not None:
            pulumi.set(__self__, "egg", egg)
        if jar is not None:
            pulumi.set(__self__, "jar", jar)
        if maven is not None:
            pulumi.set(__self__, "maven", maven)
        if pypi is not None:
            pulumi.set(__self__, "pypi", pypi)
        if whl is not None:
            pulumi.set(__self__, "whl", whl)

    @property
    @pulumi.getter
    def cran(self) -> Optional['outputs.JobTaskLibraryCran']:
        return pulumi.get(self, "cran")

    @property
    @pulumi.getter
    def egg(self) -> Optional[str]:
        return pulumi.get(self, "egg")

    @property
    @pulumi.getter
    def jar(self) -> Optional[str]:
        return pulumi.get(self, "jar")

    @property
    @pulumi.getter
    def maven(self) -> Optional['outputs.JobTaskLibraryMaven']:
        return pulumi.get(self, "maven")

    @property
    @pulumi.getter
    def pypi(self) -> Optional['outputs.JobTaskLibraryPypi']:
        return pulumi.get(self, "pypi")

    @property
    @pulumi.getter
    def whl(self) -> Optional[str]:
        return pulumi.get(self, "whl")


@pulumi.output_type
class JobTaskLibraryCran(dict):
    def __init__(__self__, *,
                 package: str,
                 repo: Optional[str] = None):
        pulumi.set(__self__, "package", package)
        if repo is not None:
            pulumi.set(__self__, "repo", repo)

    @property
    @pulumi.getter
    def package(self) -> str:
        return pulumi.get(self, "package")

    @property
    @pulumi.getter
    def repo(self) -> Optional[str]:
        return pulumi.get(self, "repo")


@pulumi.output_type
class JobTaskLibraryMaven(dict):
    def __init__(__self__, *,
                 coordinates: str,
                 exclusions: Optional[Sequence[str]] = None,
                 repo: Optional[str] = None):
        pulumi.set(__self__, "coordinates", coordinates)
        if exclusions is not None:
            pulumi.set(__self__, "exclusions", exclusions)
        if repo is not None:
            pulumi.set(__self__, "repo", repo)

    @property
    @pulumi.getter
    def coordinates(self) -> str:
        return pulumi.get(self, "coordinates")

    @property
    @pulumi.getter
    def exclusions(self) -> Optional[Sequence[str]]:
        return pulumi.get(self, "exclusions")

    @property
    @pulumi.getter
    def repo(self) -> Optional[str]:
        return pulumi.get(self, "repo")


@pulumi.output_type
class JobTaskLibraryPypi(dict):
    def __init__(__self__, *,
                 package: str,
                 repo: Optional[str] = None):
        pulumi.set(__self__, "package", package)
        if repo is not None:
            pulumi.set(__self__, "repo", repo)

    @property
    @pulumi.getter
    def package(self) -> str:
        return pulumi.get(self, "package")

    @property
    @pulumi.getter
    def repo(self) -> Optional[str]:
        return pulumi.get(self, "repo")


@pulumi.output_type
class JobTaskNewCluster(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "sparkVersion":
            suggest = "spark_version"
        elif key == "applyPolicyDefaultValues":
            suggest = "apply_policy_default_values"
        elif key == "autoterminationMinutes":
            suggest = "autotermination_minutes"
        elif key == "awsAttributes":
            suggest = "aws_attributes"
        elif key == "azureAttributes":
            suggest = "azure_attributes"
        elif key == "clusterId":
            suggest = "cluster_id"
        elif key == "clusterLogConf":
            suggest = "cluster_log_conf"
        elif key == "clusterMountInfos":
            suggest = "cluster_mount_infos"
        elif key == "clusterName":
            suggest = "cluster_name"
        elif key == "customTags":
            suggest = "custom_tags"
        elif key == "dataSecurityMode":
            suggest = "data_security_mode"
        elif key == "dockerImage":
            suggest = "docker_image"
        elif key == "driverInstancePoolId":
            suggest = "driver_instance_pool_id"
        elif key == "driverNodeTypeId":
            suggest = "driver_node_type_id"
        elif key == "enableElasticDisk":
            suggest = "enable_elastic_disk"
        elif key == "enableLocalDiskEncryption":
            suggest = "enable_local_disk_encryption"
        elif key == "gcpAttributes":
            suggest = "gcp_attributes"
        elif key == "idempotencyToken":
            suggest = "idempotency_token"
        elif key == "initScripts":
            suggest = "init_scripts"
        elif key == "instancePoolId":
            suggest = "instance_pool_id"
        elif key == "nodeTypeId":
            suggest = "node_type_id"
        elif key == "numWorkers":
            suggest = "num_workers"
        elif key == "policyId":
            suggest = "policy_id"
        elif key == "runtimeEngine":
            suggest = "runtime_engine"
        elif key == "singleUserName":
            suggest = "single_user_name"
        elif key == "sparkConf":
            suggest = "spark_conf"
        elif key == "sparkEnvVars":
            suggest = "spark_env_vars"
        elif key == "sshPublicKeys":
            suggest = "ssh_public_keys"
        elif key == "workloadType":
            suggest = "workload_type"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in JobTaskNewCluster. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        JobTaskNewCluster.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        JobTaskNewCluster.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 spark_version: str,
                 apply_policy_default_values: Optional[bool] = None,
                 autoscale: Optional['outputs.JobTaskNewClusterAutoscale'] = None,
                 autotermination_minutes: Optional[int] = None,
                 aws_attributes: Optional['outputs.JobTaskNewClusterAwsAttributes'] = None,
                 azure_attributes: Optional['outputs.JobTaskNewClusterAzureAttributes'] = None,
                 cluster_id: Optional[str] = None,
                 cluster_log_conf: Optional['outputs.JobTaskNewClusterClusterLogConf'] = None,
                 cluster_mount_infos: Optional[Sequence['outputs.JobTaskNewClusterClusterMountInfo']] = None,
                 cluster_name: Optional[str] = None,
                 custom_tags: Optional[Mapping[str, Any]] = None,
                 data_security_mode: Optional[str] = None,
                 docker_image: Optional['outputs.JobTaskNewClusterDockerImage'] = None,
                 driver_instance_pool_id: Optional[str] = None,
                 driver_node_type_id: Optional[str] = None,
                 enable_elastic_disk: Optional[bool] = None,
                 enable_local_disk_encryption: Optional[bool] = None,
                 gcp_attributes: Optional['outputs.JobTaskNewClusterGcpAttributes'] = None,
                 idempotency_token: Optional[str] = None,
                 init_scripts: Optional[Sequence['outputs.JobTaskNewClusterInitScript']] = None,
                 instance_pool_id: Optional[str] = None,
                 node_type_id: Optional[str] = None,
                 num_workers: Optional[int] = None,
                 policy_id: Optional[str] = None,
                 runtime_engine: Optional[str] = None,
                 single_user_name: Optional[str] = None,
                 spark_conf: Optional[Mapping[str, Any]] = None,
                 spark_env_vars: Optional[Mapping[str, Any]] = None,
                 ssh_public_keys: Optional[Sequence[str]] = None,
                 workload_type: Optional['outputs.JobTaskNewClusterWorkloadType'] = None):
        pulumi.set(__self__, "spark_version", spark_version)
        if apply_policy_default_values is not None:
            pulumi.set(__self__, "apply_policy_default_values", apply_policy_default_values)
        if autoscale is not None:
            pulumi.set(__self__, "autoscale", autoscale)
        if autotermination_minutes is not None:
            pulumi.set(__self__, "autotermination_minutes", autotermination_minutes)
        if aws_attributes is not None:
            pulumi.set(__self__, "aws_attributes", aws_attributes)
        if azure_attributes is not None:
            pulumi.set(__self__, "azure_attributes", azure_attributes)
        if cluster_id is not None:
            pulumi.set(__self__, "cluster_id", cluster_id)
        if cluster_log_conf is not None:
            pulumi.set(__self__, "cluster_log_conf", cluster_log_conf)
        if cluster_mount_infos is not None:
            pulumi.set(__self__, "cluster_mount_infos", cluster_mount_infos)
        if cluster_name is not None:
            pulumi.set(__self__, "cluster_name", cluster_name)
        if custom_tags is not None:
            pulumi.set(__self__, "custom_tags", custom_tags)
        if data_security_mode is not None:
            pulumi.set(__self__, "data_security_mode", data_security_mode)
        if docker_image is not None:
            pulumi.set(__self__, "docker_image", docker_image)
        if driver_instance_pool_id is not None:
            pulumi.set(__self__, "driver_instance_pool_id", driver_instance_pool_id)
        if driver_node_type_id is not None:
            pulumi.set(__self__, "driver_node_type_id", driver_node_type_id)
        if enable_elastic_disk is not None:
            pulumi.set(__self__, "enable_elastic_disk", enable_elastic_disk)
        if enable_local_disk_encryption is not None:
            pulumi.set(__self__, "enable_local_disk_encryption", enable_local_disk_encryption)
        if gcp_attributes is not None:
            pulumi.set(__self__, "gcp_attributes", gcp_attributes)
        if idempotency_token is not None:
            pulumi.set(__self__, "idempotency_token", idempotency_token)
        if init_scripts is not None:
            pulumi.set(__self__, "init_scripts", init_scripts)
        if instance_pool_id is not None:
            pulumi.set(__self__, "instance_pool_id", instance_pool_id)
        if node_type_id is not None:
            pulumi.set(__self__, "node_type_id", node_type_id)
        if num_workers is not None:
            pulumi.set(__self__, "num_workers", num_workers)
        if policy_id is not None:
            pulumi.set(__self__, "policy_id", policy_id)
        if runtime_engine is not None:
            pulumi.set(__self__, "runtime_engine", runtime_engine)
        if single_user_name is not None:
            pulumi.set(__self__, "single_user_name", single_user_name)
        if spark_conf is not None:
            pulumi.set(__self__, "spark_conf", spark_conf)
        if spark_env_vars is not None:
            pulumi.set(__self__, "spark_env_vars", spark_env_vars)
        if ssh_public_keys is not None:
            pulumi.set(__self__, "ssh_public_keys", ssh_public_keys)
        if workload_type is not None:
            pulumi.set(__self__, "workload_type", workload_type)

    @property
    @pulumi.getter(name="sparkVersion")
    def spark_version(self) -> str:
        return pulumi.get(self, "spark_version")

    @property
    @pulumi.getter(name="applyPolicyDefaultValues")
    def apply_policy_default_values(self) -> Optional[bool]:
        return pulumi.get(self, "apply_policy_default_values")

    @property
    @pulumi.getter
    def autoscale(self) -> Optional['outputs.JobTaskNewClusterAutoscale']:
        return pulumi.get(self, "autoscale")

    @property
    @pulumi.getter(name="autoterminationMinutes")
    def autotermination_minutes(self) -> Optional[int]:
        return pulumi.get(self, "autotermination_minutes")

    @property
    @pulumi.getter(name="awsAttributes")
    def aws_attributes(self) -> Optional['outputs.JobTaskNewClusterAwsAttributes']:
        return pulumi.get(self, "aws_attributes")

    @property
    @pulumi.getter(name="azureAttributes")
    def azure_attributes(self) -> Optional['outputs.JobTaskNewClusterAzureAttributes']:
        return pulumi.get(self, "azure_attributes")

    @property
    @pulumi.getter(name="clusterId")
    def cluster_id(self) -> Optional[str]:
        return pulumi.get(self, "cluster_id")

    @property
    @pulumi.getter(name="clusterLogConf")
    def cluster_log_conf(self) -> Optional['outputs.JobTaskNewClusterClusterLogConf']:
        return pulumi.get(self, "cluster_log_conf")

    @property
    @pulumi.getter(name="clusterMountInfos")
    def cluster_mount_infos(self) -> Optional[Sequence['outputs.JobTaskNewClusterClusterMountInfo']]:
        return pulumi.get(self, "cluster_mount_infos")

    @property
    @pulumi.getter(name="clusterName")
    def cluster_name(self) -> Optional[str]:
        return pulumi.get(self, "cluster_name")

    @property
    @pulumi.getter(name="customTags")
    def custom_tags(self) -> Optional[Mapping[str, Any]]:
        return pulumi.get(self, "custom_tags")

    @property
    @pulumi.getter(name="dataSecurityMode")
    def data_security_mode(self) -> Optional[str]:
        return pulumi.get(self, "data_security_mode")

    @property
    @pulumi.getter(name="dockerImage")
    def docker_image(self) -> Optional['outputs.JobTaskNewClusterDockerImage']:
        return pulumi.get(self, "docker_image")

    @property
    @pulumi.getter(name="driverInstancePoolId")
    def driver_instance_pool_id(self) -> Optional[str]:
        return pulumi.get(self, "driver_instance_pool_id")

    @property
    @pulumi.getter(name="driverNodeTypeId")
    def driver_node_type_id(self) -> Optional[str]:
        return pulumi.get(self, "driver_node_type_id")

    @property
    @pulumi.getter(name="enableElasticDisk")
    def enable_elastic_disk(self) -> Optional[bool]:
        return pulumi.get(self, "enable_elastic_disk")

    @property
    @pulumi.getter(name="enableLocalDiskEncryption")
    def enable_local_disk_encryption(self) -> Optional[bool]:
        return pulumi.get(self, "enable_local_disk_encryption")

    @property
    @pulumi.getter(name="gcpAttributes")
    def gcp_attributes(self) -> Optional['outputs.JobTaskNewClusterGcpAttributes']:
        return pulumi.get(self, "gcp_attributes")

    @property
    @pulumi.getter(name="idempotencyToken")
    def idempotency_token(self) -> Optional[str]:
        return pulumi.get(self, "idempotency_token")

    @property
    @pulumi.getter(name="initScripts")
    def init_scripts(self) -> Optional[Sequence['outputs.JobTaskNewClusterInitScript']]:
        return pulumi.get(self, "init_scripts")

    @property
    @pulumi.getter(name="instancePoolId")
    def instance_pool_id(self) -> Optional[str]:
        return pulumi.get(self, "instance_pool_id")

    @property
    @pulumi.getter(name="nodeTypeId")
    def node_type_id(self) -> Optional[str]:
        return pulumi.get(self, "node_type_id")

    @property
    @pulumi.getter(name="numWorkers")
    def num_workers(self) -> Optional[int]:
        return pulumi.get(self, "num_workers")

    @property
    @pulumi.getter(name="policyId")
    def policy_id(self) -> Optional[str]:
        return pulumi.get(self, "policy_id")

    @property
    @pulumi.getter(name="runtimeEngine")
    def runtime_engine(self) -> Optional[str]:
        return pulumi.get(self, "runtime_engine")

    @property
    @pulumi.getter(name="singleUserName")
    def single_user_name(self) -> Optional[str]:
        return pulumi.get(self, "single_user_name")

    @property
    @pulumi.getter(name="sparkConf")
    def spark_conf(self) -> Optional[Mapping[str, Any]]:
        return pulumi.get(self, "spark_conf")

    @property
    @pulumi.getter(name="sparkEnvVars")
    def spark_env_vars(self) -> Optional[Mapping[str, Any]]:
        return pulumi.get(self, "spark_env_vars")

    @property
    @pulumi.getter(name="sshPublicKeys")
    def ssh_public_keys(self) -> Optional[Sequence[str]]:
        return pulumi.get(self, "ssh_public_keys")

    @property
    @pulumi.getter(name="workloadType")
    def workload_type(self) -> Optional['outputs.JobTaskNewClusterWorkloadType']:
        return pulumi.get(self, "workload_type")


@pulumi.output_type
class JobTaskNewClusterAutoscale(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "maxWorkers":
            suggest = "max_workers"
        elif key == "minWorkers":
            suggest = "min_workers"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in JobTaskNewClusterAutoscale. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        JobTaskNewClusterAutoscale.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        JobTaskNewClusterAutoscale.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 max_workers: Optional[int] = None,
                 min_workers: Optional[int] = None):
        if max_workers is not None:
            pulumi.set(__self__, "max_workers", max_workers)
        if min_workers is not None:
            pulumi.set(__self__, "min_workers", min_workers)

    @property
    @pulumi.getter(name="maxWorkers")
    def max_workers(self) -> Optional[int]:
        return pulumi.get(self, "max_workers")

    @property
    @pulumi.getter(name="minWorkers")
    def min_workers(self) -> Optional[int]:
        return pulumi.get(self, "min_workers")


@pulumi.output_type
class JobTaskNewClusterAwsAttributes(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "ebsVolumeCount":
            suggest = "ebs_volume_count"
        elif key == "ebsVolumeSize":
            suggest = "ebs_volume_size"
        elif key == "ebsVolumeType":
            suggest = "ebs_volume_type"
        elif key == "firstOnDemand":
            suggest = "first_on_demand"
        elif key == "instanceProfileArn":
            suggest = "instance_profile_arn"
        elif key == "spotBidPricePercent":
            suggest = "spot_bid_price_percent"
        elif key == "zoneId":
            suggest = "zone_id"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in JobTaskNewClusterAwsAttributes. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        JobTaskNewClusterAwsAttributes.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        JobTaskNewClusterAwsAttributes.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 availability: Optional[str] = None,
                 ebs_volume_count: Optional[int] = None,
                 ebs_volume_size: Optional[int] = None,
                 ebs_volume_type: Optional[str] = None,
                 first_on_demand: Optional[int] = None,
                 instance_profile_arn: Optional[str] = None,
                 spot_bid_price_percent: Optional[int] = None,
                 zone_id: Optional[str] = None):
        if availability is not None:
            pulumi.set(__self__, "availability", availability)
        if ebs_volume_count is not None:
            pulumi.set(__self__, "ebs_volume_count", ebs_volume_count)
        if ebs_volume_size is not None:
            pulumi.set(__self__, "ebs_volume_size", ebs_volume_size)
        if ebs_volume_type is not None:
            pulumi.set(__self__, "ebs_volume_type", ebs_volume_type)
        if first_on_demand is not None:
            pulumi.set(__self__, "first_on_demand", first_on_demand)
        if instance_profile_arn is not None:
            pulumi.set(__self__, "instance_profile_arn", instance_profile_arn)
        if spot_bid_price_percent is not None:
            pulumi.set(__self__, "spot_bid_price_percent", spot_bid_price_percent)
        if zone_id is not None:
            pulumi.set(__self__, "zone_id", zone_id)

    @property
    @pulumi.getter
    def availability(self) -> Optional[str]:
        return pulumi.get(self, "availability")

    @property
    @pulumi.getter(name="ebsVolumeCount")
    def ebs_volume_count(self) -> Optional[int]:
        return pulumi.get(self, "ebs_volume_count")

    @property
    @pulumi.getter(name="ebsVolumeSize")
    def ebs_volume_size(self) -> Optional[int]:
        return pulumi.get(self, "ebs_volume_size")

    @property
    @pulumi.getter(name="ebsVolumeType")
    def ebs_volume_type(self) -> Optional[str]:
        return pulumi.get(self, "ebs_volume_type")

    @property
    @pulumi.getter(name="firstOnDemand")
    def first_on_demand(self) -> Optional[int]:
        return pulumi.get(self, "first_on_demand")

    @property
    @pulumi.getter(name="instanceProfileArn")
    def instance_profile_arn(self) -> Optional[str]:
        return pulumi.get(self, "instance_profile_arn")

    @property
    @pulumi.getter(name="spotBidPricePercent")
    def spot_bid_price_percent(self) -> Optional[int]:
        return pulumi.get(self, "spot_bid_price_percent")

    @property
    @pulumi.getter(name="zoneId")
    def zone_id(self) -> Optional[str]:
        return pulumi.get(self, "zone_id")


@pulumi.output_type
class JobTaskNewClusterAzureAttributes(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "firstOnDemand":
            suggest = "first_on_demand"
        elif key == "spotBidMaxPrice":
            suggest = "spot_bid_max_price"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in JobTaskNewClusterAzureAttributes. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        JobTaskNewClusterAzureAttributes.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        JobTaskNewClusterAzureAttributes.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 availability: Optional[str] = None,
                 first_on_demand: Optional[int] = None,
                 spot_bid_max_price: Optional[float] = None):
        if availability is not None:
            pulumi.set(__self__, "availability", availability)
        if first_on_demand is not None:
            pulumi.set(__self__, "first_on_demand", first_on_demand)
        if spot_bid_max_price is not None:
            pulumi.set(__self__, "spot_bid_max_price", spot_bid_max_price)

    @property
    @pulumi.getter
    def availability(self) -> Optional[str]:
        return pulumi.get(self, "availability")

    @property
    @pulumi.getter(name="firstOnDemand")
    def first_on_demand(self) -> Optional[int]:
        return pulumi.get(self, "first_on_demand")

    @property
    @pulumi.getter(name="spotBidMaxPrice")
    def spot_bid_max_price(self) -> Optional[float]:
        return pulumi.get(self, "spot_bid_max_price")


@pulumi.output_type
class JobTaskNewClusterClusterLogConf(dict):
    def __init__(__self__, *,
                 dbfs: Optional['outputs.JobTaskNewClusterClusterLogConfDbfs'] = None,
                 s3: Optional['outputs.JobTaskNewClusterClusterLogConfS3'] = None):
        if dbfs is not None:
            pulumi.set(__self__, "dbfs", dbfs)
        if s3 is not None:
            pulumi.set(__self__, "s3", s3)

    @property
    @pulumi.getter
    def dbfs(self) -> Optional['outputs.JobTaskNewClusterClusterLogConfDbfs']:
        return pulumi.get(self, "dbfs")

    @property
    @pulumi.getter
    def s3(self) -> Optional['outputs.JobTaskNewClusterClusterLogConfS3']:
        return pulumi.get(self, "s3")


@pulumi.output_type
class JobTaskNewClusterClusterLogConfDbfs(dict):
    def __init__(__self__, *,
                 destination: str):
        pulumi.set(__self__, "destination", destination)

    @property
    @pulumi.getter
    def destination(self) -> str:
        return pulumi.get(self, "destination")


@pulumi.output_type
class JobTaskNewClusterClusterLogConfS3(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "cannedAcl":
            suggest = "canned_acl"
        elif key == "enableEncryption":
            suggest = "enable_encryption"
        elif key == "encryptionType":
            suggest = "encryption_type"
        elif key == "kmsKey":
            suggest = "kms_key"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in JobTaskNewClusterClusterLogConfS3. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        JobTaskNewClusterClusterLogConfS3.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        JobTaskNewClusterClusterLogConfS3.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 destination: str,
                 canned_acl: Optional[str] = None,
                 enable_encryption: Optional[bool] = None,
                 encryption_type: Optional[str] = None,
                 endpoint: Optional[str] = None,
                 kms_key: Optional[str] = None,
                 region: Optional[str] = None):
        pulumi.set(__self__, "destination", destination)
        if canned_acl is not None:
            pulumi.set(__self__, "canned_acl", canned_acl)
        if enable_encryption is not None:
            pulumi.set(__self__, "enable_encryption", enable_encryption)
        if encryption_type is not None:
            pulumi.set(__self__, "encryption_type", encryption_type)
        if endpoint is not None:
            pulumi.set(__self__, "endpoint", endpoint)
        if kms_key is not None:
            pulumi.set(__self__, "kms_key", kms_key)
        if region is not None:
            pulumi.set(__self__, "region", region)

    @property
    @pulumi.getter
    def destination(self) -> str:
        return pulumi.get(self, "destination")

    @property
    @pulumi.getter(name="cannedAcl")
    def canned_acl(self) -> Optional[str]:
        return pulumi.get(self, "canned_acl")

    @property
    @pulumi.getter(name="enableEncryption")
    def enable_encryption(self) -> Optional[bool]:
        return pulumi.get(self, "enable_encryption")

    @property
    @pulumi.getter(name="encryptionType")
    def encryption_type(self) -> Optional[str]:
        return pulumi.get(self, "encryption_type")

    @property
    @pulumi.getter
    def endpoint(self) -> Optional[str]:
        return pulumi.get(self, "endpoint")

    @property
    @pulumi.getter(name="kmsKey")
    def kms_key(self) -> Optional[str]:
        return pulumi.get(self, "kms_key")

    @property
    @pulumi.getter
    def region(self) -> Optional[str]:
        return pulumi.get(self, "region")


@pulumi.output_type
class JobTaskNewClusterClusterMountInfo(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "localMountDirPath":
            suggest = "local_mount_dir_path"
        elif key == "networkFilesystemInfo":
            suggest = "network_filesystem_info"
        elif key == "remoteMountDirPath":
            suggest = "remote_mount_dir_path"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in JobTaskNewClusterClusterMountInfo. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        JobTaskNewClusterClusterMountInfo.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        JobTaskNewClusterClusterMountInfo.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 local_mount_dir_path: str,
                 network_filesystem_info: 'outputs.JobTaskNewClusterClusterMountInfoNetworkFilesystemInfo',
                 remote_mount_dir_path: Optional[str] = None):
        pulumi.set(__self__, "local_mount_dir_path", local_mount_dir_path)
        pulumi.set(__self__, "network_filesystem_info", network_filesystem_info)
        if remote_mount_dir_path is not None:
            pulumi.set(__self__, "remote_mount_dir_path", remote_mount_dir_path)

    @property
    @pulumi.getter(name="localMountDirPath")
    def local_mount_dir_path(self) -> str:
        return pulumi.get(self, "local_mount_dir_path")

    @property
    @pulumi.getter(name="networkFilesystemInfo")
    def network_filesystem_info(self) -> 'outputs.JobTaskNewClusterClusterMountInfoNetworkFilesystemInfo':
        return pulumi.get(self, "network_filesystem_info")

    @property
    @pulumi.getter(name="remoteMountDirPath")
    def remote_mount_dir_path(self) -> Optional[str]:
        return pulumi.get(self, "remote_mount_dir_path")


@pulumi.output_type
class JobTaskNewClusterClusterMountInfoNetworkFilesystemInfo(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "serverAddress":
            suggest = "server_address"
        elif key == "mountOptions":
            suggest = "mount_options"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in JobTaskNewClusterClusterMountInfoNetworkFilesystemInfo. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        JobTaskNewClusterClusterMountInfoNetworkFilesystemInfo.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        JobTaskNewClusterClusterMountInfoNetworkFilesystemInfo.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 server_address: str,
                 mount_options: Optional[str] = None):
        pulumi.set(__self__, "server_address", server_address)
        if mount_options is not None:
            pulumi.set(__self__, "mount_options", mount_options)

    @property
    @pulumi.getter(name="serverAddress")
    def server_address(self) -> str:
        return pulumi.get(self, "server_address")

    @property
    @pulumi.getter(name="mountOptions")
    def mount_options(self) -> Optional[str]:
        return pulumi.get(self, "mount_options")


@pulumi.output_type
class JobTaskNewClusterDockerImage(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "basicAuth":
            suggest = "basic_auth"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in JobTaskNewClusterDockerImage. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        JobTaskNewClusterDockerImage.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        JobTaskNewClusterDockerImage.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 url: str,
                 basic_auth: Optional['outputs.JobTaskNewClusterDockerImageBasicAuth'] = None):
        """
        :param str url: URL of the Git repository to use.
        """
        pulumi.set(__self__, "url", url)
        if basic_auth is not None:
            pulumi.set(__self__, "basic_auth", basic_auth)

    @property
    @pulumi.getter
    def url(self) -> str:
        """
        URL of the Git repository to use.
        """
        return pulumi.get(self, "url")

    @property
    @pulumi.getter(name="basicAuth")
    def basic_auth(self) -> Optional['outputs.JobTaskNewClusterDockerImageBasicAuth']:
        return pulumi.get(self, "basic_auth")


@pulumi.output_type
class JobTaskNewClusterDockerImageBasicAuth(dict):
    def __init__(__self__, *,
                 password: str,
                 username: str):
        pulumi.set(__self__, "password", password)
        pulumi.set(__self__, "username", username)

    @property
    @pulumi.getter
    def password(self) -> str:
        return pulumi.get(self, "password")

    @property
    @pulumi.getter
    def username(self) -> str:
        return pulumi.get(self, "username")


@pulumi.output_type
class JobTaskNewClusterGcpAttributes(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "bootDiskSize":
            suggest = "boot_disk_size"
        elif key == "googleServiceAccount":
            suggest = "google_service_account"
        elif key == "localSsdCount":
            suggest = "local_ssd_count"
        elif key == "usePreemptibleExecutors":
            suggest = "use_preemptible_executors"
        elif key == "zoneId":
            suggest = "zone_id"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in JobTaskNewClusterGcpAttributes. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        JobTaskNewClusterGcpAttributes.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        JobTaskNewClusterGcpAttributes.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 availability: Optional[str] = None,
                 boot_disk_size: Optional[int] = None,
                 google_service_account: Optional[str] = None,
                 local_ssd_count: Optional[int] = None,
                 use_preemptible_executors: Optional[bool] = None,
                 zone_id: Optional[str] = None):
        if availability is not None:
            pulumi.set(__self__, "availability", availability)
        if boot_disk_size is not None:
            pulumi.set(__self__, "boot_disk_size", boot_disk_size)
        if google_service_account is not None:
            pulumi.set(__self__, "google_service_account", google_service_account)
        if local_ssd_count is not None:
            pulumi.set(__self__, "local_ssd_count", local_ssd_count)
        if use_preemptible_executors is not None:
            pulumi.set(__self__, "use_preemptible_executors", use_preemptible_executors)
        if zone_id is not None:
            pulumi.set(__self__, "zone_id", zone_id)

    @property
    @pulumi.getter
    def availability(self) -> Optional[str]:
        return pulumi.get(self, "availability")

    @property
    @pulumi.getter(name="bootDiskSize")
    def boot_disk_size(self) -> Optional[int]:
        return pulumi.get(self, "boot_disk_size")

    @property
    @pulumi.getter(name="googleServiceAccount")
    def google_service_account(self) -> Optional[str]:
        return pulumi.get(self, "google_service_account")

    @property
    @pulumi.getter(name="localSsdCount")
    def local_ssd_count(self) -> Optional[int]:
        return pulumi.get(self, "local_ssd_count")

    @property
    @pulumi.getter(name="usePreemptibleExecutors")
    def use_preemptible_executors(self) -> Optional[bool]:
        return pulumi.get(self, "use_preemptible_executors")

    @property
    @pulumi.getter(name="zoneId")
    def zone_id(self) -> Optional[str]:
        return pulumi.get(self, "zone_id")


@pulumi.output_type
class JobTaskNewClusterInitScript(dict):
    def __init__(__self__, *,
                 abfss: Optional['outputs.JobTaskNewClusterInitScriptAbfss'] = None,
                 dbfs: Optional['outputs.JobTaskNewClusterInitScriptDbfs'] = None,
                 file: Optional['outputs.JobTaskNewClusterInitScriptFile'] = None,
                 gcs: Optional['outputs.JobTaskNewClusterInitScriptGcs'] = None,
                 s3: Optional['outputs.JobTaskNewClusterInitScriptS3'] = None,
                 volumes: Optional['outputs.JobTaskNewClusterInitScriptVolumes'] = None,
                 workspace: Optional['outputs.JobTaskNewClusterInitScriptWorkspace'] = None):
        """
        :param 'JobTaskNewClusterInitScriptFileArgs' file: block consisting of single string fields:
        """
        if abfss is not None:
            pulumi.set(__self__, "abfss", abfss)
        if dbfs is not None:
            pulumi.set(__self__, "dbfs", dbfs)
        if file is not None:
            pulumi.set(__self__, "file", file)
        if gcs is not None:
            pulumi.set(__self__, "gcs", gcs)
        if s3 is not None:
            pulumi.set(__self__, "s3", s3)
        if volumes is not None:
            pulumi.set(__self__, "volumes", volumes)
        if workspace is not None:
            pulumi.set(__self__, "workspace", workspace)

    @property
    @pulumi.getter
    def abfss(self) -> Optional['outputs.JobTaskNewClusterInitScriptAbfss']:
        return pulumi.get(self, "abfss")

    @property
    @pulumi.getter
    def dbfs(self) -> Optional['outputs.JobTaskNewClusterInitScriptDbfs']:
        warnings.warn("""For init scripts use 'volumes', 'workspace' or cloud storage location instead of 'dbfs'.""", DeprecationWarning)
        pulumi.log.warn("""dbfs is deprecated: For init scripts use 'volumes', 'workspace' or cloud storage location instead of 'dbfs'.""")

        return pulumi.get(self, "dbfs")

    @property
    @pulumi.getter
    def file(self) -> Optional['outputs.JobTaskNewClusterInitScriptFile']:
        """
        block consisting of single string fields:
        """
        return pulumi.get(self, "file")

    @property
    @pulumi.getter
    def gcs(self) -> Optional['outputs.JobTaskNewClusterInitScriptGcs']:
        return pulumi.get(self, "gcs")

    @property
    @pulumi.getter
    def s3(self) -> Optional['outputs.JobTaskNewClusterInitScriptS3']:
        return pulumi.get(self, "s3")

    @property
    @pulumi.getter
    def volumes(self) -> Optional['outputs.JobTaskNewClusterInitScriptVolumes']:
        return pulumi.get(self, "volumes")

    @property
    @pulumi.getter
    def workspace(self) -> Optional['outputs.JobTaskNewClusterInitScriptWorkspace']:
        return pulumi.get(self, "workspace")


@pulumi.output_type
class JobTaskNewClusterInitScriptAbfss(dict):
    def __init__(__self__, *,
                 destination: str):
        pulumi.set(__self__, "destination", destination)

    @property
    @pulumi.getter
    def destination(self) -> str:
        return pulumi.get(self, "destination")


@pulumi.output_type
class JobTaskNewClusterInitScriptDbfs(dict):
    def __init__(__self__, *,
                 destination: str):
        pulumi.set(__self__, "destination", destination)

    @property
    @pulumi.getter
    def destination(self) -> str:
        return pulumi.get(self, "destination")


@pulumi.output_type
class JobTaskNewClusterInitScriptFile(dict):
    def __init__(__self__, *,
                 destination: str):
        pulumi.set(__self__, "destination", destination)

    @property
    @pulumi.getter
    def destination(self) -> str:
        return pulumi.get(self, "destination")


@pulumi.output_type
class JobTaskNewClusterInitScriptGcs(dict):
    def __init__(__self__, *,
                 destination: str):
        pulumi.set(__self__, "destination", destination)

    @property
    @pulumi.getter
    def destination(self) -> str:
        return pulumi.get(self, "destination")


@pulumi.output_type
class JobTaskNewClusterInitScriptS3(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "cannedAcl":
            suggest = "canned_acl"
        elif key == "enableEncryption":
            suggest = "enable_encryption"
        elif key == "encryptionType":
            suggest = "encryption_type"
        elif key == "kmsKey":
            suggest = "kms_key"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in JobTaskNewClusterInitScriptS3. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        JobTaskNewClusterInitScriptS3.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        JobTaskNewClusterInitScriptS3.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 destination: str,
                 canned_acl: Optional[str] = None,
                 enable_encryption: Optional[bool] = None,
                 encryption_type: Optional[str] = None,
                 endpoint: Optional[str] = None,
                 kms_key: Optional[str] = None,
                 region: Optional[str] = None):
        pulumi.set(__self__, "destination", destination)
        if canned_acl is not None:
            pulumi.set(__self__, "canned_acl", canned_acl)
        if enable_encryption is not None:
            pulumi.set(__self__, "enable_encryption", enable_encryption)
        if encryption_type is not None:
            pulumi.set(__self__, "encryption_type", encryption_type)
        if endpoint is not None:
            pulumi.set(__self__, "endpoint", endpoint)
        if kms_key is not None:
            pulumi.set(__self__, "kms_key", kms_key)
        if region is not None:
            pulumi.set(__self__, "region", region)

    @property
    @pulumi.getter
    def destination(self) -> str:
        return pulumi.get(self, "destination")

    @property
    @pulumi.getter(name="cannedAcl")
    def canned_acl(self) -> Optional[str]:
        return pulumi.get(self, "canned_acl")

    @property
    @pulumi.getter(name="enableEncryption")
    def enable_encryption(self) -> Optional[bool]:
        return pulumi.get(self, "enable_encryption")

    @property
    @pulumi.getter(name="encryptionType")
    def encryption_type(self) -> Optional[str]:
        return pulumi.get(self, "encryption_type")

    @property
    @pulumi.getter
    def endpoint(self) -> Optional[str]:
        return pulumi.get(self, "endpoint")

    @property
    @pulumi.getter(name="kmsKey")
    def kms_key(self) -> Optional[str]:
        return pulumi.get(self, "kms_key")

    @property
    @pulumi.getter
    def region(self) -> Optional[str]:
        return pulumi.get(self, "region")


@pulumi.output_type
class JobTaskNewClusterInitScriptVolumes(dict):
    def __init__(__self__, *,
                 destination: str):
        pulumi.set(__self__, "destination", destination)

    @property
    @pulumi.getter
    def destination(self) -> str:
        return pulumi.get(self, "destination")


@pulumi.output_type
class JobTaskNewClusterInitScriptWorkspace(dict):
    def __init__(__self__, *,
                 destination: str):
        pulumi.set(__self__, "destination", destination)

    @property
    @pulumi.getter
    def destination(self) -> str:
        return pulumi.get(self, "destination")


@pulumi.output_type
class JobTaskNewClusterWorkloadType(dict):
    def __init__(__self__, *,
                 clients: 'outputs.JobTaskNewClusterWorkloadTypeClients'):
        pulumi.set(__self__, "clients", clients)

    @property
    @pulumi.getter
    def clients(self) -> 'outputs.JobTaskNewClusterWorkloadTypeClients':
        return pulumi.get(self, "clients")


@pulumi.output_type
class JobTaskNewClusterWorkloadTypeClients(dict):
    def __init__(__self__, *,
                 jobs: Optional[bool] = None,
                 notebooks: Optional[bool] = None):
        if jobs is not None:
            pulumi.set(__self__, "jobs", jobs)
        if notebooks is not None:
            pulumi.set(__self__, "notebooks", notebooks)

    @property
    @pulumi.getter
    def jobs(self) -> Optional[bool]:
        return pulumi.get(self, "jobs")

    @property
    @pulumi.getter
    def notebooks(self) -> Optional[bool]:
        return pulumi.get(self, "notebooks")


@pulumi.output_type
class JobTaskNotebookTask(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "notebookPath":
            suggest = "notebook_path"
        elif key == "baseParameters":
            suggest = "base_parameters"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in JobTaskNotebookTask. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        JobTaskNotebookTask.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        JobTaskNotebookTask.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 notebook_path: str,
                 base_parameters: Optional[Mapping[str, Any]] = None,
                 source: Optional[str] = None):
        """
        :param str notebook_path: The path of the Notebook to be run in the Databricks workspace or remote repository. For notebooks stored in the Databricks workspace, the path must be absolute and begin with a slash. For notebooks stored in a remote repository, the path must be relative. This field is required.
        :param Mapping[str, Any] base_parameters: (Map) Base parameters to be used for each run of this job. If the run is initiated by a call to run-now with parameters specified, the two parameters maps will be merged. If the same key is specified in base_parameters and in run-now, the value from run-now will be used. If the notebook takes a parameter that is not specified in the job’s base_parameters or the run-now override parameters, the default value from the notebook will be used. Retrieve these parameters in a notebook using `dbutils.widgets.get`.
        :param str source: Location type of the notebook, can only be `WORKSPACE` or `GIT`. When set to `WORKSPACE`, the notebook will be retrieved from the local Databricks workspace. When set to `GIT`, the notebook will be retrieved from a Git repository defined in `git_source`. If the value is empty, the task will use `GIT` if `git_source` is defined and `WORKSPACE` otherwise.
        """
        pulumi.set(__self__, "notebook_path", notebook_path)
        if base_parameters is not None:
            pulumi.set(__self__, "base_parameters", base_parameters)
        if source is not None:
            pulumi.set(__self__, "source", source)

    @property
    @pulumi.getter(name="notebookPath")
    def notebook_path(self) -> str:
        """
        The path of the Notebook to be run in the Databricks workspace or remote repository. For notebooks stored in the Databricks workspace, the path must be absolute and begin with a slash. For notebooks stored in a remote repository, the path must be relative. This field is required.
        """
        return pulumi.get(self, "notebook_path")

    @property
    @pulumi.getter(name="baseParameters")
    def base_parameters(self) -> Optional[Mapping[str, Any]]:
        """
        (Map) Base parameters to be used for each run of this job. If the run is initiated by a call to run-now with parameters specified, the two parameters maps will be merged. If the same key is specified in base_parameters and in run-now, the value from run-now will be used. If the notebook takes a parameter that is not specified in the job’s base_parameters or the run-now override parameters, the default value from the notebook will be used. Retrieve these parameters in a notebook using `dbutils.widgets.get`.
        """
        return pulumi.get(self, "base_parameters")

    @property
    @pulumi.getter
    def source(self) -> Optional[str]:
        """
        Location type of the notebook, can only be `WORKSPACE` or `GIT`. When set to `WORKSPACE`, the notebook will be retrieved from the local Databricks workspace. When set to `GIT`, the notebook will be retrieved from a Git repository defined in `git_source`. If the value is empty, the task will use `GIT` if `git_source` is defined and `WORKSPACE` otherwise.
        """
        return pulumi.get(self, "source")


@pulumi.output_type
class JobTaskNotificationSettings(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "alertOnLastAttempt":
            suggest = "alert_on_last_attempt"
        elif key == "noAlertForCanceledRuns":
            suggest = "no_alert_for_canceled_runs"
        elif key == "noAlertForSkippedRuns":
            suggest = "no_alert_for_skipped_runs"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in JobTaskNotificationSettings. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        JobTaskNotificationSettings.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        JobTaskNotificationSettings.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 alert_on_last_attempt: Optional[bool] = None,
                 no_alert_for_canceled_runs: Optional[bool] = None,
                 no_alert_for_skipped_runs: Optional[bool] = None):
        """
        :param bool alert_on_last_attempt: (Bool) do not send notifications to recipients specified in `on_start` for the retried runs and do not send notifications to recipients specified in `on_failure` until the last retry of the run.
        :param bool no_alert_for_canceled_runs: (Bool) don't send alert for cancelled runs.
        :param bool no_alert_for_skipped_runs: (Bool) don't send alert for skipped runs.
        """
        if alert_on_last_attempt is not None:
            pulumi.set(__self__, "alert_on_last_attempt", alert_on_last_attempt)
        if no_alert_for_canceled_runs is not None:
            pulumi.set(__self__, "no_alert_for_canceled_runs", no_alert_for_canceled_runs)
        if no_alert_for_skipped_runs is not None:
            pulumi.set(__self__, "no_alert_for_skipped_runs", no_alert_for_skipped_runs)

    @property
    @pulumi.getter(name="alertOnLastAttempt")
    def alert_on_last_attempt(self) -> Optional[bool]:
        """
        (Bool) do not send notifications to recipients specified in `on_start` for the retried runs and do not send notifications to recipients specified in `on_failure` until the last retry of the run.
        """
        return pulumi.get(self, "alert_on_last_attempt")

    @property
    @pulumi.getter(name="noAlertForCanceledRuns")
    def no_alert_for_canceled_runs(self) -> Optional[bool]:
        """
        (Bool) don't send alert for cancelled runs.
        """
        return pulumi.get(self, "no_alert_for_canceled_runs")

    @property
    @pulumi.getter(name="noAlertForSkippedRuns")
    def no_alert_for_skipped_runs(self) -> Optional[bool]:
        """
        (Bool) don't send alert for skipped runs.
        """
        return pulumi.get(self, "no_alert_for_skipped_runs")


@pulumi.output_type
class JobTaskPipelineTask(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "pipelineId":
            suggest = "pipeline_id"
        elif key == "fullRefresh":
            suggest = "full_refresh"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in JobTaskPipelineTask. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        JobTaskPipelineTask.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        JobTaskPipelineTask.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 pipeline_id: str,
                 full_refresh: Optional[bool] = None):
        """
        :param str pipeline_id: The pipeline's unique ID.
        :param bool full_refresh: (Bool) Specifies if there should be full refresh of the pipeline.
               
               > **Note** The following configuration blocks are only supported inside a `task` block
        """
        pulumi.set(__self__, "pipeline_id", pipeline_id)
        if full_refresh is not None:
            pulumi.set(__self__, "full_refresh", full_refresh)

    @property
    @pulumi.getter(name="pipelineId")
    def pipeline_id(self) -> str:
        """
        The pipeline's unique ID.
        """
        return pulumi.get(self, "pipeline_id")

    @property
    @pulumi.getter(name="fullRefresh")
    def full_refresh(self) -> Optional[bool]:
        """
        (Bool) Specifies if there should be full refresh of the pipeline.

        > **Note** The following configuration blocks are only supported inside a `task` block
        """
        return pulumi.get(self, "full_refresh")


@pulumi.output_type
class JobTaskPythonWheelTask(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "entryPoint":
            suggest = "entry_point"
        elif key == "namedParameters":
            suggest = "named_parameters"
        elif key == "packageName":
            suggest = "package_name"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in JobTaskPythonWheelTask. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        JobTaskPythonWheelTask.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        JobTaskPythonWheelTask.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 entry_point: Optional[str] = None,
                 named_parameters: Optional[Mapping[str, Any]] = None,
                 package_name: Optional[str] = None,
                 parameters: Optional[Sequence[str]] = None):
        """
        :param str entry_point: Python function as entry point for the task
        :param Mapping[str, Any] named_parameters: Named parameters for the task
        :param str package_name: Name of Python package
        :param Sequence[str] parameters: Parameters for the task
        """
        if entry_point is not None:
            pulumi.set(__self__, "entry_point", entry_point)
        if named_parameters is not None:
            pulumi.set(__self__, "named_parameters", named_parameters)
        if package_name is not None:
            pulumi.set(__self__, "package_name", package_name)
        if parameters is not None:
            pulumi.set(__self__, "parameters", parameters)

    @property
    @pulumi.getter(name="entryPoint")
    def entry_point(self) -> Optional[str]:
        """
        Python function as entry point for the task
        """
        return pulumi.get(self, "entry_point")

    @property
    @pulumi.getter(name="namedParameters")
    def named_parameters(self) -> Optional[Mapping[str, Any]]:
        """
        Named parameters for the task
        """
        return pulumi.get(self, "named_parameters")

    @property
    @pulumi.getter(name="packageName")
    def package_name(self) -> Optional[str]:
        """
        Name of Python package
        """
        return pulumi.get(self, "package_name")

    @property
    @pulumi.getter
    def parameters(self) -> Optional[Sequence[str]]:
        """
        Parameters for the task
        """
        return pulumi.get(self, "parameters")


@pulumi.output_type
class JobTaskRunJobTask(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "jobId":
            suggest = "job_id"
        elif key == "jobParameters":
            suggest = "job_parameters"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in JobTaskRunJobTask. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        JobTaskRunJobTask.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        JobTaskRunJobTask.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 job_id: int,
                 job_parameters: Optional[Mapping[str, Any]] = None):
        """
        :param int job_id: (String) ID of the job
        :param Mapping[str, Any] job_parameters: (Map) Job parameters for the task
        """
        pulumi.set(__self__, "job_id", job_id)
        if job_parameters is not None:
            pulumi.set(__self__, "job_parameters", job_parameters)

    @property
    @pulumi.getter(name="jobId")
    def job_id(self) -> int:
        """
        (String) ID of the job
        """
        return pulumi.get(self, "job_id")

    @property
    @pulumi.getter(name="jobParameters")
    def job_parameters(self) -> Optional[Mapping[str, Any]]:
        """
        (Map) Job parameters for the task
        """
        return pulumi.get(self, "job_parameters")


@pulumi.output_type
class JobTaskSparkJarTask(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "jarUri":
            suggest = "jar_uri"
        elif key == "mainClassName":
            suggest = "main_class_name"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in JobTaskSparkJarTask. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        JobTaskSparkJarTask.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        JobTaskSparkJarTask.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 jar_uri: Optional[str] = None,
                 main_class_name: Optional[str] = None,
                 parameters: Optional[Sequence[str]] = None):
        """
        :param str main_class_name: The full name of the class containing the main method to be executed. This class must be contained in a JAR provided as a library. The code should use `SparkContext.getOrCreate` to obtain a Spark context; otherwise, runs of the job will fail.
        :param Sequence[str] parameters: (List) Parameters passed to the main method.
        """
        if jar_uri is not None:
            pulumi.set(__self__, "jar_uri", jar_uri)
        if main_class_name is not None:
            pulumi.set(__self__, "main_class_name", main_class_name)
        if parameters is not None:
            pulumi.set(__self__, "parameters", parameters)

    @property
    @pulumi.getter(name="jarUri")
    def jar_uri(self) -> Optional[str]:
        return pulumi.get(self, "jar_uri")

    @property
    @pulumi.getter(name="mainClassName")
    def main_class_name(self) -> Optional[str]:
        """
        The full name of the class containing the main method to be executed. This class must be contained in a JAR provided as a library. The code should use `SparkContext.getOrCreate` to obtain a Spark context; otherwise, runs of the job will fail.
        """
        return pulumi.get(self, "main_class_name")

    @property
    @pulumi.getter
    def parameters(self) -> Optional[Sequence[str]]:
        """
        (List) Parameters passed to the main method.
        """
        return pulumi.get(self, "parameters")


@pulumi.output_type
class JobTaskSparkPythonTask(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "pythonFile":
            suggest = "python_file"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in JobTaskSparkPythonTask. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        JobTaskSparkPythonTask.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        JobTaskSparkPythonTask.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 python_file: str,
                 parameters: Optional[Sequence[str]] = None,
                 source: Optional[str] = None):
        """
        :param str python_file: The URI of the Python file to be executed. databricks_dbfs_file, cloud file URIs (e.g. `s3:/`, `abfss:/`, `gs:/`), workspace paths and remote repository are supported. For Python files stored in the Databricks workspace, the path must be absolute and begin with `/Repos`. For files stored in a remote repository, the path must be relative. This field is required.
        :param Sequence[str] parameters: (List) Command line parameters passed to the Python file.
        :param str source: Location type of the Python file, can only be `GIT`. When set to `GIT`, the Python file will be retrieved from a Git repository defined in `git_source`.
        """
        pulumi.set(__self__, "python_file", python_file)
        if parameters is not None:
            pulumi.set(__self__, "parameters", parameters)
        if source is not None:
            pulumi.set(__self__, "source", source)

    @property
    @pulumi.getter(name="pythonFile")
    def python_file(self) -> str:
        """
        The URI of the Python file to be executed. databricks_dbfs_file, cloud file URIs (e.g. `s3:/`, `abfss:/`, `gs:/`), workspace paths and remote repository are supported. For Python files stored in the Databricks workspace, the path must be absolute and begin with `/Repos`. For files stored in a remote repository, the path must be relative. This field is required.
        """
        return pulumi.get(self, "python_file")

    @property
    @pulumi.getter
    def parameters(self) -> Optional[Sequence[str]]:
        """
        (List) Command line parameters passed to the Python file.
        """
        return pulumi.get(self, "parameters")

    @property
    @pulumi.getter
    def source(self) -> Optional[str]:
        """
        Location type of the Python file, can only be `GIT`. When set to `GIT`, the Python file will be retrieved from a Git repository defined in `git_source`.
        """
        return pulumi.get(self, "source")


@pulumi.output_type
class JobTaskSparkSubmitTask(dict):
    def __init__(__self__, *,
                 parameters: Optional[Sequence[str]] = None):
        """
        :param Sequence[str] parameters: (List) Command-line parameters passed to spark submit.
        """
        if parameters is not None:
            pulumi.set(__self__, "parameters", parameters)

    @property
    @pulumi.getter
    def parameters(self) -> Optional[Sequence[str]]:
        """
        (List) Command-line parameters passed to spark submit.
        """
        return pulumi.get(self, "parameters")


@pulumi.output_type
class JobTaskSqlTask(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "warehouseId":
            suggest = "warehouse_id"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in JobTaskSqlTask. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        JobTaskSqlTask.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        JobTaskSqlTask.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 alert: Optional['outputs.JobTaskSqlTaskAlert'] = None,
                 dashboard: Optional['outputs.JobTaskSqlTaskDashboard'] = None,
                 file: Optional['outputs.JobTaskSqlTaskFile'] = None,
                 parameters: Optional[Mapping[str, Any]] = None,
                 query: Optional['outputs.JobTaskSqlTaskQuery'] = None,
                 warehouse_id: Optional[str] = None):
        """
        :param 'JobTaskSqlTaskAlertArgs' alert: block consisting of following fields:
        :param 'JobTaskSqlTaskDashboardArgs' dashboard: block consisting of following fields:
        :param 'JobTaskSqlTaskFileArgs' file: block consisting of single string fields:
        :param Mapping[str, Any] parameters: (Map) parameters to be used for each run of this task. The SQL alert task does not support custom parameters.
        :param 'JobTaskSqlTaskQueryArgs' query: block consisting of single string field: `query_id` - identifier of the Databricks SQL Query (databricks_sql_query).
        :param str warehouse_id: ID of the (the databricks_sql_endpoint) that will be used to execute the task.  Only Serverless & Pro warehouses are supported right now.
        """
        if alert is not None:
            pulumi.set(__self__, "alert", alert)
        if dashboard is not None:
            pulumi.set(__self__, "dashboard", dashboard)
        if file is not None:
            pulumi.set(__self__, "file", file)
        if parameters is not None:
            pulumi.set(__self__, "parameters", parameters)
        if query is not None:
            pulumi.set(__self__, "query", query)
        if warehouse_id is not None:
            pulumi.set(__self__, "warehouse_id", warehouse_id)

    @property
    @pulumi.getter
    def alert(self) -> Optional['outputs.JobTaskSqlTaskAlert']:
        """
        block consisting of following fields:
        """
        return pulumi.get(self, "alert")

    @property
    @pulumi.getter
    def dashboard(self) -> Optional['outputs.JobTaskSqlTaskDashboard']:
        """
        block consisting of following fields:
        """
        return pulumi.get(self, "dashboard")

    @property
    @pulumi.getter
    def file(self) -> Optional['outputs.JobTaskSqlTaskFile']:
        """
        block consisting of single string fields:
        """
        return pulumi.get(self, "file")

    @property
    @pulumi.getter
    def parameters(self) -> Optional[Mapping[str, Any]]:
        """
        (Map) parameters to be used for each run of this task. The SQL alert task does not support custom parameters.
        """
        return pulumi.get(self, "parameters")

    @property
    @pulumi.getter
    def query(self) -> Optional['outputs.JobTaskSqlTaskQuery']:
        """
        block consisting of single string field: `query_id` - identifier of the Databricks SQL Query (databricks_sql_query).
        """
        return pulumi.get(self, "query")

    @property
    @pulumi.getter(name="warehouseId")
    def warehouse_id(self) -> Optional[str]:
        """
        ID of the (the databricks_sql_endpoint) that will be used to execute the task.  Only Serverless & Pro warehouses are supported right now.
        """
        return pulumi.get(self, "warehouse_id")


@pulumi.output_type
class JobTaskSqlTaskAlert(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "alertId":
            suggest = "alert_id"
        elif key == "pauseSubscriptions":
            suggest = "pause_subscriptions"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in JobTaskSqlTaskAlert. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        JobTaskSqlTaskAlert.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        JobTaskSqlTaskAlert.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 alert_id: str,
                 subscriptions: Sequence['outputs.JobTaskSqlTaskAlertSubscription'],
                 pause_subscriptions: Optional[bool] = None):
        """
        :param str alert_id: (String) identifier of the Databricks SQL Alert.
        :param Sequence['JobTaskSqlTaskAlertSubscriptionArgs'] subscriptions: a list of subscription blocks consisting out of one of the required fields: `user_name` for user emails or `destination_id` - for Alert destination's identifier.
        :param bool pause_subscriptions: flag that specifies if subscriptions are paused or not.
        """
        pulumi.set(__self__, "alert_id", alert_id)
        pulumi.set(__self__, "subscriptions", subscriptions)
        if pause_subscriptions is not None:
            pulumi.set(__self__, "pause_subscriptions", pause_subscriptions)

    @property
    @pulumi.getter(name="alertId")
    def alert_id(self) -> str:
        """
        (String) identifier of the Databricks SQL Alert.
        """
        return pulumi.get(self, "alert_id")

    @property
    @pulumi.getter
    def subscriptions(self) -> Sequence['outputs.JobTaskSqlTaskAlertSubscription']:
        """
        a list of subscription blocks consisting out of one of the required fields: `user_name` for user emails or `destination_id` - for Alert destination's identifier.
        """
        return pulumi.get(self, "subscriptions")

    @property
    @pulumi.getter(name="pauseSubscriptions")
    def pause_subscriptions(self) -> Optional[bool]:
        """
        flag that specifies if subscriptions are paused or not.
        """
        return pulumi.get(self, "pause_subscriptions")


@pulumi.output_type
class JobTaskSqlTaskAlertSubscription(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "destinationId":
            suggest = "destination_id"
        elif key == "userName":
            suggest = "user_name"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in JobTaskSqlTaskAlertSubscription. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        JobTaskSqlTaskAlertSubscription.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        JobTaskSqlTaskAlertSubscription.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 destination_id: Optional[str] = None,
                 user_name: Optional[str] = None):
        """
        :param str user_name: The email of an active workspace user. Non-admin users can only set this field to their own email.
        """
        if destination_id is not None:
            pulumi.set(__self__, "destination_id", destination_id)
        if user_name is not None:
            pulumi.set(__self__, "user_name", user_name)

    @property
    @pulumi.getter(name="destinationId")
    def destination_id(self) -> Optional[str]:
        return pulumi.get(self, "destination_id")

    @property
    @pulumi.getter(name="userName")
    def user_name(self) -> Optional[str]:
        """
        The email of an active workspace user. Non-admin users can only set this field to their own email.
        """
        return pulumi.get(self, "user_name")


@pulumi.output_type
class JobTaskSqlTaskDashboard(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "dashboardId":
            suggest = "dashboard_id"
        elif key == "customSubject":
            suggest = "custom_subject"
        elif key == "pauseSubscriptions":
            suggest = "pause_subscriptions"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in JobTaskSqlTaskDashboard. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        JobTaskSqlTaskDashboard.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        JobTaskSqlTaskDashboard.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 dashboard_id: str,
                 custom_subject: Optional[str] = None,
                 pause_subscriptions: Optional[bool] = None,
                 subscriptions: Optional[Sequence['outputs.JobTaskSqlTaskDashboardSubscription']] = None):
        """
        :param str dashboard_id: (String) identifier of the Databricks SQL Dashboard databricks_sql_dashboard.
        :param str custom_subject: string specifying a custom subject of email sent.
        :param bool pause_subscriptions: flag that specifies if subscriptions are paused or not.
        :param Sequence['JobTaskSqlTaskDashboardSubscriptionArgs'] subscriptions: a list of subscription blocks consisting out of one of the required fields: `user_name` for user emails or `destination_id` - for Alert destination's identifier.
        """
        pulumi.set(__self__, "dashboard_id", dashboard_id)
        if custom_subject is not None:
            pulumi.set(__self__, "custom_subject", custom_subject)
        if pause_subscriptions is not None:
            pulumi.set(__self__, "pause_subscriptions", pause_subscriptions)
        if subscriptions is not None:
            pulumi.set(__self__, "subscriptions", subscriptions)

    @property
    @pulumi.getter(name="dashboardId")
    def dashboard_id(self) -> str:
        """
        (String) identifier of the Databricks SQL Dashboard databricks_sql_dashboard.
        """
        return pulumi.get(self, "dashboard_id")

    @property
    @pulumi.getter(name="customSubject")
    def custom_subject(self) -> Optional[str]:
        """
        string specifying a custom subject of email sent.
        """
        return pulumi.get(self, "custom_subject")

    @property
    @pulumi.getter(name="pauseSubscriptions")
    def pause_subscriptions(self) -> Optional[bool]:
        """
        flag that specifies if subscriptions are paused or not.
        """
        return pulumi.get(self, "pause_subscriptions")

    @property
    @pulumi.getter
    def subscriptions(self) -> Optional[Sequence['outputs.JobTaskSqlTaskDashboardSubscription']]:
        """
        a list of subscription blocks consisting out of one of the required fields: `user_name` for user emails or `destination_id` - for Alert destination's identifier.
        """
        return pulumi.get(self, "subscriptions")


@pulumi.output_type
class JobTaskSqlTaskDashboardSubscription(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "destinationId":
            suggest = "destination_id"
        elif key == "userName":
            suggest = "user_name"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in JobTaskSqlTaskDashboardSubscription. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        JobTaskSqlTaskDashboardSubscription.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        JobTaskSqlTaskDashboardSubscription.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 destination_id: Optional[str] = None,
                 user_name: Optional[str] = None):
        """
        :param str user_name: The email of an active workspace user. Non-admin users can only set this field to their own email.
        """
        if destination_id is not None:
            pulumi.set(__self__, "destination_id", destination_id)
        if user_name is not None:
            pulumi.set(__self__, "user_name", user_name)

    @property
    @pulumi.getter(name="destinationId")
    def destination_id(self) -> Optional[str]:
        return pulumi.get(self, "destination_id")

    @property
    @pulumi.getter(name="userName")
    def user_name(self) -> Optional[str]:
        """
        The email of an active workspace user. Non-admin users can only set this field to their own email.
        """
        return pulumi.get(self, "user_name")


@pulumi.output_type
class JobTaskSqlTaskFile(dict):
    def __init__(__self__, *,
                 path: str,
                 source: Optional[str] = None):
        """
        :param str path: If `source` is `GIT`: Relative path to the file in the repository specified in the `git_source` block with SQL commands to execute. If `source` is `WORKSPACE`: Absolute path to the file in the workspace with SQL commands to execute.
               
               Example
               
               <!--Start PulumiCodeChooser -->
               ```python
               import pulumi
               import pulumi_databricks as databricks
               
               sql_aggregation_job = databricks.Job("sqlAggregationJob", tasks=[
                   databricks.JobTaskArgs(
                       task_key="run_agg_query",
                       sql_task=databricks.JobTaskSqlTaskArgs(
                           warehouse_id=databricks_sql_endpoint["sql_job_warehouse"]["id"],
                           query=databricks.JobTaskSqlTaskQueryArgs(
                               query_id=databricks_sql_query["agg_query"]["id"],
                           ),
                       ),
                   ),
                   databricks.JobTaskArgs(
                       task_key="run_dashboard",
                       sql_task=databricks.JobTaskSqlTaskArgs(
                           warehouse_id=databricks_sql_endpoint["sql_job_warehouse"]["id"],
                           dashboard=databricks.JobTaskSqlTaskDashboardArgs(
                               dashboard_id=databricks_sql_dashboard["dash"]["id"],
                               subscriptions=[databricks.JobTaskSqlTaskDashboardSubscriptionArgs(
                                   user_name="user@domain.com",
                               )],
                           ),
                       ),
                   ),
                   databricks.JobTaskArgs(
                       task_key="run_alert",
                       sql_task=databricks.JobTaskSqlTaskArgs(
                           warehouse_id=databricks_sql_endpoint["sql_job_warehouse"]["id"],
                           alert=databricks.JobTaskSqlTaskAlertArgs(
                               alert_id=databricks_sql_alert["alert"]["id"],
                               subscriptions=[databricks.JobTaskSqlTaskAlertSubscriptionArgs(
                                   user_name="user@domain.com",
                               )],
                           ),
                       ),
                   ),
               ])
               ```
               <!--End PulumiCodeChooser -->
        :param str source: The source of the project. Possible values are `WORKSPACE` and `GIT`.  Defaults to `GIT` if a `git_source` block is present in the job definition.
        """
        pulumi.set(__self__, "path", path)
        if source is not None:
            pulumi.set(__self__, "source", source)

    @property
    @pulumi.getter
    def path(self) -> str:
        """
        If `source` is `GIT`: Relative path to the file in the repository specified in the `git_source` block with SQL commands to execute. If `source` is `WORKSPACE`: Absolute path to the file in the workspace with SQL commands to execute.

        Example

        <!--Start PulumiCodeChooser -->
        ```python
        import pulumi
        import pulumi_databricks as databricks

        sql_aggregation_job = databricks.Job("sqlAggregationJob", tasks=[
            databricks.JobTaskArgs(
                task_key="run_agg_query",
                sql_task=databricks.JobTaskSqlTaskArgs(
                    warehouse_id=databricks_sql_endpoint["sql_job_warehouse"]["id"],
                    query=databricks.JobTaskSqlTaskQueryArgs(
                        query_id=databricks_sql_query["agg_query"]["id"],
                    ),
                ),
            ),
            databricks.JobTaskArgs(
                task_key="run_dashboard",
                sql_task=databricks.JobTaskSqlTaskArgs(
                    warehouse_id=databricks_sql_endpoint["sql_job_warehouse"]["id"],
                    dashboard=databricks.JobTaskSqlTaskDashboardArgs(
                        dashboard_id=databricks_sql_dashboard["dash"]["id"],
                        subscriptions=[databricks.JobTaskSqlTaskDashboardSubscriptionArgs(
                            user_name="user@domain.com",
                        )],
                    ),
                ),
            ),
            databricks.JobTaskArgs(
                task_key="run_alert",
                sql_task=databricks.JobTaskSqlTaskArgs(
                    warehouse_id=databricks_sql_endpoint["sql_job_warehouse"]["id"],
                    alert=databricks.JobTaskSqlTaskAlertArgs(
                        alert_id=databricks_sql_alert["alert"]["id"],
                        subscriptions=[databricks.JobTaskSqlTaskAlertSubscriptionArgs(
                            user_name="user@domain.com",
                        )],
                    ),
                ),
            ),
        ])
        ```
        <!--End PulumiCodeChooser -->
        """
        return pulumi.get(self, "path")

    @property
    @pulumi.getter
    def source(self) -> Optional[str]:
        """
        The source of the project. Possible values are `WORKSPACE` and `GIT`.  Defaults to `GIT` if a `git_source` block is present in the job definition.
        """
        return pulumi.get(self, "source")


@pulumi.output_type
class JobTaskSqlTaskQuery(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "queryId":
            suggest = "query_id"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in JobTaskSqlTaskQuery. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        JobTaskSqlTaskQuery.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        JobTaskSqlTaskQuery.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 query_id: str):
        pulumi.set(__self__, "query_id", query_id)

    @property
    @pulumi.getter(name="queryId")
    def query_id(self) -> str:
        return pulumi.get(self, "query_id")


@pulumi.output_type
class JobTaskWebhookNotifications(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "onDurationWarningThresholdExceededs":
            suggest = "on_duration_warning_threshold_exceededs"
        elif key == "onFailures":
            suggest = "on_failures"
        elif key == "onStarts":
            suggest = "on_starts"
        elif key == "onSuccesses":
            suggest = "on_successes"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in JobTaskWebhookNotifications. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        JobTaskWebhookNotifications.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        JobTaskWebhookNotifications.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 on_duration_warning_threshold_exceededs: Optional[Sequence['outputs.JobTaskWebhookNotificationsOnDurationWarningThresholdExceeded']] = None,
                 on_failures: Optional[Sequence['outputs.JobTaskWebhookNotificationsOnFailure']] = None,
                 on_starts: Optional[Sequence['outputs.JobTaskWebhookNotificationsOnStart']] = None,
                 on_successes: Optional[Sequence['outputs.JobTaskWebhookNotificationsOnSuccess']] = None):
        """
        :param Sequence['JobTaskWebhookNotificationsOnDurationWarningThresholdExceededArgs'] on_duration_warning_threshold_exceededs: (List) list of notification IDs to call when the duration of a run exceeds the threshold specified by the `RUN_DURATION_SECONDS` metric in the `health` block.
               
               Note that the `id` is not to be confused with the name of the alert destination. The `id` can be retrieved through the API or the URL of Databricks UI `https://<workspace host>/sql/destinations/<notification id>?o=<workspace id>`
               
               Example
               
               <!--Start PulumiCodeChooser -->
               ```python
               import pulumi
               ```
               <!--End PulumiCodeChooser -->
        :param Sequence['JobTaskWebhookNotificationsOnFailureArgs'] on_failures: (List) list of notification IDs to call when the run fails. A maximum of 3 destinations can be specified.
        :param Sequence['JobTaskWebhookNotificationsOnStartArgs'] on_starts: (List) list of notification IDs to call when the run starts. A maximum of 3 destinations can be specified.
        :param Sequence['JobTaskWebhookNotificationsOnSuccessArgs'] on_successes: (List) list of notification IDs to call when the run completes successfully. A maximum of 3 destinations can be specified.
        """
        if on_duration_warning_threshold_exceededs is not None:
            pulumi.set(__self__, "on_duration_warning_threshold_exceededs", on_duration_warning_threshold_exceededs)
        if on_failures is not None:
            pulumi.set(__self__, "on_failures", on_failures)
        if on_starts is not None:
            pulumi.set(__self__, "on_starts", on_starts)
        if on_successes is not None:
            pulumi.set(__self__, "on_successes", on_successes)

    @property
    @pulumi.getter(name="onDurationWarningThresholdExceededs")
    def on_duration_warning_threshold_exceededs(self) -> Optional[Sequence['outputs.JobTaskWebhookNotificationsOnDurationWarningThresholdExceeded']]:
        """
        (List) list of notification IDs to call when the duration of a run exceeds the threshold specified by the `RUN_DURATION_SECONDS` metric in the `health` block.

        Note that the `id` is not to be confused with the name of the alert destination. The `id` can be retrieved through the API or the URL of Databricks UI `https://<workspace host>/sql/destinations/<notification id>?o=<workspace id>`

        Example

        <!--Start PulumiCodeChooser -->
        ```python
        import pulumi
        ```
        <!--End PulumiCodeChooser -->
        """
        return pulumi.get(self, "on_duration_warning_threshold_exceededs")

    @property
    @pulumi.getter(name="onFailures")
    def on_failures(self) -> Optional[Sequence['outputs.JobTaskWebhookNotificationsOnFailure']]:
        """
        (List) list of notification IDs to call when the run fails. A maximum of 3 destinations can be specified.
        """
        return pulumi.get(self, "on_failures")

    @property
    @pulumi.getter(name="onStarts")
    def on_starts(self) -> Optional[Sequence['outputs.JobTaskWebhookNotificationsOnStart']]:
        """
        (List) list of notification IDs to call when the run starts. A maximum of 3 destinations can be specified.
        """
        return pulumi.get(self, "on_starts")

    @property
    @pulumi.getter(name="onSuccesses")
    def on_successes(self) -> Optional[Sequence['outputs.JobTaskWebhookNotificationsOnSuccess']]:
        """
        (List) list of notification IDs to call when the run completes successfully. A maximum of 3 destinations can be specified.
        """
        return pulumi.get(self, "on_successes")


@pulumi.output_type
class JobTaskWebhookNotificationsOnDurationWarningThresholdExceeded(dict):
    def __init__(__self__, *,
                 id: Optional[str] = None):
        """
        :param str id: ID of the system notification that is notified when an event defined in `webhook_notifications` is triggered.
               
               > **Note** The following configuration blocks can be standalone or nested inside a `task` block
        """
        if id is not None:
            pulumi.set(__self__, "id", id)

    @property
    @pulumi.getter
    def id(self) -> Optional[str]:
        """
        ID of the system notification that is notified when an event defined in `webhook_notifications` is triggered.

        > **Note** The following configuration blocks can be standalone or nested inside a `task` block
        """
        return pulumi.get(self, "id")


@pulumi.output_type
class JobTaskWebhookNotificationsOnFailure(dict):
    def __init__(__self__, *,
                 id: Optional[str] = None):
        """
        :param str id: ID of the system notification that is notified when an event defined in `webhook_notifications` is triggered.
               
               > **Note** The following configuration blocks can be standalone or nested inside a `task` block
        """
        if id is not None:
            pulumi.set(__self__, "id", id)

    @property
    @pulumi.getter
    def id(self) -> Optional[str]:
        """
        ID of the system notification that is notified when an event defined in `webhook_notifications` is triggered.

        > **Note** The following configuration blocks can be standalone or nested inside a `task` block
        """
        return pulumi.get(self, "id")


@pulumi.output_type
class JobTaskWebhookNotificationsOnStart(dict):
    def __init__(__self__, *,
                 id: Optional[str] = None):
        """
        :param str id: ID of the system notification that is notified when an event defined in `webhook_notifications` is triggered.
               
               > **Note** The following configuration blocks can be standalone or nested inside a `task` block
        """
        if id is not None:
            pulumi.set(__self__, "id", id)

    @property
    @pulumi.getter
    def id(self) -> Optional[str]:
        """
        ID of the system notification that is notified when an event defined in `webhook_notifications` is triggered.

        > **Note** The following configuration blocks can be standalone or nested inside a `task` block
        """
        return pulumi.get(self, "id")


@pulumi.output_type
class JobTaskWebhookNotificationsOnSuccess(dict):
    def __init__(__self__, *,
                 id: Optional[str] = None):
        """
        :param str id: ID of the system notification that is notified when an event defined in `webhook_notifications` is triggered.
               
               > **Note** The following configuration blocks can be standalone or nested inside a `task` block
        """
        if id is not None:
            pulumi.set(__self__, "id", id)

    @property
    @pulumi.getter
    def id(self) -> Optional[str]:
        """
        ID of the system notification that is notified when an event defined in `webhook_notifications` is triggered.

        > **Note** The following configuration blocks can be standalone or nested inside a `task` block
        """
        return pulumi.get(self, "id")


@pulumi.output_type
class JobTrigger(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "fileArrival":
            suggest = "file_arrival"
        elif key == "pauseStatus":
            suggest = "pause_status"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in JobTrigger. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        JobTrigger.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        JobTrigger.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 file_arrival: 'outputs.JobTriggerFileArrival',
                 pause_status: Optional[str] = None):
        """
        :param 'JobTriggerFileArrivalArgs' file_arrival: configuration block to define a trigger for [File Arrival events](https://learn.microsoft.com/en-us/azure/databricks/workflows/jobs/file-arrival-triggers) consisting of following attributes:
        :param str pause_status: Indicate whether this trigger is paused or not. Either `PAUSED` or `UNPAUSED`. When the `pause_status` field is omitted in the block, the server will default to using `UNPAUSED` as a value for `pause_status`.
        """
        pulumi.set(__self__, "file_arrival", file_arrival)
        if pause_status is not None:
            pulumi.set(__self__, "pause_status", pause_status)

    @property
    @pulumi.getter(name="fileArrival")
    def file_arrival(self) -> 'outputs.JobTriggerFileArrival':
        """
        configuration block to define a trigger for [File Arrival events](https://learn.microsoft.com/en-us/azure/databricks/workflows/jobs/file-arrival-triggers) consisting of following attributes:
        """
        return pulumi.get(self, "file_arrival")

    @property
    @pulumi.getter(name="pauseStatus")
    def pause_status(self) -> Optional[str]:
        """
        Indicate whether this trigger is paused or not. Either `PAUSED` or `UNPAUSED`. When the `pause_status` field is omitted in the block, the server will default to using `UNPAUSED` as a value for `pause_status`.
        """
        return pulumi.get(self, "pause_status")


@pulumi.output_type
class JobTriggerFileArrival(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "minTimeBetweenTriggersSeconds":
            suggest = "min_time_between_triggers_seconds"
        elif key == "waitAfterLastChangeSeconds":
            suggest = "wait_after_last_change_seconds"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in JobTriggerFileArrival. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        JobTriggerFileArrival.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        JobTriggerFileArrival.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 url: str,
                 min_time_between_triggers_seconds: Optional[int] = None,
                 wait_after_last_change_seconds: Optional[int] = None):
        """
        :param str url: URL of the Git repository to use.
        :param int min_time_between_triggers_seconds: If set, the trigger starts a run only after the specified amount of time passed since the last time the trigger fired. The minimum allowed value is 60 seconds.
        :param int wait_after_last_change_seconds: If set, the trigger starts a run only after no file activity has occurred for the specified amount of time. This makes it possible to wait for a batch of incoming files to arrive before triggering a run. The minimum allowed value is 60 seconds.
        """
        pulumi.set(__self__, "url", url)
        if min_time_between_triggers_seconds is not None:
            pulumi.set(__self__, "min_time_between_triggers_seconds", min_time_between_triggers_seconds)
        if wait_after_last_change_seconds is not None:
            pulumi.set(__self__, "wait_after_last_change_seconds", wait_after_last_change_seconds)

    @property
    @pulumi.getter
    def url(self) -> str:
        """
        URL of the Git repository to use.
        """
        return pulumi.get(self, "url")

    @property
    @pulumi.getter(name="minTimeBetweenTriggersSeconds")
    def min_time_between_triggers_seconds(self) -> Optional[int]:
        """
        If set, the trigger starts a run only after the specified amount of time passed since the last time the trigger fired. The minimum allowed value is 60 seconds.
        """
        return pulumi.get(self, "min_time_between_triggers_seconds")

    @property
    @pulumi.getter(name="waitAfterLastChangeSeconds")
    def wait_after_last_change_seconds(self) -> Optional[int]:
        """
        If set, the trigger starts a run only after no file activity has occurred for the specified amount of time. This makes it possible to wait for a batch of incoming files to arrive before triggering a run. The minimum allowed value is 60 seconds.
        """
        return pulumi.get(self, "wait_after_last_change_seconds")


@pulumi.output_type
class JobWebhookNotifications(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "onDurationWarningThresholdExceededs":
            suggest = "on_duration_warning_threshold_exceededs"
        elif key == "onFailures":
            suggest = "on_failures"
        elif key == "onStarts":
            suggest = "on_starts"
        elif key == "onSuccesses":
            suggest = "on_successes"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in JobWebhookNotifications. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        JobWebhookNotifications.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        JobWebhookNotifications.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 on_duration_warning_threshold_exceededs: Optional[Sequence['outputs.JobWebhookNotificationsOnDurationWarningThresholdExceeded']] = None,
                 on_failures: Optional[Sequence['outputs.JobWebhookNotificationsOnFailure']] = None,
                 on_starts: Optional[Sequence['outputs.JobWebhookNotificationsOnStart']] = None,
                 on_successes: Optional[Sequence['outputs.JobWebhookNotificationsOnSuccess']] = None):
        """
        :param Sequence['JobWebhookNotificationsOnDurationWarningThresholdExceededArgs'] on_duration_warning_threshold_exceededs: (List) list of notification IDs to call when the duration of a run exceeds the threshold specified by the `RUN_DURATION_SECONDS` metric in the `health` block.
               
               Note that the `id` is not to be confused with the name of the alert destination. The `id` can be retrieved through the API or the URL of Databricks UI `https://<workspace host>/sql/destinations/<notification id>?o=<workspace id>`
               
               Example
               
               <!--Start PulumiCodeChooser -->
               ```python
               import pulumi
               ```
               <!--End PulumiCodeChooser -->
        :param Sequence['JobWebhookNotificationsOnFailureArgs'] on_failures: (List) list of notification IDs to call when the run fails. A maximum of 3 destinations can be specified.
        :param Sequence['JobWebhookNotificationsOnStartArgs'] on_starts: (List) list of notification IDs to call when the run starts. A maximum of 3 destinations can be specified.
        :param Sequence['JobWebhookNotificationsOnSuccessArgs'] on_successes: (List) list of notification IDs to call when the run completes successfully. A maximum of 3 destinations can be specified.
        """
        if on_duration_warning_threshold_exceededs is not None:
            pulumi.set(__self__, "on_duration_warning_threshold_exceededs", on_duration_warning_threshold_exceededs)
        if on_failures is not None:
            pulumi.set(__self__, "on_failures", on_failures)
        if on_starts is not None:
            pulumi.set(__self__, "on_starts", on_starts)
        if on_successes is not None:
            pulumi.set(__self__, "on_successes", on_successes)

    @property
    @pulumi.getter(name="onDurationWarningThresholdExceededs")
    def on_duration_warning_threshold_exceededs(self) -> Optional[Sequence['outputs.JobWebhookNotificationsOnDurationWarningThresholdExceeded']]:
        """
        (List) list of notification IDs to call when the duration of a run exceeds the threshold specified by the `RUN_DURATION_SECONDS` metric in the `health` block.

        Note that the `id` is not to be confused with the name of the alert destination. The `id` can be retrieved through the API or the URL of Databricks UI `https://<workspace host>/sql/destinations/<notification id>?o=<workspace id>`

        Example

        <!--Start PulumiCodeChooser -->
        ```python
        import pulumi
        ```
        <!--End PulumiCodeChooser -->
        """
        return pulumi.get(self, "on_duration_warning_threshold_exceededs")

    @property
    @pulumi.getter(name="onFailures")
    def on_failures(self) -> Optional[Sequence['outputs.JobWebhookNotificationsOnFailure']]:
        """
        (List) list of notification IDs to call when the run fails. A maximum of 3 destinations can be specified.
        """
        return pulumi.get(self, "on_failures")

    @property
    @pulumi.getter(name="onStarts")
    def on_starts(self) -> Optional[Sequence['outputs.JobWebhookNotificationsOnStart']]:
        """
        (List) list of notification IDs to call when the run starts. A maximum of 3 destinations can be specified.
        """
        return pulumi.get(self, "on_starts")

    @property
    @pulumi.getter(name="onSuccesses")
    def on_successes(self) -> Optional[Sequence['outputs.JobWebhookNotificationsOnSuccess']]:
        """
        (List) list of notification IDs to call when the run completes successfully. A maximum of 3 destinations can be specified.
        """
        return pulumi.get(self, "on_successes")


@pulumi.output_type
class JobWebhookNotificationsOnDurationWarningThresholdExceeded(dict):
    def __init__(__self__, *,
                 id: Optional[str] = None):
        """
        :param str id: ID of the system notification that is notified when an event defined in `webhook_notifications` is triggered.
               
               > **Note** The following configuration blocks can be standalone or nested inside a `task` block
        """
        if id is not None:
            pulumi.set(__self__, "id", id)

    @property
    @pulumi.getter
    def id(self) -> Optional[str]:
        """
        ID of the system notification that is notified when an event defined in `webhook_notifications` is triggered.

        > **Note** The following configuration blocks can be standalone or nested inside a `task` block
        """
        return pulumi.get(self, "id")


@pulumi.output_type
class JobWebhookNotificationsOnFailure(dict):
    def __init__(__self__, *,
                 id: Optional[str] = None):
        """
        :param str id: ID of the system notification that is notified when an event defined in `webhook_notifications` is triggered.
               
               > **Note** The following configuration blocks can be standalone or nested inside a `task` block
        """
        if id is not None:
            pulumi.set(__self__, "id", id)

    @property
    @pulumi.getter
    def id(self) -> Optional[str]:
        """
        ID of the system notification that is notified when an event defined in `webhook_notifications` is triggered.

        > **Note** The following configuration blocks can be standalone or nested inside a `task` block
        """
        return pulumi.get(self, "id")


@pulumi.output_type
class JobWebhookNotificationsOnStart(dict):
    def __init__(__self__, *,
                 id: Optional[str] = None):
        """
        :param str id: ID of the system notification that is notified when an event defined in `webhook_notifications` is triggered.
               
               > **Note** The following configuration blocks can be standalone or nested inside a `task` block
        """
        if id is not None:
            pulumi.set(__self__, "id", id)

    @property
    @pulumi.getter
    def id(self) -> Optional[str]:
        """
        ID of the system notification that is notified when an event defined in `webhook_notifications` is triggered.

        > **Note** The following configuration blocks can be standalone or nested inside a `task` block
        """
        return pulumi.get(self, "id")


@pulumi.output_type
class JobWebhookNotificationsOnSuccess(dict):
    def __init__(__self__, *,
                 id: Optional[str] = None):
        """
        :param str id: ID of the system notification that is notified when an event defined in `webhook_notifications` is triggered.
               
               > **Note** The following configuration blocks can be standalone or nested inside a `task` block
        """
        if id is not None:
            pulumi.set(__self__, "id", id)

    @property
    @pulumi.getter
    def id(self) -> Optional[str]:
        """
        ID of the system notification that is notified when an event defined in `webhook_notifications` is triggered.

        > **Note** The following configuration blocks can be standalone or nested inside a `task` block
        """
        return pulumi.get(self, "id")


@pulumi.output_type
class LibraryCran(dict):
    def __init__(__self__, *,
                 package: str,
                 repo: Optional[str] = None):
        pulumi.set(__self__, "package", package)
        if repo is not None:
            pulumi.set(__self__, "repo", repo)

    @property
    @pulumi.getter
    def package(self) -> str:
        return pulumi.get(self, "package")

    @property
    @pulumi.getter
    def repo(self) -> Optional[str]:
        return pulumi.get(self, "repo")


@pulumi.output_type
class LibraryMaven(dict):
    def __init__(__self__, *,
                 coordinates: str,
                 exclusions: Optional[Sequence[str]] = None,
                 repo: Optional[str] = None):
        pulumi.set(__self__, "coordinates", coordinates)
        if exclusions is not None:
            pulumi.set(__self__, "exclusions", exclusions)
        if repo is not None:
            pulumi.set(__self__, "repo", repo)

    @property
    @pulumi.getter
    def coordinates(self) -> str:
        return pulumi.get(self, "coordinates")

    @property
    @pulumi.getter
    def exclusions(self) -> Optional[Sequence[str]]:
        return pulumi.get(self, "exclusions")

    @property
    @pulumi.getter
    def repo(self) -> Optional[str]:
        return pulumi.get(self, "repo")


@pulumi.output_type
class LibraryPypi(dict):
    def __init__(__self__, *,
                 package: str,
                 repo: Optional[str] = None):
        pulumi.set(__self__, "package", package)
        if repo is not None:
            pulumi.set(__self__, "repo", repo)

    @property
    @pulumi.getter
    def package(self) -> str:
        return pulumi.get(self, "package")

    @property
    @pulumi.getter
    def repo(self) -> Optional[str]:
        return pulumi.get(self, "repo")


@pulumi.output_type
class MetastoreDataAccessAwsIamRole(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "roleArn":
            suggest = "role_arn"
        elif key == "externalId":
            suggest = "external_id"
        elif key == "unityCatalogIamArn":
            suggest = "unity_catalog_iam_arn"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in MetastoreDataAccessAwsIamRole. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        MetastoreDataAccessAwsIamRole.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        MetastoreDataAccessAwsIamRole.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 role_arn: str,
                 external_id: Optional[str] = None,
                 unity_catalog_iam_arn: Optional[str] = None):
        pulumi.set(__self__, "role_arn", role_arn)
        if external_id is not None:
            pulumi.set(__self__, "external_id", external_id)
        if unity_catalog_iam_arn is not None:
            pulumi.set(__self__, "unity_catalog_iam_arn", unity_catalog_iam_arn)

    @property
    @pulumi.getter(name="roleArn")
    def role_arn(self) -> str:
        return pulumi.get(self, "role_arn")

    @property
    @pulumi.getter(name="externalId")
    def external_id(self) -> Optional[str]:
        return pulumi.get(self, "external_id")

    @property
    @pulumi.getter(name="unityCatalogIamArn")
    def unity_catalog_iam_arn(self) -> Optional[str]:
        return pulumi.get(self, "unity_catalog_iam_arn")


@pulumi.output_type
class MetastoreDataAccessAzureManagedIdentity(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "accessConnectorId":
            suggest = "access_connector_id"
        elif key == "credentialId":
            suggest = "credential_id"
        elif key == "managedIdentityId":
            suggest = "managed_identity_id"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in MetastoreDataAccessAzureManagedIdentity. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        MetastoreDataAccessAzureManagedIdentity.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        MetastoreDataAccessAzureManagedIdentity.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 access_connector_id: str,
                 credential_id: Optional[str] = None,
                 managed_identity_id: Optional[str] = None):
        pulumi.set(__self__, "access_connector_id", access_connector_id)
        if credential_id is not None:
            pulumi.set(__self__, "credential_id", credential_id)
        if managed_identity_id is not None:
            pulumi.set(__self__, "managed_identity_id", managed_identity_id)

    @property
    @pulumi.getter(name="accessConnectorId")
    def access_connector_id(self) -> str:
        return pulumi.get(self, "access_connector_id")

    @property
    @pulumi.getter(name="credentialId")
    def credential_id(self) -> Optional[str]:
        return pulumi.get(self, "credential_id")

    @property
    @pulumi.getter(name="managedIdentityId")
    def managed_identity_id(self) -> Optional[str]:
        return pulumi.get(self, "managed_identity_id")


@pulumi.output_type
class MetastoreDataAccessAzureServicePrincipal(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "applicationId":
            suggest = "application_id"
        elif key == "clientSecret":
            suggest = "client_secret"
        elif key == "directoryId":
            suggest = "directory_id"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in MetastoreDataAccessAzureServicePrincipal. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        MetastoreDataAccessAzureServicePrincipal.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        MetastoreDataAccessAzureServicePrincipal.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 application_id: str,
                 client_secret: str,
                 directory_id: str):
        pulumi.set(__self__, "application_id", application_id)
        pulumi.set(__self__, "client_secret", client_secret)
        pulumi.set(__self__, "directory_id", directory_id)

    @property
    @pulumi.getter(name="applicationId")
    def application_id(self) -> str:
        return pulumi.get(self, "application_id")

    @property
    @pulumi.getter(name="clientSecret")
    def client_secret(self) -> str:
        return pulumi.get(self, "client_secret")

    @property
    @pulumi.getter(name="directoryId")
    def directory_id(self) -> str:
        return pulumi.get(self, "directory_id")


@pulumi.output_type
class MetastoreDataAccessDatabricksGcpServiceAccount(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "credentialId":
            suggest = "credential_id"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in MetastoreDataAccessDatabricksGcpServiceAccount. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        MetastoreDataAccessDatabricksGcpServiceAccount.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        MetastoreDataAccessDatabricksGcpServiceAccount.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 credential_id: Optional[str] = None,
                 email: Optional[str] = None):
        if credential_id is not None:
            pulumi.set(__self__, "credential_id", credential_id)
        if email is not None:
            pulumi.set(__self__, "email", email)

    @property
    @pulumi.getter(name="credentialId")
    def credential_id(self) -> Optional[str]:
        return pulumi.get(self, "credential_id")

    @property
    @pulumi.getter
    def email(self) -> Optional[str]:
        return pulumi.get(self, "email")


@pulumi.output_type
class MetastoreDataAccessGcpServiceAccountKey(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "privateKey":
            suggest = "private_key"
        elif key == "privateKeyId":
            suggest = "private_key_id"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in MetastoreDataAccessGcpServiceAccountKey. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        MetastoreDataAccessGcpServiceAccountKey.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        MetastoreDataAccessGcpServiceAccountKey.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 email: str,
                 private_key: str,
                 private_key_id: str):
        pulumi.set(__self__, "email", email)
        pulumi.set(__self__, "private_key", private_key)
        pulumi.set(__self__, "private_key_id", private_key_id)

    @property
    @pulumi.getter
    def email(self) -> str:
        return pulumi.get(self, "email")

    @property
    @pulumi.getter(name="privateKey")
    def private_key(self) -> str:
        return pulumi.get(self, "private_key")

    @property
    @pulumi.getter(name="privateKeyId")
    def private_key_id(self) -> str:
        return pulumi.get(self, "private_key_id")


@pulumi.output_type
class MlflowModelTag(dict):
    def __init__(__self__, *,
                 key: Optional[str] = None,
                 value: Optional[str] = None):
        if key is not None:
            pulumi.set(__self__, "key", key)
        if value is not None:
            pulumi.set(__self__, "value", value)

    @property
    @pulumi.getter
    def key(self) -> Optional[str]:
        return pulumi.get(self, "key")

    @property
    @pulumi.getter
    def value(self) -> Optional[str]:
        return pulumi.get(self, "value")


@pulumi.output_type
class MlflowWebhookHttpUrlSpec(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "enableSslVerification":
            suggest = "enable_ssl_verification"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in MlflowWebhookHttpUrlSpec. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        MlflowWebhookHttpUrlSpec.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        MlflowWebhookHttpUrlSpec.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 url: str,
                 authorization: Optional[str] = None,
                 enable_ssl_verification: Optional[bool] = None,
                 secret: Optional[str] = None):
        """
        :param str url: External HTTPS URL called on event trigger (by using a POST request). Structure of payload depends on the event type, refer to [documentation](https://docs.databricks.com/applications/mlflow/model-registry-webhooks.html) for more details.
        :param str authorization: Value of the authorization header that should be sent in the request sent by the wehbook.  It should be of the form `<auth type> <credentials>`, e.g. `Bearer <access_token>`. If set to an empty string, no authorization header will be included in the request.
        :param bool enable_ssl_verification: Enable/disable SSL certificate validation. Default is `true`. For self-signed certificates, this field must be `false` AND the destination server must disable certificate validation as well. For security purposes, it is encouraged to perform secret validation with the HMAC-encoded portion of the payload and acknowledge the risk associated with disabling hostname validation whereby it becomes more likely that requests can be maliciously routed to an unintended host.
        :param str secret: Shared secret required for HMAC encoding payload. The HMAC-encoded payload will be sent in the header as `X-Databricks-Signature: encoded_payload`.
        """
        pulumi.set(__self__, "url", url)
        if authorization is not None:
            pulumi.set(__self__, "authorization", authorization)
        if enable_ssl_verification is not None:
            pulumi.set(__self__, "enable_ssl_verification", enable_ssl_verification)
        if secret is not None:
            pulumi.set(__self__, "secret", secret)

    @property
    @pulumi.getter
    def url(self) -> str:
        """
        External HTTPS URL called on event trigger (by using a POST request). Structure of payload depends on the event type, refer to [documentation](https://docs.databricks.com/applications/mlflow/model-registry-webhooks.html) for more details.
        """
        return pulumi.get(self, "url")

    @property
    @pulumi.getter
    def authorization(self) -> Optional[str]:
        """
        Value of the authorization header that should be sent in the request sent by the wehbook.  It should be of the form `<auth type> <credentials>`, e.g. `Bearer <access_token>`. If set to an empty string, no authorization header will be included in the request.
        """
        return pulumi.get(self, "authorization")

    @property
    @pulumi.getter(name="enableSslVerification")
    def enable_ssl_verification(self) -> Optional[bool]:
        """
        Enable/disable SSL certificate validation. Default is `true`. For self-signed certificates, this field must be `false` AND the destination server must disable certificate validation as well. For security purposes, it is encouraged to perform secret validation with the HMAC-encoded portion of the payload and acknowledge the risk associated with disabling hostname validation whereby it becomes more likely that requests can be maliciously routed to an unintended host.
        """
        return pulumi.get(self, "enable_ssl_verification")

    @property
    @pulumi.getter
    def secret(self) -> Optional[str]:
        """
        Shared secret required for HMAC encoding payload. The HMAC-encoded payload will be sent in the header as `X-Databricks-Signature: encoded_payload`.
        """
        return pulumi.get(self, "secret")


@pulumi.output_type
class MlflowWebhookJobSpec(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "accessToken":
            suggest = "access_token"
        elif key == "jobId":
            suggest = "job_id"
        elif key == "workspaceUrl":
            suggest = "workspace_url"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in MlflowWebhookJobSpec. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        MlflowWebhookJobSpec.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        MlflowWebhookJobSpec.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 access_token: str,
                 job_id: str,
                 workspace_url: Optional[str] = None):
        """
        :param str access_token: The personal access token used to authorize webhook's job runs.
        :param str job_id: ID of the Databricks job that the webhook runs.
        :param str workspace_url: URL of the workspace containing the job that this webhook runs. If not specified, the job’s workspace URL is assumed to be the same as the workspace where the webhook is created.
        """
        pulumi.set(__self__, "access_token", access_token)
        pulumi.set(__self__, "job_id", job_id)
        if workspace_url is not None:
            pulumi.set(__self__, "workspace_url", workspace_url)

    @property
    @pulumi.getter(name="accessToken")
    def access_token(self) -> str:
        """
        The personal access token used to authorize webhook's job runs.
        """
        return pulumi.get(self, "access_token")

    @property
    @pulumi.getter(name="jobId")
    def job_id(self) -> str:
        """
        ID of the Databricks job that the webhook runs.
        """
        return pulumi.get(self, "job_id")

    @property
    @pulumi.getter(name="workspaceUrl")
    def workspace_url(self) -> Optional[str]:
        """
        URL of the workspace containing the job that this webhook runs. If not specified, the job’s workspace URL is assumed to be the same as the workspace where the webhook is created.
        """
        return pulumi.get(self, "workspace_url")


@pulumi.output_type
class ModelServingConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "autoCaptureConfig":
            suggest = "auto_capture_config"
        elif key == "servedModels":
            suggest = "served_models"
        elif key == "trafficConfig":
            suggest = "traffic_config"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ModelServingConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ModelServingConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ModelServingConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 auto_capture_config: Optional['outputs.ModelServingConfigAutoCaptureConfig'] = None,
                 served_models: Optional[Sequence['outputs.ModelServingConfigServedModel']] = None,
                 traffic_config: Optional['outputs.ModelServingConfigTrafficConfig'] = None):
        """
        :param Sequence['ModelServingConfigServedModelArgs'] served_models: Each block represents a served model for the endpoint to serve. A model serving endpoint can have up to 10 served models.
        :param 'ModelServingConfigTrafficConfigArgs' traffic_config: A single block represents the traffic split configuration amongst the served models.
        """
        if auto_capture_config is not None:
            pulumi.set(__self__, "auto_capture_config", auto_capture_config)
        if served_models is not None:
            pulumi.set(__self__, "served_models", served_models)
        if traffic_config is not None:
            pulumi.set(__self__, "traffic_config", traffic_config)

    @property
    @pulumi.getter(name="autoCaptureConfig")
    def auto_capture_config(self) -> Optional['outputs.ModelServingConfigAutoCaptureConfig']:
        return pulumi.get(self, "auto_capture_config")

    @property
    @pulumi.getter(name="servedModels")
    def served_models(self) -> Optional[Sequence['outputs.ModelServingConfigServedModel']]:
        """
        Each block represents a served model for the endpoint to serve. A model serving endpoint can have up to 10 served models.
        """
        return pulumi.get(self, "served_models")

    @property
    @pulumi.getter(name="trafficConfig")
    def traffic_config(self) -> Optional['outputs.ModelServingConfigTrafficConfig']:
        """
        A single block represents the traffic split configuration amongst the served models.
        """
        return pulumi.get(self, "traffic_config")


@pulumi.output_type
class ModelServingConfigAutoCaptureConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "catalogName":
            suggest = "catalog_name"
        elif key == "schemaName":
            suggest = "schema_name"
        elif key == "tableNamePrefix":
            suggest = "table_name_prefix"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ModelServingConfigAutoCaptureConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ModelServingConfigAutoCaptureConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ModelServingConfigAutoCaptureConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 catalog_name: Optional[str] = None,
                 enabled: Optional[bool] = None,
                 schema_name: Optional[str] = None,
                 table_name_prefix: Optional[str] = None):
        if catalog_name is not None:
            pulumi.set(__self__, "catalog_name", catalog_name)
        if enabled is not None:
            pulumi.set(__self__, "enabled", enabled)
        if schema_name is not None:
            pulumi.set(__self__, "schema_name", schema_name)
        if table_name_prefix is not None:
            pulumi.set(__self__, "table_name_prefix", table_name_prefix)

    @property
    @pulumi.getter(name="catalogName")
    def catalog_name(self) -> Optional[str]:
        return pulumi.get(self, "catalog_name")

    @property
    @pulumi.getter
    def enabled(self) -> Optional[bool]:
        return pulumi.get(self, "enabled")

    @property
    @pulumi.getter(name="schemaName")
    def schema_name(self) -> Optional[str]:
        return pulumi.get(self, "schema_name")

    @property
    @pulumi.getter(name="tableNamePrefix")
    def table_name_prefix(self) -> Optional[str]:
        return pulumi.get(self, "table_name_prefix")


@pulumi.output_type
class ModelServingConfigServedModel(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "modelName":
            suggest = "model_name"
        elif key == "modelVersion":
            suggest = "model_version"
        elif key == "workloadSize":
            suggest = "workload_size"
        elif key == "environmentVars":
            suggest = "environment_vars"
        elif key == "instanceProfileArn":
            suggest = "instance_profile_arn"
        elif key == "scaleToZeroEnabled":
            suggest = "scale_to_zero_enabled"
        elif key == "workloadType":
            suggest = "workload_type"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ModelServingConfigServedModel. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ModelServingConfigServedModel.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ModelServingConfigServedModel.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 model_name: str,
                 model_version: str,
                 workload_size: str,
                 environment_vars: Optional[Mapping[str, Any]] = None,
                 instance_profile_arn: Optional[str] = None,
                 name: Optional[str] = None,
                 scale_to_zero_enabled: Optional[bool] = None,
                 workload_type: Optional[str] = None):
        """
        :param str model_name: The name of the model in Databricks Model Registry to be served.
        :param str model_version: The version of the model in Databricks Model Registry to be served.
        :param str workload_size: The workload size of the served model. The workload size corresponds to a range of provisioned concurrency that the compute will autoscale between. A single unit of provisioned concurrency can process one request at a time. Valid workload sizes are "Small" (4 - 4 provisioned concurrency), "Medium" (8 - 16 provisioned concurrency), and "Large" (16 - 64 provisioned concurrency).
        :param Mapping[str, Any] environment_vars: a map of environment variable name/values that will be used for serving this model.  Environment variables may refer to Databricks secrets using the standard syntax: `{{secrets/secret_scope/secret_key}}`.
        :param str instance_profile_arn: ARN of the instance profile that the served model will use to access AWS resources.
        :param str name: The name of a served model. It must be unique across an endpoint. If not specified, this field will default to `modelname-modelversion`. A served model name can consist of alphanumeric characters, dashes, and underscores.
        :param bool scale_to_zero_enabled: Whether the compute resources for the served model should scale down to zero. If scale-to-zero is enabled, the lower bound of the provisioned concurrency for each workload size will be 0. The default value is `true`.
        :param str workload_type: The workload type of the served model. The workload type selects which type of compute to use in the endpoint. For deep learning workloads, GPU acceleration is available by selecting workload types like `GPU_SMALL` and others. See documentation for all options. The default value is `CPU`.
        """
        pulumi.set(__self__, "model_name", model_name)
        pulumi.set(__self__, "model_version", model_version)
        pulumi.set(__self__, "workload_size", workload_size)
        if environment_vars is not None:
            pulumi.set(__self__, "environment_vars", environment_vars)
        if instance_profile_arn is not None:
            pulumi.set(__self__, "instance_profile_arn", instance_profile_arn)
        if name is not None:
            pulumi.set(__self__, "name", name)
        if scale_to_zero_enabled is not None:
            pulumi.set(__self__, "scale_to_zero_enabled", scale_to_zero_enabled)
        if workload_type is not None:
            pulumi.set(__self__, "workload_type", workload_type)

    @property
    @pulumi.getter(name="modelName")
    def model_name(self) -> str:
        """
        The name of the model in Databricks Model Registry to be served.
        """
        return pulumi.get(self, "model_name")

    @property
    @pulumi.getter(name="modelVersion")
    def model_version(self) -> str:
        """
        The version of the model in Databricks Model Registry to be served.
        """
        return pulumi.get(self, "model_version")

    @property
    @pulumi.getter(name="workloadSize")
    def workload_size(self) -> str:
        """
        The workload size of the served model. The workload size corresponds to a range of provisioned concurrency that the compute will autoscale between. A single unit of provisioned concurrency can process one request at a time. Valid workload sizes are "Small" (4 - 4 provisioned concurrency), "Medium" (8 - 16 provisioned concurrency), and "Large" (16 - 64 provisioned concurrency).
        """
        return pulumi.get(self, "workload_size")

    @property
    @pulumi.getter(name="environmentVars")
    def environment_vars(self) -> Optional[Mapping[str, Any]]:
        """
        a map of environment variable name/values that will be used for serving this model.  Environment variables may refer to Databricks secrets using the standard syntax: `{{secrets/secret_scope/secret_key}}`.
        """
        return pulumi.get(self, "environment_vars")

    @property
    @pulumi.getter(name="instanceProfileArn")
    def instance_profile_arn(self) -> Optional[str]:
        """
        ARN of the instance profile that the served model will use to access AWS resources.
        """
        return pulumi.get(self, "instance_profile_arn")

    @property
    @pulumi.getter
    def name(self) -> Optional[str]:
        """
        The name of a served model. It must be unique across an endpoint. If not specified, this field will default to `modelname-modelversion`. A served model name can consist of alphanumeric characters, dashes, and underscores.
        """
        return pulumi.get(self, "name")

    @property
    @pulumi.getter(name="scaleToZeroEnabled")
    def scale_to_zero_enabled(self) -> Optional[bool]:
        """
        Whether the compute resources for the served model should scale down to zero. If scale-to-zero is enabled, the lower bound of the provisioned concurrency for each workload size will be 0. The default value is `true`.
        """
        return pulumi.get(self, "scale_to_zero_enabled")

    @property
    @pulumi.getter(name="workloadType")
    def workload_type(self) -> Optional[str]:
        """
        The workload type of the served model. The workload type selects which type of compute to use in the endpoint. For deep learning workloads, GPU acceleration is available by selecting workload types like `GPU_SMALL` and others. See documentation for all options. The default value is `CPU`.
        """
        return pulumi.get(self, "workload_type")


@pulumi.output_type
class ModelServingConfigTrafficConfig(dict):
    def __init__(__self__, *,
                 routes: Optional[Sequence['outputs.ModelServingConfigTrafficConfigRoute']] = None):
        """
        :param Sequence['ModelServingConfigTrafficConfigRouteArgs'] routes: Each block represents a route that defines traffic to each served model. Each `served_models` block needs to have a corresponding `routes` block
        """
        if routes is not None:
            pulumi.set(__self__, "routes", routes)

    @property
    @pulumi.getter
    def routes(self) -> Optional[Sequence['outputs.ModelServingConfigTrafficConfigRoute']]:
        """
        Each block represents a route that defines traffic to each served model. Each `served_models` block needs to have a corresponding `routes` block
        """
        return pulumi.get(self, "routes")


@pulumi.output_type
class ModelServingConfigTrafficConfigRoute(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "servedModelName":
            suggest = "served_model_name"
        elif key == "trafficPercentage":
            suggest = "traffic_percentage"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ModelServingConfigTrafficConfigRoute. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ModelServingConfigTrafficConfigRoute.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ModelServingConfigTrafficConfigRoute.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 served_model_name: str,
                 traffic_percentage: int):
        """
        :param str served_model_name: The name of the served model this route configures traffic for. This needs to match the name of a `served_models` block
        :param int traffic_percentage: The percentage of endpoint traffic to send to this route. It must be an integer between 0 and 100 inclusive.
        """
        pulumi.set(__self__, "served_model_name", served_model_name)
        pulumi.set(__self__, "traffic_percentage", traffic_percentage)

    @property
    @pulumi.getter(name="servedModelName")
    def served_model_name(self) -> str:
        """
        The name of the served model this route configures traffic for. This needs to match the name of a `served_models` block
        """
        return pulumi.get(self, "served_model_name")

    @property
    @pulumi.getter(name="trafficPercentage")
    def traffic_percentage(self) -> int:
        """
        The percentage of endpoint traffic to send to this route. It must be an integer between 0 and 100 inclusive.
        """
        return pulumi.get(self, "traffic_percentage")


@pulumi.output_type
class ModelServingRateLimit(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "renewalPeriod":
            suggest = "renewal_period"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ModelServingRateLimit. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ModelServingRateLimit.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ModelServingRateLimit.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 calls: int,
                 renewal_period: str,
                 key: Optional[str] = None):
        pulumi.set(__self__, "calls", calls)
        pulumi.set(__self__, "renewal_period", renewal_period)
        if key is not None:
            pulumi.set(__self__, "key", key)

    @property
    @pulumi.getter
    def calls(self) -> int:
        return pulumi.get(self, "calls")

    @property
    @pulumi.getter(name="renewalPeriod")
    def renewal_period(self) -> str:
        return pulumi.get(self, "renewal_period")

    @property
    @pulumi.getter
    def key(self) -> Optional[str]:
        return pulumi.get(self, "key")


@pulumi.output_type
class ModelServingTag(dict):
    def __init__(__self__, *,
                 key: str,
                 value: Optional[str] = None):
        pulumi.set(__self__, "key", key)
        if value is not None:
            pulumi.set(__self__, "value", value)

    @property
    @pulumi.getter
    def key(self) -> str:
        return pulumi.get(self, "key")

    @property
    @pulumi.getter
    def value(self) -> Optional[str]:
        return pulumi.get(self, "value")


@pulumi.output_type
class MountAbfs(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "clientId":
            suggest = "client_id"
        elif key == "clientSecretKey":
            suggest = "client_secret_key"
        elif key == "clientSecretScope":
            suggest = "client_secret_scope"
        elif key == "initializeFileSystem":
            suggest = "initialize_file_system"
        elif key == "containerName":
            suggest = "container_name"
        elif key == "storageAccountName":
            suggest = "storage_account_name"
        elif key == "tenantId":
            suggest = "tenant_id"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in MountAbfs. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        MountAbfs.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        MountAbfs.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 client_id: str,
                 client_secret_key: str,
                 client_secret_scope: str,
                 initialize_file_system: bool,
                 container_name: Optional[str] = None,
                 directory: Optional[str] = None,
                 storage_account_name: Optional[str] = None,
                 tenant_id: Optional[str] = None):
        pulumi.set(__self__, "client_id", client_id)
        pulumi.set(__self__, "client_secret_key", client_secret_key)
        pulumi.set(__self__, "client_secret_scope", client_secret_scope)
        pulumi.set(__self__, "initialize_file_system", initialize_file_system)
        if container_name is not None:
            pulumi.set(__self__, "container_name", container_name)
        if directory is not None:
            pulumi.set(__self__, "directory", directory)
        if storage_account_name is not None:
            pulumi.set(__self__, "storage_account_name", storage_account_name)
        if tenant_id is not None:
            pulumi.set(__self__, "tenant_id", tenant_id)

    @property
    @pulumi.getter(name="clientId")
    def client_id(self) -> str:
        return pulumi.get(self, "client_id")

    @property
    @pulumi.getter(name="clientSecretKey")
    def client_secret_key(self) -> str:
        return pulumi.get(self, "client_secret_key")

    @property
    @pulumi.getter(name="clientSecretScope")
    def client_secret_scope(self) -> str:
        return pulumi.get(self, "client_secret_scope")

    @property
    @pulumi.getter(name="initializeFileSystem")
    def initialize_file_system(self) -> bool:
        return pulumi.get(self, "initialize_file_system")

    @property
    @pulumi.getter(name="containerName")
    def container_name(self) -> Optional[str]:
        return pulumi.get(self, "container_name")

    @property
    @pulumi.getter
    def directory(self) -> Optional[str]:
        return pulumi.get(self, "directory")

    @property
    @pulumi.getter(name="storageAccountName")
    def storage_account_name(self) -> Optional[str]:
        return pulumi.get(self, "storage_account_name")

    @property
    @pulumi.getter(name="tenantId")
    def tenant_id(self) -> Optional[str]:
        return pulumi.get(self, "tenant_id")


@pulumi.output_type
class MountAdl(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "clientId":
            suggest = "client_id"
        elif key == "clientSecretKey":
            suggest = "client_secret_key"
        elif key == "clientSecretScope":
            suggest = "client_secret_scope"
        elif key == "sparkConfPrefix":
            suggest = "spark_conf_prefix"
        elif key == "storageResourceName":
            suggest = "storage_resource_name"
        elif key == "tenantId":
            suggest = "tenant_id"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in MountAdl. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        MountAdl.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        MountAdl.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 client_id: str,
                 client_secret_key: str,
                 client_secret_scope: str,
                 directory: Optional[str] = None,
                 spark_conf_prefix: Optional[str] = None,
                 storage_resource_name: Optional[str] = None,
                 tenant_id: Optional[str] = None):
        pulumi.set(__self__, "client_id", client_id)
        pulumi.set(__self__, "client_secret_key", client_secret_key)
        pulumi.set(__self__, "client_secret_scope", client_secret_scope)
        if directory is not None:
            pulumi.set(__self__, "directory", directory)
        if spark_conf_prefix is not None:
            pulumi.set(__self__, "spark_conf_prefix", spark_conf_prefix)
        if storage_resource_name is not None:
            pulumi.set(__self__, "storage_resource_name", storage_resource_name)
        if tenant_id is not None:
            pulumi.set(__self__, "tenant_id", tenant_id)

    @property
    @pulumi.getter(name="clientId")
    def client_id(self) -> str:
        return pulumi.get(self, "client_id")

    @property
    @pulumi.getter(name="clientSecretKey")
    def client_secret_key(self) -> str:
        return pulumi.get(self, "client_secret_key")

    @property
    @pulumi.getter(name="clientSecretScope")
    def client_secret_scope(self) -> str:
        return pulumi.get(self, "client_secret_scope")

    @property
    @pulumi.getter
    def directory(self) -> Optional[str]:
        return pulumi.get(self, "directory")

    @property
    @pulumi.getter(name="sparkConfPrefix")
    def spark_conf_prefix(self) -> Optional[str]:
        return pulumi.get(self, "spark_conf_prefix")

    @property
    @pulumi.getter(name="storageResourceName")
    def storage_resource_name(self) -> Optional[str]:
        return pulumi.get(self, "storage_resource_name")

    @property
    @pulumi.getter(name="tenantId")
    def tenant_id(self) -> Optional[str]:
        return pulumi.get(self, "tenant_id")


@pulumi.output_type
class MountGs(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "bucketName":
            suggest = "bucket_name"
        elif key == "serviceAccount":
            suggest = "service_account"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in MountGs. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        MountGs.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        MountGs.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 bucket_name: str,
                 service_account: Optional[str] = None):
        pulumi.set(__self__, "bucket_name", bucket_name)
        if service_account is not None:
            pulumi.set(__self__, "service_account", service_account)

    @property
    @pulumi.getter(name="bucketName")
    def bucket_name(self) -> str:
        return pulumi.get(self, "bucket_name")

    @property
    @pulumi.getter(name="serviceAccount")
    def service_account(self) -> Optional[str]:
        return pulumi.get(self, "service_account")


@pulumi.output_type
class MountS3(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "bucketName":
            suggest = "bucket_name"
        elif key == "instanceProfile":
            suggest = "instance_profile"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in MountS3. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        MountS3.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        MountS3.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 bucket_name: str,
                 instance_profile: Optional[str] = None):
        pulumi.set(__self__, "bucket_name", bucket_name)
        if instance_profile is not None:
            pulumi.set(__self__, "instance_profile", instance_profile)

    @property
    @pulumi.getter(name="bucketName")
    def bucket_name(self) -> str:
        return pulumi.get(self, "bucket_name")

    @property
    @pulumi.getter(name="instanceProfile")
    def instance_profile(self) -> Optional[str]:
        return pulumi.get(self, "instance_profile")


@pulumi.output_type
class MountWasb(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "authType":
            suggest = "auth_type"
        elif key == "tokenSecretKey":
            suggest = "token_secret_key"
        elif key == "tokenSecretScope":
            suggest = "token_secret_scope"
        elif key == "containerName":
            suggest = "container_name"
        elif key == "storageAccountName":
            suggest = "storage_account_name"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in MountWasb. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        MountWasb.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        MountWasb.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 auth_type: str,
                 token_secret_key: str,
                 token_secret_scope: str,
                 container_name: Optional[str] = None,
                 directory: Optional[str] = None,
                 storage_account_name: Optional[str] = None):
        pulumi.set(__self__, "auth_type", auth_type)
        pulumi.set(__self__, "token_secret_key", token_secret_key)
        pulumi.set(__self__, "token_secret_scope", token_secret_scope)
        if container_name is not None:
            pulumi.set(__self__, "container_name", container_name)
        if directory is not None:
            pulumi.set(__self__, "directory", directory)
        if storage_account_name is not None:
            pulumi.set(__self__, "storage_account_name", storage_account_name)

    @property
    @pulumi.getter(name="authType")
    def auth_type(self) -> str:
        return pulumi.get(self, "auth_type")

    @property
    @pulumi.getter(name="tokenSecretKey")
    def token_secret_key(self) -> str:
        return pulumi.get(self, "token_secret_key")

    @property
    @pulumi.getter(name="tokenSecretScope")
    def token_secret_scope(self) -> str:
        return pulumi.get(self, "token_secret_scope")

    @property
    @pulumi.getter(name="containerName")
    def container_name(self) -> Optional[str]:
        return pulumi.get(self, "container_name")

    @property
    @pulumi.getter
    def directory(self) -> Optional[str]:
        return pulumi.get(self, "directory")

    @property
    @pulumi.getter(name="storageAccountName")
    def storage_account_name(self) -> Optional[str]:
        return pulumi.get(self, "storage_account_name")


@pulumi.output_type
class MwsCustomerManagedKeysAwsKeyInfo(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "keyArn":
            suggest = "key_arn"
        elif key == "keyAlias":
            suggest = "key_alias"
        elif key == "keyRegion":
            suggest = "key_region"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in MwsCustomerManagedKeysAwsKeyInfo. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        MwsCustomerManagedKeysAwsKeyInfo.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        MwsCustomerManagedKeysAwsKeyInfo.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 key_arn: str,
                 key_alias: Optional[str] = None,
                 key_region: Optional[str] = None):
        """
        :param str key_arn: The AWS KMS key's Amazon Resource Name (ARN).
        :param str key_alias: The AWS KMS key alias.
        :param str key_region: (Computed) The AWS region in which KMS key is deployed to. This is not required.
        """
        pulumi.set(__self__, "key_arn", key_arn)
        if key_alias is not None:
            pulumi.set(__self__, "key_alias", key_alias)
        if key_region is not None:
            pulumi.set(__self__, "key_region", key_region)

    @property
    @pulumi.getter(name="keyArn")
    def key_arn(self) -> str:
        """
        The AWS KMS key's Amazon Resource Name (ARN).
        """
        return pulumi.get(self, "key_arn")

    @property
    @pulumi.getter(name="keyAlias")
    def key_alias(self) -> Optional[str]:
        """
        The AWS KMS key alias.
        """
        return pulumi.get(self, "key_alias")

    @property
    @pulumi.getter(name="keyRegion")
    def key_region(self) -> Optional[str]:
        """
        (Computed) The AWS region in which KMS key is deployed to. This is not required.
        """
        return pulumi.get(self, "key_region")


@pulumi.output_type
class MwsCustomerManagedKeysGcpKeyInfo(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "kmsKeyId":
            suggest = "kms_key_id"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in MwsCustomerManagedKeysGcpKeyInfo. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        MwsCustomerManagedKeysGcpKeyInfo.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        MwsCustomerManagedKeysGcpKeyInfo.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 kms_key_id: str):
        """
        :param str kms_key_id: The GCP KMS key's resource name.
        """
        pulumi.set(__self__, "kms_key_id", kms_key_id)

    @property
    @pulumi.getter(name="kmsKeyId")
    def kms_key_id(self) -> str:
        """
        The GCP KMS key's resource name.
        """
        return pulumi.get(self, "kms_key_id")


@pulumi.output_type
class MwsNetworksErrorMessage(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "errorMessage":
            suggest = "error_message"
        elif key == "errorType":
            suggest = "error_type"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in MwsNetworksErrorMessage. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        MwsNetworksErrorMessage.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        MwsNetworksErrorMessage.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 error_message: Optional[str] = None,
                 error_type: Optional[str] = None):
        if error_message is not None:
            pulumi.set(__self__, "error_message", error_message)
        if error_type is not None:
            pulumi.set(__self__, "error_type", error_type)

    @property
    @pulumi.getter(name="errorMessage")
    def error_message(self) -> Optional[str]:
        return pulumi.get(self, "error_message")

    @property
    @pulumi.getter(name="errorType")
    def error_type(self) -> Optional[str]:
        return pulumi.get(self, "error_type")


@pulumi.output_type
class MwsNetworksGcpNetworkInfo(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "networkProjectId":
            suggest = "network_project_id"
        elif key == "podIpRangeName":
            suggest = "pod_ip_range_name"
        elif key == "serviceIpRangeName":
            suggest = "service_ip_range_name"
        elif key == "subnetId":
            suggest = "subnet_id"
        elif key == "subnetRegion":
            suggest = "subnet_region"
        elif key == "vpcId":
            suggest = "vpc_id"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in MwsNetworksGcpNetworkInfo. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        MwsNetworksGcpNetworkInfo.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        MwsNetworksGcpNetworkInfo.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 network_project_id: str,
                 pod_ip_range_name: str,
                 service_ip_range_name: str,
                 subnet_id: str,
                 subnet_region: str,
                 vpc_id: str):
        """
        :param str network_project_id: The Google Cloud project ID of the VPC network.
        :param str pod_ip_range_name: The name of the secondary IP range for pods. A Databricks-managed GKE cluster uses this IP range for its pods. This secondary IP range can only be used by one workspace.
        :param str service_ip_range_name: The name of the secondary IP range for services. A Databricks-managed GKE cluster uses this IP range for its services. This secondary IP range can only be used by one workspace.
        :param str subnet_id: The ID of the subnet associated with this network.
        :param str subnet_region: The Google Cloud region of the workspace data plane. For example, `us-east4`.
        :param str vpc_id: The ID of the VPC associated with this network. VPC IDs can be used in multiple network configurations.
        """
        pulumi.set(__self__, "network_project_id", network_project_id)
        pulumi.set(__self__, "pod_ip_range_name", pod_ip_range_name)
        pulumi.set(__self__, "service_ip_range_name", service_ip_range_name)
        pulumi.set(__self__, "subnet_id", subnet_id)
        pulumi.set(__self__, "subnet_region", subnet_region)
        pulumi.set(__self__, "vpc_id", vpc_id)

    @property
    @pulumi.getter(name="networkProjectId")
    def network_project_id(self) -> str:
        """
        The Google Cloud project ID of the VPC network.
        """
        return pulumi.get(self, "network_project_id")

    @property
    @pulumi.getter(name="podIpRangeName")
    def pod_ip_range_name(self) -> str:
        """
        The name of the secondary IP range for pods. A Databricks-managed GKE cluster uses this IP range for its pods. This secondary IP range can only be used by one workspace.
        """
        return pulumi.get(self, "pod_ip_range_name")

    @property
    @pulumi.getter(name="serviceIpRangeName")
    def service_ip_range_name(self) -> str:
        """
        The name of the secondary IP range for services. A Databricks-managed GKE cluster uses this IP range for its services. This secondary IP range can only be used by one workspace.
        """
        return pulumi.get(self, "service_ip_range_name")

    @property
    @pulumi.getter(name="subnetId")
    def subnet_id(self) -> str:
        """
        The ID of the subnet associated with this network.
        """
        return pulumi.get(self, "subnet_id")

    @property
    @pulumi.getter(name="subnetRegion")
    def subnet_region(self) -> str:
        """
        The Google Cloud region of the workspace data plane. For example, `us-east4`.
        """
        return pulumi.get(self, "subnet_region")

    @property
    @pulumi.getter(name="vpcId")
    def vpc_id(self) -> str:
        """
        The ID of the VPC associated with this network. VPC IDs can be used in multiple network configurations.
        """
        return pulumi.get(self, "vpc_id")


@pulumi.output_type
class MwsNetworksVpcEndpoints(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "dataplaneRelays":
            suggest = "dataplane_relays"
        elif key == "restApis":
            suggest = "rest_apis"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in MwsNetworksVpcEndpoints. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        MwsNetworksVpcEndpoints.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        MwsNetworksVpcEndpoints.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 dataplane_relays: Sequence[str],
                 rest_apis: Sequence[str]):
        pulumi.set(__self__, "dataplane_relays", dataplane_relays)
        pulumi.set(__self__, "rest_apis", rest_apis)

    @property
    @pulumi.getter(name="dataplaneRelays")
    def dataplane_relays(self) -> Sequence[str]:
        return pulumi.get(self, "dataplane_relays")

    @property
    @pulumi.getter(name="restApis")
    def rest_apis(self) -> Sequence[str]:
        return pulumi.get(self, "rest_apis")


@pulumi.output_type
class MwsVpcEndpointGcpVpcEndpointInfo(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "endpointRegion":
            suggest = "endpoint_region"
        elif key == "projectId":
            suggest = "project_id"
        elif key == "pscEndpointName":
            suggest = "psc_endpoint_name"
        elif key == "pscConnectionId":
            suggest = "psc_connection_id"
        elif key == "serviceAttachmentId":
            suggest = "service_attachment_id"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in MwsVpcEndpointGcpVpcEndpointInfo. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        MwsVpcEndpointGcpVpcEndpointInfo.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        MwsVpcEndpointGcpVpcEndpointInfo.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 endpoint_region: str,
                 project_id: str,
                 psc_endpoint_name: str,
                 psc_connection_id: Optional[str] = None,
                 service_attachment_id: Optional[str] = None):
        """
        :param str endpoint_region: Region of the PSC endpoint.
        :param str project_id: The Google Cloud project ID of the VPC network where the PSC connection resides.
        :param str psc_endpoint_name: The name of the PSC endpoint in the Google Cloud project.
        :param str psc_connection_id: The unique ID of this PSC connection.
        :param str service_attachment_id: The service attachment this PSC connection connects to.
        """
        pulumi.set(__self__, "endpoint_region", endpoint_region)
        pulumi.set(__self__, "project_id", project_id)
        pulumi.set(__self__, "psc_endpoint_name", psc_endpoint_name)
        if psc_connection_id is not None:
            pulumi.set(__self__, "psc_connection_id", psc_connection_id)
        if service_attachment_id is not None:
            pulumi.set(__self__, "service_attachment_id", service_attachment_id)

    @property
    @pulumi.getter(name="endpointRegion")
    def endpoint_region(self) -> str:
        """
        Region of the PSC endpoint.
        """
        return pulumi.get(self, "endpoint_region")

    @property
    @pulumi.getter(name="projectId")
    def project_id(self) -> str:
        """
        The Google Cloud project ID of the VPC network where the PSC connection resides.
        """
        return pulumi.get(self, "project_id")

    @property
    @pulumi.getter(name="pscEndpointName")
    def psc_endpoint_name(self) -> str:
        """
        The name of the PSC endpoint in the Google Cloud project.
        """
        return pulumi.get(self, "psc_endpoint_name")

    @property
    @pulumi.getter(name="pscConnectionId")
    def psc_connection_id(self) -> Optional[str]:
        """
        The unique ID of this PSC connection.
        """
        return pulumi.get(self, "psc_connection_id")

    @property
    @pulumi.getter(name="serviceAttachmentId")
    def service_attachment_id(self) -> Optional[str]:
        """
        The service attachment this PSC connection connects to.
        """
        return pulumi.get(self, "service_attachment_id")


@pulumi.output_type
class MwsWorkspacesCloudResourceContainer(dict):
    def __init__(__self__, *,
                 gcp: 'outputs.MwsWorkspacesCloudResourceContainerGcp'):
        """
        :param 'MwsWorkspacesCloudResourceContainerGcpArgs' gcp: A block that consists of the following field:
        """
        pulumi.set(__self__, "gcp", gcp)

    @property
    @pulumi.getter
    def gcp(self) -> 'outputs.MwsWorkspacesCloudResourceContainerGcp':
        """
        A block that consists of the following field:
        """
        return pulumi.get(self, "gcp")


@pulumi.output_type
class MwsWorkspacesCloudResourceContainerGcp(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "projectId":
            suggest = "project_id"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in MwsWorkspacesCloudResourceContainerGcp. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        MwsWorkspacesCloudResourceContainerGcp.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        MwsWorkspacesCloudResourceContainerGcp.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 project_id: str):
        """
        :param str project_id: The Google Cloud project ID, which the workspace uses to instantiate cloud resources for your workspace.
        """
        pulumi.set(__self__, "project_id", project_id)

    @property
    @pulumi.getter(name="projectId")
    def project_id(self) -> str:
        """
        The Google Cloud project ID, which the workspace uses to instantiate cloud resources for your workspace.
        """
        return pulumi.get(self, "project_id")


@pulumi.output_type
class MwsWorkspacesExternalCustomerInfo(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "authoritativeUserEmail":
            suggest = "authoritative_user_email"
        elif key == "authoritativeUserFullName":
            suggest = "authoritative_user_full_name"
        elif key == "customerName":
            suggest = "customer_name"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in MwsWorkspacesExternalCustomerInfo. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        MwsWorkspacesExternalCustomerInfo.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        MwsWorkspacesExternalCustomerInfo.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 authoritative_user_email: str,
                 authoritative_user_full_name: str,
                 customer_name: str):
        pulumi.set(__self__, "authoritative_user_email", authoritative_user_email)
        pulumi.set(__self__, "authoritative_user_full_name", authoritative_user_full_name)
        pulumi.set(__self__, "customer_name", customer_name)

    @property
    @pulumi.getter(name="authoritativeUserEmail")
    def authoritative_user_email(self) -> str:
        return pulumi.get(self, "authoritative_user_email")

    @property
    @pulumi.getter(name="authoritativeUserFullName")
    def authoritative_user_full_name(self) -> str:
        return pulumi.get(self, "authoritative_user_full_name")

    @property
    @pulumi.getter(name="customerName")
    def customer_name(self) -> str:
        return pulumi.get(self, "customer_name")


@pulumi.output_type
class MwsWorkspacesGcpManagedNetworkConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "gkeClusterPodIpRange":
            suggest = "gke_cluster_pod_ip_range"
        elif key == "gkeClusterServiceIpRange":
            suggest = "gke_cluster_service_ip_range"
        elif key == "subnetCidr":
            suggest = "subnet_cidr"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in MwsWorkspacesGcpManagedNetworkConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        MwsWorkspacesGcpManagedNetworkConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        MwsWorkspacesGcpManagedNetworkConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 gke_cluster_pod_ip_range: str,
                 gke_cluster_service_ip_range: str,
                 subnet_cidr: str):
        pulumi.set(__self__, "gke_cluster_pod_ip_range", gke_cluster_pod_ip_range)
        pulumi.set(__self__, "gke_cluster_service_ip_range", gke_cluster_service_ip_range)
        pulumi.set(__self__, "subnet_cidr", subnet_cidr)

    @property
    @pulumi.getter(name="gkeClusterPodIpRange")
    def gke_cluster_pod_ip_range(self) -> str:
        return pulumi.get(self, "gke_cluster_pod_ip_range")

    @property
    @pulumi.getter(name="gkeClusterServiceIpRange")
    def gke_cluster_service_ip_range(self) -> str:
        return pulumi.get(self, "gke_cluster_service_ip_range")

    @property
    @pulumi.getter(name="subnetCidr")
    def subnet_cidr(self) -> str:
        return pulumi.get(self, "subnet_cidr")


@pulumi.output_type
class MwsWorkspacesGkeConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "connectivityType":
            suggest = "connectivity_type"
        elif key == "masterIpRange":
            suggest = "master_ip_range"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in MwsWorkspacesGkeConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        MwsWorkspacesGkeConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        MwsWorkspacesGkeConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 connectivity_type: str,
                 master_ip_range: str):
        """
        :param str connectivity_type: Specifies the network connectivity types for the GKE nodes and the GKE master network. Possible values are: `PRIVATE_NODE_PUBLIC_MASTER`, `PUBLIC_NODE_PUBLIC_MASTER`.
        :param str master_ip_range: The IP range from which to allocate GKE cluster master resources. This field will be ignored if GKE private cluster is not enabled. It must be exactly as big as `/28`.
        """
        pulumi.set(__self__, "connectivity_type", connectivity_type)
        pulumi.set(__self__, "master_ip_range", master_ip_range)

    @property
    @pulumi.getter(name="connectivityType")
    def connectivity_type(self) -> str:
        """
        Specifies the network connectivity types for the GKE nodes and the GKE master network. Possible values are: `PRIVATE_NODE_PUBLIC_MASTER`, `PUBLIC_NODE_PUBLIC_MASTER`.
        """
        return pulumi.get(self, "connectivity_type")

    @property
    @pulumi.getter(name="masterIpRange")
    def master_ip_range(self) -> str:
        """
        The IP range from which to allocate GKE cluster master resources. This field will be ignored if GKE private cluster is not enabled. It must be exactly as big as `/28`.
        """
        return pulumi.get(self, "master_ip_range")


@pulumi.output_type
class MwsWorkspacesToken(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "lifetimeSeconds":
            suggest = "lifetime_seconds"
        elif key == "tokenId":
            suggest = "token_id"
        elif key == "tokenValue":
            suggest = "token_value"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in MwsWorkspacesToken. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        MwsWorkspacesToken.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        MwsWorkspacesToken.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 comment: Optional[str] = None,
                 lifetime_seconds: Optional[int] = None,
                 token_id: Optional[str] = None,
                 token_value: Optional[str] = None):
        """
        :param int lifetime_seconds: Token expiry lifetime. By default its 2592000 (30 days).
        """
        if comment is not None:
            pulumi.set(__self__, "comment", comment)
        if lifetime_seconds is not None:
            pulumi.set(__self__, "lifetime_seconds", lifetime_seconds)
        if token_id is not None:
            pulumi.set(__self__, "token_id", token_id)
        if token_value is not None:
            pulumi.set(__self__, "token_value", token_value)

    @property
    @pulumi.getter
    def comment(self) -> Optional[str]:
        return pulumi.get(self, "comment")

    @property
    @pulumi.getter(name="lifetimeSeconds")
    def lifetime_seconds(self) -> Optional[int]:
        """
        Token expiry lifetime. By default its 2592000 (30 days).
        """
        return pulumi.get(self, "lifetime_seconds")

    @property
    @pulumi.getter(name="tokenId")
    def token_id(self) -> Optional[str]:
        return pulumi.get(self, "token_id")

    @property
    @pulumi.getter(name="tokenValue")
    def token_value(self) -> Optional[str]:
        return pulumi.get(self, "token_value")


@pulumi.output_type
class PermissionsAccessControl(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "permissionLevel":
            suggest = "permission_level"
        elif key == "groupName":
            suggest = "group_name"
        elif key == "servicePrincipalName":
            suggest = "service_principal_name"
        elif key == "userName":
            suggest = "user_name"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in PermissionsAccessControl. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        PermissionsAccessControl.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        PermissionsAccessControl.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 permission_level: str,
                 group_name: Optional[str] = None,
                 service_principal_name: Optional[str] = None,
                 user_name: Optional[str] = None):
        """
        :param str permission_level: permission level according to specific resource. See examples above for the reference.
               
               Exactly one of the below arguments is required:
        :param str group_name: name of the group. We recommend setting permissions on groups.
        :param str service_principal_name: Application ID of the service_principal.
        :param str user_name: name of the user.
        """
        pulumi.set(__self__, "permission_level", permission_level)
        if group_name is not None:
            pulumi.set(__self__, "group_name", group_name)
        if service_principal_name is not None:
            pulumi.set(__self__, "service_principal_name", service_principal_name)
        if user_name is not None:
            pulumi.set(__self__, "user_name", user_name)

    @property
    @pulumi.getter(name="permissionLevel")
    def permission_level(self) -> str:
        """
        permission level according to specific resource. See examples above for the reference.

        Exactly one of the below arguments is required:
        """
        return pulumi.get(self, "permission_level")

    @property
    @pulumi.getter(name="groupName")
    def group_name(self) -> Optional[str]:
        """
        name of the group. We recommend setting permissions on groups.
        """
        return pulumi.get(self, "group_name")

    @property
    @pulumi.getter(name="servicePrincipalName")
    def service_principal_name(self) -> Optional[str]:
        """
        Application ID of the service_principal.
        """
        return pulumi.get(self, "service_principal_name")

    @property
    @pulumi.getter(name="userName")
    def user_name(self) -> Optional[str]:
        """
        name of the user.
        """
        return pulumi.get(self, "user_name")


@pulumi.output_type
class PipelineCluster(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "applyPolicyDefaultValues":
            suggest = "apply_policy_default_values"
        elif key == "awsAttributes":
            suggest = "aws_attributes"
        elif key == "azureAttributes":
            suggest = "azure_attributes"
        elif key == "clusterLogConf":
            suggest = "cluster_log_conf"
        elif key == "customTags":
            suggest = "custom_tags"
        elif key == "driverInstancePoolId":
            suggest = "driver_instance_pool_id"
        elif key == "driverNodeTypeId":
            suggest = "driver_node_type_id"
        elif key == "enableLocalDiskEncryption":
            suggest = "enable_local_disk_encryption"
        elif key == "gcpAttributes":
            suggest = "gcp_attributes"
        elif key == "initScripts":
            suggest = "init_scripts"
        elif key == "instancePoolId":
            suggest = "instance_pool_id"
        elif key == "nodeTypeId":
            suggest = "node_type_id"
        elif key == "numWorkers":
            suggest = "num_workers"
        elif key == "policyId":
            suggest = "policy_id"
        elif key == "sparkConf":
            suggest = "spark_conf"
        elif key == "sparkEnvVars":
            suggest = "spark_env_vars"
        elif key == "sshPublicKeys":
            suggest = "ssh_public_keys"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in PipelineCluster. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        PipelineCluster.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        PipelineCluster.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 apply_policy_default_values: Optional[bool] = None,
                 autoscale: Optional['outputs.PipelineClusterAutoscale'] = None,
                 aws_attributes: Optional['outputs.PipelineClusterAwsAttributes'] = None,
                 azure_attributes: Optional['outputs.PipelineClusterAzureAttributes'] = None,
                 cluster_log_conf: Optional['outputs.PipelineClusterClusterLogConf'] = None,
                 custom_tags: Optional[Mapping[str, Any]] = None,
                 driver_instance_pool_id: Optional[str] = None,
                 driver_node_type_id: Optional[str] = None,
                 enable_local_disk_encryption: Optional[bool] = None,
                 gcp_attributes: Optional['outputs.PipelineClusterGcpAttributes'] = None,
                 init_scripts: Optional[Sequence['outputs.PipelineClusterInitScript']] = None,
                 instance_pool_id: Optional[str] = None,
                 label: Optional[str] = None,
                 node_type_id: Optional[str] = None,
                 num_workers: Optional[int] = None,
                 policy_id: Optional[str] = None,
                 spark_conf: Optional[Mapping[str, Any]] = None,
                 spark_env_vars: Optional[Mapping[str, Any]] = None,
                 ssh_public_keys: Optional[Sequence[str]] = None):
        if apply_policy_default_values is not None:
            pulumi.set(__self__, "apply_policy_default_values", apply_policy_default_values)
        if autoscale is not None:
            pulumi.set(__self__, "autoscale", autoscale)
        if aws_attributes is not None:
            pulumi.set(__self__, "aws_attributes", aws_attributes)
        if azure_attributes is not None:
            pulumi.set(__self__, "azure_attributes", azure_attributes)
        if cluster_log_conf is not None:
            pulumi.set(__self__, "cluster_log_conf", cluster_log_conf)
        if custom_tags is not None:
            pulumi.set(__self__, "custom_tags", custom_tags)
        if driver_instance_pool_id is not None:
            pulumi.set(__self__, "driver_instance_pool_id", driver_instance_pool_id)
        if driver_node_type_id is not None:
            pulumi.set(__self__, "driver_node_type_id", driver_node_type_id)
        if enable_local_disk_encryption is not None:
            pulumi.set(__self__, "enable_local_disk_encryption", enable_local_disk_encryption)
        if gcp_attributes is not None:
            pulumi.set(__self__, "gcp_attributes", gcp_attributes)
        if init_scripts is not None:
            pulumi.set(__self__, "init_scripts", init_scripts)
        if instance_pool_id is not None:
            pulumi.set(__self__, "instance_pool_id", instance_pool_id)
        if label is not None:
            pulumi.set(__self__, "label", label)
        if node_type_id is not None:
            pulumi.set(__self__, "node_type_id", node_type_id)
        if num_workers is not None:
            pulumi.set(__self__, "num_workers", num_workers)
        if policy_id is not None:
            pulumi.set(__self__, "policy_id", policy_id)
        if spark_conf is not None:
            pulumi.set(__self__, "spark_conf", spark_conf)
        if spark_env_vars is not None:
            pulumi.set(__self__, "spark_env_vars", spark_env_vars)
        if ssh_public_keys is not None:
            pulumi.set(__self__, "ssh_public_keys", ssh_public_keys)

    @property
    @pulumi.getter(name="applyPolicyDefaultValues")
    def apply_policy_default_values(self) -> Optional[bool]:
        return pulumi.get(self, "apply_policy_default_values")

    @property
    @pulumi.getter
    def autoscale(self) -> Optional['outputs.PipelineClusterAutoscale']:
        return pulumi.get(self, "autoscale")

    @property
    @pulumi.getter(name="awsAttributes")
    def aws_attributes(self) -> Optional['outputs.PipelineClusterAwsAttributes']:
        return pulumi.get(self, "aws_attributes")

    @property
    @pulumi.getter(name="azureAttributes")
    def azure_attributes(self) -> Optional['outputs.PipelineClusterAzureAttributes']:
        return pulumi.get(self, "azure_attributes")

    @property
    @pulumi.getter(name="clusterLogConf")
    def cluster_log_conf(self) -> Optional['outputs.PipelineClusterClusterLogConf']:
        return pulumi.get(self, "cluster_log_conf")

    @property
    @pulumi.getter(name="customTags")
    def custom_tags(self) -> Optional[Mapping[str, Any]]:
        return pulumi.get(self, "custom_tags")

    @property
    @pulumi.getter(name="driverInstancePoolId")
    def driver_instance_pool_id(self) -> Optional[str]:
        return pulumi.get(self, "driver_instance_pool_id")

    @property
    @pulumi.getter(name="driverNodeTypeId")
    def driver_node_type_id(self) -> Optional[str]:
        return pulumi.get(self, "driver_node_type_id")

    @property
    @pulumi.getter(name="enableLocalDiskEncryption")
    def enable_local_disk_encryption(self) -> Optional[bool]:
        return pulumi.get(self, "enable_local_disk_encryption")

    @property
    @pulumi.getter(name="gcpAttributes")
    def gcp_attributes(self) -> Optional['outputs.PipelineClusterGcpAttributes']:
        return pulumi.get(self, "gcp_attributes")

    @property
    @pulumi.getter(name="initScripts")
    def init_scripts(self) -> Optional[Sequence['outputs.PipelineClusterInitScript']]:
        return pulumi.get(self, "init_scripts")

    @property
    @pulumi.getter(name="instancePoolId")
    def instance_pool_id(self) -> Optional[str]:
        return pulumi.get(self, "instance_pool_id")

    @property
    @pulumi.getter
    def label(self) -> Optional[str]:
        return pulumi.get(self, "label")

    @property
    @pulumi.getter(name="nodeTypeId")
    def node_type_id(self) -> Optional[str]:
        return pulumi.get(self, "node_type_id")

    @property
    @pulumi.getter(name="numWorkers")
    def num_workers(self) -> Optional[int]:
        return pulumi.get(self, "num_workers")

    @property
    @pulumi.getter(name="policyId")
    def policy_id(self) -> Optional[str]:
        return pulumi.get(self, "policy_id")

    @property
    @pulumi.getter(name="sparkConf")
    def spark_conf(self) -> Optional[Mapping[str, Any]]:
        return pulumi.get(self, "spark_conf")

    @property
    @pulumi.getter(name="sparkEnvVars")
    def spark_env_vars(self) -> Optional[Mapping[str, Any]]:
        return pulumi.get(self, "spark_env_vars")

    @property
    @pulumi.getter(name="sshPublicKeys")
    def ssh_public_keys(self) -> Optional[Sequence[str]]:
        return pulumi.get(self, "ssh_public_keys")


@pulumi.output_type
class PipelineClusterAutoscale(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "maxWorkers":
            suggest = "max_workers"
        elif key == "minWorkers":
            suggest = "min_workers"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in PipelineClusterAutoscale. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        PipelineClusterAutoscale.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        PipelineClusterAutoscale.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 max_workers: Optional[int] = None,
                 min_workers: Optional[int] = None,
                 mode: Optional[str] = None):
        if max_workers is not None:
            pulumi.set(__self__, "max_workers", max_workers)
        if min_workers is not None:
            pulumi.set(__self__, "min_workers", min_workers)
        if mode is not None:
            pulumi.set(__self__, "mode", mode)

    @property
    @pulumi.getter(name="maxWorkers")
    def max_workers(self) -> Optional[int]:
        return pulumi.get(self, "max_workers")

    @property
    @pulumi.getter(name="minWorkers")
    def min_workers(self) -> Optional[int]:
        return pulumi.get(self, "min_workers")

    @property
    @pulumi.getter
    def mode(self) -> Optional[str]:
        return pulumi.get(self, "mode")


@pulumi.output_type
class PipelineClusterAwsAttributes(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "ebsVolumeCount":
            suggest = "ebs_volume_count"
        elif key == "ebsVolumeSize":
            suggest = "ebs_volume_size"
        elif key == "ebsVolumeType":
            suggest = "ebs_volume_type"
        elif key == "firstOnDemand":
            suggest = "first_on_demand"
        elif key == "instanceProfileArn":
            suggest = "instance_profile_arn"
        elif key == "spotBidPricePercent":
            suggest = "spot_bid_price_percent"
        elif key == "zoneId":
            suggest = "zone_id"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in PipelineClusterAwsAttributes. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        PipelineClusterAwsAttributes.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        PipelineClusterAwsAttributes.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 availability: Optional[str] = None,
                 ebs_volume_count: Optional[int] = None,
                 ebs_volume_size: Optional[int] = None,
                 ebs_volume_type: Optional[str] = None,
                 first_on_demand: Optional[int] = None,
                 instance_profile_arn: Optional[str] = None,
                 spot_bid_price_percent: Optional[int] = None,
                 zone_id: Optional[str] = None):
        if availability is not None:
            pulumi.set(__self__, "availability", availability)
        if ebs_volume_count is not None:
            pulumi.set(__self__, "ebs_volume_count", ebs_volume_count)
        if ebs_volume_size is not None:
            pulumi.set(__self__, "ebs_volume_size", ebs_volume_size)
        if ebs_volume_type is not None:
            pulumi.set(__self__, "ebs_volume_type", ebs_volume_type)
        if first_on_demand is not None:
            pulumi.set(__self__, "first_on_demand", first_on_demand)
        if instance_profile_arn is not None:
            pulumi.set(__self__, "instance_profile_arn", instance_profile_arn)
        if spot_bid_price_percent is not None:
            pulumi.set(__self__, "spot_bid_price_percent", spot_bid_price_percent)
        if zone_id is not None:
            pulumi.set(__self__, "zone_id", zone_id)

    @property
    @pulumi.getter
    def availability(self) -> Optional[str]:
        return pulumi.get(self, "availability")

    @property
    @pulumi.getter(name="ebsVolumeCount")
    def ebs_volume_count(self) -> Optional[int]:
        return pulumi.get(self, "ebs_volume_count")

    @property
    @pulumi.getter(name="ebsVolumeSize")
    def ebs_volume_size(self) -> Optional[int]:
        return pulumi.get(self, "ebs_volume_size")

    @property
    @pulumi.getter(name="ebsVolumeType")
    def ebs_volume_type(self) -> Optional[str]:
        return pulumi.get(self, "ebs_volume_type")

    @property
    @pulumi.getter(name="firstOnDemand")
    def first_on_demand(self) -> Optional[int]:
        return pulumi.get(self, "first_on_demand")

    @property
    @pulumi.getter(name="instanceProfileArn")
    def instance_profile_arn(self) -> Optional[str]:
        return pulumi.get(self, "instance_profile_arn")

    @property
    @pulumi.getter(name="spotBidPricePercent")
    def spot_bid_price_percent(self) -> Optional[int]:
        return pulumi.get(self, "spot_bid_price_percent")

    @property
    @pulumi.getter(name="zoneId")
    def zone_id(self) -> Optional[str]:
        return pulumi.get(self, "zone_id")


@pulumi.output_type
class PipelineClusterAzureAttributes(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "firstOnDemand":
            suggest = "first_on_demand"
        elif key == "spotBidMaxPrice":
            suggest = "spot_bid_max_price"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in PipelineClusterAzureAttributes. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        PipelineClusterAzureAttributes.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        PipelineClusterAzureAttributes.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 availability: Optional[str] = None,
                 first_on_demand: Optional[int] = None,
                 spot_bid_max_price: Optional[float] = None):
        if availability is not None:
            pulumi.set(__self__, "availability", availability)
        if first_on_demand is not None:
            pulumi.set(__self__, "first_on_demand", first_on_demand)
        if spot_bid_max_price is not None:
            pulumi.set(__self__, "spot_bid_max_price", spot_bid_max_price)

    @property
    @pulumi.getter
    def availability(self) -> Optional[str]:
        return pulumi.get(self, "availability")

    @property
    @pulumi.getter(name="firstOnDemand")
    def first_on_demand(self) -> Optional[int]:
        return pulumi.get(self, "first_on_demand")

    @property
    @pulumi.getter(name="spotBidMaxPrice")
    def spot_bid_max_price(self) -> Optional[float]:
        return pulumi.get(self, "spot_bid_max_price")


@pulumi.output_type
class PipelineClusterClusterLogConf(dict):
    def __init__(__self__, *,
                 dbfs: Optional['outputs.PipelineClusterClusterLogConfDbfs'] = None,
                 s3: Optional['outputs.PipelineClusterClusterLogConfS3'] = None):
        if dbfs is not None:
            pulumi.set(__self__, "dbfs", dbfs)
        if s3 is not None:
            pulumi.set(__self__, "s3", s3)

    @property
    @pulumi.getter
    def dbfs(self) -> Optional['outputs.PipelineClusterClusterLogConfDbfs']:
        return pulumi.get(self, "dbfs")

    @property
    @pulumi.getter
    def s3(self) -> Optional['outputs.PipelineClusterClusterLogConfS3']:
        return pulumi.get(self, "s3")


@pulumi.output_type
class PipelineClusterClusterLogConfDbfs(dict):
    def __init__(__self__, *,
                 destination: str):
        pulumi.set(__self__, "destination", destination)

    @property
    @pulumi.getter
    def destination(self) -> str:
        return pulumi.get(self, "destination")


@pulumi.output_type
class PipelineClusterClusterLogConfS3(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "cannedAcl":
            suggest = "canned_acl"
        elif key == "enableEncryption":
            suggest = "enable_encryption"
        elif key == "encryptionType":
            suggest = "encryption_type"
        elif key == "kmsKey":
            suggest = "kms_key"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in PipelineClusterClusterLogConfS3. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        PipelineClusterClusterLogConfS3.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        PipelineClusterClusterLogConfS3.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 destination: str,
                 canned_acl: Optional[str] = None,
                 enable_encryption: Optional[bool] = None,
                 encryption_type: Optional[str] = None,
                 endpoint: Optional[str] = None,
                 kms_key: Optional[str] = None,
                 region: Optional[str] = None):
        pulumi.set(__self__, "destination", destination)
        if canned_acl is not None:
            pulumi.set(__self__, "canned_acl", canned_acl)
        if enable_encryption is not None:
            pulumi.set(__self__, "enable_encryption", enable_encryption)
        if encryption_type is not None:
            pulumi.set(__self__, "encryption_type", encryption_type)
        if endpoint is not None:
            pulumi.set(__self__, "endpoint", endpoint)
        if kms_key is not None:
            pulumi.set(__self__, "kms_key", kms_key)
        if region is not None:
            pulumi.set(__self__, "region", region)

    @property
    @pulumi.getter
    def destination(self) -> str:
        return pulumi.get(self, "destination")

    @property
    @pulumi.getter(name="cannedAcl")
    def canned_acl(self) -> Optional[str]:
        return pulumi.get(self, "canned_acl")

    @property
    @pulumi.getter(name="enableEncryption")
    def enable_encryption(self) -> Optional[bool]:
        return pulumi.get(self, "enable_encryption")

    @property
    @pulumi.getter(name="encryptionType")
    def encryption_type(self) -> Optional[str]:
        return pulumi.get(self, "encryption_type")

    @property
    @pulumi.getter
    def endpoint(self) -> Optional[str]:
        return pulumi.get(self, "endpoint")

    @property
    @pulumi.getter(name="kmsKey")
    def kms_key(self) -> Optional[str]:
        return pulumi.get(self, "kms_key")

    @property
    @pulumi.getter
    def region(self) -> Optional[str]:
        return pulumi.get(self, "region")


@pulumi.output_type
class PipelineClusterGcpAttributes(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "googleServiceAccount":
            suggest = "google_service_account"
        elif key == "localSsdCount":
            suggest = "local_ssd_count"
        elif key == "zoneId":
            suggest = "zone_id"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in PipelineClusterGcpAttributes. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        PipelineClusterGcpAttributes.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        PipelineClusterGcpAttributes.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 availability: Optional[str] = None,
                 google_service_account: Optional[str] = None,
                 local_ssd_count: Optional[int] = None,
                 zone_id: Optional[str] = None):
        if availability is not None:
            pulumi.set(__self__, "availability", availability)
        if google_service_account is not None:
            pulumi.set(__self__, "google_service_account", google_service_account)
        if local_ssd_count is not None:
            pulumi.set(__self__, "local_ssd_count", local_ssd_count)
        if zone_id is not None:
            pulumi.set(__self__, "zone_id", zone_id)

    @property
    @pulumi.getter
    def availability(self) -> Optional[str]:
        return pulumi.get(self, "availability")

    @property
    @pulumi.getter(name="googleServiceAccount")
    def google_service_account(self) -> Optional[str]:
        return pulumi.get(self, "google_service_account")

    @property
    @pulumi.getter(name="localSsdCount")
    def local_ssd_count(self) -> Optional[int]:
        return pulumi.get(self, "local_ssd_count")

    @property
    @pulumi.getter(name="zoneId")
    def zone_id(self) -> Optional[str]:
        return pulumi.get(self, "zone_id")


@pulumi.output_type
class PipelineClusterInitScript(dict):
    def __init__(__self__, *,
                 abfss: Optional['outputs.PipelineClusterInitScriptAbfss'] = None,
                 dbfs: Optional['outputs.PipelineClusterInitScriptDbfs'] = None,
                 file: Optional['outputs.PipelineClusterInitScriptFile'] = None,
                 gcs: Optional['outputs.PipelineClusterInitScriptGcs'] = None,
                 s3: Optional['outputs.PipelineClusterInitScriptS3'] = None,
                 volumes: Optional['outputs.PipelineClusterInitScriptVolumes'] = None,
                 workspace: Optional['outputs.PipelineClusterInitScriptWorkspace'] = None):
        if abfss is not None:
            pulumi.set(__self__, "abfss", abfss)
        if dbfs is not None:
            pulumi.set(__self__, "dbfs", dbfs)
        if file is not None:
            pulumi.set(__self__, "file", file)
        if gcs is not None:
            pulumi.set(__self__, "gcs", gcs)
        if s3 is not None:
            pulumi.set(__self__, "s3", s3)
        if volumes is not None:
            pulumi.set(__self__, "volumes", volumes)
        if workspace is not None:
            pulumi.set(__self__, "workspace", workspace)

    @property
    @pulumi.getter
    def abfss(self) -> Optional['outputs.PipelineClusterInitScriptAbfss']:
        return pulumi.get(self, "abfss")

    @property
    @pulumi.getter
    def dbfs(self) -> Optional['outputs.PipelineClusterInitScriptDbfs']:
        warnings.warn("""For init scripts use 'volumes', 'workspace' or cloud storage location instead of 'dbfs'.""", DeprecationWarning)
        pulumi.log.warn("""dbfs is deprecated: For init scripts use 'volumes', 'workspace' or cloud storage location instead of 'dbfs'.""")

        return pulumi.get(self, "dbfs")

    @property
    @pulumi.getter
    def file(self) -> Optional['outputs.PipelineClusterInitScriptFile']:
        return pulumi.get(self, "file")

    @property
    @pulumi.getter
    def gcs(self) -> Optional['outputs.PipelineClusterInitScriptGcs']:
        return pulumi.get(self, "gcs")

    @property
    @pulumi.getter
    def s3(self) -> Optional['outputs.PipelineClusterInitScriptS3']:
        return pulumi.get(self, "s3")

    @property
    @pulumi.getter
    def volumes(self) -> Optional['outputs.PipelineClusterInitScriptVolumes']:
        return pulumi.get(self, "volumes")

    @property
    @pulumi.getter
    def workspace(self) -> Optional['outputs.PipelineClusterInitScriptWorkspace']:
        return pulumi.get(self, "workspace")


@pulumi.output_type
class PipelineClusterInitScriptAbfss(dict):
    def __init__(__self__, *,
                 destination: str):
        pulumi.set(__self__, "destination", destination)

    @property
    @pulumi.getter
    def destination(self) -> str:
        return pulumi.get(self, "destination")


@pulumi.output_type
class PipelineClusterInitScriptDbfs(dict):
    def __init__(__self__, *,
                 destination: str):
        pulumi.set(__self__, "destination", destination)

    @property
    @pulumi.getter
    def destination(self) -> str:
        return pulumi.get(self, "destination")


@pulumi.output_type
class PipelineClusterInitScriptFile(dict):
    def __init__(__self__, *,
                 destination: str):
        pulumi.set(__self__, "destination", destination)

    @property
    @pulumi.getter
    def destination(self) -> str:
        return pulumi.get(self, "destination")


@pulumi.output_type
class PipelineClusterInitScriptGcs(dict):
    def __init__(__self__, *,
                 destination: str):
        pulumi.set(__self__, "destination", destination)

    @property
    @pulumi.getter
    def destination(self) -> str:
        return pulumi.get(self, "destination")


@pulumi.output_type
class PipelineClusterInitScriptS3(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "cannedAcl":
            suggest = "canned_acl"
        elif key == "enableEncryption":
            suggest = "enable_encryption"
        elif key == "encryptionType":
            suggest = "encryption_type"
        elif key == "kmsKey":
            suggest = "kms_key"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in PipelineClusterInitScriptS3. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        PipelineClusterInitScriptS3.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        PipelineClusterInitScriptS3.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 destination: str,
                 canned_acl: Optional[str] = None,
                 enable_encryption: Optional[bool] = None,
                 encryption_type: Optional[str] = None,
                 endpoint: Optional[str] = None,
                 kms_key: Optional[str] = None,
                 region: Optional[str] = None):
        pulumi.set(__self__, "destination", destination)
        if canned_acl is not None:
            pulumi.set(__self__, "canned_acl", canned_acl)
        if enable_encryption is not None:
            pulumi.set(__self__, "enable_encryption", enable_encryption)
        if encryption_type is not None:
            pulumi.set(__self__, "encryption_type", encryption_type)
        if endpoint is not None:
            pulumi.set(__self__, "endpoint", endpoint)
        if kms_key is not None:
            pulumi.set(__self__, "kms_key", kms_key)
        if region is not None:
            pulumi.set(__self__, "region", region)

    @property
    @pulumi.getter
    def destination(self) -> str:
        return pulumi.get(self, "destination")

    @property
    @pulumi.getter(name="cannedAcl")
    def canned_acl(self) -> Optional[str]:
        return pulumi.get(self, "canned_acl")

    @property
    @pulumi.getter(name="enableEncryption")
    def enable_encryption(self) -> Optional[bool]:
        return pulumi.get(self, "enable_encryption")

    @property
    @pulumi.getter(name="encryptionType")
    def encryption_type(self) -> Optional[str]:
        return pulumi.get(self, "encryption_type")

    @property
    @pulumi.getter
    def endpoint(self) -> Optional[str]:
        return pulumi.get(self, "endpoint")

    @property
    @pulumi.getter(name="kmsKey")
    def kms_key(self) -> Optional[str]:
        return pulumi.get(self, "kms_key")

    @property
    @pulumi.getter
    def region(self) -> Optional[str]:
        return pulumi.get(self, "region")


@pulumi.output_type
class PipelineClusterInitScriptVolumes(dict):
    def __init__(__self__, *,
                 destination: str):
        pulumi.set(__self__, "destination", destination)

    @property
    @pulumi.getter
    def destination(self) -> str:
        return pulumi.get(self, "destination")


@pulumi.output_type
class PipelineClusterInitScriptWorkspace(dict):
    def __init__(__self__, *,
                 destination: str):
        pulumi.set(__self__, "destination", destination)

    @property
    @pulumi.getter
    def destination(self) -> str:
        return pulumi.get(self, "destination")


@pulumi.output_type
class PipelineFilters(dict):
    def __init__(__self__, *,
                 excludes: Optional[Sequence[str]] = None,
                 includes: Optional[Sequence[str]] = None):
        if excludes is not None:
            pulumi.set(__self__, "excludes", excludes)
        if includes is not None:
            pulumi.set(__self__, "includes", includes)

    @property
    @pulumi.getter
    def excludes(self) -> Optional[Sequence[str]]:
        return pulumi.get(self, "excludes")

    @property
    @pulumi.getter
    def includes(self) -> Optional[Sequence[str]]:
        return pulumi.get(self, "includes")


@pulumi.output_type
class PipelineLibrary(dict):
    def __init__(__self__, *,
                 file: Optional['outputs.PipelineLibraryFile'] = None,
                 jar: Optional[str] = None,
                 maven: Optional['outputs.PipelineLibraryMaven'] = None,
                 notebook: Optional['outputs.PipelineLibraryNotebook'] = None,
                 whl: Optional[str] = None):
        if file is not None:
            pulumi.set(__self__, "file", file)
        if jar is not None:
            pulumi.set(__self__, "jar", jar)
        if maven is not None:
            pulumi.set(__self__, "maven", maven)
        if notebook is not None:
            pulumi.set(__self__, "notebook", notebook)
        if whl is not None:
            pulumi.set(__self__, "whl", whl)

    @property
    @pulumi.getter
    def file(self) -> Optional['outputs.PipelineLibraryFile']:
        return pulumi.get(self, "file")

    @property
    @pulumi.getter
    def jar(self) -> Optional[str]:
        return pulumi.get(self, "jar")

    @property
    @pulumi.getter
    def maven(self) -> Optional['outputs.PipelineLibraryMaven']:
        return pulumi.get(self, "maven")

    @property
    @pulumi.getter
    def notebook(self) -> Optional['outputs.PipelineLibraryNotebook']:
        return pulumi.get(self, "notebook")

    @property
    @pulumi.getter
    def whl(self) -> Optional[str]:
        return pulumi.get(self, "whl")


@pulumi.output_type
class PipelineLibraryFile(dict):
    def __init__(__self__, *,
                 path: str):
        pulumi.set(__self__, "path", path)

    @property
    @pulumi.getter
    def path(self) -> str:
        return pulumi.get(self, "path")


@pulumi.output_type
class PipelineLibraryMaven(dict):
    def __init__(__self__, *,
                 coordinates: str,
                 exclusions: Optional[Sequence[str]] = None,
                 repo: Optional[str] = None):
        pulumi.set(__self__, "coordinates", coordinates)
        if exclusions is not None:
            pulumi.set(__self__, "exclusions", exclusions)
        if repo is not None:
            pulumi.set(__self__, "repo", repo)

    @property
    @pulumi.getter
    def coordinates(self) -> str:
        return pulumi.get(self, "coordinates")

    @property
    @pulumi.getter
    def exclusions(self) -> Optional[Sequence[str]]:
        return pulumi.get(self, "exclusions")

    @property
    @pulumi.getter
    def repo(self) -> Optional[str]:
        return pulumi.get(self, "repo")


@pulumi.output_type
class PipelineLibraryNotebook(dict):
    def __init__(__self__, *,
                 path: str):
        pulumi.set(__self__, "path", path)

    @property
    @pulumi.getter
    def path(self) -> str:
        return pulumi.get(self, "path")


@pulumi.output_type
class PipelineNotification(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "emailRecipients":
            suggest = "email_recipients"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in PipelineNotification. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        PipelineNotification.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        PipelineNotification.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 alerts: Sequence[str],
                 email_recipients: Sequence[str]):
        """
        :param Sequence[str] alerts: non-empty list of alert types. Right now following alert types are supported, consult documentation for actual list
               * `on-update-success` - a pipeline update completes successfully.
               * `on-update-failure` - a pipeline update fails with a retryable error.
               * `on-update-fatal-failure` - a pipeline update fails with a non-retryable (fatal) error.
               * `on-flow-failure` - a single data flow fails.
        :param Sequence[str] email_recipients: non-empty list of emails to notify.
        """
        pulumi.set(__self__, "alerts", alerts)
        pulumi.set(__self__, "email_recipients", email_recipients)

    @property
    @pulumi.getter
    def alerts(self) -> Sequence[str]:
        """
        non-empty list of alert types. Right now following alert types are supported, consult documentation for actual list
        * `on-update-success` - a pipeline update completes successfully.
        * `on-update-failure` - a pipeline update fails with a retryable error.
        * `on-update-fatal-failure` - a pipeline update fails with a non-retryable (fatal) error.
        * `on-flow-failure` - a single data flow fails.
        """
        return pulumi.get(self, "alerts")

    @property
    @pulumi.getter(name="emailRecipients")
    def email_recipients(self) -> Sequence[str]:
        """
        non-empty list of emails to notify.
        """
        return pulumi.get(self, "email_recipients")


@pulumi.output_type
class RecipientIpAccessList(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "allowedIpAddresses":
            suggest = "allowed_ip_addresses"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in RecipientIpAccessList. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        RecipientIpAccessList.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        RecipientIpAccessList.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 allowed_ip_addresses: Sequence[str]):
        """
        :param Sequence[str] allowed_ip_addresses: Allowed IP Addresses in CIDR notation. Limit of 100.
        """
        pulumi.set(__self__, "allowed_ip_addresses", allowed_ip_addresses)

    @property
    @pulumi.getter(name="allowedIpAddresses")
    def allowed_ip_addresses(self) -> Sequence[str]:
        """
        Allowed IP Addresses in CIDR notation. Limit of 100.
        """
        return pulumi.get(self, "allowed_ip_addresses")


@pulumi.output_type
class RecipientToken(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "activationUrl":
            suggest = "activation_url"
        elif key == "createdAt":
            suggest = "created_at"
        elif key == "createdBy":
            suggest = "created_by"
        elif key == "expirationTime":
            suggest = "expiration_time"
        elif key == "updatedAt":
            suggest = "updated_at"
        elif key == "updatedBy":
            suggest = "updated_by"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in RecipientToken. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        RecipientToken.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        RecipientToken.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 activation_url: Optional[str] = None,
                 created_at: Optional[int] = None,
                 created_by: Optional[str] = None,
                 expiration_time: Optional[int] = None,
                 id: Optional[str] = None,
                 updated_at: Optional[int] = None,
                 updated_by: Optional[str] = None):
        """
        :param str activation_url: Full activation URL to retrieve the access token. It will be empty if the token is already retrieved.
        :param int created_at: Time at which this recipient Token was created, in epoch milliseconds.
        :param str created_by: Username of recipient token creator.
        :param int expiration_time: Expiration timestamp of the token in epoch milliseconds.
        :param str id: ID of this recipient - same as the `name`.
        :param int updated_at: Time at which this recipient Token was updated, in epoch milliseconds.
        :param str updated_by: Username of recipient Token updater.
        """
        if activation_url is not None:
            pulumi.set(__self__, "activation_url", activation_url)
        if created_at is not None:
            pulumi.set(__self__, "created_at", created_at)
        if created_by is not None:
            pulumi.set(__self__, "created_by", created_by)
        if expiration_time is not None:
            pulumi.set(__self__, "expiration_time", expiration_time)
        if id is not None:
            pulumi.set(__self__, "id", id)
        if updated_at is not None:
            pulumi.set(__self__, "updated_at", updated_at)
        if updated_by is not None:
            pulumi.set(__self__, "updated_by", updated_by)

    @property
    @pulumi.getter(name="activationUrl")
    def activation_url(self) -> Optional[str]:
        """
        Full activation URL to retrieve the access token. It will be empty if the token is already retrieved.
        """
        return pulumi.get(self, "activation_url")

    @property
    @pulumi.getter(name="createdAt")
    def created_at(self) -> Optional[int]:
        """
        Time at which this recipient Token was created, in epoch milliseconds.
        """
        return pulumi.get(self, "created_at")

    @property
    @pulumi.getter(name="createdBy")
    def created_by(self) -> Optional[str]:
        """
        Username of recipient token creator.
        """
        return pulumi.get(self, "created_by")

    @property
    @pulumi.getter(name="expirationTime")
    def expiration_time(self) -> Optional[int]:
        """
        Expiration timestamp of the token in epoch milliseconds.
        """
        return pulumi.get(self, "expiration_time")

    @property
    @pulumi.getter
    def id(self) -> Optional[str]:
        """
        ID of this recipient - same as the `name`.
        """
        return pulumi.get(self, "id")

    @property
    @pulumi.getter(name="updatedAt")
    def updated_at(self) -> Optional[int]:
        """
        Time at which this recipient Token was updated, in epoch milliseconds.
        """
        return pulumi.get(self, "updated_at")

    @property
    @pulumi.getter(name="updatedBy")
    def updated_by(self) -> Optional[str]:
        """
        Username of recipient Token updater.
        """
        return pulumi.get(self, "updated_by")


@pulumi.output_type
class RepoSparseCheckout(dict):
    def __init__(__self__, *,
                 patterns: Sequence[str]):
        """
        :param Sequence[str] patterns: array of paths (directories) that will be used for sparse checkout.  List of patterns could be updated in-place.
               
               Addition or removal of the `sparse_checkout` configuration block will lead to recreation of the repo.
        """
        pulumi.set(__self__, "patterns", patterns)

    @property
    @pulumi.getter
    def patterns(self) -> Sequence[str]:
        """
        array of paths (directories) that will be used for sparse checkout.  List of patterns could be updated in-place.

        Addition or removal of the `sparse_checkout` configuration block will lead to recreation of the repo.
        """
        return pulumi.get(self, "patterns")


@pulumi.output_type
class RestrictWorkspaceAdminsSettingRestrictWorkspaceAdmins(dict):
    def __init__(__self__, *,
                 status: str):
        """
        :param str status: The restrict workspace admins status for the workspace.
        """
        pulumi.set(__self__, "status", status)

    @property
    @pulumi.getter
    def status(self) -> str:
        """
        The restrict workspace admins status for the workspace.
        """
        return pulumi.get(self, "status")


@pulumi.output_type
class SecretScopeKeyvaultMetadata(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "dnsName":
            suggest = "dns_name"
        elif key == "resourceId":
            suggest = "resource_id"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in SecretScopeKeyvaultMetadata. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        SecretScopeKeyvaultMetadata.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        SecretScopeKeyvaultMetadata.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 dns_name: str,
                 resource_id: str):
        pulumi.set(__self__, "dns_name", dns_name)
        pulumi.set(__self__, "resource_id", resource_id)

    @property
    @pulumi.getter(name="dnsName")
    def dns_name(self) -> str:
        return pulumi.get(self, "dns_name")

    @property
    @pulumi.getter(name="resourceId")
    def resource_id(self) -> str:
        return pulumi.get(self, "resource_id")


@pulumi.output_type
class ShareObject(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "dataObjectType":
            suggest = "data_object_type"
        elif key == "addedAt":
            suggest = "added_at"
        elif key == "addedBy":
            suggest = "added_by"
        elif key == "cdfEnabled":
            suggest = "cdf_enabled"
        elif key == "historyDataSharingStatus":
            suggest = "history_data_sharing_status"
        elif key == "sharedAs":
            suggest = "shared_as"
        elif key == "startVersion":
            suggest = "start_version"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ShareObject. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ShareObject.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ShareObject.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 data_object_type: str,
                 name: str,
                 added_at: Optional[int] = None,
                 added_by: Optional[str] = None,
                 cdf_enabled: Optional[bool] = None,
                 comment: Optional[str] = None,
                 history_data_sharing_status: Optional[str] = None,
                 partitions: Optional[Sequence['outputs.ShareObjectPartition']] = None,
                 shared_as: Optional[str] = None,
                 start_version: Optional[int] = None,
                 status: Optional[str] = None):
        """
        :param str data_object_type: Type of the data object, currently `TABLE`, `SCHEMA`, `VOLUME`, `NOTEBOOK_FILE` are supported.
        :param str name: Full name of the object, e.g. `catalog.schema.name` for a table.
        :param bool cdf_enabled: Whether to enable Change Data Feed (cdf) on the shared object. When this field is set, field `history_data_sharing_status` can not be set.
        :param str comment: Description about the object.
        :param str history_data_sharing_status: Whether to enable history sharing, one of: `ENABLED`, `DISABLED`. When a table has history sharing enabled, recipients can query table data by version, starting from the current table version. If not specified, clients can only query starting from the version of the object at the time it was added to the share. *NOTE*: The start_version should be less than or equal the current version of the object. When this field is set, field `cdf_enabled` can not be set.
               
               To share only part of a table when you add the table to a share, you can provide partition specifications. This is specified by a number of `partition` blocks. Each entry in `partition` block takes a list of `value` blocks. The field is documented below.
        :param str shared_as: A user-provided new name for the data object within the share. If this new name is not provided, the object's original name will be used as the `shared_as` name. The `shared_as` name must be unique within a Share. Change forces creation of a new resource.
        :param int start_version: The start version associated with the object for cdf. This allows data providers to control the lowest object version that is accessible by clients.
        :param str status: Status of the object, one of: `ACTIVE`, `PERMISSION_DENIED`.
        """
        pulumi.set(__self__, "data_object_type", data_object_type)
        pulumi.set(__self__, "name", name)
        if added_at is not None:
            pulumi.set(__self__, "added_at", added_at)
        if added_by is not None:
            pulumi.set(__self__, "added_by", added_by)
        if cdf_enabled is not None:
            pulumi.set(__self__, "cdf_enabled", cdf_enabled)
        if comment is not None:
            pulumi.set(__self__, "comment", comment)
        if history_data_sharing_status is not None:
            pulumi.set(__self__, "history_data_sharing_status", history_data_sharing_status)
        if partitions is not None:
            pulumi.set(__self__, "partitions", partitions)
        if shared_as is not None:
            pulumi.set(__self__, "shared_as", shared_as)
        if start_version is not None:
            pulumi.set(__self__, "start_version", start_version)
        if status is not None:
            pulumi.set(__self__, "status", status)

    @property
    @pulumi.getter(name="dataObjectType")
    def data_object_type(self) -> str:
        """
        Type of the data object, currently `TABLE`, `SCHEMA`, `VOLUME`, `NOTEBOOK_FILE` are supported.
        """
        return pulumi.get(self, "data_object_type")

    @property
    @pulumi.getter
    def name(self) -> str:
        """
        Full name of the object, e.g. `catalog.schema.name` for a table.
        """
        return pulumi.get(self, "name")

    @property
    @pulumi.getter(name="addedAt")
    def added_at(self) -> Optional[int]:
        return pulumi.get(self, "added_at")

    @property
    @pulumi.getter(name="addedBy")
    def added_by(self) -> Optional[str]:
        return pulumi.get(self, "added_by")

    @property
    @pulumi.getter(name="cdfEnabled")
    def cdf_enabled(self) -> Optional[bool]:
        """
        Whether to enable Change Data Feed (cdf) on the shared object. When this field is set, field `history_data_sharing_status` can not be set.
        """
        return pulumi.get(self, "cdf_enabled")

    @property
    @pulumi.getter
    def comment(self) -> Optional[str]:
        """
        Description about the object.
        """
        return pulumi.get(self, "comment")

    @property
    @pulumi.getter(name="historyDataSharingStatus")
    def history_data_sharing_status(self) -> Optional[str]:
        """
        Whether to enable history sharing, one of: `ENABLED`, `DISABLED`. When a table has history sharing enabled, recipients can query table data by version, starting from the current table version. If not specified, clients can only query starting from the version of the object at the time it was added to the share. *NOTE*: The start_version should be less than or equal the current version of the object. When this field is set, field `cdf_enabled` can not be set.

        To share only part of a table when you add the table to a share, you can provide partition specifications. This is specified by a number of `partition` blocks. Each entry in `partition` block takes a list of `value` blocks. The field is documented below.
        """
        return pulumi.get(self, "history_data_sharing_status")

    @property
    @pulumi.getter
    def partitions(self) -> Optional[Sequence['outputs.ShareObjectPartition']]:
        return pulumi.get(self, "partitions")

    @property
    @pulumi.getter(name="sharedAs")
    def shared_as(self) -> Optional[str]:
        """
        A user-provided new name for the data object within the share. If this new name is not provided, the object's original name will be used as the `shared_as` name. The `shared_as` name must be unique within a Share. Change forces creation of a new resource.
        """
        return pulumi.get(self, "shared_as")

    @property
    @pulumi.getter(name="startVersion")
    def start_version(self) -> Optional[int]:
        """
        The start version associated with the object for cdf. This allows data providers to control the lowest object version that is accessible by clients.
        """
        return pulumi.get(self, "start_version")

    @property
    @pulumi.getter
    def status(self) -> Optional[str]:
        """
        Status of the object, one of: `ACTIVE`, `PERMISSION_DENIED`.
        """
        return pulumi.get(self, "status")


@pulumi.output_type
class ShareObjectPartition(dict):
    def __init__(__self__, *,
                 values: Sequence['outputs.ShareObjectPartitionValue']):
        """
        :param Sequence['ShareObjectPartitionValueArgs'] values: The value of the partition column. When this value is not set, it means null value. When this field is set, field `recipient_property_key` can not be set.
        """
        pulumi.set(__self__, "values", values)

    @property
    @pulumi.getter
    def values(self) -> Sequence['outputs.ShareObjectPartitionValue']:
        """
        The value of the partition column. When this value is not set, it means null value. When this field is set, field `recipient_property_key` can not be set.
        """
        return pulumi.get(self, "values")


@pulumi.output_type
class ShareObjectPartitionValue(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "recipientPropertyKey":
            suggest = "recipient_property_key"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ShareObjectPartitionValue. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ShareObjectPartitionValue.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ShareObjectPartitionValue.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 name: str,
                 op: str,
                 recipient_property_key: Optional[str] = None,
                 value: Optional[str] = None):
        """
        :param str name: The name of the partition column.
        :param str op: The operator to apply for the value, one of: `EQUAL`, `LIKE`
        :param str recipient_property_key: The key of a Delta Sharing recipient's property. For example `databricks-account-id`. When this field is set, field `value` can not be set.
        :param str value: The value of the partition column. When this value is not set, it means null value. When this field is set, field `recipient_property_key` can not be set.
        """
        pulumi.set(__self__, "name", name)
        pulumi.set(__self__, "op", op)
        if recipient_property_key is not None:
            pulumi.set(__self__, "recipient_property_key", recipient_property_key)
        if value is not None:
            pulumi.set(__self__, "value", value)

    @property
    @pulumi.getter
    def name(self) -> str:
        """
        The name of the partition column.
        """
        return pulumi.get(self, "name")

    @property
    @pulumi.getter
    def op(self) -> str:
        """
        The operator to apply for the value, one of: `EQUAL`, `LIKE`
        """
        return pulumi.get(self, "op")

    @property
    @pulumi.getter(name="recipientPropertyKey")
    def recipient_property_key(self) -> Optional[str]:
        """
        The key of a Delta Sharing recipient's property. For example `databricks-account-id`. When this field is set, field `value` can not be set.
        """
        return pulumi.get(self, "recipient_property_key")

    @property
    @pulumi.getter
    def value(self) -> Optional[str]:
        """
        The value of the partition column. When this value is not set, it means null value. When this field is set, field `recipient_property_key` can not be set.
        """
        return pulumi.get(self, "value")


@pulumi.output_type
class SqlAlertOptions(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "customBody":
            suggest = "custom_body"
        elif key == "customSubject":
            suggest = "custom_subject"
        elif key == "emptyResultState":
            suggest = "empty_result_state"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in SqlAlertOptions. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        SqlAlertOptions.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        SqlAlertOptions.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 column: str,
                 op: str,
                 value: str,
                 custom_body: Optional[str] = None,
                 custom_subject: Optional[str] = None,
                 empty_result_state: Optional[str] = None,
                 muted: Optional[bool] = None):
        """
        :param str column: Name of column in the query result to compare in alert evaluation.
        :param str op: Operator used to compare in alert evaluation. (Enum: `>`, `>=`, `<`, `<=`, `==`, `!=`)
        :param str value: Value used to compare in alert evaluation.
        :param str custom_body: Custom body of alert notification, if it exists. See [Alerts API reference](https://docs.databricks.com/sql/user/alerts/index.html) for custom templating instructions.
        :param str custom_subject: Custom subject of alert notification, if it exists. This includes email subject, Slack notification header, etc. See [Alerts API reference](https://docs.databricks.com/sql/user/alerts/index.html) for custom templating instructions.
        :param str empty_result_state: State that alert evaluates to when query result is empty.  Currently supported values are `unknown`, `triggered`, `ok` - check [API documentation](https://docs.databricks.com/api/workspace/alerts/create) for full list of supported values.
        :param bool muted: Whether or not the alert is muted. If an alert is muted, it will not notify users and alert destinations when triggered.
        """
        pulumi.set(__self__, "column", column)
        pulumi.set(__self__, "op", op)
        pulumi.set(__self__, "value", value)
        if custom_body is not None:
            pulumi.set(__self__, "custom_body", custom_body)
        if custom_subject is not None:
            pulumi.set(__self__, "custom_subject", custom_subject)
        if empty_result_state is not None:
            pulumi.set(__self__, "empty_result_state", empty_result_state)
        if muted is not None:
            pulumi.set(__self__, "muted", muted)

    @property
    @pulumi.getter
    def column(self) -> str:
        """
        Name of column in the query result to compare in alert evaluation.
        """
        return pulumi.get(self, "column")

    @property
    @pulumi.getter
    def op(self) -> str:
        """
        Operator used to compare in alert evaluation. (Enum: `>`, `>=`, `<`, `<=`, `==`, `!=`)
        """
        return pulumi.get(self, "op")

    @property
    @pulumi.getter
    def value(self) -> str:
        """
        Value used to compare in alert evaluation.
        """
        return pulumi.get(self, "value")

    @property
    @pulumi.getter(name="customBody")
    def custom_body(self) -> Optional[str]:
        """
        Custom body of alert notification, if it exists. See [Alerts API reference](https://docs.databricks.com/sql/user/alerts/index.html) for custom templating instructions.
        """
        return pulumi.get(self, "custom_body")

    @property
    @pulumi.getter(name="customSubject")
    def custom_subject(self) -> Optional[str]:
        """
        Custom subject of alert notification, if it exists. This includes email subject, Slack notification header, etc. See [Alerts API reference](https://docs.databricks.com/sql/user/alerts/index.html) for custom templating instructions.
        """
        return pulumi.get(self, "custom_subject")

    @property
    @pulumi.getter(name="emptyResultState")
    def empty_result_state(self) -> Optional[str]:
        """
        State that alert evaluates to when query result is empty.  Currently supported values are `unknown`, `triggered`, `ok` - check [API documentation](https://docs.databricks.com/api/workspace/alerts/create) for full list of supported values.
        """
        return pulumi.get(self, "empty_result_state")

    @property
    @pulumi.getter
    def muted(self) -> Optional[bool]:
        """
        Whether or not the alert is muted. If an alert is muted, it will not notify users and alert destinations when triggered.
        """
        return pulumi.get(self, "muted")


@pulumi.output_type
class SqlEndpointChannel(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "dbsqlVersion":
            suggest = "dbsql_version"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in SqlEndpointChannel. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        SqlEndpointChannel.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        SqlEndpointChannel.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 dbsql_version: Optional[str] = None,
                 name: Optional[str] = None):
        """
        :param str name: Name of the Databricks SQL release channel. Possible values are: `CHANNEL_NAME_PREVIEW` and `CHANNEL_NAME_CURRENT`. Default is `CHANNEL_NAME_CURRENT`.
        """
        if dbsql_version is not None:
            pulumi.set(__self__, "dbsql_version", dbsql_version)
        if name is not None:
            pulumi.set(__self__, "name", name)

    @property
    @pulumi.getter(name="dbsqlVersion")
    def dbsql_version(self) -> Optional[str]:
        return pulumi.get(self, "dbsql_version")

    @property
    @pulumi.getter
    def name(self) -> Optional[str]:
        """
        Name of the Databricks SQL release channel. Possible values are: `CHANNEL_NAME_PREVIEW` and `CHANNEL_NAME_CURRENT`. Default is `CHANNEL_NAME_CURRENT`.
        """
        return pulumi.get(self, "name")


@pulumi.output_type
class SqlEndpointHealth(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "failureReason":
            suggest = "failure_reason"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in SqlEndpointHealth. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        SqlEndpointHealth.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        SqlEndpointHealth.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 details: Optional[str] = None,
                 failure_reason: Optional['outputs.SqlEndpointHealthFailureReason'] = None,
                 message: Optional[str] = None,
                 status: Optional[str] = None,
                 summary: Optional[str] = None):
        if details is not None:
            pulumi.set(__self__, "details", details)
        if failure_reason is not None:
            pulumi.set(__self__, "failure_reason", failure_reason)
        if message is not None:
            pulumi.set(__self__, "message", message)
        if status is not None:
            pulumi.set(__self__, "status", status)
        if summary is not None:
            pulumi.set(__self__, "summary", summary)

    @property
    @pulumi.getter
    def details(self) -> Optional[str]:
        return pulumi.get(self, "details")

    @property
    @pulumi.getter(name="failureReason")
    def failure_reason(self) -> Optional['outputs.SqlEndpointHealthFailureReason']:
        return pulumi.get(self, "failure_reason")

    @property
    @pulumi.getter
    def message(self) -> Optional[str]:
        return pulumi.get(self, "message")

    @property
    @pulumi.getter
    def status(self) -> Optional[str]:
        return pulumi.get(self, "status")

    @property
    @pulumi.getter
    def summary(self) -> Optional[str]:
        return pulumi.get(self, "summary")


@pulumi.output_type
class SqlEndpointHealthFailureReason(dict):
    def __init__(__self__, *,
                 code: Optional[str] = None,
                 parameters: Optional[Mapping[str, Any]] = None,
                 type: Optional[str] = None):
        if code is not None:
            pulumi.set(__self__, "code", code)
        if parameters is not None:
            pulumi.set(__self__, "parameters", parameters)
        if type is not None:
            pulumi.set(__self__, "type", type)

    @property
    @pulumi.getter
    def code(self) -> Optional[str]:
        return pulumi.get(self, "code")

    @property
    @pulumi.getter
    def parameters(self) -> Optional[Mapping[str, Any]]:
        return pulumi.get(self, "parameters")

    @property
    @pulumi.getter
    def type(self) -> Optional[str]:
        return pulumi.get(self, "type")


@pulumi.output_type
class SqlEndpointOdbcParams(dict):
    def __init__(__self__, *,
                 hostname: Optional[str] = None,
                 path: Optional[str] = None,
                 port: Optional[int] = None,
                 protocol: Optional[str] = None):
        if hostname is not None:
            pulumi.set(__self__, "hostname", hostname)
        if path is not None:
            pulumi.set(__self__, "path", path)
        if port is not None:
            pulumi.set(__self__, "port", port)
        if protocol is not None:
            pulumi.set(__self__, "protocol", protocol)

    @property
    @pulumi.getter
    def hostname(self) -> Optional[str]:
        return pulumi.get(self, "hostname")

    @property
    @pulumi.getter
    def path(self) -> Optional[str]:
        return pulumi.get(self, "path")

    @property
    @pulumi.getter
    def port(self) -> Optional[int]:
        return pulumi.get(self, "port")

    @property
    @pulumi.getter
    def protocol(self) -> Optional[str]:
        return pulumi.get(self, "protocol")


@pulumi.output_type
class SqlEndpointTags(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "customTags":
            suggest = "custom_tags"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in SqlEndpointTags. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        SqlEndpointTags.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        SqlEndpointTags.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 custom_tags: Optional[Sequence['outputs.SqlEndpointTagsCustomTag']] = None):
        if custom_tags is not None:
            pulumi.set(__self__, "custom_tags", custom_tags)

    @property
    @pulumi.getter(name="customTags")
    def custom_tags(self) -> Optional[Sequence['outputs.SqlEndpointTagsCustomTag']]:
        return pulumi.get(self, "custom_tags")


@pulumi.output_type
class SqlEndpointTagsCustomTag(dict):
    def __init__(__self__, *,
                 key: str,
                 value: str):
        pulumi.set(__self__, "key", key)
        pulumi.set(__self__, "value", value)

    @property
    @pulumi.getter
    def key(self) -> str:
        return pulumi.get(self, "key")

    @property
    @pulumi.getter
    def value(self) -> str:
        return pulumi.get(self, "value")


@pulumi.output_type
class SqlPermissionsPrivilegeAssignment(dict):
    def __init__(__self__, *,
                 principal: str,
                 privileges: Sequence[str]):
        """
        :param str principal: `display_name` for a Group or databricks_user, `application_id` for a databricks_service_principal.
        :param Sequence[str] privileges: set of available privilege names in upper case.
               
               [Available](https://docs.databricks.com/security/access-control/table-acls/object-privileges.html) privilege names are:
        """
        pulumi.set(__self__, "principal", principal)
        pulumi.set(__self__, "privileges", privileges)

    @property
    @pulumi.getter
    def principal(self) -> str:
        """
        `display_name` for a Group or databricks_user, `application_id` for a databricks_service_principal.
        """
        return pulumi.get(self, "principal")

    @property
    @pulumi.getter
    def privileges(self) -> Sequence[str]:
        """
        set of available privilege names in upper case.

        [Available](https://docs.databricks.com/security/access-control/table-acls/object-privileges.html) privilege names are:
        """
        return pulumi.get(self, "privileges")


@pulumi.output_type
class SqlQueryParameter(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "dateRange":
            suggest = "date_range"
        elif key == "datetimeRange":
            suggest = "datetime_range"
        elif key == "datetimesecRange":
            suggest = "datetimesec_range"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in SqlQueryParameter. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        SqlQueryParameter.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        SqlQueryParameter.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 name: str,
                 date: Optional['outputs.SqlQueryParameterDate'] = None,
                 date_range: Optional['outputs.SqlQueryParameterDateRange'] = None,
                 datetime: Optional['outputs.SqlQueryParameterDatetime'] = None,
                 datetime_range: Optional['outputs.SqlQueryParameterDatetimeRange'] = None,
                 datetimesec: Optional['outputs.SqlQueryParameterDatetimesec'] = None,
                 datetimesec_range: Optional['outputs.SqlQueryParameterDatetimesecRange'] = None,
                 enum: Optional['outputs.SqlQueryParameterEnum'] = None,
                 number: Optional['outputs.SqlQueryParameterNumber'] = None,
                 query: Optional['outputs.SqlQueryParameterQuery'] = None,
                 text: Optional['outputs.SqlQueryParameterText'] = None,
                 title: Optional[str] = None):
        """
        :param str name: The literal parameter marker that appears between double curly braces in the query text.
               Parameters can have several different types. Type is specified using one of the following configuration blocks: `text`, `number`, `enum`, `query`, `date`, `datetime`, `datetimesec`, `date_range`, `datetime_range`, `datetimesec_range`.
               
               For `text`, `number`, `date`, `datetime`, `datetimesec` block
        :param 'SqlQueryParameterQueryArgs' query: The text of the query to be run.
        :param str title: The text displayed in a parameter picking widget.
        """
        pulumi.set(__self__, "name", name)
        if date is not None:
            pulumi.set(__self__, "date", date)
        if date_range is not None:
            pulumi.set(__self__, "date_range", date_range)
        if datetime is not None:
            pulumi.set(__self__, "datetime", datetime)
        if datetime_range is not None:
            pulumi.set(__self__, "datetime_range", datetime_range)
        if datetimesec is not None:
            pulumi.set(__self__, "datetimesec", datetimesec)
        if datetimesec_range is not None:
            pulumi.set(__self__, "datetimesec_range", datetimesec_range)
        if enum is not None:
            pulumi.set(__self__, "enum", enum)
        if number is not None:
            pulumi.set(__self__, "number", number)
        if query is not None:
            pulumi.set(__self__, "query", query)
        if text is not None:
            pulumi.set(__self__, "text", text)
        if title is not None:
            pulumi.set(__self__, "title", title)

    @property
    @pulumi.getter
    def name(self) -> str:
        """
        The literal parameter marker that appears between double curly braces in the query text.
        Parameters can have several different types. Type is specified using one of the following configuration blocks: `text`, `number`, `enum`, `query`, `date`, `datetime`, `datetimesec`, `date_range`, `datetime_range`, `datetimesec_range`.

        For `text`, `number`, `date`, `datetime`, `datetimesec` block
        """
        return pulumi.get(self, "name")

    @property
    @pulumi.getter
    def date(self) -> Optional['outputs.SqlQueryParameterDate']:
        return pulumi.get(self, "date")

    @property
    @pulumi.getter(name="dateRange")
    def date_range(self) -> Optional['outputs.SqlQueryParameterDateRange']:
        return pulumi.get(self, "date_range")

    @property
    @pulumi.getter
    def datetime(self) -> Optional['outputs.SqlQueryParameterDatetime']:
        return pulumi.get(self, "datetime")

    @property
    @pulumi.getter(name="datetimeRange")
    def datetime_range(self) -> Optional['outputs.SqlQueryParameterDatetimeRange']:
        return pulumi.get(self, "datetime_range")

    @property
    @pulumi.getter
    def datetimesec(self) -> Optional['outputs.SqlQueryParameterDatetimesec']:
        return pulumi.get(self, "datetimesec")

    @property
    @pulumi.getter(name="datetimesecRange")
    def datetimesec_range(self) -> Optional['outputs.SqlQueryParameterDatetimesecRange']:
        return pulumi.get(self, "datetimesec_range")

    @property
    @pulumi.getter
    def enum(self) -> Optional['outputs.SqlQueryParameterEnum']:
        return pulumi.get(self, "enum")

    @property
    @pulumi.getter
    def number(self) -> Optional['outputs.SqlQueryParameterNumber']:
        return pulumi.get(self, "number")

    @property
    @pulumi.getter
    def query(self) -> Optional['outputs.SqlQueryParameterQuery']:
        """
        The text of the query to be run.
        """
        return pulumi.get(self, "query")

    @property
    @pulumi.getter
    def text(self) -> Optional['outputs.SqlQueryParameterText']:
        return pulumi.get(self, "text")

    @property
    @pulumi.getter
    def title(self) -> Optional[str]:
        """
        The text displayed in a parameter picking widget.
        """
        return pulumi.get(self, "title")


@pulumi.output_type
class SqlQueryParameterDate(dict):
    def __init__(__self__, *,
                 value: str):
        """
        :param str value: The default value for this parameter.
        """
        pulumi.set(__self__, "value", value)

    @property
    @pulumi.getter
    def value(self) -> str:
        """
        The default value for this parameter.
        """
        return pulumi.get(self, "value")


@pulumi.output_type
class SqlQueryParameterDateRange(dict):
    def __init__(__self__, *,
                 range: Optional['outputs.SqlQueryParameterDateRangeRange'] = None,
                 value: Optional[str] = None):
        """
        :param str value: The default value for this parameter.
        """
        if range is not None:
            pulumi.set(__self__, "range", range)
        if value is not None:
            pulumi.set(__self__, "value", value)

    @property
    @pulumi.getter
    def range(self) -> Optional['outputs.SqlQueryParameterDateRangeRange']:
        return pulumi.get(self, "range")

    @property
    @pulumi.getter
    def value(self) -> Optional[str]:
        """
        The default value for this parameter.
        """
        return pulumi.get(self, "value")


@pulumi.output_type
class SqlQueryParameterDateRangeRange(dict):
    def __init__(__self__, *,
                 end: str,
                 start: str):
        pulumi.set(__self__, "end", end)
        pulumi.set(__self__, "start", start)

    @property
    @pulumi.getter
    def end(self) -> str:
        return pulumi.get(self, "end")

    @property
    @pulumi.getter
    def start(self) -> str:
        return pulumi.get(self, "start")


@pulumi.output_type
class SqlQueryParameterDatetime(dict):
    def __init__(__self__, *,
                 value: str):
        """
        :param str value: The default value for this parameter.
        """
        pulumi.set(__self__, "value", value)

    @property
    @pulumi.getter
    def value(self) -> str:
        """
        The default value for this parameter.
        """
        return pulumi.get(self, "value")


@pulumi.output_type
class SqlQueryParameterDatetimeRange(dict):
    def __init__(__self__, *,
                 range: Optional['outputs.SqlQueryParameterDatetimeRangeRange'] = None,
                 value: Optional[str] = None):
        """
        :param str value: The default value for this parameter.
        """
        if range is not None:
            pulumi.set(__self__, "range", range)
        if value is not None:
            pulumi.set(__self__, "value", value)

    @property
    @pulumi.getter
    def range(self) -> Optional['outputs.SqlQueryParameterDatetimeRangeRange']:
        return pulumi.get(self, "range")

    @property
    @pulumi.getter
    def value(self) -> Optional[str]:
        """
        The default value for this parameter.
        """
        return pulumi.get(self, "value")


@pulumi.output_type
class SqlQueryParameterDatetimeRangeRange(dict):
    def __init__(__self__, *,
                 end: str,
                 start: str):
        pulumi.set(__self__, "end", end)
        pulumi.set(__self__, "start", start)

    @property
    @pulumi.getter
    def end(self) -> str:
        return pulumi.get(self, "end")

    @property
    @pulumi.getter
    def start(self) -> str:
        return pulumi.get(self, "start")


@pulumi.output_type
class SqlQueryParameterDatetimesec(dict):
    def __init__(__self__, *,
                 value: str):
        """
        :param str value: The default value for this parameter.
        """
        pulumi.set(__self__, "value", value)

    @property
    @pulumi.getter
    def value(self) -> str:
        """
        The default value for this parameter.
        """
        return pulumi.get(self, "value")


@pulumi.output_type
class SqlQueryParameterDatetimesecRange(dict):
    def __init__(__self__, *,
                 range: Optional['outputs.SqlQueryParameterDatetimesecRangeRange'] = None,
                 value: Optional[str] = None):
        """
        :param str value: The default value for this parameter.
        """
        if range is not None:
            pulumi.set(__self__, "range", range)
        if value is not None:
            pulumi.set(__self__, "value", value)

    @property
    @pulumi.getter
    def range(self) -> Optional['outputs.SqlQueryParameterDatetimesecRangeRange']:
        return pulumi.get(self, "range")

    @property
    @pulumi.getter
    def value(self) -> Optional[str]:
        """
        The default value for this parameter.
        """
        return pulumi.get(self, "value")


@pulumi.output_type
class SqlQueryParameterDatetimesecRangeRange(dict):
    def __init__(__self__, *,
                 end: str,
                 start: str):
        pulumi.set(__self__, "end", end)
        pulumi.set(__self__, "start", start)

    @property
    @pulumi.getter
    def end(self) -> str:
        return pulumi.get(self, "end")

    @property
    @pulumi.getter
    def start(self) -> str:
        return pulumi.get(self, "start")


@pulumi.output_type
class SqlQueryParameterEnum(dict):
    def __init__(__self__, *,
                 options: Sequence[str],
                 multiple: Optional['outputs.SqlQueryParameterEnumMultiple'] = None,
                 value: Optional[str] = None,
                 values: Optional[Sequence[str]] = None):
        """
        :param str value: The default value for this parameter.
        """
        pulumi.set(__self__, "options", options)
        if multiple is not None:
            pulumi.set(__self__, "multiple", multiple)
        if value is not None:
            pulumi.set(__self__, "value", value)
        if values is not None:
            pulumi.set(__self__, "values", values)

    @property
    @pulumi.getter
    def options(self) -> Sequence[str]:
        return pulumi.get(self, "options")

    @property
    @pulumi.getter
    def multiple(self) -> Optional['outputs.SqlQueryParameterEnumMultiple']:
        return pulumi.get(self, "multiple")

    @property
    @pulumi.getter
    def value(self) -> Optional[str]:
        """
        The default value for this parameter.
        """
        return pulumi.get(self, "value")

    @property
    @pulumi.getter
    def values(self) -> Optional[Sequence[str]]:
        return pulumi.get(self, "values")


@pulumi.output_type
class SqlQueryParameterEnumMultiple(dict):
    def __init__(__self__, *,
                 separator: str,
                 prefix: Optional[str] = None,
                 suffix: Optional[str] = None):
        pulumi.set(__self__, "separator", separator)
        if prefix is not None:
            pulumi.set(__self__, "prefix", prefix)
        if suffix is not None:
            pulumi.set(__self__, "suffix", suffix)

    @property
    @pulumi.getter
    def separator(self) -> str:
        return pulumi.get(self, "separator")

    @property
    @pulumi.getter
    def prefix(self) -> Optional[str]:
        return pulumi.get(self, "prefix")

    @property
    @pulumi.getter
    def suffix(self) -> Optional[str]:
        return pulumi.get(self, "suffix")


@pulumi.output_type
class SqlQueryParameterNumber(dict):
    def __init__(__self__, *,
                 value: float):
        """
        :param float value: The default value for this parameter.
        """
        pulumi.set(__self__, "value", value)

    @property
    @pulumi.getter
    def value(self) -> float:
        """
        The default value for this parameter.
        """
        return pulumi.get(self, "value")


@pulumi.output_type
class SqlQueryParameterQuery(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "queryId":
            suggest = "query_id"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in SqlQueryParameterQuery. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        SqlQueryParameterQuery.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        SqlQueryParameterQuery.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 query_id: str,
                 multiple: Optional['outputs.SqlQueryParameterQueryMultiple'] = None,
                 value: Optional[str] = None,
                 values: Optional[Sequence[str]] = None):
        """
        :param str value: The default value for this parameter.
        """
        pulumi.set(__self__, "query_id", query_id)
        if multiple is not None:
            pulumi.set(__self__, "multiple", multiple)
        if value is not None:
            pulumi.set(__self__, "value", value)
        if values is not None:
            pulumi.set(__self__, "values", values)

    @property
    @pulumi.getter(name="queryId")
    def query_id(self) -> str:
        return pulumi.get(self, "query_id")

    @property
    @pulumi.getter
    def multiple(self) -> Optional['outputs.SqlQueryParameterQueryMultiple']:
        return pulumi.get(self, "multiple")

    @property
    @pulumi.getter
    def value(self) -> Optional[str]:
        """
        The default value for this parameter.
        """
        return pulumi.get(self, "value")

    @property
    @pulumi.getter
    def values(self) -> Optional[Sequence[str]]:
        return pulumi.get(self, "values")


@pulumi.output_type
class SqlQueryParameterQueryMultiple(dict):
    def __init__(__self__, *,
                 separator: str,
                 prefix: Optional[str] = None,
                 suffix: Optional[str] = None):
        pulumi.set(__self__, "separator", separator)
        if prefix is not None:
            pulumi.set(__self__, "prefix", prefix)
        if suffix is not None:
            pulumi.set(__self__, "suffix", suffix)

    @property
    @pulumi.getter
    def separator(self) -> str:
        return pulumi.get(self, "separator")

    @property
    @pulumi.getter
    def prefix(self) -> Optional[str]:
        return pulumi.get(self, "prefix")

    @property
    @pulumi.getter
    def suffix(self) -> Optional[str]:
        return pulumi.get(self, "suffix")


@pulumi.output_type
class SqlQueryParameterText(dict):
    def __init__(__self__, *,
                 value: str):
        """
        :param str value: The default value for this parameter.
        """
        pulumi.set(__self__, "value", value)

    @property
    @pulumi.getter
    def value(self) -> str:
        """
        The default value for this parameter.
        """
        return pulumi.get(self, "value")


@pulumi.output_type
class SqlQuerySchedule(dict):
    def __init__(__self__, *,
                 continuous: Optional['outputs.SqlQueryScheduleContinuous'] = None,
                 daily: Optional['outputs.SqlQueryScheduleDaily'] = None,
                 weekly: Optional['outputs.SqlQueryScheduleWeekly'] = None):
        if continuous is not None:
            pulumi.set(__self__, "continuous", continuous)
        if daily is not None:
            pulumi.set(__self__, "daily", daily)
        if weekly is not None:
            pulumi.set(__self__, "weekly", weekly)

    @property
    @pulumi.getter
    def continuous(self) -> Optional['outputs.SqlQueryScheduleContinuous']:
        return pulumi.get(self, "continuous")

    @property
    @pulumi.getter
    def daily(self) -> Optional['outputs.SqlQueryScheduleDaily']:
        return pulumi.get(self, "daily")

    @property
    @pulumi.getter
    def weekly(self) -> Optional['outputs.SqlQueryScheduleWeekly']:
        return pulumi.get(self, "weekly")


@pulumi.output_type
class SqlQueryScheduleContinuous(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "intervalSeconds":
            suggest = "interval_seconds"
        elif key == "untilDate":
            suggest = "until_date"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in SqlQueryScheduleContinuous. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        SqlQueryScheduleContinuous.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        SqlQueryScheduleContinuous.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 interval_seconds: int,
                 until_date: Optional[str] = None):
        pulumi.set(__self__, "interval_seconds", interval_seconds)
        if until_date is not None:
            pulumi.set(__self__, "until_date", until_date)

    @property
    @pulumi.getter(name="intervalSeconds")
    def interval_seconds(self) -> int:
        return pulumi.get(self, "interval_seconds")

    @property
    @pulumi.getter(name="untilDate")
    def until_date(self) -> Optional[str]:
        return pulumi.get(self, "until_date")


@pulumi.output_type
class SqlQueryScheduleDaily(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "intervalDays":
            suggest = "interval_days"
        elif key == "timeOfDay":
            suggest = "time_of_day"
        elif key == "untilDate":
            suggest = "until_date"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in SqlQueryScheduleDaily. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        SqlQueryScheduleDaily.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        SqlQueryScheduleDaily.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 interval_days: int,
                 time_of_day: str,
                 until_date: Optional[str] = None):
        pulumi.set(__self__, "interval_days", interval_days)
        pulumi.set(__self__, "time_of_day", time_of_day)
        if until_date is not None:
            pulumi.set(__self__, "until_date", until_date)

    @property
    @pulumi.getter(name="intervalDays")
    def interval_days(self) -> int:
        return pulumi.get(self, "interval_days")

    @property
    @pulumi.getter(name="timeOfDay")
    def time_of_day(self) -> str:
        return pulumi.get(self, "time_of_day")

    @property
    @pulumi.getter(name="untilDate")
    def until_date(self) -> Optional[str]:
        return pulumi.get(self, "until_date")


@pulumi.output_type
class SqlQueryScheduleWeekly(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "dayOfWeek":
            suggest = "day_of_week"
        elif key == "intervalWeeks":
            suggest = "interval_weeks"
        elif key == "timeOfDay":
            suggest = "time_of_day"
        elif key == "untilDate":
            suggest = "until_date"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in SqlQueryScheduleWeekly. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        SqlQueryScheduleWeekly.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        SqlQueryScheduleWeekly.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 day_of_week: str,
                 interval_weeks: int,
                 time_of_day: str,
                 until_date: Optional[str] = None):
        pulumi.set(__self__, "day_of_week", day_of_week)
        pulumi.set(__self__, "interval_weeks", interval_weeks)
        pulumi.set(__self__, "time_of_day", time_of_day)
        if until_date is not None:
            pulumi.set(__self__, "until_date", until_date)

    @property
    @pulumi.getter(name="dayOfWeek")
    def day_of_week(self) -> str:
        return pulumi.get(self, "day_of_week")

    @property
    @pulumi.getter(name="intervalWeeks")
    def interval_weeks(self) -> int:
        return pulumi.get(self, "interval_weeks")

    @property
    @pulumi.getter(name="timeOfDay")
    def time_of_day(self) -> str:
        return pulumi.get(self, "time_of_day")

    @property
    @pulumi.getter(name="untilDate")
    def until_date(self) -> Optional[str]:
        return pulumi.get(self, "until_date")


@pulumi.output_type
class SqlTableColumn(dict):
    def __init__(__self__, *,
                 name: str,
                 comment: Optional[str] = None,
                 nullable: Optional[bool] = None,
                 type: Optional[str] = None):
        """
        :param str name: User-visible name of column
        :param str comment: User-supplied free-form text.
        :param bool nullable: Whether field is nullable (Default: `true`)
        :param str type: Column type spec (with metadata) as SQL text. Not supported for `VIEW` table_type.
        """
        pulumi.set(__self__, "name", name)
        if comment is not None:
            pulumi.set(__self__, "comment", comment)
        if nullable is not None:
            pulumi.set(__self__, "nullable", nullable)
        if type is not None:
            pulumi.set(__self__, "type", type)

    @property
    @pulumi.getter
    def name(self) -> str:
        """
        User-visible name of column
        """
        return pulumi.get(self, "name")

    @property
    @pulumi.getter
    def comment(self) -> Optional[str]:
        """
        User-supplied free-form text.
        """
        return pulumi.get(self, "comment")

    @property
    @pulumi.getter
    def nullable(self) -> Optional[bool]:
        """
        Whether field is nullable (Default: `true`)
        """
        return pulumi.get(self, "nullable")

    @property
    @pulumi.getter
    def type(self) -> Optional[str]:
        """
        Column type spec (with metadata) as SQL text. Not supported for `VIEW` table_type.
        """
        return pulumi.get(self, "type")


@pulumi.output_type
class SqlWidgetParameter(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "mapTo":
            suggest = "map_to"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in SqlWidgetParameter. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        SqlWidgetParameter.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        SqlWidgetParameter.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 name: str,
                 type: str,
                 map_to: Optional[str] = None,
                 title: Optional[str] = None,
                 value: Optional[str] = None,
                 values: Optional[Sequence[str]] = None):
        pulumi.set(__self__, "name", name)
        pulumi.set(__self__, "type", type)
        if map_to is not None:
            pulumi.set(__self__, "map_to", map_to)
        if title is not None:
            pulumi.set(__self__, "title", title)
        if value is not None:
            pulumi.set(__self__, "value", value)
        if values is not None:
            pulumi.set(__self__, "values", values)

    @property
    @pulumi.getter
    def name(self) -> str:
        return pulumi.get(self, "name")

    @property
    @pulumi.getter
    def type(self) -> str:
        return pulumi.get(self, "type")

    @property
    @pulumi.getter(name="mapTo")
    def map_to(self) -> Optional[str]:
        return pulumi.get(self, "map_to")

    @property
    @pulumi.getter
    def title(self) -> Optional[str]:
        return pulumi.get(self, "title")

    @property
    @pulumi.getter
    def value(self) -> Optional[str]:
        return pulumi.get(self, "value")

    @property
    @pulumi.getter
    def values(self) -> Optional[Sequence[str]]:
        return pulumi.get(self, "values")


@pulumi.output_type
class SqlWidgetPosition(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "sizeX":
            suggest = "size_x"
        elif key == "sizeY":
            suggest = "size_y"
        elif key == "autoHeight":
            suggest = "auto_height"
        elif key == "posX":
            suggest = "pos_x"
        elif key == "posY":
            suggest = "pos_y"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in SqlWidgetPosition. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        SqlWidgetPosition.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        SqlWidgetPosition.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 size_x: int,
                 size_y: int,
                 auto_height: Optional[bool] = None,
                 pos_x: Optional[int] = None,
                 pos_y: Optional[int] = None):
        pulumi.set(__self__, "size_x", size_x)
        pulumi.set(__self__, "size_y", size_y)
        if auto_height is not None:
            pulumi.set(__self__, "auto_height", auto_height)
        if pos_x is not None:
            pulumi.set(__self__, "pos_x", pos_x)
        if pos_y is not None:
            pulumi.set(__self__, "pos_y", pos_y)

    @property
    @pulumi.getter(name="sizeX")
    def size_x(self) -> int:
        return pulumi.get(self, "size_x")

    @property
    @pulumi.getter(name="sizeY")
    def size_y(self) -> int:
        return pulumi.get(self, "size_y")

    @property
    @pulumi.getter(name="autoHeight")
    def auto_height(self) -> Optional[bool]:
        return pulumi.get(self, "auto_height")

    @property
    @pulumi.getter(name="posX")
    def pos_x(self) -> Optional[int]:
        return pulumi.get(self, "pos_x")

    @property
    @pulumi.getter(name="posY")
    def pos_y(self) -> Optional[int]:
        return pulumi.get(self, "pos_y")


@pulumi.output_type
class StorageCredentialAwsIamRole(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "roleArn":
            suggest = "role_arn"
        elif key == "externalId":
            suggest = "external_id"
        elif key == "unityCatalogIamArn":
            suggest = "unity_catalog_iam_arn"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in StorageCredentialAwsIamRole. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        StorageCredentialAwsIamRole.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        StorageCredentialAwsIamRole.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 role_arn: str,
                 external_id: Optional[str] = None,
                 unity_catalog_iam_arn: Optional[str] = None):
        """
        :param str role_arn: The Amazon Resource Name (ARN) of the AWS IAM role for S3 data access, of the form `arn:aws:iam::1234567890:role/MyRole-AJJHDSKSDF`
        :param str external_id: The external ID used in role assumption to prevent confused deputy problem.
        :param str unity_catalog_iam_arn: The Amazon Resource Name (ARN) of the AWS IAM user managed by Databricks. This is the identity that is going to assume the AWS IAM role.
               
               `azure_managed_identity` optional configuration block for using managed identity as credential details for Azure (recommended over service principal):
        """
        pulumi.set(__self__, "role_arn", role_arn)
        if external_id is not None:
            pulumi.set(__self__, "external_id", external_id)
        if unity_catalog_iam_arn is not None:
            pulumi.set(__self__, "unity_catalog_iam_arn", unity_catalog_iam_arn)

    @property
    @pulumi.getter(name="roleArn")
    def role_arn(self) -> str:
        """
        The Amazon Resource Name (ARN) of the AWS IAM role for S3 data access, of the form `arn:aws:iam::1234567890:role/MyRole-AJJHDSKSDF`
        """
        return pulumi.get(self, "role_arn")

    @property
    @pulumi.getter(name="externalId")
    def external_id(self) -> Optional[str]:
        """
        The external ID used in role assumption to prevent confused deputy problem.
        """
        return pulumi.get(self, "external_id")

    @property
    @pulumi.getter(name="unityCatalogIamArn")
    def unity_catalog_iam_arn(self) -> Optional[str]:
        """
        The Amazon Resource Name (ARN) of the AWS IAM user managed by Databricks. This is the identity that is going to assume the AWS IAM role.

        `azure_managed_identity` optional configuration block for using managed identity as credential details for Azure (recommended over service principal):
        """
        return pulumi.get(self, "unity_catalog_iam_arn")


@pulumi.output_type
class StorageCredentialAzureManagedIdentity(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "accessConnectorId":
            suggest = "access_connector_id"
        elif key == "credentialId":
            suggest = "credential_id"
        elif key == "managedIdentityId":
            suggest = "managed_identity_id"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in StorageCredentialAzureManagedIdentity. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        StorageCredentialAzureManagedIdentity.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        StorageCredentialAzureManagedIdentity.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 access_connector_id: str,
                 credential_id: Optional[str] = None,
                 managed_identity_id: Optional[str] = None):
        """
        :param str access_connector_id: The Resource ID of the Azure Databricks Access Connector resource, of the form `/subscriptions/00000000-0000-0000-0000-000000000000/resourceGroups/rg-name/providers/Microsoft.Databricks/accessConnectors/connector-name`.
        :param str managed_identity_id: The Resource ID of the Azure User Assigned Managed Identity associated with Azure Databricks Access Connector, of the form `/subscriptions/00000000-0000-0000-0000-000000000000/resourceGroups/rg-name/providers/Microsoft.ManagedIdentity/userAssignedIdentities/user-managed-identity-name`.
               
               `databricks_gcp_service_account` optional configuration block for creating a Databricks-managed GCP Service Account:
        """
        pulumi.set(__self__, "access_connector_id", access_connector_id)
        if credential_id is not None:
            pulumi.set(__self__, "credential_id", credential_id)
        if managed_identity_id is not None:
            pulumi.set(__self__, "managed_identity_id", managed_identity_id)

    @property
    @pulumi.getter(name="accessConnectorId")
    def access_connector_id(self) -> str:
        """
        The Resource ID of the Azure Databricks Access Connector resource, of the form `/subscriptions/00000000-0000-0000-0000-000000000000/resourceGroups/rg-name/providers/Microsoft.Databricks/accessConnectors/connector-name`.
        """
        return pulumi.get(self, "access_connector_id")

    @property
    @pulumi.getter(name="credentialId")
    def credential_id(self) -> Optional[str]:
        return pulumi.get(self, "credential_id")

    @property
    @pulumi.getter(name="managedIdentityId")
    def managed_identity_id(self) -> Optional[str]:
        """
        The Resource ID of the Azure User Assigned Managed Identity associated with Azure Databricks Access Connector, of the form `/subscriptions/00000000-0000-0000-0000-000000000000/resourceGroups/rg-name/providers/Microsoft.ManagedIdentity/userAssignedIdentities/user-managed-identity-name`.

        `databricks_gcp_service_account` optional configuration block for creating a Databricks-managed GCP Service Account:
        """
        return pulumi.get(self, "managed_identity_id")


@pulumi.output_type
class StorageCredentialAzureServicePrincipal(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "applicationId":
            suggest = "application_id"
        elif key == "clientSecret":
            suggest = "client_secret"
        elif key == "directoryId":
            suggest = "directory_id"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in StorageCredentialAzureServicePrincipal. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        StorageCredentialAzureServicePrincipal.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        StorageCredentialAzureServicePrincipal.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 application_id: str,
                 client_secret: str,
                 directory_id: str):
        """
        :param str application_id: The application ID of the application registration within the referenced AAD tenant
        :param str client_secret: The client secret generated for the above app ID in AAD. **This field is redacted on output**
        :param str directory_id: The directory ID corresponding to the Azure Active Directory (AAD) tenant of the application
        """
        pulumi.set(__self__, "application_id", application_id)
        pulumi.set(__self__, "client_secret", client_secret)
        pulumi.set(__self__, "directory_id", directory_id)

    @property
    @pulumi.getter(name="applicationId")
    def application_id(self) -> str:
        """
        The application ID of the application registration within the referenced AAD tenant
        """
        return pulumi.get(self, "application_id")

    @property
    @pulumi.getter(name="clientSecret")
    def client_secret(self) -> str:
        """
        The client secret generated for the above app ID in AAD. **This field is redacted on output**
        """
        return pulumi.get(self, "client_secret")

    @property
    @pulumi.getter(name="directoryId")
    def directory_id(self) -> str:
        """
        The directory ID corresponding to the Azure Active Directory (AAD) tenant of the application
        """
        return pulumi.get(self, "directory_id")


@pulumi.output_type
class StorageCredentialDatabricksGcpServiceAccount(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "credentialId":
            suggest = "credential_id"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in StorageCredentialDatabricksGcpServiceAccount. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        StorageCredentialDatabricksGcpServiceAccount.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        StorageCredentialDatabricksGcpServiceAccount.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 credential_id: Optional[str] = None,
                 email: Optional[str] = None):
        """
        :param str email: The email of the GCP service account created, to be granted access to relevant buckets.
               
               `azure_service_principal` optional configuration block to use service principal as credential details for Azure (Legacy):
        """
        if credential_id is not None:
            pulumi.set(__self__, "credential_id", credential_id)
        if email is not None:
            pulumi.set(__self__, "email", email)

    @property
    @pulumi.getter(name="credentialId")
    def credential_id(self) -> Optional[str]:
        return pulumi.get(self, "credential_id")

    @property
    @pulumi.getter
    def email(self) -> Optional[str]:
        """
        The email of the GCP service account created, to be granted access to relevant buckets.

        `azure_service_principal` optional configuration block to use service principal as credential details for Azure (Legacy):
        """
        return pulumi.get(self, "email")


@pulumi.output_type
class StorageCredentialGcpServiceAccountKey(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "privateKey":
            suggest = "private_key"
        elif key == "privateKeyId":
            suggest = "private_key_id"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in StorageCredentialGcpServiceAccountKey. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        StorageCredentialGcpServiceAccountKey.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        StorageCredentialGcpServiceAccountKey.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 email: str,
                 private_key: str,
                 private_key_id: str):
        """
        :param str email: The email of the GCP service account created, to be granted access to relevant buckets.
               
               `azure_service_principal` optional configuration block to use service principal as credential details for Azure (Legacy):
        """
        pulumi.set(__self__, "email", email)
        pulumi.set(__self__, "private_key", private_key)
        pulumi.set(__self__, "private_key_id", private_key_id)

    @property
    @pulumi.getter
    def email(self) -> str:
        """
        The email of the GCP service account created, to be granted access to relevant buckets.

        `azure_service_principal` optional configuration block to use service principal as credential details for Azure (Legacy):
        """
        return pulumi.get(self, "email")

    @property
    @pulumi.getter(name="privateKey")
    def private_key(self) -> str:
        return pulumi.get(self, "private_key")

    @property
    @pulumi.getter(name="privateKeyId")
    def private_key_id(self) -> str:
        return pulumi.get(self, "private_key_id")


@pulumi.output_type
class TableColumn(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "typeName":
            suggest = "type_name"
        elif key == "typeText":
            suggest = "type_text"
        elif key == "partitionIndex":
            suggest = "partition_index"
        elif key == "typeIntervalType":
            suggest = "type_interval_type"
        elif key == "typeJson":
            suggest = "type_json"
        elif key == "typePrecision":
            suggest = "type_precision"
        elif key == "typeScale":
            suggest = "type_scale"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in TableColumn. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        TableColumn.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        TableColumn.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 name: str,
                 position: int,
                 type_name: str,
                 type_text: str,
                 comment: Optional[str] = None,
                 nullable: Optional[bool] = None,
                 partition_index: Optional[int] = None,
                 type_interval_type: Optional[str] = None,
                 type_json: Optional[str] = None,
                 type_precision: Optional[int] = None,
                 type_scale: Optional[int] = None):
        pulumi.set(__self__, "name", name)
        pulumi.set(__self__, "position", position)
        pulumi.set(__self__, "type_name", type_name)
        pulumi.set(__self__, "type_text", type_text)
        if comment is not None:
            pulumi.set(__self__, "comment", comment)
        if nullable is not None:
            pulumi.set(__self__, "nullable", nullable)
        if partition_index is not None:
            pulumi.set(__self__, "partition_index", partition_index)
        if type_interval_type is not None:
            pulumi.set(__self__, "type_interval_type", type_interval_type)
        if type_json is not None:
            pulumi.set(__self__, "type_json", type_json)
        if type_precision is not None:
            pulumi.set(__self__, "type_precision", type_precision)
        if type_scale is not None:
            pulumi.set(__self__, "type_scale", type_scale)

    @property
    @pulumi.getter
    def name(self) -> str:
        return pulumi.get(self, "name")

    @property
    @pulumi.getter
    def position(self) -> int:
        return pulumi.get(self, "position")

    @property
    @pulumi.getter(name="typeName")
    def type_name(self) -> str:
        return pulumi.get(self, "type_name")

    @property
    @pulumi.getter(name="typeText")
    def type_text(self) -> str:
        return pulumi.get(self, "type_text")

    @property
    @pulumi.getter
    def comment(self) -> Optional[str]:
        return pulumi.get(self, "comment")

    @property
    @pulumi.getter
    def nullable(self) -> Optional[bool]:
        return pulumi.get(self, "nullable")

    @property
    @pulumi.getter(name="partitionIndex")
    def partition_index(self) -> Optional[int]:
        return pulumi.get(self, "partition_index")

    @property
    @pulumi.getter(name="typeIntervalType")
    def type_interval_type(self) -> Optional[str]:
        return pulumi.get(self, "type_interval_type")

    @property
    @pulumi.getter(name="typeJson")
    def type_json(self) -> Optional[str]:
        return pulumi.get(self, "type_json")

    @property
    @pulumi.getter(name="typePrecision")
    def type_precision(self) -> Optional[int]:
        return pulumi.get(self, "type_precision")

    @property
    @pulumi.getter(name="typeScale")
    def type_scale(self) -> Optional[int]:
        return pulumi.get(self, "type_scale")


@pulumi.output_type
class VectorSearchEndpointEndpointStatus(dict):
    def __init__(__self__, *,
                 message: Optional[str] = None,
                 state: Optional[str] = None):
        """
        :param str message: Additional status message.
        :param str state: Current state of the endpoint. Currently following values are supported: `PROVISIONING`, `ONLINE`, `OFFLINE`.
        """
        if message is not None:
            pulumi.set(__self__, "message", message)
        if state is not None:
            pulumi.set(__self__, "state", state)

    @property
    @pulumi.getter
    def message(self) -> Optional[str]:
        """
        Additional status message.
        """
        return pulumi.get(self, "message")

    @property
    @pulumi.getter
    def state(self) -> Optional[str]:
        """
        Current state of the endpoint. Currently following values are supported: `PROVISIONING`, `ONLINE`, `OFFLINE`.
        """
        return pulumi.get(self, "state")


@pulumi.output_type
class GetClusterClusterInfoResult(dict):
    def __init__(__self__, *,
                 cluster_source: str,
                 default_tags: Mapping[str, Any],
                 driver_instance_pool_id: str,
                 spark_version: str,
                 state: str,
                 autoscale: Optional['outputs.GetClusterClusterInfoAutoscaleResult'] = None,
                 autotermination_minutes: Optional[int] = None,
                 aws_attributes: Optional['outputs.GetClusterClusterInfoAwsAttributesResult'] = None,
                 azure_attributes: Optional['outputs.GetClusterClusterInfoAzureAttributesResult'] = None,
                 cluster_cores: Optional[float] = None,
                 cluster_id: Optional[str] = None,
                 cluster_log_conf: Optional['outputs.GetClusterClusterInfoClusterLogConfResult'] = None,
                 cluster_log_status: Optional['outputs.GetClusterClusterInfoClusterLogStatusResult'] = None,
                 cluster_memory_mb: Optional[int] = None,
                 cluster_name: Optional[str] = None,
                 creator_user_name: Optional[str] = None,
                 custom_tags: Optional[Mapping[str, Any]] = None,
                 data_security_mode: Optional[str] = None,
                 docker_image: Optional['outputs.GetClusterClusterInfoDockerImageResult'] = None,
                 driver: Optional['outputs.GetClusterClusterInfoDriverResult'] = None,
                 driver_node_type_id: Optional[str] = None,
                 enable_elastic_disk: Optional[bool] = None,
                 enable_local_disk_encryption: Optional[bool] = None,
                 executors: Optional[Sequence['outputs.GetClusterClusterInfoExecutorResult']] = None,
                 gcp_attributes: Optional['outputs.GetClusterClusterInfoGcpAttributesResult'] = None,
                 init_scripts: Optional[Sequence['outputs.GetClusterClusterInfoInitScriptResult']] = None,
                 instance_pool_id: Optional[str] = None,
                 jdbc_port: Optional[int] = None,
                 last_activity_time: Optional[int] = None,
                 last_state_loss_time: Optional[int] = None,
                 node_type_id: Optional[str] = None,
                 num_workers: Optional[int] = None,
                 policy_id: Optional[str] = None,
                 runtime_engine: Optional[str] = None,
                 single_user_name: Optional[str] = None,
                 spark_conf: Optional[Mapping[str, Any]] = None,
                 spark_context_id: Optional[int] = None,
                 spark_env_vars: Optional[Mapping[str, Any]] = None,
                 ssh_public_keys: Optional[Sequence[str]] = None,
                 start_time: Optional[int] = None,
                 state_message: Optional[str] = None,
                 terminate_time: Optional[int] = None,
                 termination_reason: Optional['outputs.GetClusterClusterInfoTerminationReasonResult'] = None):
        """
        :param str driver_instance_pool_id: similar to `instance_pool_id`, but for driver node.
        :param str spark_version: [Runtime version](https://docs.databricks.com/runtime/index.html) of the cluster.
        :param int autotermination_minutes: Automatically terminate the cluster after being inactive for this time in minutes. If specified, the threshold must be between 10 and 10000 minutes. You can also set this value to 0 to explicitly disable automatic termination.
        :param str cluster_id: The id of the cluster
        :param str cluster_name: The exact name of the cluster to search
        :param Mapping[str, Any] custom_tags: Additional tags for cluster resources.
        :param str data_security_mode: Security features of the cluster. Unity Catalog requires `SINGLE_USER` or `USER_ISOLATION` mode. `LEGACY_PASSTHROUGH` for passthrough cluster and `LEGACY_TABLE_ACL` for Table ACL cluster. Default to `NONE`, i.e. no security feature enabled.
        :param str driver_node_type_id: The node type of the Spark driver.
        :param bool enable_elastic_disk: Use autoscaling local storage.
        :param bool enable_local_disk_encryption: Enable local disk encryption.
        :param str instance_pool_id: The pool of idle instances the cluster is attached to.
        :param str node_type_id: Any supported get_node_type id.
        :param str policy_id: Identifier of Cluster Policy to validate cluster and preset certain defaults.
        :param str runtime_engine: The type of runtime of the cluster
        :param str single_user_name: The optional user name of the user to assign to an interactive cluster. This field is required when using standard AAD Passthrough for Azure Data Lake Storage (ADLS) with a single-user cluster (i.e., not high-concurrency clusters).
        :param Mapping[str, Any] spark_conf: Map with key-value pairs to fine-tune Spark clusters.
        :param Mapping[str, Any] spark_env_vars: Map with environment variable key-value pairs to fine-tune Spark clusters. Key-value pairs of the form (X,Y) are exported (i.e., X='Y') while launching the driver and workers.
        :param Sequence[str] ssh_public_keys: SSH public key contents that will be added to each Spark node in this cluster.
        """
        pulumi.set(__self__, "cluster_source", cluster_source)
        pulumi.set(__self__, "default_tags", default_tags)
        pulumi.set(__self__, "driver_instance_pool_id", driver_instance_pool_id)
        pulumi.set(__self__, "spark_version", spark_version)
        pulumi.set(__self__, "state", state)
        if autoscale is not None:
            pulumi.set(__self__, "autoscale", autoscale)
        if autotermination_minutes is not None:
            pulumi.set(__self__, "autotermination_minutes", autotermination_minutes)
        if aws_attributes is not None:
            pulumi.set(__self__, "aws_attributes", aws_attributes)
        if azure_attributes is not None:
            pulumi.set(__self__, "azure_attributes", azure_attributes)
        if cluster_cores is not None:
            pulumi.set(__self__, "cluster_cores", cluster_cores)
        if cluster_id is not None:
            pulumi.set(__self__, "cluster_id", cluster_id)
        if cluster_log_conf is not None:
            pulumi.set(__self__, "cluster_log_conf", cluster_log_conf)
        if cluster_log_status is not None:
            pulumi.set(__self__, "cluster_log_status", cluster_log_status)
        if cluster_memory_mb is not None:
            pulumi.set(__self__, "cluster_memory_mb", cluster_memory_mb)
        if cluster_name is not None:
            pulumi.set(__self__, "cluster_name", cluster_name)
        if creator_user_name is not None:
            pulumi.set(__self__, "creator_user_name", creator_user_name)
        if custom_tags is not None:
            pulumi.set(__self__, "custom_tags", custom_tags)
        if data_security_mode is not None:
            pulumi.set(__self__, "data_security_mode", data_security_mode)
        if docker_image is not None:
            pulumi.set(__self__, "docker_image", docker_image)
        if driver is not None:
            pulumi.set(__self__, "driver", driver)
        if driver_node_type_id is not None:
            pulumi.set(__self__, "driver_node_type_id", driver_node_type_id)
        if enable_elastic_disk is not None:
            pulumi.set(__self__, "enable_elastic_disk", enable_elastic_disk)
        if enable_local_disk_encryption is not None:
            pulumi.set(__self__, "enable_local_disk_encryption", enable_local_disk_encryption)
        if executors is not None:
            pulumi.set(__self__, "executors", executors)
        if gcp_attributes is not None:
            pulumi.set(__self__, "gcp_attributes", gcp_attributes)
        if init_scripts is not None:
            pulumi.set(__self__, "init_scripts", init_scripts)
        if instance_pool_id is not None:
            pulumi.set(__self__, "instance_pool_id", instance_pool_id)
        if jdbc_port is not None:
            pulumi.set(__self__, "jdbc_port", jdbc_port)
        if last_activity_time is not None:
            pulumi.set(__self__, "last_activity_time", last_activity_time)
        if last_state_loss_time is not None:
            pulumi.set(__self__, "last_state_loss_time", last_state_loss_time)
        if node_type_id is not None:
            pulumi.set(__self__, "node_type_id", node_type_id)
        if num_workers is not None:
            pulumi.set(__self__, "num_workers", num_workers)
        if policy_id is not None:
            pulumi.set(__self__, "policy_id", policy_id)
        if runtime_engine is not None:
            pulumi.set(__self__, "runtime_engine", runtime_engine)
        if single_user_name is not None:
            pulumi.set(__self__, "single_user_name", single_user_name)
        if spark_conf is not None:
            pulumi.set(__self__, "spark_conf", spark_conf)
        if spark_context_id is not None:
            pulumi.set(__self__, "spark_context_id", spark_context_id)
        if spark_env_vars is not None:
            pulumi.set(__self__, "spark_env_vars", spark_env_vars)
        if ssh_public_keys is not None:
            pulumi.set(__self__, "ssh_public_keys", ssh_public_keys)
        if start_time is not None:
            pulumi.set(__self__, "start_time", start_time)
        if state_message is not None:
            pulumi.set(__self__, "state_message", state_message)
        if terminate_time is not None:
            pulumi.set(__self__, "terminate_time", terminate_time)
        if termination_reason is not None:
            pulumi.set(__self__, "termination_reason", termination_reason)

    @property
    @pulumi.getter(name="clusterSource")
    def cluster_source(self) -> str:
        return pulumi.get(self, "cluster_source")

    @property
    @pulumi.getter(name="defaultTags")
    def default_tags(self) -> Mapping[str, Any]:
        return pulumi.get(self, "default_tags")

    @property
    @pulumi.getter(name="driverInstancePoolId")
    def driver_instance_pool_id(self) -> str:
        """
        similar to `instance_pool_id`, but for driver node.
        """
        return pulumi.get(self, "driver_instance_pool_id")

    @property
    @pulumi.getter(name="sparkVersion")
    def spark_version(self) -> str:
        """
        [Runtime version](https://docs.databricks.com/runtime/index.html) of the cluster.
        """
        return pulumi.get(self, "spark_version")

    @property
    @pulumi.getter
    def state(self) -> str:
        return pulumi.get(self, "state")

    @property
    @pulumi.getter
    def autoscale(self) -> Optional['outputs.GetClusterClusterInfoAutoscaleResult']:
        return pulumi.get(self, "autoscale")

    @property
    @pulumi.getter(name="autoterminationMinutes")
    def autotermination_minutes(self) -> Optional[int]:
        """
        Automatically terminate the cluster after being inactive for this time in minutes. If specified, the threshold must be between 10 and 10000 minutes. You can also set this value to 0 to explicitly disable automatic termination.
        """
        return pulumi.get(self, "autotermination_minutes")

    @property
    @pulumi.getter(name="awsAttributes")
    def aws_attributes(self) -> Optional['outputs.GetClusterClusterInfoAwsAttributesResult']:
        return pulumi.get(self, "aws_attributes")

    @property
    @pulumi.getter(name="azureAttributes")
    def azure_attributes(self) -> Optional['outputs.GetClusterClusterInfoAzureAttributesResult']:
        return pulumi.get(self, "azure_attributes")

    @property
    @pulumi.getter(name="clusterCores")
    def cluster_cores(self) -> Optional[float]:
        return pulumi.get(self, "cluster_cores")

    @property
    @pulumi.getter(name="clusterId")
    def cluster_id(self) -> Optional[str]:
        """
        The id of the cluster
        """
        return pulumi.get(self, "cluster_id")

    @property
    @pulumi.getter(name="clusterLogConf")
    def cluster_log_conf(self) -> Optional['outputs.GetClusterClusterInfoClusterLogConfResult']:
        return pulumi.get(self, "cluster_log_conf")

    @property
    @pulumi.getter(name="clusterLogStatus")
    def cluster_log_status(self) -> Optional['outputs.GetClusterClusterInfoClusterLogStatusResult']:
        return pulumi.get(self, "cluster_log_status")

    @property
    @pulumi.getter(name="clusterMemoryMb")
    def cluster_memory_mb(self) -> Optional[int]:
        return pulumi.get(self, "cluster_memory_mb")

    @property
    @pulumi.getter(name="clusterName")
    def cluster_name(self) -> Optional[str]:
        """
        The exact name of the cluster to search
        """
        return pulumi.get(self, "cluster_name")

    @property
    @pulumi.getter(name="creatorUserName")
    def creator_user_name(self) -> Optional[str]:
        return pulumi.get(self, "creator_user_name")

    @property
    @pulumi.getter(name="customTags")
    def custom_tags(self) -> Optional[Mapping[str, Any]]:
        """
        Additional tags for cluster resources.
        """
        return pulumi.get(self, "custom_tags")

    @property
    @pulumi.getter(name="dataSecurityMode")
    def data_security_mode(self) -> Optional[str]:
        """
        Security features of the cluster. Unity Catalog requires `SINGLE_USER` or `USER_ISOLATION` mode. `LEGACY_PASSTHROUGH` for passthrough cluster and `LEGACY_TABLE_ACL` for Table ACL cluster. Default to `NONE`, i.e. no security feature enabled.
        """
        return pulumi.get(self, "data_security_mode")

    @property
    @pulumi.getter(name="dockerImage")
    def docker_image(self) -> Optional['outputs.GetClusterClusterInfoDockerImageResult']:
        return pulumi.get(self, "docker_image")

    @property
    @pulumi.getter
    def driver(self) -> Optional['outputs.GetClusterClusterInfoDriverResult']:
        return pulumi.get(self, "driver")

    @property
    @pulumi.getter(name="driverNodeTypeId")
    def driver_node_type_id(self) -> Optional[str]:
        """
        The node type of the Spark driver.
        """
        return pulumi.get(self, "driver_node_type_id")

    @property
    @pulumi.getter(name="enableElasticDisk")
    def enable_elastic_disk(self) -> Optional[bool]:
        """
        Use autoscaling local storage.
        """
        return pulumi.get(self, "enable_elastic_disk")

    @property
    @pulumi.getter(name="enableLocalDiskEncryption")
    def enable_local_disk_encryption(self) -> Optional[bool]:
        """
        Enable local disk encryption.
        """
        return pulumi.get(self, "enable_local_disk_encryption")

    @property
    @pulumi.getter
    def executors(self) -> Optional[Sequence['outputs.GetClusterClusterInfoExecutorResult']]:
        return pulumi.get(self, "executors")

    @property
    @pulumi.getter(name="gcpAttributes")
    def gcp_attributes(self) -> Optional['outputs.GetClusterClusterInfoGcpAttributesResult']:
        return pulumi.get(self, "gcp_attributes")

    @property
    @pulumi.getter(name="initScripts")
    def init_scripts(self) -> Optional[Sequence['outputs.GetClusterClusterInfoInitScriptResult']]:
        return pulumi.get(self, "init_scripts")

    @property
    @pulumi.getter(name="instancePoolId")
    def instance_pool_id(self) -> Optional[str]:
        """
        The pool of idle instances the cluster is attached to.
        """
        return pulumi.get(self, "instance_pool_id")

    @property
    @pulumi.getter(name="jdbcPort")
    def jdbc_port(self) -> Optional[int]:
        return pulumi.get(self, "jdbc_port")

    @property
    @pulumi.getter(name="lastActivityTime")
    def last_activity_time(self) -> Optional[int]:
        return pulumi.get(self, "last_activity_time")

    @property
    @pulumi.getter(name="lastStateLossTime")
    def last_state_loss_time(self) -> Optional[int]:
        return pulumi.get(self, "last_state_loss_time")

    @property
    @pulumi.getter(name="nodeTypeId")
    def node_type_id(self) -> Optional[str]:
        """
        Any supported get_node_type id.
        """
        return pulumi.get(self, "node_type_id")

    @property
    @pulumi.getter(name="numWorkers")
    def num_workers(self) -> Optional[int]:
        return pulumi.get(self, "num_workers")

    @property
    @pulumi.getter(name="policyId")
    def policy_id(self) -> Optional[str]:
        """
        Identifier of Cluster Policy to validate cluster and preset certain defaults.
        """
        return pulumi.get(self, "policy_id")

    @property
    @pulumi.getter(name="runtimeEngine")
    def runtime_engine(self) -> Optional[str]:
        """
        The type of runtime of the cluster
        """
        return pulumi.get(self, "runtime_engine")

    @property
    @pulumi.getter(name="singleUserName")
    def single_user_name(self) -> Optional[str]:
        """
        The optional user name of the user to assign to an interactive cluster. This field is required when using standard AAD Passthrough for Azure Data Lake Storage (ADLS) with a single-user cluster (i.e., not high-concurrency clusters).
        """
        return pulumi.get(self, "single_user_name")

    @property
    @pulumi.getter(name="sparkConf")
    def spark_conf(self) -> Optional[Mapping[str, Any]]:
        """
        Map with key-value pairs to fine-tune Spark clusters.
        """
        return pulumi.get(self, "spark_conf")

    @property
    @pulumi.getter(name="sparkContextId")
    def spark_context_id(self) -> Optional[int]:
        return pulumi.get(self, "spark_context_id")

    @property
    @pulumi.getter(name="sparkEnvVars")
    def spark_env_vars(self) -> Optional[Mapping[str, Any]]:
        """
        Map with environment variable key-value pairs to fine-tune Spark clusters. Key-value pairs of the form (X,Y) are exported (i.e., X='Y') while launching the driver and workers.
        """
        return pulumi.get(self, "spark_env_vars")

    @property
    @pulumi.getter(name="sshPublicKeys")
    def ssh_public_keys(self) -> Optional[Sequence[str]]:
        """
        SSH public key contents that will be added to each Spark node in this cluster.
        """
        return pulumi.get(self, "ssh_public_keys")

    @property
    @pulumi.getter(name="startTime")
    def start_time(self) -> Optional[int]:
        return pulumi.get(self, "start_time")

    @property
    @pulumi.getter(name="stateMessage")
    def state_message(self) -> Optional[str]:
        return pulumi.get(self, "state_message")

    @property
    @pulumi.getter(name="terminateTime")
    def terminate_time(self) -> Optional[int]:
        return pulumi.get(self, "terminate_time")

    @property
    @pulumi.getter(name="terminationReason")
    def termination_reason(self) -> Optional['outputs.GetClusterClusterInfoTerminationReasonResult']:
        return pulumi.get(self, "termination_reason")


@pulumi.output_type
class GetClusterClusterInfoAutoscaleResult(dict):
    def __init__(__self__, *,
                 max_workers: Optional[int] = None,
                 min_workers: Optional[int] = None):
        if max_workers is not None:
            pulumi.set(__self__, "max_workers", max_workers)
        if min_workers is not None:
            pulumi.set(__self__, "min_workers", min_workers)

    @property
    @pulumi.getter(name="maxWorkers")
    def max_workers(self) -> Optional[int]:
        return pulumi.get(self, "max_workers")

    @property
    @pulumi.getter(name="minWorkers")
    def min_workers(self) -> Optional[int]:
        return pulumi.get(self, "min_workers")


@pulumi.output_type
class GetClusterClusterInfoAwsAttributesResult(dict):
    def __init__(__self__, *,
                 availability: Optional[str] = None,
                 ebs_volume_count: Optional[int] = None,
                 ebs_volume_size: Optional[int] = None,
                 ebs_volume_type: Optional[str] = None,
                 first_on_demand: Optional[int] = None,
                 instance_profile_arn: Optional[str] = None,
                 spot_bid_price_percent: Optional[int] = None,
                 zone_id: Optional[str] = None):
        if availability is not None:
            pulumi.set(__self__, "availability", availability)
        if ebs_volume_count is not None:
            pulumi.set(__self__, "ebs_volume_count", ebs_volume_count)
        if ebs_volume_size is not None:
            pulumi.set(__self__, "ebs_volume_size", ebs_volume_size)
        if ebs_volume_type is not None:
            pulumi.set(__self__, "ebs_volume_type", ebs_volume_type)
        if first_on_demand is not None:
            pulumi.set(__self__, "first_on_demand", first_on_demand)
        if instance_profile_arn is not None:
            pulumi.set(__self__, "instance_profile_arn", instance_profile_arn)
        if spot_bid_price_percent is not None:
            pulumi.set(__self__, "spot_bid_price_percent", spot_bid_price_percent)
        if zone_id is not None:
            pulumi.set(__self__, "zone_id", zone_id)

    @property
    @pulumi.getter
    def availability(self) -> Optional[str]:
        return pulumi.get(self, "availability")

    @property
    @pulumi.getter(name="ebsVolumeCount")
    def ebs_volume_count(self) -> Optional[int]:
        return pulumi.get(self, "ebs_volume_count")

    @property
    @pulumi.getter(name="ebsVolumeSize")
    def ebs_volume_size(self) -> Optional[int]:
        return pulumi.get(self, "ebs_volume_size")

    @property
    @pulumi.getter(name="ebsVolumeType")
    def ebs_volume_type(self) -> Optional[str]:
        return pulumi.get(self, "ebs_volume_type")

    @property
    @pulumi.getter(name="firstOnDemand")
    def first_on_demand(self) -> Optional[int]:
        return pulumi.get(self, "first_on_demand")

    @property
    @pulumi.getter(name="instanceProfileArn")
    def instance_profile_arn(self) -> Optional[str]:
        return pulumi.get(self, "instance_profile_arn")

    @property
    @pulumi.getter(name="spotBidPricePercent")
    def spot_bid_price_percent(self) -> Optional[int]:
        return pulumi.get(self, "spot_bid_price_percent")

    @property
    @pulumi.getter(name="zoneId")
    def zone_id(self) -> Optional[str]:
        return pulumi.get(self, "zone_id")


@pulumi.output_type
class GetClusterClusterInfoAzureAttributesResult(dict):
    def __init__(__self__, *,
                 availability: Optional[str] = None,
                 first_on_demand: Optional[int] = None,
                 spot_bid_max_price: Optional[float] = None):
        if availability is not None:
            pulumi.set(__self__, "availability", availability)
        if first_on_demand is not None:
            pulumi.set(__self__, "first_on_demand", first_on_demand)
        if spot_bid_max_price is not None:
            pulumi.set(__self__, "spot_bid_max_price", spot_bid_max_price)

    @property
    @pulumi.getter
    def availability(self) -> Optional[str]:
        return pulumi.get(self, "availability")

    @property
    @pulumi.getter(name="firstOnDemand")
    def first_on_demand(self) -> Optional[int]:
        return pulumi.get(self, "first_on_demand")

    @property
    @pulumi.getter(name="spotBidMaxPrice")
    def spot_bid_max_price(self) -> Optional[float]:
        return pulumi.get(self, "spot_bid_max_price")


@pulumi.output_type
class GetClusterClusterInfoClusterLogConfResult(dict):
    def __init__(__self__, *,
                 dbfs: Optional['outputs.GetClusterClusterInfoClusterLogConfDbfsResult'] = None,
                 s3: Optional['outputs.GetClusterClusterInfoClusterLogConfS3Result'] = None):
        if dbfs is not None:
            pulumi.set(__self__, "dbfs", dbfs)
        if s3 is not None:
            pulumi.set(__self__, "s3", s3)

    @property
    @pulumi.getter
    def dbfs(self) -> Optional['outputs.GetClusterClusterInfoClusterLogConfDbfsResult']:
        return pulumi.get(self, "dbfs")

    @property
    @pulumi.getter
    def s3(self) -> Optional['outputs.GetClusterClusterInfoClusterLogConfS3Result']:
        return pulumi.get(self, "s3")


@pulumi.output_type
class GetClusterClusterInfoClusterLogConfDbfsResult(dict):
    def __init__(__self__, *,
                 destination: str):
        pulumi.set(__self__, "destination", destination)

    @property
    @pulumi.getter
    def destination(self) -> str:
        return pulumi.get(self, "destination")


@pulumi.output_type
class GetClusterClusterInfoClusterLogConfS3Result(dict):
    def __init__(__self__, *,
                 destination: str,
                 canned_acl: Optional[str] = None,
                 enable_encryption: Optional[bool] = None,
                 encryption_type: Optional[str] = None,
                 endpoint: Optional[str] = None,
                 kms_key: Optional[str] = None,
                 region: Optional[str] = None):
        pulumi.set(__self__, "destination", destination)
        if canned_acl is not None:
            pulumi.set(__self__, "canned_acl", canned_acl)
        if enable_encryption is not None:
            pulumi.set(__self__, "enable_encryption", enable_encryption)
        if encryption_type is not None:
            pulumi.set(__self__, "encryption_type", encryption_type)
        if endpoint is not None:
            pulumi.set(__self__, "endpoint", endpoint)
        if kms_key is not None:
            pulumi.set(__self__, "kms_key", kms_key)
        if region is not None:
            pulumi.set(__self__, "region", region)

    @property
    @pulumi.getter
    def destination(self) -> str:
        return pulumi.get(self, "destination")

    @property
    @pulumi.getter(name="cannedAcl")
    def canned_acl(self) -> Optional[str]:
        return pulumi.get(self, "canned_acl")

    @property
    @pulumi.getter(name="enableEncryption")
    def enable_encryption(self) -> Optional[bool]:
        return pulumi.get(self, "enable_encryption")

    @property
    @pulumi.getter(name="encryptionType")
    def encryption_type(self) -> Optional[str]:
        return pulumi.get(self, "encryption_type")

    @property
    @pulumi.getter
    def endpoint(self) -> Optional[str]:
        return pulumi.get(self, "endpoint")

    @property
    @pulumi.getter(name="kmsKey")
    def kms_key(self) -> Optional[str]:
        return pulumi.get(self, "kms_key")

    @property
    @pulumi.getter
    def region(self) -> Optional[str]:
        return pulumi.get(self, "region")


@pulumi.output_type
class GetClusterClusterInfoClusterLogStatusResult(dict):
    def __init__(__self__, *,
                 last_attempted: Optional[int] = None,
                 last_exception: Optional[str] = None):
        if last_attempted is not None:
            pulumi.set(__self__, "last_attempted", last_attempted)
        if last_exception is not None:
            pulumi.set(__self__, "last_exception", last_exception)

    @property
    @pulumi.getter(name="lastAttempted")
    def last_attempted(self) -> Optional[int]:
        return pulumi.get(self, "last_attempted")

    @property
    @pulumi.getter(name="lastException")
    def last_exception(self) -> Optional[str]:
        return pulumi.get(self, "last_exception")


@pulumi.output_type
class GetClusterClusterInfoDockerImageResult(dict):
    def __init__(__self__, *,
                 url: str,
                 basic_auth: Optional['outputs.GetClusterClusterInfoDockerImageBasicAuthResult'] = None):
        pulumi.set(__self__, "url", url)
        if basic_auth is not None:
            pulumi.set(__self__, "basic_auth", basic_auth)

    @property
    @pulumi.getter
    def url(self) -> str:
        return pulumi.get(self, "url")

    @property
    @pulumi.getter(name="basicAuth")
    def basic_auth(self) -> Optional['outputs.GetClusterClusterInfoDockerImageBasicAuthResult']:
        return pulumi.get(self, "basic_auth")


@pulumi.output_type
class GetClusterClusterInfoDockerImageBasicAuthResult(dict):
    def __init__(__self__, *,
                 password: str,
                 username: str):
        pulumi.set(__self__, "password", password)
        pulumi.set(__self__, "username", username)

    @property
    @pulumi.getter
    def password(self) -> str:
        return pulumi.get(self, "password")

    @property
    @pulumi.getter
    def username(self) -> str:
        return pulumi.get(self, "username")


@pulumi.output_type
class GetClusterClusterInfoDriverResult(dict):
    def __init__(__self__, *,
                 host_private_ip: Optional[str] = None,
                 instance_id: Optional[str] = None,
                 node_aws_attributes: Optional['outputs.GetClusterClusterInfoDriverNodeAwsAttributesResult'] = None,
                 node_id: Optional[str] = None,
                 private_ip: Optional[str] = None,
                 public_dns: Optional[str] = None,
                 start_timestamp: Optional[int] = None):
        if host_private_ip is not None:
            pulumi.set(__self__, "host_private_ip", host_private_ip)
        if instance_id is not None:
            pulumi.set(__self__, "instance_id", instance_id)
        if node_aws_attributes is not None:
            pulumi.set(__self__, "node_aws_attributes", node_aws_attributes)
        if node_id is not None:
            pulumi.set(__self__, "node_id", node_id)
        if private_ip is not None:
            pulumi.set(__self__, "private_ip", private_ip)
        if public_dns is not None:
            pulumi.set(__self__, "public_dns", public_dns)
        if start_timestamp is not None:
            pulumi.set(__self__, "start_timestamp", start_timestamp)

    @property
    @pulumi.getter(name="hostPrivateIp")
    def host_private_ip(self) -> Optional[str]:
        return pulumi.get(self, "host_private_ip")

    @property
    @pulumi.getter(name="instanceId")
    def instance_id(self) -> Optional[str]:
        return pulumi.get(self, "instance_id")

    @property
    @pulumi.getter(name="nodeAwsAttributes")
    def node_aws_attributes(self) -> Optional['outputs.GetClusterClusterInfoDriverNodeAwsAttributesResult']:
        return pulumi.get(self, "node_aws_attributes")

    @property
    @pulumi.getter(name="nodeId")
    def node_id(self) -> Optional[str]:
        return pulumi.get(self, "node_id")

    @property
    @pulumi.getter(name="privateIp")
    def private_ip(self) -> Optional[str]:
        return pulumi.get(self, "private_ip")

    @property
    @pulumi.getter(name="publicDns")
    def public_dns(self) -> Optional[str]:
        return pulumi.get(self, "public_dns")

    @property
    @pulumi.getter(name="startTimestamp")
    def start_timestamp(self) -> Optional[int]:
        return pulumi.get(self, "start_timestamp")


@pulumi.output_type
class GetClusterClusterInfoDriverNodeAwsAttributesResult(dict):
    def __init__(__self__, *,
                 is_spot: Optional[bool] = None):
        if is_spot is not None:
            pulumi.set(__self__, "is_spot", is_spot)

    @property
    @pulumi.getter(name="isSpot")
    def is_spot(self) -> Optional[bool]:
        return pulumi.get(self, "is_spot")


@pulumi.output_type
class GetClusterClusterInfoExecutorResult(dict):
    def __init__(__self__, *,
                 host_private_ip: Optional[str] = None,
                 instance_id: Optional[str] = None,
                 node_aws_attributes: Optional['outputs.GetClusterClusterInfoExecutorNodeAwsAttributesResult'] = None,
                 node_id: Optional[str] = None,
                 private_ip: Optional[str] = None,
                 public_dns: Optional[str] = None,
                 start_timestamp: Optional[int] = None):
        if host_private_ip is not None:
            pulumi.set(__self__, "host_private_ip", host_private_ip)
        if instance_id is not None:
            pulumi.set(__self__, "instance_id", instance_id)
        if node_aws_attributes is not None:
            pulumi.set(__self__, "node_aws_attributes", node_aws_attributes)
        if node_id is not None:
            pulumi.set(__self__, "node_id", node_id)
        if private_ip is not None:
            pulumi.set(__self__, "private_ip", private_ip)
        if public_dns is not None:
            pulumi.set(__self__, "public_dns", public_dns)
        if start_timestamp is not None:
            pulumi.set(__self__, "start_timestamp", start_timestamp)

    @property
    @pulumi.getter(name="hostPrivateIp")
    def host_private_ip(self) -> Optional[str]:
        return pulumi.get(self, "host_private_ip")

    @property
    @pulumi.getter(name="instanceId")
    def instance_id(self) -> Optional[str]:
        return pulumi.get(self, "instance_id")

    @property
    @pulumi.getter(name="nodeAwsAttributes")
    def node_aws_attributes(self) -> Optional['outputs.GetClusterClusterInfoExecutorNodeAwsAttributesResult']:
        return pulumi.get(self, "node_aws_attributes")

    @property
    @pulumi.getter(name="nodeId")
    def node_id(self) -> Optional[str]:
        return pulumi.get(self, "node_id")

    @property
    @pulumi.getter(name="privateIp")
    def private_ip(self) -> Optional[str]:
        return pulumi.get(self, "private_ip")

    @property
    @pulumi.getter(name="publicDns")
    def public_dns(self) -> Optional[str]:
        return pulumi.get(self, "public_dns")

    @property
    @pulumi.getter(name="startTimestamp")
    def start_timestamp(self) -> Optional[int]:
        return pulumi.get(self, "start_timestamp")


@pulumi.output_type
class GetClusterClusterInfoExecutorNodeAwsAttributesResult(dict):
    def __init__(__self__, *,
                 is_spot: Optional[bool] = None):
        if is_spot is not None:
            pulumi.set(__self__, "is_spot", is_spot)

    @property
    @pulumi.getter(name="isSpot")
    def is_spot(self) -> Optional[bool]:
        return pulumi.get(self, "is_spot")


@pulumi.output_type
class GetClusterClusterInfoGcpAttributesResult(dict):
    def __init__(__self__, *,
                 availability: Optional[str] = None,
                 boot_disk_size: Optional[int] = None,
                 google_service_account: Optional[str] = None,
                 local_ssd_count: Optional[int] = None,
                 use_preemptible_executors: Optional[bool] = None,
                 zone_id: Optional[str] = None):
        if availability is not None:
            pulumi.set(__self__, "availability", availability)
        if boot_disk_size is not None:
            pulumi.set(__self__, "boot_disk_size", boot_disk_size)
        if google_service_account is not None:
            pulumi.set(__self__, "google_service_account", google_service_account)
        if local_ssd_count is not None:
            pulumi.set(__self__, "local_ssd_count", local_ssd_count)
        if use_preemptible_executors is not None:
            pulumi.set(__self__, "use_preemptible_executors", use_preemptible_executors)
        if zone_id is not None:
            pulumi.set(__self__, "zone_id", zone_id)

    @property
    @pulumi.getter
    def availability(self) -> Optional[str]:
        return pulumi.get(self, "availability")

    @property
    @pulumi.getter(name="bootDiskSize")
    def boot_disk_size(self) -> Optional[int]:
        return pulumi.get(self, "boot_disk_size")

    @property
    @pulumi.getter(name="googleServiceAccount")
    def google_service_account(self) -> Optional[str]:
        return pulumi.get(self, "google_service_account")

    @property
    @pulumi.getter(name="localSsdCount")
    def local_ssd_count(self) -> Optional[int]:
        return pulumi.get(self, "local_ssd_count")

    @property
    @pulumi.getter(name="usePreemptibleExecutors")
    def use_preemptible_executors(self) -> Optional[bool]:
        return pulumi.get(self, "use_preemptible_executors")

    @property
    @pulumi.getter(name="zoneId")
    def zone_id(self) -> Optional[str]:
        return pulumi.get(self, "zone_id")


@pulumi.output_type
class GetClusterClusterInfoInitScriptResult(dict):
    def __init__(__self__, *,
                 abfss: Optional['outputs.GetClusterClusterInfoInitScriptAbfssResult'] = None,
                 dbfs: Optional['outputs.GetClusterClusterInfoInitScriptDbfsResult'] = None,
                 file: Optional['outputs.GetClusterClusterInfoInitScriptFileResult'] = None,
                 gcs: Optional['outputs.GetClusterClusterInfoInitScriptGcsResult'] = None,
                 s3: Optional['outputs.GetClusterClusterInfoInitScriptS3Result'] = None,
                 volumes: Optional['outputs.GetClusterClusterInfoInitScriptVolumesResult'] = None,
                 workspace: Optional['outputs.GetClusterClusterInfoInitScriptWorkspaceResult'] = None):
        if abfss is not None:
            pulumi.set(__self__, "abfss", abfss)
        if dbfs is not None:
            pulumi.set(__self__, "dbfs", dbfs)
        if file is not None:
            pulumi.set(__self__, "file", file)
        if gcs is not None:
            pulumi.set(__self__, "gcs", gcs)
        if s3 is not None:
            pulumi.set(__self__, "s3", s3)
        if volumes is not None:
            pulumi.set(__self__, "volumes", volumes)
        if workspace is not None:
            pulumi.set(__self__, "workspace", workspace)

    @property
    @pulumi.getter
    def abfss(self) -> Optional['outputs.GetClusterClusterInfoInitScriptAbfssResult']:
        return pulumi.get(self, "abfss")

    @property
    @pulumi.getter
    def dbfs(self) -> Optional['outputs.GetClusterClusterInfoInitScriptDbfsResult']:
        return pulumi.get(self, "dbfs")

    @property
    @pulumi.getter
    def file(self) -> Optional['outputs.GetClusterClusterInfoInitScriptFileResult']:
        return pulumi.get(self, "file")

    @property
    @pulumi.getter
    def gcs(self) -> Optional['outputs.GetClusterClusterInfoInitScriptGcsResult']:
        return pulumi.get(self, "gcs")

    @property
    @pulumi.getter
    def s3(self) -> Optional['outputs.GetClusterClusterInfoInitScriptS3Result']:
        return pulumi.get(self, "s3")

    @property
    @pulumi.getter
    def volumes(self) -> Optional['outputs.GetClusterClusterInfoInitScriptVolumesResult']:
        return pulumi.get(self, "volumes")

    @property
    @pulumi.getter
    def workspace(self) -> Optional['outputs.GetClusterClusterInfoInitScriptWorkspaceResult']:
        return pulumi.get(self, "workspace")


@pulumi.output_type
class GetClusterClusterInfoInitScriptAbfssResult(dict):
    def __init__(__self__, *,
                 destination: str):
        pulumi.set(__self__, "destination", destination)

    @property
    @pulumi.getter
    def destination(self) -> str:
        return pulumi.get(self, "destination")


@pulumi.output_type
class GetClusterClusterInfoInitScriptDbfsResult(dict):
    def __init__(__self__, *,
                 destination: str):
        pulumi.set(__self__, "destination", destination)

    @property
    @pulumi.getter
    def destination(self) -> str:
        return pulumi.get(self, "destination")


@pulumi.output_type
class GetClusterClusterInfoInitScriptFileResult(dict):
    def __init__(__self__, *,
                 destination: str):
        pulumi.set(__self__, "destination", destination)

    @property
    @pulumi.getter
    def destination(self) -> str:
        return pulumi.get(self, "destination")


@pulumi.output_type
class GetClusterClusterInfoInitScriptGcsResult(dict):
    def __init__(__self__, *,
                 destination: str):
        pulumi.set(__self__, "destination", destination)

    @property
    @pulumi.getter
    def destination(self) -> str:
        return pulumi.get(self, "destination")


@pulumi.output_type
class GetClusterClusterInfoInitScriptS3Result(dict):
    def __init__(__self__, *,
                 destination: str,
                 canned_acl: Optional[str] = None,
                 enable_encryption: Optional[bool] = None,
                 encryption_type: Optional[str] = None,
                 endpoint: Optional[str] = None,
                 kms_key: Optional[str] = None,
                 region: Optional[str] = None):
        pulumi.set(__self__, "destination", destination)
        if canned_acl is not None:
            pulumi.set(__self__, "canned_acl", canned_acl)
        if enable_encryption is not None:
            pulumi.set(__self__, "enable_encryption", enable_encryption)
        if encryption_type is not None:
            pulumi.set(__self__, "encryption_type", encryption_type)
        if endpoint is not None:
            pulumi.set(__self__, "endpoint", endpoint)
        if kms_key is not None:
            pulumi.set(__self__, "kms_key", kms_key)
        if region is not None:
            pulumi.set(__self__, "region", region)

    @property
    @pulumi.getter
    def destination(self) -> str:
        return pulumi.get(self, "destination")

    @property
    @pulumi.getter(name="cannedAcl")
    def canned_acl(self) -> Optional[str]:
        return pulumi.get(self, "canned_acl")

    @property
    @pulumi.getter(name="enableEncryption")
    def enable_encryption(self) -> Optional[bool]:
        return pulumi.get(self, "enable_encryption")

    @property
    @pulumi.getter(name="encryptionType")
    def encryption_type(self) -> Optional[str]:
        return pulumi.get(self, "encryption_type")

    @property
    @pulumi.getter
    def endpoint(self) -> Optional[str]:
        return pulumi.get(self, "endpoint")

    @property
    @pulumi.getter(name="kmsKey")
    def kms_key(self) -> Optional[str]:
        return pulumi.get(self, "kms_key")

    @property
    @pulumi.getter
    def region(self) -> Optional[str]:
        return pulumi.get(self, "region")


@pulumi.output_type
class GetClusterClusterInfoInitScriptVolumesResult(dict):
    def __init__(__self__, *,
                 destination: str):
        pulumi.set(__self__, "destination", destination)

    @property
    @pulumi.getter
    def destination(self) -> str:
        return pulumi.get(self, "destination")


@pulumi.output_type
class GetClusterClusterInfoInitScriptWorkspaceResult(dict):
    def __init__(__self__, *,
                 destination: str):
        pulumi.set(__self__, "destination", destination)

    @property
    @pulumi.getter
    def destination(self) -> str:
        return pulumi.get(self, "destination")


@pulumi.output_type
class GetClusterClusterInfoTerminationReasonResult(dict):
    def __init__(__self__, *,
                 code: Optional[str] = None,
                 parameters: Optional[Mapping[str, Any]] = None,
                 type: Optional[str] = None):
        if code is not None:
            pulumi.set(__self__, "code", code)
        if parameters is not None:
            pulumi.set(__self__, "parameters", parameters)
        if type is not None:
            pulumi.set(__self__, "type", type)

    @property
    @pulumi.getter
    def code(self) -> Optional[str]:
        return pulumi.get(self, "code")

    @property
    @pulumi.getter
    def parameters(self) -> Optional[Mapping[str, Any]]:
        return pulumi.get(self, "parameters")

    @property
    @pulumi.getter
    def type(self) -> Optional[str]:
        return pulumi.get(self, "type")


@pulumi.output_type
class GetCurrentMetastoreMetastoreInfoResult(dict):
    def __init__(__self__, *,
                 cloud: Optional[str] = None,
                 created_at: Optional[int] = None,
                 created_by: Optional[str] = None,
                 default_data_access_config_id: Optional[str] = None,
                 delta_sharing_organization_name: Optional[str] = None,
                 delta_sharing_recipient_token_lifetime_in_seconds: Optional[int] = None,
                 delta_sharing_scope: Optional[str] = None,
                 global_metastore_id: Optional[str] = None,
                 metastore_id: Optional[str] = None,
                 name: Optional[str] = None,
                 owner: Optional[str] = None,
                 privilege_model_version: Optional[str] = None,
                 region: Optional[str] = None,
                 storage_root: Optional[str] = None,
                 storage_root_credential_id: Optional[str] = None,
                 storage_root_credential_name: Optional[str] = None,
                 updated_at: Optional[int] = None,
                 updated_by: Optional[str] = None):
        """
        :param int created_at: Timestamp (in milliseconds) when the current metastore was created.
        :param str created_by: the ID of the identity that created the current metastore.
        :param str default_data_access_config_id: the ID of the default data access configuration.
        :param str delta_sharing_organization_name: The organization name of a Delta Sharing entity. This field is used for Databricks to Databricks sharing.
        :param int delta_sharing_recipient_token_lifetime_in_seconds: the expiration duration in seconds on recipient data access tokens.
        :param str delta_sharing_scope: Used to enable delta sharing on the metastore. Valid values: INTERNAL, INTERNAL_AND_EXTERNAL. INTERNAL only allows sharing within the same account, and INTERNAL_AND_EXTERNAL allows cross account sharing and token based sharing.
        :param str global_metastore_id: Identifier in form of `<cloud>:<region>:<metastore_id>` for use in Databricks to Databricks Delta Sharing.
        :param str metastore_id: Metastore ID.
        :param str name: Name of metastore.
        :param str owner: Username/group name/sp application_id of the metastore owner.
        :param str privilege_model_version: the version of the privilege model used by the metastore.
        :param str region: (Mandatory for account-level) The region of the metastore.
        :param str storage_root: Path on cloud storage account, where managed `Table` are stored.
        :param str storage_root_credential_id: ID of a storage credential used for the `storage_root`.
        :param str storage_root_credential_name: Name of a storage credential used for the `storage_root`.
        :param int updated_at: Timestamp (in milliseconds) when the current metastore was updated.
        :param str updated_by: the ID of the identity that updated the current metastore.
        """
        if cloud is not None:
            pulumi.set(__self__, "cloud", cloud)
        if created_at is not None:
            pulumi.set(__self__, "created_at", created_at)
        if created_by is not None:
            pulumi.set(__self__, "created_by", created_by)
        if default_data_access_config_id is not None:
            pulumi.set(__self__, "default_data_access_config_id", default_data_access_config_id)
        if delta_sharing_organization_name is not None:
            pulumi.set(__self__, "delta_sharing_organization_name", delta_sharing_organization_name)
        if delta_sharing_recipient_token_lifetime_in_seconds is not None:
            pulumi.set(__self__, "delta_sharing_recipient_token_lifetime_in_seconds", delta_sharing_recipient_token_lifetime_in_seconds)
        if delta_sharing_scope is not None:
            pulumi.set(__self__, "delta_sharing_scope", delta_sharing_scope)
        if global_metastore_id is not None:
            pulumi.set(__self__, "global_metastore_id", global_metastore_id)
        if metastore_id is not None:
            pulumi.set(__self__, "metastore_id", metastore_id)
        if name is not None:
            pulumi.set(__self__, "name", name)
        if owner is not None:
            pulumi.set(__self__, "owner", owner)
        if privilege_model_version is not None:
            pulumi.set(__self__, "privilege_model_version", privilege_model_version)
        if region is not None:
            pulumi.set(__self__, "region", region)
        if storage_root is not None:
            pulumi.set(__self__, "storage_root", storage_root)
        if storage_root_credential_id is not None:
            pulumi.set(__self__, "storage_root_credential_id", storage_root_credential_id)
        if storage_root_credential_name is not None:
            pulumi.set(__self__, "storage_root_credential_name", storage_root_credential_name)
        if updated_at is not None:
            pulumi.set(__self__, "updated_at", updated_at)
        if updated_by is not None:
            pulumi.set(__self__, "updated_by", updated_by)

    @property
    @pulumi.getter
    def cloud(self) -> Optional[str]:
        return pulumi.get(self, "cloud")

    @property
    @pulumi.getter(name="createdAt")
    def created_at(self) -> Optional[int]:
        """
        Timestamp (in milliseconds) when the current metastore was created.
        """
        return pulumi.get(self, "created_at")

    @property
    @pulumi.getter(name="createdBy")
    def created_by(self) -> Optional[str]:
        """
        the ID of the identity that created the current metastore.
        """
        return pulumi.get(self, "created_by")

    @property
    @pulumi.getter(name="defaultDataAccessConfigId")
    def default_data_access_config_id(self) -> Optional[str]:
        """
        the ID of the default data access configuration.
        """
        return pulumi.get(self, "default_data_access_config_id")

    @property
    @pulumi.getter(name="deltaSharingOrganizationName")
    def delta_sharing_organization_name(self) -> Optional[str]:
        """
        The organization name of a Delta Sharing entity. This field is used for Databricks to Databricks sharing.
        """
        return pulumi.get(self, "delta_sharing_organization_name")

    @property
    @pulumi.getter(name="deltaSharingRecipientTokenLifetimeInSeconds")
    def delta_sharing_recipient_token_lifetime_in_seconds(self) -> Optional[int]:
        """
        the expiration duration in seconds on recipient data access tokens.
        """
        return pulumi.get(self, "delta_sharing_recipient_token_lifetime_in_seconds")

    @property
    @pulumi.getter(name="deltaSharingScope")
    def delta_sharing_scope(self) -> Optional[str]:
        """
        Used to enable delta sharing on the metastore. Valid values: INTERNAL, INTERNAL_AND_EXTERNAL. INTERNAL only allows sharing within the same account, and INTERNAL_AND_EXTERNAL allows cross account sharing and token based sharing.
        """
        return pulumi.get(self, "delta_sharing_scope")

    @property
    @pulumi.getter(name="globalMetastoreId")
    def global_metastore_id(self) -> Optional[str]:
        """
        Identifier in form of `<cloud>:<region>:<metastore_id>` for use in Databricks to Databricks Delta Sharing.
        """
        return pulumi.get(self, "global_metastore_id")

    @property
    @pulumi.getter(name="metastoreId")
    def metastore_id(self) -> Optional[str]:
        """
        Metastore ID.
        """
        return pulumi.get(self, "metastore_id")

    @property
    @pulumi.getter
    def name(self) -> Optional[str]:
        """
        Name of metastore.
        """
        return pulumi.get(self, "name")

    @property
    @pulumi.getter
    def owner(self) -> Optional[str]:
        """
        Username/group name/sp application_id of the metastore owner.
        """
        return pulumi.get(self, "owner")

    @property
    @pulumi.getter(name="privilegeModelVersion")
    def privilege_model_version(self) -> Optional[str]:
        """
        the version of the privilege model used by the metastore.
        """
        return pulumi.get(self, "privilege_model_version")

    @property
    @pulumi.getter
    def region(self) -> Optional[str]:
        """
        (Mandatory for account-level) The region of the metastore.
        """
        return pulumi.get(self, "region")

    @property
    @pulumi.getter(name="storageRoot")
    def storage_root(self) -> Optional[str]:
        """
        Path on cloud storage account, where managed `Table` are stored.
        """
        return pulumi.get(self, "storage_root")

    @property
    @pulumi.getter(name="storageRootCredentialId")
    def storage_root_credential_id(self) -> Optional[str]:
        """
        ID of a storage credential used for the `storage_root`.
        """
        return pulumi.get(self, "storage_root_credential_id")

    @property
    @pulumi.getter(name="storageRootCredentialName")
    def storage_root_credential_name(self) -> Optional[str]:
        """
        Name of a storage credential used for the `storage_root`.
        """
        return pulumi.get(self, "storage_root_credential_name")

    @property
    @pulumi.getter(name="updatedAt")
    def updated_at(self) -> Optional[int]:
        """
        Timestamp (in milliseconds) when the current metastore was updated.
        """
        return pulumi.get(self, "updated_at")

    @property
    @pulumi.getter(name="updatedBy")
    def updated_by(self) -> Optional[str]:
        """
        the ID of the identity that updated the current metastore.
        """
        return pulumi.get(self, "updated_by")


@pulumi.output_type
class GetDbfsFilePathsPathListResult(dict):
    def __init__(__self__, *,
                 file_size: Optional[int] = None,
                 path: Optional[str] = None):
        """
        :param str path: Path on DBFS for the file to perform listing
        """
        if file_size is not None:
            pulumi.set(__self__, "file_size", file_size)
        if path is not None:
            pulumi.set(__self__, "path", path)

    @property
    @pulumi.getter(name="fileSize")
    def file_size(self) -> Optional[int]:
        return pulumi.get(self, "file_size")

    @property
    @pulumi.getter
    def path(self) -> Optional[str]:
        """
        Path on DBFS for the file to perform listing
        """
        return pulumi.get(self, "path")


@pulumi.output_type
class GetInstancePoolPoolInfoResult(dict):
    def __init__(__self__, *,
                 default_tags: Mapping[str, Any],
                 idle_instance_autotermination_minutes: int,
                 instance_pool_id: str,
                 instance_pool_name: str,
                 aws_attributes: Optional['outputs.GetInstancePoolPoolInfoAwsAttributesResult'] = None,
                 azure_attributes: Optional['outputs.GetInstancePoolPoolInfoAzureAttributesResult'] = None,
                 custom_tags: Optional[Mapping[str, Any]] = None,
                 disk_spec: Optional['outputs.GetInstancePoolPoolInfoDiskSpecResult'] = None,
                 enable_elastic_disk: Optional[bool] = None,
                 gcp_attributes: Optional['outputs.GetInstancePoolPoolInfoGcpAttributesResult'] = None,
                 instance_pool_fleet_attributes: Optional[Sequence['outputs.GetInstancePoolPoolInfoInstancePoolFleetAttributeResult']] = None,
                 max_capacity: Optional[int] = None,
                 min_idle_instances: Optional[int] = None,
                 node_type_id: Optional[str] = None,
                 preloaded_docker_images: Optional[Sequence['outputs.GetInstancePoolPoolInfoPreloadedDockerImageResult']] = None,
                 preloaded_spark_versions: Optional[Sequence[str]] = None,
                 state: Optional[str] = None,
                 stats: Optional['outputs.GetInstancePoolPoolInfoStatsResult'] = None):
        pulumi.set(__self__, "default_tags", default_tags)
        pulumi.set(__self__, "idle_instance_autotermination_minutes", idle_instance_autotermination_minutes)
        pulumi.set(__self__, "instance_pool_id", instance_pool_id)
        pulumi.set(__self__, "instance_pool_name", instance_pool_name)
        if aws_attributes is not None:
            pulumi.set(__self__, "aws_attributes", aws_attributes)
        if azure_attributes is not None:
            pulumi.set(__self__, "azure_attributes", azure_attributes)
        if custom_tags is not None:
            pulumi.set(__self__, "custom_tags", custom_tags)
        if disk_spec is not None:
            pulumi.set(__self__, "disk_spec", disk_spec)
        if enable_elastic_disk is not None:
            pulumi.set(__self__, "enable_elastic_disk", enable_elastic_disk)
        if gcp_attributes is not None:
            pulumi.set(__self__, "gcp_attributes", gcp_attributes)
        if instance_pool_fleet_attributes is not None:
            pulumi.set(__self__, "instance_pool_fleet_attributes", instance_pool_fleet_attributes)
        if max_capacity is not None:
            pulumi.set(__self__, "max_capacity", max_capacity)
        if min_idle_instances is not None:
            pulumi.set(__self__, "min_idle_instances", min_idle_instances)
        if node_type_id is not None:
            pulumi.set(__self__, "node_type_id", node_type_id)
        if preloaded_docker_images is not None:
            pulumi.set(__self__, "preloaded_docker_images", preloaded_docker_images)
        if preloaded_spark_versions is not None:
            pulumi.set(__self__, "preloaded_spark_versions", preloaded_spark_versions)
        if state is not None:
            pulumi.set(__self__, "state", state)
        if stats is not None:
            pulumi.set(__self__, "stats", stats)

    @property
    @pulumi.getter(name="defaultTags")
    def default_tags(self) -> Mapping[str, Any]:
        return pulumi.get(self, "default_tags")

    @property
    @pulumi.getter(name="idleInstanceAutoterminationMinutes")
    def idle_instance_autotermination_minutes(self) -> int:
        return pulumi.get(self, "idle_instance_autotermination_minutes")

    @property
    @pulumi.getter(name="instancePoolId")
    def instance_pool_id(self) -> str:
        return pulumi.get(self, "instance_pool_id")

    @property
    @pulumi.getter(name="instancePoolName")
    def instance_pool_name(self) -> str:
        return pulumi.get(self, "instance_pool_name")

    @property
    @pulumi.getter(name="awsAttributes")
    def aws_attributes(self) -> Optional['outputs.GetInstancePoolPoolInfoAwsAttributesResult']:
        return pulumi.get(self, "aws_attributes")

    @property
    @pulumi.getter(name="azureAttributes")
    def azure_attributes(self) -> Optional['outputs.GetInstancePoolPoolInfoAzureAttributesResult']:
        return pulumi.get(self, "azure_attributes")

    @property
    @pulumi.getter(name="customTags")
    def custom_tags(self) -> Optional[Mapping[str, Any]]:
        return pulumi.get(self, "custom_tags")

    @property
    @pulumi.getter(name="diskSpec")
    def disk_spec(self) -> Optional['outputs.GetInstancePoolPoolInfoDiskSpecResult']:
        return pulumi.get(self, "disk_spec")

    @property
    @pulumi.getter(name="enableElasticDisk")
    def enable_elastic_disk(self) -> Optional[bool]:
        return pulumi.get(self, "enable_elastic_disk")

    @property
    @pulumi.getter(name="gcpAttributes")
    def gcp_attributes(self) -> Optional['outputs.GetInstancePoolPoolInfoGcpAttributesResult']:
        return pulumi.get(self, "gcp_attributes")

    @property
    @pulumi.getter(name="instancePoolFleetAttributes")
    def instance_pool_fleet_attributes(self) -> Optional[Sequence['outputs.GetInstancePoolPoolInfoInstancePoolFleetAttributeResult']]:
        return pulumi.get(self, "instance_pool_fleet_attributes")

    @property
    @pulumi.getter(name="maxCapacity")
    def max_capacity(self) -> Optional[int]:
        return pulumi.get(self, "max_capacity")

    @property
    @pulumi.getter(name="minIdleInstances")
    def min_idle_instances(self) -> Optional[int]:
        return pulumi.get(self, "min_idle_instances")

    @property
    @pulumi.getter(name="nodeTypeId")
    def node_type_id(self) -> Optional[str]:
        return pulumi.get(self, "node_type_id")

    @property
    @pulumi.getter(name="preloadedDockerImages")
    def preloaded_docker_images(self) -> Optional[Sequence['outputs.GetInstancePoolPoolInfoPreloadedDockerImageResult']]:
        return pulumi.get(self, "preloaded_docker_images")

    @property
    @pulumi.getter(name="preloadedSparkVersions")
    def preloaded_spark_versions(self) -> Optional[Sequence[str]]:
        return pulumi.get(self, "preloaded_spark_versions")

    @property
    @pulumi.getter
    def state(self) -> Optional[str]:
        return pulumi.get(self, "state")

    @property
    @pulumi.getter
    def stats(self) -> Optional['outputs.GetInstancePoolPoolInfoStatsResult']:
        return pulumi.get(self, "stats")


@pulumi.output_type
class GetInstancePoolPoolInfoAwsAttributesResult(dict):
    def __init__(__self__, *,
                 zone_id: str,
                 availability: Optional[str] = None,
                 spot_bid_price_percent: Optional[int] = None):
        pulumi.set(__self__, "zone_id", zone_id)
        if availability is not None:
            pulumi.set(__self__, "availability", availability)
        if spot_bid_price_percent is not None:
            pulumi.set(__self__, "spot_bid_price_percent", spot_bid_price_percent)

    @property
    @pulumi.getter(name="zoneId")
    def zone_id(self) -> str:
        return pulumi.get(self, "zone_id")

    @property
    @pulumi.getter
    def availability(self) -> Optional[str]:
        return pulumi.get(self, "availability")

    @property
    @pulumi.getter(name="spotBidPricePercent")
    def spot_bid_price_percent(self) -> Optional[int]:
        return pulumi.get(self, "spot_bid_price_percent")


@pulumi.output_type
class GetInstancePoolPoolInfoAzureAttributesResult(dict):
    def __init__(__self__, *,
                 availability: Optional[str] = None,
                 spot_bid_max_price: Optional[float] = None):
        if availability is not None:
            pulumi.set(__self__, "availability", availability)
        if spot_bid_max_price is not None:
            pulumi.set(__self__, "spot_bid_max_price", spot_bid_max_price)

    @property
    @pulumi.getter
    def availability(self) -> Optional[str]:
        return pulumi.get(self, "availability")

    @property
    @pulumi.getter(name="spotBidMaxPrice")
    def spot_bid_max_price(self) -> Optional[float]:
        return pulumi.get(self, "spot_bid_max_price")


@pulumi.output_type
class GetInstancePoolPoolInfoDiskSpecResult(dict):
    def __init__(__self__, *,
                 disk_count: Optional[int] = None,
                 disk_size: Optional[int] = None,
                 disk_type: Optional['outputs.GetInstancePoolPoolInfoDiskSpecDiskTypeResult'] = None):
        if disk_count is not None:
            pulumi.set(__self__, "disk_count", disk_count)
        if disk_size is not None:
            pulumi.set(__self__, "disk_size", disk_size)
        if disk_type is not None:
            pulumi.set(__self__, "disk_type", disk_type)

    @property
    @pulumi.getter(name="diskCount")
    def disk_count(self) -> Optional[int]:
        return pulumi.get(self, "disk_count")

    @property
    @pulumi.getter(name="diskSize")
    def disk_size(self) -> Optional[int]:
        return pulumi.get(self, "disk_size")

    @property
    @pulumi.getter(name="diskType")
    def disk_type(self) -> Optional['outputs.GetInstancePoolPoolInfoDiskSpecDiskTypeResult']:
        return pulumi.get(self, "disk_type")


@pulumi.output_type
class GetInstancePoolPoolInfoDiskSpecDiskTypeResult(dict):
    def __init__(__self__, *,
                 azure_disk_volume_type: Optional[str] = None,
                 ebs_volume_type: Optional[str] = None):
        if azure_disk_volume_type is not None:
            pulumi.set(__self__, "azure_disk_volume_type", azure_disk_volume_type)
        if ebs_volume_type is not None:
            pulumi.set(__self__, "ebs_volume_type", ebs_volume_type)

    @property
    @pulumi.getter(name="azureDiskVolumeType")
    def azure_disk_volume_type(self) -> Optional[str]:
        return pulumi.get(self, "azure_disk_volume_type")

    @property
    @pulumi.getter(name="ebsVolumeType")
    def ebs_volume_type(self) -> Optional[str]:
        return pulumi.get(self, "ebs_volume_type")


@pulumi.output_type
class GetInstancePoolPoolInfoGcpAttributesResult(dict):
    def __init__(__self__, *,
                 gcp_availability: Optional[str] = None,
                 local_ssd_count: Optional[int] = None):
        if gcp_availability is not None:
            pulumi.set(__self__, "gcp_availability", gcp_availability)
        if local_ssd_count is not None:
            pulumi.set(__self__, "local_ssd_count", local_ssd_count)

    @property
    @pulumi.getter(name="gcpAvailability")
    def gcp_availability(self) -> Optional[str]:
        return pulumi.get(self, "gcp_availability")

    @property
    @pulumi.getter(name="localSsdCount")
    def local_ssd_count(self) -> Optional[int]:
        return pulumi.get(self, "local_ssd_count")


@pulumi.output_type
class GetInstancePoolPoolInfoInstancePoolFleetAttributeResult(dict):
    def __init__(__self__, *,
                 launch_template_overrides: Sequence['outputs.GetInstancePoolPoolInfoInstancePoolFleetAttributeLaunchTemplateOverrideResult'],
                 fleet_on_demand_option: Optional['outputs.GetInstancePoolPoolInfoInstancePoolFleetAttributeFleetOnDemandOptionResult'] = None,
                 fleet_spot_option: Optional['outputs.GetInstancePoolPoolInfoInstancePoolFleetAttributeFleetSpotOptionResult'] = None):
        pulumi.set(__self__, "launch_template_overrides", launch_template_overrides)
        if fleet_on_demand_option is not None:
            pulumi.set(__self__, "fleet_on_demand_option", fleet_on_demand_option)
        if fleet_spot_option is not None:
            pulumi.set(__self__, "fleet_spot_option", fleet_spot_option)

    @property
    @pulumi.getter(name="launchTemplateOverrides")
    def launch_template_overrides(self) -> Sequence['outputs.GetInstancePoolPoolInfoInstancePoolFleetAttributeLaunchTemplateOverrideResult']:
        return pulumi.get(self, "launch_template_overrides")

    @property
    @pulumi.getter(name="fleetOnDemandOption")
    def fleet_on_demand_option(self) -> Optional['outputs.GetInstancePoolPoolInfoInstancePoolFleetAttributeFleetOnDemandOptionResult']:
        return pulumi.get(self, "fleet_on_demand_option")

    @property
    @pulumi.getter(name="fleetSpotOption")
    def fleet_spot_option(self) -> Optional['outputs.GetInstancePoolPoolInfoInstancePoolFleetAttributeFleetSpotOptionResult']:
        return pulumi.get(self, "fleet_spot_option")


@pulumi.output_type
class GetInstancePoolPoolInfoInstancePoolFleetAttributeFleetOnDemandOptionResult(dict):
    def __init__(__self__, *,
                 allocation_strategy: str,
                 instance_pools_to_use_count: Optional[int] = None):
        pulumi.set(__self__, "allocation_strategy", allocation_strategy)
        if instance_pools_to_use_count is not None:
            pulumi.set(__self__, "instance_pools_to_use_count", instance_pools_to_use_count)

    @property
    @pulumi.getter(name="allocationStrategy")
    def allocation_strategy(self) -> str:
        return pulumi.get(self, "allocation_strategy")

    @property
    @pulumi.getter(name="instancePoolsToUseCount")
    def instance_pools_to_use_count(self) -> Optional[int]:
        return pulumi.get(self, "instance_pools_to_use_count")


@pulumi.output_type
class GetInstancePoolPoolInfoInstancePoolFleetAttributeFleetSpotOptionResult(dict):
    def __init__(__self__, *,
                 allocation_strategy: str,
                 instance_pools_to_use_count: Optional[int] = None):
        pulumi.set(__self__, "allocation_strategy", allocation_strategy)
        if instance_pools_to_use_count is not None:
            pulumi.set(__self__, "instance_pools_to_use_count", instance_pools_to_use_count)

    @property
    @pulumi.getter(name="allocationStrategy")
    def allocation_strategy(self) -> str:
        return pulumi.get(self, "allocation_strategy")

    @property
    @pulumi.getter(name="instancePoolsToUseCount")
    def instance_pools_to_use_count(self) -> Optional[int]:
        return pulumi.get(self, "instance_pools_to_use_count")


@pulumi.output_type
class GetInstancePoolPoolInfoInstancePoolFleetAttributeLaunchTemplateOverrideResult(dict):
    def __init__(__self__, *,
                 availability_zone: str,
                 instance_type: str):
        pulumi.set(__self__, "availability_zone", availability_zone)
        pulumi.set(__self__, "instance_type", instance_type)

    @property
    @pulumi.getter(name="availabilityZone")
    def availability_zone(self) -> str:
        return pulumi.get(self, "availability_zone")

    @property
    @pulumi.getter(name="instanceType")
    def instance_type(self) -> str:
        return pulumi.get(self, "instance_type")


@pulumi.output_type
class GetInstancePoolPoolInfoPreloadedDockerImageResult(dict):
    def __init__(__self__, *,
                 url: str,
                 basic_auth: Optional['outputs.GetInstancePoolPoolInfoPreloadedDockerImageBasicAuthResult'] = None):
        pulumi.set(__self__, "url", url)
        if basic_auth is not None:
            pulumi.set(__self__, "basic_auth", basic_auth)

    @property
    @pulumi.getter
    def url(self) -> str:
        return pulumi.get(self, "url")

    @property
    @pulumi.getter(name="basicAuth")
    def basic_auth(self) -> Optional['outputs.GetInstancePoolPoolInfoPreloadedDockerImageBasicAuthResult']:
        return pulumi.get(self, "basic_auth")


@pulumi.output_type
class GetInstancePoolPoolInfoPreloadedDockerImageBasicAuthResult(dict):
    def __init__(__self__, *,
                 password: str,
                 username: str):
        pulumi.set(__self__, "password", password)
        pulumi.set(__self__, "username", username)

    @property
    @pulumi.getter
    def password(self) -> str:
        return pulumi.get(self, "password")

    @property
    @pulumi.getter
    def username(self) -> str:
        return pulumi.get(self, "username")


@pulumi.output_type
class GetInstancePoolPoolInfoStatsResult(dict):
    def __init__(__self__, *,
                 idle_count: Optional[int] = None,
                 pending_idle_count: Optional[int] = None,
                 pending_used_count: Optional[int] = None,
                 used_count: Optional[int] = None):
        if idle_count is not None:
            pulumi.set(__self__, "idle_count", idle_count)
        if pending_idle_count is not None:
            pulumi.set(__self__, "pending_idle_count", pending_idle_count)
        if pending_used_count is not None:
            pulumi.set(__self__, "pending_used_count", pending_used_count)
        if used_count is not None:
            pulumi.set(__self__, "used_count", used_count)

    @property
    @pulumi.getter(name="idleCount")
    def idle_count(self) -> Optional[int]:
        return pulumi.get(self, "idle_count")

    @property
    @pulumi.getter(name="pendingIdleCount")
    def pending_idle_count(self) -> Optional[int]:
        return pulumi.get(self, "pending_idle_count")

    @property
    @pulumi.getter(name="pendingUsedCount")
    def pending_used_count(self) -> Optional[int]:
        return pulumi.get(self, "pending_used_count")

    @property
    @pulumi.getter(name="usedCount")
    def used_count(self) -> Optional[int]:
        return pulumi.get(self, "used_count")


@pulumi.output_type
class GetInstanceProfilesInstanceProfileResult(dict):
    def __init__(__self__, *,
                 arn: str,
                 is_meta: bool,
                 name: str,
                 role_arn: str):
        """
        :param str arn: ARN of the instance profile.
        :param bool is_meta: Whether the instance profile is a meta instance profile or not.
        :param str name: Name of the instance profile.
        :param str role_arn: ARN of the role attached to the instance profile.
        """
        pulumi.set(__self__, "arn", arn)
        pulumi.set(__self__, "is_meta", is_meta)
        pulumi.set(__self__, "name", name)
        pulumi.set(__self__, "role_arn", role_arn)

    @property
    @pulumi.getter
    def arn(self) -> str:
        """
        ARN of the instance profile.
        """
        return pulumi.get(self, "arn")

    @property
    @pulumi.getter(name="isMeta")
    def is_meta(self) -> bool:
        """
        Whether the instance profile is a meta instance profile or not.
        """
        return pulumi.get(self, "is_meta")

    @property
    @pulumi.getter
    def name(self) -> str:
        """
        Name of the instance profile.
        """
        return pulumi.get(self, "name")

    @property
    @pulumi.getter(name="roleArn")
    def role_arn(self) -> str:
        """
        ARN of the role attached to the instance profile.
        """
        return pulumi.get(self, "role_arn")


@pulumi.output_type
class GetJobJobSettingsResult(dict):
    def __init__(__self__, *,
                 run_as_user_name: str,
                 created_time: Optional[int] = None,
                 creator_user_name: Optional[str] = None,
                 job_id: Optional[int] = None,
                 settings: Optional['outputs.GetJobJobSettingsSettingsResult'] = None):
        pulumi.set(__self__, "run_as_user_name", run_as_user_name)
        if created_time is not None:
            pulumi.set(__self__, "created_time", created_time)
        if creator_user_name is not None:
            pulumi.set(__self__, "creator_user_name", creator_user_name)
        if job_id is not None:
            pulumi.set(__self__, "job_id", job_id)
        if settings is not None:
            pulumi.set(__self__, "settings", settings)

    @property
    @pulumi.getter(name="runAsUserName")
    def run_as_user_name(self) -> str:
        return pulumi.get(self, "run_as_user_name")

    @property
    @pulumi.getter(name="createdTime")
    def created_time(self) -> Optional[int]:
        return pulumi.get(self, "created_time")

    @property
    @pulumi.getter(name="creatorUserName")
    def creator_user_name(self) -> Optional[str]:
        return pulumi.get(self, "creator_user_name")

    @property
    @pulumi.getter(name="jobId")
    def job_id(self) -> Optional[int]:
        return pulumi.get(self, "job_id")

    @property
    @pulumi.getter
    def settings(self) -> Optional['outputs.GetJobJobSettingsSettingsResult']:
        return pulumi.get(self, "settings")


@pulumi.output_type
class GetJobJobSettingsSettingsResult(dict):
    def __init__(__self__, *,
                 format: str,
                 run_as: 'outputs.GetJobJobSettingsSettingsRunAsResult',
                 computes: Optional[Sequence['outputs.GetJobJobSettingsSettingsComputeResult']] = None,
                 continuous: Optional['outputs.GetJobJobSettingsSettingsContinuousResult'] = None,
                 dbt_task: Optional['outputs.GetJobJobSettingsSettingsDbtTaskResult'] = None,
                 deployment: Optional['outputs.GetJobJobSettingsSettingsDeploymentResult'] = None,
                 description: Optional[str] = None,
                 edit_mode: Optional[str] = None,
                 email_notifications: Optional['outputs.GetJobJobSettingsSettingsEmailNotificationsResult'] = None,
                 existing_cluster_id: Optional[str] = None,
                 git_source: Optional['outputs.GetJobJobSettingsSettingsGitSourceResult'] = None,
                 health: Optional['outputs.GetJobJobSettingsSettingsHealthResult'] = None,
                 job_clusters: Optional[Sequence['outputs.GetJobJobSettingsSettingsJobClusterResult']] = None,
                 libraries: Optional[Sequence['outputs.GetJobJobSettingsSettingsLibraryResult']] = None,
                 max_concurrent_runs: Optional[int] = None,
                 max_retries: Optional[int] = None,
                 min_retry_interval_millis: Optional[int] = None,
                 name: Optional[str] = None,
                 new_cluster: Optional['outputs.GetJobJobSettingsSettingsNewClusterResult'] = None,
                 notebook_task: Optional['outputs.GetJobJobSettingsSettingsNotebookTaskResult'] = None,
                 notification_settings: Optional['outputs.GetJobJobSettingsSettingsNotificationSettingsResult'] = None,
                 parameters: Optional[Sequence['outputs.GetJobJobSettingsSettingsParameterResult']] = None,
                 pipeline_task: Optional['outputs.GetJobJobSettingsSettingsPipelineTaskResult'] = None,
                 python_wheel_task: Optional['outputs.GetJobJobSettingsSettingsPythonWheelTaskResult'] = None,
                 queue: Optional['outputs.GetJobJobSettingsSettingsQueueResult'] = None,
                 retry_on_timeout: Optional[bool] = None,
                 run_job_task: Optional['outputs.GetJobJobSettingsSettingsRunJobTaskResult'] = None,
                 schedule: Optional['outputs.GetJobJobSettingsSettingsScheduleResult'] = None,
                 spark_jar_task: Optional['outputs.GetJobJobSettingsSettingsSparkJarTaskResult'] = None,
                 spark_python_task: Optional['outputs.GetJobJobSettingsSettingsSparkPythonTaskResult'] = None,
                 spark_submit_task: Optional['outputs.GetJobJobSettingsSettingsSparkSubmitTaskResult'] = None,
                 tags: Optional[Mapping[str, Any]] = None,
                 tasks: Optional[Sequence['outputs.GetJobJobSettingsSettingsTaskResult']] = None,
                 timeout_seconds: Optional[int] = None,
                 trigger: Optional['outputs.GetJobJobSettingsSettingsTriggerResult'] = None,
                 webhook_notifications: Optional['outputs.GetJobJobSettingsSettingsWebhookNotificationsResult'] = None):
        """
        :param str name: the job name of Job if the resource was matched by id.
        """
        pulumi.set(__self__, "format", format)
        pulumi.set(__self__, "run_as", run_as)
        if computes is not None:
            pulumi.set(__self__, "computes", computes)
        if continuous is not None:
            pulumi.set(__self__, "continuous", continuous)
        if dbt_task is not None:
            pulumi.set(__self__, "dbt_task", dbt_task)
        if deployment is not None:
            pulumi.set(__self__, "deployment", deployment)
        if description is not None:
            pulumi.set(__self__, "description", description)
        if edit_mode is not None:
            pulumi.set(__self__, "edit_mode", edit_mode)
        if email_notifications is not None:
            pulumi.set(__self__, "email_notifications", email_notifications)
        if existing_cluster_id is not None:
            pulumi.set(__self__, "existing_cluster_id", existing_cluster_id)
        if git_source is not None:
            pulumi.set(__self__, "git_source", git_source)
        if health is not None:
            pulumi.set(__self__, "health", health)
        if job_clusters is not None:
            pulumi.set(__self__, "job_clusters", job_clusters)
        if libraries is not None:
            pulumi.set(__self__, "libraries", libraries)
        if max_concurrent_runs is not None:
            pulumi.set(__self__, "max_concurrent_runs", max_concurrent_runs)
        if max_retries is not None:
            pulumi.set(__self__, "max_retries", max_retries)
        if min_retry_interval_millis is not None:
            pulumi.set(__self__, "min_retry_interval_millis", min_retry_interval_millis)
        if name is not None:
            pulumi.set(__self__, "name", name)
        if new_cluster is not None:
            pulumi.set(__self__, "new_cluster", new_cluster)
        if notebook_task is not None:
            pulumi.set(__self__, "notebook_task", notebook_task)
        if notification_settings is not None:
            pulumi.set(__self__, "notification_settings", notification_settings)
        if parameters is not None:
            pulumi.set(__self__, "parameters", parameters)
        if pipeline_task is not None:
            pulumi.set(__self__, "pipeline_task", pipeline_task)
        if python_wheel_task is not None:
            pulumi.set(__self__, "python_wheel_task", python_wheel_task)
        if queue is not None:
            pulumi.set(__self__, "queue", queue)
        if retry_on_timeout is not None:
            pulumi.set(__self__, "retry_on_timeout", retry_on_timeout)
        if run_job_task is not None:
            pulumi.set(__self__, "run_job_task", run_job_task)
        if schedule is not None:
            pulumi.set(__self__, "schedule", schedule)
        if spark_jar_task is not None:
            pulumi.set(__self__, "spark_jar_task", spark_jar_task)
        if spark_python_task is not None:
            pulumi.set(__self__, "spark_python_task", spark_python_task)
        if spark_submit_task is not None:
            pulumi.set(__self__, "spark_submit_task", spark_submit_task)
        if tags is not None:
            pulumi.set(__self__, "tags", tags)
        if tasks is not None:
            pulumi.set(__self__, "tasks", tasks)
        if timeout_seconds is not None:
            pulumi.set(__self__, "timeout_seconds", timeout_seconds)
        if trigger is not None:
            pulumi.set(__self__, "trigger", trigger)
        if webhook_notifications is not None:
            pulumi.set(__self__, "webhook_notifications", webhook_notifications)

    @property
    @pulumi.getter
    def format(self) -> str:
        return pulumi.get(self, "format")

    @property
    @pulumi.getter(name="runAs")
    def run_as(self) -> 'outputs.GetJobJobSettingsSettingsRunAsResult':
        return pulumi.get(self, "run_as")

    @property
    @pulumi.getter
    def computes(self) -> Optional[Sequence['outputs.GetJobJobSettingsSettingsComputeResult']]:
        return pulumi.get(self, "computes")

    @property
    @pulumi.getter
    def continuous(self) -> Optional['outputs.GetJobJobSettingsSettingsContinuousResult']:
        return pulumi.get(self, "continuous")

    @property
    @pulumi.getter(name="dbtTask")
    def dbt_task(self) -> Optional['outputs.GetJobJobSettingsSettingsDbtTaskResult']:
        return pulumi.get(self, "dbt_task")

    @property
    @pulumi.getter
    def deployment(self) -> Optional['outputs.GetJobJobSettingsSettingsDeploymentResult']:
        return pulumi.get(self, "deployment")

    @property
    @pulumi.getter
    def description(self) -> Optional[str]:
        return pulumi.get(self, "description")

    @property
    @pulumi.getter(name="editMode")
    def edit_mode(self) -> Optional[str]:
        return pulumi.get(self, "edit_mode")

    @property
    @pulumi.getter(name="emailNotifications")
    def email_notifications(self) -> Optional['outputs.GetJobJobSettingsSettingsEmailNotificationsResult']:
        return pulumi.get(self, "email_notifications")

    @property
    @pulumi.getter(name="existingClusterId")
    def existing_cluster_id(self) -> Optional[str]:
        return pulumi.get(self, "existing_cluster_id")

    @property
    @pulumi.getter(name="gitSource")
    def git_source(self) -> Optional['outputs.GetJobJobSettingsSettingsGitSourceResult']:
        return pulumi.get(self, "git_source")

    @property
    @pulumi.getter
    def health(self) -> Optional['outputs.GetJobJobSettingsSettingsHealthResult']:
        return pulumi.get(self, "health")

    @property
    @pulumi.getter(name="jobClusters")
    def job_clusters(self) -> Optional[Sequence['outputs.GetJobJobSettingsSettingsJobClusterResult']]:
        return pulumi.get(self, "job_clusters")

    @property
    @pulumi.getter
    def libraries(self) -> Optional[Sequence['outputs.GetJobJobSettingsSettingsLibraryResult']]:
        return pulumi.get(self, "libraries")

    @property
    @pulumi.getter(name="maxConcurrentRuns")
    def max_concurrent_runs(self) -> Optional[int]:
        return pulumi.get(self, "max_concurrent_runs")

    @property
    @pulumi.getter(name="maxRetries")
    def max_retries(self) -> Optional[int]:
        return pulumi.get(self, "max_retries")

    @property
    @pulumi.getter(name="minRetryIntervalMillis")
    def min_retry_interval_millis(self) -> Optional[int]:
        return pulumi.get(self, "min_retry_interval_millis")

    @property
    @pulumi.getter
    def name(self) -> Optional[str]:
        """
        the job name of Job if the resource was matched by id.
        """
        return pulumi.get(self, "name")

    @property
    @pulumi.getter(name="newCluster")
    def new_cluster(self) -> Optional['outputs.GetJobJobSettingsSettingsNewClusterResult']:
        return pulumi.get(self, "new_cluster")

    @property
    @pulumi.getter(name="notebookTask")
    def notebook_task(self) -> Optional['outputs.GetJobJobSettingsSettingsNotebookTaskResult']:
        return pulumi.get(self, "notebook_task")

    @property
    @pulumi.getter(name="notificationSettings")
    def notification_settings(self) -> Optional['outputs.GetJobJobSettingsSettingsNotificationSettingsResult']:
        return pulumi.get(self, "notification_settings")

    @property
    @pulumi.getter
    def parameters(self) -> Optional[Sequence['outputs.GetJobJobSettingsSettingsParameterResult']]:
        return pulumi.get(self, "parameters")

    @property
    @pulumi.getter(name="pipelineTask")
    def pipeline_task(self) -> Optional['outputs.GetJobJobSettingsSettingsPipelineTaskResult']:
        return pulumi.get(self, "pipeline_task")

    @property
    @pulumi.getter(name="pythonWheelTask")
    def python_wheel_task(self) -> Optional['outputs.GetJobJobSettingsSettingsPythonWheelTaskResult']:
        return pulumi.get(self, "python_wheel_task")

    @property
    @pulumi.getter
    def queue(self) -> Optional['outputs.GetJobJobSettingsSettingsQueueResult']:
        return pulumi.get(self, "queue")

    @property
    @pulumi.getter(name="retryOnTimeout")
    def retry_on_timeout(self) -> Optional[bool]:
        return pulumi.get(self, "retry_on_timeout")

    @property
    @pulumi.getter(name="runJobTask")
    def run_job_task(self) -> Optional['outputs.GetJobJobSettingsSettingsRunJobTaskResult']:
        return pulumi.get(self, "run_job_task")

    @property
    @pulumi.getter
    def schedule(self) -> Optional['outputs.GetJobJobSettingsSettingsScheduleResult']:
        return pulumi.get(self, "schedule")

    @property
    @pulumi.getter(name="sparkJarTask")
    def spark_jar_task(self) -> Optional['outputs.GetJobJobSettingsSettingsSparkJarTaskResult']:
        return pulumi.get(self, "spark_jar_task")

    @property
    @pulumi.getter(name="sparkPythonTask")
    def spark_python_task(self) -> Optional['outputs.GetJobJobSettingsSettingsSparkPythonTaskResult']:
        return pulumi.get(self, "spark_python_task")

    @property
    @pulumi.getter(name="sparkSubmitTask")
    def spark_submit_task(self) -> Optional['outputs.GetJobJobSettingsSettingsSparkSubmitTaskResult']:
        return pulumi.get(self, "spark_submit_task")

    @property
    @pulumi.getter
    def tags(self) -> Optional[Mapping[str, Any]]:
        return pulumi.get(self, "tags")

    @property
    @pulumi.getter
    def tasks(self) -> Optional[Sequence['outputs.GetJobJobSettingsSettingsTaskResult']]:
        return pulumi.get(self, "tasks")

    @property
    @pulumi.getter(name="timeoutSeconds")
    def timeout_seconds(self) -> Optional[int]:
        return pulumi.get(self, "timeout_seconds")

    @property
    @pulumi.getter
    def trigger(self) -> Optional['outputs.GetJobJobSettingsSettingsTriggerResult']:
        return pulumi.get(self, "trigger")

    @property
    @pulumi.getter(name="webhookNotifications")
    def webhook_notifications(self) -> Optional['outputs.GetJobJobSettingsSettingsWebhookNotificationsResult']:
        return pulumi.get(self, "webhook_notifications")


@pulumi.output_type
class GetJobJobSettingsSettingsComputeResult(dict):
    def __init__(__self__, *,
                 compute_key: Optional[str] = None,
                 spec: Optional['outputs.GetJobJobSettingsSettingsComputeSpecResult'] = None):
        if compute_key is not None:
            pulumi.set(__self__, "compute_key", compute_key)
        if spec is not None:
            pulumi.set(__self__, "spec", spec)

    @property
    @pulumi.getter(name="computeKey")
    def compute_key(self) -> Optional[str]:
        return pulumi.get(self, "compute_key")

    @property
    @pulumi.getter
    def spec(self) -> Optional['outputs.GetJobJobSettingsSettingsComputeSpecResult']:
        return pulumi.get(self, "spec")


@pulumi.output_type
class GetJobJobSettingsSettingsComputeSpecResult(dict):
    def __init__(__self__, *,
                 kind: Optional[str] = None):
        if kind is not None:
            pulumi.set(__self__, "kind", kind)

    @property
    @pulumi.getter
    def kind(self) -> Optional[str]:
        return pulumi.get(self, "kind")


@pulumi.output_type
class GetJobJobSettingsSettingsContinuousResult(dict):
    def __init__(__self__, *,
                 pause_status: Optional[str] = None):
        if pause_status is not None:
            pulumi.set(__self__, "pause_status", pause_status)

    @property
    @pulumi.getter(name="pauseStatus")
    def pause_status(self) -> Optional[str]:
        return pulumi.get(self, "pause_status")


@pulumi.output_type
class GetJobJobSettingsSettingsDbtTaskResult(dict):
    def __init__(__self__, *,
                 commands: Sequence[str],
                 catalog: Optional[str] = None,
                 profiles_directory: Optional[str] = None,
                 project_directory: Optional[str] = None,
                 schema: Optional[str] = None,
                 source: Optional[str] = None,
                 warehouse_id: Optional[str] = None):
        pulumi.set(__self__, "commands", commands)
        if catalog is not None:
            pulumi.set(__self__, "catalog", catalog)
        if profiles_directory is not None:
            pulumi.set(__self__, "profiles_directory", profiles_directory)
        if project_directory is not None:
            pulumi.set(__self__, "project_directory", project_directory)
        if schema is not None:
            pulumi.set(__self__, "schema", schema)
        if source is not None:
            pulumi.set(__self__, "source", source)
        if warehouse_id is not None:
            pulumi.set(__self__, "warehouse_id", warehouse_id)

    @property
    @pulumi.getter
    def commands(self) -> Sequence[str]:
        return pulumi.get(self, "commands")

    @property
    @pulumi.getter
    def catalog(self) -> Optional[str]:
        return pulumi.get(self, "catalog")

    @property
    @pulumi.getter(name="profilesDirectory")
    def profiles_directory(self) -> Optional[str]:
        return pulumi.get(self, "profiles_directory")

    @property
    @pulumi.getter(name="projectDirectory")
    def project_directory(self) -> Optional[str]:
        return pulumi.get(self, "project_directory")

    @property
    @pulumi.getter
    def schema(self) -> Optional[str]:
        return pulumi.get(self, "schema")

    @property
    @pulumi.getter
    def source(self) -> Optional[str]:
        return pulumi.get(self, "source")

    @property
    @pulumi.getter(name="warehouseId")
    def warehouse_id(self) -> Optional[str]:
        return pulumi.get(self, "warehouse_id")


@pulumi.output_type
class GetJobJobSettingsSettingsDeploymentResult(dict):
    def __init__(__self__, *,
                 kind: str,
                 metadata_file_path: Optional[str] = None):
        pulumi.set(__self__, "kind", kind)
        if metadata_file_path is not None:
            pulumi.set(__self__, "metadata_file_path", metadata_file_path)

    @property
    @pulumi.getter
    def kind(self) -> str:
        return pulumi.get(self, "kind")

    @property
    @pulumi.getter(name="metadataFilePath")
    def metadata_file_path(self) -> Optional[str]:
        return pulumi.get(self, "metadata_file_path")


@pulumi.output_type
class GetJobJobSettingsSettingsEmailNotificationsResult(dict):
    def __init__(__self__, *,
                 no_alert_for_skipped_runs: Optional[bool] = None,
                 on_duration_warning_threshold_exceededs: Optional[Sequence[str]] = None,
                 on_failures: Optional[Sequence[str]] = None,
                 on_starts: Optional[Sequence[str]] = None,
                 on_successes: Optional[Sequence[str]] = None):
        if no_alert_for_skipped_runs is not None:
            pulumi.set(__self__, "no_alert_for_skipped_runs", no_alert_for_skipped_runs)
        if on_duration_warning_threshold_exceededs is not None:
            pulumi.set(__self__, "on_duration_warning_threshold_exceededs", on_duration_warning_threshold_exceededs)
        if on_failures is not None:
            pulumi.set(__self__, "on_failures", on_failures)
        if on_starts is not None:
            pulumi.set(__self__, "on_starts", on_starts)
        if on_successes is not None:
            pulumi.set(__self__, "on_successes", on_successes)

    @property
    @pulumi.getter(name="noAlertForSkippedRuns")
    def no_alert_for_skipped_runs(self) -> Optional[bool]:
        return pulumi.get(self, "no_alert_for_skipped_runs")

    @property
    @pulumi.getter(name="onDurationWarningThresholdExceededs")
    def on_duration_warning_threshold_exceededs(self) -> Optional[Sequence[str]]:
        return pulumi.get(self, "on_duration_warning_threshold_exceededs")

    @property
    @pulumi.getter(name="onFailures")
    def on_failures(self) -> Optional[Sequence[str]]:
        return pulumi.get(self, "on_failures")

    @property
    @pulumi.getter(name="onStarts")
    def on_starts(self) -> Optional[Sequence[str]]:
        return pulumi.get(self, "on_starts")

    @property
    @pulumi.getter(name="onSuccesses")
    def on_successes(self) -> Optional[Sequence[str]]:
        return pulumi.get(self, "on_successes")


@pulumi.output_type
class GetJobJobSettingsSettingsGitSourceResult(dict):
    def __init__(__self__, *,
                 url: str,
                 branch: Optional[str] = None,
                 commit: Optional[str] = None,
                 job_source: Optional['outputs.GetJobJobSettingsSettingsGitSourceJobSourceResult'] = None,
                 provider: Optional[str] = None,
                 tag: Optional[str] = None):
        pulumi.set(__self__, "url", url)
        if branch is not None:
            pulumi.set(__self__, "branch", branch)
        if commit is not None:
            pulumi.set(__self__, "commit", commit)
        if job_source is not None:
            pulumi.set(__self__, "job_source", job_source)
        if provider is not None:
            pulumi.set(__self__, "provider", provider)
        if tag is not None:
            pulumi.set(__self__, "tag", tag)

    @property
    @pulumi.getter
    def url(self) -> str:
        return pulumi.get(self, "url")

    @property
    @pulumi.getter
    def branch(self) -> Optional[str]:
        return pulumi.get(self, "branch")

    @property
    @pulumi.getter
    def commit(self) -> Optional[str]:
        return pulumi.get(self, "commit")

    @property
    @pulumi.getter(name="jobSource")
    def job_source(self) -> Optional['outputs.GetJobJobSettingsSettingsGitSourceJobSourceResult']:
        return pulumi.get(self, "job_source")

    @property
    @pulumi.getter
    def provider(self) -> Optional[str]:
        return pulumi.get(self, "provider")

    @property
    @pulumi.getter
    def tag(self) -> Optional[str]:
        return pulumi.get(self, "tag")


@pulumi.output_type
class GetJobJobSettingsSettingsGitSourceJobSourceResult(dict):
    def __init__(__self__, *,
                 import_from_git_branch: str,
                 job_config_path: str,
                 dirty_state: Optional[str] = None):
        pulumi.set(__self__, "import_from_git_branch", import_from_git_branch)
        pulumi.set(__self__, "job_config_path", job_config_path)
        if dirty_state is not None:
            pulumi.set(__self__, "dirty_state", dirty_state)

    @property
    @pulumi.getter(name="importFromGitBranch")
    def import_from_git_branch(self) -> str:
        return pulumi.get(self, "import_from_git_branch")

    @property
    @pulumi.getter(name="jobConfigPath")
    def job_config_path(self) -> str:
        return pulumi.get(self, "job_config_path")

    @property
    @pulumi.getter(name="dirtyState")
    def dirty_state(self) -> Optional[str]:
        return pulumi.get(self, "dirty_state")


@pulumi.output_type
class GetJobJobSettingsSettingsHealthResult(dict):
    def __init__(__self__, *,
                 rules: Sequence['outputs.GetJobJobSettingsSettingsHealthRuleResult']):
        pulumi.set(__self__, "rules", rules)

    @property
    @pulumi.getter
    def rules(self) -> Sequence['outputs.GetJobJobSettingsSettingsHealthRuleResult']:
        return pulumi.get(self, "rules")


@pulumi.output_type
class GetJobJobSettingsSettingsHealthRuleResult(dict):
    def __init__(__self__, *,
                 metric: Optional[str] = None,
                 op: Optional[str] = None,
                 value: Optional[int] = None):
        if metric is not None:
            pulumi.set(__self__, "metric", metric)
        if op is not None:
            pulumi.set(__self__, "op", op)
        if value is not None:
            pulumi.set(__self__, "value", value)

    @property
    @pulumi.getter
    def metric(self) -> Optional[str]:
        return pulumi.get(self, "metric")

    @property
    @pulumi.getter
    def op(self) -> Optional[str]:
        return pulumi.get(self, "op")

    @property
    @pulumi.getter
    def value(self) -> Optional[int]:
        return pulumi.get(self, "value")


@pulumi.output_type
class GetJobJobSettingsSettingsJobClusterResult(dict):
    def __init__(__self__, *,
                 job_cluster_key: Optional[str] = None,
                 new_cluster: Optional['outputs.GetJobJobSettingsSettingsJobClusterNewClusterResult'] = None):
        if job_cluster_key is not None:
            pulumi.set(__self__, "job_cluster_key", job_cluster_key)
        if new_cluster is not None:
            pulumi.set(__self__, "new_cluster", new_cluster)

    @property
    @pulumi.getter(name="jobClusterKey")
    def job_cluster_key(self) -> Optional[str]:
        return pulumi.get(self, "job_cluster_key")

    @property
    @pulumi.getter(name="newCluster")
    def new_cluster(self) -> Optional['outputs.GetJobJobSettingsSettingsJobClusterNewClusterResult']:
        return pulumi.get(self, "new_cluster")


@pulumi.output_type
class GetJobJobSettingsSettingsJobClusterNewClusterResult(dict):
    def __init__(__self__, *,
                 driver_instance_pool_id: str,
                 driver_node_type_id: str,
                 enable_elastic_disk: bool,
                 enable_local_disk_encryption: bool,
                 node_type_id: str,
                 num_workers: int,
                 spark_version: str,
                 apply_policy_default_values: Optional[bool] = None,
                 autoscale: Optional['outputs.GetJobJobSettingsSettingsJobClusterNewClusterAutoscaleResult'] = None,
                 autotermination_minutes: Optional[int] = None,
                 aws_attributes: Optional['outputs.GetJobJobSettingsSettingsJobClusterNewClusterAwsAttributesResult'] = None,
                 azure_attributes: Optional['outputs.GetJobJobSettingsSettingsJobClusterNewClusterAzureAttributesResult'] = None,
                 cluster_id: Optional[str] = None,
                 cluster_log_conf: Optional['outputs.GetJobJobSettingsSettingsJobClusterNewClusterClusterLogConfResult'] = None,
                 cluster_mount_infos: Optional[Sequence['outputs.GetJobJobSettingsSettingsJobClusterNewClusterClusterMountInfoResult']] = None,
                 cluster_name: Optional[str] = None,
                 custom_tags: Optional[Mapping[str, Any]] = None,
                 data_security_mode: Optional[str] = None,
                 docker_image: Optional['outputs.GetJobJobSettingsSettingsJobClusterNewClusterDockerImageResult'] = None,
                 gcp_attributes: Optional['outputs.GetJobJobSettingsSettingsJobClusterNewClusterGcpAttributesResult'] = None,
                 idempotency_token: Optional[str] = None,
                 init_scripts: Optional[Sequence['outputs.GetJobJobSettingsSettingsJobClusterNewClusterInitScriptResult']] = None,
                 instance_pool_id: Optional[str] = None,
                 policy_id: Optional[str] = None,
                 runtime_engine: Optional[str] = None,
                 single_user_name: Optional[str] = None,
                 spark_conf: Optional[Mapping[str, Any]] = None,
                 spark_env_vars: Optional[Mapping[str, Any]] = None,
                 ssh_public_keys: Optional[Sequence[str]] = None,
                 workload_type: Optional['outputs.GetJobJobSettingsSettingsJobClusterNewClusterWorkloadTypeResult'] = None):
        pulumi.set(__self__, "driver_instance_pool_id", driver_instance_pool_id)
        pulumi.set(__self__, "driver_node_type_id", driver_node_type_id)
        pulumi.set(__self__, "enable_elastic_disk", enable_elastic_disk)
        pulumi.set(__self__, "enable_local_disk_encryption", enable_local_disk_encryption)
        pulumi.set(__self__, "node_type_id", node_type_id)
        pulumi.set(__self__, "num_workers", num_workers)
        pulumi.set(__self__, "spark_version", spark_version)
        if apply_policy_default_values is not None:
            pulumi.set(__self__, "apply_policy_default_values", apply_policy_default_values)
        if autoscale is not None:
            pulumi.set(__self__, "autoscale", autoscale)
        if autotermination_minutes is not None:
            pulumi.set(__self__, "autotermination_minutes", autotermination_minutes)
        if aws_attributes is not None:
            pulumi.set(__self__, "aws_attributes", aws_attributes)
        if azure_attributes is not None:
            pulumi.set(__self__, "azure_attributes", azure_attributes)
        if cluster_id is not None:
            pulumi.set(__self__, "cluster_id", cluster_id)
        if cluster_log_conf is not None:
            pulumi.set(__self__, "cluster_log_conf", cluster_log_conf)
        if cluster_mount_infos is not None:
            pulumi.set(__self__, "cluster_mount_infos", cluster_mount_infos)
        if cluster_name is not None:
            pulumi.set(__self__, "cluster_name", cluster_name)
        if custom_tags is not None:
            pulumi.set(__self__, "custom_tags", custom_tags)
        if data_security_mode is not None:
            pulumi.set(__self__, "data_security_mode", data_security_mode)
        if docker_image is not None:
            pulumi.set(__self__, "docker_image", docker_image)
        if gcp_attributes is not None:
            pulumi.set(__self__, "gcp_attributes", gcp_attributes)
        if idempotency_token is not None:
            pulumi.set(__self__, "idempotency_token", idempotency_token)
        if init_scripts is not None:
            pulumi.set(__self__, "init_scripts", init_scripts)
        if instance_pool_id is not None:
            pulumi.set(__self__, "instance_pool_id", instance_pool_id)
        if policy_id is not None:
            pulumi.set(__self__, "policy_id", policy_id)
        if runtime_engine is not None:
            pulumi.set(__self__, "runtime_engine", runtime_engine)
        if single_user_name is not None:
            pulumi.set(__self__, "single_user_name", single_user_name)
        if spark_conf is not None:
            pulumi.set(__self__, "spark_conf", spark_conf)
        if spark_env_vars is not None:
            pulumi.set(__self__, "spark_env_vars", spark_env_vars)
        if ssh_public_keys is not None:
            pulumi.set(__self__, "ssh_public_keys", ssh_public_keys)
        if workload_type is not None:
            pulumi.set(__self__, "workload_type", workload_type)

    @property
    @pulumi.getter(name="driverInstancePoolId")
    def driver_instance_pool_id(self) -> str:
        return pulumi.get(self, "driver_instance_pool_id")

    @property
    @pulumi.getter(name="driverNodeTypeId")
    def driver_node_type_id(self) -> str:
        return pulumi.get(self, "driver_node_type_id")

    @property
    @pulumi.getter(name="enableElasticDisk")
    def enable_elastic_disk(self) -> bool:
        return pulumi.get(self, "enable_elastic_disk")

    @property
    @pulumi.getter(name="enableLocalDiskEncryption")
    def enable_local_disk_encryption(self) -> bool:
        return pulumi.get(self, "enable_local_disk_encryption")

    @property
    @pulumi.getter(name="nodeTypeId")
    def node_type_id(self) -> str:
        return pulumi.get(self, "node_type_id")

    @property
    @pulumi.getter(name="numWorkers")
    def num_workers(self) -> int:
        return pulumi.get(self, "num_workers")

    @property
    @pulumi.getter(name="sparkVersion")
    def spark_version(self) -> str:
        return pulumi.get(self, "spark_version")

    @property
    @pulumi.getter(name="applyPolicyDefaultValues")
    def apply_policy_default_values(self) -> Optional[bool]:
        return pulumi.get(self, "apply_policy_default_values")

    @property
    @pulumi.getter
    def autoscale(self) -> Optional['outputs.GetJobJobSettingsSettingsJobClusterNewClusterAutoscaleResult']:
        return pulumi.get(self, "autoscale")

    @property
    @pulumi.getter(name="autoterminationMinutes")
    def autotermination_minutes(self) -> Optional[int]:
        return pulumi.get(self, "autotermination_minutes")

    @property
    @pulumi.getter(name="awsAttributes")
    def aws_attributes(self) -> Optional['outputs.GetJobJobSettingsSettingsJobClusterNewClusterAwsAttributesResult']:
        return pulumi.get(self, "aws_attributes")

    @property
    @pulumi.getter(name="azureAttributes")
    def azure_attributes(self) -> Optional['outputs.GetJobJobSettingsSettingsJobClusterNewClusterAzureAttributesResult']:
        return pulumi.get(self, "azure_attributes")

    @property
    @pulumi.getter(name="clusterId")
    def cluster_id(self) -> Optional[str]:
        return pulumi.get(self, "cluster_id")

    @property
    @pulumi.getter(name="clusterLogConf")
    def cluster_log_conf(self) -> Optional['outputs.GetJobJobSettingsSettingsJobClusterNewClusterClusterLogConfResult']:
        return pulumi.get(self, "cluster_log_conf")

    @property
    @pulumi.getter(name="clusterMountInfos")
    def cluster_mount_infos(self) -> Optional[Sequence['outputs.GetJobJobSettingsSettingsJobClusterNewClusterClusterMountInfoResult']]:
        return pulumi.get(self, "cluster_mount_infos")

    @property
    @pulumi.getter(name="clusterName")
    def cluster_name(self) -> Optional[str]:
        return pulumi.get(self, "cluster_name")

    @property
    @pulumi.getter(name="customTags")
    def custom_tags(self) -> Optional[Mapping[str, Any]]:
        return pulumi.get(self, "custom_tags")

    @property
    @pulumi.getter(name="dataSecurityMode")
    def data_security_mode(self) -> Optional[str]:
        return pulumi.get(self, "data_security_mode")

    @property
    @pulumi.getter(name="dockerImage")
    def docker_image(self) -> Optional['outputs.GetJobJobSettingsSettingsJobClusterNewClusterDockerImageResult']:
        return pulumi.get(self, "docker_image")

    @property
    @pulumi.getter(name="gcpAttributes")
    def gcp_attributes(self) -> Optional['outputs.GetJobJobSettingsSettingsJobClusterNewClusterGcpAttributesResult']:
        return pulumi.get(self, "gcp_attributes")

    @property
    @pulumi.getter(name="idempotencyToken")
    def idempotency_token(self) -> Optional[str]:
        return pulumi.get(self, "idempotency_token")

    @property
    @pulumi.getter(name="initScripts")
    def init_scripts(self) -> Optional[Sequence['outputs.GetJobJobSettingsSettingsJobClusterNewClusterInitScriptResult']]:
        return pulumi.get(self, "init_scripts")

    @property
    @pulumi.getter(name="instancePoolId")
    def instance_pool_id(self) -> Optional[str]:
        return pulumi.get(self, "instance_pool_id")

    @property
    @pulumi.getter(name="policyId")
    def policy_id(self) -> Optional[str]:
        return pulumi.get(self, "policy_id")

    @property
    @pulumi.getter(name="runtimeEngine")
    def runtime_engine(self) -> Optional[str]:
        return pulumi.get(self, "runtime_engine")

    @property
    @pulumi.getter(name="singleUserName")
    def single_user_name(self) -> Optional[str]:
        return pulumi.get(self, "single_user_name")

    @property
    @pulumi.getter(name="sparkConf")
    def spark_conf(self) -> Optional[Mapping[str, Any]]:
        return pulumi.get(self, "spark_conf")

    @property
    @pulumi.getter(name="sparkEnvVars")
    def spark_env_vars(self) -> Optional[Mapping[str, Any]]:
        return pulumi.get(self, "spark_env_vars")

    @property
    @pulumi.getter(name="sshPublicKeys")
    def ssh_public_keys(self) -> Optional[Sequence[str]]:
        return pulumi.get(self, "ssh_public_keys")

    @property
    @pulumi.getter(name="workloadType")
    def workload_type(self) -> Optional['outputs.GetJobJobSettingsSettingsJobClusterNewClusterWorkloadTypeResult']:
        return pulumi.get(self, "workload_type")


@pulumi.output_type
class GetJobJobSettingsSettingsJobClusterNewClusterAutoscaleResult(dict):
    def __init__(__self__, *,
                 max_workers: Optional[int] = None,
                 min_workers: Optional[int] = None):
        if max_workers is not None:
            pulumi.set(__self__, "max_workers", max_workers)
        if min_workers is not None:
            pulumi.set(__self__, "min_workers", min_workers)

    @property
    @pulumi.getter(name="maxWorkers")
    def max_workers(self) -> Optional[int]:
        return pulumi.get(self, "max_workers")

    @property
    @pulumi.getter(name="minWorkers")
    def min_workers(self) -> Optional[int]:
        return pulumi.get(self, "min_workers")


@pulumi.output_type
class GetJobJobSettingsSettingsJobClusterNewClusterAwsAttributesResult(dict):
    def __init__(__self__, *,
                 availability: Optional[str] = None,
                 ebs_volume_count: Optional[int] = None,
                 ebs_volume_size: Optional[int] = None,
                 ebs_volume_type: Optional[str] = None,
                 first_on_demand: Optional[int] = None,
                 instance_profile_arn: Optional[str] = None,
                 spot_bid_price_percent: Optional[int] = None,
                 zone_id: Optional[str] = None):
        if availability is not None:
            pulumi.set(__self__, "availability", availability)
        if ebs_volume_count is not None:
            pulumi.set(__self__, "ebs_volume_count", ebs_volume_count)
        if ebs_volume_size is not None:
            pulumi.set(__self__, "ebs_volume_size", ebs_volume_size)
        if ebs_volume_type is not None:
            pulumi.set(__self__, "ebs_volume_type", ebs_volume_type)
        if first_on_demand is not None:
            pulumi.set(__self__, "first_on_demand", first_on_demand)
        if instance_profile_arn is not None:
            pulumi.set(__self__, "instance_profile_arn", instance_profile_arn)
        if spot_bid_price_percent is not None:
            pulumi.set(__self__, "spot_bid_price_percent", spot_bid_price_percent)
        if zone_id is not None:
            pulumi.set(__self__, "zone_id", zone_id)

    @property
    @pulumi.getter
    def availability(self) -> Optional[str]:
        return pulumi.get(self, "availability")

    @property
    @pulumi.getter(name="ebsVolumeCount")
    def ebs_volume_count(self) -> Optional[int]:
        return pulumi.get(self, "ebs_volume_count")

    @property
    @pulumi.getter(name="ebsVolumeSize")
    def ebs_volume_size(self) -> Optional[int]:
        return pulumi.get(self, "ebs_volume_size")

    @property
    @pulumi.getter(name="ebsVolumeType")
    def ebs_volume_type(self) -> Optional[str]:
        return pulumi.get(self, "ebs_volume_type")

    @property
    @pulumi.getter(name="firstOnDemand")
    def first_on_demand(self) -> Optional[int]:
        return pulumi.get(self, "first_on_demand")

    @property
    @pulumi.getter(name="instanceProfileArn")
    def instance_profile_arn(self) -> Optional[str]:
        return pulumi.get(self, "instance_profile_arn")

    @property
    @pulumi.getter(name="spotBidPricePercent")
    def spot_bid_price_percent(self) -> Optional[int]:
        return pulumi.get(self, "spot_bid_price_percent")

    @property
    @pulumi.getter(name="zoneId")
    def zone_id(self) -> Optional[str]:
        return pulumi.get(self, "zone_id")


@pulumi.output_type
class GetJobJobSettingsSettingsJobClusterNewClusterAzureAttributesResult(dict):
    def __init__(__self__, *,
                 availability: Optional[str] = None,
                 first_on_demand: Optional[int] = None,
                 spot_bid_max_price: Optional[float] = None):
        if availability is not None:
            pulumi.set(__self__, "availability", availability)
        if first_on_demand is not None:
            pulumi.set(__self__, "first_on_demand", first_on_demand)
        if spot_bid_max_price is not None:
            pulumi.set(__self__, "spot_bid_max_price", spot_bid_max_price)

    @property
    @pulumi.getter
    def availability(self) -> Optional[str]:
        return pulumi.get(self, "availability")

    @property
    @pulumi.getter(name="firstOnDemand")
    def first_on_demand(self) -> Optional[int]:
        return pulumi.get(self, "first_on_demand")

    @property
    @pulumi.getter(name="spotBidMaxPrice")
    def spot_bid_max_price(self) -> Optional[float]:
        return pulumi.get(self, "spot_bid_max_price")


@pulumi.output_type
class GetJobJobSettingsSettingsJobClusterNewClusterClusterLogConfResult(dict):
    def __init__(__self__, *,
                 dbfs: Optional['outputs.GetJobJobSettingsSettingsJobClusterNewClusterClusterLogConfDbfsResult'] = None,
                 s3: Optional['outputs.GetJobJobSettingsSettingsJobClusterNewClusterClusterLogConfS3Result'] = None):
        if dbfs is not None:
            pulumi.set(__self__, "dbfs", dbfs)
        if s3 is not None:
            pulumi.set(__self__, "s3", s3)

    @property
    @pulumi.getter
    def dbfs(self) -> Optional['outputs.GetJobJobSettingsSettingsJobClusterNewClusterClusterLogConfDbfsResult']:
        return pulumi.get(self, "dbfs")

    @property
    @pulumi.getter
    def s3(self) -> Optional['outputs.GetJobJobSettingsSettingsJobClusterNewClusterClusterLogConfS3Result']:
        return pulumi.get(self, "s3")


@pulumi.output_type
class GetJobJobSettingsSettingsJobClusterNewClusterClusterLogConfDbfsResult(dict):
    def __init__(__self__, *,
                 destination: str):
        pulumi.set(__self__, "destination", destination)

    @property
    @pulumi.getter
    def destination(self) -> str:
        return pulumi.get(self, "destination")


@pulumi.output_type
class GetJobJobSettingsSettingsJobClusterNewClusterClusterLogConfS3Result(dict):
    def __init__(__self__, *,
                 destination: str,
                 canned_acl: Optional[str] = None,
                 enable_encryption: Optional[bool] = None,
                 encryption_type: Optional[str] = None,
                 endpoint: Optional[str] = None,
                 kms_key: Optional[str] = None,
                 region: Optional[str] = None):
        pulumi.set(__self__, "destination", destination)
        if canned_acl is not None:
            pulumi.set(__self__, "canned_acl", canned_acl)
        if enable_encryption is not None:
            pulumi.set(__self__, "enable_encryption", enable_encryption)
        if encryption_type is not None:
            pulumi.set(__self__, "encryption_type", encryption_type)
        if endpoint is not None:
            pulumi.set(__self__, "endpoint", endpoint)
        if kms_key is not None:
            pulumi.set(__self__, "kms_key", kms_key)
        if region is not None:
            pulumi.set(__self__, "region", region)

    @property
    @pulumi.getter
    def destination(self) -> str:
        return pulumi.get(self, "destination")

    @property
    @pulumi.getter(name="cannedAcl")
    def canned_acl(self) -> Optional[str]:
        return pulumi.get(self, "canned_acl")

    @property
    @pulumi.getter(name="enableEncryption")
    def enable_encryption(self) -> Optional[bool]:
        return pulumi.get(self, "enable_encryption")

    @property
    @pulumi.getter(name="encryptionType")
    def encryption_type(self) -> Optional[str]:
        return pulumi.get(self, "encryption_type")

    @property
    @pulumi.getter
    def endpoint(self) -> Optional[str]:
        return pulumi.get(self, "endpoint")

    @property
    @pulumi.getter(name="kmsKey")
    def kms_key(self) -> Optional[str]:
        return pulumi.get(self, "kms_key")

    @property
    @pulumi.getter
    def region(self) -> Optional[str]:
        return pulumi.get(self, "region")


@pulumi.output_type
class GetJobJobSettingsSettingsJobClusterNewClusterClusterMountInfoResult(dict):
    def __init__(__self__, *,
                 local_mount_dir_path: str,
                 network_filesystem_info: 'outputs.GetJobJobSettingsSettingsJobClusterNewClusterClusterMountInfoNetworkFilesystemInfoResult',
                 remote_mount_dir_path: Optional[str] = None):
        pulumi.set(__self__, "local_mount_dir_path", local_mount_dir_path)
        pulumi.set(__self__, "network_filesystem_info", network_filesystem_info)
        if remote_mount_dir_path is not None:
            pulumi.set(__self__, "remote_mount_dir_path", remote_mount_dir_path)

    @property
    @pulumi.getter(name="localMountDirPath")
    def local_mount_dir_path(self) -> str:
        return pulumi.get(self, "local_mount_dir_path")

    @property
    @pulumi.getter(name="networkFilesystemInfo")
    def network_filesystem_info(self) -> 'outputs.GetJobJobSettingsSettingsJobClusterNewClusterClusterMountInfoNetworkFilesystemInfoResult':
        return pulumi.get(self, "network_filesystem_info")

    @property
    @pulumi.getter(name="remoteMountDirPath")
    def remote_mount_dir_path(self) -> Optional[str]:
        return pulumi.get(self, "remote_mount_dir_path")


@pulumi.output_type
class GetJobJobSettingsSettingsJobClusterNewClusterClusterMountInfoNetworkFilesystemInfoResult(dict):
    def __init__(__self__, *,
                 server_address: str,
                 mount_options: Optional[str] = None):
        pulumi.set(__self__, "server_address", server_address)
        if mount_options is not None:
            pulumi.set(__self__, "mount_options", mount_options)

    @property
    @pulumi.getter(name="serverAddress")
    def server_address(self) -> str:
        return pulumi.get(self, "server_address")

    @property
    @pulumi.getter(name="mountOptions")
    def mount_options(self) -> Optional[str]:
        return pulumi.get(self, "mount_options")


@pulumi.output_type
class GetJobJobSettingsSettingsJobClusterNewClusterDockerImageResult(dict):
    def __init__(__self__, *,
                 url: str,
                 basic_auth: Optional['outputs.GetJobJobSettingsSettingsJobClusterNewClusterDockerImageBasicAuthResult'] = None):
        pulumi.set(__self__, "url", url)
        if basic_auth is not None:
            pulumi.set(__self__, "basic_auth", basic_auth)

    @property
    @pulumi.getter
    def url(self) -> str:
        return pulumi.get(self, "url")

    @property
    @pulumi.getter(name="basicAuth")
    def basic_auth(self) -> Optional['outputs.GetJobJobSettingsSettingsJobClusterNewClusterDockerImageBasicAuthResult']:
        return pulumi.get(self, "basic_auth")


@pulumi.output_type
class GetJobJobSettingsSettingsJobClusterNewClusterDockerImageBasicAuthResult(dict):
    def __init__(__self__, *,
                 password: str,
                 username: str):
        pulumi.set(__self__, "password", password)
        pulumi.set(__self__, "username", username)

    @property
    @pulumi.getter
    def password(self) -> str:
        return pulumi.get(self, "password")

    @property
    @pulumi.getter
    def username(self) -> str:
        return pulumi.get(self, "username")


@pulumi.output_type
class GetJobJobSettingsSettingsJobClusterNewClusterGcpAttributesResult(dict):
    def __init__(__self__, *,
                 availability: Optional[str] = None,
                 boot_disk_size: Optional[int] = None,
                 google_service_account: Optional[str] = None,
                 local_ssd_count: Optional[int] = None,
                 use_preemptible_executors: Optional[bool] = None,
                 zone_id: Optional[str] = None):
        if availability is not None:
            pulumi.set(__self__, "availability", availability)
        if boot_disk_size is not None:
            pulumi.set(__self__, "boot_disk_size", boot_disk_size)
        if google_service_account is not None:
            pulumi.set(__self__, "google_service_account", google_service_account)
        if local_ssd_count is not None:
            pulumi.set(__self__, "local_ssd_count", local_ssd_count)
        if use_preemptible_executors is not None:
            pulumi.set(__self__, "use_preemptible_executors", use_preemptible_executors)
        if zone_id is not None:
            pulumi.set(__self__, "zone_id", zone_id)

    @property
    @pulumi.getter
    def availability(self) -> Optional[str]:
        return pulumi.get(self, "availability")

    @property
    @pulumi.getter(name="bootDiskSize")
    def boot_disk_size(self) -> Optional[int]:
        return pulumi.get(self, "boot_disk_size")

    @property
    @pulumi.getter(name="googleServiceAccount")
    def google_service_account(self) -> Optional[str]:
        return pulumi.get(self, "google_service_account")

    @property
    @pulumi.getter(name="localSsdCount")
    def local_ssd_count(self) -> Optional[int]:
        return pulumi.get(self, "local_ssd_count")

    @property
    @pulumi.getter(name="usePreemptibleExecutors")
    def use_preemptible_executors(self) -> Optional[bool]:
        return pulumi.get(self, "use_preemptible_executors")

    @property
    @pulumi.getter(name="zoneId")
    def zone_id(self) -> Optional[str]:
        return pulumi.get(self, "zone_id")


@pulumi.output_type
class GetJobJobSettingsSettingsJobClusterNewClusterInitScriptResult(dict):
    def __init__(__self__, *,
                 abfss: Optional['outputs.GetJobJobSettingsSettingsJobClusterNewClusterInitScriptAbfssResult'] = None,
                 dbfs: Optional['outputs.GetJobJobSettingsSettingsJobClusterNewClusterInitScriptDbfsResult'] = None,
                 file: Optional['outputs.GetJobJobSettingsSettingsJobClusterNewClusterInitScriptFileResult'] = None,
                 gcs: Optional['outputs.GetJobJobSettingsSettingsJobClusterNewClusterInitScriptGcsResult'] = None,
                 s3: Optional['outputs.GetJobJobSettingsSettingsJobClusterNewClusterInitScriptS3Result'] = None,
                 volumes: Optional['outputs.GetJobJobSettingsSettingsJobClusterNewClusterInitScriptVolumesResult'] = None,
                 workspace: Optional['outputs.GetJobJobSettingsSettingsJobClusterNewClusterInitScriptWorkspaceResult'] = None):
        if abfss is not None:
            pulumi.set(__self__, "abfss", abfss)
        if dbfs is not None:
            pulumi.set(__self__, "dbfs", dbfs)
        if file is not None:
            pulumi.set(__self__, "file", file)
        if gcs is not None:
            pulumi.set(__self__, "gcs", gcs)
        if s3 is not None:
            pulumi.set(__self__, "s3", s3)
        if volumes is not None:
            pulumi.set(__self__, "volumes", volumes)
        if workspace is not None:
            pulumi.set(__self__, "workspace", workspace)

    @property
    @pulumi.getter
    def abfss(self) -> Optional['outputs.GetJobJobSettingsSettingsJobClusterNewClusterInitScriptAbfssResult']:
        return pulumi.get(self, "abfss")

    @property
    @pulumi.getter
    def dbfs(self) -> Optional['outputs.GetJobJobSettingsSettingsJobClusterNewClusterInitScriptDbfsResult']:
        return pulumi.get(self, "dbfs")

    @property
    @pulumi.getter
    def file(self) -> Optional['outputs.GetJobJobSettingsSettingsJobClusterNewClusterInitScriptFileResult']:
        return pulumi.get(self, "file")

    @property
    @pulumi.getter
    def gcs(self) -> Optional['outputs.GetJobJobSettingsSettingsJobClusterNewClusterInitScriptGcsResult']:
        return pulumi.get(self, "gcs")

    @property
    @pulumi.getter
    def s3(self) -> Optional['outputs.GetJobJobSettingsSettingsJobClusterNewClusterInitScriptS3Result']:
        return pulumi.get(self, "s3")

    @property
    @pulumi.getter
    def volumes(self) -> Optional['outputs.GetJobJobSettingsSettingsJobClusterNewClusterInitScriptVolumesResult']:
        return pulumi.get(self, "volumes")

    @property
    @pulumi.getter
    def workspace(self) -> Optional['outputs.GetJobJobSettingsSettingsJobClusterNewClusterInitScriptWorkspaceResult']:
        return pulumi.get(self, "workspace")


@pulumi.output_type
class GetJobJobSettingsSettingsJobClusterNewClusterInitScriptAbfssResult(dict):
    def __init__(__self__, *,
                 destination: str):
        pulumi.set(__self__, "destination", destination)

    @property
    @pulumi.getter
    def destination(self) -> str:
        return pulumi.get(self, "destination")


@pulumi.output_type
class GetJobJobSettingsSettingsJobClusterNewClusterInitScriptDbfsResult(dict):
    def __init__(__self__, *,
                 destination: str):
        pulumi.set(__self__, "destination", destination)

    @property
    @pulumi.getter
    def destination(self) -> str:
        return pulumi.get(self, "destination")


@pulumi.output_type
class GetJobJobSettingsSettingsJobClusterNewClusterInitScriptFileResult(dict):
    def __init__(__self__, *,
                 destination: str):
        pulumi.set(__self__, "destination", destination)

    @property
    @pulumi.getter
    def destination(self) -> str:
        return pulumi.get(self, "destination")


@pulumi.output_type
class GetJobJobSettingsSettingsJobClusterNewClusterInitScriptGcsResult(dict):
    def __init__(__self__, *,
                 destination: str):
        pulumi.set(__self__, "destination", destination)

    @property
    @pulumi.getter
    def destination(self) -> str:
        return pulumi.get(self, "destination")


@pulumi.output_type
class GetJobJobSettingsSettingsJobClusterNewClusterInitScriptS3Result(dict):
    def __init__(__self__, *,
                 destination: str,
                 canned_acl: Optional[str] = None,
                 enable_encryption: Optional[bool] = None,
                 encryption_type: Optional[str] = None,
                 endpoint: Optional[str] = None,
                 kms_key: Optional[str] = None,
                 region: Optional[str] = None):
        pulumi.set(__self__, "destination", destination)
        if canned_acl is not None:
            pulumi.set(__self__, "canned_acl", canned_acl)
        if enable_encryption is not None:
            pulumi.set(__self__, "enable_encryption", enable_encryption)
        if encryption_type is not None:
            pulumi.set(__self__, "encryption_type", encryption_type)
        if endpoint is not None:
            pulumi.set(__self__, "endpoint", endpoint)
        if kms_key is not None:
            pulumi.set(__self__, "kms_key", kms_key)
        if region is not None:
            pulumi.set(__self__, "region", region)

    @property
    @pulumi.getter
    def destination(self) -> str:
        return pulumi.get(self, "destination")

    @property
    @pulumi.getter(name="cannedAcl")
    def canned_acl(self) -> Optional[str]:
        return pulumi.get(self, "canned_acl")

    @property
    @pulumi.getter(name="enableEncryption")
    def enable_encryption(self) -> Optional[bool]:
        return pulumi.get(self, "enable_encryption")

    @property
    @pulumi.getter(name="encryptionType")
    def encryption_type(self) -> Optional[str]:
        return pulumi.get(self, "encryption_type")

    @property
    @pulumi.getter
    def endpoint(self) -> Optional[str]:
        return pulumi.get(self, "endpoint")

    @property
    @pulumi.getter(name="kmsKey")
    def kms_key(self) -> Optional[str]:
        return pulumi.get(self, "kms_key")

    @property
    @pulumi.getter
    def region(self) -> Optional[str]:
        return pulumi.get(self, "region")


@pulumi.output_type
class GetJobJobSettingsSettingsJobClusterNewClusterInitScriptVolumesResult(dict):
    def __init__(__self__, *,
                 destination: str):
        pulumi.set(__self__, "destination", destination)

    @property
    @pulumi.getter
    def destination(self) -> str:
        return pulumi.get(self, "destination")


@pulumi.output_type
class GetJobJobSettingsSettingsJobClusterNewClusterInitScriptWorkspaceResult(dict):
    def __init__(__self__, *,
                 destination: str):
        pulumi.set(__self__, "destination", destination)

    @property
    @pulumi.getter
    def destination(self) -> str:
        return pulumi.get(self, "destination")


@pulumi.output_type
class GetJobJobSettingsSettingsJobClusterNewClusterWorkloadTypeResult(dict):
    def __init__(__self__, *,
                 clients: 'outputs.GetJobJobSettingsSettingsJobClusterNewClusterWorkloadTypeClientsResult'):
        pulumi.set(__self__, "clients", clients)

    @property
    @pulumi.getter
    def clients(self) -> 'outputs.GetJobJobSettingsSettingsJobClusterNewClusterWorkloadTypeClientsResult':
        return pulumi.get(self, "clients")


@pulumi.output_type
class GetJobJobSettingsSettingsJobClusterNewClusterWorkloadTypeClientsResult(dict):
    def __init__(__self__, *,
                 jobs: Optional[bool] = None,
                 notebooks: Optional[bool] = None):
        if jobs is not None:
            pulumi.set(__self__, "jobs", jobs)
        if notebooks is not None:
            pulumi.set(__self__, "notebooks", notebooks)

    @property
    @pulumi.getter
    def jobs(self) -> Optional[bool]:
        return pulumi.get(self, "jobs")

    @property
    @pulumi.getter
    def notebooks(self) -> Optional[bool]:
        return pulumi.get(self, "notebooks")


@pulumi.output_type
class GetJobJobSettingsSettingsLibraryResult(dict):
    def __init__(__self__, *,
                 cran: Optional['outputs.GetJobJobSettingsSettingsLibraryCranResult'] = None,
                 egg: Optional[str] = None,
                 jar: Optional[str] = None,
                 maven: Optional['outputs.GetJobJobSettingsSettingsLibraryMavenResult'] = None,
                 pypi: Optional['outputs.GetJobJobSettingsSettingsLibraryPypiResult'] = None,
                 whl: Optional[str] = None):
        if cran is not None:
            pulumi.set(__self__, "cran", cran)
        if egg is not None:
            pulumi.set(__self__, "egg", egg)
        if jar is not None:
            pulumi.set(__self__, "jar", jar)
        if maven is not None:
            pulumi.set(__self__, "maven", maven)
        if pypi is not None:
            pulumi.set(__self__, "pypi", pypi)
        if whl is not None:
            pulumi.set(__self__, "whl", whl)

    @property
    @pulumi.getter
    def cran(self) -> Optional['outputs.GetJobJobSettingsSettingsLibraryCranResult']:
        return pulumi.get(self, "cran")

    @property
    @pulumi.getter
    def egg(self) -> Optional[str]:
        return pulumi.get(self, "egg")

    @property
    @pulumi.getter
    def jar(self) -> Optional[str]:
        return pulumi.get(self, "jar")

    @property
    @pulumi.getter
    def maven(self) -> Optional['outputs.GetJobJobSettingsSettingsLibraryMavenResult']:
        return pulumi.get(self, "maven")

    @property
    @pulumi.getter
    def pypi(self) -> Optional['outputs.GetJobJobSettingsSettingsLibraryPypiResult']:
        return pulumi.get(self, "pypi")

    @property
    @pulumi.getter
    def whl(self) -> Optional[str]:
        return pulumi.get(self, "whl")


@pulumi.output_type
class GetJobJobSettingsSettingsLibraryCranResult(dict):
    def __init__(__self__, *,
                 package: str,
                 repo: Optional[str] = None):
        pulumi.set(__self__, "package", package)
        if repo is not None:
            pulumi.set(__self__, "repo", repo)

    @property
    @pulumi.getter
    def package(self) -> str:
        return pulumi.get(self, "package")

    @property
    @pulumi.getter
    def repo(self) -> Optional[str]:
        return pulumi.get(self, "repo")


@pulumi.output_type
class GetJobJobSettingsSettingsLibraryMavenResult(dict):
    def __init__(__self__, *,
                 coordinates: str,
                 exclusions: Optional[Sequence[str]] = None,
                 repo: Optional[str] = None):
        pulumi.set(__self__, "coordinates", coordinates)
        if exclusions is not None:
            pulumi.set(__self__, "exclusions", exclusions)
        if repo is not None:
            pulumi.set(__self__, "repo", repo)

    @property
    @pulumi.getter
    def coordinates(self) -> str:
        return pulumi.get(self, "coordinates")

    @property
    @pulumi.getter
    def exclusions(self) -> Optional[Sequence[str]]:
        return pulumi.get(self, "exclusions")

    @property
    @pulumi.getter
    def repo(self) -> Optional[str]:
        return pulumi.get(self, "repo")


@pulumi.output_type
class GetJobJobSettingsSettingsLibraryPypiResult(dict):
    def __init__(__self__, *,
                 package: str,
                 repo: Optional[str] = None):
        pulumi.set(__self__, "package", package)
        if repo is not None:
            pulumi.set(__self__, "repo", repo)

    @property
    @pulumi.getter
    def package(self) -> str:
        return pulumi.get(self, "package")

    @property
    @pulumi.getter
    def repo(self) -> Optional[str]:
        return pulumi.get(self, "repo")


@pulumi.output_type
class GetJobJobSettingsSettingsNewClusterResult(dict):
    def __init__(__self__, *,
                 driver_instance_pool_id: str,
                 driver_node_type_id: str,
                 enable_elastic_disk: bool,
                 enable_local_disk_encryption: bool,
                 node_type_id: str,
                 num_workers: int,
                 spark_version: str,
                 apply_policy_default_values: Optional[bool] = None,
                 autoscale: Optional['outputs.GetJobJobSettingsSettingsNewClusterAutoscaleResult'] = None,
                 autotermination_minutes: Optional[int] = None,
                 aws_attributes: Optional['outputs.GetJobJobSettingsSettingsNewClusterAwsAttributesResult'] = None,
                 azure_attributes: Optional['outputs.GetJobJobSettingsSettingsNewClusterAzureAttributesResult'] = None,
                 cluster_id: Optional[str] = None,
                 cluster_log_conf: Optional['outputs.GetJobJobSettingsSettingsNewClusterClusterLogConfResult'] = None,
                 cluster_mount_infos: Optional[Sequence['outputs.GetJobJobSettingsSettingsNewClusterClusterMountInfoResult']] = None,
                 cluster_name: Optional[str] = None,
                 custom_tags: Optional[Mapping[str, Any]] = None,
                 data_security_mode: Optional[str] = None,
                 docker_image: Optional['outputs.GetJobJobSettingsSettingsNewClusterDockerImageResult'] = None,
                 gcp_attributes: Optional['outputs.GetJobJobSettingsSettingsNewClusterGcpAttributesResult'] = None,
                 idempotency_token: Optional[str] = None,
                 init_scripts: Optional[Sequence['outputs.GetJobJobSettingsSettingsNewClusterInitScriptResult']] = None,
                 instance_pool_id: Optional[str] = None,
                 policy_id: Optional[str] = None,
                 runtime_engine: Optional[str] = None,
                 single_user_name: Optional[str] = None,
                 spark_conf: Optional[Mapping[str, Any]] = None,
                 spark_env_vars: Optional[Mapping[str, Any]] = None,
                 ssh_public_keys: Optional[Sequence[str]] = None,
                 workload_type: Optional['outputs.GetJobJobSettingsSettingsNewClusterWorkloadTypeResult'] = None):
        pulumi.set(__self__, "driver_instance_pool_id", driver_instance_pool_id)
        pulumi.set(__self__, "driver_node_type_id", driver_node_type_id)
        pulumi.set(__self__, "enable_elastic_disk", enable_elastic_disk)
        pulumi.set(__self__, "enable_local_disk_encryption", enable_local_disk_encryption)
        pulumi.set(__self__, "node_type_id", node_type_id)
        pulumi.set(__self__, "num_workers", num_workers)
        pulumi.set(__self__, "spark_version", spark_version)
        if apply_policy_default_values is not None:
            pulumi.set(__self__, "apply_policy_default_values", apply_policy_default_values)
        if autoscale is not None:
            pulumi.set(__self__, "autoscale", autoscale)
        if autotermination_minutes is not None:
            pulumi.set(__self__, "autotermination_minutes", autotermination_minutes)
        if aws_attributes is not None:
            pulumi.set(__self__, "aws_attributes", aws_attributes)
        if azure_attributes is not None:
            pulumi.set(__self__, "azure_attributes", azure_attributes)
        if cluster_id is not None:
            pulumi.set(__self__, "cluster_id", cluster_id)
        if cluster_log_conf is not None:
            pulumi.set(__self__, "cluster_log_conf", cluster_log_conf)
        if cluster_mount_infos is not None:
            pulumi.set(__self__, "cluster_mount_infos", cluster_mount_infos)
        if cluster_name is not None:
            pulumi.set(__self__, "cluster_name", cluster_name)
        if custom_tags is not None:
            pulumi.set(__self__, "custom_tags", custom_tags)
        if data_security_mode is not None:
            pulumi.set(__self__, "data_security_mode", data_security_mode)
        if docker_image is not None:
            pulumi.set(__self__, "docker_image", docker_image)
        if gcp_attributes is not None:
            pulumi.set(__self__, "gcp_attributes", gcp_attributes)
        if idempotency_token is not None:
            pulumi.set(__self__, "idempotency_token", idempotency_token)
        if init_scripts is not None:
            pulumi.set(__self__, "init_scripts", init_scripts)
        if instance_pool_id is not None:
            pulumi.set(__self__, "instance_pool_id", instance_pool_id)
        if policy_id is not None:
            pulumi.set(__self__, "policy_id", policy_id)
        if runtime_engine is not None:
            pulumi.set(__self__, "runtime_engine", runtime_engine)
        if single_user_name is not None:
            pulumi.set(__self__, "single_user_name", single_user_name)
        if spark_conf is not None:
            pulumi.set(__self__, "spark_conf", spark_conf)
        if spark_env_vars is not None:
            pulumi.set(__self__, "spark_env_vars", spark_env_vars)
        if ssh_public_keys is not None:
            pulumi.set(__self__, "ssh_public_keys", ssh_public_keys)
        if workload_type is not None:
            pulumi.set(__self__, "workload_type", workload_type)

    @property
    @pulumi.getter(name="driverInstancePoolId")
    def driver_instance_pool_id(self) -> str:
        return pulumi.get(self, "driver_instance_pool_id")

    @property
    @pulumi.getter(name="driverNodeTypeId")
    def driver_node_type_id(self) -> str:
        return pulumi.get(self, "driver_node_type_id")

    @property
    @pulumi.getter(name="enableElasticDisk")
    def enable_elastic_disk(self) -> bool:
        return pulumi.get(self, "enable_elastic_disk")

    @property
    @pulumi.getter(name="enableLocalDiskEncryption")
    def enable_local_disk_encryption(self) -> bool:
        return pulumi.get(self, "enable_local_disk_encryption")

    @property
    @pulumi.getter(name="nodeTypeId")
    def node_type_id(self) -> str:
        return pulumi.get(self, "node_type_id")

    @property
    @pulumi.getter(name="numWorkers")
    def num_workers(self) -> int:
        return pulumi.get(self, "num_workers")

    @property
    @pulumi.getter(name="sparkVersion")
    def spark_version(self) -> str:
        return pulumi.get(self, "spark_version")

    @property
    @pulumi.getter(name="applyPolicyDefaultValues")
    def apply_policy_default_values(self) -> Optional[bool]:
        return pulumi.get(self, "apply_policy_default_values")

    @property
    @pulumi.getter
    def autoscale(self) -> Optional['outputs.GetJobJobSettingsSettingsNewClusterAutoscaleResult']:
        return pulumi.get(self, "autoscale")

    @property
    @pulumi.getter(name="autoterminationMinutes")
    def autotermination_minutes(self) -> Optional[int]:
        return pulumi.get(self, "autotermination_minutes")

    @property
    @pulumi.getter(name="awsAttributes")
    def aws_attributes(self) -> Optional['outputs.GetJobJobSettingsSettingsNewClusterAwsAttributesResult']:
        return pulumi.get(self, "aws_attributes")

    @property
    @pulumi.getter(name="azureAttributes")
    def azure_attributes(self) -> Optional['outputs.GetJobJobSettingsSettingsNewClusterAzureAttributesResult']:
        return pulumi.get(self, "azure_attributes")

    @property
    @pulumi.getter(name="clusterId")
    def cluster_id(self) -> Optional[str]:
        return pulumi.get(self, "cluster_id")

    @property
    @pulumi.getter(name="clusterLogConf")
    def cluster_log_conf(self) -> Optional['outputs.GetJobJobSettingsSettingsNewClusterClusterLogConfResult']:
        return pulumi.get(self, "cluster_log_conf")

    @property
    @pulumi.getter(name="clusterMountInfos")
    def cluster_mount_infos(self) -> Optional[Sequence['outputs.GetJobJobSettingsSettingsNewClusterClusterMountInfoResult']]:
        return pulumi.get(self, "cluster_mount_infos")

    @property
    @pulumi.getter(name="clusterName")
    def cluster_name(self) -> Optional[str]:
        return pulumi.get(self, "cluster_name")

    @property
    @pulumi.getter(name="customTags")
    def custom_tags(self) -> Optional[Mapping[str, Any]]:
        return pulumi.get(self, "custom_tags")

    @property
    @pulumi.getter(name="dataSecurityMode")
    def data_security_mode(self) -> Optional[str]:
        return pulumi.get(self, "data_security_mode")

    @property
    @pulumi.getter(name="dockerImage")
    def docker_image(self) -> Optional['outputs.GetJobJobSettingsSettingsNewClusterDockerImageResult']:
        return pulumi.get(self, "docker_image")

    @property
    @pulumi.getter(name="gcpAttributes")
    def gcp_attributes(self) -> Optional['outputs.GetJobJobSettingsSettingsNewClusterGcpAttributesResult']:
        return pulumi.get(self, "gcp_attributes")

    @property
    @pulumi.getter(name="idempotencyToken")
    def idempotency_token(self) -> Optional[str]:
        return pulumi.get(self, "idempotency_token")

    @property
    @pulumi.getter(name="initScripts")
    def init_scripts(self) -> Optional[Sequence['outputs.GetJobJobSettingsSettingsNewClusterInitScriptResult']]:
        return pulumi.get(self, "init_scripts")

    @property
    @pulumi.getter(name="instancePoolId")
    def instance_pool_id(self) -> Optional[str]:
        return pulumi.get(self, "instance_pool_id")

    @property
    @pulumi.getter(name="policyId")
    def policy_id(self) -> Optional[str]:
        return pulumi.get(self, "policy_id")

    @property
    @pulumi.getter(name="runtimeEngine")
    def runtime_engine(self) -> Optional[str]:
        return pulumi.get(self, "runtime_engine")

    @property
    @pulumi.getter(name="singleUserName")
    def single_user_name(self) -> Optional[str]:
        return pulumi.get(self, "single_user_name")

    @property
    @pulumi.getter(name="sparkConf")
    def spark_conf(self) -> Optional[Mapping[str, Any]]:
        return pulumi.get(self, "spark_conf")

    @property
    @pulumi.getter(name="sparkEnvVars")
    def spark_env_vars(self) -> Optional[Mapping[str, Any]]:
        return pulumi.get(self, "spark_env_vars")

    @property
    @pulumi.getter(name="sshPublicKeys")
    def ssh_public_keys(self) -> Optional[Sequence[str]]:
        return pulumi.get(self, "ssh_public_keys")

    @property
    @pulumi.getter(name="workloadType")
    def workload_type(self) -> Optional['outputs.GetJobJobSettingsSettingsNewClusterWorkloadTypeResult']:
        return pulumi.get(self, "workload_type")


@pulumi.output_type
class GetJobJobSettingsSettingsNewClusterAutoscaleResult(dict):
    def __init__(__self__, *,
                 max_workers: Optional[int] = None,
                 min_workers: Optional[int] = None):
        if max_workers is not None:
            pulumi.set(__self__, "max_workers", max_workers)
        if min_workers is not None:
            pulumi.set(__self__, "min_workers", min_workers)

    @property
    @pulumi.getter(name="maxWorkers")
    def max_workers(self) -> Optional[int]:
        return pulumi.get(self, "max_workers")

    @property
    @pulumi.getter(name="minWorkers")
    def min_workers(self) -> Optional[int]:
        return pulumi.get(self, "min_workers")


@pulumi.output_type
class GetJobJobSettingsSettingsNewClusterAwsAttributesResult(dict):
    def __init__(__self__, *,
                 availability: Optional[str] = None,
                 ebs_volume_count: Optional[int] = None,
                 ebs_volume_size: Optional[int] = None,
                 ebs_volume_type: Optional[str] = None,
                 first_on_demand: Optional[int] = None,
                 instance_profile_arn: Optional[str] = None,
                 spot_bid_price_percent: Optional[int] = None,
                 zone_id: Optional[str] = None):
        if availability is not None:
            pulumi.set(__self__, "availability", availability)
        if ebs_volume_count is not None:
            pulumi.set(__self__, "ebs_volume_count", ebs_volume_count)
        if ebs_volume_size is not None:
            pulumi.set(__self__, "ebs_volume_size", ebs_volume_size)
        if ebs_volume_type is not None:
            pulumi.set(__self__, "ebs_volume_type", ebs_volume_type)
        if first_on_demand is not None:
            pulumi.set(__self__, "first_on_demand", first_on_demand)
        if instance_profile_arn is not None:
            pulumi.set(__self__, "instance_profile_arn", instance_profile_arn)
        if spot_bid_price_percent is not None:
            pulumi.set(__self__, "spot_bid_price_percent", spot_bid_price_percent)
        if zone_id is not None:
            pulumi.set(__self__, "zone_id", zone_id)

    @property
    @pulumi.getter
    def availability(self) -> Optional[str]:
        return pulumi.get(self, "availability")

    @property
    @pulumi.getter(name="ebsVolumeCount")
    def ebs_volume_count(self) -> Optional[int]:
        return pulumi.get(self, "ebs_volume_count")

    @property
    @pulumi.getter(name="ebsVolumeSize")
    def ebs_volume_size(self) -> Optional[int]:
        return pulumi.get(self, "ebs_volume_size")

    @property
    @pulumi.getter(name="ebsVolumeType")
    def ebs_volume_type(self) -> Optional[str]:
        return pulumi.get(self, "ebs_volume_type")

    @property
    @pulumi.getter(name="firstOnDemand")
    def first_on_demand(self) -> Optional[int]:
        return pulumi.get(self, "first_on_demand")

    @property
    @pulumi.getter(name="instanceProfileArn")
    def instance_profile_arn(self) -> Optional[str]:
        return pulumi.get(self, "instance_profile_arn")

    @property
    @pulumi.getter(name="spotBidPricePercent")
    def spot_bid_price_percent(self) -> Optional[int]:
        return pulumi.get(self, "spot_bid_price_percent")

    @property
    @pulumi.getter(name="zoneId")
    def zone_id(self) -> Optional[str]:
        return pulumi.get(self, "zone_id")


@pulumi.output_type
class GetJobJobSettingsSettingsNewClusterAzureAttributesResult(dict):
    def __init__(__self__, *,
                 availability: Optional[str] = None,
                 first_on_demand: Optional[int] = None,
                 spot_bid_max_price: Optional[float] = None):
        if availability is not None:
            pulumi.set(__self__, "availability", availability)
        if first_on_demand is not None:
            pulumi.set(__self__, "first_on_demand", first_on_demand)
        if spot_bid_max_price is not None:
            pulumi.set(__self__, "spot_bid_max_price", spot_bid_max_price)

    @property
    @pulumi.getter
    def availability(self) -> Optional[str]:
        return pulumi.get(self, "availability")

    @property
    @pulumi.getter(name="firstOnDemand")
    def first_on_demand(self) -> Optional[int]:
        return pulumi.get(self, "first_on_demand")

    @property
    @pulumi.getter(name="spotBidMaxPrice")
    def spot_bid_max_price(self) -> Optional[float]:
        return pulumi.get(self, "spot_bid_max_price")


@pulumi.output_type
class GetJobJobSettingsSettingsNewClusterClusterLogConfResult(dict):
    def __init__(__self__, *,
                 dbfs: Optional['outputs.GetJobJobSettingsSettingsNewClusterClusterLogConfDbfsResult'] = None,
                 s3: Optional['outputs.GetJobJobSettingsSettingsNewClusterClusterLogConfS3Result'] = None):
        if dbfs is not None:
            pulumi.set(__self__, "dbfs", dbfs)
        if s3 is not None:
            pulumi.set(__self__, "s3", s3)

    @property
    @pulumi.getter
    def dbfs(self) -> Optional['outputs.GetJobJobSettingsSettingsNewClusterClusterLogConfDbfsResult']:
        return pulumi.get(self, "dbfs")

    @property
    @pulumi.getter
    def s3(self) -> Optional['outputs.GetJobJobSettingsSettingsNewClusterClusterLogConfS3Result']:
        return pulumi.get(self, "s3")


@pulumi.output_type
class GetJobJobSettingsSettingsNewClusterClusterLogConfDbfsResult(dict):
    def __init__(__self__, *,
                 destination: str):
        pulumi.set(__self__, "destination", destination)

    @property
    @pulumi.getter
    def destination(self) -> str:
        return pulumi.get(self, "destination")


@pulumi.output_type
class GetJobJobSettingsSettingsNewClusterClusterLogConfS3Result(dict):
    def __init__(__self__, *,
                 destination: str,
                 canned_acl: Optional[str] = None,
                 enable_encryption: Optional[bool] = None,
                 encryption_type: Optional[str] = None,
                 endpoint: Optional[str] = None,
                 kms_key: Optional[str] = None,
                 region: Optional[str] = None):
        pulumi.set(__self__, "destination", destination)
        if canned_acl is not None:
            pulumi.set(__self__, "canned_acl", canned_acl)
        if enable_encryption is not None:
            pulumi.set(__self__, "enable_encryption", enable_encryption)
        if encryption_type is not None:
            pulumi.set(__self__, "encryption_type", encryption_type)
        if endpoint is not None:
            pulumi.set(__self__, "endpoint", endpoint)
        if kms_key is not None:
            pulumi.set(__self__, "kms_key", kms_key)
        if region is not None:
            pulumi.set(__self__, "region", region)

    @property
    @pulumi.getter
    def destination(self) -> str:
        return pulumi.get(self, "destination")

    @property
    @pulumi.getter(name="cannedAcl")
    def canned_acl(self) -> Optional[str]:
        return pulumi.get(self, "canned_acl")

    @property
    @pulumi.getter(name="enableEncryption")
    def enable_encryption(self) -> Optional[bool]:
        return pulumi.get(self, "enable_encryption")

    @property
    @pulumi.getter(name="encryptionType")
    def encryption_type(self) -> Optional[str]:
        return pulumi.get(self, "encryption_type")

    @property
    @pulumi.getter
    def endpoint(self) -> Optional[str]:
        return pulumi.get(self, "endpoint")

    @property
    @pulumi.getter(name="kmsKey")
    def kms_key(self) -> Optional[str]:
        return pulumi.get(self, "kms_key")

    @property
    @pulumi.getter
    def region(self) -> Optional[str]:
        return pulumi.get(self, "region")


@pulumi.output_type
class GetJobJobSettingsSettingsNewClusterClusterMountInfoResult(dict):
    def __init__(__self__, *,
                 local_mount_dir_path: str,
                 network_filesystem_info: 'outputs.GetJobJobSettingsSettingsNewClusterClusterMountInfoNetworkFilesystemInfoResult',
                 remote_mount_dir_path: Optional[str] = None):
        pulumi.set(__self__, "local_mount_dir_path", local_mount_dir_path)
        pulumi.set(__self__, "network_filesystem_info", network_filesystem_info)
        if remote_mount_dir_path is not None:
            pulumi.set(__self__, "remote_mount_dir_path", remote_mount_dir_path)

    @property
    @pulumi.getter(name="localMountDirPath")
    def local_mount_dir_path(self) -> str:
        return pulumi.get(self, "local_mount_dir_path")

    @property
    @pulumi.getter(name="networkFilesystemInfo")
    def network_filesystem_info(self) -> 'outputs.GetJobJobSettingsSettingsNewClusterClusterMountInfoNetworkFilesystemInfoResult':
        return pulumi.get(self, "network_filesystem_info")

    @property
    @pulumi.getter(name="remoteMountDirPath")
    def remote_mount_dir_path(self) -> Optional[str]:
        return pulumi.get(self, "remote_mount_dir_path")


@pulumi.output_type
class GetJobJobSettingsSettingsNewClusterClusterMountInfoNetworkFilesystemInfoResult(dict):
    def __init__(__self__, *,
                 server_address: str,
                 mount_options: Optional[str] = None):
        pulumi.set(__self__, "server_address", server_address)
        if mount_options is not None:
            pulumi.set(__self__, "mount_options", mount_options)

    @property
    @pulumi.getter(name="serverAddress")
    def server_address(self) -> str:
        return pulumi.get(self, "server_address")

    @property
    @pulumi.getter(name="mountOptions")
    def mount_options(self) -> Optional[str]:
        return pulumi.get(self, "mount_options")


@pulumi.output_type
class GetJobJobSettingsSettingsNewClusterDockerImageResult(dict):
    def __init__(__self__, *,
                 url: str,
                 basic_auth: Optional['outputs.GetJobJobSettingsSettingsNewClusterDockerImageBasicAuthResult'] = None):
        pulumi.set(__self__, "url", url)
        if basic_auth is not None:
            pulumi.set(__self__, "basic_auth", basic_auth)

    @property
    @pulumi.getter
    def url(self) -> str:
        return pulumi.get(self, "url")

    @property
    @pulumi.getter(name="basicAuth")
    def basic_auth(self) -> Optional['outputs.GetJobJobSettingsSettingsNewClusterDockerImageBasicAuthResult']:
        return pulumi.get(self, "basic_auth")


@pulumi.output_type
class GetJobJobSettingsSettingsNewClusterDockerImageBasicAuthResult(dict):
    def __init__(__self__, *,
                 password: str,
                 username: str):
        pulumi.set(__self__, "password", password)
        pulumi.set(__self__, "username", username)

    @property
    @pulumi.getter
    def password(self) -> str:
        return pulumi.get(self, "password")

    @property
    @pulumi.getter
    def username(self) -> str:
        return pulumi.get(self, "username")


@pulumi.output_type
class GetJobJobSettingsSettingsNewClusterGcpAttributesResult(dict):
    def __init__(__self__, *,
                 availability: Optional[str] = None,
                 boot_disk_size: Optional[int] = None,
                 google_service_account: Optional[str] = None,
                 local_ssd_count: Optional[int] = None,
                 use_preemptible_executors: Optional[bool] = None,
                 zone_id: Optional[str] = None):
        if availability is not None:
            pulumi.set(__self__, "availability", availability)
        if boot_disk_size is not None:
            pulumi.set(__self__, "boot_disk_size", boot_disk_size)
        if google_service_account is not None:
            pulumi.set(__self__, "google_service_account", google_service_account)
        if local_ssd_count is not None:
            pulumi.set(__self__, "local_ssd_count", local_ssd_count)
        if use_preemptible_executors is not None:
            pulumi.set(__self__, "use_preemptible_executors", use_preemptible_executors)
        if zone_id is not None:
            pulumi.set(__self__, "zone_id", zone_id)

    @property
    @pulumi.getter
    def availability(self) -> Optional[str]:
        return pulumi.get(self, "availability")

    @property
    @pulumi.getter(name="bootDiskSize")
    def boot_disk_size(self) -> Optional[int]:
        return pulumi.get(self, "boot_disk_size")

    @property
    @pulumi.getter(name="googleServiceAccount")
    def google_service_account(self) -> Optional[str]:
        return pulumi.get(self, "google_service_account")

    @property
    @pulumi.getter(name="localSsdCount")
    def local_ssd_count(self) -> Optional[int]:
        return pulumi.get(self, "local_ssd_count")

    @property
    @pulumi.getter(name="usePreemptibleExecutors")
    def use_preemptible_executors(self) -> Optional[bool]:
        return pulumi.get(self, "use_preemptible_executors")

    @property
    @pulumi.getter(name="zoneId")
    def zone_id(self) -> Optional[str]:
        return pulumi.get(self, "zone_id")


@pulumi.output_type
class GetJobJobSettingsSettingsNewClusterInitScriptResult(dict):
    def __init__(__self__, *,
                 abfss: Optional['outputs.GetJobJobSettingsSettingsNewClusterInitScriptAbfssResult'] = None,
                 dbfs: Optional['outputs.GetJobJobSettingsSettingsNewClusterInitScriptDbfsResult'] = None,
                 file: Optional['outputs.GetJobJobSettingsSettingsNewClusterInitScriptFileResult'] = None,
                 gcs: Optional['outputs.GetJobJobSettingsSettingsNewClusterInitScriptGcsResult'] = None,
                 s3: Optional['outputs.GetJobJobSettingsSettingsNewClusterInitScriptS3Result'] = None,
                 volumes: Optional['outputs.GetJobJobSettingsSettingsNewClusterInitScriptVolumesResult'] = None,
                 workspace: Optional['outputs.GetJobJobSettingsSettingsNewClusterInitScriptWorkspaceResult'] = None):
        if abfss is not None:
            pulumi.set(__self__, "abfss", abfss)
        if dbfs is not None:
            pulumi.set(__self__, "dbfs", dbfs)
        if file is not None:
            pulumi.set(__self__, "file", file)
        if gcs is not None:
            pulumi.set(__self__, "gcs", gcs)
        if s3 is not None:
            pulumi.set(__self__, "s3", s3)
        if volumes is not None:
            pulumi.set(__self__, "volumes", volumes)
        if workspace is not None:
            pulumi.set(__self__, "workspace", workspace)

    @property
    @pulumi.getter
    def abfss(self) -> Optional['outputs.GetJobJobSettingsSettingsNewClusterInitScriptAbfssResult']:
        return pulumi.get(self, "abfss")

    @property
    @pulumi.getter
    def dbfs(self) -> Optional['outputs.GetJobJobSettingsSettingsNewClusterInitScriptDbfsResult']:
        return pulumi.get(self, "dbfs")

    @property
    @pulumi.getter
    def file(self) -> Optional['outputs.GetJobJobSettingsSettingsNewClusterInitScriptFileResult']:
        return pulumi.get(self, "file")

    @property
    @pulumi.getter
    def gcs(self) -> Optional['outputs.GetJobJobSettingsSettingsNewClusterInitScriptGcsResult']:
        return pulumi.get(self, "gcs")

    @property
    @pulumi.getter
    def s3(self) -> Optional['outputs.GetJobJobSettingsSettingsNewClusterInitScriptS3Result']:
        return pulumi.get(self, "s3")

    @property
    @pulumi.getter
    def volumes(self) -> Optional['outputs.GetJobJobSettingsSettingsNewClusterInitScriptVolumesResult']:
        return pulumi.get(self, "volumes")

    @property
    @pulumi.getter
    def workspace(self) -> Optional['outputs.GetJobJobSettingsSettingsNewClusterInitScriptWorkspaceResult']:
        return pulumi.get(self, "workspace")


@pulumi.output_type
class GetJobJobSettingsSettingsNewClusterInitScriptAbfssResult(dict):
    def __init__(__self__, *,
                 destination: str):
        pulumi.set(__self__, "destination", destination)

    @property
    @pulumi.getter
    def destination(self) -> str:
        return pulumi.get(self, "destination")


@pulumi.output_type
class GetJobJobSettingsSettingsNewClusterInitScriptDbfsResult(dict):
    def __init__(__self__, *,
                 destination: str):
        pulumi.set(__self__, "destination", destination)

    @property
    @pulumi.getter
    def destination(self) -> str:
        return pulumi.get(self, "destination")


@pulumi.output_type
class GetJobJobSettingsSettingsNewClusterInitScriptFileResult(dict):
    def __init__(__self__, *,
                 destination: str):
        pulumi.set(__self__, "destination", destination)

    @property
    @pulumi.getter
    def destination(self) -> str:
        return pulumi.get(self, "destination")


@pulumi.output_type
class GetJobJobSettingsSettingsNewClusterInitScriptGcsResult(dict):
    def __init__(__self__, *,
                 destination: str):
        pulumi.set(__self__, "destination", destination)

    @property
    @pulumi.getter
    def destination(self) -> str:
        return pulumi.get(self, "destination")


@pulumi.output_type
class GetJobJobSettingsSettingsNewClusterInitScriptS3Result(dict):
    def __init__(__self__, *,
                 destination: str,
                 canned_acl: Optional[str] = None,
                 enable_encryption: Optional[bool] = None,
                 encryption_type: Optional[str] = None,
                 endpoint: Optional[str] = None,
                 kms_key: Optional[str] = None,
                 region: Optional[str] = None):
        pulumi.set(__self__, "destination", destination)
        if canned_acl is not None:
            pulumi.set(__self__, "canned_acl", canned_acl)
        if enable_encryption is not None:
            pulumi.set(__self__, "enable_encryption", enable_encryption)
        if encryption_type is not None:
            pulumi.set(__self__, "encryption_type", encryption_type)
        if endpoint is not None:
            pulumi.set(__self__, "endpoint", endpoint)
        if kms_key is not None:
            pulumi.set(__self__, "kms_key", kms_key)
        if region is not None:
            pulumi.set(__self__, "region", region)

    @property
    @pulumi.getter
    def destination(self) -> str:
        return pulumi.get(self, "destination")

    @property
    @pulumi.getter(name="cannedAcl")
    def canned_acl(self) -> Optional[str]:
        return pulumi.get(self, "canned_acl")

    @property
    @pulumi.getter(name="enableEncryption")
    def enable_encryption(self) -> Optional[bool]:
        return pulumi.get(self, "enable_encryption")

    @property
    @pulumi.getter(name="encryptionType")
    def encryption_type(self) -> Optional[str]:
        return pulumi.get(self, "encryption_type")

    @property
    @pulumi.getter
    def endpoint(self) -> Optional[str]:
        return pulumi.get(self, "endpoint")

    @property
    @pulumi.getter(name="kmsKey")
    def kms_key(self) -> Optional[str]:
        return pulumi.get(self, "kms_key")

    @property
    @pulumi.getter
    def region(self) -> Optional[str]:
        return pulumi.get(self, "region")


@pulumi.output_type
class GetJobJobSettingsSettingsNewClusterInitScriptVolumesResult(dict):
    def __init__(__self__, *,
                 destination: str):
        pulumi.set(__self__, "destination", destination)

    @property
    @pulumi.getter
    def destination(self) -> str:
        return pulumi.get(self, "destination")


@pulumi.output_type
class GetJobJobSettingsSettingsNewClusterInitScriptWorkspaceResult(dict):
    def __init__(__self__, *,
                 destination: str):
        pulumi.set(__self__, "destination", destination)

    @property
    @pulumi.getter
    def destination(self) -> str:
        return pulumi.get(self, "destination")


@pulumi.output_type
class GetJobJobSettingsSettingsNewClusterWorkloadTypeResult(dict):
    def __init__(__self__, *,
                 clients: 'outputs.GetJobJobSettingsSettingsNewClusterWorkloadTypeClientsResult'):
        pulumi.set(__self__, "clients", clients)

    @property
    @pulumi.getter
    def clients(self) -> 'outputs.GetJobJobSettingsSettingsNewClusterWorkloadTypeClientsResult':
        return pulumi.get(self, "clients")


@pulumi.output_type
class GetJobJobSettingsSettingsNewClusterWorkloadTypeClientsResult(dict):
    def __init__(__self__, *,
                 jobs: Optional[bool] = None,
                 notebooks: Optional[bool] = None):
        if jobs is not None:
            pulumi.set(__self__, "jobs", jobs)
        if notebooks is not None:
            pulumi.set(__self__, "notebooks", notebooks)

    @property
    @pulumi.getter
    def jobs(self) -> Optional[bool]:
        return pulumi.get(self, "jobs")

    @property
    @pulumi.getter
    def notebooks(self) -> Optional[bool]:
        return pulumi.get(self, "notebooks")


@pulumi.output_type
class GetJobJobSettingsSettingsNotebookTaskResult(dict):
    def __init__(__self__, *,
                 notebook_path: str,
                 base_parameters: Optional[Mapping[str, Any]] = None,
                 source: Optional[str] = None):
        pulumi.set(__self__, "notebook_path", notebook_path)
        if base_parameters is not None:
            pulumi.set(__self__, "base_parameters", base_parameters)
        if source is not None:
            pulumi.set(__self__, "source", source)

    @property
    @pulumi.getter(name="notebookPath")
    def notebook_path(self) -> str:
        return pulumi.get(self, "notebook_path")

    @property
    @pulumi.getter(name="baseParameters")
    def base_parameters(self) -> Optional[Mapping[str, Any]]:
        return pulumi.get(self, "base_parameters")

    @property
    @pulumi.getter
    def source(self) -> Optional[str]:
        return pulumi.get(self, "source")


@pulumi.output_type
class GetJobJobSettingsSettingsNotificationSettingsResult(dict):
    def __init__(__self__, *,
                 no_alert_for_canceled_runs: Optional[bool] = None,
                 no_alert_for_skipped_runs: Optional[bool] = None):
        if no_alert_for_canceled_runs is not None:
            pulumi.set(__self__, "no_alert_for_canceled_runs", no_alert_for_canceled_runs)
        if no_alert_for_skipped_runs is not None:
            pulumi.set(__self__, "no_alert_for_skipped_runs", no_alert_for_skipped_runs)

    @property
    @pulumi.getter(name="noAlertForCanceledRuns")
    def no_alert_for_canceled_runs(self) -> Optional[bool]:
        return pulumi.get(self, "no_alert_for_canceled_runs")

    @property
    @pulumi.getter(name="noAlertForSkippedRuns")
    def no_alert_for_skipped_runs(self) -> Optional[bool]:
        return pulumi.get(self, "no_alert_for_skipped_runs")


@pulumi.output_type
class GetJobJobSettingsSettingsParameterResult(dict):
    def __init__(__self__, *,
                 default: str,
                 name: str):
        """
        :param str name: the job name of Job if the resource was matched by id.
        """
        pulumi.set(__self__, "default", default)
        pulumi.set(__self__, "name", name)

    @property
    @pulumi.getter
    def default(self) -> str:
        return pulumi.get(self, "default")

    @property
    @pulumi.getter
    def name(self) -> str:
        """
        the job name of Job if the resource was matched by id.
        """
        return pulumi.get(self, "name")


@pulumi.output_type
class GetJobJobSettingsSettingsPipelineTaskResult(dict):
    def __init__(__self__, *,
                 pipeline_id: str,
                 full_refresh: Optional[bool] = None):
        pulumi.set(__self__, "pipeline_id", pipeline_id)
        if full_refresh is not None:
            pulumi.set(__self__, "full_refresh", full_refresh)

    @property
    @pulumi.getter(name="pipelineId")
    def pipeline_id(self) -> str:
        return pulumi.get(self, "pipeline_id")

    @property
    @pulumi.getter(name="fullRefresh")
    def full_refresh(self) -> Optional[bool]:
        return pulumi.get(self, "full_refresh")


@pulumi.output_type
class GetJobJobSettingsSettingsPythonWheelTaskResult(dict):
    def __init__(__self__, *,
                 entry_point: Optional[str] = None,
                 named_parameters: Optional[Mapping[str, Any]] = None,
                 package_name: Optional[str] = None,
                 parameters: Optional[Sequence[str]] = None):
        if entry_point is not None:
            pulumi.set(__self__, "entry_point", entry_point)
        if named_parameters is not None:
            pulumi.set(__self__, "named_parameters", named_parameters)
        if package_name is not None:
            pulumi.set(__self__, "package_name", package_name)
        if parameters is not None:
            pulumi.set(__self__, "parameters", parameters)

    @property
    @pulumi.getter(name="entryPoint")
    def entry_point(self) -> Optional[str]:
        return pulumi.get(self, "entry_point")

    @property
    @pulumi.getter(name="namedParameters")
    def named_parameters(self) -> Optional[Mapping[str, Any]]:
        return pulumi.get(self, "named_parameters")

    @property
    @pulumi.getter(name="packageName")
    def package_name(self) -> Optional[str]:
        return pulumi.get(self, "package_name")

    @property
    @pulumi.getter
    def parameters(self) -> Optional[Sequence[str]]:
        return pulumi.get(self, "parameters")


@pulumi.output_type
class GetJobJobSettingsSettingsQueueResult(dict):
    def __init__(__self__, *,
                 enabled: bool):
        pulumi.set(__self__, "enabled", enabled)

    @property
    @pulumi.getter
    def enabled(self) -> bool:
        return pulumi.get(self, "enabled")


@pulumi.output_type
class GetJobJobSettingsSettingsRunAsResult(dict):
    def __init__(__self__, *,
                 service_principal_name: Optional[str] = None,
                 user_name: Optional[str] = None):
        if service_principal_name is not None:
            pulumi.set(__self__, "service_principal_name", service_principal_name)
        if user_name is not None:
            pulumi.set(__self__, "user_name", user_name)

    @property
    @pulumi.getter(name="servicePrincipalName")
    def service_principal_name(self) -> Optional[str]:
        return pulumi.get(self, "service_principal_name")

    @property
    @pulumi.getter(name="userName")
    def user_name(self) -> Optional[str]:
        return pulumi.get(self, "user_name")


@pulumi.output_type
class GetJobJobSettingsSettingsRunJobTaskResult(dict):
    def __init__(__self__, *,
                 job_id: int,
                 job_parameters: Optional[Mapping[str, Any]] = None):
        pulumi.set(__self__, "job_id", job_id)
        if job_parameters is not None:
            pulumi.set(__self__, "job_parameters", job_parameters)

    @property
    @pulumi.getter(name="jobId")
    def job_id(self) -> int:
        return pulumi.get(self, "job_id")

    @property
    @pulumi.getter(name="jobParameters")
    def job_parameters(self) -> Optional[Mapping[str, Any]]:
        return pulumi.get(self, "job_parameters")


@pulumi.output_type
class GetJobJobSettingsSettingsScheduleResult(dict):
    def __init__(__self__, *,
                 quartz_cron_expression: str,
                 timezone_id: str,
                 pause_status: Optional[str] = None):
        pulumi.set(__self__, "quartz_cron_expression", quartz_cron_expression)
        pulumi.set(__self__, "timezone_id", timezone_id)
        if pause_status is not None:
            pulumi.set(__self__, "pause_status", pause_status)

    @property
    @pulumi.getter(name="quartzCronExpression")
    def quartz_cron_expression(self) -> str:
        return pulumi.get(self, "quartz_cron_expression")

    @property
    @pulumi.getter(name="timezoneId")
    def timezone_id(self) -> str:
        return pulumi.get(self, "timezone_id")

    @property
    @pulumi.getter(name="pauseStatus")
    def pause_status(self) -> Optional[str]:
        return pulumi.get(self, "pause_status")


@pulumi.output_type
class GetJobJobSettingsSettingsSparkJarTaskResult(dict):
    def __init__(__self__, *,
                 jar_uri: Optional[str] = None,
                 main_class_name: Optional[str] = None,
                 parameters: Optional[Sequence[str]] = None):
        if jar_uri is not None:
            pulumi.set(__self__, "jar_uri", jar_uri)
        if main_class_name is not None:
            pulumi.set(__self__, "main_class_name", main_class_name)
        if parameters is not None:
            pulumi.set(__self__, "parameters", parameters)

    @property
    @pulumi.getter(name="jarUri")
    def jar_uri(self) -> Optional[str]:
        return pulumi.get(self, "jar_uri")

    @property
    @pulumi.getter(name="mainClassName")
    def main_class_name(self) -> Optional[str]:
        return pulumi.get(self, "main_class_name")

    @property
    @pulumi.getter
    def parameters(self) -> Optional[Sequence[str]]:
        return pulumi.get(self, "parameters")


@pulumi.output_type
class GetJobJobSettingsSettingsSparkPythonTaskResult(dict):
    def __init__(__self__, *,
                 python_file: str,
                 parameters: Optional[Sequence[str]] = None,
                 source: Optional[str] = None):
        pulumi.set(__self__, "python_file", python_file)
        if parameters is not None:
            pulumi.set(__self__, "parameters", parameters)
        if source is not None:
            pulumi.set(__self__, "source", source)

    @property
    @pulumi.getter(name="pythonFile")
    def python_file(self) -> str:
        return pulumi.get(self, "python_file")

    @property
    @pulumi.getter
    def parameters(self) -> Optional[Sequence[str]]:
        return pulumi.get(self, "parameters")

    @property
    @pulumi.getter
    def source(self) -> Optional[str]:
        return pulumi.get(self, "source")


@pulumi.output_type
class GetJobJobSettingsSettingsSparkSubmitTaskResult(dict):
    def __init__(__self__, *,
                 parameters: Optional[Sequence[str]] = None):
        if parameters is not None:
            pulumi.set(__self__, "parameters", parameters)

    @property
    @pulumi.getter
    def parameters(self) -> Optional[Sequence[str]]:
        return pulumi.get(self, "parameters")


@pulumi.output_type
class GetJobJobSettingsSettingsTaskResult(dict):
    def __init__(__self__, *,
                 retry_on_timeout: bool,
                 compute_key: Optional[str] = None,
                 condition_task: Optional['outputs.GetJobJobSettingsSettingsTaskConditionTaskResult'] = None,
                 dbt_task: Optional['outputs.GetJobJobSettingsSettingsTaskDbtTaskResult'] = None,
                 depends_ons: Optional[Sequence['outputs.GetJobJobSettingsSettingsTaskDependsOnResult']] = None,
                 description: Optional[str] = None,
                 email_notifications: Optional['outputs.GetJobJobSettingsSettingsTaskEmailNotificationsResult'] = None,
                 existing_cluster_id: Optional[str] = None,
                 for_each_task: Optional['outputs.GetJobJobSettingsSettingsTaskForEachTaskResult'] = None,
                 health: Optional['outputs.GetJobJobSettingsSettingsTaskHealthResult'] = None,
                 job_cluster_key: Optional[str] = None,
                 libraries: Optional[Sequence['outputs.GetJobJobSettingsSettingsTaskLibraryResult']] = None,
                 max_retries: Optional[int] = None,
                 min_retry_interval_millis: Optional[int] = None,
                 new_cluster: Optional['outputs.GetJobJobSettingsSettingsTaskNewClusterResult'] = None,
                 notebook_task: Optional['outputs.GetJobJobSettingsSettingsTaskNotebookTaskResult'] = None,
                 notification_settings: Optional['outputs.GetJobJobSettingsSettingsTaskNotificationSettingsResult'] = None,
                 pipeline_task: Optional['outputs.GetJobJobSettingsSettingsTaskPipelineTaskResult'] = None,
                 python_wheel_task: Optional['outputs.GetJobJobSettingsSettingsTaskPythonWheelTaskResult'] = None,
                 run_if: Optional[str] = None,
                 run_job_task: Optional['outputs.GetJobJobSettingsSettingsTaskRunJobTaskResult'] = None,
                 spark_jar_task: Optional['outputs.GetJobJobSettingsSettingsTaskSparkJarTaskResult'] = None,
                 spark_python_task: Optional['outputs.GetJobJobSettingsSettingsTaskSparkPythonTaskResult'] = None,
                 spark_submit_task: Optional['outputs.GetJobJobSettingsSettingsTaskSparkSubmitTaskResult'] = None,
                 sql_task: Optional['outputs.GetJobJobSettingsSettingsTaskSqlTaskResult'] = None,
                 task_key: Optional[str] = None,
                 timeout_seconds: Optional[int] = None,
                 webhook_notifications: Optional['outputs.GetJobJobSettingsSettingsTaskWebhookNotificationsResult'] = None):
        pulumi.set(__self__, "retry_on_timeout", retry_on_timeout)
        if compute_key is not None:
            pulumi.set(__self__, "compute_key", compute_key)
        if condition_task is not None:
            pulumi.set(__self__, "condition_task", condition_task)
        if dbt_task is not None:
            pulumi.set(__self__, "dbt_task", dbt_task)
        if depends_ons is not None:
            pulumi.set(__self__, "depends_ons", depends_ons)
        if description is not None:
            pulumi.set(__self__, "description", description)
        if email_notifications is not None:
            pulumi.set(__self__, "email_notifications", email_notifications)
        if existing_cluster_id is not None:
            pulumi.set(__self__, "existing_cluster_id", existing_cluster_id)
        if for_each_task is not None:
            pulumi.set(__self__, "for_each_task", for_each_task)
        if health is not None:
            pulumi.set(__self__, "health", health)
        if job_cluster_key is not None:
            pulumi.set(__self__, "job_cluster_key", job_cluster_key)
        if libraries is not None:
            pulumi.set(__self__, "libraries", libraries)
        if max_retries is not None:
            pulumi.set(__self__, "max_retries", max_retries)
        if min_retry_interval_millis is not None:
            pulumi.set(__self__, "min_retry_interval_millis", min_retry_interval_millis)
        if new_cluster is not None:
            pulumi.set(__self__, "new_cluster", new_cluster)
        if notebook_task is not None:
            pulumi.set(__self__, "notebook_task", notebook_task)
        if notification_settings is not None:
            pulumi.set(__self__, "notification_settings", notification_settings)
        if pipeline_task is not None:
            pulumi.set(__self__, "pipeline_task", pipeline_task)
        if python_wheel_task is not None:
            pulumi.set(__self__, "python_wheel_task", python_wheel_task)
        if run_if is not None:
            pulumi.set(__self__, "run_if", run_if)
        if run_job_task is not None:
            pulumi.set(__self__, "run_job_task", run_job_task)
        if spark_jar_task is not None:
            pulumi.set(__self__, "spark_jar_task", spark_jar_task)
        if spark_python_task is not None:
            pulumi.set(__self__, "spark_python_task", spark_python_task)
        if spark_submit_task is not None:
            pulumi.set(__self__, "spark_submit_task", spark_submit_task)
        if sql_task is not None:
            pulumi.set(__self__, "sql_task", sql_task)
        if task_key is not None:
            pulumi.set(__self__, "task_key", task_key)
        if timeout_seconds is not None:
            pulumi.set(__self__, "timeout_seconds", timeout_seconds)
        if webhook_notifications is not None:
            pulumi.set(__self__, "webhook_notifications", webhook_notifications)

    @property
    @pulumi.getter(name="retryOnTimeout")
    def retry_on_timeout(self) -> bool:
        return pulumi.get(self, "retry_on_timeout")

    @property
    @pulumi.getter(name="computeKey")
    def compute_key(self) -> Optional[str]:
        return pulumi.get(self, "compute_key")

    @property
    @pulumi.getter(name="conditionTask")
    def condition_task(self) -> Optional['outputs.GetJobJobSettingsSettingsTaskConditionTaskResult']:
        return pulumi.get(self, "condition_task")

    @property
    @pulumi.getter(name="dbtTask")
    def dbt_task(self) -> Optional['outputs.GetJobJobSettingsSettingsTaskDbtTaskResult']:
        return pulumi.get(self, "dbt_task")

    @property
    @pulumi.getter(name="dependsOns")
    def depends_ons(self) -> Optional[Sequence['outputs.GetJobJobSettingsSettingsTaskDependsOnResult']]:
        return pulumi.get(self, "depends_ons")

    @property
    @pulumi.getter
    def description(self) -> Optional[str]:
        return pulumi.get(self, "description")

    @property
    @pulumi.getter(name="emailNotifications")
    def email_notifications(self) -> Optional['outputs.GetJobJobSettingsSettingsTaskEmailNotificationsResult']:
        return pulumi.get(self, "email_notifications")

    @property
    @pulumi.getter(name="existingClusterId")
    def existing_cluster_id(self) -> Optional[str]:
        return pulumi.get(self, "existing_cluster_id")

    @property
    @pulumi.getter(name="forEachTask")
    def for_each_task(self) -> Optional['outputs.GetJobJobSettingsSettingsTaskForEachTaskResult']:
        return pulumi.get(self, "for_each_task")

    @property
    @pulumi.getter
    def health(self) -> Optional['outputs.GetJobJobSettingsSettingsTaskHealthResult']:
        return pulumi.get(self, "health")

    @property
    @pulumi.getter(name="jobClusterKey")
    def job_cluster_key(self) -> Optional[str]:
        return pulumi.get(self, "job_cluster_key")

    @property
    @pulumi.getter
    def libraries(self) -> Optional[Sequence['outputs.GetJobJobSettingsSettingsTaskLibraryResult']]:
        return pulumi.get(self, "libraries")

    @property
    @pulumi.getter(name="maxRetries")
    def max_retries(self) -> Optional[int]:
        return pulumi.get(self, "max_retries")

    @property
    @pulumi.getter(name="minRetryIntervalMillis")
    def min_retry_interval_millis(self) -> Optional[int]:
        return pulumi.get(self, "min_retry_interval_millis")

    @property
    @pulumi.getter(name="newCluster")
    def new_cluster(self) -> Optional['outputs.GetJobJobSettingsSettingsTaskNewClusterResult']:
        return pulumi.get(self, "new_cluster")

    @property
    @pulumi.getter(name="notebookTask")
    def notebook_task(self) -> Optional['outputs.GetJobJobSettingsSettingsTaskNotebookTaskResult']:
        return pulumi.get(self, "notebook_task")

    @property
    @pulumi.getter(name="notificationSettings")
    def notification_settings(self) -> Optional['outputs.GetJobJobSettingsSettingsTaskNotificationSettingsResult']:
        return pulumi.get(self, "notification_settings")

    @property
    @pulumi.getter(name="pipelineTask")
    def pipeline_task(self) -> Optional['outputs.GetJobJobSettingsSettingsTaskPipelineTaskResult']:
        return pulumi.get(self, "pipeline_task")

    @property
    @pulumi.getter(name="pythonWheelTask")
    def python_wheel_task(self) -> Optional['outputs.GetJobJobSettingsSettingsTaskPythonWheelTaskResult']:
        return pulumi.get(self, "python_wheel_task")

    @property
    @pulumi.getter(name="runIf")
    def run_if(self) -> Optional[str]:
        return pulumi.get(self, "run_if")

    @property
    @pulumi.getter(name="runJobTask")
    def run_job_task(self) -> Optional['outputs.GetJobJobSettingsSettingsTaskRunJobTaskResult']:
        return pulumi.get(self, "run_job_task")

    @property
    @pulumi.getter(name="sparkJarTask")
    def spark_jar_task(self) -> Optional['outputs.GetJobJobSettingsSettingsTaskSparkJarTaskResult']:
        return pulumi.get(self, "spark_jar_task")

    @property
    @pulumi.getter(name="sparkPythonTask")
    def spark_python_task(self) -> Optional['outputs.GetJobJobSettingsSettingsTaskSparkPythonTaskResult']:
        return pulumi.get(self, "spark_python_task")

    @property
    @pulumi.getter(name="sparkSubmitTask")
    def spark_submit_task(self) -> Optional['outputs.GetJobJobSettingsSettingsTaskSparkSubmitTaskResult']:
        return pulumi.get(self, "spark_submit_task")

    @property
    @pulumi.getter(name="sqlTask")
    def sql_task(self) -> Optional['outputs.GetJobJobSettingsSettingsTaskSqlTaskResult']:
        return pulumi.get(self, "sql_task")

    @property
    @pulumi.getter(name="taskKey")
    def task_key(self) -> Optional[str]:
        return pulumi.get(self, "task_key")

    @property
    @pulumi.getter(name="timeoutSeconds")
    def timeout_seconds(self) -> Optional[int]:
        return pulumi.get(self, "timeout_seconds")

    @property
    @pulumi.getter(name="webhookNotifications")
    def webhook_notifications(self) -> Optional['outputs.GetJobJobSettingsSettingsTaskWebhookNotificationsResult']:
        return pulumi.get(self, "webhook_notifications")


@pulumi.output_type
class GetJobJobSettingsSettingsTaskConditionTaskResult(dict):
    def __init__(__self__, *,
                 left: Optional[str] = None,
                 op: Optional[str] = None,
                 right: Optional[str] = None):
        if left is not None:
            pulumi.set(__self__, "left", left)
        if op is not None:
            pulumi.set(__self__, "op", op)
        if right is not None:
            pulumi.set(__self__, "right", right)

    @property
    @pulumi.getter
    def left(self) -> Optional[str]:
        return pulumi.get(self, "left")

    @property
    @pulumi.getter
    def op(self) -> Optional[str]:
        return pulumi.get(self, "op")

    @property
    @pulumi.getter
    def right(self) -> Optional[str]:
        return pulumi.get(self, "right")


@pulumi.output_type
class GetJobJobSettingsSettingsTaskDbtTaskResult(dict):
    def __init__(__self__, *,
                 commands: Sequence[str],
                 catalog: Optional[str] = None,
                 profiles_directory: Optional[str] = None,
                 project_directory: Optional[str] = None,
                 schema: Optional[str] = None,
                 source: Optional[str] = None,
                 warehouse_id: Optional[str] = None):
        pulumi.set(__self__, "commands", commands)
        if catalog is not None:
            pulumi.set(__self__, "catalog", catalog)
        if profiles_directory is not None:
            pulumi.set(__self__, "profiles_directory", profiles_directory)
        if project_directory is not None:
            pulumi.set(__self__, "project_directory", project_directory)
        if schema is not None:
            pulumi.set(__self__, "schema", schema)
        if source is not None:
            pulumi.set(__self__, "source", source)
        if warehouse_id is not None:
            pulumi.set(__self__, "warehouse_id", warehouse_id)

    @property
    @pulumi.getter
    def commands(self) -> Sequence[str]:
        return pulumi.get(self, "commands")

    @property
    @pulumi.getter
    def catalog(self) -> Optional[str]:
        return pulumi.get(self, "catalog")

    @property
    @pulumi.getter(name="profilesDirectory")
    def profiles_directory(self) -> Optional[str]:
        return pulumi.get(self, "profiles_directory")

    @property
    @pulumi.getter(name="projectDirectory")
    def project_directory(self) -> Optional[str]:
        return pulumi.get(self, "project_directory")

    @property
    @pulumi.getter
    def schema(self) -> Optional[str]:
        return pulumi.get(self, "schema")

    @property
    @pulumi.getter
    def source(self) -> Optional[str]:
        return pulumi.get(self, "source")

    @property
    @pulumi.getter(name="warehouseId")
    def warehouse_id(self) -> Optional[str]:
        return pulumi.get(self, "warehouse_id")


@pulumi.output_type
class GetJobJobSettingsSettingsTaskDependsOnResult(dict):
    def __init__(__self__, *,
                 task_key: str,
                 outcome: Optional[str] = None):
        pulumi.set(__self__, "task_key", task_key)
        if outcome is not None:
            pulumi.set(__self__, "outcome", outcome)

    @property
    @pulumi.getter(name="taskKey")
    def task_key(self) -> str:
        return pulumi.get(self, "task_key")

    @property
    @pulumi.getter
    def outcome(self) -> Optional[str]:
        return pulumi.get(self, "outcome")


@pulumi.output_type
class GetJobJobSettingsSettingsTaskEmailNotificationsResult(dict):
    def __init__(__self__, *,
                 on_duration_warning_threshold_exceededs: Optional[Sequence[str]] = None,
                 on_failures: Optional[Sequence[str]] = None,
                 on_starts: Optional[Sequence[str]] = None,
                 on_successes: Optional[Sequence[str]] = None):
        if on_duration_warning_threshold_exceededs is not None:
            pulumi.set(__self__, "on_duration_warning_threshold_exceededs", on_duration_warning_threshold_exceededs)
        if on_failures is not None:
            pulumi.set(__self__, "on_failures", on_failures)
        if on_starts is not None:
            pulumi.set(__self__, "on_starts", on_starts)
        if on_successes is not None:
            pulumi.set(__self__, "on_successes", on_successes)

    @property
    @pulumi.getter(name="onDurationWarningThresholdExceededs")
    def on_duration_warning_threshold_exceededs(self) -> Optional[Sequence[str]]:
        return pulumi.get(self, "on_duration_warning_threshold_exceededs")

    @property
    @pulumi.getter(name="onFailures")
    def on_failures(self) -> Optional[Sequence[str]]:
        return pulumi.get(self, "on_failures")

    @property
    @pulumi.getter(name="onStarts")
    def on_starts(self) -> Optional[Sequence[str]]:
        return pulumi.get(self, "on_starts")

    @property
    @pulumi.getter(name="onSuccesses")
    def on_successes(self) -> Optional[Sequence[str]]:
        return pulumi.get(self, "on_successes")


@pulumi.output_type
class GetJobJobSettingsSettingsTaskForEachTaskResult(dict):
    def __init__(__self__, *,
                 inputs: str,
                 task: 'outputs.GetJobJobSettingsSettingsTaskForEachTaskTaskResult',
                 concurrency: Optional[int] = None):
        pulumi.set(__self__, "inputs", inputs)
        pulumi.set(__self__, "task", task)
        if concurrency is not None:
            pulumi.set(__self__, "concurrency", concurrency)

    @property
    @pulumi.getter
    def inputs(self) -> str:
        return pulumi.get(self, "inputs")

    @property
    @pulumi.getter
    def task(self) -> 'outputs.GetJobJobSettingsSettingsTaskForEachTaskTaskResult':
        return pulumi.get(self, "task")

    @property
    @pulumi.getter
    def concurrency(self) -> Optional[int]:
        return pulumi.get(self, "concurrency")


@pulumi.output_type
class GetJobJobSettingsSettingsTaskForEachTaskTaskResult(dict):
    def __init__(__self__, *,
                 retry_on_timeout: bool,
                 compute_key: Optional[str] = None,
                 condition_task: Optional['outputs.GetJobJobSettingsSettingsTaskForEachTaskTaskConditionTaskResult'] = None,
                 dbt_task: Optional['outputs.GetJobJobSettingsSettingsTaskForEachTaskTaskDbtTaskResult'] = None,
                 depends_ons: Optional[Sequence['outputs.GetJobJobSettingsSettingsTaskForEachTaskTaskDependsOnResult']] = None,
                 description: Optional[str] = None,
                 email_notifications: Optional['outputs.GetJobJobSettingsSettingsTaskForEachTaskTaskEmailNotificationsResult'] = None,
                 existing_cluster_id: Optional[str] = None,
                 health: Optional['outputs.GetJobJobSettingsSettingsTaskForEachTaskTaskHealthResult'] = None,
                 job_cluster_key: Optional[str] = None,
                 libraries: Optional[Sequence['outputs.GetJobJobSettingsSettingsTaskForEachTaskTaskLibraryResult']] = None,
                 max_retries: Optional[int] = None,
                 min_retry_interval_millis: Optional[int] = None,
                 new_cluster: Optional['outputs.GetJobJobSettingsSettingsTaskForEachTaskTaskNewClusterResult'] = None,
                 notebook_task: Optional['outputs.GetJobJobSettingsSettingsTaskForEachTaskTaskNotebookTaskResult'] = None,
                 notification_settings: Optional['outputs.GetJobJobSettingsSettingsTaskForEachTaskTaskNotificationSettingsResult'] = None,
                 pipeline_task: Optional['outputs.GetJobJobSettingsSettingsTaskForEachTaskTaskPipelineTaskResult'] = None,
                 python_wheel_task: Optional['outputs.GetJobJobSettingsSettingsTaskForEachTaskTaskPythonWheelTaskResult'] = None,
                 run_if: Optional[str] = None,
                 run_job_task: Optional['outputs.GetJobJobSettingsSettingsTaskForEachTaskTaskRunJobTaskResult'] = None,
                 spark_jar_task: Optional['outputs.GetJobJobSettingsSettingsTaskForEachTaskTaskSparkJarTaskResult'] = None,
                 spark_python_task: Optional['outputs.GetJobJobSettingsSettingsTaskForEachTaskTaskSparkPythonTaskResult'] = None,
                 spark_submit_task: Optional['outputs.GetJobJobSettingsSettingsTaskForEachTaskTaskSparkSubmitTaskResult'] = None,
                 sql_task: Optional['outputs.GetJobJobSettingsSettingsTaskForEachTaskTaskSqlTaskResult'] = None,
                 task_key: Optional[str] = None,
                 timeout_seconds: Optional[int] = None,
                 webhook_notifications: Optional['outputs.GetJobJobSettingsSettingsTaskForEachTaskTaskWebhookNotificationsResult'] = None):
        pulumi.set(__self__, "retry_on_timeout", retry_on_timeout)
        if compute_key is not None:
            pulumi.set(__self__, "compute_key", compute_key)
        if condition_task is not None:
            pulumi.set(__self__, "condition_task", condition_task)
        if dbt_task is not None:
            pulumi.set(__self__, "dbt_task", dbt_task)
        if depends_ons is not None:
            pulumi.set(__self__, "depends_ons", depends_ons)
        if description is not None:
            pulumi.set(__self__, "description", description)
        if email_notifications is not None:
            pulumi.set(__self__, "email_notifications", email_notifications)
        if existing_cluster_id is not None:
            pulumi.set(__self__, "existing_cluster_id", existing_cluster_id)
        if health is not None:
            pulumi.set(__self__, "health", health)
        if job_cluster_key is not None:
            pulumi.set(__self__, "job_cluster_key", job_cluster_key)
        if libraries is not None:
            pulumi.set(__self__, "libraries", libraries)
        if max_retries is not None:
            pulumi.set(__self__, "max_retries", max_retries)
        if min_retry_interval_millis is not None:
            pulumi.set(__self__, "min_retry_interval_millis", min_retry_interval_millis)
        if new_cluster is not None:
            pulumi.set(__self__, "new_cluster", new_cluster)
        if notebook_task is not None:
            pulumi.set(__self__, "notebook_task", notebook_task)
        if notification_settings is not None:
            pulumi.set(__self__, "notification_settings", notification_settings)
        if pipeline_task is not None:
            pulumi.set(__self__, "pipeline_task", pipeline_task)
        if python_wheel_task is not None:
            pulumi.set(__self__, "python_wheel_task", python_wheel_task)
        if run_if is not None:
            pulumi.set(__self__, "run_if", run_if)
        if run_job_task is not None:
            pulumi.set(__self__, "run_job_task", run_job_task)
        if spark_jar_task is not None:
            pulumi.set(__self__, "spark_jar_task", spark_jar_task)
        if spark_python_task is not None:
            pulumi.set(__self__, "spark_python_task", spark_python_task)
        if spark_submit_task is not None:
            pulumi.set(__self__, "spark_submit_task", spark_submit_task)
        if sql_task is not None:
            pulumi.set(__self__, "sql_task", sql_task)
        if task_key is not None:
            pulumi.set(__self__, "task_key", task_key)
        if timeout_seconds is not None:
            pulumi.set(__self__, "timeout_seconds", timeout_seconds)
        if webhook_notifications is not None:
            pulumi.set(__self__, "webhook_notifications", webhook_notifications)

    @property
    @pulumi.getter(name="retryOnTimeout")
    def retry_on_timeout(self) -> bool:
        return pulumi.get(self, "retry_on_timeout")

    @property
    @pulumi.getter(name="computeKey")
    def compute_key(self) -> Optional[str]:
        return pulumi.get(self, "compute_key")

    @property
    @pulumi.getter(name="conditionTask")
    def condition_task(self) -> Optional['outputs.GetJobJobSettingsSettingsTaskForEachTaskTaskConditionTaskResult']:
        return pulumi.get(self, "condition_task")

    @property
    @pulumi.getter(name="dbtTask")
    def dbt_task(self) -> Optional['outputs.GetJobJobSettingsSettingsTaskForEachTaskTaskDbtTaskResult']:
        return pulumi.get(self, "dbt_task")

    @property
    @pulumi.getter(name="dependsOns")
    def depends_ons(self) -> Optional[Sequence['outputs.GetJobJobSettingsSettingsTaskForEachTaskTaskDependsOnResult']]:
        return pulumi.get(self, "depends_ons")

    @property
    @pulumi.getter
    def description(self) -> Optional[str]:
        return pulumi.get(self, "description")

    @property
    @pulumi.getter(name="emailNotifications")
    def email_notifications(self) -> Optional['outputs.GetJobJobSettingsSettingsTaskForEachTaskTaskEmailNotificationsResult']:
        return pulumi.get(self, "email_notifications")

    @property
    @pulumi.getter(name="existingClusterId")
    def existing_cluster_id(self) -> Optional[str]:
        return pulumi.get(self, "existing_cluster_id")

    @property
    @pulumi.getter
    def health(self) -> Optional['outputs.GetJobJobSettingsSettingsTaskForEachTaskTaskHealthResult']:
        return pulumi.get(self, "health")

    @property
    @pulumi.getter(name="jobClusterKey")
    def job_cluster_key(self) -> Optional[str]:
        return pulumi.get(self, "job_cluster_key")

    @property
    @pulumi.getter
    def libraries(self) -> Optional[Sequence['outputs.GetJobJobSettingsSettingsTaskForEachTaskTaskLibraryResult']]:
        return pulumi.get(self, "libraries")

    @property
    @pulumi.getter(name="maxRetries")
    def max_retries(self) -> Optional[int]:
        return pulumi.get(self, "max_retries")

    @property
    @pulumi.getter(name="minRetryIntervalMillis")
    def min_retry_interval_millis(self) -> Optional[int]:
        return pulumi.get(self, "min_retry_interval_millis")

    @property
    @pulumi.getter(name="newCluster")
    def new_cluster(self) -> Optional['outputs.GetJobJobSettingsSettingsTaskForEachTaskTaskNewClusterResult']:
        return pulumi.get(self, "new_cluster")

    @property
    @pulumi.getter(name="notebookTask")
    def notebook_task(self) -> Optional['outputs.GetJobJobSettingsSettingsTaskForEachTaskTaskNotebookTaskResult']:
        return pulumi.get(self, "notebook_task")

    @property
    @pulumi.getter(name="notificationSettings")
    def notification_settings(self) -> Optional['outputs.GetJobJobSettingsSettingsTaskForEachTaskTaskNotificationSettingsResult']:
        return pulumi.get(self, "notification_settings")

    @property
    @pulumi.getter(name="pipelineTask")
    def pipeline_task(self) -> Optional['outputs.GetJobJobSettingsSettingsTaskForEachTaskTaskPipelineTaskResult']:
        return pulumi.get(self, "pipeline_task")

    @property
    @pulumi.getter(name="pythonWheelTask")
    def python_wheel_task(self) -> Optional['outputs.GetJobJobSettingsSettingsTaskForEachTaskTaskPythonWheelTaskResult']:
        return pulumi.get(self, "python_wheel_task")

    @property
    @pulumi.getter(name="runIf")
    def run_if(self) -> Optional[str]:
        return pulumi.get(self, "run_if")

    @property
    @pulumi.getter(name="runJobTask")
    def run_job_task(self) -> Optional['outputs.GetJobJobSettingsSettingsTaskForEachTaskTaskRunJobTaskResult']:
        return pulumi.get(self, "run_job_task")

    @property
    @pulumi.getter(name="sparkJarTask")
    def spark_jar_task(self) -> Optional['outputs.GetJobJobSettingsSettingsTaskForEachTaskTaskSparkJarTaskResult']:
        return pulumi.get(self, "spark_jar_task")

    @property
    @pulumi.getter(name="sparkPythonTask")
    def spark_python_task(self) -> Optional['outputs.GetJobJobSettingsSettingsTaskForEachTaskTaskSparkPythonTaskResult']:
        return pulumi.get(self, "spark_python_task")

    @property
    @pulumi.getter(name="sparkSubmitTask")
    def spark_submit_task(self) -> Optional['outputs.GetJobJobSettingsSettingsTaskForEachTaskTaskSparkSubmitTaskResult']:
        return pulumi.get(self, "spark_submit_task")

    @property
    @pulumi.getter(name="sqlTask")
    def sql_task(self) -> Optional['outputs.GetJobJobSettingsSettingsTaskForEachTaskTaskSqlTaskResult']:
        return pulumi.get(self, "sql_task")

    @property
    @pulumi.getter(name="taskKey")
    def task_key(self) -> Optional[str]:
        return pulumi.get(self, "task_key")

    @property
    @pulumi.getter(name="timeoutSeconds")
    def timeout_seconds(self) -> Optional[int]:
        return pulumi.get(self, "timeout_seconds")

    @property
    @pulumi.getter(name="webhookNotifications")
    def webhook_notifications(self) -> Optional['outputs.GetJobJobSettingsSettingsTaskForEachTaskTaskWebhookNotificationsResult']:
        return pulumi.get(self, "webhook_notifications")


@pulumi.output_type
class GetJobJobSettingsSettingsTaskForEachTaskTaskConditionTaskResult(dict):
    def __init__(__self__, *,
                 left: Optional[str] = None,
                 op: Optional[str] = None,
                 right: Optional[str] = None):
        if left is not None:
            pulumi.set(__self__, "left", left)
        if op is not None:
            pulumi.set(__self__, "op", op)
        if right is not None:
            pulumi.set(__self__, "right", right)

    @property
    @pulumi.getter
    def left(self) -> Optional[str]:
        return pulumi.get(self, "left")

    @property
    @pulumi.getter
    def op(self) -> Optional[str]:
        return pulumi.get(self, "op")

    @property
    @pulumi.getter
    def right(self) -> Optional[str]:
        return pulumi.get(self, "right")


@pulumi.output_type
class GetJobJobSettingsSettingsTaskForEachTaskTaskDbtTaskResult(dict):
    def __init__(__self__, *,
                 commands: Sequence[str],
                 catalog: Optional[str] = None,
                 profiles_directory: Optional[str] = None,
                 project_directory: Optional[str] = None,
                 schema: Optional[str] = None,
                 source: Optional[str] = None,
                 warehouse_id: Optional[str] = None):
        pulumi.set(__self__, "commands", commands)
        if catalog is not None:
            pulumi.set(__self__, "catalog", catalog)
        if profiles_directory is not None:
            pulumi.set(__self__, "profiles_directory", profiles_directory)
        if project_directory is not None:
            pulumi.set(__self__, "project_directory", project_directory)
        if schema is not None:
            pulumi.set(__self__, "schema", schema)
        if source is not None:
            pulumi.set(__self__, "source", source)
        if warehouse_id is not None:
            pulumi.set(__self__, "warehouse_id", warehouse_id)

    @property
    @pulumi.getter
    def commands(self) -> Sequence[str]:
        return pulumi.get(self, "commands")

    @property
    @pulumi.getter
    def catalog(self) -> Optional[str]:
        return pulumi.get(self, "catalog")

    @property
    @pulumi.getter(name="profilesDirectory")
    def profiles_directory(self) -> Optional[str]:
        return pulumi.get(self, "profiles_directory")

    @property
    @pulumi.getter(name="projectDirectory")
    def project_directory(self) -> Optional[str]:
        return pulumi.get(self, "project_directory")

    @property
    @pulumi.getter
    def schema(self) -> Optional[str]:
        return pulumi.get(self, "schema")

    @property
    @pulumi.getter
    def source(self) -> Optional[str]:
        return pulumi.get(self, "source")

    @property
    @pulumi.getter(name="warehouseId")
    def warehouse_id(self) -> Optional[str]:
        return pulumi.get(self, "warehouse_id")


@pulumi.output_type
class GetJobJobSettingsSettingsTaskForEachTaskTaskDependsOnResult(dict):
    def __init__(__self__, *,
                 task_key: str,
                 outcome: Optional[str] = None):
        pulumi.set(__self__, "task_key", task_key)
        if outcome is not None:
            pulumi.set(__self__, "outcome", outcome)

    @property
    @pulumi.getter(name="taskKey")
    def task_key(self) -> str:
        return pulumi.get(self, "task_key")

    @property
    @pulumi.getter
    def outcome(self) -> Optional[str]:
        return pulumi.get(self, "outcome")


@pulumi.output_type
class GetJobJobSettingsSettingsTaskForEachTaskTaskEmailNotificationsResult(dict):
    def __init__(__self__, *,
                 on_duration_warning_threshold_exceededs: Optional[Sequence[str]] = None,
                 on_failures: Optional[Sequence[str]] = None,
                 on_starts: Optional[Sequence[str]] = None,
                 on_successes: Optional[Sequence[str]] = None):
        if on_duration_warning_threshold_exceededs is not None:
            pulumi.set(__self__, "on_duration_warning_threshold_exceededs", on_duration_warning_threshold_exceededs)
        if on_failures is not None:
            pulumi.set(__self__, "on_failures", on_failures)
        if on_starts is not None:
            pulumi.set(__self__, "on_starts", on_starts)
        if on_successes is not None:
            pulumi.set(__self__, "on_successes", on_successes)

    @property
    @pulumi.getter(name="onDurationWarningThresholdExceededs")
    def on_duration_warning_threshold_exceededs(self) -> Optional[Sequence[str]]:
        return pulumi.get(self, "on_duration_warning_threshold_exceededs")

    @property
    @pulumi.getter(name="onFailures")
    def on_failures(self) -> Optional[Sequence[str]]:
        return pulumi.get(self, "on_failures")

    @property
    @pulumi.getter(name="onStarts")
    def on_starts(self) -> Optional[Sequence[str]]:
        return pulumi.get(self, "on_starts")

    @property
    @pulumi.getter(name="onSuccesses")
    def on_successes(self) -> Optional[Sequence[str]]:
        return pulumi.get(self, "on_successes")


@pulumi.output_type
class GetJobJobSettingsSettingsTaskForEachTaskTaskHealthResult(dict):
    def __init__(__self__, *,
                 rules: Sequence['outputs.GetJobJobSettingsSettingsTaskForEachTaskTaskHealthRuleResult']):
        pulumi.set(__self__, "rules", rules)

    @property
    @pulumi.getter
    def rules(self) -> Sequence['outputs.GetJobJobSettingsSettingsTaskForEachTaskTaskHealthRuleResult']:
        return pulumi.get(self, "rules")


@pulumi.output_type
class GetJobJobSettingsSettingsTaskForEachTaskTaskHealthRuleResult(dict):
    def __init__(__self__, *,
                 metric: Optional[str] = None,
                 op: Optional[str] = None,
                 value: Optional[int] = None):
        if metric is not None:
            pulumi.set(__self__, "metric", metric)
        if op is not None:
            pulumi.set(__self__, "op", op)
        if value is not None:
            pulumi.set(__self__, "value", value)

    @property
    @pulumi.getter
    def metric(self) -> Optional[str]:
        return pulumi.get(self, "metric")

    @property
    @pulumi.getter
    def op(self) -> Optional[str]:
        return pulumi.get(self, "op")

    @property
    @pulumi.getter
    def value(self) -> Optional[int]:
        return pulumi.get(self, "value")


@pulumi.output_type
class GetJobJobSettingsSettingsTaskForEachTaskTaskLibraryResult(dict):
    def __init__(__self__, *,
                 cran: Optional['outputs.GetJobJobSettingsSettingsTaskForEachTaskTaskLibraryCranResult'] = None,
                 egg: Optional[str] = None,
                 jar: Optional[str] = None,
                 maven: Optional['outputs.GetJobJobSettingsSettingsTaskForEachTaskTaskLibraryMavenResult'] = None,
                 pypi: Optional['outputs.GetJobJobSettingsSettingsTaskForEachTaskTaskLibraryPypiResult'] = None,
                 whl: Optional[str] = None):
        if cran is not None:
            pulumi.set(__self__, "cran", cran)
        if egg is not None:
            pulumi.set(__self__, "egg", egg)
        if jar is not None:
            pulumi.set(__self__, "jar", jar)
        if maven is not None:
            pulumi.set(__self__, "maven", maven)
        if pypi is not None:
            pulumi.set(__self__, "pypi", pypi)
        if whl is not None:
            pulumi.set(__self__, "whl", whl)

    @property
    @pulumi.getter
    def cran(self) -> Optional['outputs.GetJobJobSettingsSettingsTaskForEachTaskTaskLibraryCranResult']:
        return pulumi.get(self, "cran")

    @property
    @pulumi.getter
    def egg(self) -> Optional[str]:
        return pulumi.get(self, "egg")

    @property
    @pulumi.getter
    def jar(self) -> Optional[str]:
        return pulumi.get(self, "jar")

    @property
    @pulumi.getter
    def maven(self) -> Optional['outputs.GetJobJobSettingsSettingsTaskForEachTaskTaskLibraryMavenResult']:
        return pulumi.get(self, "maven")

    @property
    @pulumi.getter
    def pypi(self) -> Optional['outputs.GetJobJobSettingsSettingsTaskForEachTaskTaskLibraryPypiResult']:
        return pulumi.get(self, "pypi")

    @property
    @pulumi.getter
    def whl(self) -> Optional[str]:
        return pulumi.get(self, "whl")


@pulumi.output_type
class GetJobJobSettingsSettingsTaskForEachTaskTaskLibraryCranResult(dict):
    def __init__(__self__, *,
                 package: str,
                 repo: Optional[str] = None):
        pulumi.set(__self__, "package", package)
        if repo is not None:
            pulumi.set(__self__, "repo", repo)

    @property
    @pulumi.getter
    def package(self) -> str:
        return pulumi.get(self, "package")

    @property
    @pulumi.getter
    def repo(self) -> Optional[str]:
        return pulumi.get(self, "repo")


@pulumi.output_type
class GetJobJobSettingsSettingsTaskForEachTaskTaskLibraryMavenResult(dict):
    def __init__(__self__, *,
                 coordinates: str,
                 exclusions: Optional[Sequence[str]] = None,
                 repo: Optional[str] = None):
        pulumi.set(__self__, "coordinates", coordinates)
        if exclusions is not None:
            pulumi.set(__self__, "exclusions", exclusions)
        if repo is not None:
            pulumi.set(__self__, "repo", repo)

    @property
    @pulumi.getter
    def coordinates(self) -> str:
        return pulumi.get(self, "coordinates")

    @property
    @pulumi.getter
    def exclusions(self) -> Optional[Sequence[str]]:
        return pulumi.get(self, "exclusions")

    @property
    @pulumi.getter
    def repo(self) -> Optional[str]:
        return pulumi.get(self, "repo")


@pulumi.output_type
class GetJobJobSettingsSettingsTaskForEachTaskTaskLibraryPypiResult(dict):
    def __init__(__self__, *,
                 package: str,
                 repo: Optional[str] = None):
        pulumi.set(__self__, "package", package)
        if repo is not None:
            pulumi.set(__self__, "repo", repo)

    @property
    @pulumi.getter
    def package(self) -> str:
        return pulumi.get(self, "package")

    @property
    @pulumi.getter
    def repo(self) -> Optional[str]:
        return pulumi.get(self, "repo")


@pulumi.output_type
class GetJobJobSettingsSettingsTaskForEachTaskTaskNewClusterResult(dict):
    def __init__(__self__, *,
                 driver_instance_pool_id: str,
                 driver_node_type_id: str,
                 enable_elastic_disk: bool,
                 enable_local_disk_encryption: bool,
                 node_type_id: str,
                 num_workers: int,
                 spark_version: str,
                 apply_policy_default_values: Optional[bool] = None,
                 autoscale: Optional['outputs.GetJobJobSettingsSettingsTaskForEachTaskTaskNewClusterAutoscaleResult'] = None,
                 autotermination_minutes: Optional[int] = None,
                 aws_attributes: Optional['outputs.GetJobJobSettingsSettingsTaskForEachTaskTaskNewClusterAwsAttributesResult'] = None,
                 azure_attributes: Optional['outputs.GetJobJobSettingsSettingsTaskForEachTaskTaskNewClusterAzureAttributesResult'] = None,
                 cluster_id: Optional[str] = None,
                 cluster_log_conf: Optional['outputs.GetJobJobSettingsSettingsTaskForEachTaskTaskNewClusterClusterLogConfResult'] = None,
                 cluster_mount_infos: Optional[Sequence['outputs.GetJobJobSettingsSettingsTaskForEachTaskTaskNewClusterClusterMountInfoResult']] = None,
                 cluster_name: Optional[str] = None,
                 custom_tags: Optional[Mapping[str, Any]] = None,
                 data_security_mode: Optional[str] = None,
                 docker_image: Optional['outputs.GetJobJobSettingsSettingsTaskForEachTaskTaskNewClusterDockerImageResult'] = None,
                 gcp_attributes: Optional['outputs.GetJobJobSettingsSettingsTaskForEachTaskTaskNewClusterGcpAttributesResult'] = None,
                 idempotency_token: Optional[str] = None,
                 init_scripts: Optional[Sequence['outputs.GetJobJobSettingsSettingsTaskForEachTaskTaskNewClusterInitScriptResult']] = None,
                 instance_pool_id: Optional[str] = None,
                 policy_id: Optional[str] = None,
                 runtime_engine: Optional[str] = None,
                 single_user_name: Optional[str] = None,
                 spark_conf: Optional[Mapping[str, Any]] = None,
                 spark_env_vars: Optional[Mapping[str, Any]] = None,
                 ssh_public_keys: Optional[Sequence[str]] = None,
                 workload_type: Optional['outputs.GetJobJobSettingsSettingsTaskForEachTaskTaskNewClusterWorkloadTypeResult'] = None):
        pulumi.set(__self__, "driver_instance_pool_id", driver_instance_pool_id)
        pulumi.set(__self__, "driver_node_type_id", driver_node_type_id)
        pulumi.set(__self__, "enable_elastic_disk", enable_elastic_disk)
        pulumi.set(__self__, "enable_local_disk_encryption", enable_local_disk_encryption)
        pulumi.set(__self__, "node_type_id", node_type_id)
        pulumi.set(__self__, "num_workers", num_workers)
        pulumi.set(__self__, "spark_version", spark_version)
        if apply_policy_default_values is not None:
            pulumi.set(__self__, "apply_policy_default_values", apply_policy_default_values)
        if autoscale is not None:
            pulumi.set(__self__, "autoscale", autoscale)
        if autotermination_minutes is not None:
            pulumi.set(__self__, "autotermination_minutes", autotermination_minutes)
        if aws_attributes is not None:
            pulumi.set(__self__, "aws_attributes", aws_attributes)
        if azure_attributes is not None:
            pulumi.set(__self__, "azure_attributes", azure_attributes)
        if cluster_id is not None:
            pulumi.set(__self__, "cluster_id", cluster_id)
        if cluster_log_conf is not None:
            pulumi.set(__self__, "cluster_log_conf", cluster_log_conf)
        if cluster_mount_infos is not None:
            pulumi.set(__self__, "cluster_mount_infos", cluster_mount_infos)
        if cluster_name is not None:
            pulumi.set(__self__, "cluster_name", cluster_name)
        if custom_tags is not None:
            pulumi.set(__self__, "custom_tags", custom_tags)
        if data_security_mode is not None:
            pulumi.set(__self__, "data_security_mode", data_security_mode)
        if docker_image is not None:
            pulumi.set(__self__, "docker_image", docker_image)
        if gcp_attributes is not None:
            pulumi.set(__self__, "gcp_attributes", gcp_attributes)
        if idempotency_token is not None:
            pulumi.set(__self__, "idempotency_token", idempotency_token)
        if init_scripts is not None:
            pulumi.set(__self__, "init_scripts", init_scripts)
        if instance_pool_id is not None:
            pulumi.set(__self__, "instance_pool_id", instance_pool_id)
        if policy_id is not None:
            pulumi.set(__self__, "policy_id", policy_id)
        if runtime_engine is not None:
            pulumi.set(__self__, "runtime_engine", runtime_engine)
        if single_user_name is not None:
            pulumi.set(__self__, "single_user_name", single_user_name)
        if spark_conf is not None:
            pulumi.set(__self__, "spark_conf", spark_conf)
        if spark_env_vars is not None:
            pulumi.set(__self__, "spark_env_vars", spark_env_vars)
        if ssh_public_keys is not None:
            pulumi.set(__self__, "ssh_public_keys", ssh_public_keys)
        if workload_type is not None:
            pulumi.set(__self__, "workload_type", workload_type)

    @property
    @pulumi.getter(name="driverInstancePoolId")
    def driver_instance_pool_id(self) -> str:
        return pulumi.get(self, "driver_instance_pool_id")

    @property
    @pulumi.getter(name="driverNodeTypeId")
    def driver_node_type_id(self) -> str:
        return pulumi.get(self, "driver_node_type_id")

    @property
    @pulumi.getter(name="enableElasticDisk")
    def enable_elastic_disk(self) -> bool:
        return pulumi.get(self, "enable_elastic_disk")

    @property
    @pulumi.getter(name="enableLocalDiskEncryption")
    def enable_local_disk_encryption(self) -> bool:
        return pulumi.get(self, "enable_local_disk_encryption")

    @property
    @pulumi.getter(name="nodeTypeId")
    def node_type_id(self) -> str:
        return pulumi.get(self, "node_type_id")

    @property
    @pulumi.getter(name="numWorkers")
    def num_workers(self) -> int:
        return pulumi.get(self, "num_workers")

    @property
    @pulumi.getter(name="sparkVersion")
    def spark_version(self) -> str:
        return pulumi.get(self, "spark_version")

    @property
    @pulumi.getter(name="applyPolicyDefaultValues")
    def apply_policy_default_values(self) -> Optional[bool]:
        return pulumi.get(self, "apply_policy_default_values")

    @property
    @pulumi.getter
    def autoscale(self) -> Optional['outputs.GetJobJobSettingsSettingsTaskForEachTaskTaskNewClusterAutoscaleResult']:
        return pulumi.get(self, "autoscale")

    @property
    @pulumi.getter(name="autoterminationMinutes")
    def autotermination_minutes(self) -> Optional[int]:
        return pulumi.get(self, "autotermination_minutes")

    @property
    @pulumi.getter(name="awsAttributes")
    def aws_attributes(self) -> Optional['outputs.GetJobJobSettingsSettingsTaskForEachTaskTaskNewClusterAwsAttributesResult']:
        return pulumi.get(self, "aws_attributes")

    @property
    @pulumi.getter(name="azureAttributes")
    def azure_attributes(self) -> Optional['outputs.GetJobJobSettingsSettingsTaskForEachTaskTaskNewClusterAzureAttributesResult']:
        return pulumi.get(self, "azure_attributes")

    @property
    @pulumi.getter(name="clusterId")
    def cluster_id(self) -> Optional[str]:
        return pulumi.get(self, "cluster_id")

    @property
    @pulumi.getter(name="clusterLogConf")
    def cluster_log_conf(self) -> Optional['outputs.GetJobJobSettingsSettingsTaskForEachTaskTaskNewClusterClusterLogConfResult']:
        return pulumi.get(self, "cluster_log_conf")

    @property
    @pulumi.getter(name="clusterMountInfos")
    def cluster_mount_infos(self) -> Optional[Sequence['outputs.GetJobJobSettingsSettingsTaskForEachTaskTaskNewClusterClusterMountInfoResult']]:
        return pulumi.get(self, "cluster_mount_infos")

    @property
    @pulumi.getter(name="clusterName")
    def cluster_name(self) -> Optional[str]:
        return pulumi.get(self, "cluster_name")

    @property
    @pulumi.getter(name="customTags")
    def custom_tags(self) -> Optional[Mapping[str, Any]]:
        return pulumi.get(self, "custom_tags")

    @property
    @pulumi.getter(name="dataSecurityMode")
    def data_security_mode(self) -> Optional[str]:
        return pulumi.get(self, "data_security_mode")

    @property
    @pulumi.getter(name="dockerImage")
    def docker_image(self) -> Optional['outputs.GetJobJobSettingsSettingsTaskForEachTaskTaskNewClusterDockerImageResult']:
        return pulumi.get(self, "docker_image")

    @property
    @pulumi.getter(name="gcpAttributes")
    def gcp_attributes(self) -> Optional['outputs.GetJobJobSettingsSettingsTaskForEachTaskTaskNewClusterGcpAttributesResult']:
        return pulumi.get(self, "gcp_attributes")

    @property
    @pulumi.getter(name="idempotencyToken")
    def idempotency_token(self) -> Optional[str]:
        return pulumi.get(self, "idempotency_token")

    @property
    @pulumi.getter(name="initScripts")
    def init_scripts(self) -> Optional[Sequence['outputs.GetJobJobSettingsSettingsTaskForEachTaskTaskNewClusterInitScriptResult']]:
        return pulumi.get(self, "init_scripts")

    @property
    @pulumi.getter(name="instancePoolId")
    def instance_pool_id(self) -> Optional[str]:
        return pulumi.get(self, "instance_pool_id")

    @property
    @pulumi.getter(name="policyId")
    def policy_id(self) -> Optional[str]:
        return pulumi.get(self, "policy_id")

    @property
    @pulumi.getter(name="runtimeEngine")
    def runtime_engine(self) -> Optional[str]:
        return pulumi.get(self, "runtime_engine")

    @property
    @pulumi.getter(name="singleUserName")
    def single_user_name(self) -> Optional[str]:
        return pulumi.get(self, "single_user_name")

    @property
    @pulumi.getter(name="sparkConf")
    def spark_conf(self) -> Optional[Mapping[str, Any]]:
        return pulumi.get(self, "spark_conf")

    @property
    @pulumi.getter(name="sparkEnvVars")
    def spark_env_vars(self) -> Optional[Mapping[str, Any]]:
        return pulumi.get(self, "spark_env_vars")

    @property
    @pulumi.getter(name="sshPublicKeys")
    def ssh_public_keys(self) -> Optional[Sequence[str]]:
        return pulumi.get(self, "ssh_public_keys")

    @property
    @pulumi.getter(name="workloadType")
    def workload_type(self) -> Optional['outputs.GetJobJobSettingsSettingsTaskForEachTaskTaskNewClusterWorkloadTypeResult']:
        return pulumi.get(self, "workload_type")


@pulumi.output_type
class GetJobJobSettingsSettingsTaskForEachTaskTaskNewClusterAutoscaleResult(dict):
    def __init__(__self__, *,
                 max_workers: Optional[int] = None,
                 min_workers: Optional[int] = None):
        if max_workers is not None:
            pulumi.set(__self__, "max_workers", max_workers)
        if min_workers is not None:
            pulumi.set(__self__, "min_workers", min_workers)

    @property
    @pulumi.getter(name="maxWorkers")
    def max_workers(self) -> Optional[int]:
        return pulumi.get(self, "max_workers")

    @property
    @pulumi.getter(name="minWorkers")
    def min_workers(self) -> Optional[int]:
        return pulumi.get(self, "min_workers")


@pulumi.output_type
class GetJobJobSettingsSettingsTaskForEachTaskTaskNewClusterAwsAttributesResult(dict):
    def __init__(__self__, *,
                 availability: Optional[str] = None,
                 ebs_volume_count: Optional[int] = None,
                 ebs_volume_size: Optional[int] = None,
                 ebs_volume_type: Optional[str] = None,
                 first_on_demand: Optional[int] = None,
                 instance_profile_arn: Optional[str] = None,
                 spot_bid_price_percent: Optional[int] = None,
                 zone_id: Optional[str] = None):
        if availability is not None:
            pulumi.set(__self__, "availability", availability)
        if ebs_volume_count is not None:
            pulumi.set(__self__, "ebs_volume_count", ebs_volume_count)
        if ebs_volume_size is not None:
            pulumi.set(__self__, "ebs_volume_size", ebs_volume_size)
        if ebs_volume_type is not None:
            pulumi.set(__self__, "ebs_volume_type", ebs_volume_type)
        if first_on_demand is not None:
            pulumi.set(__self__, "first_on_demand", first_on_demand)
        if instance_profile_arn is not None:
            pulumi.set(__self__, "instance_profile_arn", instance_profile_arn)
        if spot_bid_price_percent is not None:
            pulumi.set(__self__, "spot_bid_price_percent", spot_bid_price_percent)
        if zone_id is not None:
            pulumi.set(__self__, "zone_id", zone_id)

    @property
    @pulumi.getter
    def availability(self) -> Optional[str]:
        return pulumi.get(self, "availability")

    @property
    @pulumi.getter(name="ebsVolumeCount")
    def ebs_volume_count(self) -> Optional[int]:
        return pulumi.get(self, "ebs_volume_count")

    @property
    @pulumi.getter(name="ebsVolumeSize")
    def ebs_volume_size(self) -> Optional[int]:
        return pulumi.get(self, "ebs_volume_size")

    @property
    @pulumi.getter(name="ebsVolumeType")
    def ebs_volume_type(self) -> Optional[str]:
        return pulumi.get(self, "ebs_volume_type")

    @property
    @pulumi.getter(name="firstOnDemand")
    def first_on_demand(self) -> Optional[int]:
        return pulumi.get(self, "first_on_demand")

    @property
    @pulumi.getter(name="instanceProfileArn")
    def instance_profile_arn(self) -> Optional[str]:
        return pulumi.get(self, "instance_profile_arn")

    @property
    @pulumi.getter(name="spotBidPricePercent")
    def spot_bid_price_percent(self) -> Optional[int]:
        return pulumi.get(self, "spot_bid_price_percent")

    @property
    @pulumi.getter(name="zoneId")
    def zone_id(self) -> Optional[str]:
        return pulumi.get(self, "zone_id")


@pulumi.output_type
class GetJobJobSettingsSettingsTaskForEachTaskTaskNewClusterAzureAttributesResult(dict):
    def __init__(__self__, *,
                 availability: Optional[str] = None,
                 first_on_demand: Optional[int] = None,
                 spot_bid_max_price: Optional[float] = None):
        if availability is not None:
            pulumi.set(__self__, "availability", availability)
        if first_on_demand is not None:
            pulumi.set(__self__, "first_on_demand", first_on_demand)
        if spot_bid_max_price is not None:
            pulumi.set(__self__, "spot_bid_max_price", spot_bid_max_price)

    @property
    @pulumi.getter
    def availability(self) -> Optional[str]:
        return pulumi.get(self, "availability")

    @property
    @pulumi.getter(name="firstOnDemand")
    def first_on_demand(self) -> Optional[int]:
        return pulumi.get(self, "first_on_demand")

    @property
    @pulumi.getter(name="spotBidMaxPrice")
    def spot_bid_max_price(self) -> Optional[float]:
        return pulumi.get(self, "spot_bid_max_price")


@pulumi.output_type
class GetJobJobSettingsSettingsTaskForEachTaskTaskNewClusterClusterLogConfResult(dict):
    def __init__(__self__, *,
                 dbfs: Optional['outputs.GetJobJobSettingsSettingsTaskForEachTaskTaskNewClusterClusterLogConfDbfsResult'] = None,
                 s3: Optional['outputs.GetJobJobSettingsSettingsTaskForEachTaskTaskNewClusterClusterLogConfS3Result'] = None):
        if dbfs is not None:
            pulumi.set(__self__, "dbfs", dbfs)
        if s3 is not None:
            pulumi.set(__self__, "s3", s3)

    @property
    @pulumi.getter
    def dbfs(self) -> Optional['outputs.GetJobJobSettingsSettingsTaskForEachTaskTaskNewClusterClusterLogConfDbfsResult']:
        return pulumi.get(self, "dbfs")

    @property
    @pulumi.getter
    def s3(self) -> Optional['outputs.GetJobJobSettingsSettingsTaskForEachTaskTaskNewClusterClusterLogConfS3Result']:
        return pulumi.get(self, "s3")


@pulumi.output_type
class GetJobJobSettingsSettingsTaskForEachTaskTaskNewClusterClusterLogConfDbfsResult(dict):
    def __init__(__self__, *,
                 destination: str):
        pulumi.set(__self__, "destination", destination)

    @property
    @pulumi.getter
    def destination(self) -> str:
        return pulumi.get(self, "destination")


@pulumi.output_type
class GetJobJobSettingsSettingsTaskForEachTaskTaskNewClusterClusterLogConfS3Result(dict):
    def __init__(__self__, *,
                 destination: str,
                 canned_acl: Optional[str] = None,
                 enable_encryption: Optional[bool] = None,
                 encryption_type: Optional[str] = None,
                 endpoint: Optional[str] = None,
                 kms_key: Optional[str] = None,
                 region: Optional[str] = None):
        pulumi.set(__self__, "destination", destination)
        if canned_acl is not None:
            pulumi.set(__self__, "canned_acl", canned_acl)
        if enable_encryption is not None:
            pulumi.set(__self__, "enable_encryption", enable_encryption)
        if encryption_type is not None:
            pulumi.set(__self__, "encryption_type", encryption_type)
        if endpoint is not None:
            pulumi.set(__self__, "endpoint", endpoint)
        if kms_key is not None:
            pulumi.set(__self__, "kms_key", kms_key)
        if region is not None:
            pulumi.set(__self__, "region", region)

    @property
    @pulumi.getter
    def destination(self) -> str:
        return pulumi.get(self, "destination")

    @property
    @pulumi.getter(name="cannedAcl")
    def canned_acl(self) -> Optional[str]:
        return pulumi.get(self, "canned_acl")

    @property
    @pulumi.getter(name="enableEncryption")
    def enable_encryption(self) -> Optional[bool]:
        return pulumi.get(self, "enable_encryption")

    @property
    @pulumi.getter(name="encryptionType")
    def encryption_type(self) -> Optional[str]:
        return pulumi.get(self, "encryption_type")

    @property
    @pulumi.getter
    def endpoint(self) -> Optional[str]:
        return pulumi.get(self, "endpoint")

    @property
    @pulumi.getter(name="kmsKey")
    def kms_key(self) -> Optional[str]:
        return pulumi.get(self, "kms_key")

    @property
    @pulumi.getter
    def region(self) -> Optional[str]:
        return pulumi.get(self, "region")


@pulumi.output_type
class GetJobJobSettingsSettingsTaskForEachTaskTaskNewClusterClusterMountInfoResult(dict):
    def __init__(__self__, *,
                 local_mount_dir_path: str,
                 network_filesystem_info: 'outputs.GetJobJobSettingsSettingsTaskForEachTaskTaskNewClusterClusterMountInfoNetworkFilesystemInfoResult',
                 remote_mount_dir_path: Optional[str] = None):
        pulumi.set(__self__, "local_mount_dir_path", local_mount_dir_path)
        pulumi.set(__self__, "network_filesystem_info", network_filesystem_info)
        if remote_mount_dir_path is not None:
            pulumi.set(__self__, "remote_mount_dir_path", remote_mount_dir_path)

    @property
    @pulumi.getter(name="localMountDirPath")
    def local_mount_dir_path(self) -> str:
        return pulumi.get(self, "local_mount_dir_path")

    @property
    @pulumi.getter(name="networkFilesystemInfo")
    def network_filesystem_info(self) -> 'outputs.GetJobJobSettingsSettingsTaskForEachTaskTaskNewClusterClusterMountInfoNetworkFilesystemInfoResult':
        return pulumi.get(self, "network_filesystem_info")

    @property
    @pulumi.getter(name="remoteMountDirPath")
    def remote_mount_dir_path(self) -> Optional[str]:
        return pulumi.get(self, "remote_mount_dir_path")


@pulumi.output_type
class GetJobJobSettingsSettingsTaskForEachTaskTaskNewClusterClusterMountInfoNetworkFilesystemInfoResult(dict):
    def __init__(__self__, *,
                 server_address: str,
                 mount_options: Optional[str] = None):
        pulumi.set(__self__, "server_address", server_address)
        if mount_options is not None:
            pulumi.set(__self__, "mount_options", mount_options)

    @property
    @pulumi.getter(name="serverAddress")
    def server_address(self) -> str:
        return pulumi.get(self, "server_address")

    @property
    @pulumi.getter(name="mountOptions")
    def mount_options(self) -> Optional[str]:
        return pulumi.get(self, "mount_options")


@pulumi.output_type
class GetJobJobSettingsSettingsTaskForEachTaskTaskNewClusterDockerImageResult(dict):
    def __init__(__self__, *,
                 url: str,
                 basic_auth: Optional['outputs.GetJobJobSettingsSettingsTaskForEachTaskTaskNewClusterDockerImageBasicAuthResult'] = None):
        pulumi.set(__self__, "url", url)
        if basic_auth is not None:
            pulumi.set(__self__, "basic_auth", basic_auth)

    @property
    @pulumi.getter
    def url(self) -> str:
        return pulumi.get(self, "url")

    @property
    @pulumi.getter(name="basicAuth")
    def basic_auth(self) -> Optional['outputs.GetJobJobSettingsSettingsTaskForEachTaskTaskNewClusterDockerImageBasicAuthResult']:
        return pulumi.get(self, "basic_auth")


@pulumi.output_type
class GetJobJobSettingsSettingsTaskForEachTaskTaskNewClusterDockerImageBasicAuthResult(dict):
    def __init__(__self__, *,
                 password: str,
                 username: str):
        pulumi.set(__self__, "password", password)
        pulumi.set(__self__, "username", username)

    @property
    @pulumi.getter
    def password(self) -> str:
        return pulumi.get(self, "password")

    @property
    @pulumi.getter
    def username(self) -> str:
        return pulumi.get(self, "username")


@pulumi.output_type
class GetJobJobSettingsSettingsTaskForEachTaskTaskNewClusterGcpAttributesResult(dict):
    def __init__(__self__, *,
                 availability: Optional[str] = None,
                 boot_disk_size: Optional[int] = None,
                 google_service_account: Optional[str] = None,
                 local_ssd_count: Optional[int] = None,
                 use_preemptible_executors: Optional[bool] = None,
                 zone_id: Optional[str] = None):
        if availability is not None:
            pulumi.set(__self__, "availability", availability)
        if boot_disk_size is not None:
            pulumi.set(__self__, "boot_disk_size", boot_disk_size)
        if google_service_account is not None:
            pulumi.set(__self__, "google_service_account", google_service_account)
        if local_ssd_count is not None:
            pulumi.set(__self__, "local_ssd_count", local_ssd_count)
        if use_preemptible_executors is not None:
            pulumi.set(__self__, "use_preemptible_executors", use_preemptible_executors)
        if zone_id is not None:
            pulumi.set(__self__, "zone_id", zone_id)

    @property
    @pulumi.getter
    def availability(self) -> Optional[str]:
        return pulumi.get(self, "availability")

    @property
    @pulumi.getter(name="bootDiskSize")
    def boot_disk_size(self) -> Optional[int]:
        return pulumi.get(self, "boot_disk_size")

    @property
    @pulumi.getter(name="googleServiceAccount")
    def google_service_account(self) -> Optional[str]:
        return pulumi.get(self, "google_service_account")

    @property
    @pulumi.getter(name="localSsdCount")
    def local_ssd_count(self) -> Optional[int]:
        return pulumi.get(self, "local_ssd_count")

    @property
    @pulumi.getter(name="usePreemptibleExecutors")
    def use_preemptible_executors(self) -> Optional[bool]:
        return pulumi.get(self, "use_preemptible_executors")

    @property
    @pulumi.getter(name="zoneId")
    def zone_id(self) -> Optional[str]:
        return pulumi.get(self, "zone_id")


@pulumi.output_type
class GetJobJobSettingsSettingsTaskForEachTaskTaskNewClusterInitScriptResult(dict):
    def __init__(__self__, *,
                 abfss: Optional['outputs.GetJobJobSettingsSettingsTaskForEachTaskTaskNewClusterInitScriptAbfssResult'] = None,
                 dbfs: Optional['outputs.GetJobJobSettingsSettingsTaskForEachTaskTaskNewClusterInitScriptDbfsResult'] = None,
                 file: Optional['outputs.GetJobJobSettingsSettingsTaskForEachTaskTaskNewClusterInitScriptFileResult'] = None,
                 gcs: Optional['outputs.GetJobJobSettingsSettingsTaskForEachTaskTaskNewClusterInitScriptGcsResult'] = None,
                 s3: Optional['outputs.GetJobJobSettingsSettingsTaskForEachTaskTaskNewClusterInitScriptS3Result'] = None,
                 volumes: Optional['outputs.GetJobJobSettingsSettingsTaskForEachTaskTaskNewClusterInitScriptVolumesResult'] = None,
                 workspace: Optional['outputs.GetJobJobSettingsSettingsTaskForEachTaskTaskNewClusterInitScriptWorkspaceResult'] = None):
        if abfss is not None:
            pulumi.set(__self__, "abfss", abfss)
        if dbfs is not None:
            pulumi.set(__self__, "dbfs", dbfs)
        if file is not None:
            pulumi.set(__self__, "file", file)
        if gcs is not None:
            pulumi.set(__self__, "gcs", gcs)
        if s3 is not None:
            pulumi.set(__self__, "s3", s3)
        if volumes is not None:
            pulumi.set(__self__, "volumes", volumes)
        if workspace is not None:
            pulumi.set(__self__, "workspace", workspace)

    @property
    @pulumi.getter
    def abfss(self) -> Optional['outputs.GetJobJobSettingsSettingsTaskForEachTaskTaskNewClusterInitScriptAbfssResult']:
        return pulumi.get(self, "abfss")

    @property
    @pulumi.getter
    def dbfs(self) -> Optional['outputs.GetJobJobSettingsSettingsTaskForEachTaskTaskNewClusterInitScriptDbfsResult']:
        return pulumi.get(self, "dbfs")

    @property
    @pulumi.getter
    def file(self) -> Optional['outputs.GetJobJobSettingsSettingsTaskForEachTaskTaskNewClusterInitScriptFileResult']:
        return pulumi.get(self, "file")

    @property
    @pulumi.getter
    def gcs(self) -> Optional['outputs.GetJobJobSettingsSettingsTaskForEachTaskTaskNewClusterInitScriptGcsResult']:
        return pulumi.get(self, "gcs")

    @property
    @pulumi.getter
    def s3(self) -> Optional['outputs.GetJobJobSettingsSettingsTaskForEachTaskTaskNewClusterInitScriptS3Result']:
        return pulumi.get(self, "s3")

    @property
    @pulumi.getter
    def volumes(self) -> Optional['outputs.GetJobJobSettingsSettingsTaskForEachTaskTaskNewClusterInitScriptVolumesResult']:
        return pulumi.get(self, "volumes")

    @property
    @pulumi.getter
    def workspace(self) -> Optional['outputs.GetJobJobSettingsSettingsTaskForEachTaskTaskNewClusterInitScriptWorkspaceResult']:
        return pulumi.get(self, "workspace")


@pulumi.output_type
class GetJobJobSettingsSettingsTaskForEachTaskTaskNewClusterInitScriptAbfssResult(dict):
    def __init__(__self__, *,
                 destination: str):
        pulumi.set(__self__, "destination", destination)

    @property
    @pulumi.getter
    def destination(self) -> str:
        return pulumi.get(self, "destination")


@pulumi.output_type
class GetJobJobSettingsSettingsTaskForEachTaskTaskNewClusterInitScriptDbfsResult(dict):
    def __init__(__self__, *,
                 destination: str):
        pulumi.set(__self__, "destination", destination)

    @property
    @pulumi.getter
    def destination(self) -> str:
        return pulumi.get(self, "destination")


@pulumi.output_type
class GetJobJobSettingsSettingsTaskForEachTaskTaskNewClusterInitScriptFileResult(dict):
    def __init__(__self__, *,
                 destination: str):
        pulumi.set(__self__, "destination", destination)

    @property
    @pulumi.getter
    def destination(self) -> str:
        return pulumi.get(self, "destination")


@pulumi.output_type
class GetJobJobSettingsSettingsTaskForEachTaskTaskNewClusterInitScriptGcsResult(dict):
    def __init__(__self__, *,
                 destination: str):
        pulumi.set(__self__, "destination", destination)

    @property
    @pulumi.getter
    def destination(self) -> str:
        return pulumi.get(self, "destination")


@pulumi.output_type
class GetJobJobSettingsSettingsTaskForEachTaskTaskNewClusterInitScriptS3Result(dict):
    def __init__(__self__, *,
                 destination: str,
                 canned_acl: Optional[str] = None,
                 enable_encryption: Optional[bool] = None,
                 encryption_type: Optional[str] = None,
                 endpoint: Optional[str] = None,
                 kms_key: Optional[str] = None,
                 region: Optional[str] = None):
        pulumi.set(__self__, "destination", destination)
        if canned_acl is not None:
            pulumi.set(__self__, "canned_acl", canned_acl)
        if enable_encryption is not None:
            pulumi.set(__self__, "enable_encryption", enable_encryption)
        if encryption_type is not None:
            pulumi.set(__self__, "encryption_type", encryption_type)
        if endpoint is not None:
            pulumi.set(__self__, "endpoint", endpoint)
        if kms_key is not None:
            pulumi.set(__self__, "kms_key", kms_key)
        if region is not None:
            pulumi.set(__self__, "region", region)

    @property
    @pulumi.getter
    def destination(self) -> str:
        return pulumi.get(self, "destination")

    @property
    @pulumi.getter(name="cannedAcl")
    def canned_acl(self) -> Optional[str]:
        return pulumi.get(self, "canned_acl")

    @property
    @pulumi.getter(name="enableEncryption")
    def enable_encryption(self) -> Optional[bool]:
        return pulumi.get(self, "enable_encryption")

    @property
    @pulumi.getter(name="encryptionType")
    def encryption_type(self) -> Optional[str]:
        return pulumi.get(self, "encryption_type")

    @property
    @pulumi.getter
    def endpoint(self) -> Optional[str]:
        return pulumi.get(self, "endpoint")

    @property
    @pulumi.getter(name="kmsKey")
    def kms_key(self) -> Optional[str]:
        return pulumi.get(self, "kms_key")

    @property
    @pulumi.getter
    def region(self) -> Optional[str]:
        return pulumi.get(self, "region")


@pulumi.output_type
class GetJobJobSettingsSettingsTaskForEachTaskTaskNewClusterInitScriptVolumesResult(dict):
    def __init__(__self__, *,
                 destination: str):
        pulumi.set(__self__, "destination", destination)

    @property
    @pulumi.getter
    def destination(self) -> str:
        return pulumi.get(self, "destination")


@pulumi.output_type
class GetJobJobSettingsSettingsTaskForEachTaskTaskNewClusterInitScriptWorkspaceResult(dict):
    def __init__(__self__, *,
                 destination: str):
        pulumi.set(__self__, "destination", destination)

    @property
    @pulumi.getter
    def destination(self) -> str:
        return pulumi.get(self, "destination")


@pulumi.output_type
class GetJobJobSettingsSettingsTaskForEachTaskTaskNewClusterWorkloadTypeResult(dict):
    def __init__(__self__, *,
                 clients: 'outputs.GetJobJobSettingsSettingsTaskForEachTaskTaskNewClusterWorkloadTypeClientsResult'):
        pulumi.set(__self__, "clients", clients)

    @property
    @pulumi.getter
    def clients(self) -> 'outputs.GetJobJobSettingsSettingsTaskForEachTaskTaskNewClusterWorkloadTypeClientsResult':
        return pulumi.get(self, "clients")


@pulumi.output_type
class GetJobJobSettingsSettingsTaskForEachTaskTaskNewClusterWorkloadTypeClientsResult(dict):
    def __init__(__self__, *,
                 jobs: Optional[bool] = None,
                 notebooks: Optional[bool] = None):
        if jobs is not None:
            pulumi.set(__self__, "jobs", jobs)
        if notebooks is not None:
            pulumi.set(__self__, "notebooks", notebooks)

    @property
    @pulumi.getter
    def jobs(self) -> Optional[bool]:
        return pulumi.get(self, "jobs")

    @property
    @pulumi.getter
    def notebooks(self) -> Optional[bool]:
        return pulumi.get(self, "notebooks")


@pulumi.output_type
class GetJobJobSettingsSettingsTaskForEachTaskTaskNotebookTaskResult(dict):
    def __init__(__self__, *,
                 notebook_path: str,
                 base_parameters: Optional[Mapping[str, Any]] = None,
                 source: Optional[str] = None):
        pulumi.set(__self__, "notebook_path", notebook_path)
        if base_parameters is not None:
            pulumi.set(__self__, "base_parameters", base_parameters)
        if source is not None:
            pulumi.set(__self__, "source", source)

    @property
    @pulumi.getter(name="notebookPath")
    def notebook_path(self) -> str:
        return pulumi.get(self, "notebook_path")

    @property
    @pulumi.getter(name="baseParameters")
    def base_parameters(self) -> Optional[Mapping[str, Any]]:
        return pulumi.get(self, "base_parameters")

    @property
    @pulumi.getter
    def source(self) -> Optional[str]:
        return pulumi.get(self, "source")


@pulumi.output_type
class GetJobJobSettingsSettingsTaskForEachTaskTaskNotificationSettingsResult(dict):
    def __init__(__self__, *,
                 alert_on_last_attempt: Optional[bool] = None,
                 no_alert_for_canceled_runs: Optional[bool] = None,
                 no_alert_for_skipped_runs: Optional[bool] = None):
        if alert_on_last_attempt is not None:
            pulumi.set(__self__, "alert_on_last_attempt", alert_on_last_attempt)
        if no_alert_for_canceled_runs is not None:
            pulumi.set(__self__, "no_alert_for_canceled_runs", no_alert_for_canceled_runs)
        if no_alert_for_skipped_runs is not None:
            pulumi.set(__self__, "no_alert_for_skipped_runs", no_alert_for_skipped_runs)

    @property
    @pulumi.getter(name="alertOnLastAttempt")
    def alert_on_last_attempt(self) -> Optional[bool]:
        return pulumi.get(self, "alert_on_last_attempt")

    @property
    @pulumi.getter(name="noAlertForCanceledRuns")
    def no_alert_for_canceled_runs(self) -> Optional[bool]:
        return pulumi.get(self, "no_alert_for_canceled_runs")

    @property
    @pulumi.getter(name="noAlertForSkippedRuns")
    def no_alert_for_skipped_runs(self) -> Optional[bool]:
        return pulumi.get(self, "no_alert_for_skipped_runs")


@pulumi.output_type
class GetJobJobSettingsSettingsTaskForEachTaskTaskPipelineTaskResult(dict):
    def __init__(__self__, *,
                 pipeline_id: str,
                 full_refresh: Optional[bool] = None):
        pulumi.set(__self__, "pipeline_id", pipeline_id)
        if full_refresh is not None:
            pulumi.set(__self__, "full_refresh", full_refresh)

    @property
    @pulumi.getter(name="pipelineId")
    def pipeline_id(self) -> str:
        return pulumi.get(self, "pipeline_id")

    @property
    @pulumi.getter(name="fullRefresh")
    def full_refresh(self) -> Optional[bool]:
        return pulumi.get(self, "full_refresh")


@pulumi.output_type
class GetJobJobSettingsSettingsTaskForEachTaskTaskPythonWheelTaskResult(dict):
    def __init__(__self__, *,
                 entry_point: Optional[str] = None,
                 named_parameters: Optional[Mapping[str, Any]] = None,
                 package_name: Optional[str] = None,
                 parameters: Optional[Sequence[str]] = None):
        if entry_point is not None:
            pulumi.set(__self__, "entry_point", entry_point)
        if named_parameters is not None:
            pulumi.set(__self__, "named_parameters", named_parameters)
        if package_name is not None:
            pulumi.set(__self__, "package_name", package_name)
        if parameters is not None:
            pulumi.set(__self__, "parameters", parameters)

    @property
    @pulumi.getter(name="entryPoint")
    def entry_point(self) -> Optional[str]:
        return pulumi.get(self, "entry_point")

    @property
    @pulumi.getter(name="namedParameters")
    def named_parameters(self) -> Optional[Mapping[str, Any]]:
        return pulumi.get(self, "named_parameters")

    @property
    @pulumi.getter(name="packageName")
    def package_name(self) -> Optional[str]:
        return pulumi.get(self, "package_name")

    @property
    @pulumi.getter
    def parameters(self) -> Optional[Sequence[str]]:
        return pulumi.get(self, "parameters")


@pulumi.output_type
class GetJobJobSettingsSettingsTaskForEachTaskTaskRunJobTaskResult(dict):
    def __init__(__self__, *,
                 job_id: int,
                 job_parameters: Optional[Mapping[str, Any]] = None):
        pulumi.set(__self__, "job_id", job_id)
        if job_parameters is not None:
            pulumi.set(__self__, "job_parameters", job_parameters)

    @property
    @pulumi.getter(name="jobId")
    def job_id(self) -> int:
        return pulumi.get(self, "job_id")

    @property
    @pulumi.getter(name="jobParameters")
    def job_parameters(self) -> Optional[Mapping[str, Any]]:
        return pulumi.get(self, "job_parameters")


@pulumi.output_type
class GetJobJobSettingsSettingsTaskForEachTaskTaskSparkJarTaskResult(dict):
    def __init__(__self__, *,
                 jar_uri: Optional[str] = None,
                 main_class_name: Optional[str] = None,
                 parameters: Optional[Sequence[str]] = None):
        if jar_uri is not None:
            pulumi.set(__self__, "jar_uri", jar_uri)
        if main_class_name is not None:
            pulumi.set(__self__, "main_class_name", main_class_name)
        if parameters is not None:
            pulumi.set(__self__, "parameters", parameters)

    @property
    @pulumi.getter(name="jarUri")
    def jar_uri(self) -> Optional[str]:
        return pulumi.get(self, "jar_uri")

    @property
    @pulumi.getter(name="mainClassName")
    def main_class_name(self) -> Optional[str]:
        return pulumi.get(self, "main_class_name")

    @property
    @pulumi.getter
    def parameters(self) -> Optional[Sequence[str]]:
        return pulumi.get(self, "parameters")


@pulumi.output_type
class GetJobJobSettingsSettingsTaskForEachTaskTaskSparkPythonTaskResult(dict):
    def __init__(__self__, *,
                 python_file: str,
                 parameters: Optional[Sequence[str]] = None,
                 source: Optional[str] = None):
        pulumi.set(__self__, "python_file", python_file)
        if parameters is not None:
            pulumi.set(__self__, "parameters", parameters)
        if source is not None:
            pulumi.set(__self__, "source", source)

    @property
    @pulumi.getter(name="pythonFile")
    def python_file(self) -> str:
        return pulumi.get(self, "python_file")

    @property
    @pulumi.getter
    def parameters(self) -> Optional[Sequence[str]]:
        return pulumi.get(self, "parameters")

    @property
    @pulumi.getter
    def source(self) -> Optional[str]:
        return pulumi.get(self, "source")


@pulumi.output_type
class GetJobJobSettingsSettingsTaskForEachTaskTaskSparkSubmitTaskResult(dict):
    def __init__(__self__, *,
                 parameters: Optional[Sequence[str]] = None):
        if parameters is not None:
            pulumi.set(__self__, "parameters", parameters)

    @property
    @pulumi.getter
    def parameters(self) -> Optional[Sequence[str]]:
        return pulumi.get(self, "parameters")


@pulumi.output_type
class GetJobJobSettingsSettingsTaskForEachTaskTaskSqlTaskResult(dict):
    def __init__(__self__, *,
                 alert: Optional['outputs.GetJobJobSettingsSettingsTaskForEachTaskTaskSqlTaskAlertResult'] = None,
                 dashboard: Optional['outputs.GetJobJobSettingsSettingsTaskForEachTaskTaskSqlTaskDashboardResult'] = None,
                 file: Optional['outputs.GetJobJobSettingsSettingsTaskForEachTaskTaskSqlTaskFileResult'] = None,
                 parameters: Optional[Mapping[str, Any]] = None,
                 query: Optional['outputs.GetJobJobSettingsSettingsTaskForEachTaskTaskSqlTaskQueryResult'] = None,
                 warehouse_id: Optional[str] = None):
        if alert is not None:
            pulumi.set(__self__, "alert", alert)
        if dashboard is not None:
            pulumi.set(__self__, "dashboard", dashboard)
        if file is not None:
            pulumi.set(__self__, "file", file)
        if parameters is not None:
            pulumi.set(__self__, "parameters", parameters)
        if query is not None:
            pulumi.set(__self__, "query", query)
        if warehouse_id is not None:
            pulumi.set(__self__, "warehouse_id", warehouse_id)

    @property
    @pulumi.getter
    def alert(self) -> Optional['outputs.GetJobJobSettingsSettingsTaskForEachTaskTaskSqlTaskAlertResult']:
        return pulumi.get(self, "alert")

    @property
    @pulumi.getter
    def dashboard(self) -> Optional['outputs.GetJobJobSettingsSettingsTaskForEachTaskTaskSqlTaskDashboardResult']:
        return pulumi.get(self, "dashboard")

    @property
    @pulumi.getter
    def file(self) -> Optional['outputs.GetJobJobSettingsSettingsTaskForEachTaskTaskSqlTaskFileResult']:
        return pulumi.get(self, "file")

    @property
    @pulumi.getter
    def parameters(self) -> Optional[Mapping[str, Any]]:
        return pulumi.get(self, "parameters")

    @property
    @pulumi.getter
    def query(self) -> Optional['outputs.GetJobJobSettingsSettingsTaskForEachTaskTaskSqlTaskQueryResult']:
        return pulumi.get(self, "query")

    @property
    @pulumi.getter(name="warehouseId")
    def warehouse_id(self) -> Optional[str]:
        return pulumi.get(self, "warehouse_id")


@pulumi.output_type
class GetJobJobSettingsSettingsTaskForEachTaskTaskSqlTaskAlertResult(dict):
    def __init__(__self__, *,
                 alert_id: str,
                 subscriptions: Sequence['outputs.GetJobJobSettingsSettingsTaskForEachTaskTaskSqlTaskAlertSubscriptionResult'],
                 pause_subscriptions: Optional[bool] = None):
        pulumi.set(__self__, "alert_id", alert_id)
        pulumi.set(__self__, "subscriptions", subscriptions)
        if pause_subscriptions is not None:
            pulumi.set(__self__, "pause_subscriptions", pause_subscriptions)

    @property
    @pulumi.getter(name="alertId")
    def alert_id(self) -> str:
        return pulumi.get(self, "alert_id")

    @property
    @pulumi.getter
    def subscriptions(self) -> Sequence['outputs.GetJobJobSettingsSettingsTaskForEachTaskTaskSqlTaskAlertSubscriptionResult']:
        return pulumi.get(self, "subscriptions")

    @property
    @pulumi.getter(name="pauseSubscriptions")
    def pause_subscriptions(self) -> Optional[bool]:
        return pulumi.get(self, "pause_subscriptions")


@pulumi.output_type
class GetJobJobSettingsSettingsTaskForEachTaskTaskSqlTaskAlertSubscriptionResult(dict):
    def __init__(__self__, *,
                 destination_id: Optional[str] = None,
                 user_name: Optional[str] = None):
        if destination_id is not None:
            pulumi.set(__self__, "destination_id", destination_id)
        if user_name is not None:
            pulumi.set(__self__, "user_name", user_name)

    @property
    @pulumi.getter(name="destinationId")
    def destination_id(self) -> Optional[str]:
        return pulumi.get(self, "destination_id")

    @property
    @pulumi.getter(name="userName")
    def user_name(self) -> Optional[str]:
        return pulumi.get(self, "user_name")


@pulumi.output_type
class GetJobJobSettingsSettingsTaskForEachTaskTaskSqlTaskDashboardResult(dict):
    def __init__(__self__, *,
                 dashboard_id: str,
                 custom_subject: Optional[str] = None,
                 pause_subscriptions: Optional[bool] = None,
                 subscriptions: Optional[Sequence['outputs.GetJobJobSettingsSettingsTaskForEachTaskTaskSqlTaskDashboardSubscriptionResult']] = None):
        pulumi.set(__self__, "dashboard_id", dashboard_id)
        if custom_subject is not None:
            pulumi.set(__self__, "custom_subject", custom_subject)
        if pause_subscriptions is not None:
            pulumi.set(__self__, "pause_subscriptions", pause_subscriptions)
        if subscriptions is not None:
            pulumi.set(__self__, "subscriptions", subscriptions)

    @property
    @pulumi.getter(name="dashboardId")
    def dashboard_id(self) -> str:
        return pulumi.get(self, "dashboard_id")

    @property
    @pulumi.getter(name="customSubject")
    def custom_subject(self) -> Optional[str]:
        return pulumi.get(self, "custom_subject")

    @property
    @pulumi.getter(name="pauseSubscriptions")
    def pause_subscriptions(self) -> Optional[bool]:
        return pulumi.get(self, "pause_subscriptions")

    @property
    @pulumi.getter
    def subscriptions(self) -> Optional[Sequence['outputs.GetJobJobSettingsSettingsTaskForEachTaskTaskSqlTaskDashboardSubscriptionResult']]:
        return pulumi.get(self, "subscriptions")


@pulumi.output_type
class GetJobJobSettingsSettingsTaskForEachTaskTaskSqlTaskDashboardSubscriptionResult(dict):
    def __init__(__self__, *,
                 destination_id: Optional[str] = None,
                 user_name: Optional[str] = None):
        if destination_id is not None:
            pulumi.set(__self__, "destination_id", destination_id)
        if user_name is not None:
            pulumi.set(__self__, "user_name", user_name)

    @property
    @pulumi.getter(name="destinationId")
    def destination_id(self) -> Optional[str]:
        return pulumi.get(self, "destination_id")

    @property
    @pulumi.getter(name="userName")
    def user_name(self) -> Optional[str]:
        return pulumi.get(self, "user_name")


@pulumi.output_type
class GetJobJobSettingsSettingsTaskForEachTaskTaskSqlTaskFileResult(dict):
    def __init__(__self__, *,
                 path: str,
                 source: Optional[str] = None):
        pulumi.set(__self__, "path", path)
        if source is not None:
            pulumi.set(__self__, "source", source)

    @property
    @pulumi.getter
    def path(self) -> str:
        return pulumi.get(self, "path")

    @property
    @pulumi.getter
    def source(self) -> Optional[str]:
        return pulumi.get(self, "source")


@pulumi.output_type
class GetJobJobSettingsSettingsTaskForEachTaskTaskSqlTaskQueryResult(dict):
    def __init__(__self__, *,
                 query_id: str):
        pulumi.set(__self__, "query_id", query_id)

    @property
    @pulumi.getter(name="queryId")
    def query_id(self) -> str:
        return pulumi.get(self, "query_id")


@pulumi.output_type
class GetJobJobSettingsSettingsTaskForEachTaskTaskWebhookNotificationsResult(dict):
    def __init__(__self__, *,
                 on_duration_warning_threshold_exceededs: Optional[Sequence['outputs.GetJobJobSettingsSettingsTaskForEachTaskTaskWebhookNotificationsOnDurationWarningThresholdExceededResult']] = None,
                 on_failures: Optional[Sequence['outputs.GetJobJobSettingsSettingsTaskForEachTaskTaskWebhookNotificationsOnFailureResult']] = None,
                 on_starts: Optional[Sequence['outputs.GetJobJobSettingsSettingsTaskForEachTaskTaskWebhookNotificationsOnStartResult']] = None,
                 on_successes: Optional[Sequence['outputs.GetJobJobSettingsSettingsTaskForEachTaskTaskWebhookNotificationsOnSuccessResult']] = None):
        if on_duration_warning_threshold_exceededs is not None:
            pulumi.set(__self__, "on_duration_warning_threshold_exceededs", on_duration_warning_threshold_exceededs)
        if on_failures is not None:
            pulumi.set(__self__, "on_failures", on_failures)
        if on_starts is not None:
            pulumi.set(__self__, "on_starts", on_starts)
        if on_successes is not None:
            pulumi.set(__self__, "on_successes", on_successes)

    @property
    @pulumi.getter(name="onDurationWarningThresholdExceededs")
    def on_duration_warning_threshold_exceededs(self) -> Optional[Sequence['outputs.GetJobJobSettingsSettingsTaskForEachTaskTaskWebhookNotificationsOnDurationWarningThresholdExceededResult']]:
        return pulumi.get(self, "on_duration_warning_threshold_exceededs")

    @property
    @pulumi.getter(name="onFailures")
    def on_failures(self) -> Optional[Sequence['outputs.GetJobJobSettingsSettingsTaskForEachTaskTaskWebhookNotificationsOnFailureResult']]:
        return pulumi.get(self, "on_failures")

    @property
    @pulumi.getter(name="onStarts")
    def on_starts(self) -> Optional[Sequence['outputs.GetJobJobSettingsSettingsTaskForEachTaskTaskWebhookNotificationsOnStartResult']]:
        return pulumi.get(self, "on_starts")

    @property
    @pulumi.getter(name="onSuccesses")
    def on_successes(self) -> Optional[Sequence['outputs.GetJobJobSettingsSettingsTaskForEachTaskTaskWebhookNotificationsOnSuccessResult']]:
        return pulumi.get(self, "on_successes")


@pulumi.output_type
class GetJobJobSettingsSettingsTaskForEachTaskTaskWebhookNotificationsOnDurationWarningThresholdExceededResult(dict):
    def __init__(__self__, *,
                 id: Optional[str] = None):
        """
        :param str id: the id of Job if the resource was matched by name.
        """
        if id is not None:
            pulumi.set(__self__, "id", id)

    @property
    @pulumi.getter
    def id(self) -> Optional[str]:
        """
        the id of Job if the resource was matched by name.
        """
        return pulumi.get(self, "id")


@pulumi.output_type
class GetJobJobSettingsSettingsTaskForEachTaskTaskWebhookNotificationsOnFailureResult(dict):
    def __init__(__self__, *,
                 id: Optional[str] = None):
        """
        :param str id: the id of Job if the resource was matched by name.
        """
        if id is not None:
            pulumi.set(__self__, "id", id)

    @property
    @pulumi.getter
    def id(self) -> Optional[str]:
        """
        the id of Job if the resource was matched by name.
        """
        return pulumi.get(self, "id")


@pulumi.output_type
class GetJobJobSettingsSettingsTaskForEachTaskTaskWebhookNotificationsOnStartResult(dict):
    def __init__(__self__, *,
                 id: Optional[str] = None):
        """
        :param str id: the id of Job if the resource was matched by name.
        """
        if id is not None:
            pulumi.set(__self__, "id", id)

    @property
    @pulumi.getter
    def id(self) -> Optional[str]:
        """
        the id of Job if the resource was matched by name.
        """
        return pulumi.get(self, "id")


@pulumi.output_type
class GetJobJobSettingsSettingsTaskForEachTaskTaskWebhookNotificationsOnSuccessResult(dict):
    def __init__(__self__, *,
                 id: Optional[str] = None):
        """
        :param str id: the id of Job if the resource was matched by name.
        """
        if id is not None:
            pulumi.set(__self__, "id", id)

    @property
    @pulumi.getter
    def id(self) -> Optional[str]:
        """
        the id of Job if the resource was matched by name.
        """
        return pulumi.get(self, "id")


@pulumi.output_type
class GetJobJobSettingsSettingsTaskHealthResult(dict):
    def __init__(__self__, *,
                 rules: Sequence['outputs.GetJobJobSettingsSettingsTaskHealthRuleResult']):
        pulumi.set(__self__, "rules", rules)

    @property
    @pulumi.getter
    def rules(self) -> Sequence['outputs.GetJobJobSettingsSettingsTaskHealthRuleResult']:
        return pulumi.get(self, "rules")


@pulumi.output_type
class GetJobJobSettingsSettingsTaskHealthRuleResult(dict):
    def __init__(__self__, *,
                 metric: Optional[str] = None,
                 op: Optional[str] = None,
                 value: Optional[int] = None):
        if metric is not None:
            pulumi.set(__self__, "metric", metric)
        if op is not None:
            pulumi.set(__self__, "op", op)
        if value is not None:
            pulumi.set(__self__, "value", value)

    @property
    @pulumi.getter
    def metric(self) -> Optional[str]:
        return pulumi.get(self, "metric")

    @property
    @pulumi.getter
    def op(self) -> Optional[str]:
        return pulumi.get(self, "op")

    @property
    @pulumi.getter
    def value(self) -> Optional[int]:
        return pulumi.get(self, "value")


@pulumi.output_type
class GetJobJobSettingsSettingsTaskLibraryResult(dict):
    def __init__(__self__, *,
                 cran: Optional['outputs.GetJobJobSettingsSettingsTaskLibraryCranResult'] = None,
                 egg: Optional[str] = None,
                 jar: Optional[str] = None,
                 maven: Optional['outputs.GetJobJobSettingsSettingsTaskLibraryMavenResult'] = None,
                 pypi: Optional['outputs.GetJobJobSettingsSettingsTaskLibraryPypiResult'] = None,
                 whl: Optional[str] = None):
        if cran is not None:
            pulumi.set(__self__, "cran", cran)
        if egg is not None:
            pulumi.set(__self__, "egg", egg)
        if jar is not None:
            pulumi.set(__self__, "jar", jar)
        if maven is not None:
            pulumi.set(__self__, "maven", maven)
        if pypi is not None:
            pulumi.set(__self__, "pypi", pypi)
        if whl is not None:
            pulumi.set(__self__, "whl", whl)

    @property
    @pulumi.getter
    def cran(self) -> Optional['outputs.GetJobJobSettingsSettingsTaskLibraryCranResult']:
        return pulumi.get(self, "cran")

    @property
    @pulumi.getter
    def egg(self) -> Optional[str]:
        return pulumi.get(self, "egg")

    @property
    @pulumi.getter
    def jar(self) -> Optional[str]:
        return pulumi.get(self, "jar")

    @property
    @pulumi.getter
    def maven(self) -> Optional['outputs.GetJobJobSettingsSettingsTaskLibraryMavenResult']:
        return pulumi.get(self, "maven")

    @property
    @pulumi.getter
    def pypi(self) -> Optional['outputs.GetJobJobSettingsSettingsTaskLibraryPypiResult']:
        return pulumi.get(self, "pypi")

    @property
    @pulumi.getter
    def whl(self) -> Optional[str]:
        return pulumi.get(self, "whl")


@pulumi.output_type
class GetJobJobSettingsSettingsTaskLibraryCranResult(dict):
    def __init__(__self__, *,
                 package: str,
                 repo: Optional[str] = None):
        pulumi.set(__self__, "package", package)
        if repo is not None:
            pulumi.set(__self__, "repo", repo)

    @property
    @pulumi.getter
    def package(self) -> str:
        return pulumi.get(self, "package")

    @property
    @pulumi.getter
    def repo(self) -> Optional[str]:
        return pulumi.get(self, "repo")


@pulumi.output_type
class GetJobJobSettingsSettingsTaskLibraryMavenResult(dict):
    def __init__(__self__, *,
                 coordinates: str,
                 exclusions: Optional[Sequence[str]] = None,
                 repo: Optional[str] = None):
        pulumi.set(__self__, "coordinates", coordinates)
        if exclusions is not None:
            pulumi.set(__self__, "exclusions", exclusions)
        if repo is not None:
            pulumi.set(__self__, "repo", repo)

    @property
    @pulumi.getter
    def coordinates(self) -> str:
        return pulumi.get(self, "coordinates")

    @property
    @pulumi.getter
    def exclusions(self) -> Optional[Sequence[str]]:
        return pulumi.get(self, "exclusions")

    @property
    @pulumi.getter
    def repo(self) -> Optional[str]:
        return pulumi.get(self, "repo")


@pulumi.output_type
class GetJobJobSettingsSettingsTaskLibraryPypiResult(dict):
    def __init__(__self__, *,
                 package: str,
                 repo: Optional[str] = None):
        pulumi.set(__self__, "package", package)
        if repo is not None:
            pulumi.set(__self__, "repo", repo)

    @property
    @pulumi.getter
    def package(self) -> str:
        return pulumi.get(self, "package")

    @property
    @pulumi.getter
    def repo(self) -> Optional[str]:
        return pulumi.get(self, "repo")


@pulumi.output_type
class GetJobJobSettingsSettingsTaskNewClusterResult(dict):
    def __init__(__self__, *,
                 driver_instance_pool_id: str,
                 driver_node_type_id: str,
                 enable_elastic_disk: bool,
                 enable_local_disk_encryption: bool,
                 node_type_id: str,
                 num_workers: int,
                 spark_version: str,
                 apply_policy_default_values: Optional[bool] = None,
                 autoscale: Optional['outputs.GetJobJobSettingsSettingsTaskNewClusterAutoscaleResult'] = None,
                 autotermination_minutes: Optional[int] = None,
                 aws_attributes: Optional['outputs.GetJobJobSettingsSettingsTaskNewClusterAwsAttributesResult'] = None,
                 azure_attributes: Optional['outputs.GetJobJobSettingsSettingsTaskNewClusterAzureAttributesResult'] = None,
                 cluster_id: Optional[str] = None,
                 cluster_log_conf: Optional['outputs.GetJobJobSettingsSettingsTaskNewClusterClusterLogConfResult'] = None,
                 cluster_mount_infos: Optional[Sequence['outputs.GetJobJobSettingsSettingsTaskNewClusterClusterMountInfoResult']] = None,
                 cluster_name: Optional[str] = None,
                 custom_tags: Optional[Mapping[str, Any]] = None,
                 data_security_mode: Optional[str] = None,
                 docker_image: Optional['outputs.GetJobJobSettingsSettingsTaskNewClusterDockerImageResult'] = None,
                 gcp_attributes: Optional['outputs.GetJobJobSettingsSettingsTaskNewClusterGcpAttributesResult'] = None,
                 idempotency_token: Optional[str] = None,
                 init_scripts: Optional[Sequence['outputs.GetJobJobSettingsSettingsTaskNewClusterInitScriptResult']] = None,
                 instance_pool_id: Optional[str] = None,
                 policy_id: Optional[str] = None,
                 runtime_engine: Optional[str] = None,
                 single_user_name: Optional[str] = None,
                 spark_conf: Optional[Mapping[str, Any]] = None,
                 spark_env_vars: Optional[Mapping[str, Any]] = None,
                 ssh_public_keys: Optional[Sequence[str]] = None,
                 workload_type: Optional['outputs.GetJobJobSettingsSettingsTaskNewClusterWorkloadTypeResult'] = None):
        pulumi.set(__self__, "driver_instance_pool_id", driver_instance_pool_id)
        pulumi.set(__self__, "driver_node_type_id", driver_node_type_id)
        pulumi.set(__self__, "enable_elastic_disk", enable_elastic_disk)
        pulumi.set(__self__, "enable_local_disk_encryption", enable_local_disk_encryption)
        pulumi.set(__self__, "node_type_id", node_type_id)
        pulumi.set(__self__, "num_workers", num_workers)
        pulumi.set(__self__, "spark_version", spark_version)
        if apply_policy_default_values is not None:
            pulumi.set(__self__, "apply_policy_default_values", apply_policy_default_values)
        if autoscale is not None:
            pulumi.set(__self__, "autoscale", autoscale)
        if autotermination_minutes is not None:
            pulumi.set(__self__, "autotermination_minutes", autotermination_minutes)
        if aws_attributes is not None:
            pulumi.set(__self__, "aws_attributes", aws_attributes)
        if azure_attributes is not None:
            pulumi.set(__self__, "azure_attributes", azure_attributes)
        if cluster_id is not None:
            pulumi.set(__self__, "cluster_id", cluster_id)
        if cluster_log_conf is not None:
            pulumi.set(__self__, "cluster_log_conf", cluster_log_conf)
        if cluster_mount_infos is not None:
            pulumi.set(__self__, "cluster_mount_infos", cluster_mount_infos)
        if cluster_name is not None:
            pulumi.set(__self__, "cluster_name", cluster_name)
        if custom_tags is not None:
            pulumi.set(__self__, "custom_tags", custom_tags)
        if data_security_mode is not None:
            pulumi.set(__self__, "data_security_mode", data_security_mode)
        if docker_image is not None:
            pulumi.set(__self__, "docker_image", docker_image)
        if gcp_attributes is not None:
            pulumi.set(__self__, "gcp_attributes", gcp_attributes)
        if idempotency_token is not None:
            pulumi.set(__self__, "idempotency_token", idempotency_token)
        if init_scripts is not None:
            pulumi.set(__self__, "init_scripts", init_scripts)
        if instance_pool_id is not None:
            pulumi.set(__self__, "instance_pool_id", instance_pool_id)
        if policy_id is not None:
            pulumi.set(__self__, "policy_id", policy_id)
        if runtime_engine is not None:
            pulumi.set(__self__, "runtime_engine", runtime_engine)
        if single_user_name is not None:
            pulumi.set(__self__, "single_user_name", single_user_name)
        if spark_conf is not None:
            pulumi.set(__self__, "spark_conf", spark_conf)
        if spark_env_vars is not None:
            pulumi.set(__self__, "spark_env_vars", spark_env_vars)
        if ssh_public_keys is not None:
            pulumi.set(__self__, "ssh_public_keys", ssh_public_keys)
        if workload_type is not None:
            pulumi.set(__self__, "workload_type", workload_type)

    @property
    @pulumi.getter(name="driverInstancePoolId")
    def driver_instance_pool_id(self) -> str:
        return pulumi.get(self, "driver_instance_pool_id")

    @property
    @pulumi.getter(name="driverNodeTypeId")
    def driver_node_type_id(self) -> str:
        return pulumi.get(self, "driver_node_type_id")

    @property
    @pulumi.getter(name="enableElasticDisk")
    def enable_elastic_disk(self) -> bool:
        return pulumi.get(self, "enable_elastic_disk")

    @property
    @pulumi.getter(name="enableLocalDiskEncryption")
    def enable_local_disk_encryption(self) -> bool:
        return pulumi.get(self, "enable_local_disk_encryption")

    @property
    @pulumi.getter(name="nodeTypeId")
    def node_type_id(self) -> str:
        return pulumi.get(self, "node_type_id")

    @property
    @pulumi.getter(name="numWorkers")
    def num_workers(self) -> int:
        return pulumi.get(self, "num_workers")

    @property
    @pulumi.getter(name="sparkVersion")
    def spark_version(self) -> str:
        return pulumi.get(self, "spark_version")

    @property
    @pulumi.getter(name="applyPolicyDefaultValues")
    def apply_policy_default_values(self) -> Optional[bool]:
        return pulumi.get(self, "apply_policy_default_values")

    @property
    @pulumi.getter
    def autoscale(self) -> Optional['outputs.GetJobJobSettingsSettingsTaskNewClusterAutoscaleResult']:
        return pulumi.get(self, "autoscale")

    @property
    @pulumi.getter(name="autoterminationMinutes")
    def autotermination_minutes(self) -> Optional[int]:
        return pulumi.get(self, "autotermination_minutes")

    @property
    @pulumi.getter(name="awsAttributes")
    def aws_attributes(self) -> Optional['outputs.GetJobJobSettingsSettingsTaskNewClusterAwsAttributesResult']:
        return pulumi.get(self, "aws_attributes")

    @property
    @pulumi.getter(name="azureAttributes")
    def azure_attributes(self) -> Optional['outputs.GetJobJobSettingsSettingsTaskNewClusterAzureAttributesResult']:
        return pulumi.get(self, "azure_attributes")

    @property
    @pulumi.getter(name="clusterId")
    def cluster_id(self) -> Optional[str]:
        return pulumi.get(self, "cluster_id")

    @property
    @pulumi.getter(name="clusterLogConf")
    def cluster_log_conf(self) -> Optional['outputs.GetJobJobSettingsSettingsTaskNewClusterClusterLogConfResult']:
        return pulumi.get(self, "cluster_log_conf")

    @property
    @pulumi.getter(name="clusterMountInfos")
    def cluster_mount_infos(self) -> Optional[Sequence['outputs.GetJobJobSettingsSettingsTaskNewClusterClusterMountInfoResult']]:
        return pulumi.get(self, "cluster_mount_infos")

    @property
    @pulumi.getter(name="clusterName")
    def cluster_name(self) -> Optional[str]:
        return pulumi.get(self, "cluster_name")

    @property
    @pulumi.getter(name="customTags")
    def custom_tags(self) -> Optional[Mapping[str, Any]]:
        return pulumi.get(self, "custom_tags")

    @property
    @pulumi.getter(name="dataSecurityMode")
    def data_security_mode(self) -> Optional[str]:
        return pulumi.get(self, "data_security_mode")

    @property
    @pulumi.getter(name="dockerImage")
    def docker_image(self) -> Optional['outputs.GetJobJobSettingsSettingsTaskNewClusterDockerImageResult']:
        return pulumi.get(self, "docker_image")

    @property
    @pulumi.getter(name="gcpAttributes")
    def gcp_attributes(self) -> Optional['outputs.GetJobJobSettingsSettingsTaskNewClusterGcpAttributesResult']:
        return pulumi.get(self, "gcp_attributes")

    @property
    @pulumi.getter(name="idempotencyToken")
    def idempotency_token(self) -> Optional[str]:
        return pulumi.get(self, "idempotency_token")

    @property
    @pulumi.getter(name="initScripts")
    def init_scripts(self) -> Optional[Sequence['outputs.GetJobJobSettingsSettingsTaskNewClusterInitScriptResult']]:
        return pulumi.get(self, "init_scripts")

    @property
    @pulumi.getter(name="instancePoolId")
    def instance_pool_id(self) -> Optional[str]:
        return pulumi.get(self, "instance_pool_id")

    @property
    @pulumi.getter(name="policyId")
    def policy_id(self) -> Optional[str]:
        return pulumi.get(self, "policy_id")

    @property
    @pulumi.getter(name="runtimeEngine")
    def runtime_engine(self) -> Optional[str]:
        return pulumi.get(self, "runtime_engine")

    @property
    @pulumi.getter(name="singleUserName")
    def single_user_name(self) -> Optional[str]:
        return pulumi.get(self, "single_user_name")

    @property
    @pulumi.getter(name="sparkConf")
    def spark_conf(self) -> Optional[Mapping[str, Any]]:
        return pulumi.get(self, "spark_conf")

    @property
    @pulumi.getter(name="sparkEnvVars")
    def spark_env_vars(self) -> Optional[Mapping[str, Any]]:
        return pulumi.get(self, "spark_env_vars")

    @property
    @pulumi.getter(name="sshPublicKeys")
    def ssh_public_keys(self) -> Optional[Sequence[str]]:
        return pulumi.get(self, "ssh_public_keys")

    @property
    @pulumi.getter(name="workloadType")
    def workload_type(self) -> Optional['outputs.GetJobJobSettingsSettingsTaskNewClusterWorkloadTypeResult']:
        return pulumi.get(self, "workload_type")


@pulumi.output_type
class GetJobJobSettingsSettingsTaskNewClusterAutoscaleResult(dict):
    def __init__(__self__, *,
                 max_workers: Optional[int] = None,
                 min_workers: Optional[int] = None):
        if max_workers is not None:
            pulumi.set(__self__, "max_workers", max_workers)
        if min_workers is not None:
            pulumi.set(__self__, "min_workers", min_workers)

    @property
    @pulumi.getter(name="maxWorkers")
    def max_workers(self) -> Optional[int]:
        return pulumi.get(self, "max_workers")

    @property
    @pulumi.getter(name="minWorkers")
    def min_workers(self) -> Optional[int]:
        return pulumi.get(self, "min_workers")


@pulumi.output_type
class GetJobJobSettingsSettingsTaskNewClusterAwsAttributesResult(dict):
    def __init__(__self__, *,
                 availability: Optional[str] = None,
                 ebs_volume_count: Optional[int] = None,
                 ebs_volume_size: Optional[int] = None,
                 ebs_volume_type: Optional[str] = None,
                 first_on_demand: Optional[int] = None,
                 instance_profile_arn: Optional[str] = None,
                 spot_bid_price_percent: Optional[int] = None,
                 zone_id: Optional[str] = None):
        if availability is not None:
            pulumi.set(__self__, "availability", availability)
        if ebs_volume_count is not None:
            pulumi.set(__self__, "ebs_volume_count", ebs_volume_count)
        if ebs_volume_size is not None:
            pulumi.set(__self__, "ebs_volume_size", ebs_volume_size)
        if ebs_volume_type is not None:
            pulumi.set(__self__, "ebs_volume_type", ebs_volume_type)
        if first_on_demand is not None:
            pulumi.set(__self__, "first_on_demand", first_on_demand)
        if instance_profile_arn is not None:
            pulumi.set(__self__, "instance_profile_arn", instance_profile_arn)
        if spot_bid_price_percent is not None:
            pulumi.set(__self__, "spot_bid_price_percent", spot_bid_price_percent)
        if zone_id is not None:
            pulumi.set(__self__, "zone_id", zone_id)

    @property
    @pulumi.getter
    def availability(self) -> Optional[str]:
        return pulumi.get(self, "availability")

    @property
    @pulumi.getter(name="ebsVolumeCount")
    def ebs_volume_count(self) -> Optional[int]:
        return pulumi.get(self, "ebs_volume_count")

    @property
    @pulumi.getter(name="ebsVolumeSize")
    def ebs_volume_size(self) -> Optional[int]:
        return pulumi.get(self, "ebs_volume_size")

    @property
    @pulumi.getter(name="ebsVolumeType")
    def ebs_volume_type(self) -> Optional[str]:
        return pulumi.get(self, "ebs_volume_type")

    @property
    @pulumi.getter(name="firstOnDemand")
    def first_on_demand(self) -> Optional[int]:
        return pulumi.get(self, "first_on_demand")

    @property
    @pulumi.getter(name="instanceProfileArn")
    def instance_profile_arn(self) -> Optional[str]:
        return pulumi.get(self, "instance_profile_arn")

    @property
    @pulumi.getter(name="spotBidPricePercent")
    def spot_bid_price_percent(self) -> Optional[int]:
        return pulumi.get(self, "spot_bid_price_percent")

    @property
    @pulumi.getter(name="zoneId")
    def zone_id(self) -> Optional[str]:
        return pulumi.get(self, "zone_id")


@pulumi.output_type
class GetJobJobSettingsSettingsTaskNewClusterAzureAttributesResult(dict):
    def __init__(__self__, *,
                 availability: Optional[str] = None,
                 first_on_demand: Optional[int] = None,
                 spot_bid_max_price: Optional[float] = None):
        if availability is not None:
            pulumi.set(__self__, "availability", availability)
        if first_on_demand is not None:
            pulumi.set(__self__, "first_on_demand", first_on_demand)
        if spot_bid_max_price is not None:
            pulumi.set(__self__, "spot_bid_max_price", spot_bid_max_price)

    @property
    @pulumi.getter
    def availability(self) -> Optional[str]:
        return pulumi.get(self, "availability")

    @property
    @pulumi.getter(name="firstOnDemand")
    def first_on_demand(self) -> Optional[int]:
        return pulumi.get(self, "first_on_demand")

    @property
    @pulumi.getter(name="spotBidMaxPrice")
    def spot_bid_max_price(self) -> Optional[float]:
        return pulumi.get(self, "spot_bid_max_price")


@pulumi.output_type
class GetJobJobSettingsSettingsTaskNewClusterClusterLogConfResult(dict):
    def __init__(__self__, *,
                 dbfs: Optional['outputs.GetJobJobSettingsSettingsTaskNewClusterClusterLogConfDbfsResult'] = None,
                 s3: Optional['outputs.GetJobJobSettingsSettingsTaskNewClusterClusterLogConfS3Result'] = None):
        if dbfs is not None:
            pulumi.set(__self__, "dbfs", dbfs)
        if s3 is not None:
            pulumi.set(__self__, "s3", s3)

    @property
    @pulumi.getter
    def dbfs(self) -> Optional['outputs.GetJobJobSettingsSettingsTaskNewClusterClusterLogConfDbfsResult']:
        return pulumi.get(self, "dbfs")

    @property
    @pulumi.getter
    def s3(self) -> Optional['outputs.GetJobJobSettingsSettingsTaskNewClusterClusterLogConfS3Result']:
        return pulumi.get(self, "s3")


@pulumi.output_type
class GetJobJobSettingsSettingsTaskNewClusterClusterLogConfDbfsResult(dict):
    def __init__(__self__, *,
                 destination: str):
        pulumi.set(__self__, "destination", destination)

    @property
    @pulumi.getter
    def destination(self) -> str:
        return pulumi.get(self, "destination")


@pulumi.output_type
class GetJobJobSettingsSettingsTaskNewClusterClusterLogConfS3Result(dict):
    def __init__(__self__, *,
                 destination: str,
                 canned_acl: Optional[str] = None,
                 enable_encryption: Optional[bool] = None,
                 encryption_type: Optional[str] = None,
                 endpoint: Optional[str] = None,
                 kms_key: Optional[str] = None,
                 region: Optional[str] = None):
        pulumi.set(__self__, "destination", destination)
        if canned_acl is not None:
            pulumi.set(__self__, "canned_acl", canned_acl)
        if enable_encryption is not None:
            pulumi.set(__self__, "enable_encryption", enable_encryption)
        if encryption_type is not None:
            pulumi.set(__self__, "encryption_type", encryption_type)
        if endpoint is not None:
            pulumi.set(__self__, "endpoint", endpoint)
        if kms_key is not None:
            pulumi.set(__self__, "kms_key", kms_key)
        if region is not None:
            pulumi.set(__self__, "region", region)

    @property
    @pulumi.getter
    def destination(self) -> str:
        return pulumi.get(self, "destination")

    @property
    @pulumi.getter(name="cannedAcl")
    def canned_acl(self) -> Optional[str]:
        return pulumi.get(self, "canned_acl")

    @property
    @pulumi.getter(name="enableEncryption")
    def enable_encryption(self) -> Optional[bool]:
        return pulumi.get(self, "enable_encryption")

    @property
    @pulumi.getter(name="encryptionType")
    def encryption_type(self) -> Optional[str]:
        return pulumi.get(self, "encryption_type")

    @property
    @pulumi.getter
    def endpoint(self) -> Optional[str]:
        return pulumi.get(self, "endpoint")

    @property
    @pulumi.getter(name="kmsKey")
    def kms_key(self) -> Optional[str]:
        return pulumi.get(self, "kms_key")

    @property
    @pulumi.getter
    def region(self) -> Optional[str]:
        return pulumi.get(self, "region")


@pulumi.output_type
class GetJobJobSettingsSettingsTaskNewClusterClusterMountInfoResult(dict):
    def __init__(__self__, *,
                 local_mount_dir_path: str,
                 network_filesystem_info: 'outputs.GetJobJobSettingsSettingsTaskNewClusterClusterMountInfoNetworkFilesystemInfoResult',
                 remote_mount_dir_path: Optional[str] = None):
        pulumi.set(__self__, "local_mount_dir_path", local_mount_dir_path)
        pulumi.set(__self__, "network_filesystem_info", network_filesystem_info)
        if remote_mount_dir_path is not None:
            pulumi.set(__self__, "remote_mount_dir_path", remote_mount_dir_path)

    @property
    @pulumi.getter(name="localMountDirPath")
    def local_mount_dir_path(self) -> str:
        return pulumi.get(self, "local_mount_dir_path")

    @property
    @pulumi.getter(name="networkFilesystemInfo")
    def network_filesystem_info(self) -> 'outputs.GetJobJobSettingsSettingsTaskNewClusterClusterMountInfoNetworkFilesystemInfoResult':
        return pulumi.get(self, "network_filesystem_info")

    @property
    @pulumi.getter(name="remoteMountDirPath")
    def remote_mount_dir_path(self) -> Optional[str]:
        return pulumi.get(self, "remote_mount_dir_path")


@pulumi.output_type
class GetJobJobSettingsSettingsTaskNewClusterClusterMountInfoNetworkFilesystemInfoResult(dict):
    def __init__(__self__, *,
                 server_address: str,
                 mount_options: Optional[str] = None):
        pulumi.set(__self__, "server_address", server_address)
        if mount_options is not None:
            pulumi.set(__self__, "mount_options", mount_options)

    @property
    @pulumi.getter(name="serverAddress")
    def server_address(self) -> str:
        return pulumi.get(self, "server_address")

    @property
    @pulumi.getter(name="mountOptions")
    def mount_options(self) -> Optional[str]:
        return pulumi.get(self, "mount_options")


@pulumi.output_type
class GetJobJobSettingsSettingsTaskNewClusterDockerImageResult(dict):
    def __init__(__self__, *,
                 url: str,
                 basic_auth: Optional['outputs.GetJobJobSettingsSettingsTaskNewClusterDockerImageBasicAuthResult'] = None):
        pulumi.set(__self__, "url", url)
        if basic_auth is not None:
            pulumi.set(__self__, "basic_auth", basic_auth)

    @property
    @pulumi.getter
    def url(self) -> str:
        return pulumi.get(self, "url")

    @property
    @pulumi.getter(name="basicAuth")
    def basic_auth(self) -> Optional['outputs.GetJobJobSettingsSettingsTaskNewClusterDockerImageBasicAuthResult']:
        return pulumi.get(self, "basic_auth")


@pulumi.output_type
class GetJobJobSettingsSettingsTaskNewClusterDockerImageBasicAuthResult(dict):
    def __init__(__self__, *,
                 password: str,
                 username: str):
        pulumi.set(__self__, "password", password)
        pulumi.set(__self__, "username", username)

    @property
    @pulumi.getter
    def password(self) -> str:
        return pulumi.get(self, "password")

    @property
    @pulumi.getter
    def username(self) -> str:
        return pulumi.get(self, "username")


@pulumi.output_type
class GetJobJobSettingsSettingsTaskNewClusterGcpAttributesResult(dict):
    def __init__(__self__, *,
                 availability: Optional[str] = None,
                 boot_disk_size: Optional[int] = None,
                 google_service_account: Optional[str] = None,
                 local_ssd_count: Optional[int] = None,
                 use_preemptible_executors: Optional[bool] = None,
                 zone_id: Optional[str] = None):
        if availability is not None:
            pulumi.set(__self__, "availability", availability)
        if boot_disk_size is not None:
            pulumi.set(__self__, "boot_disk_size", boot_disk_size)
        if google_service_account is not None:
            pulumi.set(__self__, "google_service_account", google_service_account)
        if local_ssd_count is not None:
            pulumi.set(__self__, "local_ssd_count", local_ssd_count)
        if use_preemptible_executors is not None:
            pulumi.set(__self__, "use_preemptible_executors", use_preemptible_executors)
        if zone_id is not None:
            pulumi.set(__self__, "zone_id", zone_id)

    @property
    @pulumi.getter
    def availability(self) -> Optional[str]:
        return pulumi.get(self, "availability")

    @property
    @pulumi.getter(name="bootDiskSize")
    def boot_disk_size(self) -> Optional[int]:
        return pulumi.get(self, "boot_disk_size")

    @property
    @pulumi.getter(name="googleServiceAccount")
    def google_service_account(self) -> Optional[str]:
        return pulumi.get(self, "google_service_account")

    @property
    @pulumi.getter(name="localSsdCount")
    def local_ssd_count(self) -> Optional[int]:
        return pulumi.get(self, "local_ssd_count")

    @property
    @pulumi.getter(name="usePreemptibleExecutors")
    def use_preemptible_executors(self) -> Optional[bool]:
        return pulumi.get(self, "use_preemptible_executors")

    @property
    @pulumi.getter(name="zoneId")
    def zone_id(self) -> Optional[str]:
        return pulumi.get(self, "zone_id")


@pulumi.output_type
class GetJobJobSettingsSettingsTaskNewClusterInitScriptResult(dict):
    def __init__(__self__, *,
                 abfss: Optional['outputs.GetJobJobSettingsSettingsTaskNewClusterInitScriptAbfssResult'] = None,
                 dbfs: Optional['outputs.GetJobJobSettingsSettingsTaskNewClusterInitScriptDbfsResult'] = None,
                 file: Optional['outputs.GetJobJobSettingsSettingsTaskNewClusterInitScriptFileResult'] = None,
                 gcs: Optional['outputs.GetJobJobSettingsSettingsTaskNewClusterInitScriptGcsResult'] = None,
                 s3: Optional['outputs.GetJobJobSettingsSettingsTaskNewClusterInitScriptS3Result'] = None,
                 volumes: Optional['outputs.GetJobJobSettingsSettingsTaskNewClusterInitScriptVolumesResult'] = None,
                 workspace: Optional['outputs.GetJobJobSettingsSettingsTaskNewClusterInitScriptWorkspaceResult'] = None):
        if abfss is not None:
            pulumi.set(__self__, "abfss", abfss)
        if dbfs is not None:
            pulumi.set(__self__, "dbfs", dbfs)
        if file is not None:
            pulumi.set(__self__, "file", file)
        if gcs is not None:
            pulumi.set(__self__, "gcs", gcs)
        if s3 is not None:
            pulumi.set(__self__, "s3", s3)
        if volumes is not None:
            pulumi.set(__self__, "volumes", volumes)
        if workspace is not None:
            pulumi.set(__self__, "workspace", workspace)

    @property
    @pulumi.getter
    def abfss(self) -> Optional['outputs.GetJobJobSettingsSettingsTaskNewClusterInitScriptAbfssResult']:
        return pulumi.get(self, "abfss")

    @property
    @pulumi.getter
    def dbfs(self) -> Optional['outputs.GetJobJobSettingsSettingsTaskNewClusterInitScriptDbfsResult']:
        return pulumi.get(self, "dbfs")

    @property
    @pulumi.getter
    def file(self) -> Optional['outputs.GetJobJobSettingsSettingsTaskNewClusterInitScriptFileResult']:
        return pulumi.get(self, "file")

    @property
    @pulumi.getter
    def gcs(self) -> Optional['outputs.GetJobJobSettingsSettingsTaskNewClusterInitScriptGcsResult']:
        return pulumi.get(self, "gcs")

    @property
    @pulumi.getter
    def s3(self) -> Optional['outputs.GetJobJobSettingsSettingsTaskNewClusterInitScriptS3Result']:
        return pulumi.get(self, "s3")

    @property
    @pulumi.getter
    def volumes(self) -> Optional['outputs.GetJobJobSettingsSettingsTaskNewClusterInitScriptVolumesResult']:
        return pulumi.get(self, "volumes")

    @property
    @pulumi.getter
    def workspace(self) -> Optional['outputs.GetJobJobSettingsSettingsTaskNewClusterInitScriptWorkspaceResult']:
        return pulumi.get(self, "workspace")


@pulumi.output_type
class GetJobJobSettingsSettingsTaskNewClusterInitScriptAbfssResult(dict):
    def __init__(__self__, *,
                 destination: str):
        pulumi.set(__self__, "destination", destination)

    @property
    @pulumi.getter
    def destination(self) -> str:
        return pulumi.get(self, "destination")


@pulumi.output_type
class GetJobJobSettingsSettingsTaskNewClusterInitScriptDbfsResult(dict):
    def __init__(__self__, *,
                 destination: str):
        pulumi.set(__self__, "destination", destination)

    @property
    @pulumi.getter
    def destination(self) -> str:
        return pulumi.get(self, "destination")


@pulumi.output_type
class GetJobJobSettingsSettingsTaskNewClusterInitScriptFileResult(dict):
    def __init__(__self__, *,
                 destination: str):
        pulumi.set(__self__, "destination", destination)

    @property
    @pulumi.getter
    def destination(self) -> str:
        return pulumi.get(self, "destination")


@pulumi.output_type
class GetJobJobSettingsSettingsTaskNewClusterInitScriptGcsResult(dict):
    def __init__(__self__, *,
                 destination: str):
        pulumi.set(__self__, "destination", destination)

    @property
    @pulumi.getter
    def destination(self) -> str:
        return pulumi.get(self, "destination")


@pulumi.output_type
class GetJobJobSettingsSettingsTaskNewClusterInitScriptS3Result(dict):
    def __init__(__self__, *,
                 destination: str,
                 canned_acl: Optional[str] = None,
                 enable_encryption: Optional[bool] = None,
                 encryption_type: Optional[str] = None,
                 endpoint: Optional[str] = None,
                 kms_key: Optional[str] = None,
                 region: Optional[str] = None):
        pulumi.set(__self__, "destination", destination)
        if canned_acl is not None:
            pulumi.set(__self__, "canned_acl", canned_acl)
        if enable_encryption is not None:
            pulumi.set(__self__, "enable_encryption", enable_encryption)
        if encryption_type is not None:
            pulumi.set(__self__, "encryption_type", encryption_type)
        if endpoint is not None:
            pulumi.set(__self__, "endpoint", endpoint)
        if kms_key is not None:
            pulumi.set(__self__, "kms_key", kms_key)
        if region is not None:
            pulumi.set(__self__, "region", region)

    @property
    @pulumi.getter
    def destination(self) -> str:
        return pulumi.get(self, "destination")

    @property
    @pulumi.getter(name="cannedAcl")
    def canned_acl(self) -> Optional[str]:
        return pulumi.get(self, "canned_acl")

    @property
    @pulumi.getter(name="enableEncryption")
    def enable_encryption(self) -> Optional[bool]:
        return pulumi.get(self, "enable_encryption")

    @property
    @pulumi.getter(name="encryptionType")
    def encryption_type(self) -> Optional[str]:
        return pulumi.get(self, "encryption_type")

    @property
    @pulumi.getter
    def endpoint(self) -> Optional[str]:
        return pulumi.get(self, "endpoint")

    @property
    @pulumi.getter(name="kmsKey")
    def kms_key(self) -> Optional[str]:
        return pulumi.get(self, "kms_key")

    @property
    @pulumi.getter
    def region(self) -> Optional[str]:
        return pulumi.get(self, "region")


@pulumi.output_type
class GetJobJobSettingsSettingsTaskNewClusterInitScriptVolumesResult(dict):
    def __init__(__self__, *,
                 destination: str):
        pulumi.set(__self__, "destination", destination)

    @property
    @pulumi.getter
    def destination(self) -> str:
        return pulumi.get(self, "destination")


@pulumi.output_type
class GetJobJobSettingsSettingsTaskNewClusterInitScriptWorkspaceResult(dict):
    def __init__(__self__, *,
                 destination: str):
        pulumi.set(__self__, "destination", destination)

    @property
    @pulumi.getter
    def destination(self) -> str:
        return pulumi.get(self, "destination")


@pulumi.output_type
class GetJobJobSettingsSettingsTaskNewClusterWorkloadTypeResult(dict):
    def __init__(__self__, *,
                 clients: 'outputs.GetJobJobSettingsSettingsTaskNewClusterWorkloadTypeClientsResult'):
        pulumi.set(__self__, "clients", clients)

    @property
    @pulumi.getter
    def clients(self) -> 'outputs.GetJobJobSettingsSettingsTaskNewClusterWorkloadTypeClientsResult':
        return pulumi.get(self, "clients")


@pulumi.output_type
class GetJobJobSettingsSettingsTaskNewClusterWorkloadTypeClientsResult(dict):
    def __init__(__self__, *,
                 jobs: Optional[bool] = None,
                 notebooks: Optional[bool] = None):
        if jobs is not None:
            pulumi.set(__self__, "jobs", jobs)
        if notebooks is not None:
            pulumi.set(__self__, "notebooks", notebooks)

    @property
    @pulumi.getter
    def jobs(self) -> Optional[bool]:
        return pulumi.get(self, "jobs")

    @property
    @pulumi.getter
    def notebooks(self) -> Optional[bool]:
        return pulumi.get(self, "notebooks")


@pulumi.output_type
class GetJobJobSettingsSettingsTaskNotebookTaskResult(dict):
    def __init__(__self__, *,
                 notebook_path: str,
                 base_parameters: Optional[Mapping[str, Any]] = None,
                 source: Optional[str] = None):
        pulumi.set(__self__, "notebook_path", notebook_path)
        if base_parameters is not None:
            pulumi.set(__self__, "base_parameters", base_parameters)
        if source is not None:
            pulumi.set(__self__, "source", source)

    @property
    @pulumi.getter(name="notebookPath")
    def notebook_path(self) -> str:
        return pulumi.get(self, "notebook_path")

    @property
    @pulumi.getter(name="baseParameters")
    def base_parameters(self) -> Optional[Mapping[str, Any]]:
        return pulumi.get(self, "base_parameters")

    @property
    @pulumi.getter
    def source(self) -> Optional[str]:
        return pulumi.get(self, "source")


@pulumi.output_type
class GetJobJobSettingsSettingsTaskNotificationSettingsResult(dict):
    def __init__(__self__, *,
                 alert_on_last_attempt: Optional[bool] = None,
                 no_alert_for_canceled_runs: Optional[bool] = None,
                 no_alert_for_skipped_runs: Optional[bool] = None):
        if alert_on_last_attempt is not None:
            pulumi.set(__self__, "alert_on_last_attempt", alert_on_last_attempt)
        if no_alert_for_canceled_runs is not None:
            pulumi.set(__self__, "no_alert_for_canceled_runs", no_alert_for_canceled_runs)
        if no_alert_for_skipped_runs is not None:
            pulumi.set(__self__, "no_alert_for_skipped_runs", no_alert_for_skipped_runs)

    @property
    @pulumi.getter(name="alertOnLastAttempt")
    def alert_on_last_attempt(self) -> Optional[bool]:
        return pulumi.get(self, "alert_on_last_attempt")

    @property
    @pulumi.getter(name="noAlertForCanceledRuns")
    def no_alert_for_canceled_runs(self) -> Optional[bool]:
        return pulumi.get(self, "no_alert_for_canceled_runs")

    @property
    @pulumi.getter(name="noAlertForSkippedRuns")
    def no_alert_for_skipped_runs(self) -> Optional[bool]:
        return pulumi.get(self, "no_alert_for_skipped_runs")


@pulumi.output_type
class GetJobJobSettingsSettingsTaskPipelineTaskResult(dict):
    def __init__(__self__, *,
                 pipeline_id: str,
                 full_refresh: Optional[bool] = None):
        pulumi.set(__self__, "pipeline_id", pipeline_id)
        if full_refresh is not None:
            pulumi.set(__self__, "full_refresh", full_refresh)

    @property
    @pulumi.getter(name="pipelineId")
    def pipeline_id(self) -> str:
        return pulumi.get(self, "pipeline_id")

    @property
    @pulumi.getter(name="fullRefresh")
    def full_refresh(self) -> Optional[bool]:
        return pulumi.get(self, "full_refresh")


@pulumi.output_type
class GetJobJobSettingsSettingsTaskPythonWheelTaskResult(dict):
    def __init__(__self__, *,
                 entry_point: Optional[str] = None,
                 named_parameters: Optional[Mapping[str, Any]] = None,
                 package_name: Optional[str] = None,
                 parameters: Optional[Sequence[str]] = None):
        if entry_point is not None:
            pulumi.set(__self__, "entry_point", entry_point)
        if named_parameters is not None:
            pulumi.set(__self__, "named_parameters", named_parameters)
        if package_name is not None:
            pulumi.set(__self__, "package_name", package_name)
        if parameters is not None:
            pulumi.set(__self__, "parameters", parameters)

    @property
    @pulumi.getter(name="entryPoint")
    def entry_point(self) -> Optional[str]:
        return pulumi.get(self, "entry_point")

    @property
    @pulumi.getter(name="namedParameters")
    def named_parameters(self) -> Optional[Mapping[str, Any]]:
        return pulumi.get(self, "named_parameters")

    @property
    @pulumi.getter(name="packageName")
    def package_name(self) -> Optional[str]:
        return pulumi.get(self, "package_name")

    @property
    @pulumi.getter
    def parameters(self) -> Optional[Sequence[str]]:
        return pulumi.get(self, "parameters")


@pulumi.output_type
class GetJobJobSettingsSettingsTaskRunJobTaskResult(dict):
    def __init__(__self__, *,
                 job_id: int,
                 job_parameters: Optional[Mapping[str, Any]] = None):
        pulumi.set(__self__, "job_id", job_id)
        if job_parameters is not None:
            pulumi.set(__self__, "job_parameters", job_parameters)

    @property
    @pulumi.getter(name="jobId")
    def job_id(self) -> int:
        return pulumi.get(self, "job_id")

    @property
    @pulumi.getter(name="jobParameters")
    def job_parameters(self) -> Optional[Mapping[str, Any]]:
        return pulumi.get(self, "job_parameters")


@pulumi.output_type
class GetJobJobSettingsSettingsTaskSparkJarTaskResult(dict):
    def __init__(__self__, *,
                 jar_uri: Optional[str] = None,
                 main_class_name: Optional[str] = None,
                 parameters: Optional[Sequence[str]] = None):
        if jar_uri is not None:
            pulumi.set(__self__, "jar_uri", jar_uri)
        if main_class_name is not None:
            pulumi.set(__self__, "main_class_name", main_class_name)
        if parameters is not None:
            pulumi.set(__self__, "parameters", parameters)

    @property
    @pulumi.getter(name="jarUri")
    def jar_uri(self) -> Optional[str]:
        return pulumi.get(self, "jar_uri")

    @property
    @pulumi.getter(name="mainClassName")
    def main_class_name(self) -> Optional[str]:
        return pulumi.get(self, "main_class_name")

    @property
    @pulumi.getter
    def parameters(self) -> Optional[Sequence[str]]:
        return pulumi.get(self, "parameters")


@pulumi.output_type
class GetJobJobSettingsSettingsTaskSparkPythonTaskResult(dict):
    def __init__(__self__, *,
                 python_file: str,
                 parameters: Optional[Sequence[str]] = None,
                 source: Optional[str] = None):
        pulumi.set(__self__, "python_file", python_file)
        if parameters is not None:
            pulumi.set(__self__, "parameters", parameters)
        if source is not None:
            pulumi.set(__self__, "source", source)

    @property
    @pulumi.getter(name="pythonFile")
    def python_file(self) -> str:
        return pulumi.get(self, "python_file")

    @property
    @pulumi.getter
    def parameters(self) -> Optional[Sequence[str]]:
        return pulumi.get(self, "parameters")

    @property
    @pulumi.getter
    def source(self) -> Optional[str]:
        return pulumi.get(self, "source")


@pulumi.output_type
class GetJobJobSettingsSettingsTaskSparkSubmitTaskResult(dict):
    def __init__(__self__, *,
                 parameters: Optional[Sequence[str]] = None):
        if parameters is not None:
            pulumi.set(__self__, "parameters", parameters)

    @property
    @pulumi.getter
    def parameters(self) -> Optional[Sequence[str]]:
        return pulumi.get(self, "parameters")


@pulumi.output_type
class GetJobJobSettingsSettingsTaskSqlTaskResult(dict):
    def __init__(__self__, *,
                 alert: Optional['outputs.GetJobJobSettingsSettingsTaskSqlTaskAlertResult'] = None,
                 dashboard: Optional['outputs.GetJobJobSettingsSettingsTaskSqlTaskDashboardResult'] = None,
                 file: Optional['outputs.GetJobJobSettingsSettingsTaskSqlTaskFileResult'] = None,
                 parameters: Optional[Mapping[str, Any]] = None,
                 query: Optional['outputs.GetJobJobSettingsSettingsTaskSqlTaskQueryResult'] = None,
                 warehouse_id: Optional[str] = None):
        if alert is not None:
            pulumi.set(__self__, "alert", alert)
        if dashboard is not None:
            pulumi.set(__self__, "dashboard", dashboard)
        if file is not None:
            pulumi.set(__self__, "file", file)
        if parameters is not None:
            pulumi.set(__self__, "parameters", parameters)
        if query is not None:
            pulumi.set(__self__, "query", query)
        if warehouse_id is not None:
            pulumi.set(__self__, "warehouse_id", warehouse_id)

    @property
    @pulumi.getter
    def alert(self) -> Optional['outputs.GetJobJobSettingsSettingsTaskSqlTaskAlertResult']:
        return pulumi.get(self, "alert")

    @property
    @pulumi.getter
    def dashboard(self) -> Optional['outputs.GetJobJobSettingsSettingsTaskSqlTaskDashboardResult']:
        return pulumi.get(self, "dashboard")

    @property
    @pulumi.getter
    def file(self) -> Optional['outputs.GetJobJobSettingsSettingsTaskSqlTaskFileResult']:
        return pulumi.get(self, "file")

    @property
    @pulumi.getter
    def parameters(self) -> Optional[Mapping[str, Any]]:
        return pulumi.get(self, "parameters")

    @property
    @pulumi.getter
    def query(self) -> Optional['outputs.GetJobJobSettingsSettingsTaskSqlTaskQueryResult']:
        return pulumi.get(self, "query")

    @property
    @pulumi.getter(name="warehouseId")
    def warehouse_id(self) -> Optional[str]:
        return pulumi.get(self, "warehouse_id")


@pulumi.output_type
class GetJobJobSettingsSettingsTaskSqlTaskAlertResult(dict):
    def __init__(__self__, *,
                 alert_id: str,
                 subscriptions: Sequence['outputs.GetJobJobSettingsSettingsTaskSqlTaskAlertSubscriptionResult'],
                 pause_subscriptions: Optional[bool] = None):
        pulumi.set(__self__, "alert_id", alert_id)
        pulumi.set(__self__, "subscriptions", subscriptions)
        if pause_subscriptions is not None:
            pulumi.set(__self__, "pause_subscriptions", pause_subscriptions)

    @property
    @pulumi.getter(name="alertId")
    def alert_id(self) -> str:
        return pulumi.get(self, "alert_id")

    @property
    @pulumi.getter
    def subscriptions(self) -> Sequence['outputs.GetJobJobSettingsSettingsTaskSqlTaskAlertSubscriptionResult']:
        return pulumi.get(self, "subscriptions")

    @property
    @pulumi.getter(name="pauseSubscriptions")
    def pause_subscriptions(self) -> Optional[bool]:
        return pulumi.get(self, "pause_subscriptions")


@pulumi.output_type
class GetJobJobSettingsSettingsTaskSqlTaskAlertSubscriptionResult(dict):
    def __init__(__self__, *,
                 destination_id: Optional[str] = None,
                 user_name: Optional[str] = None):
        if destination_id is not None:
            pulumi.set(__self__, "destination_id", destination_id)
        if user_name is not None:
            pulumi.set(__self__, "user_name", user_name)

    @property
    @pulumi.getter(name="destinationId")
    def destination_id(self) -> Optional[str]:
        return pulumi.get(self, "destination_id")

    @property
    @pulumi.getter(name="userName")
    def user_name(self) -> Optional[str]:
        return pulumi.get(self, "user_name")


@pulumi.output_type
class GetJobJobSettingsSettingsTaskSqlTaskDashboardResult(dict):
    def __init__(__self__, *,
                 dashboard_id: str,
                 custom_subject: Optional[str] = None,
                 pause_subscriptions: Optional[bool] = None,
                 subscriptions: Optional[Sequence['outputs.GetJobJobSettingsSettingsTaskSqlTaskDashboardSubscriptionResult']] = None):
        pulumi.set(__self__, "dashboard_id", dashboard_id)
        if custom_subject is not None:
            pulumi.set(__self__, "custom_subject", custom_subject)
        if pause_subscriptions is not None:
            pulumi.set(__self__, "pause_subscriptions", pause_subscriptions)
        if subscriptions is not None:
            pulumi.set(__self__, "subscriptions", subscriptions)

    @property
    @pulumi.getter(name="dashboardId")
    def dashboard_id(self) -> str:
        return pulumi.get(self, "dashboard_id")

    @property
    @pulumi.getter(name="customSubject")
    def custom_subject(self) -> Optional[str]:
        return pulumi.get(self, "custom_subject")

    @property
    @pulumi.getter(name="pauseSubscriptions")
    def pause_subscriptions(self) -> Optional[bool]:
        return pulumi.get(self, "pause_subscriptions")

    @property
    @pulumi.getter
    def subscriptions(self) -> Optional[Sequence['outputs.GetJobJobSettingsSettingsTaskSqlTaskDashboardSubscriptionResult']]:
        return pulumi.get(self, "subscriptions")


@pulumi.output_type
class GetJobJobSettingsSettingsTaskSqlTaskDashboardSubscriptionResult(dict):
    def __init__(__self__, *,
                 destination_id: Optional[str] = None,
                 user_name: Optional[str] = None):
        if destination_id is not None:
            pulumi.set(__self__, "destination_id", destination_id)
        if user_name is not None:
            pulumi.set(__self__, "user_name", user_name)

    @property
    @pulumi.getter(name="destinationId")
    def destination_id(self) -> Optional[str]:
        return pulumi.get(self, "destination_id")

    @property
    @pulumi.getter(name="userName")
    def user_name(self) -> Optional[str]:
        return pulumi.get(self, "user_name")


@pulumi.output_type
class GetJobJobSettingsSettingsTaskSqlTaskFileResult(dict):
    def __init__(__self__, *,
                 path: str,
                 source: Optional[str] = None):
        pulumi.set(__self__, "path", path)
        if source is not None:
            pulumi.set(__self__, "source", source)

    @property
    @pulumi.getter
    def path(self) -> str:
        return pulumi.get(self, "path")

    @property
    @pulumi.getter
    def source(self) -> Optional[str]:
        return pulumi.get(self, "source")


@pulumi.output_type
class GetJobJobSettingsSettingsTaskSqlTaskQueryResult(dict):
    def __init__(__self__, *,
                 query_id: str):
        pulumi.set(__self__, "query_id", query_id)

    @property
    @pulumi.getter(name="queryId")
    def query_id(self) -> str:
        return pulumi.get(self, "query_id")


@pulumi.output_type
class GetJobJobSettingsSettingsTaskWebhookNotificationsResult(dict):
    def __init__(__self__, *,
                 on_duration_warning_threshold_exceededs: Optional[Sequence['outputs.GetJobJobSettingsSettingsTaskWebhookNotificationsOnDurationWarningThresholdExceededResult']] = None,
                 on_failures: Optional[Sequence['outputs.GetJobJobSettingsSettingsTaskWebhookNotificationsOnFailureResult']] = None,
                 on_starts: Optional[Sequence['outputs.GetJobJobSettingsSettingsTaskWebhookNotificationsOnStartResult']] = None,
                 on_successes: Optional[Sequence['outputs.GetJobJobSettingsSettingsTaskWebhookNotificationsOnSuccessResult']] = None):
        if on_duration_warning_threshold_exceededs is not None:
            pulumi.set(__self__, "on_duration_warning_threshold_exceededs", on_duration_warning_threshold_exceededs)
        if on_failures is not None:
            pulumi.set(__self__, "on_failures", on_failures)
        if on_starts is not None:
            pulumi.set(__self__, "on_starts", on_starts)
        if on_successes is not None:
            pulumi.set(__self__, "on_successes", on_successes)

    @property
    @pulumi.getter(name="onDurationWarningThresholdExceededs")
    def on_duration_warning_threshold_exceededs(self) -> Optional[Sequence['outputs.GetJobJobSettingsSettingsTaskWebhookNotificationsOnDurationWarningThresholdExceededResult']]:
        return pulumi.get(self, "on_duration_warning_threshold_exceededs")

    @property
    @pulumi.getter(name="onFailures")
    def on_failures(self) -> Optional[Sequence['outputs.GetJobJobSettingsSettingsTaskWebhookNotificationsOnFailureResult']]:
        return pulumi.get(self, "on_failures")

    @property
    @pulumi.getter(name="onStarts")
    def on_starts(self) -> Optional[Sequence['outputs.GetJobJobSettingsSettingsTaskWebhookNotificationsOnStartResult']]:
        return pulumi.get(self, "on_starts")

    @property
    @pulumi.getter(name="onSuccesses")
    def on_successes(self) -> Optional[Sequence['outputs.GetJobJobSettingsSettingsTaskWebhookNotificationsOnSuccessResult']]:
        return pulumi.get(self, "on_successes")


@pulumi.output_type
class GetJobJobSettingsSettingsTaskWebhookNotificationsOnDurationWarningThresholdExceededResult(dict):
    def __init__(__self__, *,
                 id: Optional[str] = None):
        """
        :param str id: the id of Job if the resource was matched by name.
        """
        if id is not None:
            pulumi.set(__self__, "id", id)

    @property
    @pulumi.getter
    def id(self) -> Optional[str]:
        """
        the id of Job if the resource was matched by name.
        """
        return pulumi.get(self, "id")


@pulumi.output_type
class GetJobJobSettingsSettingsTaskWebhookNotificationsOnFailureResult(dict):
    def __init__(__self__, *,
                 id: Optional[str] = None):
        """
        :param str id: the id of Job if the resource was matched by name.
        """
        if id is not None:
            pulumi.set(__self__, "id", id)

    @property
    @pulumi.getter
    def id(self) -> Optional[str]:
        """
        the id of Job if the resource was matched by name.
        """
        return pulumi.get(self, "id")


@pulumi.output_type
class GetJobJobSettingsSettingsTaskWebhookNotificationsOnStartResult(dict):
    def __init__(__self__, *,
                 id: Optional[str] = None):
        """
        :param str id: the id of Job if the resource was matched by name.
        """
        if id is not None:
            pulumi.set(__self__, "id", id)

    @property
    @pulumi.getter
    def id(self) -> Optional[str]:
        """
        the id of Job if the resource was matched by name.
        """
        return pulumi.get(self, "id")


@pulumi.output_type
class GetJobJobSettingsSettingsTaskWebhookNotificationsOnSuccessResult(dict):
    def __init__(__self__, *,
                 id: Optional[str] = None):
        """
        :param str id: the id of Job if the resource was matched by name.
        """
        if id is not None:
            pulumi.set(__self__, "id", id)

    @property
    @pulumi.getter
    def id(self) -> Optional[str]:
        """
        the id of Job if the resource was matched by name.
        """
        return pulumi.get(self, "id")


@pulumi.output_type
class GetJobJobSettingsSettingsTriggerResult(dict):
    def __init__(__self__, *,
                 file_arrival: 'outputs.GetJobJobSettingsSettingsTriggerFileArrivalResult',
                 pause_status: Optional[str] = None):
        pulumi.set(__self__, "file_arrival", file_arrival)
        if pause_status is not None:
            pulumi.set(__self__, "pause_status", pause_status)

    @property
    @pulumi.getter(name="fileArrival")
    def file_arrival(self) -> 'outputs.GetJobJobSettingsSettingsTriggerFileArrivalResult':
        return pulumi.get(self, "file_arrival")

    @property
    @pulumi.getter(name="pauseStatus")
    def pause_status(self) -> Optional[str]:
        return pulumi.get(self, "pause_status")


@pulumi.output_type
class GetJobJobSettingsSettingsTriggerFileArrivalResult(dict):
    def __init__(__self__, *,
                 url: str,
                 min_time_between_triggers_seconds: Optional[int] = None,
                 wait_after_last_change_seconds: Optional[int] = None):
        pulumi.set(__self__, "url", url)
        if min_time_between_triggers_seconds is not None:
            pulumi.set(__self__, "min_time_between_triggers_seconds", min_time_between_triggers_seconds)
        if wait_after_last_change_seconds is not None:
            pulumi.set(__self__, "wait_after_last_change_seconds", wait_after_last_change_seconds)

    @property
    @pulumi.getter
    def url(self) -> str:
        return pulumi.get(self, "url")

    @property
    @pulumi.getter(name="minTimeBetweenTriggersSeconds")
    def min_time_between_triggers_seconds(self) -> Optional[int]:
        return pulumi.get(self, "min_time_between_triggers_seconds")

    @property
    @pulumi.getter(name="waitAfterLastChangeSeconds")
    def wait_after_last_change_seconds(self) -> Optional[int]:
        return pulumi.get(self, "wait_after_last_change_seconds")


@pulumi.output_type
class GetJobJobSettingsSettingsWebhookNotificationsResult(dict):
    def __init__(__self__, *,
                 on_duration_warning_threshold_exceededs: Optional[Sequence['outputs.GetJobJobSettingsSettingsWebhookNotificationsOnDurationWarningThresholdExceededResult']] = None,
                 on_failures: Optional[Sequence['outputs.GetJobJobSettingsSettingsWebhookNotificationsOnFailureResult']] = None,
                 on_starts: Optional[Sequence['outputs.GetJobJobSettingsSettingsWebhookNotificationsOnStartResult']] = None,
                 on_successes: Optional[Sequence['outputs.GetJobJobSettingsSettingsWebhookNotificationsOnSuccessResult']] = None):
        if on_duration_warning_threshold_exceededs is not None:
            pulumi.set(__self__, "on_duration_warning_threshold_exceededs", on_duration_warning_threshold_exceededs)
        if on_failures is not None:
            pulumi.set(__self__, "on_failures", on_failures)
        if on_starts is not None:
            pulumi.set(__self__, "on_starts", on_starts)
        if on_successes is not None:
            pulumi.set(__self__, "on_successes", on_successes)

    @property
    @pulumi.getter(name="onDurationWarningThresholdExceededs")
    def on_duration_warning_threshold_exceededs(self) -> Optional[Sequence['outputs.GetJobJobSettingsSettingsWebhookNotificationsOnDurationWarningThresholdExceededResult']]:
        return pulumi.get(self, "on_duration_warning_threshold_exceededs")

    @property
    @pulumi.getter(name="onFailures")
    def on_failures(self) -> Optional[Sequence['outputs.GetJobJobSettingsSettingsWebhookNotificationsOnFailureResult']]:
        return pulumi.get(self, "on_failures")

    @property
    @pulumi.getter(name="onStarts")
    def on_starts(self) -> Optional[Sequence['outputs.GetJobJobSettingsSettingsWebhookNotificationsOnStartResult']]:
        return pulumi.get(self, "on_starts")

    @property
    @pulumi.getter(name="onSuccesses")
    def on_successes(self) -> Optional[Sequence['outputs.GetJobJobSettingsSettingsWebhookNotificationsOnSuccessResult']]:
        return pulumi.get(self, "on_successes")


@pulumi.output_type
class GetJobJobSettingsSettingsWebhookNotificationsOnDurationWarningThresholdExceededResult(dict):
    def __init__(__self__, *,
                 id: Optional[str] = None):
        """
        :param str id: the id of Job if the resource was matched by name.
        """
        if id is not None:
            pulumi.set(__self__, "id", id)

    @property
    @pulumi.getter
    def id(self) -> Optional[str]:
        """
        the id of Job if the resource was matched by name.
        """
        return pulumi.get(self, "id")


@pulumi.output_type
class GetJobJobSettingsSettingsWebhookNotificationsOnFailureResult(dict):
    def __init__(__self__, *,
                 id: Optional[str] = None):
        """
        :param str id: the id of Job if the resource was matched by name.
        """
        if id is not None:
            pulumi.set(__self__, "id", id)

    @property
    @pulumi.getter
    def id(self) -> Optional[str]:
        """
        the id of Job if the resource was matched by name.
        """
        return pulumi.get(self, "id")


@pulumi.output_type
class GetJobJobSettingsSettingsWebhookNotificationsOnStartResult(dict):
    def __init__(__self__, *,
                 id: Optional[str] = None):
        """
        :param str id: the id of Job if the resource was matched by name.
        """
        if id is not None:
            pulumi.set(__self__, "id", id)

    @property
    @pulumi.getter
    def id(self) -> Optional[str]:
        """
        the id of Job if the resource was matched by name.
        """
        return pulumi.get(self, "id")


@pulumi.output_type
class GetJobJobSettingsSettingsWebhookNotificationsOnSuccessResult(dict):
    def __init__(__self__, *,
                 id: Optional[str] = None):
        """
        :param str id: the id of Job if the resource was matched by name.
        """
        if id is not None:
            pulumi.set(__self__, "id", id)

    @property
    @pulumi.getter
    def id(self) -> Optional[str]:
        """
        the id of Job if the resource was matched by name.
        """
        return pulumi.get(self, "id")


@pulumi.output_type
class GetMetastoreMetastoreInfoResult(dict):
    def __init__(__self__, *,
                 cloud: Optional[str] = None,
                 created_at: Optional[int] = None,
                 created_by: Optional[str] = None,
                 default_data_access_config_id: Optional[str] = None,
                 delta_sharing_organization_name: Optional[str] = None,
                 delta_sharing_recipient_token_lifetime_in_seconds: Optional[int] = None,
                 delta_sharing_scope: Optional[str] = None,
                 global_metastore_id: Optional[str] = None,
                 metastore_id: Optional[str] = None,
                 name: Optional[str] = None,
                 owner: Optional[str] = None,
                 privilege_model_version: Optional[str] = None,
                 region: Optional[str] = None,
                 storage_root: Optional[str] = None,
                 storage_root_credential_id: Optional[str] = None,
                 storage_root_credential_name: Optional[str] = None,
                 updated_at: Optional[int] = None,
                 updated_by: Optional[str] = None):
        """
        :param str delta_sharing_organization_name: The organization name of a Delta Sharing entity. This field is used for Databricks to Databricks sharing.
        :param int delta_sharing_recipient_token_lifetime_in_seconds: Used to set expiration duration in seconds on recipient data access tokens.
        :param str delta_sharing_scope: Used to enable delta sharing on the metastore. Valid values: INTERNAL, INTERNAL_AND_EXTERNAL. INTERNAL only allows sharing within the same account, and INTERNAL_AND_EXTERNAL allows cross account sharing and token based sharing.
        :param str metastore_id: Id of the metastore to be fetched
        :param str name: Name of metastore.
        :param str owner: Username/groupname/sp application_id of the metastore owner.
        :param str storage_root: Path on cloud storage account, where managed `Table` are stored.
        """
        if cloud is not None:
            pulumi.set(__self__, "cloud", cloud)
        if created_at is not None:
            pulumi.set(__self__, "created_at", created_at)
        if created_by is not None:
            pulumi.set(__self__, "created_by", created_by)
        if default_data_access_config_id is not None:
            pulumi.set(__self__, "default_data_access_config_id", default_data_access_config_id)
        if delta_sharing_organization_name is not None:
            pulumi.set(__self__, "delta_sharing_organization_name", delta_sharing_organization_name)
        if delta_sharing_recipient_token_lifetime_in_seconds is not None:
            pulumi.set(__self__, "delta_sharing_recipient_token_lifetime_in_seconds", delta_sharing_recipient_token_lifetime_in_seconds)
        if delta_sharing_scope is not None:
            pulumi.set(__self__, "delta_sharing_scope", delta_sharing_scope)
        if global_metastore_id is not None:
            pulumi.set(__self__, "global_metastore_id", global_metastore_id)
        if metastore_id is not None:
            pulumi.set(__self__, "metastore_id", metastore_id)
        if name is not None:
            pulumi.set(__self__, "name", name)
        if owner is not None:
            pulumi.set(__self__, "owner", owner)
        if privilege_model_version is not None:
            pulumi.set(__self__, "privilege_model_version", privilege_model_version)
        if region is not None:
            pulumi.set(__self__, "region", region)
        if storage_root is not None:
            pulumi.set(__self__, "storage_root", storage_root)
        if storage_root_credential_id is not None:
            pulumi.set(__self__, "storage_root_credential_id", storage_root_credential_id)
        if storage_root_credential_name is not None:
            pulumi.set(__self__, "storage_root_credential_name", storage_root_credential_name)
        if updated_at is not None:
            pulumi.set(__self__, "updated_at", updated_at)
        if updated_by is not None:
            pulumi.set(__self__, "updated_by", updated_by)

    @property
    @pulumi.getter
    def cloud(self) -> Optional[str]:
        return pulumi.get(self, "cloud")

    @property
    @pulumi.getter(name="createdAt")
    def created_at(self) -> Optional[int]:
        return pulumi.get(self, "created_at")

    @property
    @pulumi.getter(name="createdBy")
    def created_by(self) -> Optional[str]:
        return pulumi.get(self, "created_by")

    @property
    @pulumi.getter(name="defaultDataAccessConfigId")
    def default_data_access_config_id(self) -> Optional[str]:
        return pulumi.get(self, "default_data_access_config_id")

    @property
    @pulumi.getter(name="deltaSharingOrganizationName")
    def delta_sharing_organization_name(self) -> Optional[str]:
        """
        The organization name of a Delta Sharing entity. This field is used for Databricks to Databricks sharing.
        """
        return pulumi.get(self, "delta_sharing_organization_name")

    @property
    @pulumi.getter(name="deltaSharingRecipientTokenLifetimeInSeconds")
    def delta_sharing_recipient_token_lifetime_in_seconds(self) -> Optional[int]:
        """
        Used to set expiration duration in seconds on recipient data access tokens.
        """
        return pulumi.get(self, "delta_sharing_recipient_token_lifetime_in_seconds")

    @property
    @pulumi.getter(name="deltaSharingScope")
    def delta_sharing_scope(self) -> Optional[str]:
        """
        Used to enable delta sharing on the metastore. Valid values: INTERNAL, INTERNAL_AND_EXTERNAL. INTERNAL only allows sharing within the same account, and INTERNAL_AND_EXTERNAL allows cross account sharing and token based sharing.
        """
        return pulumi.get(self, "delta_sharing_scope")

    @property
    @pulumi.getter(name="globalMetastoreId")
    def global_metastore_id(self) -> Optional[str]:
        return pulumi.get(self, "global_metastore_id")

    @property
    @pulumi.getter(name="metastoreId")
    def metastore_id(self) -> Optional[str]:
        """
        Id of the metastore to be fetched
        """
        return pulumi.get(self, "metastore_id")

    @property
    @pulumi.getter
    def name(self) -> Optional[str]:
        """
        Name of metastore.
        """
        return pulumi.get(self, "name")

    @property
    @pulumi.getter
    def owner(self) -> Optional[str]:
        """
        Username/groupname/sp application_id of the metastore owner.
        """
        return pulumi.get(self, "owner")

    @property
    @pulumi.getter(name="privilegeModelVersion")
    def privilege_model_version(self) -> Optional[str]:
        return pulumi.get(self, "privilege_model_version")

    @property
    @pulumi.getter
    def region(self) -> Optional[str]:
        return pulumi.get(self, "region")

    @property
    @pulumi.getter(name="storageRoot")
    def storage_root(self) -> Optional[str]:
        """
        Path on cloud storage account, where managed `Table` are stored.
        """
        return pulumi.get(self, "storage_root")

    @property
    @pulumi.getter(name="storageRootCredentialId")
    def storage_root_credential_id(self) -> Optional[str]:
        return pulumi.get(self, "storage_root_credential_id")

    @property
    @pulumi.getter(name="storageRootCredentialName")
    def storage_root_credential_name(self) -> Optional[str]:
        return pulumi.get(self, "storage_root_credential_name")

    @property
    @pulumi.getter(name="updatedAt")
    def updated_at(self) -> Optional[int]:
        return pulumi.get(self, "updated_at")

    @property
    @pulumi.getter(name="updatedBy")
    def updated_by(self) -> Optional[str]:
        return pulumi.get(self, "updated_by")


@pulumi.output_type
class GetMlflowModelLatestVersionResult(dict):
    def __init__(__self__, *,
                 creation_timestamp: Optional[int] = None,
                 current_stage: Optional[str] = None,
                 description: Optional[str] = None,
                 last_updated_timestamp: Optional[int] = None,
                 name: Optional[str] = None,
                 run_id: Optional[str] = None,
                 run_link: Optional[str] = None,
                 source: Optional[str] = None,
                 status: Optional[str] = None,
                 status_message: Optional[str] = None,
                 tags: Optional[Sequence['outputs.GetMlflowModelLatestVersionTagResult']] = None,
                 user_id: Optional[str] = None,
                 version: Optional[str] = None):
        """
        :param str description: User-specified description for the object.
        :param str name: Name of the registered model.
        :param Sequence['GetMlflowModelLatestVersionTagArgs'] tags: Array of tags associated with the model.
        :param str user_id: The username of the user that created the object.
        """
        if creation_timestamp is not None:
            pulumi.set(__self__, "creation_timestamp", creation_timestamp)
        if current_stage is not None:
            pulumi.set(__self__, "current_stage", current_stage)
        if description is not None:
            pulumi.set(__self__, "description", description)
        if last_updated_timestamp is not None:
            pulumi.set(__self__, "last_updated_timestamp", last_updated_timestamp)
        if name is not None:
            pulumi.set(__self__, "name", name)
        if run_id is not None:
            pulumi.set(__self__, "run_id", run_id)
        if run_link is not None:
            pulumi.set(__self__, "run_link", run_link)
        if source is not None:
            pulumi.set(__self__, "source", source)
        if status is not None:
            pulumi.set(__self__, "status", status)
        if status_message is not None:
            pulumi.set(__self__, "status_message", status_message)
        if tags is not None:
            pulumi.set(__self__, "tags", tags)
        if user_id is not None:
            pulumi.set(__self__, "user_id", user_id)
        if version is not None:
            pulumi.set(__self__, "version", version)

    @property
    @pulumi.getter(name="creationTimestamp")
    def creation_timestamp(self) -> Optional[int]:
        return pulumi.get(self, "creation_timestamp")

    @property
    @pulumi.getter(name="currentStage")
    def current_stage(self) -> Optional[str]:
        return pulumi.get(self, "current_stage")

    @property
    @pulumi.getter
    def description(self) -> Optional[str]:
        """
        User-specified description for the object.
        """
        return pulumi.get(self, "description")

    @property
    @pulumi.getter(name="lastUpdatedTimestamp")
    def last_updated_timestamp(self) -> Optional[int]:
        return pulumi.get(self, "last_updated_timestamp")

    @property
    @pulumi.getter
    def name(self) -> Optional[str]:
        """
        Name of the registered model.
        """
        return pulumi.get(self, "name")

    @property
    @pulumi.getter(name="runId")
    def run_id(self) -> Optional[str]:
        return pulumi.get(self, "run_id")

    @property
    @pulumi.getter(name="runLink")
    def run_link(self) -> Optional[str]:
        return pulumi.get(self, "run_link")

    @property
    @pulumi.getter
    def source(self) -> Optional[str]:
        return pulumi.get(self, "source")

    @property
    @pulumi.getter
    def status(self) -> Optional[str]:
        return pulumi.get(self, "status")

    @property
    @pulumi.getter(name="statusMessage")
    def status_message(self) -> Optional[str]:
        return pulumi.get(self, "status_message")

    @property
    @pulumi.getter
    def tags(self) -> Optional[Sequence['outputs.GetMlflowModelLatestVersionTagResult']]:
        """
        Array of tags associated with the model.
        """
        return pulumi.get(self, "tags")

    @property
    @pulumi.getter(name="userId")
    def user_id(self) -> Optional[str]:
        """
        The username of the user that created the object.
        """
        return pulumi.get(self, "user_id")

    @property
    @pulumi.getter
    def version(self) -> Optional[str]:
        return pulumi.get(self, "version")


@pulumi.output_type
class GetMlflowModelLatestVersionTagResult(dict):
    def __init__(__self__, *,
                 key: Optional[str] = None,
                 value: Optional[str] = None):
        if key is not None:
            pulumi.set(__self__, "key", key)
        if value is not None:
            pulumi.set(__self__, "value", value)

    @property
    @pulumi.getter
    def key(self) -> Optional[str]:
        return pulumi.get(self, "key")

    @property
    @pulumi.getter
    def value(self) -> Optional[str]:
        return pulumi.get(self, "value")


@pulumi.output_type
class GetMlflowModelTagResult(dict):
    def __init__(__self__, *,
                 key: Optional[str] = None,
                 value: Optional[str] = None):
        if key is not None:
            pulumi.set(__self__, "key", key)
        if value is not None:
            pulumi.set(__self__, "value", value)

    @property
    @pulumi.getter
    def key(self) -> Optional[str]:
        return pulumi.get(self, "key")

    @property
    @pulumi.getter
    def value(self) -> Optional[str]:
        return pulumi.get(self, "value")


@pulumi.output_type
class GetNotebookPathsNotebookPathListResult(dict):
    def __init__(__self__, *,
                 language: Optional[str] = None,
                 path: Optional[str] = None):
        """
        :param str path: Path to workspace directory
        """
        if language is not None:
            pulumi.set(__self__, "language", language)
        if path is not None:
            pulumi.set(__self__, "path", path)

    @property
    @pulumi.getter
    def language(self) -> Optional[str]:
        return pulumi.get(self, "language")

    @property
    @pulumi.getter
    def path(self) -> Optional[str]:
        """
        Path to workspace directory
        """
        return pulumi.get(self, "path")


@pulumi.output_type
class GetShareObjectResult(dict):
    def __init__(__self__, *,
                 added_at: int,
                 added_by: str,
                 data_object_type: str,
                 name: str,
                 status: str,
                 cdf_enabled: Optional[bool] = None,
                 comment: Optional[str] = None,
                 history_data_sharing_status: Optional[str] = None,
                 partitions: Optional[Sequence['outputs.GetShareObjectPartitionResult']] = None,
                 shared_as: Optional[str] = None,
                 start_version: Optional[int] = None):
        """
        :param str data_object_type: Type of the object.
        :param str name: The name of the share
        :param str comment: Description about the object.
        """
        pulumi.set(__self__, "added_at", added_at)
        pulumi.set(__self__, "added_by", added_by)
        pulumi.set(__self__, "data_object_type", data_object_type)
        pulumi.set(__self__, "name", name)
        pulumi.set(__self__, "status", status)
        if cdf_enabled is not None:
            pulumi.set(__self__, "cdf_enabled", cdf_enabled)
        if comment is not None:
            pulumi.set(__self__, "comment", comment)
        if history_data_sharing_status is not None:
            pulumi.set(__self__, "history_data_sharing_status", history_data_sharing_status)
        if partitions is not None:
            pulumi.set(__self__, "partitions", partitions)
        if shared_as is not None:
            pulumi.set(__self__, "shared_as", shared_as)
        if start_version is not None:
            pulumi.set(__self__, "start_version", start_version)

    @property
    @pulumi.getter(name="addedAt")
    def added_at(self) -> int:
        return pulumi.get(self, "added_at")

    @property
    @pulumi.getter(name="addedBy")
    def added_by(self) -> str:
        return pulumi.get(self, "added_by")

    @property
    @pulumi.getter(name="dataObjectType")
    def data_object_type(self) -> str:
        """
        Type of the object.
        """
        return pulumi.get(self, "data_object_type")

    @property
    @pulumi.getter
    def name(self) -> str:
        """
        The name of the share
        """
        return pulumi.get(self, "name")

    @property
    @pulumi.getter
    def status(self) -> str:
        return pulumi.get(self, "status")

    @property
    @pulumi.getter(name="cdfEnabled")
    def cdf_enabled(self) -> Optional[bool]:
        return pulumi.get(self, "cdf_enabled")

    @property
    @pulumi.getter
    def comment(self) -> Optional[str]:
        """
        Description about the object.
        """
        return pulumi.get(self, "comment")

    @property
    @pulumi.getter(name="historyDataSharingStatus")
    def history_data_sharing_status(self) -> Optional[str]:
        return pulumi.get(self, "history_data_sharing_status")

    @property
    @pulumi.getter
    def partitions(self) -> Optional[Sequence['outputs.GetShareObjectPartitionResult']]:
        return pulumi.get(self, "partitions")

    @property
    @pulumi.getter(name="sharedAs")
    def shared_as(self) -> Optional[str]:
        return pulumi.get(self, "shared_as")

    @property
    @pulumi.getter(name="startVersion")
    def start_version(self) -> Optional[int]:
        return pulumi.get(self, "start_version")


@pulumi.output_type
class GetShareObjectPartitionResult(dict):
    def __init__(__self__, *,
                 values: Sequence['outputs.GetShareObjectPartitionValueResult']):
        pulumi.set(__self__, "values", values)

    @property
    @pulumi.getter
    def values(self) -> Sequence['outputs.GetShareObjectPartitionValueResult']:
        return pulumi.get(self, "values")


@pulumi.output_type
class GetShareObjectPartitionValueResult(dict):
    def __init__(__self__, *,
                 name: str,
                 op: str,
                 recipient_property_key: Optional[str] = None,
                 value: Optional[str] = None):
        """
        :param str name: The name of the share
        """
        pulumi.set(__self__, "name", name)
        pulumi.set(__self__, "op", op)
        if recipient_property_key is not None:
            pulumi.set(__self__, "recipient_property_key", recipient_property_key)
        if value is not None:
            pulumi.set(__self__, "value", value)

    @property
    @pulumi.getter
    def name(self) -> str:
        """
        The name of the share
        """
        return pulumi.get(self, "name")

    @property
    @pulumi.getter
    def op(self) -> str:
        return pulumi.get(self, "op")

    @property
    @pulumi.getter(name="recipientPropertyKey")
    def recipient_property_key(self) -> Optional[str]:
        return pulumi.get(self, "recipient_property_key")

    @property
    @pulumi.getter
    def value(self) -> Optional[str]:
        return pulumi.get(self, "value")


@pulumi.output_type
class GetSqlWarehouseChannelResult(dict):
    def __init__(__self__, *,
                 dbsql_version: Optional[str] = None,
                 name: Optional[str] = None):
        """
        :param str name: Name of the SQL warehouse to search (case-sensitive).
        """
        if dbsql_version is not None:
            pulumi.set(__self__, "dbsql_version", dbsql_version)
        if name is not None:
            pulumi.set(__self__, "name", name)

    @property
    @pulumi.getter(name="dbsqlVersion")
    def dbsql_version(self) -> Optional[str]:
        return pulumi.get(self, "dbsql_version")

    @property
    @pulumi.getter
    def name(self) -> Optional[str]:
        """
        Name of the SQL warehouse to search (case-sensitive).
        """
        return pulumi.get(self, "name")


@pulumi.output_type
class GetSqlWarehouseHealthResult(dict):
    def __init__(__self__, *,
                 details: Optional[str] = None,
                 failure_reason: Optional['outputs.GetSqlWarehouseHealthFailureReasonResult'] = None,
                 message: Optional[str] = None,
                 status: Optional[str] = None,
                 summary: Optional[str] = None):
        if details is not None:
            pulumi.set(__self__, "details", details)
        if failure_reason is not None:
            pulumi.set(__self__, "failure_reason", failure_reason)
        if message is not None:
            pulumi.set(__self__, "message", message)
        if status is not None:
            pulumi.set(__self__, "status", status)
        if summary is not None:
            pulumi.set(__self__, "summary", summary)

    @property
    @pulumi.getter
    def details(self) -> Optional[str]:
        return pulumi.get(self, "details")

    @property
    @pulumi.getter(name="failureReason")
    def failure_reason(self) -> Optional['outputs.GetSqlWarehouseHealthFailureReasonResult']:
        return pulumi.get(self, "failure_reason")

    @property
    @pulumi.getter
    def message(self) -> Optional[str]:
        return pulumi.get(self, "message")

    @property
    @pulumi.getter
    def status(self) -> Optional[str]:
        return pulumi.get(self, "status")

    @property
    @pulumi.getter
    def summary(self) -> Optional[str]:
        return pulumi.get(self, "summary")


@pulumi.output_type
class GetSqlWarehouseHealthFailureReasonResult(dict):
    def __init__(__self__, *,
                 code: Optional[str] = None,
                 parameters: Optional[Mapping[str, Any]] = None,
                 type: Optional[str] = None):
        if code is not None:
            pulumi.set(__self__, "code", code)
        if parameters is not None:
            pulumi.set(__self__, "parameters", parameters)
        if type is not None:
            pulumi.set(__self__, "type", type)

    @property
    @pulumi.getter
    def code(self) -> Optional[str]:
        return pulumi.get(self, "code")

    @property
    @pulumi.getter
    def parameters(self) -> Optional[Mapping[str, Any]]:
        return pulumi.get(self, "parameters")

    @property
    @pulumi.getter
    def type(self) -> Optional[str]:
        return pulumi.get(self, "type")


@pulumi.output_type
class GetSqlWarehouseOdbcParamsResult(dict):
    def __init__(__self__, *,
                 hostname: Optional[str] = None,
                 path: Optional[str] = None,
                 port: Optional[int] = None,
                 protocol: Optional[str] = None):
        if hostname is not None:
            pulumi.set(__self__, "hostname", hostname)
        if path is not None:
            pulumi.set(__self__, "path", path)
        if port is not None:
            pulumi.set(__self__, "port", port)
        if protocol is not None:
            pulumi.set(__self__, "protocol", protocol)

    @property
    @pulumi.getter
    def hostname(self) -> Optional[str]:
        return pulumi.get(self, "hostname")

    @property
    @pulumi.getter
    def path(self) -> Optional[str]:
        return pulumi.get(self, "path")

    @property
    @pulumi.getter
    def port(self) -> Optional[int]:
        return pulumi.get(self, "port")

    @property
    @pulumi.getter
    def protocol(self) -> Optional[str]:
        return pulumi.get(self, "protocol")


@pulumi.output_type
class GetSqlWarehouseTagsResult(dict):
    def __init__(__self__, *,
                 custom_tags: Optional[Sequence['outputs.GetSqlWarehouseTagsCustomTagResult']] = None):
        if custom_tags is not None:
            pulumi.set(__self__, "custom_tags", custom_tags)

    @property
    @pulumi.getter(name="customTags")
    def custom_tags(self) -> Optional[Sequence['outputs.GetSqlWarehouseTagsCustomTagResult']]:
        return pulumi.get(self, "custom_tags")


@pulumi.output_type
class GetSqlWarehouseTagsCustomTagResult(dict):
    def __init__(__self__, *,
                 key: Optional[str] = None,
                 value: Optional[str] = None):
        if key is not None:
            pulumi.set(__self__, "key", key)
        if value is not None:
            pulumi.set(__self__, "value", value)

    @property
    @pulumi.getter
    def key(self) -> Optional[str]:
        return pulumi.get(self, "key")

    @property
    @pulumi.getter
    def value(self) -> Optional[str]:
        return pulumi.get(self, "value")


@pulumi.output_type
class GetStorageCredentialStorageCredentialInfoResult(dict):
    def __init__(__self__, *,
                 aws_iam_role: Optional['outputs.GetStorageCredentialStorageCredentialInfoAwsIamRoleResult'] = None,
                 azure_managed_identity: Optional['outputs.GetStorageCredentialStorageCredentialInfoAzureManagedIdentityResult'] = None,
                 azure_service_principal: Optional['outputs.GetStorageCredentialStorageCredentialInfoAzureServicePrincipalResult'] = None,
                 cloudflare_api_token: Optional['outputs.GetStorageCredentialStorageCredentialInfoCloudflareApiTokenResult'] = None,
                 comment: Optional[str] = None,
                 created_at: Optional[int] = None,
                 created_by: Optional[str] = None,
                 databricks_gcp_service_account: Optional['outputs.GetStorageCredentialStorageCredentialInfoDatabricksGcpServiceAccountResult'] = None,
                 id: Optional[str] = None,
                 metastore_id: Optional[str] = None,
                 name: Optional[str] = None,
                 owner: Optional[str] = None,
                 read_only: Optional[bool] = None,
                 updated_at: Optional[int] = None,
                 updated_by: Optional[str] = None,
                 used_for_managed_storage: Optional[bool] = None):
        """
        :param str metastore_id: Unique identifier of the parent Metastore.
        :param str name: The name of the storage credential
        :param str owner: Username/groupname/sp application_id of the storage credential owner.
        :param bool read_only: Indicates whether the storage credential is only usable for read operations.
        """
        if aws_iam_role is not None:
            pulumi.set(__self__, "aws_iam_role", aws_iam_role)
        if azure_managed_identity is not None:
            pulumi.set(__self__, "azure_managed_identity", azure_managed_identity)
        if azure_service_principal is not None:
            pulumi.set(__self__, "azure_service_principal", azure_service_principal)
        if cloudflare_api_token is not None:
            pulumi.set(__self__, "cloudflare_api_token", cloudflare_api_token)
        if comment is not None:
            pulumi.set(__self__, "comment", comment)
        if created_at is not None:
            pulumi.set(__self__, "created_at", created_at)
        if created_by is not None:
            pulumi.set(__self__, "created_by", created_by)
        if databricks_gcp_service_account is not None:
            pulumi.set(__self__, "databricks_gcp_service_account", databricks_gcp_service_account)
        if id is not None:
            pulumi.set(__self__, "id", id)
        if metastore_id is not None:
            pulumi.set(__self__, "metastore_id", metastore_id)
        if name is not None:
            pulumi.set(__self__, "name", name)
        if owner is not None:
            pulumi.set(__self__, "owner", owner)
        if read_only is not None:
            pulumi.set(__self__, "read_only", read_only)
        if updated_at is not None:
            pulumi.set(__self__, "updated_at", updated_at)
        if updated_by is not None:
            pulumi.set(__self__, "updated_by", updated_by)
        if used_for_managed_storage is not None:
            pulumi.set(__self__, "used_for_managed_storage", used_for_managed_storage)

    @property
    @pulumi.getter(name="awsIamRole")
    def aws_iam_role(self) -> Optional['outputs.GetStorageCredentialStorageCredentialInfoAwsIamRoleResult']:
        return pulumi.get(self, "aws_iam_role")

    @property
    @pulumi.getter(name="azureManagedIdentity")
    def azure_managed_identity(self) -> Optional['outputs.GetStorageCredentialStorageCredentialInfoAzureManagedIdentityResult']:
        return pulumi.get(self, "azure_managed_identity")

    @property
    @pulumi.getter(name="azureServicePrincipal")
    def azure_service_principal(self) -> Optional['outputs.GetStorageCredentialStorageCredentialInfoAzureServicePrincipalResult']:
        return pulumi.get(self, "azure_service_principal")

    @property
    @pulumi.getter(name="cloudflareApiToken")
    def cloudflare_api_token(self) -> Optional['outputs.GetStorageCredentialStorageCredentialInfoCloudflareApiTokenResult']:
        return pulumi.get(self, "cloudflare_api_token")

    @property
    @pulumi.getter
    def comment(self) -> Optional[str]:
        return pulumi.get(self, "comment")

    @property
    @pulumi.getter(name="createdAt")
    def created_at(self) -> Optional[int]:
        return pulumi.get(self, "created_at")

    @property
    @pulumi.getter(name="createdBy")
    def created_by(self) -> Optional[str]:
        return pulumi.get(self, "created_by")

    @property
    @pulumi.getter(name="databricksGcpServiceAccount")
    def databricks_gcp_service_account(self) -> Optional['outputs.GetStorageCredentialStorageCredentialInfoDatabricksGcpServiceAccountResult']:
        return pulumi.get(self, "databricks_gcp_service_account")

    @property
    @pulumi.getter
    def id(self) -> Optional[str]:
        return pulumi.get(self, "id")

    @property
    @pulumi.getter(name="metastoreId")
    def metastore_id(self) -> Optional[str]:
        """
        Unique identifier of the parent Metastore.
        """
        return pulumi.get(self, "metastore_id")

    @property
    @pulumi.getter
    def name(self) -> Optional[str]:
        """
        The name of the storage credential
        """
        return pulumi.get(self, "name")

    @property
    @pulumi.getter
    def owner(self) -> Optional[str]:
        """
        Username/groupname/sp application_id of the storage credential owner.
        """
        return pulumi.get(self, "owner")

    @property
    @pulumi.getter(name="readOnly")
    def read_only(self) -> Optional[bool]:
        """
        Indicates whether the storage credential is only usable for read operations.
        """
        return pulumi.get(self, "read_only")

    @property
    @pulumi.getter(name="updatedAt")
    def updated_at(self) -> Optional[int]:
        return pulumi.get(self, "updated_at")

    @property
    @pulumi.getter(name="updatedBy")
    def updated_by(self) -> Optional[str]:
        return pulumi.get(self, "updated_by")

    @property
    @pulumi.getter(name="usedForManagedStorage")
    def used_for_managed_storage(self) -> Optional[bool]:
        return pulumi.get(self, "used_for_managed_storage")


@pulumi.output_type
class GetStorageCredentialStorageCredentialInfoAwsIamRoleResult(dict):
    def __init__(__self__, *,
                 role_arn: str,
                 external_id: Optional[str] = None,
                 unity_catalog_iam_arn: Optional[str] = None):
        """
        :param str role_arn: The Amazon Resource Name (ARN) of the AWS IAM role for S3 data access, of the form `arn:aws:iam::1234567890:role/MyRole-AJJHDSKSDF`
        :param str external_id: (output only) - The external ID used in role assumption to prevent confused deputy problem.
        :param str unity_catalog_iam_arn: (output only) - The Amazon Resource Name (ARN) of the AWS IAM user managed by Databricks. This is the identity that is going to assume the AWS IAM role.
        """
        pulumi.set(__self__, "role_arn", role_arn)
        if external_id is not None:
            pulumi.set(__self__, "external_id", external_id)
        if unity_catalog_iam_arn is not None:
            pulumi.set(__self__, "unity_catalog_iam_arn", unity_catalog_iam_arn)

    @property
    @pulumi.getter(name="roleArn")
    def role_arn(self) -> str:
        """
        The Amazon Resource Name (ARN) of the AWS IAM role for S3 data access, of the form `arn:aws:iam::1234567890:role/MyRole-AJJHDSKSDF`
        """
        return pulumi.get(self, "role_arn")

    @property
    @pulumi.getter(name="externalId")
    def external_id(self) -> Optional[str]:
        """
        (output only) - The external ID used in role assumption to prevent confused deputy problem.
        """
        return pulumi.get(self, "external_id")

    @property
    @pulumi.getter(name="unityCatalogIamArn")
    def unity_catalog_iam_arn(self) -> Optional[str]:
        """
        (output only) - The Amazon Resource Name (ARN) of the AWS IAM user managed by Databricks. This is the identity that is going to assume the AWS IAM role.
        """
        return pulumi.get(self, "unity_catalog_iam_arn")


@pulumi.output_type
class GetStorageCredentialStorageCredentialInfoAzureManagedIdentityResult(dict):
    def __init__(__self__, *,
                 access_connector_id: str,
                 credential_id: Optional[str] = None,
                 managed_identity_id: Optional[str] = None):
        """
        :param str access_connector_id: The Resource ID of the Azure Databricks Access Connector resource, of the form `/subscriptions/00000000-0000-0000-0000-000000000000/resourceGroups/rg-name/providers/Microsoft.Databricks/accessConnectors/connector-name`.
        :param str managed_identity_id: The Resource ID of the Azure User Assigned Managed Identity associated with Azure Databricks Access Connector, of the form `/subscriptions/00000000-0000-0000-0000-000000000000/resourceGroups/rg-name/providers/Microsoft.ManagedIdentity/userAssignedIdentities/user-managed-identity-name`.
        """
        pulumi.set(__self__, "access_connector_id", access_connector_id)
        if credential_id is not None:
            pulumi.set(__self__, "credential_id", credential_id)
        if managed_identity_id is not None:
            pulumi.set(__self__, "managed_identity_id", managed_identity_id)

    @property
    @pulumi.getter(name="accessConnectorId")
    def access_connector_id(self) -> str:
        """
        The Resource ID of the Azure Databricks Access Connector resource, of the form `/subscriptions/00000000-0000-0000-0000-000000000000/resourceGroups/rg-name/providers/Microsoft.Databricks/accessConnectors/connector-name`.
        """
        return pulumi.get(self, "access_connector_id")

    @property
    @pulumi.getter(name="credentialId")
    def credential_id(self) -> Optional[str]:
        return pulumi.get(self, "credential_id")

    @property
    @pulumi.getter(name="managedIdentityId")
    def managed_identity_id(self) -> Optional[str]:
        """
        The Resource ID of the Azure User Assigned Managed Identity associated with Azure Databricks Access Connector, of the form `/subscriptions/00000000-0000-0000-0000-000000000000/resourceGroups/rg-name/providers/Microsoft.ManagedIdentity/userAssignedIdentities/user-managed-identity-name`.
        """
        return pulumi.get(self, "managed_identity_id")


@pulumi.output_type
class GetStorageCredentialStorageCredentialInfoAzureServicePrincipalResult(dict):
    def __init__(__self__, *,
                 application_id: str,
                 client_secret: str,
                 directory_id: str):
        """
        :param str application_id: The application ID of the application registration within the referenced AAD tenant
        :param str directory_id: The directory ID corresponding to the Azure Active Directory (AAD) tenant of the application
        """
        pulumi.set(__self__, "application_id", application_id)
        pulumi.set(__self__, "client_secret", client_secret)
        pulumi.set(__self__, "directory_id", directory_id)

    @property
    @pulumi.getter(name="applicationId")
    def application_id(self) -> str:
        """
        The application ID of the application registration within the referenced AAD tenant
        """
        return pulumi.get(self, "application_id")

    @property
    @pulumi.getter(name="clientSecret")
    def client_secret(self) -> str:
        return pulumi.get(self, "client_secret")

    @property
    @pulumi.getter(name="directoryId")
    def directory_id(self) -> str:
        """
        The directory ID corresponding to the Azure Active Directory (AAD) tenant of the application
        """
        return pulumi.get(self, "directory_id")


@pulumi.output_type
class GetStorageCredentialStorageCredentialInfoCloudflareApiTokenResult(dict):
    def __init__(__self__, *,
                 access_key_id: str,
                 account_id: str,
                 secret_access_key: str):
        pulumi.set(__self__, "access_key_id", access_key_id)
        pulumi.set(__self__, "account_id", account_id)
        pulumi.set(__self__, "secret_access_key", secret_access_key)

    @property
    @pulumi.getter(name="accessKeyId")
    def access_key_id(self) -> str:
        return pulumi.get(self, "access_key_id")

    @property
    @pulumi.getter(name="accountId")
    def account_id(self) -> str:
        return pulumi.get(self, "account_id")

    @property
    @pulumi.getter(name="secretAccessKey")
    def secret_access_key(self) -> str:
        return pulumi.get(self, "secret_access_key")


@pulumi.output_type
class GetStorageCredentialStorageCredentialInfoDatabricksGcpServiceAccountResult(dict):
    def __init__(__self__, *,
                 credential_id: Optional[str] = None,
                 email: Optional[str] = None):
        """
        :param str email: The email of the GCP service account created, to be granted access to relevant buckets.
        """
        if credential_id is not None:
            pulumi.set(__self__, "credential_id", credential_id)
        if email is not None:
            pulumi.set(__self__, "email", email)

    @property
    @pulumi.getter(name="credentialId")
    def credential_id(self) -> Optional[str]:
        return pulumi.get(self, "credential_id")

    @property
    @pulumi.getter
    def email(self) -> Optional[str]:
        """
        The email of the GCP service account created, to be granted access to relevant buckets.
        """
        return pulumi.get(self, "email")


