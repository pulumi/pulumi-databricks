# coding=utf-8
# *** WARNING: this file was generated by the Pulumi Terraform Bridge (tfgen) Tool. ***
# *** Do not edit by hand unless you're certain you know what you are doing! ***

import copy
import warnings
import pulumi
import pulumi.runtime
from typing import Any, Mapping, Optional, Sequence, Union, overload
from . import _utilities
from . import outputs

__all__ = [
    'AccessControlRuleSetGrantRule',
    'ArtifactAllowlistArtifactMatcher',
    'AutomaticClusterUpdateWorkspaceSettingAutomaticClusterUpdateWorkspace',
    'AutomaticClusterUpdateWorkspaceSettingAutomaticClusterUpdateWorkspaceEnablementDetails',
    'AutomaticClusterUpdateWorkspaceSettingAutomaticClusterUpdateWorkspaceMaintenanceWindow',
    'AutomaticClusterUpdateWorkspaceSettingAutomaticClusterUpdateWorkspaceMaintenanceWindowWeekDayBasedSchedule',
    'AutomaticClusterUpdateWorkspaceSettingAutomaticClusterUpdateWorkspaceMaintenanceWindowWeekDayBasedScheduleWindowStartTime',
    'ClusterAutoscale',
    'ClusterAwsAttributes',
    'ClusterAzureAttributes',
    'ClusterAzureAttributesLogAnalyticsInfo',
    'ClusterClusterLogConf',
    'ClusterClusterLogConfDbfs',
    'ClusterClusterLogConfS3',
    'ClusterClusterMountInfo',
    'ClusterClusterMountInfoNetworkFilesystemInfo',
    'ClusterDockerImage',
    'ClusterDockerImageBasicAuth',
    'ClusterGcpAttributes',
    'ClusterInitScript',
    'ClusterInitScriptAbfss',
    'ClusterInitScriptDbfs',
    'ClusterInitScriptFile',
    'ClusterInitScriptGcs',
    'ClusterInitScriptS3',
    'ClusterInitScriptVolumes',
    'ClusterInitScriptWorkspace',
    'ClusterLibrary',
    'ClusterLibraryCran',
    'ClusterLibraryMaven',
    'ClusterLibraryPypi',
    'ClusterPolicyLibrary',
    'ClusterPolicyLibraryCran',
    'ClusterPolicyLibraryMaven',
    'ClusterPolicyLibraryPypi',
    'ClusterWorkloadType',
    'ClusterWorkloadTypeClients',
    'ComplianceSecurityProfileWorkspaceSettingComplianceSecurityProfileWorkspace',
    'DefaultNamespaceSettingNamespace',
    'EnhancedSecurityMonitoringWorkspaceSettingEnhancedSecurityMonitoringWorkspace',
    'ExternalLocationEncryptionDetails',
    'ExternalLocationEncryptionDetailsSseEncryptionDetails',
    'GrantsGrant',
    'InstancePoolAwsAttributes',
    'InstancePoolAzureAttributes',
    'InstancePoolDiskSpec',
    'InstancePoolDiskSpecDiskType',
    'InstancePoolGcpAttributes',
    'InstancePoolInstancePoolFleetAttributes',
    'InstancePoolInstancePoolFleetAttributesFleetOnDemandOption',
    'InstancePoolInstancePoolFleetAttributesFleetSpotOption',
    'InstancePoolInstancePoolFleetAttributesLaunchTemplateOverride',
    'InstancePoolPreloadedDockerImage',
    'InstancePoolPreloadedDockerImageBasicAuth',
    'JobContinuous',
    'JobDbtTask',
    'JobDeployment',
    'JobEmailNotifications',
    'JobEnvironment',
    'JobEnvironmentSpec',
    'JobGitSource',
    'JobGitSourceGitSnapshot',
    'JobGitSourceJobSource',
    'JobHealth',
    'JobHealthRule',
    'JobJobCluster',
    'JobJobClusterNewCluster',
    'JobJobClusterNewClusterAutoscale',
    'JobJobClusterNewClusterAwsAttributes',
    'JobJobClusterNewClusterAzureAttributes',
    'JobJobClusterNewClusterAzureAttributesLogAnalyticsInfo',
    'JobJobClusterNewClusterClusterLogConf',
    'JobJobClusterNewClusterClusterLogConfDbfs',
    'JobJobClusterNewClusterClusterLogConfS3',
    'JobJobClusterNewClusterClusterMountInfo',
    'JobJobClusterNewClusterClusterMountInfoNetworkFilesystemInfo',
    'JobJobClusterNewClusterDockerImage',
    'JobJobClusterNewClusterDockerImageBasicAuth',
    'JobJobClusterNewClusterGcpAttributes',
    'JobJobClusterNewClusterInitScript',
    'JobJobClusterNewClusterInitScriptAbfss',
    'JobJobClusterNewClusterInitScriptDbfs',
    'JobJobClusterNewClusterInitScriptFile',
    'JobJobClusterNewClusterInitScriptGcs',
    'JobJobClusterNewClusterInitScriptS3',
    'JobJobClusterNewClusterInitScriptVolumes',
    'JobJobClusterNewClusterInitScriptWorkspace',
    'JobJobClusterNewClusterLibrary',
    'JobJobClusterNewClusterLibraryCran',
    'JobJobClusterNewClusterLibraryMaven',
    'JobJobClusterNewClusterLibraryPypi',
    'JobJobClusterNewClusterWorkloadType',
    'JobJobClusterNewClusterWorkloadTypeClients',
    'JobLibrary',
    'JobLibraryCran',
    'JobLibraryMaven',
    'JobLibraryPypi',
    'JobNewCluster',
    'JobNewClusterAutoscale',
    'JobNewClusterAwsAttributes',
    'JobNewClusterAzureAttributes',
    'JobNewClusterAzureAttributesLogAnalyticsInfo',
    'JobNewClusterClusterLogConf',
    'JobNewClusterClusterLogConfDbfs',
    'JobNewClusterClusterLogConfS3',
    'JobNewClusterClusterMountInfo',
    'JobNewClusterClusterMountInfoNetworkFilesystemInfo',
    'JobNewClusterDockerImage',
    'JobNewClusterDockerImageBasicAuth',
    'JobNewClusterGcpAttributes',
    'JobNewClusterInitScript',
    'JobNewClusterInitScriptAbfss',
    'JobNewClusterInitScriptDbfs',
    'JobNewClusterInitScriptFile',
    'JobNewClusterInitScriptGcs',
    'JobNewClusterInitScriptS3',
    'JobNewClusterInitScriptVolumes',
    'JobNewClusterInitScriptWorkspace',
    'JobNewClusterLibrary',
    'JobNewClusterLibraryCran',
    'JobNewClusterLibraryMaven',
    'JobNewClusterLibraryPypi',
    'JobNewClusterWorkloadType',
    'JobNewClusterWorkloadTypeClients',
    'JobNotebookTask',
    'JobNotificationSettings',
    'JobParameter',
    'JobPipelineTask',
    'JobPythonWheelTask',
    'JobQueue',
    'JobRunAs',
    'JobRunJobTask',
    'JobSchedule',
    'JobSparkJarTask',
    'JobSparkPythonTask',
    'JobSparkSubmitTask',
    'JobTask',
    'JobTaskConditionTask',
    'JobTaskDbtTask',
    'JobTaskDependsOn',
    'JobTaskEmailNotifications',
    'JobTaskForEachTask',
    'JobTaskForEachTaskTask',
    'JobTaskForEachTaskTaskConditionTask',
    'JobTaskForEachTaskTaskDbtTask',
    'JobTaskForEachTaskTaskDependsOn',
    'JobTaskForEachTaskTaskEmailNotifications',
    'JobTaskForEachTaskTaskHealth',
    'JobTaskForEachTaskTaskHealthRule',
    'JobTaskForEachTaskTaskLibrary',
    'JobTaskForEachTaskTaskLibraryCran',
    'JobTaskForEachTaskTaskLibraryMaven',
    'JobTaskForEachTaskTaskLibraryPypi',
    'JobTaskForEachTaskTaskNewCluster',
    'JobTaskForEachTaskTaskNewClusterAutoscale',
    'JobTaskForEachTaskTaskNewClusterAwsAttributes',
    'JobTaskForEachTaskTaskNewClusterAzureAttributes',
    'JobTaskForEachTaskTaskNewClusterAzureAttributesLogAnalyticsInfo',
    'JobTaskForEachTaskTaskNewClusterClusterLogConf',
    'JobTaskForEachTaskTaskNewClusterClusterLogConfDbfs',
    'JobTaskForEachTaskTaskNewClusterClusterLogConfS3',
    'JobTaskForEachTaskTaskNewClusterClusterMountInfo',
    'JobTaskForEachTaskTaskNewClusterClusterMountInfoNetworkFilesystemInfo',
    'JobTaskForEachTaskTaskNewClusterDockerImage',
    'JobTaskForEachTaskTaskNewClusterDockerImageBasicAuth',
    'JobTaskForEachTaskTaskNewClusterGcpAttributes',
    'JobTaskForEachTaskTaskNewClusterInitScript',
    'JobTaskForEachTaskTaskNewClusterInitScriptAbfss',
    'JobTaskForEachTaskTaskNewClusterInitScriptDbfs',
    'JobTaskForEachTaskTaskNewClusterInitScriptFile',
    'JobTaskForEachTaskTaskNewClusterInitScriptGcs',
    'JobTaskForEachTaskTaskNewClusterInitScriptS3',
    'JobTaskForEachTaskTaskNewClusterInitScriptVolumes',
    'JobTaskForEachTaskTaskNewClusterInitScriptWorkspace',
    'JobTaskForEachTaskTaskNewClusterLibrary',
    'JobTaskForEachTaskTaskNewClusterLibraryCran',
    'JobTaskForEachTaskTaskNewClusterLibraryMaven',
    'JobTaskForEachTaskTaskNewClusterLibraryPypi',
    'JobTaskForEachTaskTaskNewClusterWorkloadType',
    'JobTaskForEachTaskTaskNewClusterWorkloadTypeClients',
    'JobTaskForEachTaskTaskNotebookTask',
    'JobTaskForEachTaskTaskNotificationSettings',
    'JobTaskForEachTaskTaskPipelineTask',
    'JobTaskForEachTaskTaskPythonWheelTask',
    'JobTaskForEachTaskTaskRunJobTask',
    'JobTaskForEachTaskTaskRunJobTaskPipelineParams',
    'JobTaskForEachTaskTaskSparkJarTask',
    'JobTaskForEachTaskTaskSparkPythonTask',
    'JobTaskForEachTaskTaskSparkSubmitTask',
    'JobTaskForEachTaskTaskSqlTask',
    'JobTaskForEachTaskTaskSqlTaskAlert',
    'JobTaskForEachTaskTaskSqlTaskAlertSubscription',
    'JobTaskForEachTaskTaskSqlTaskDashboard',
    'JobTaskForEachTaskTaskSqlTaskDashboardSubscription',
    'JobTaskForEachTaskTaskSqlTaskFile',
    'JobTaskForEachTaskTaskSqlTaskQuery',
    'JobTaskForEachTaskTaskWebhookNotifications',
    'JobTaskForEachTaskTaskWebhookNotificationsOnDurationWarningThresholdExceeded',
    'JobTaskForEachTaskTaskWebhookNotificationsOnFailure',
    'JobTaskForEachTaskTaskWebhookNotificationsOnStart',
    'JobTaskForEachTaskTaskWebhookNotificationsOnStreamingBacklogExceeded',
    'JobTaskForEachTaskTaskWebhookNotificationsOnSuccess',
    'JobTaskHealth',
    'JobTaskHealthRule',
    'JobTaskLibrary',
    'JobTaskLibraryCran',
    'JobTaskLibraryMaven',
    'JobTaskLibraryPypi',
    'JobTaskNewCluster',
    'JobTaskNewClusterAutoscale',
    'JobTaskNewClusterAwsAttributes',
    'JobTaskNewClusterAzureAttributes',
    'JobTaskNewClusterAzureAttributesLogAnalyticsInfo',
    'JobTaskNewClusterClusterLogConf',
    'JobTaskNewClusterClusterLogConfDbfs',
    'JobTaskNewClusterClusterLogConfS3',
    'JobTaskNewClusterClusterMountInfo',
    'JobTaskNewClusterClusterMountInfoNetworkFilesystemInfo',
    'JobTaskNewClusterDockerImage',
    'JobTaskNewClusterDockerImageBasicAuth',
    'JobTaskNewClusterGcpAttributes',
    'JobTaskNewClusterInitScript',
    'JobTaskNewClusterInitScriptAbfss',
    'JobTaskNewClusterInitScriptDbfs',
    'JobTaskNewClusterInitScriptFile',
    'JobTaskNewClusterInitScriptGcs',
    'JobTaskNewClusterInitScriptS3',
    'JobTaskNewClusterInitScriptVolumes',
    'JobTaskNewClusterInitScriptWorkspace',
    'JobTaskNewClusterLibrary',
    'JobTaskNewClusterLibraryCran',
    'JobTaskNewClusterLibraryMaven',
    'JobTaskNewClusterLibraryPypi',
    'JobTaskNewClusterWorkloadType',
    'JobTaskNewClusterWorkloadTypeClients',
    'JobTaskNotebookTask',
    'JobTaskNotificationSettings',
    'JobTaskPipelineTask',
    'JobTaskPythonWheelTask',
    'JobTaskRunJobTask',
    'JobTaskRunJobTaskPipelineParams',
    'JobTaskSparkJarTask',
    'JobTaskSparkPythonTask',
    'JobTaskSparkSubmitTask',
    'JobTaskSqlTask',
    'JobTaskSqlTaskAlert',
    'JobTaskSqlTaskAlertSubscription',
    'JobTaskSqlTaskDashboard',
    'JobTaskSqlTaskDashboardSubscription',
    'JobTaskSqlTaskFile',
    'JobTaskSqlTaskQuery',
    'JobTaskWebhookNotifications',
    'JobTaskWebhookNotificationsOnDurationWarningThresholdExceeded',
    'JobTaskWebhookNotificationsOnFailure',
    'JobTaskWebhookNotificationsOnStart',
    'JobTaskWebhookNotificationsOnStreamingBacklogExceeded',
    'JobTaskWebhookNotificationsOnSuccess',
    'JobTrigger',
    'JobTriggerFileArrival',
    'JobTriggerPeriodic',
    'JobTriggerTable',
    'JobTriggerTableUpdate',
    'JobWebhookNotifications',
    'JobWebhookNotificationsOnDurationWarningThresholdExceeded',
    'JobWebhookNotificationsOnFailure',
    'JobWebhookNotificationsOnStart',
    'JobWebhookNotificationsOnStreamingBacklogExceeded',
    'JobWebhookNotificationsOnSuccess',
    'LakehouseMonitorCustomMetric',
    'LakehouseMonitorDataClassificationConfig',
    'LakehouseMonitorInferenceLog',
    'LakehouseMonitorNotifications',
    'LakehouseMonitorNotificationsOnFailure',
    'LakehouseMonitorNotificationsOnNewClassificationTagDetected',
    'LakehouseMonitorSchedule',
    'LakehouseMonitorSnapshot',
    'LakehouseMonitorTimeSeries',
    'LibraryCran',
    'LibraryMaven',
    'LibraryPypi',
    'MetastoreDataAccessAwsIamRole',
    'MetastoreDataAccessAzureManagedIdentity',
    'MetastoreDataAccessAzureServicePrincipal',
    'MetastoreDataAccessCloudflareApiToken',
    'MetastoreDataAccessDatabricksGcpServiceAccount',
    'MetastoreDataAccessGcpServiceAccountKey',
    'MlflowModelTag',
    'MlflowWebhookHttpUrlSpec',
    'MlflowWebhookJobSpec',
    'ModelServingConfig',
    'ModelServingConfigAutoCaptureConfig',
    'ModelServingConfigServedEntity',
    'ModelServingConfigServedEntityExternalModel',
    'ModelServingConfigServedEntityExternalModelAi21labsConfig',
    'ModelServingConfigServedEntityExternalModelAmazonBedrockConfig',
    'ModelServingConfigServedEntityExternalModelAnthropicConfig',
    'ModelServingConfigServedEntityExternalModelCohereConfig',
    'ModelServingConfigServedEntityExternalModelDatabricksModelServingConfig',
    'ModelServingConfigServedEntityExternalModelGoogleCloudVertexAiConfig',
    'ModelServingConfigServedEntityExternalModelOpenaiConfig',
    'ModelServingConfigServedEntityExternalModelPalmConfig',
    'ModelServingConfigServedModel',
    'ModelServingConfigTrafficConfig',
    'ModelServingConfigTrafficConfigRoute',
    'ModelServingRateLimit',
    'ModelServingTag',
    'MountAbfs',
    'MountAdl',
    'MountGs',
    'MountS3',
    'MountWasb',
    'MwsCustomerManagedKeysAwsKeyInfo',
    'MwsCustomerManagedKeysGcpKeyInfo',
    'MwsNetworkConnectivityConfigEgressConfig',
    'MwsNetworkConnectivityConfigEgressConfigDefaultRules',
    'MwsNetworkConnectivityConfigEgressConfigDefaultRulesAwsStableIpRule',
    'MwsNetworkConnectivityConfigEgressConfigDefaultRulesAzureServiceEndpointRule',
    'MwsNetworkConnectivityConfigEgressConfigTargetRules',
    'MwsNetworkConnectivityConfigEgressConfigTargetRulesAzurePrivateEndpointRule',
    'MwsNetworksErrorMessage',
    'MwsNetworksGcpNetworkInfo',
    'MwsNetworksVpcEndpoints',
    'MwsVpcEndpointGcpVpcEndpointInfo',
    'MwsWorkspacesCloudResourceContainer',
    'MwsWorkspacesCloudResourceContainerGcp',
    'MwsWorkspacesExternalCustomerInfo',
    'MwsWorkspacesGcpManagedNetworkConfig',
    'MwsWorkspacesGkeConfig',
    'MwsWorkspacesToken',
    'NotificationDestinationConfig',
    'NotificationDestinationConfigEmail',
    'NotificationDestinationConfigGenericWebhook',
    'NotificationDestinationConfigMicrosoftTeams',
    'NotificationDestinationConfigPagerduty',
    'NotificationDestinationConfigSlack',
    'OnlineTableSpec',
    'OnlineTableSpecRunContinuously',
    'OnlineTableSpecRunTriggered',
    'OnlineTableStatus',
    'OnlineTableStatusContinuousUpdateStatus',
    'OnlineTableStatusContinuousUpdateStatusInitialPipelineSyncProgress',
    'OnlineTableStatusFailedStatus',
    'OnlineTableStatusProvisioningStatus',
    'OnlineTableStatusProvisioningStatusInitialPipelineSyncProgress',
    'OnlineTableStatusTriggeredUpdateStatus',
    'OnlineTableStatusTriggeredUpdateStatusTriggeredUpdateProgress',
    'PermissionsAccessControl',
    'PipelineCluster',
    'PipelineClusterAutoscale',
    'PipelineClusterAwsAttributes',
    'PipelineClusterAzureAttributes',
    'PipelineClusterAzureAttributesLogAnalyticsInfo',
    'PipelineClusterClusterLogConf',
    'PipelineClusterClusterLogConfDbfs',
    'PipelineClusterClusterLogConfS3',
    'PipelineClusterGcpAttributes',
    'PipelineClusterInitScript',
    'PipelineClusterInitScriptAbfss',
    'PipelineClusterInitScriptDbfs',
    'PipelineClusterInitScriptFile',
    'PipelineClusterInitScriptGcs',
    'PipelineClusterInitScriptS3',
    'PipelineClusterInitScriptVolumes',
    'PipelineClusterInitScriptWorkspace',
    'PipelineDeployment',
    'PipelineFilters',
    'PipelineGatewayDefinition',
    'PipelineIngestionDefinition',
    'PipelineIngestionDefinitionObject',
    'PipelineIngestionDefinitionObjectSchema',
    'PipelineIngestionDefinitionObjectSchemaTableConfiguration',
    'PipelineIngestionDefinitionObjectTable',
    'PipelineIngestionDefinitionObjectTableTableConfiguration',
    'PipelineIngestionDefinitionTableConfiguration',
    'PipelineLatestUpdate',
    'PipelineLibrary',
    'PipelineLibraryFile',
    'PipelineLibraryMaven',
    'PipelineLibraryNotebook',
    'PipelineNotification',
    'PipelineTrigger',
    'PipelineTriggerCron',
    'PipelineTriggerManual',
    'QualityMonitorCustomMetric',
    'QualityMonitorDataClassificationConfig',
    'QualityMonitorInferenceLog',
    'QualityMonitorNotifications',
    'QualityMonitorNotificationsOnFailure',
    'QualityMonitorNotificationsOnNewClassificationTagDetected',
    'QualityMonitorSchedule',
    'QualityMonitorSnapshot',
    'QualityMonitorTimeSeries',
    'RecipientIpAccessList',
    'RecipientPropertiesKvpairs',
    'RecipientToken',
    'RepoSparseCheckout',
    'RestrictWorkspaceAdminsSettingRestrictWorkspaceAdmins',
    'SecretScopeKeyvaultMetadata',
    'ShareObject',
    'ShareObjectPartition',
    'ShareObjectPartitionValue',
    'SqlAlertOptions',
    'SqlEndpointChannel',
    'SqlEndpointHealth',
    'SqlEndpointHealthFailureReason',
    'SqlEndpointOdbcParams',
    'SqlEndpointTags',
    'SqlEndpointTagsCustomTag',
    'SqlPermissionsPrivilegeAssignment',
    'SqlQueryParameter',
    'SqlQueryParameterDate',
    'SqlQueryParameterDateRange',
    'SqlQueryParameterDateRangeRange',
    'SqlQueryParameterDatetime',
    'SqlQueryParameterDatetimeRange',
    'SqlQueryParameterDatetimeRangeRange',
    'SqlQueryParameterDatetimesec',
    'SqlQueryParameterDatetimesecRange',
    'SqlQueryParameterDatetimesecRangeRange',
    'SqlQueryParameterEnum',
    'SqlQueryParameterEnumMultiple',
    'SqlQueryParameterNumber',
    'SqlQueryParameterQuery',
    'SqlQueryParameterQueryMultiple',
    'SqlQueryParameterText',
    'SqlQuerySchedule',
    'SqlQueryScheduleContinuous',
    'SqlQueryScheduleDaily',
    'SqlQueryScheduleWeekly',
    'SqlTableColumn',
    'SqlWidgetParameter',
    'SqlWidgetPosition',
    'StorageCredentialAwsIamRole',
    'StorageCredentialAzureManagedIdentity',
    'StorageCredentialAzureServicePrincipal',
    'StorageCredentialCloudflareApiToken',
    'StorageCredentialDatabricksGcpServiceAccount',
    'StorageCredentialGcpServiceAccountKey',
    'TableColumn',
    'VectorSearchEndpointEndpointStatus',
    'VectorSearchIndexDeltaSyncIndexSpec',
    'VectorSearchIndexDeltaSyncIndexSpecEmbeddingSourceColumn',
    'VectorSearchIndexDeltaSyncIndexSpecEmbeddingVectorColumn',
    'VectorSearchIndexDirectAccessIndexSpec',
    'VectorSearchIndexDirectAccessIndexSpecEmbeddingSourceColumn',
    'VectorSearchIndexDirectAccessIndexSpecEmbeddingVectorColumn',
    'VectorSearchIndexStatus',
    'GetCatalogCatalogInfoResult',
    'GetCatalogCatalogInfoEffectivePredictiveOptimizationFlagResult',
    'GetCatalogCatalogInfoProvisioningInfoResult',
    'GetClusterClusterInfoResult',
    'GetClusterClusterInfoAutoscaleResult',
    'GetClusterClusterInfoAwsAttributesResult',
    'GetClusterClusterInfoAzureAttributesResult',
    'GetClusterClusterInfoAzureAttributesLogAnalyticsInfoResult',
    'GetClusterClusterInfoClusterLogConfResult',
    'GetClusterClusterInfoClusterLogConfDbfsResult',
    'GetClusterClusterInfoClusterLogConfS3Result',
    'GetClusterClusterInfoClusterLogStatusResult',
    'GetClusterClusterInfoDockerImageResult',
    'GetClusterClusterInfoDockerImageBasicAuthResult',
    'GetClusterClusterInfoDriverResult',
    'GetClusterClusterInfoDriverNodeAwsAttributesResult',
    'GetClusterClusterInfoExecutorResult',
    'GetClusterClusterInfoExecutorNodeAwsAttributesResult',
    'GetClusterClusterInfoGcpAttributesResult',
    'GetClusterClusterInfoInitScriptResult',
    'GetClusterClusterInfoInitScriptAbfssResult',
    'GetClusterClusterInfoInitScriptDbfsResult',
    'GetClusterClusterInfoInitScriptFileResult',
    'GetClusterClusterInfoInitScriptGcsResult',
    'GetClusterClusterInfoInitScriptS3Result',
    'GetClusterClusterInfoInitScriptVolumesResult',
    'GetClusterClusterInfoInitScriptWorkspaceResult',
    'GetClusterClusterInfoSpecResult',
    'GetClusterClusterInfoSpecAutoscaleResult',
    'GetClusterClusterInfoSpecAwsAttributesResult',
    'GetClusterClusterInfoSpecAzureAttributesResult',
    'GetClusterClusterInfoSpecAzureAttributesLogAnalyticsInfoResult',
    'GetClusterClusterInfoSpecClusterLogConfResult',
    'GetClusterClusterInfoSpecClusterLogConfDbfsResult',
    'GetClusterClusterInfoSpecClusterLogConfS3Result',
    'GetClusterClusterInfoSpecClusterMountInfoResult',
    'GetClusterClusterInfoSpecClusterMountInfoNetworkFilesystemInfoResult',
    'GetClusterClusterInfoSpecDockerImageResult',
    'GetClusterClusterInfoSpecDockerImageBasicAuthResult',
    'GetClusterClusterInfoSpecGcpAttributesResult',
    'GetClusterClusterInfoSpecInitScriptResult',
    'GetClusterClusterInfoSpecInitScriptAbfssResult',
    'GetClusterClusterInfoSpecInitScriptDbfsResult',
    'GetClusterClusterInfoSpecInitScriptFileResult',
    'GetClusterClusterInfoSpecInitScriptGcsResult',
    'GetClusterClusterInfoSpecInitScriptS3Result',
    'GetClusterClusterInfoSpecInitScriptVolumesResult',
    'GetClusterClusterInfoSpecInitScriptWorkspaceResult',
    'GetClusterClusterInfoSpecLibraryResult',
    'GetClusterClusterInfoSpecLibraryCranResult',
    'GetClusterClusterInfoSpecLibraryMavenResult',
    'GetClusterClusterInfoSpecLibraryPypiResult',
    'GetClusterClusterInfoSpecWorkloadTypeResult',
    'GetClusterClusterInfoSpecWorkloadTypeClientsResult',
    'GetClusterClusterInfoTerminationReasonResult',
    'GetClusterClusterInfoWorkloadTypeResult',
    'GetClusterClusterInfoWorkloadTypeClientsResult',
    'GetCurrentMetastoreMetastoreInfoResult',
    'GetDbfsFilePathsPathListResult',
    'GetExternalLocationExternalLocationInfoResult',
    'GetExternalLocationExternalLocationInfoEncryptionDetailsResult',
    'GetExternalLocationExternalLocationInfoEncryptionDetailsSseEncryptionDetailsResult',
    'GetInstancePoolPoolInfoResult',
    'GetInstancePoolPoolInfoAwsAttributesResult',
    'GetInstancePoolPoolInfoAzureAttributesResult',
    'GetInstancePoolPoolInfoDiskSpecResult',
    'GetInstancePoolPoolInfoDiskSpecDiskTypeResult',
    'GetInstancePoolPoolInfoGcpAttributesResult',
    'GetInstancePoolPoolInfoInstancePoolFleetAttributeResult',
    'GetInstancePoolPoolInfoInstancePoolFleetAttributeFleetOnDemandOptionResult',
    'GetInstancePoolPoolInfoInstancePoolFleetAttributeFleetSpotOptionResult',
    'GetInstancePoolPoolInfoInstancePoolFleetAttributeLaunchTemplateOverrideResult',
    'GetInstancePoolPoolInfoPreloadedDockerImageResult',
    'GetInstancePoolPoolInfoPreloadedDockerImageBasicAuthResult',
    'GetInstancePoolPoolInfoStatsResult',
    'GetInstanceProfilesInstanceProfileResult',
    'GetJobJobSettingsResult',
    'GetJobJobSettingsSettingsResult',
    'GetJobJobSettingsSettingsContinuousResult',
    'GetJobJobSettingsSettingsDbtTaskResult',
    'GetJobJobSettingsSettingsDeploymentResult',
    'GetJobJobSettingsSettingsEmailNotificationsResult',
    'GetJobJobSettingsSettingsEnvironmentResult',
    'GetJobJobSettingsSettingsEnvironmentSpecResult',
    'GetJobJobSettingsSettingsGitSourceResult',
    'GetJobJobSettingsSettingsGitSourceJobSourceResult',
    'GetJobJobSettingsSettingsHealthResult',
    'GetJobJobSettingsSettingsHealthRuleResult',
    'GetJobJobSettingsSettingsJobClusterResult',
    'GetJobJobSettingsSettingsJobClusterNewClusterResult',
    'GetJobJobSettingsSettingsJobClusterNewClusterAutoscaleResult',
    'GetJobJobSettingsSettingsJobClusterNewClusterAwsAttributesResult',
    'GetJobJobSettingsSettingsJobClusterNewClusterAzureAttributesResult',
    'GetJobJobSettingsSettingsJobClusterNewClusterClusterLogConfResult',
    'GetJobJobSettingsSettingsJobClusterNewClusterClusterLogConfDbfsResult',
    'GetJobJobSettingsSettingsJobClusterNewClusterClusterLogConfS3Result',
    'GetJobJobSettingsSettingsJobClusterNewClusterClusterMountInfoResult',
    'GetJobJobSettingsSettingsJobClusterNewClusterClusterMountInfoNetworkFilesystemInfoResult',
    'GetJobJobSettingsSettingsJobClusterNewClusterDockerImageResult',
    'GetJobJobSettingsSettingsJobClusterNewClusterDockerImageBasicAuthResult',
    'GetJobJobSettingsSettingsJobClusterNewClusterGcpAttributesResult',
    'GetJobJobSettingsSettingsJobClusterNewClusterInitScriptResult',
    'GetJobJobSettingsSettingsJobClusterNewClusterInitScriptAbfssResult',
    'GetJobJobSettingsSettingsJobClusterNewClusterInitScriptDbfsResult',
    'GetJobJobSettingsSettingsJobClusterNewClusterInitScriptFileResult',
    'GetJobJobSettingsSettingsJobClusterNewClusterInitScriptGcsResult',
    'GetJobJobSettingsSettingsJobClusterNewClusterInitScriptS3Result',
    'GetJobJobSettingsSettingsJobClusterNewClusterInitScriptVolumesResult',
    'GetJobJobSettingsSettingsJobClusterNewClusterInitScriptWorkspaceResult',
    'GetJobJobSettingsSettingsJobClusterNewClusterWorkloadTypeResult',
    'GetJobJobSettingsSettingsJobClusterNewClusterWorkloadTypeClientsResult',
    'GetJobJobSettingsSettingsLibraryResult',
    'GetJobJobSettingsSettingsLibraryCranResult',
    'GetJobJobSettingsSettingsLibraryMavenResult',
    'GetJobJobSettingsSettingsLibraryPypiResult',
    'GetJobJobSettingsSettingsNewClusterResult',
    'GetJobJobSettingsSettingsNewClusterAutoscaleResult',
    'GetJobJobSettingsSettingsNewClusterAwsAttributesResult',
    'GetJobJobSettingsSettingsNewClusterAzureAttributesResult',
    'GetJobJobSettingsSettingsNewClusterClusterLogConfResult',
    'GetJobJobSettingsSettingsNewClusterClusterLogConfDbfsResult',
    'GetJobJobSettingsSettingsNewClusterClusterLogConfS3Result',
    'GetJobJobSettingsSettingsNewClusterClusterMountInfoResult',
    'GetJobJobSettingsSettingsNewClusterClusterMountInfoNetworkFilesystemInfoResult',
    'GetJobJobSettingsSettingsNewClusterDockerImageResult',
    'GetJobJobSettingsSettingsNewClusterDockerImageBasicAuthResult',
    'GetJobJobSettingsSettingsNewClusterGcpAttributesResult',
    'GetJobJobSettingsSettingsNewClusterInitScriptResult',
    'GetJobJobSettingsSettingsNewClusterInitScriptAbfssResult',
    'GetJobJobSettingsSettingsNewClusterInitScriptDbfsResult',
    'GetJobJobSettingsSettingsNewClusterInitScriptFileResult',
    'GetJobJobSettingsSettingsNewClusterInitScriptGcsResult',
    'GetJobJobSettingsSettingsNewClusterInitScriptS3Result',
    'GetJobJobSettingsSettingsNewClusterInitScriptVolumesResult',
    'GetJobJobSettingsSettingsNewClusterInitScriptWorkspaceResult',
    'GetJobJobSettingsSettingsNewClusterWorkloadTypeResult',
    'GetJobJobSettingsSettingsNewClusterWorkloadTypeClientsResult',
    'GetJobJobSettingsSettingsNotebookTaskResult',
    'GetJobJobSettingsSettingsNotificationSettingsResult',
    'GetJobJobSettingsSettingsParameterResult',
    'GetJobJobSettingsSettingsPipelineTaskResult',
    'GetJobJobSettingsSettingsPythonWheelTaskResult',
    'GetJobJobSettingsSettingsQueueResult',
    'GetJobJobSettingsSettingsRunAsResult',
    'GetJobJobSettingsSettingsRunJobTaskResult',
    'GetJobJobSettingsSettingsScheduleResult',
    'GetJobJobSettingsSettingsSparkJarTaskResult',
    'GetJobJobSettingsSettingsSparkPythonTaskResult',
    'GetJobJobSettingsSettingsSparkSubmitTaskResult',
    'GetJobJobSettingsSettingsTaskResult',
    'GetJobJobSettingsSettingsTaskConditionTaskResult',
    'GetJobJobSettingsSettingsTaskDbtTaskResult',
    'GetJobJobSettingsSettingsTaskDependsOnResult',
    'GetJobJobSettingsSettingsTaskEmailNotificationsResult',
    'GetJobJobSettingsSettingsTaskForEachTaskResult',
    'GetJobJobSettingsSettingsTaskForEachTaskTaskResult',
    'GetJobJobSettingsSettingsTaskForEachTaskTaskConditionTaskResult',
    'GetJobJobSettingsSettingsTaskForEachTaskTaskDbtTaskResult',
    'GetJobJobSettingsSettingsTaskForEachTaskTaskDependsOnResult',
    'GetJobJobSettingsSettingsTaskForEachTaskTaskEmailNotificationsResult',
    'GetJobJobSettingsSettingsTaskForEachTaskTaskHealthResult',
    'GetJobJobSettingsSettingsTaskForEachTaskTaskHealthRuleResult',
    'GetJobJobSettingsSettingsTaskForEachTaskTaskLibraryResult',
    'GetJobJobSettingsSettingsTaskForEachTaskTaskLibraryCranResult',
    'GetJobJobSettingsSettingsTaskForEachTaskTaskLibraryMavenResult',
    'GetJobJobSettingsSettingsTaskForEachTaskTaskLibraryPypiResult',
    'GetJobJobSettingsSettingsTaskForEachTaskTaskNewClusterResult',
    'GetJobJobSettingsSettingsTaskForEachTaskTaskNewClusterAutoscaleResult',
    'GetJobJobSettingsSettingsTaskForEachTaskTaskNewClusterAwsAttributesResult',
    'GetJobJobSettingsSettingsTaskForEachTaskTaskNewClusterAzureAttributesResult',
    'GetJobJobSettingsSettingsTaskForEachTaskTaskNewClusterClusterLogConfResult',
    'GetJobJobSettingsSettingsTaskForEachTaskTaskNewClusterClusterLogConfDbfsResult',
    'GetJobJobSettingsSettingsTaskForEachTaskTaskNewClusterClusterLogConfS3Result',
    'GetJobJobSettingsSettingsTaskForEachTaskTaskNewClusterClusterMountInfoResult',
    'GetJobJobSettingsSettingsTaskForEachTaskTaskNewClusterClusterMountInfoNetworkFilesystemInfoResult',
    'GetJobJobSettingsSettingsTaskForEachTaskTaskNewClusterDockerImageResult',
    'GetJobJobSettingsSettingsTaskForEachTaskTaskNewClusterDockerImageBasicAuthResult',
    'GetJobJobSettingsSettingsTaskForEachTaskTaskNewClusterGcpAttributesResult',
    'GetJobJobSettingsSettingsTaskForEachTaskTaskNewClusterInitScriptResult',
    'GetJobJobSettingsSettingsTaskForEachTaskTaskNewClusterInitScriptAbfssResult',
    'GetJobJobSettingsSettingsTaskForEachTaskTaskNewClusterInitScriptDbfsResult',
    'GetJobJobSettingsSettingsTaskForEachTaskTaskNewClusterInitScriptFileResult',
    'GetJobJobSettingsSettingsTaskForEachTaskTaskNewClusterInitScriptGcsResult',
    'GetJobJobSettingsSettingsTaskForEachTaskTaskNewClusterInitScriptS3Result',
    'GetJobJobSettingsSettingsTaskForEachTaskTaskNewClusterInitScriptVolumesResult',
    'GetJobJobSettingsSettingsTaskForEachTaskTaskNewClusterInitScriptWorkspaceResult',
    'GetJobJobSettingsSettingsTaskForEachTaskTaskNewClusterWorkloadTypeResult',
    'GetJobJobSettingsSettingsTaskForEachTaskTaskNewClusterWorkloadTypeClientsResult',
    'GetJobJobSettingsSettingsTaskForEachTaskTaskNotebookTaskResult',
    'GetJobJobSettingsSettingsTaskForEachTaskTaskNotificationSettingsResult',
    'GetJobJobSettingsSettingsTaskForEachTaskTaskPipelineTaskResult',
    'GetJobJobSettingsSettingsTaskForEachTaskTaskPythonWheelTaskResult',
    'GetJobJobSettingsSettingsTaskForEachTaskTaskRunJobTaskResult',
    'GetJobJobSettingsSettingsTaskForEachTaskTaskSparkJarTaskResult',
    'GetJobJobSettingsSettingsTaskForEachTaskTaskSparkPythonTaskResult',
    'GetJobJobSettingsSettingsTaskForEachTaskTaskSparkSubmitTaskResult',
    'GetJobJobSettingsSettingsTaskForEachTaskTaskSqlTaskResult',
    'GetJobJobSettingsSettingsTaskForEachTaskTaskSqlTaskAlertResult',
    'GetJobJobSettingsSettingsTaskForEachTaskTaskSqlTaskAlertSubscriptionResult',
    'GetJobJobSettingsSettingsTaskForEachTaskTaskSqlTaskDashboardResult',
    'GetJobJobSettingsSettingsTaskForEachTaskTaskSqlTaskDashboardSubscriptionResult',
    'GetJobJobSettingsSettingsTaskForEachTaskTaskSqlTaskFileResult',
    'GetJobJobSettingsSettingsTaskForEachTaskTaskSqlTaskQueryResult',
    'GetJobJobSettingsSettingsTaskForEachTaskTaskWebhookNotificationsResult',
    'GetJobJobSettingsSettingsTaskForEachTaskTaskWebhookNotificationsOnDurationWarningThresholdExceededResult',
    'GetJobJobSettingsSettingsTaskForEachTaskTaskWebhookNotificationsOnFailureResult',
    'GetJobJobSettingsSettingsTaskForEachTaskTaskWebhookNotificationsOnStartResult',
    'GetJobJobSettingsSettingsTaskForEachTaskTaskWebhookNotificationsOnStreamingBacklogExceededResult',
    'GetJobJobSettingsSettingsTaskForEachTaskTaskWebhookNotificationsOnSuccessResult',
    'GetJobJobSettingsSettingsTaskHealthResult',
    'GetJobJobSettingsSettingsTaskHealthRuleResult',
    'GetJobJobSettingsSettingsTaskLibraryResult',
    'GetJobJobSettingsSettingsTaskLibraryCranResult',
    'GetJobJobSettingsSettingsTaskLibraryMavenResult',
    'GetJobJobSettingsSettingsTaskLibraryPypiResult',
    'GetJobJobSettingsSettingsTaskNewClusterResult',
    'GetJobJobSettingsSettingsTaskNewClusterAutoscaleResult',
    'GetJobJobSettingsSettingsTaskNewClusterAwsAttributesResult',
    'GetJobJobSettingsSettingsTaskNewClusterAzureAttributesResult',
    'GetJobJobSettingsSettingsTaskNewClusterClusterLogConfResult',
    'GetJobJobSettingsSettingsTaskNewClusterClusterLogConfDbfsResult',
    'GetJobJobSettingsSettingsTaskNewClusterClusterLogConfS3Result',
    'GetJobJobSettingsSettingsTaskNewClusterClusterMountInfoResult',
    'GetJobJobSettingsSettingsTaskNewClusterClusterMountInfoNetworkFilesystemInfoResult',
    'GetJobJobSettingsSettingsTaskNewClusterDockerImageResult',
    'GetJobJobSettingsSettingsTaskNewClusterDockerImageBasicAuthResult',
    'GetJobJobSettingsSettingsTaskNewClusterGcpAttributesResult',
    'GetJobJobSettingsSettingsTaskNewClusterInitScriptResult',
    'GetJobJobSettingsSettingsTaskNewClusterInitScriptAbfssResult',
    'GetJobJobSettingsSettingsTaskNewClusterInitScriptDbfsResult',
    'GetJobJobSettingsSettingsTaskNewClusterInitScriptFileResult',
    'GetJobJobSettingsSettingsTaskNewClusterInitScriptGcsResult',
    'GetJobJobSettingsSettingsTaskNewClusterInitScriptS3Result',
    'GetJobJobSettingsSettingsTaskNewClusterInitScriptVolumesResult',
    'GetJobJobSettingsSettingsTaskNewClusterInitScriptWorkspaceResult',
    'GetJobJobSettingsSettingsTaskNewClusterWorkloadTypeResult',
    'GetJobJobSettingsSettingsTaskNewClusterWorkloadTypeClientsResult',
    'GetJobJobSettingsSettingsTaskNotebookTaskResult',
    'GetJobJobSettingsSettingsTaskNotificationSettingsResult',
    'GetJobJobSettingsSettingsTaskPipelineTaskResult',
    'GetJobJobSettingsSettingsTaskPythonWheelTaskResult',
    'GetJobJobSettingsSettingsTaskRunJobTaskResult',
    'GetJobJobSettingsSettingsTaskSparkJarTaskResult',
    'GetJobJobSettingsSettingsTaskSparkPythonTaskResult',
    'GetJobJobSettingsSettingsTaskSparkSubmitTaskResult',
    'GetJobJobSettingsSettingsTaskSqlTaskResult',
    'GetJobJobSettingsSettingsTaskSqlTaskAlertResult',
    'GetJobJobSettingsSettingsTaskSqlTaskAlertSubscriptionResult',
    'GetJobJobSettingsSettingsTaskSqlTaskDashboardResult',
    'GetJobJobSettingsSettingsTaskSqlTaskDashboardSubscriptionResult',
    'GetJobJobSettingsSettingsTaskSqlTaskFileResult',
    'GetJobJobSettingsSettingsTaskSqlTaskQueryResult',
    'GetJobJobSettingsSettingsTaskWebhookNotificationsResult',
    'GetJobJobSettingsSettingsTaskWebhookNotificationsOnDurationWarningThresholdExceededResult',
    'GetJobJobSettingsSettingsTaskWebhookNotificationsOnFailureResult',
    'GetJobJobSettingsSettingsTaskWebhookNotificationsOnStartResult',
    'GetJobJobSettingsSettingsTaskWebhookNotificationsOnStreamingBacklogExceededResult',
    'GetJobJobSettingsSettingsTaskWebhookNotificationsOnSuccessResult',
    'GetJobJobSettingsSettingsTriggerResult',
    'GetJobJobSettingsSettingsTriggerFileArrivalResult',
    'GetJobJobSettingsSettingsTriggerPeriodicResult',
    'GetJobJobSettingsSettingsTriggerTableUpdateResult',
    'GetJobJobSettingsSettingsWebhookNotificationsResult',
    'GetJobJobSettingsSettingsWebhookNotificationsOnDurationWarningThresholdExceededResult',
    'GetJobJobSettingsSettingsWebhookNotificationsOnFailureResult',
    'GetJobJobSettingsSettingsWebhookNotificationsOnStartResult',
    'GetJobJobSettingsSettingsWebhookNotificationsOnStreamingBacklogExceededResult',
    'GetJobJobSettingsSettingsWebhookNotificationsOnSuccessResult',
    'GetMetastoreMetastoreInfoResult',
    'GetMlflowExperimentTagResult',
    'GetMlflowModelLatestVersionResult',
    'GetMlflowModelLatestVersionTagResult',
    'GetMlflowModelTagResult',
    'GetNotebookPathsNotebookPathListResult',
    'GetSchemaSchemaInfoResult',
    'GetSchemaSchemaInfoEffectivePredictiveOptimizationFlagResult',
    'GetShareObjectResult',
    'GetShareObjectPartitionResult',
    'GetShareObjectPartitionValueResult',
    'GetSqlWarehouseChannelResult',
    'GetSqlWarehouseHealthResult',
    'GetSqlWarehouseHealthFailureReasonResult',
    'GetSqlWarehouseOdbcParamsResult',
    'GetSqlWarehouseTagsResult',
    'GetSqlWarehouseTagsCustomTagResult',
    'GetStorageCredentialStorageCredentialInfoResult',
    'GetStorageCredentialStorageCredentialInfoAwsIamRoleResult',
    'GetStorageCredentialStorageCredentialInfoAzureManagedIdentityResult',
    'GetStorageCredentialStorageCredentialInfoAzureServicePrincipalResult',
    'GetStorageCredentialStorageCredentialInfoCloudflareApiTokenResult',
    'GetStorageCredentialStorageCredentialInfoDatabricksGcpServiceAccountResult',
    'GetTableTableInfoResult',
    'GetTableTableInfoColumnResult',
    'GetTableTableInfoColumnMaskResult',
    'GetTableTableInfoDeltaRuntimePropertiesKvpairsResult',
    'GetTableTableInfoEffectivePredictiveOptimizationFlagResult',
    'GetTableTableInfoEncryptionDetailsResult',
    'GetTableTableInfoEncryptionDetailsSseEncryptionDetailsResult',
    'GetTableTableInfoRowFilterResult',
    'GetTableTableInfoTableConstraintResult',
    'GetTableTableInfoTableConstraintForeignKeyConstraintResult',
    'GetTableTableInfoTableConstraintNamedTableConstraintResult',
    'GetTableTableInfoTableConstraintPrimaryKeyConstraintResult',
    'GetTableTableInfoViewDependenciesResult',
    'GetTableTableInfoViewDependenciesDependencyResult',
    'GetTableTableInfoViewDependenciesDependencyFunctionResult',
    'GetTableTableInfoViewDependenciesDependencyTableResult',
    'GetVolumeVolumeInfoResult',
    'GetVolumeVolumeInfoEncryptionDetailsResult',
    'GetVolumeVolumeInfoEncryptionDetailsSseEncryptionDetailsResult',
]

@pulumi.output_type
class AccessControlRuleSetGrantRule(dict):
    def __init__(__self__, *,
                 role: str,
                 principals: Optional[Sequence[str]] = None):
        """
        :param str role: Role to be granted. The supported roles are listed below. For more information about these roles, refer to [service principal roles](https://docs.databricks.com/security/auth-authz/access-control/service-principal-acl.html#service-principal-roles), [group roles](https://docs.databricks.com/en/administration-guide/users-groups/groups.html#manage-roles-on-an-account-group-using-the-workspace-admin-settings-page) or [marketplace roles](https://docs.databricks.com/en/marketplace/get-started-provider.html#assign-the-marketplace-admin-role).
               * `roles/servicePrincipal.manager` - Manager of a service principal.
               * `roles/servicePrincipal.user` - User of a service principal.
               * `roles/group.manager` - Manager of a group.
               * `roles/marketplace.admin` - Admin of marketplace.
        :param Sequence[str] principals: a list of principals who are granted a role. The following format is supported:
               * `users/{username}` (also exposed as `acl_principal_id` attribute of `User` resource).
               * `groups/{groupname}` (also exposed as `acl_principal_id` attribute of `Group` resource).
               * `servicePrincipals/{applicationId}` (also exposed as `acl_principal_id` attribute of `ServicePrincipal` resource).
        """
        pulumi.set(__self__, "role", role)
        if principals is not None:
            pulumi.set(__self__, "principals", principals)

    @property
    @pulumi.getter
    def role(self) -> str:
        """
        Role to be granted. The supported roles are listed below. For more information about these roles, refer to [service principal roles](https://docs.databricks.com/security/auth-authz/access-control/service-principal-acl.html#service-principal-roles), [group roles](https://docs.databricks.com/en/administration-guide/users-groups/groups.html#manage-roles-on-an-account-group-using-the-workspace-admin-settings-page) or [marketplace roles](https://docs.databricks.com/en/marketplace/get-started-provider.html#assign-the-marketplace-admin-role).
        * `roles/servicePrincipal.manager` - Manager of a service principal.
        * `roles/servicePrincipal.user` - User of a service principal.
        * `roles/group.manager` - Manager of a group.
        * `roles/marketplace.admin` - Admin of marketplace.
        """
        return pulumi.get(self, "role")

    @property
    @pulumi.getter
    def principals(self) -> Optional[Sequence[str]]:
        """
        a list of principals who are granted a role. The following format is supported:
        * `users/{username}` (also exposed as `acl_principal_id` attribute of `User` resource).
        * `groups/{groupname}` (also exposed as `acl_principal_id` attribute of `Group` resource).
        * `servicePrincipals/{applicationId}` (also exposed as `acl_principal_id` attribute of `ServicePrincipal` resource).
        """
        return pulumi.get(self, "principals")


@pulumi.output_type
class ArtifactAllowlistArtifactMatcher(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "matchType":
            suggest = "match_type"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ArtifactAllowlistArtifactMatcher. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ArtifactAllowlistArtifactMatcher.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ArtifactAllowlistArtifactMatcher.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 artifact: str,
                 match_type: str):
        """
        :param str artifact: The artifact path or maven coordinate.
        :param str match_type: The pattern matching type of the artifact. Only `PREFIX_MATCH` is supported.
        """
        pulumi.set(__self__, "artifact", artifact)
        pulumi.set(__self__, "match_type", match_type)

    @property
    @pulumi.getter
    def artifact(self) -> str:
        """
        The artifact path or maven coordinate.
        """
        return pulumi.get(self, "artifact")

    @property
    @pulumi.getter(name="matchType")
    def match_type(self) -> str:
        """
        The pattern matching type of the artifact. Only `PREFIX_MATCH` is supported.
        """
        return pulumi.get(self, "match_type")


@pulumi.output_type
class AutomaticClusterUpdateWorkspaceSettingAutomaticClusterUpdateWorkspace(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "canToggle":
            suggest = "can_toggle"
        elif key == "enablementDetails":
            suggest = "enablement_details"
        elif key == "maintenanceWindow":
            suggest = "maintenance_window"
        elif key == "restartEvenIfNoUpdatesAvailable":
            suggest = "restart_even_if_no_updates_available"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in AutomaticClusterUpdateWorkspaceSettingAutomaticClusterUpdateWorkspace. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        AutomaticClusterUpdateWorkspaceSettingAutomaticClusterUpdateWorkspace.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        AutomaticClusterUpdateWorkspaceSettingAutomaticClusterUpdateWorkspace.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 can_toggle: Optional[bool] = None,
                 enabled: Optional[bool] = None,
                 enablement_details: Optional['outputs.AutomaticClusterUpdateWorkspaceSettingAutomaticClusterUpdateWorkspaceEnablementDetails'] = None,
                 maintenance_window: Optional['outputs.AutomaticClusterUpdateWorkspaceSettingAutomaticClusterUpdateWorkspaceMaintenanceWindow'] = None,
                 restart_even_if_no_updates_available: Optional[bool] = None):
        if can_toggle is not None:
            pulumi.set(__self__, "can_toggle", can_toggle)
        if enabled is not None:
            pulumi.set(__self__, "enabled", enabled)
        if enablement_details is not None:
            pulumi.set(__self__, "enablement_details", enablement_details)
        if maintenance_window is not None:
            pulumi.set(__self__, "maintenance_window", maintenance_window)
        if restart_even_if_no_updates_available is not None:
            pulumi.set(__self__, "restart_even_if_no_updates_available", restart_even_if_no_updates_available)

    @property
    @pulumi.getter(name="canToggle")
    def can_toggle(self) -> Optional[bool]:
        return pulumi.get(self, "can_toggle")

    @property
    @pulumi.getter
    def enabled(self) -> Optional[bool]:
        return pulumi.get(self, "enabled")

    @property
    @pulumi.getter(name="enablementDetails")
    def enablement_details(self) -> Optional['outputs.AutomaticClusterUpdateWorkspaceSettingAutomaticClusterUpdateWorkspaceEnablementDetails']:
        return pulumi.get(self, "enablement_details")

    @property
    @pulumi.getter(name="maintenanceWindow")
    def maintenance_window(self) -> Optional['outputs.AutomaticClusterUpdateWorkspaceSettingAutomaticClusterUpdateWorkspaceMaintenanceWindow']:
        return pulumi.get(self, "maintenance_window")

    @property
    @pulumi.getter(name="restartEvenIfNoUpdatesAvailable")
    def restart_even_if_no_updates_available(self) -> Optional[bool]:
        return pulumi.get(self, "restart_even_if_no_updates_available")


@pulumi.output_type
class AutomaticClusterUpdateWorkspaceSettingAutomaticClusterUpdateWorkspaceEnablementDetails(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "forcedForComplianceMode":
            suggest = "forced_for_compliance_mode"
        elif key == "unavailableForDisabledEntitlement":
            suggest = "unavailable_for_disabled_entitlement"
        elif key == "unavailableForNonEnterpriseTier":
            suggest = "unavailable_for_non_enterprise_tier"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in AutomaticClusterUpdateWorkspaceSettingAutomaticClusterUpdateWorkspaceEnablementDetails. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        AutomaticClusterUpdateWorkspaceSettingAutomaticClusterUpdateWorkspaceEnablementDetails.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        AutomaticClusterUpdateWorkspaceSettingAutomaticClusterUpdateWorkspaceEnablementDetails.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 forced_for_compliance_mode: Optional[bool] = None,
                 unavailable_for_disabled_entitlement: Optional[bool] = None,
                 unavailable_for_non_enterprise_tier: Optional[bool] = None):
        if forced_for_compliance_mode is not None:
            pulumi.set(__self__, "forced_for_compliance_mode", forced_for_compliance_mode)
        if unavailable_for_disabled_entitlement is not None:
            pulumi.set(__self__, "unavailable_for_disabled_entitlement", unavailable_for_disabled_entitlement)
        if unavailable_for_non_enterprise_tier is not None:
            pulumi.set(__self__, "unavailable_for_non_enterprise_tier", unavailable_for_non_enterprise_tier)

    @property
    @pulumi.getter(name="forcedForComplianceMode")
    def forced_for_compliance_mode(self) -> Optional[bool]:
        return pulumi.get(self, "forced_for_compliance_mode")

    @property
    @pulumi.getter(name="unavailableForDisabledEntitlement")
    def unavailable_for_disabled_entitlement(self) -> Optional[bool]:
        return pulumi.get(self, "unavailable_for_disabled_entitlement")

    @property
    @pulumi.getter(name="unavailableForNonEnterpriseTier")
    def unavailable_for_non_enterprise_tier(self) -> Optional[bool]:
        return pulumi.get(self, "unavailable_for_non_enterprise_tier")


@pulumi.output_type
class AutomaticClusterUpdateWorkspaceSettingAutomaticClusterUpdateWorkspaceMaintenanceWindow(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "weekDayBasedSchedule":
            suggest = "week_day_based_schedule"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in AutomaticClusterUpdateWorkspaceSettingAutomaticClusterUpdateWorkspaceMaintenanceWindow. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        AutomaticClusterUpdateWorkspaceSettingAutomaticClusterUpdateWorkspaceMaintenanceWindow.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        AutomaticClusterUpdateWorkspaceSettingAutomaticClusterUpdateWorkspaceMaintenanceWindow.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 week_day_based_schedule: Optional['outputs.AutomaticClusterUpdateWorkspaceSettingAutomaticClusterUpdateWorkspaceMaintenanceWindowWeekDayBasedSchedule'] = None):
        if week_day_based_schedule is not None:
            pulumi.set(__self__, "week_day_based_schedule", week_day_based_schedule)

    @property
    @pulumi.getter(name="weekDayBasedSchedule")
    def week_day_based_schedule(self) -> Optional['outputs.AutomaticClusterUpdateWorkspaceSettingAutomaticClusterUpdateWorkspaceMaintenanceWindowWeekDayBasedSchedule']:
        return pulumi.get(self, "week_day_based_schedule")


@pulumi.output_type
class AutomaticClusterUpdateWorkspaceSettingAutomaticClusterUpdateWorkspaceMaintenanceWindowWeekDayBasedSchedule(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "dayOfWeek":
            suggest = "day_of_week"
        elif key == "windowStartTime":
            suggest = "window_start_time"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in AutomaticClusterUpdateWorkspaceSettingAutomaticClusterUpdateWorkspaceMaintenanceWindowWeekDayBasedSchedule. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        AutomaticClusterUpdateWorkspaceSettingAutomaticClusterUpdateWorkspaceMaintenanceWindowWeekDayBasedSchedule.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        AutomaticClusterUpdateWorkspaceSettingAutomaticClusterUpdateWorkspaceMaintenanceWindowWeekDayBasedSchedule.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 day_of_week: Optional[str] = None,
                 frequency: Optional[str] = None,
                 window_start_time: Optional['outputs.AutomaticClusterUpdateWorkspaceSettingAutomaticClusterUpdateWorkspaceMaintenanceWindowWeekDayBasedScheduleWindowStartTime'] = None):
        if day_of_week is not None:
            pulumi.set(__self__, "day_of_week", day_of_week)
        if frequency is not None:
            pulumi.set(__self__, "frequency", frequency)
        if window_start_time is not None:
            pulumi.set(__self__, "window_start_time", window_start_time)

    @property
    @pulumi.getter(name="dayOfWeek")
    def day_of_week(self) -> Optional[str]:
        return pulumi.get(self, "day_of_week")

    @property
    @pulumi.getter
    def frequency(self) -> Optional[str]:
        return pulumi.get(self, "frequency")

    @property
    @pulumi.getter(name="windowStartTime")
    def window_start_time(self) -> Optional['outputs.AutomaticClusterUpdateWorkspaceSettingAutomaticClusterUpdateWorkspaceMaintenanceWindowWeekDayBasedScheduleWindowStartTime']:
        return pulumi.get(self, "window_start_time")


@pulumi.output_type
class AutomaticClusterUpdateWorkspaceSettingAutomaticClusterUpdateWorkspaceMaintenanceWindowWeekDayBasedScheduleWindowStartTime(dict):
    def __init__(__self__, *,
                 hours: Optional[int] = None,
                 minutes: Optional[int] = None):
        if hours is not None:
            pulumi.set(__self__, "hours", hours)
        if minutes is not None:
            pulumi.set(__self__, "minutes", minutes)

    @property
    @pulumi.getter
    def hours(self) -> Optional[int]:
        return pulumi.get(self, "hours")

    @property
    @pulumi.getter
    def minutes(self) -> Optional[int]:
        return pulumi.get(self, "minutes")


@pulumi.output_type
class ClusterAutoscale(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "maxWorkers":
            suggest = "max_workers"
        elif key == "minWorkers":
            suggest = "min_workers"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterAutoscale. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterAutoscale.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterAutoscale.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 max_workers: Optional[int] = None,
                 min_workers: Optional[int] = None):
        """
        :param int max_workers: The maximum number of workers to which the cluster can scale up when overloaded. max_workers must be strictly greater than min_workers.
               
               When using a [Single Node cluster](https://docs.databricks.com/clusters/single-node.html), `num_workers` needs to be `0`. It can be set to `0` explicitly, or simply not specified, as it defaults to `0`.  When `num_workers` is `0`, provider checks for presence of the required Spark configurations:
               
               * `spark.master` must have prefix `local`, like `local[*]`
               * `spark.databricks.cluster.profile` must have value `singleNode`
               
               and also `custom_tag` entry:
               
               * `"ResourceClass" = "SingleNode"`
               
               The following example demonstrates how to create an single node cluster:
               
               ```python
               import pulumi
               import pulumi_databricks as databricks
               
               smallest = databricks.get_node_type(local_disk=True)
               latest_lts = databricks.get_spark_version(long_term_support=True)
               single_node = databricks.Cluster("single_node",
                   cluster_name="Single Node",
                   spark_version=latest_lts.id,
                   node_type_id=smallest.id,
                   autotermination_minutes=20,
                   spark_conf={
                       "spark.databricks.cluster.profile": "singleNode",
                       "spark.master": "local[*]",
                   },
                   custom_tags={
                       "ResourceClass": "SingleNode",
                   })
               ```
        :param int min_workers: The minimum number of workers to which the cluster can scale down when underutilized. It is also the initial number of workers the cluster will have after creation.
        """
        if max_workers is not None:
            pulumi.set(__self__, "max_workers", max_workers)
        if min_workers is not None:
            pulumi.set(__self__, "min_workers", min_workers)

    @property
    @pulumi.getter(name="maxWorkers")
    def max_workers(self) -> Optional[int]:
        """
        The maximum number of workers to which the cluster can scale up when overloaded. max_workers must be strictly greater than min_workers.

        When using a [Single Node cluster](https://docs.databricks.com/clusters/single-node.html), `num_workers` needs to be `0`. It can be set to `0` explicitly, or simply not specified, as it defaults to `0`.  When `num_workers` is `0`, provider checks for presence of the required Spark configurations:

        * `spark.master` must have prefix `local`, like `local[*]`
        * `spark.databricks.cluster.profile` must have value `singleNode`

        and also `custom_tag` entry:

        * `"ResourceClass" = "SingleNode"`

        The following example demonstrates how to create an single node cluster:

        ```python
        import pulumi
        import pulumi_databricks as databricks

        smallest = databricks.get_node_type(local_disk=True)
        latest_lts = databricks.get_spark_version(long_term_support=True)
        single_node = databricks.Cluster("single_node",
            cluster_name="Single Node",
            spark_version=latest_lts.id,
            node_type_id=smallest.id,
            autotermination_minutes=20,
            spark_conf={
                "spark.databricks.cluster.profile": "singleNode",
                "spark.master": "local[*]",
            },
            custom_tags={
                "ResourceClass": "SingleNode",
            })
        ```
        """
        return pulumi.get(self, "max_workers")

    @property
    @pulumi.getter(name="minWorkers")
    def min_workers(self) -> Optional[int]:
        """
        The minimum number of workers to which the cluster can scale down when underutilized. It is also the initial number of workers the cluster will have after creation.
        """
        return pulumi.get(self, "min_workers")


@pulumi.output_type
class ClusterAwsAttributes(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "ebsVolumeCount":
            suggest = "ebs_volume_count"
        elif key == "ebsVolumeIops":
            suggest = "ebs_volume_iops"
        elif key == "ebsVolumeSize":
            suggest = "ebs_volume_size"
        elif key == "ebsVolumeThroughput":
            suggest = "ebs_volume_throughput"
        elif key == "ebsVolumeType":
            suggest = "ebs_volume_type"
        elif key == "firstOnDemand":
            suggest = "first_on_demand"
        elif key == "instanceProfileArn":
            suggest = "instance_profile_arn"
        elif key == "spotBidPricePercent":
            suggest = "spot_bid_price_percent"
        elif key == "zoneId":
            suggest = "zone_id"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterAwsAttributes. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterAwsAttributes.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterAwsAttributes.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 availability: Optional[str] = None,
                 ebs_volume_count: Optional[int] = None,
                 ebs_volume_iops: Optional[int] = None,
                 ebs_volume_size: Optional[int] = None,
                 ebs_volume_throughput: Optional[int] = None,
                 ebs_volume_type: Optional[str] = None,
                 first_on_demand: Optional[int] = None,
                 instance_profile_arn: Optional[str] = None,
                 spot_bid_price_percent: Optional[int] = None,
                 zone_id: Optional[str] = None):
        """
        :param str availability: Availability type used for all subsequent nodes past the `first_on_demand` ones. Valid values are `SPOT`, `SPOT_WITH_FALLBACK` and `ON_DEMAND`. Note: If `first_on_demand` is zero, this availability type will be used for the entire cluster. Backend default value is `SPOT_WITH_FALLBACK` and could change in the future
        :param int ebs_volume_count: The number of volumes launched for each instance. You can choose up to 10 volumes. This feature is only enabled for supported node types. Legacy node types cannot specify custom EBS volumes. For node types with no instance store, at least one EBS volume needs to be specified; otherwise, cluster creation will fail. These EBS volumes will be mounted at /ebs0, /ebs1, and etc. Instance store volumes will be mounted at /local_disk0, /local_disk1, and etc. If EBS volumes are attached, Databricks will configure Spark to use only the EBS volumes for scratch storage because heterogeneously sized scratch devices can lead to inefficient disk utilization. If no EBS volumes are attached, Databricks will configure Spark to use instance store volumes. If EBS volumes are specified, then the Spark configuration spark.local.dir will be overridden.
        :param int ebs_volume_size: The size of each EBS volume (in GiB) launched for each instance. For general purpose SSD, this value must be within the range 100 - 4096. For throughput optimized HDD, this value must be within the range 500 - 4096. Custom EBS volumes cannot be specified for the legacy node types (memory-optimized and compute-optimized).
        :param str ebs_volume_type: The type of EBS volumes that will be launched with this cluster. Valid values are `GENERAL_PURPOSE_SSD` or `THROUGHPUT_OPTIMIZED_HDD`. Use this option only if you're not picking *Delta Optimized `i3.*`* node types.
        :param int first_on_demand: The first `first_on_demand` nodes of the cluster will be placed on on-demand instances. If this value is greater than 0, the cluster driver node will be placed on an on-demand instance. If this value is greater than or equal to the current cluster size, all nodes will be placed on on-demand instances. If this value is less than the current cluster size, `first_on_demand` nodes will be placed on on-demand instances, and the remainder will be placed on availability instances. This value does not affect cluster size and cannot be mutated over the lifetime of a cluster. Backend default value is `1` and could change in the future
        :param str instance_profile_arn: Nodes for this cluster will only be placed on AWS instances with this instance profile. Please see InstanceProfile resource documentation for extended examples on adding a valid instance profile using Pulumi.
        :param int spot_bid_price_percent: The max price for AWS spot instances, as a percentage of the corresponding instance types on-demand price. For example, if this field is set to 50, and the cluster needs a new `i3.xlarge` spot instance, then the max price is half of the price of on-demand `i3.xlarge` instances. Similarly, if this field is set to 200, the max price is twice the price of on-demand `i3.xlarge` instances. If not specified, the default value is `100`. When spot instances are requested for this cluster, only spot instances whose max price percentage matches this field will be considered. For safety, we enforce this field to be no more than `10000`.
        :param str zone_id: Identifier for the availability zone/datacenter in which the cluster resides. This string will be of a form like `us-west-2a`. The provided availability zone must be in the same region as the Databricks deployment. For example, `us-west-2a` is not a valid zone ID if the Databricks deployment resides in the `us-east-1` region. Enable automatic availability zone selection ("Auto-AZ"), by setting the value `auto`. Databricks selects the AZ based on available IPs in the workspace subnets and retries in other availability zones if AWS returns insufficient capacity errors.
        """
        if availability is not None:
            pulumi.set(__self__, "availability", availability)
        if ebs_volume_count is not None:
            pulumi.set(__self__, "ebs_volume_count", ebs_volume_count)
        if ebs_volume_iops is not None:
            pulumi.set(__self__, "ebs_volume_iops", ebs_volume_iops)
        if ebs_volume_size is not None:
            pulumi.set(__self__, "ebs_volume_size", ebs_volume_size)
        if ebs_volume_throughput is not None:
            pulumi.set(__self__, "ebs_volume_throughput", ebs_volume_throughput)
        if ebs_volume_type is not None:
            pulumi.set(__self__, "ebs_volume_type", ebs_volume_type)
        if first_on_demand is not None:
            pulumi.set(__self__, "first_on_demand", first_on_demand)
        if instance_profile_arn is not None:
            pulumi.set(__self__, "instance_profile_arn", instance_profile_arn)
        if spot_bid_price_percent is not None:
            pulumi.set(__self__, "spot_bid_price_percent", spot_bid_price_percent)
        if zone_id is not None:
            pulumi.set(__self__, "zone_id", zone_id)

    @property
    @pulumi.getter
    def availability(self) -> Optional[str]:
        """
        Availability type used for all subsequent nodes past the `first_on_demand` ones. Valid values are `SPOT`, `SPOT_WITH_FALLBACK` and `ON_DEMAND`. Note: If `first_on_demand` is zero, this availability type will be used for the entire cluster. Backend default value is `SPOT_WITH_FALLBACK` and could change in the future
        """
        return pulumi.get(self, "availability")

    @property
    @pulumi.getter(name="ebsVolumeCount")
    def ebs_volume_count(self) -> Optional[int]:
        """
        The number of volumes launched for each instance. You can choose up to 10 volumes. This feature is only enabled for supported node types. Legacy node types cannot specify custom EBS volumes. For node types with no instance store, at least one EBS volume needs to be specified; otherwise, cluster creation will fail. These EBS volumes will be mounted at /ebs0, /ebs1, and etc. Instance store volumes will be mounted at /local_disk0, /local_disk1, and etc. If EBS volumes are attached, Databricks will configure Spark to use only the EBS volumes for scratch storage because heterogeneously sized scratch devices can lead to inefficient disk utilization. If no EBS volumes are attached, Databricks will configure Spark to use instance store volumes. If EBS volumes are specified, then the Spark configuration spark.local.dir will be overridden.
        """
        return pulumi.get(self, "ebs_volume_count")

    @property
    @pulumi.getter(name="ebsVolumeIops")
    def ebs_volume_iops(self) -> Optional[int]:
        return pulumi.get(self, "ebs_volume_iops")

    @property
    @pulumi.getter(name="ebsVolumeSize")
    def ebs_volume_size(self) -> Optional[int]:
        """
        The size of each EBS volume (in GiB) launched for each instance. For general purpose SSD, this value must be within the range 100 - 4096. For throughput optimized HDD, this value must be within the range 500 - 4096. Custom EBS volumes cannot be specified for the legacy node types (memory-optimized and compute-optimized).
        """
        return pulumi.get(self, "ebs_volume_size")

    @property
    @pulumi.getter(name="ebsVolumeThroughput")
    def ebs_volume_throughput(self) -> Optional[int]:
        return pulumi.get(self, "ebs_volume_throughput")

    @property
    @pulumi.getter(name="ebsVolumeType")
    def ebs_volume_type(self) -> Optional[str]:
        """
        The type of EBS volumes that will be launched with this cluster. Valid values are `GENERAL_PURPOSE_SSD` or `THROUGHPUT_OPTIMIZED_HDD`. Use this option only if you're not picking *Delta Optimized `i3.*`* node types.
        """
        return pulumi.get(self, "ebs_volume_type")

    @property
    @pulumi.getter(name="firstOnDemand")
    def first_on_demand(self) -> Optional[int]:
        """
        The first `first_on_demand` nodes of the cluster will be placed on on-demand instances. If this value is greater than 0, the cluster driver node will be placed on an on-demand instance. If this value is greater than or equal to the current cluster size, all nodes will be placed on on-demand instances. If this value is less than the current cluster size, `first_on_demand` nodes will be placed on on-demand instances, and the remainder will be placed on availability instances. This value does not affect cluster size and cannot be mutated over the lifetime of a cluster. Backend default value is `1` and could change in the future
        """
        return pulumi.get(self, "first_on_demand")

    @property
    @pulumi.getter(name="instanceProfileArn")
    def instance_profile_arn(self) -> Optional[str]:
        """
        Nodes for this cluster will only be placed on AWS instances with this instance profile. Please see InstanceProfile resource documentation for extended examples on adding a valid instance profile using Pulumi.
        """
        return pulumi.get(self, "instance_profile_arn")

    @property
    @pulumi.getter(name="spotBidPricePercent")
    def spot_bid_price_percent(self) -> Optional[int]:
        """
        The max price for AWS spot instances, as a percentage of the corresponding instance types on-demand price. For example, if this field is set to 50, and the cluster needs a new `i3.xlarge` spot instance, then the max price is half of the price of on-demand `i3.xlarge` instances. Similarly, if this field is set to 200, the max price is twice the price of on-demand `i3.xlarge` instances. If not specified, the default value is `100`. When spot instances are requested for this cluster, only spot instances whose max price percentage matches this field will be considered. For safety, we enforce this field to be no more than `10000`.
        """
        return pulumi.get(self, "spot_bid_price_percent")

    @property
    @pulumi.getter(name="zoneId")
    def zone_id(self) -> Optional[str]:
        """
        Identifier for the availability zone/datacenter in which the cluster resides. This string will be of a form like `us-west-2a`. The provided availability zone must be in the same region as the Databricks deployment. For example, `us-west-2a` is not a valid zone ID if the Databricks deployment resides in the `us-east-1` region. Enable automatic availability zone selection ("Auto-AZ"), by setting the value `auto`. Databricks selects the AZ based on available IPs in the workspace subnets and retries in other availability zones if AWS returns insufficient capacity errors.
        """
        return pulumi.get(self, "zone_id")


@pulumi.output_type
class ClusterAzureAttributes(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "firstOnDemand":
            suggest = "first_on_demand"
        elif key == "logAnalyticsInfo":
            suggest = "log_analytics_info"
        elif key == "spotBidMaxPrice":
            suggest = "spot_bid_max_price"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterAzureAttributes. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterAzureAttributes.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterAzureAttributes.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 availability: Optional[str] = None,
                 first_on_demand: Optional[int] = None,
                 log_analytics_info: Optional['outputs.ClusterAzureAttributesLogAnalyticsInfo'] = None,
                 spot_bid_max_price: Optional[float] = None):
        """
        :param str availability: Availability type used for all subsequent nodes past the `first_on_demand` ones. Valid values are `SPOT_AZURE`, `SPOT_WITH_FALLBACK_AZURE`, and `ON_DEMAND_AZURE`. Note: If `first_on_demand` is zero, this availability type will be used for the entire cluster.
        :param int first_on_demand: The first `first_on_demand` nodes of the cluster will be placed on on-demand instances. If this value is greater than 0, the cluster driver node will be placed on an on-demand instance. If this value is greater than or equal to the current cluster size, all nodes will be placed on on-demand instances. If this value is less than the current cluster size, `first_on_demand` nodes will be placed on on-demand instances, and the remainder will be placed on availability instances. This value does not affect cluster size and cannot be mutated over the lifetime of a cluster.
        :param float spot_bid_max_price: The max bid price used for Azure spot instances. You can set this to greater than or equal to the current spot price. You can also set this to `-1`, which specifies that the instance cannot be evicted on the basis of price. The price for the instance will be the current price for spot instances or the price for a standard instance.
        """
        if availability is not None:
            pulumi.set(__self__, "availability", availability)
        if first_on_demand is not None:
            pulumi.set(__self__, "first_on_demand", first_on_demand)
        if log_analytics_info is not None:
            pulumi.set(__self__, "log_analytics_info", log_analytics_info)
        if spot_bid_max_price is not None:
            pulumi.set(__self__, "spot_bid_max_price", spot_bid_max_price)

    @property
    @pulumi.getter
    def availability(self) -> Optional[str]:
        """
        Availability type used for all subsequent nodes past the `first_on_demand` ones. Valid values are `SPOT_AZURE`, `SPOT_WITH_FALLBACK_AZURE`, and `ON_DEMAND_AZURE`. Note: If `first_on_demand` is zero, this availability type will be used for the entire cluster.
        """
        return pulumi.get(self, "availability")

    @property
    @pulumi.getter(name="firstOnDemand")
    def first_on_demand(self) -> Optional[int]:
        """
        The first `first_on_demand` nodes of the cluster will be placed on on-demand instances. If this value is greater than 0, the cluster driver node will be placed on an on-demand instance. If this value is greater than or equal to the current cluster size, all nodes will be placed on on-demand instances. If this value is less than the current cluster size, `first_on_demand` nodes will be placed on on-demand instances, and the remainder will be placed on availability instances. This value does not affect cluster size and cannot be mutated over the lifetime of a cluster.
        """
        return pulumi.get(self, "first_on_demand")

    @property
    @pulumi.getter(name="logAnalyticsInfo")
    def log_analytics_info(self) -> Optional['outputs.ClusterAzureAttributesLogAnalyticsInfo']:
        return pulumi.get(self, "log_analytics_info")

    @property
    @pulumi.getter(name="spotBidMaxPrice")
    def spot_bid_max_price(self) -> Optional[float]:
        """
        The max bid price used for Azure spot instances. You can set this to greater than or equal to the current spot price. You can also set this to `-1`, which specifies that the instance cannot be evicted on the basis of price. The price for the instance will be the current price for spot instances or the price for a standard instance.
        """
        return pulumi.get(self, "spot_bid_max_price")


@pulumi.output_type
class ClusterAzureAttributesLogAnalyticsInfo(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "logAnalyticsPrimaryKey":
            suggest = "log_analytics_primary_key"
        elif key == "logAnalyticsWorkspaceId":
            suggest = "log_analytics_workspace_id"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterAzureAttributesLogAnalyticsInfo. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterAzureAttributesLogAnalyticsInfo.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterAzureAttributesLogAnalyticsInfo.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 log_analytics_primary_key: Optional[str] = None,
                 log_analytics_workspace_id: Optional[str] = None):
        if log_analytics_primary_key is not None:
            pulumi.set(__self__, "log_analytics_primary_key", log_analytics_primary_key)
        if log_analytics_workspace_id is not None:
            pulumi.set(__self__, "log_analytics_workspace_id", log_analytics_workspace_id)

    @property
    @pulumi.getter(name="logAnalyticsPrimaryKey")
    def log_analytics_primary_key(self) -> Optional[str]:
        return pulumi.get(self, "log_analytics_primary_key")

    @property
    @pulumi.getter(name="logAnalyticsWorkspaceId")
    def log_analytics_workspace_id(self) -> Optional[str]:
        return pulumi.get(self, "log_analytics_workspace_id")


@pulumi.output_type
class ClusterClusterLogConf(dict):
    def __init__(__self__, *,
                 dbfs: Optional['outputs.ClusterClusterLogConfDbfs'] = None,
                 s3: Optional['outputs.ClusterClusterLogConfS3'] = None):
        if dbfs is not None:
            pulumi.set(__self__, "dbfs", dbfs)
        if s3 is not None:
            pulumi.set(__self__, "s3", s3)

    @property
    @pulumi.getter
    def dbfs(self) -> Optional['outputs.ClusterClusterLogConfDbfs']:
        return pulumi.get(self, "dbfs")

    @property
    @pulumi.getter
    def s3(self) -> Optional['outputs.ClusterClusterLogConfS3']:
        return pulumi.get(self, "s3")


@pulumi.output_type
class ClusterClusterLogConfDbfs(dict):
    def __init__(__self__, *,
                 destination: str):
        """
        :param str destination: S3 destination, e.g., `s3://my-bucket/some-prefix` You must configure the cluster with an instance profile, and the instance profile must have write access to the destination. You cannot use AWS keys.
        """
        pulumi.set(__self__, "destination", destination)

    @property
    @pulumi.getter
    def destination(self) -> str:
        """
        S3 destination, e.g., `s3://my-bucket/some-prefix` You must configure the cluster with an instance profile, and the instance profile must have write access to the destination. You cannot use AWS keys.
        """
        return pulumi.get(self, "destination")


@pulumi.output_type
class ClusterClusterLogConfS3(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "cannedAcl":
            suggest = "canned_acl"
        elif key == "enableEncryption":
            suggest = "enable_encryption"
        elif key == "encryptionType":
            suggest = "encryption_type"
        elif key == "kmsKey":
            suggest = "kms_key"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterClusterLogConfS3. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterClusterLogConfS3.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterClusterLogConfS3.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 destination: str,
                 canned_acl: Optional[str] = None,
                 enable_encryption: Optional[bool] = None,
                 encryption_type: Optional[str] = None,
                 endpoint: Optional[str] = None,
                 kms_key: Optional[str] = None,
                 region: Optional[str] = None):
        """
        :param str destination: S3 destination, e.g., `s3://my-bucket/some-prefix` You must configure the cluster with an instance profile, and the instance profile must have write access to the destination. You cannot use AWS keys.
        :param str canned_acl: Set canned access control list, e.g. `bucket-owner-full-control`. If `canned_cal` is set, the cluster instance profile must have `s3:PutObjectAcl` permission on the destination bucket and prefix. The full list of possible canned ACLs can be found [here](https://docs.aws.amazon.com/AmazonS3/latest/dev/acl-overview.html#canned-acl). By default, only the object owner gets full control. If you are using a cross-account role for writing data, you may want to set `bucket-owner-full-control` to make bucket owners able to read the logs.
        :param bool enable_encryption: Enable server-side encryption, false by default.
        :param str encryption_type: The encryption type, it could be `sse-s3` or `sse-kms`. It is used only when encryption is enabled, and the default type is `sse-s3`.
        :param str endpoint: S3 endpoint, e.g. <https://s3-us-west-2.amazonaws.com>. Either `region` or `endpoint` needs to be set. If both are set, the endpoint is used.
        :param str kms_key: KMS key used if encryption is enabled and encryption type is set to `sse-kms`.
        :param str region: S3 region, e.g. `us-west-2`. Either `region` or `endpoint` must be set. If both are set, the endpoint is used.
        """
        pulumi.set(__self__, "destination", destination)
        if canned_acl is not None:
            pulumi.set(__self__, "canned_acl", canned_acl)
        if enable_encryption is not None:
            pulumi.set(__self__, "enable_encryption", enable_encryption)
        if encryption_type is not None:
            pulumi.set(__self__, "encryption_type", encryption_type)
        if endpoint is not None:
            pulumi.set(__self__, "endpoint", endpoint)
        if kms_key is not None:
            pulumi.set(__self__, "kms_key", kms_key)
        if region is not None:
            pulumi.set(__self__, "region", region)

    @property
    @pulumi.getter
    def destination(self) -> str:
        """
        S3 destination, e.g., `s3://my-bucket/some-prefix` You must configure the cluster with an instance profile, and the instance profile must have write access to the destination. You cannot use AWS keys.
        """
        return pulumi.get(self, "destination")

    @property
    @pulumi.getter(name="cannedAcl")
    def canned_acl(self) -> Optional[str]:
        """
        Set canned access control list, e.g. `bucket-owner-full-control`. If `canned_cal` is set, the cluster instance profile must have `s3:PutObjectAcl` permission on the destination bucket and prefix. The full list of possible canned ACLs can be found [here](https://docs.aws.amazon.com/AmazonS3/latest/dev/acl-overview.html#canned-acl). By default, only the object owner gets full control. If you are using a cross-account role for writing data, you may want to set `bucket-owner-full-control` to make bucket owners able to read the logs.
        """
        return pulumi.get(self, "canned_acl")

    @property
    @pulumi.getter(name="enableEncryption")
    def enable_encryption(self) -> Optional[bool]:
        """
        Enable server-side encryption, false by default.
        """
        return pulumi.get(self, "enable_encryption")

    @property
    @pulumi.getter(name="encryptionType")
    def encryption_type(self) -> Optional[str]:
        """
        The encryption type, it could be `sse-s3` or `sse-kms`. It is used only when encryption is enabled, and the default type is `sse-s3`.
        """
        return pulumi.get(self, "encryption_type")

    @property
    @pulumi.getter
    def endpoint(self) -> Optional[str]:
        """
        S3 endpoint, e.g. <https://s3-us-west-2.amazonaws.com>. Either `region` or `endpoint` needs to be set. If both are set, the endpoint is used.
        """
        return pulumi.get(self, "endpoint")

    @property
    @pulumi.getter(name="kmsKey")
    def kms_key(self) -> Optional[str]:
        """
        KMS key used if encryption is enabled and encryption type is set to `sse-kms`.
        """
        return pulumi.get(self, "kms_key")

    @property
    @pulumi.getter
    def region(self) -> Optional[str]:
        """
        S3 region, e.g. `us-west-2`. Either `region` or `endpoint` must be set. If both are set, the endpoint is used.
        """
        return pulumi.get(self, "region")


@pulumi.output_type
class ClusterClusterMountInfo(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "localMountDirPath":
            suggest = "local_mount_dir_path"
        elif key == "networkFilesystemInfo":
            suggest = "network_filesystem_info"
        elif key == "remoteMountDirPath":
            suggest = "remote_mount_dir_path"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterClusterMountInfo. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterClusterMountInfo.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterClusterMountInfo.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 local_mount_dir_path: str,
                 network_filesystem_info: 'outputs.ClusterClusterMountInfoNetworkFilesystemInfo',
                 remote_mount_dir_path: Optional[str] = None):
        """
        :param str local_mount_dir_path: path inside the Spark container.
               
               For example, you can mount Azure Data Lake Storage container using the following code:
               
               ```python
               import pulumi
               import pulumi_databricks as databricks
               
               storage_account = "ewfw3ggwegwg"
               storage_container = "test"
               with_nfs = databricks.Cluster("with_nfs", cluster_mount_infos=[{
                   "network_filesystem_info": {
                       "server_address": f"{storage_account}.blob.core.windows.net",
                       "mount_options": "sec=sys,vers=3,nolock,proto=tcp",
                   },
                   "remote_mount_dir_path": f"{storage_account}/{storage_container}",
                   "local_mount_dir_path": "/mnt/nfs-test",
               }])
               ```
        :param 'ClusterClusterMountInfoNetworkFilesystemInfoArgs' network_filesystem_info: block specifying connection. It consists of:
        :param str remote_mount_dir_path: string specifying path to mount on the remote service.
        """
        pulumi.set(__self__, "local_mount_dir_path", local_mount_dir_path)
        pulumi.set(__self__, "network_filesystem_info", network_filesystem_info)
        if remote_mount_dir_path is not None:
            pulumi.set(__self__, "remote_mount_dir_path", remote_mount_dir_path)

    @property
    @pulumi.getter(name="localMountDirPath")
    def local_mount_dir_path(self) -> str:
        """
        path inside the Spark container.

        For example, you can mount Azure Data Lake Storage container using the following code:

        ```python
        import pulumi
        import pulumi_databricks as databricks

        storage_account = "ewfw3ggwegwg"
        storage_container = "test"
        with_nfs = databricks.Cluster("with_nfs", cluster_mount_infos=[{
            "network_filesystem_info": {
                "server_address": f"{storage_account}.blob.core.windows.net",
                "mount_options": "sec=sys,vers=3,nolock,proto=tcp",
            },
            "remote_mount_dir_path": f"{storage_account}/{storage_container}",
            "local_mount_dir_path": "/mnt/nfs-test",
        }])
        ```
        """
        return pulumi.get(self, "local_mount_dir_path")

    @property
    @pulumi.getter(name="networkFilesystemInfo")
    def network_filesystem_info(self) -> 'outputs.ClusterClusterMountInfoNetworkFilesystemInfo':
        """
        block specifying connection. It consists of:
        """
        return pulumi.get(self, "network_filesystem_info")

    @property
    @pulumi.getter(name="remoteMountDirPath")
    def remote_mount_dir_path(self) -> Optional[str]:
        """
        string specifying path to mount on the remote service.
        """
        return pulumi.get(self, "remote_mount_dir_path")


@pulumi.output_type
class ClusterClusterMountInfoNetworkFilesystemInfo(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "serverAddress":
            suggest = "server_address"
        elif key == "mountOptions":
            suggest = "mount_options"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterClusterMountInfoNetworkFilesystemInfo. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterClusterMountInfoNetworkFilesystemInfo.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterClusterMountInfoNetworkFilesystemInfo.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 server_address: str,
                 mount_options: Optional[str] = None):
        """
        :param str server_address: host name.
        :param str mount_options: string that will be passed as options passed to the `mount` command.
        """
        pulumi.set(__self__, "server_address", server_address)
        if mount_options is not None:
            pulumi.set(__self__, "mount_options", mount_options)

    @property
    @pulumi.getter(name="serverAddress")
    def server_address(self) -> str:
        """
        host name.
        """
        return pulumi.get(self, "server_address")

    @property
    @pulumi.getter(name="mountOptions")
    def mount_options(self) -> Optional[str]:
        """
        string that will be passed as options passed to the `mount` command.
        """
        return pulumi.get(self, "mount_options")


@pulumi.output_type
class ClusterDockerImage(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "basicAuth":
            suggest = "basic_auth"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterDockerImage. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterDockerImage.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterDockerImage.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 url: str,
                 basic_auth: Optional['outputs.ClusterDockerImageBasicAuth'] = None):
        """
        :param str url: URL for the Docker image
        :param 'ClusterDockerImageBasicAuthArgs' basic_auth: `basic_auth.username` and `basic_auth.password` for Docker repository. Docker registry credentials are encrypted when they are stored in Databricks internal storage and when they are passed to a registry upon fetching Docker images at cluster launch. However, other authenticated and authorized API users of this workspace can access the username and password.
               
               Example usage with azurerm_container_registry, that you can adapt to your specific use-case:
               
               ```python
               import pulumi
               import pulumi_databricks as databricks
               import pulumi_docker as docker
               
               this = docker.index.RegistryImage("this",
                   build=[{}],
                   name=f{this_azurerm_container_registry.login_server}/sample:latest)
               this_cluster = databricks.Cluster("this", docker_image={
                   "url": this["name"],
                   "basic_auth": {
                       "username": this_azurerm_container_registry["adminUsername"],
                       "password": this_azurerm_container_registry["adminPassword"],
                   },
               })
               ```
        """
        pulumi.set(__self__, "url", url)
        if basic_auth is not None:
            pulumi.set(__self__, "basic_auth", basic_auth)

    @property
    @pulumi.getter
    def url(self) -> str:
        """
        URL for the Docker image
        """
        return pulumi.get(self, "url")

    @property
    @pulumi.getter(name="basicAuth")
    def basic_auth(self) -> Optional['outputs.ClusterDockerImageBasicAuth']:
        """
        `basic_auth.username` and `basic_auth.password` for Docker repository. Docker registry credentials are encrypted when they are stored in Databricks internal storage and when they are passed to a registry upon fetching Docker images at cluster launch. However, other authenticated and authorized API users of this workspace can access the username and password.

        Example usage with azurerm_container_registry, that you can adapt to your specific use-case:

        ```python
        import pulumi
        import pulumi_databricks as databricks
        import pulumi_docker as docker

        this = docker.index.RegistryImage("this",
            build=[{}],
            name=f{this_azurerm_container_registry.login_server}/sample:latest)
        this_cluster = databricks.Cluster("this", docker_image={
            "url": this["name"],
            "basic_auth": {
                "username": this_azurerm_container_registry["adminUsername"],
                "password": this_azurerm_container_registry["adminPassword"],
            },
        })
        ```
        """
        return pulumi.get(self, "basic_auth")


@pulumi.output_type
class ClusterDockerImageBasicAuth(dict):
    def __init__(__self__, *,
                 password: str,
                 username: str):
        pulumi.set(__self__, "password", password)
        pulumi.set(__self__, "username", username)

    @property
    @pulumi.getter
    def password(self) -> str:
        return pulumi.get(self, "password")

    @property
    @pulumi.getter
    def username(self) -> str:
        return pulumi.get(self, "username")


@pulumi.output_type
class ClusterGcpAttributes(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "bootDiskSize":
            suggest = "boot_disk_size"
        elif key == "googleServiceAccount":
            suggest = "google_service_account"
        elif key == "localSsdCount":
            suggest = "local_ssd_count"
        elif key == "usePreemptibleExecutors":
            suggest = "use_preemptible_executors"
        elif key == "zoneId":
            suggest = "zone_id"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterGcpAttributes. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterGcpAttributes.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterGcpAttributes.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 availability: Optional[str] = None,
                 boot_disk_size: Optional[int] = None,
                 google_service_account: Optional[str] = None,
                 local_ssd_count: Optional[int] = None,
                 use_preemptible_executors: Optional[bool] = None,
                 zone_id: Optional[str] = None):
        """
        :param str availability: Availability type used for all nodes. Valid values are `PREEMPTIBLE_GCP`, `PREEMPTIBLE_WITH_FALLBACK_GCP` and `ON_DEMAND_GCP`, default: `ON_DEMAND_GCP`.
        :param int boot_disk_size: Boot disk size in GB
        :param str google_service_account: Google Service Account email address that the cluster uses to authenticate with Google Identity. This field is used for authentication with the GCS and BigQuery data sources.
        :param int local_ssd_count: Number of local SSD disks (each is 375GB in size) that will be attached to each node of the cluster.
        :param bool use_preemptible_executors: if we should use preemptible executors ([GCP documentation](https://cloud.google.com/compute/docs/instances/preemptible)). *Warning: this field is deprecated in favor of `availability`, and will be removed soon.*
        :param str zone_id: Identifier for the availability zone in which the cluster resides. This can be one of the following:
               * `HA` (default): High availability, spread nodes across availability zones for a Databricks deployment region.
               * `AUTO`: Databricks picks an availability zone to schedule the cluster on.
               * name of a GCP availability zone: pick one of the available zones from the [list of available availability zones](https://cloud.google.com/compute/docs/regions-zones#available).
        """
        if availability is not None:
            pulumi.set(__self__, "availability", availability)
        if boot_disk_size is not None:
            pulumi.set(__self__, "boot_disk_size", boot_disk_size)
        if google_service_account is not None:
            pulumi.set(__self__, "google_service_account", google_service_account)
        if local_ssd_count is not None:
            pulumi.set(__self__, "local_ssd_count", local_ssd_count)
        if use_preemptible_executors is not None:
            pulumi.set(__self__, "use_preemptible_executors", use_preemptible_executors)
        if zone_id is not None:
            pulumi.set(__self__, "zone_id", zone_id)

    @property
    @pulumi.getter
    def availability(self) -> Optional[str]:
        """
        Availability type used for all nodes. Valid values are `PREEMPTIBLE_GCP`, `PREEMPTIBLE_WITH_FALLBACK_GCP` and `ON_DEMAND_GCP`, default: `ON_DEMAND_GCP`.
        """
        return pulumi.get(self, "availability")

    @property
    @pulumi.getter(name="bootDiskSize")
    def boot_disk_size(self) -> Optional[int]:
        """
        Boot disk size in GB
        """
        return pulumi.get(self, "boot_disk_size")

    @property
    @pulumi.getter(name="googleServiceAccount")
    def google_service_account(self) -> Optional[str]:
        """
        Google Service Account email address that the cluster uses to authenticate with Google Identity. This field is used for authentication with the GCS and BigQuery data sources.
        """
        return pulumi.get(self, "google_service_account")

    @property
    @pulumi.getter(name="localSsdCount")
    def local_ssd_count(self) -> Optional[int]:
        """
        Number of local SSD disks (each is 375GB in size) that will be attached to each node of the cluster.
        """
        return pulumi.get(self, "local_ssd_count")

    @property
    @pulumi.getter(name="usePreemptibleExecutors")
    def use_preemptible_executors(self) -> Optional[bool]:
        """
        if we should use preemptible executors ([GCP documentation](https://cloud.google.com/compute/docs/instances/preemptible)). *Warning: this field is deprecated in favor of `availability`, and will be removed soon.*
        """
        return pulumi.get(self, "use_preemptible_executors")

    @property
    @pulumi.getter(name="zoneId")
    def zone_id(self) -> Optional[str]:
        """
        Identifier for the availability zone in which the cluster resides. This can be one of the following:
        * `HA` (default): High availability, spread nodes across availability zones for a Databricks deployment region.
        * `AUTO`: Databricks picks an availability zone to schedule the cluster on.
        * name of a GCP availability zone: pick one of the available zones from the [list of available availability zones](https://cloud.google.com/compute/docs/regions-zones#available).
        """
        return pulumi.get(self, "zone_id")


@pulumi.output_type
class ClusterInitScript(dict):
    def __init__(__self__, *,
                 abfss: Optional['outputs.ClusterInitScriptAbfss'] = None,
                 dbfs: Optional['outputs.ClusterInitScriptDbfs'] = None,
                 file: Optional['outputs.ClusterInitScriptFile'] = None,
                 gcs: Optional['outputs.ClusterInitScriptGcs'] = None,
                 s3: Optional['outputs.ClusterInitScriptS3'] = None,
                 volumes: Optional['outputs.ClusterInitScriptVolumes'] = None,
                 workspace: Optional['outputs.ClusterInitScriptWorkspace'] = None):
        if abfss is not None:
            pulumi.set(__self__, "abfss", abfss)
        if dbfs is not None:
            pulumi.set(__self__, "dbfs", dbfs)
        if file is not None:
            pulumi.set(__self__, "file", file)
        if gcs is not None:
            pulumi.set(__self__, "gcs", gcs)
        if s3 is not None:
            pulumi.set(__self__, "s3", s3)
        if volumes is not None:
            pulumi.set(__self__, "volumes", volumes)
        if workspace is not None:
            pulumi.set(__self__, "workspace", workspace)

    @property
    @pulumi.getter
    def abfss(self) -> Optional['outputs.ClusterInitScriptAbfss']:
        return pulumi.get(self, "abfss")

    @property
    @pulumi.getter
    @_utilities.deprecated("""For init scripts use 'volumes', 'workspace' or cloud storage location instead of 'dbfs'.""")
    def dbfs(self) -> Optional['outputs.ClusterInitScriptDbfs']:
        return pulumi.get(self, "dbfs")

    @property
    @pulumi.getter
    def file(self) -> Optional['outputs.ClusterInitScriptFile']:
        return pulumi.get(self, "file")

    @property
    @pulumi.getter
    def gcs(self) -> Optional['outputs.ClusterInitScriptGcs']:
        return pulumi.get(self, "gcs")

    @property
    @pulumi.getter
    def s3(self) -> Optional['outputs.ClusterInitScriptS3']:
        return pulumi.get(self, "s3")

    @property
    @pulumi.getter
    def volumes(self) -> Optional['outputs.ClusterInitScriptVolumes']:
        return pulumi.get(self, "volumes")

    @property
    @pulumi.getter
    def workspace(self) -> Optional['outputs.ClusterInitScriptWorkspace']:
        return pulumi.get(self, "workspace")


@pulumi.output_type
class ClusterInitScriptAbfss(dict):
    def __init__(__self__, *,
                 destination: str):
        """
        :param str destination: S3 destination, e.g., `s3://my-bucket/some-prefix` You must configure the cluster with an instance profile, and the instance profile must have write access to the destination. You cannot use AWS keys.
        """
        pulumi.set(__self__, "destination", destination)

    @property
    @pulumi.getter
    def destination(self) -> str:
        """
        S3 destination, e.g., `s3://my-bucket/some-prefix` You must configure the cluster with an instance profile, and the instance profile must have write access to the destination. You cannot use AWS keys.
        """
        return pulumi.get(self, "destination")


@pulumi.output_type
class ClusterInitScriptDbfs(dict):
    def __init__(__self__, *,
                 destination: str):
        """
        :param str destination: S3 destination, e.g., `s3://my-bucket/some-prefix` You must configure the cluster with an instance profile, and the instance profile must have write access to the destination. You cannot use AWS keys.
        """
        pulumi.set(__self__, "destination", destination)

    @property
    @pulumi.getter
    def destination(self) -> str:
        """
        S3 destination, e.g., `s3://my-bucket/some-prefix` You must configure the cluster with an instance profile, and the instance profile must have write access to the destination. You cannot use AWS keys.
        """
        return pulumi.get(self, "destination")


@pulumi.output_type
class ClusterInitScriptFile(dict):
    def __init__(__self__, *,
                 destination: str):
        """
        :param str destination: S3 destination, e.g., `s3://my-bucket/some-prefix` You must configure the cluster with an instance profile, and the instance profile must have write access to the destination. You cannot use AWS keys.
        """
        pulumi.set(__self__, "destination", destination)

    @property
    @pulumi.getter
    def destination(self) -> str:
        """
        S3 destination, e.g., `s3://my-bucket/some-prefix` You must configure the cluster with an instance profile, and the instance profile must have write access to the destination. You cannot use AWS keys.
        """
        return pulumi.get(self, "destination")


@pulumi.output_type
class ClusterInitScriptGcs(dict):
    def __init__(__self__, *,
                 destination: str):
        """
        :param str destination: S3 destination, e.g., `s3://my-bucket/some-prefix` You must configure the cluster with an instance profile, and the instance profile must have write access to the destination. You cannot use AWS keys.
        """
        pulumi.set(__self__, "destination", destination)

    @property
    @pulumi.getter
    def destination(self) -> str:
        """
        S3 destination, e.g., `s3://my-bucket/some-prefix` You must configure the cluster with an instance profile, and the instance profile must have write access to the destination. You cannot use AWS keys.
        """
        return pulumi.get(self, "destination")


@pulumi.output_type
class ClusterInitScriptS3(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "cannedAcl":
            suggest = "canned_acl"
        elif key == "enableEncryption":
            suggest = "enable_encryption"
        elif key == "encryptionType":
            suggest = "encryption_type"
        elif key == "kmsKey":
            suggest = "kms_key"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ClusterInitScriptS3. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ClusterInitScriptS3.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ClusterInitScriptS3.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 destination: str,
                 canned_acl: Optional[str] = None,
                 enable_encryption: Optional[bool] = None,
                 encryption_type: Optional[str] = None,
                 endpoint: Optional[str] = None,
                 kms_key: Optional[str] = None,
                 region: Optional[str] = None):
        """
        :param str destination: S3 destination, e.g., `s3://my-bucket/some-prefix` You must configure the cluster with an instance profile, and the instance profile must have write access to the destination. You cannot use AWS keys.
        :param str canned_acl: Set canned access control list, e.g. `bucket-owner-full-control`. If `canned_cal` is set, the cluster instance profile must have `s3:PutObjectAcl` permission on the destination bucket and prefix. The full list of possible canned ACLs can be found [here](https://docs.aws.amazon.com/AmazonS3/latest/dev/acl-overview.html#canned-acl). By default, only the object owner gets full control. If you are using a cross-account role for writing data, you may want to set `bucket-owner-full-control` to make bucket owners able to read the logs.
        :param bool enable_encryption: Enable server-side encryption, false by default.
        :param str encryption_type: The encryption type, it could be `sse-s3` or `sse-kms`. It is used only when encryption is enabled, and the default type is `sse-s3`.
        :param str endpoint: S3 endpoint, e.g. <https://s3-us-west-2.amazonaws.com>. Either `region` or `endpoint` needs to be set. If both are set, the endpoint is used.
        :param str kms_key: KMS key used if encryption is enabled and encryption type is set to `sse-kms`.
        :param str region: S3 region, e.g. `us-west-2`. Either `region` or `endpoint` must be set. If both are set, the endpoint is used.
        """
        pulumi.set(__self__, "destination", destination)
        if canned_acl is not None:
            pulumi.set(__self__, "canned_acl", canned_acl)
        if enable_encryption is not None:
            pulumi.set(__self__, "enable_encryption", enable_encryption)
        if encryption_type is not None:
            pulumi.set(__self__, "encryption_type", encryption_type)
        if endpoint is not None:
            pulumi.set(__self__, "endpoint", endpoint)
        if kms_key is not None:
            pulumi.set(__self__, "kms_key", kms_key)
        if region is not None:
            pulumi.set(__self__, "region", region)

    @property
    @pulumi.getter
    def destination(self) -> str:
        """
        S3 destination, e.g., `s3://my-bucket/some-prefix` You must configure the cluster with an instance profile, and the instance profile must have write access to the destination. You cannot use AWS keys.
        """
        return pulumi.get(self, "destination")

    @property
    @pulumi.getter(name="cannedAcl")
    def canned_acl(self) -> Optional[str]:
        """
        Set canned access control list, e.g. `bucket-owner-full-control`. If `canned_cal` is set, the cluster instance profile must have `s3:PutObjectAcl` permission on the destination bucket and prefix. The full list of possible canned ACLs can be found [here](https://docs.aws.amazon.com/AmazonS3/latest/dev/acl-overview.html#canned-acl). By default, only the object owner gets full control. If you are using a cross-account role for writing data, you may want to set `bucket-owner-full-control` to make bucket owners able to read the logs.
        """
        return pulumi.get(self, "canned_acl")

    @property
    @pulumi.getter(name="enableEncryption")
    def enable_encryption(self) -> Optional[bool]:
        """
        Enable server-side encryption, false by default.
        """
        return pulumi.get(self, "enable_encryption")

    @property
    @pulumi.getter(name="encryptionType")
    def encryption_type(self) -> Optional[str]:
        """
        The encryption type, it could be `sse-s3` or `sse-kms`. It is used only when encryption is enabled, and the default type is `sse-s3`.
        """
        return pulumi.get(self, "encryption_type")

    @property
    @pulumi.getter
    def endpoint(self) -> Optional[str]:
        """
        S3 endpoint, e.g. <https://s3-us-west-2.amazonaws.com>. Either `region` or `endpoint` needs to be set. If both are set, the endpoint is used.
        """
        return pulumi.get(self, "endpoint")

    @property
    @pulumi.getter(name="kmsKey")
    def kms_key(self) -> Optional[str]:
        """
        KMS key used if encryption is enabled and encryption type is set to `sse-kms`.
        """
        return pulumi.get(self, "kms_key")

    @property
    @pulumi.getter
    def region(self) -> Optional[str]:
        """
        S3 region, e.g. `us-west-2`. Either `region` or `endpoint` must be set. If both are set, the endpoint is used.
        """
        return pulumi.get(self, "region")


@pulumi.output_type
class ClusterInitScriptVolumes(dict):
    def __init__(__self__, *,
                 destination: str):
        """
        :param str destination: S3 destination, e.g., `s3://my-bucket/some-prefix` You must configure the cluster with an instance profile, and the instance profile must have write access to the destination. You cannot use AWS keys.
        """
        pulumi.set(__self__, "destination", destination)

    @property
    @pulumi.getter
    def destination(self) -> str:
        """
        S3 destination, e.g., `s3://my-bucket/some-prefix` You must configure the cluster with an instance profile, and the instance profile must have write access to the destination. You cannot use AWS keys.
        """
        return pulumi.get(self, "destination")


@pulumi.output_type
class ClusterInitScriptWorkspace(dict):
    def __init__(__self__, *,
                 destination: str):
        """
        :param str destination: S3 destination, e.g., `s3://my-bucket/some-prefix` You must configure the cluster with an instance profile, and the instance profile must have write access to the destination. You cannot use AWS keys.
        """
        pulumi.set(__self__, "destination", destination)

    @property
    @pulumi.getter
    def destination(self) -> str:
        """
        S3 destination, e.g., `s3://my-bucket/some-prefix` You must configure the cluster with an instance profile, and the instance profile must have write access to the destination. You cannot use AWS keys.
        """
        return pulumi.get(self, "destination")


@pulumi.output_type
class ClusterLibrary(dict):
    def __init__(__self__, *,
                 cran: Optional['outputs.ClusterLibraryCran'] = None,
                 egg: Optional[str] = None,
                 jar: Optional[str] = None,
                 maven: Optional['outputs.ClusterLibraryMaven'] = None,
                 pypi: Optional['outputs.ClusterLibraryPypi'] = None,
                 requirements: Optional[str] = None,
                 whl: Optional[str] = None):
        if cran is not None:
            pulumi.set(__self__, "cran", cran)
        if egg is not None:
            pulumi.set(__self__, "egg", egg)
        if jar is not None:
            pulumi.set(__self__, "jar", jar)
        if maven is not None:
            pulumi.set(__self__, "maven", maven)
        if pypi is not None:
            pulumi.set(__self__, "pypi", pypi)
        if requirements is not None:
            pulumi.set(__self__, "requirements", requirements)
        if whl is not None:
            pulumi.set(__self__, "whl", whl)

    @property
    @pulumi.getter
    def cran(self) -> Optional['outputs.ClusterLibraryCran']:
        return pulumi.get(self, "cran")

    @property
    @pulumi.getter
    def egg(self) -> Optional[str]:
        return pulumi.get(self, "egg")

    @property
    @pulumi.getter
    def jar(self) -> Optional[str]:
        return pulumi.get(self, "jar")

    @property
    @pulumi.getter
    def maven(self) -> Optional['outputs.ClusterLibraryMaven']:
        return pulumi.get(self, "maven")

    @property
    @pulumi.getter
    def pypi(self) -> Optional['outputs.ClusterLibraryPypi']:
        return pulumi.get(self, "pypi")

    @property
    @pulumi.getter
    def requirements(self) -> Optional[str]:
        return pulumi.get(self, "requirements")

    @property
    @pulumi.getter
    def whl(self) -> Optional[str]:
        return pulumi.get(self, "whl")


@pulumi.output_type
class ClusterLibraryCran(dict):
    def __init__(__self__, *,
                 package: str,
                 repo: Optional[str] = None):
        pulumi.set(__self__, "package", package)
        if repo is not None:
            pulumi.set(__self__, "repo", repo)

    @property
    @pulumi.getter
    def package(self) -> str:
        return pulumi.get(self, "package")

    @property
    @pulumi.getter
    def repo(self) -> Optional[str]:
        return pulumi.get(self, "repo")


@pulumi.output_type
class ClusterLibraryMaven(dict):
    def __init__(__self__, *,
                 coordinates: str,
                 exclusions: Optional[Sequence[str]] = None,
                 repo: Optional[str] = None):
        pulumi.set(__self__, "coordinates", coordinates)
        if exclusions is not None:
            pulumi.set(__self__, "exclusions", exclusions)
        if repo is not None:
            pulumi.set(__self__, "repo", repo)

    @property
    @pulumi.getter
    def coordinates(self) -> str:
        return pulumi.get(self, "coordinates")

    @property
    @pulumi.getter
    def exclusions(self) -> Optional[Sequence[str]]:
        return pulumi.get(self, "exclusions")

    @property
    @pulumi.getter
    def repo(self) -> Optional[str]:
        return pulumi.get(self, "repo")


@pulumi.output_type
class ClusterLibraryPypi(dict):
    def __init__(__self__, *,
                 package: str,
                 repo: Optional[str] = None):
        pulumi.set(__self__, "package", package)
        if repo is not None:
            pulumi.set(__self__, "repo", repo)

    @property
    @pulumi.getter
    def package(self) -> str:
        return pulumi.get(self, "package")

    @property
    @pulumi.getter
    def repo(self) -> Optional[str]:
        return pulumi.get(self, "repo")


@pulumi.output_type
class ClusterPolicyLibrary(dict):
    def __init__(__self__, *,
                 cran: Optional['outputs.ClusterPolicyLibraryCran'] = None,
                 egg: Optional[str] = None,
                 jar: Optional[str] = None,
                 maven: Optional['outputs.ClusterPolicyLibraryMaven'] = None,
                 pypi: Optional['outputs.ClusterPolicyLibraryPypi'] = None,
                 requirements: Optional[str] = None,
                 whl: Optional[str] = None):
        if cran is not None:
            pulumi.set(__self__, "cran", cran)
        if egg is not None:
            pulumi.set(__self__, "egg", egg)
        if jar is not None:
            pulumi.set(__self__, "jar", jar)
        if maven is not None:
            pulumi.set(__self__, "maven", maven)
        if pypi is not None:
            pulumi.set(__self__, "pypi", pypi)
        if requirements is not None:
            pulumi.set(__self__, "requirements", requirements)
        if whl is not None:
            pulumi.set(__self__, "whl", whl)

    @property
    @pulumi.getter
    def cran(self) -> Optional['outputs.ClusterPolicyLibraryCran']:
        return pulumi.get(self, "cran")

    @property
    @pulumi.getter
    def egg(self) -> Optional[str]:
        return pulumi.get(self, "egg")

    @property
    @pulumi.getter
    def jar(self) -> Optional[str]:
        return pulumi.get(self, "jar")

    @property
    @pulumi.getter
    def maven(self) -> Optional['outputs.ClusterPolicyLibraryMaven']:
        return pulumi.get(self, "maven")

    @property
    @pulumi.getter
    def pypi(self) -> Optional['outputs.ClusterPolicyLibraryPypi']:
        return pulumi.get(self, "pypi")

    @property
    @pulumi.getter
    def requirements(self) -> Optional[str]:
        return pulumi.get(self, "requirements")

    @property
    @pulumi.getter
    def whl(self) -> Optional[str]:
        return pulumi.get(self, "whl")


@pulumi.output_type
class ClusterPolicyLibraryCran(dict):
    def __init__(__self__, *,
                 package: str,
                 repo: Optional[str] = None):
        pulumi.set(__self__, "package", package)
        if repo is not None:
            pulumi.set(__self__, "repo", repo)

    @property
    @pulumi.getter
    def package(self) -> str:
        return pulumi.get(self, "package")

    @property
    @pulumi.getter
    def repo(self) -> Optional[str]:
        return pulumi.get(self, "repo")


@pulumi.output_type
class ClusterPolicyLibraryMaven(dict):
    def __init__(__self__, *,
                 coordinates: str,
                 exclusions: Optional[Sequence[str]] = None,
                 repo: Optional[str] = None):
        pulumi.set(__self__, "coordinates", coordinates)
        if exclusions is not None:
            pulumi.set(__self__, "exclusions", exclusions)
        if repo is not None:
            pulumi.set(__self__, "repo", repo)

    @property
    @pulumi.getter
    def coordinates(self) -> str:
        return pulumi.get(self, "coordinates")

    @property
    @pulumi.getter
    def exclusions(self) -> Optional[Sequence[str]]:
        return pulumi.get(self, "exclusions")

    @property
    @pulumi.getter
    def repo(self) -> Optional[str]:
        return pulumi.get(self, "repo")


@pulumi.output_type
class ClusterPolicyLibraryPypi(dict):
    def __init__(__self__, *,
                 package: str,
                 repo: Optional[str] = None):
        pulumi.set(__self__, "package", package)
        if repo is not None:
            pulumi.set(__self__, "repo", repo)

    @property
    @pulumi.getter
    def package(self) -> str:
        return pulumi.get(self, "package")

    @property
    @pulumi.getter
    def repo(self) -> Optional[str]:
        return pulumi.get(self, "repo")


@pulumi.output_type
class ClusterWorkloadType(dict):
    def __init__(__self__, *,
                 clients: 'outputs.ClusterWorkloadTypeClients'):
        pulumi.set(__self__, "clients", clients)

    @property
    @pulumi.getter
    def clients(self) -> 'outputs.ClusterWorkloadTypeClients':
        return pulumi.get(self, "clients")


@pulumi.output_type
class ClusterWorkloadTypeClients(dict):
    def __init__(__self__, *,
                 jobs: Optional[bool] = None,
                 notebooks: Optional[bool] = None):
        """
        :param bool jobs: boolean flag defining if it's possible to run Databricks Jobs on this cluster. Default: `true`.
               
               ```python
               import pulumi
               import pulumi_databricks as databricks
               
               with_nfs = databricks.Cluster("with_nfs", workload_type={
                   "clients": {
                       "jobs": False,
                       "notebooks": True,
                   },
               })
               ```
        :param bool notebooks: boolean flag defining if it's possible to run notebooks on this cluster. Default: `true`.
        """
        if jobs is not None:
            pulumi.set(__self__, "jobs", jobs)
        if notebooks is not None:
            pulumi.set(__self__, "notebooks", notebooks)

    @property
    @pulumi.getter
    def jobs(self) -> Optional[bool]:
        """
        boolean flag defining if it's possible to run Databricks Jobs on this cluster. Default: `true`.

        ```python
        import pulumi
        import pulumi_databricks as databricks

        with_nfs = databricks.Cluster("with_nfs", workload_type={
            "clients": {
                "jobs": False,
                "notebooks": True,
            },
        })
        ```
        """
        return pulumi.get(self, "jobs")

    @property
    @pulumi.getter
    def notebooks(self) -> Optional[bool]:
        """
        boolean flag defining if it's possible to run notebooks on this cluster. Default: `true`.
        """
        return pulumi.get(self, "notebooks")


@pulumi.output_type
class ComplianceSecurityProfileWorkspaceSettingComplianceSecurityProfileWorkspace(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "complianceStandards":
            suggest = "compliance_standards"
        elif key == "isEnabled":
            suggest = "is_enabled"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ComplianceSecurityProfileWorkspaceSettingComplianceSecurityProfileWorkspace. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ComplianceSecurityProfileWorkspaceSettingComplianceSecurityProfileWorkspace.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ComplianceSecurityProfileWorkspaceSettingComplianceSecurityProfileWorkspace.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 compliance_standards: Optional[Sequence[str]] = None,
                 is_enabled: Optional[bool] = None):
        if compliance_standards is not None:
            pulumi.set(__self__, "compliance_standards", compliance_standards)
        if is_enabled is not None:
            pulumi.set(__self__, "is_enabled", is_enabled)

    @property
    @pulumi.getter(name="complianceStandards")
    def compliance_standards(self) -> Optional[Sequence[str]]:
        return pulumi.get(self, "compliance_standards")

    @property
    @pulumi.getter(name="isEnabled")
    def is_enabled(self) -> Optional[bool]:
        return pulumi.get(self, "is_enabled")


@pulumi.output_type
class DefaultNamespaceSettingNamespace(dict):
    def __init__(__self__, *,
                 value: Optional[str] = None):
        """
        :param str value: The value for the setting.
        """
        if value is not None:
            pulumi.set(__self__, "value", value)

    @property
    @pulumi.getter
    def value(self) -> Optional[str]:
        """
        The value for the setting.
        """
        return pulumi.get(self, "value")


@pulumi.output_type
class EnhancedSecurityMonitoringWorkspaceSettingEnhancedSecurityMonitoringWorkspace(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "isEnabled":
            suggest = "is_enabled"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in EnhancedSecurityMonitoringWorkspaceSettingEnhancedSecurityMonitoringWorkspace. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        EnhancedSecurityMonitoringWorkspaceSettingEnhancedSecurityMonitoringWorkspace.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        EnhancedSecurityMonitoringWorkspaceSettingEnhancedSecurityMonitoringWorkspace.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 is_enabled: Optional[bool] = None):
        if is_enabled is not None:
            pulumi.set(__self__, "is_enabled", is_enabled)

    @property
    @pulumi.getter(name="isEnabled")
    def is_enabled(self) -> Optional[bool]:
        return pulumi.get(self, "is_enabled")


@pulumi.output_type
class ExternalLocationEncryptionDetails(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "sseEncryptionDetails":
            suggest = "sse_encryption_details"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ExternalLocationEncryptionDetails. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ExternalLocationEncryptionDetails.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ExternalLocationEncryptionDetails.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 sse_encryption_details: Optional['outputs.ExternalLocationEncryptionDetailsSseEncryptionDetails'] = None):
        if sse_encryption_details is not None:
            pulumi.set(__self__, "sse_encryption_details", sse_encryption_details)

    @property
    @pulumi.getter(name="sseEncryptionDetails")
    def sse_encryption_details(self) -> Optional['outputs.ExternalLocationEncryptionDetailsSseEncryptionDetails']:
        return pulumi.get(self, "sse_encryption_details")


@pulumi.output_type
class ExternalLocationEncryptionDetailsSseEncryptionDetails(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "awsKmsKeyArn":
            suggest = "aws_kms_key_arn"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ExternalLocationEncryptionDetailsSseEncryptionDetails. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ExternalLocationEncryptionDetailsSseEncryptionDetails.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ExternalLocationEncryptionDetailsSseEncryptionDetails.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 algorithm: Optional[str] = None,
                 aws_kms_key_arn: Optional[str] = None):
        if algorithm is not None:
            pulumi.set(__self__, "algorithm", algorithm)
        if aws_kms_key_arn is not None:
            pulumi.set(__self__, "aws_kms_key_arn", aws_kms_key_arn)

    @property
    @pulumi.getter
    def algorithm(self) -> Optional[str]:
        return pulumi.get(self, "algorithm")

    @property
    @pulumi.getter(name="awsKmsKeyArn")
    def aws_kms_key_arn(self) -> Optional[str]:
        return pulumi.get(self, "aws_kms_key_arn")


@pulumi.output_type
class GrantsGrant(dict):
    def __init__(__self__, *,
                 principal: str,
                 privileges: Sequence[str]):
        pulumi.set(__self__, "principal", principal)
        pulumi.set(__self__, "privileges", privileges)

    @property
    @pulumi.getter
    def principal(self) -> str:
        return pulumi.get(self, "principal")

    @property
    @pulumi.getter
    def privileges(self) -> Sequence[str]:
        return pulumi.get(self, "privileges")


@pulumi.output_type
class InstancePoolAwsAttributes(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "spotBidPricePercent":
            suggest = "spot_bid_price_percent"
        elif key == "zoneId":
            suggest = "zone_id"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in InstancePoolAwsAttributes. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        InstancePoolAwsAttributes.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        InstancePoolAwsAttributes.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 availability: Optional[str] = None,
                 spot_bid_price_percent: Optional[int] = None,
                 zone_id: Optional[str] = None):
        """
        :param str availability: (String) Availability type used for all instances in the pool. Only `ON_DEMAND` and `SPOT` are supported.
        :param int spot_bid_price_percent: (Integer) The max price for AWS spot instances, as a percentage of the corresponding instance types on-demand price. For example, if this field is set to 50, and the instance pool needs a new i3.xlarge spot instance, then the max price is half of the price of on-demand i3.xlarge instances. Similarly, if this field is set to 200, the max price is twice the price of on-demand i3.xlarge instances. If not specified, the *default value is 100*. When spot instances are requested for this instance pool, only spot instances whose max price percentage matches this field are considered. *For safety, this field cannot be greater than 10000.*
        :param str zone_id: (String) Identifier for the availability zone/datacenter in which the instance pool resides. This string is of the form like `"us-west-2a"`. The provided availability zone must be in the same region as the Databricks deployment. For example, `"us-west-2a"` is not a valid zone ID if the Databricks deployment resides in the `"us-east-1"` region. If not specified, a default zone is used. You can find the list of available zones as well as the default value by using the [List Zones API](https://docs.databricks.com/dev-tools/api/latest/clusters.html#clusterclusterservicelistavailablezones).
        """
        if availability is not None:
            pulumi.set(__self__, "availability", availability)
        if spot_bid_price_percent is not None:
            pulumi.set(__self__, "spot_bid_price_percent", spot_bid_price_percent)
        if zone_id is not None:
            pulumi.set(__self__, "zone_id", zone_id)

    @property
    @pulumi.getter
    def availability(self) -> Optional[str]:
        """
        (String) Availability type used for all instances in the pool. Only `ON_DEMAND` and `SPOT` are supported.
        """
        return pulumi.get(self, "availability")

    @property
    @pulumi.getter(name="spotBidPricePercent")
    def spot_bid_price_percent(self) -> Optional[int]:
        """
        (Integer) The max price for AWS spot instances, as a percentage of the corresponding instance types on-demand price. For example, if this field is set to 50, and the instance pool needs a new i3.xlarge spot instance, then the max price is half of the price of on-demand i3.xlarge instances. Similarly, if this field is set to 200, the max price is twice the price of on-demand i3.xlarge instances. If not specified, the *default value is 100*. When spot instances are requested for this instance pool, only spot instances whose max price percentage matches this field are considered. *For safety, this field cannot be greater than 10000.*
        """
        return pulumi.get(self, "spot_bid_price_percent")

    @property
    @pulumi.getter(name="zoneId")
    def zone_id(self) -> Optional[str]:
        """
        (String) Identifier for the availability zone/datacenter in which the instance pool resides. This string is of the form like `"us-west-2a"`. The provided availability zone must be in the same region as the Databricks deployment. For example, `"us-west-2a"` is not a valid zone ID if the Databricks deployment resides in the `"us-east-1"` region. If not specified, a default zone is used. You can find the list of available zones as well as the default value by using the [List Zones API](https://docs.databricks.com/dev-tools/api/latest/clusters.html#clusterclusterservicelistavailablezones).
        """
        return pulumi.get(self, "zone_id")


@pulumi.output_type
class InstancePoolAzureAttributes(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "spotBidMaxPrice":
            suggest = "spot_bid_max_price"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in InstancePoolAzureAttributes. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        InstancePoolAzureAttributes.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        InstancePoolAzureAttributes.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 availability: Optional[str] = None,
                 spot_bid_max_price: Optional[float] = None):
        """
        :param str availability: Availability type used for all nodes. Valid values are `SPOT_AZURE` and `ON_DEMAND_AZURE`.
        :param float spot_bid_max_price: The max bid price used for Azure spot instances. You can set this to greater than or equal to the current spot price. You can also set this to `-1`, which specifies that the instance cannot be evicted on the basis of price. The price for the instance will be the current price for spot instances or the price for a standard instance.
        """
        if availability is not None:
            pulumi.set(__self__, "availability", availability)
        if spot_bid_max_price is not None:
            pulumi.set(__self__, "spot_bid_max_price", spot_bid_max_price)

    @property
    @pulumi.getter
    def availability(self) -> Optional[str]:
        """
        Availability type used for all nodes. Valid values are `SPOT_AZURE` and `ON_DEMAND_AZURE`.
        """
        return pulumi.get(self, "availability")

    @property
    @pulumi.getter(name="spotBidMaxPrice")
    def spot_bid_max_price(self) -> Optional[float]:
        """
        The max bid price used for Azure spot instances. You can set this to greater than or equal to the current spot price. You can also set this to `-1`, which specifies that the instance cannot be evicted on the basis of price. The price for the instance will be the current price for spot instances or the price for a standard instance.
        """
        return pulumi.get(self, "spot_bid_max_price")


@pulumi.output_type
class InstancePoolDiskSpec(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "diskCount":
            suggest = "disk_count"
        elif key == "diskSize":
            suggest = "disk_size"
        elif key == "diskType":
            suggest = "disk_type"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in InstancePoolDiskSpec. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        InstancePoolDiskSpec.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        InstancePoolDiskSpec.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 disk_count: Optional[int] = None,
                 disk_size: Optional[int] = None,
                 disk_type: Optional['outputs.InstancePoolDiskSpecDiskType'] = None):
        """
        :param int disk_count: (Integer) The number of disks to attach to each instance. This feature is only enabled for supported node types. Users can choose up to the limit of the disks supported by the node type. For node types with no local disk, at least one disk needs to be specified.
        :param int disk_size: (Integer) The size of each disk (in GiB) to attach.
        """
        if disk_count is not None:
            pulumi.set(__self__, "disk_count", disk_count)
        if disk_size is not None:
            pulumi.set(__self__, "disk_size", disk_size)
        if disk_type is not None:
            pulumi.set(__self__, "disk_type", disk_type)

    @property
    @pulumi.getter(name="diskCount")
    def disk_count(self) -> Optional[int]:
        """
        (Integer) The number of disks to attach to each instance. This feature is only enabled for supported node types. Users can choose up to the limit of the disks supported by the node type. For node types with no local disk, at least one disk needs to be specified.
        """
        return pulumi.get(self, "disk_count")

    @property
    @pulumi.getter(name="diskSize")
    def disk_size(self) -> Optional[int]:
        """
        (Integer) The size of each disk (in GiB) to attach.
        """
        return pulumi.get(self, "disk_size")

    @property
    @pulumi.getter(name="diskType")
    def disk_type(self) -> Optional['outputs.InstancePoolDiskSpecDiskType']:
        return pulumi.get(self, "disk_type")


@pulumi.output_type
class InstancePoolDiskSpecDiskType(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "azureDiskVolumeType":
            suggest = "azure_disk_volume_type"
        elif key == "ebsVolumeType":
            suggest = "ebs_volume_type"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in InstancePoolDiskSpecDiskType. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        InstancePoolDiskSpecDiskType.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        InstancePoolDiskSpecDiskType.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 azure_disk_volume_type: Optional[str] = None,
                 ebs_volume_type: Optional[str] = None):
        if azure_disk_volume_type is not None:
            pulumi.set(__self__, "azure_disk_volume_type", azure_disk_volume_type)
        if ebs_volume_type is not None:
            pulumi.set(__self__, "ebs_volume_type", ebs_volume_type)

    @property
    @pulumi.getter(name="azureDiskVolumeType")
    def azure_disk_volume_type(self) -> Optional[str]:
        return pulumi.get(self, "azure_disk_volume_type")

    @property
    @pulumi.getter(name="ebsVolumeType")
    def ebs_volume_type(self) -> Optional[str]:
        return pulumi.get(self, "ebs_volume_type")


@pulumi.output_type
class InstancePoolGcpAttributes(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "gcpAvailability":
            suggest = "gcp_availability"
        elif key == "localSsdCount":
            suggest = "local_ssd_count"
        elif key == "zoneId":
            suggest = "zone_id"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in InstancePoolGcpAttributes. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        InstancePoolGcpAttributes.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        InstancePoolGcpAttributes.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 gcp_availability: Optional[str] = None,
                 local_ssd_count: Optional[int] = None,
                 zone_id: Optional[str] = None):
        """
        :param str gcp_availability: Availability type used for all nodes. Valid values are `PREEMPTIBLE_GCP`, `PREEMPTIBLE_WITH_FALLBACK_GCP` and `ON_DEMAND_GCP`, default: `ON_DEMAND_GCP`.
        :param int local_ssd_count: Number of local SSD disks (each is 375GB in size) that will be attached to each node of the cluster.
        :param str zone_id: Identifier for the availability zone/datacenter in which the cluster resides. This string will be of a form like `us-central1-a`. The provided availability zone must be in the same region as the Databricks workspace.
        """
        if gcp_availability is not None:
            pulumi.set(__self__, "gcp_availability", gcp_availability)
        if local_ssd_count is not None:
            pulumi.set(__self__, "local_ssd_count", local_ssd_count)
        if zone_id is not None:
            pulumi.set(__self__, "zone_id", zone_id)

    @property
    @pulumi.getter(name="gcpAvailability")
    def gcp_availability(self) -> Optional[str]:
        """
        Availability type used for all nodes. Valid values are `PREEMPTIBLE_GCP`, `PREEMPTIBLE_WITH_FALLBACK_GCP` and `ON_DEMAND_GCP`, default: `ON_DEMAND_GCP`.
        """
        return pulumi.get(self, "gcp_availability")

    @property
    @pulumi.getter(name="localSsdCount")
    def local_ssd_count(self) -> Optional[int]:
        """
        Number of local SSD disks (each is 375GB in size) that will be attached to each node of the cluster.
        """
        return pulumi.get(self, "local_ssd_count")

    @property
    @pulumi.getter(name="zoneId")
    def zone_id(self) -> Optional[str]:
        """
        Identifier for the availability zone/datacenter in which the cluster resides. This string will be of a form like `us-central1-a`. The provided availability zone must be in the same region as the Databricks workspace.
        """
        return pulumi.get(self, "zone_id")


@pulumi.output_type
class InstancePoolInstancePoolFleetAttributes(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "launchTemplateOverrides":
            suggest = "launch_template_overrides"
        elif key == "fleetOnDemandOption":
            suggest = "fleet_on_demand_option"
        elif key == "fleetSpotOption":
            suggest = "fleet_spot_option"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in InstancePoolInstancePoolFleetAttributes. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        InstancePoolInstancePoolFleetAttributes.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        InstancePoolInstancePoolFleetAttributes.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 launch_template_overrides: Sequence['outputs.InstancePoolInstancePoolFleetAttributesLaunchTemplateOverride'],
                 fleet_on_demand_option: Optional['outputs.InstancePoolInstancePoolFleetAttributesFleetOnDemandOption'] = None,
                 fleet_spot_option: Optional['outputs.InstancePoolInstancePoolFleetAttributesFleetSpotOption'] = None):
        pulumi.set(__self__, "launch_template_overrides", launch_template_overrides)
        if fleet_on_demand_option is not None:
            pulumi.set(__self__, "fleet_on_demand_option", fleet_on_demand_option)
        if fleet_spot_option is not None:
            pulumi.set(__self__, "fleet_spot_option", fleet_spot_option)

    @property
    @pulumi.getter(name="launchTemplateOverrides")
    def launch_template_overrides(self) -> Sequence['outputs.InstancePoolInstancePoolFleetAttributesLaunchTemplateOverride']:
        return pulumi.get(self, "launch_template_overrides")

    @property
    @pulumi.getter(name="fleetOnDemandOption")
    def fleet_on_demand_option(self) -> Optional['outputs.InstancePoolInstancePoolFleetAttributesFleetOnDemandOption']:
        return pulumi.get(self, "fleet_on_demand_option")

    @property
    @pulumi.getter(name="fleetSpotOption")
    def fleet_spot_option(self) -> Optional['outputs.InstancePoolInstancePoolFleetAttributesFleetSpotOption']:
        return pulumi.get(self, "fleet_spot_option")


@pulumi.output_type
class InstancePoolInstancePoolFleetAttributesFleetOnDemandOption(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "allocationStrategy":
            suggest = "allocation_strategy"
        elif key == "instancePoolsToUseCount":
            suggest = "instance_pools_to_use_count"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in InstancePoolInstancePoolFleetAttributesFleetOnDemandOption. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        InstancePoolInstancePoolFleetAttributesFleetOnDemandOption.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        InstancePoolInstancePoolFleetAttributesFleetOnDemandOption.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 allocation_strategy: str,
                 instance_pools_to_use_count: Optional[int] = None):
        pulumi.set(__self__, "allocation_strategy", allocation_strategy)
        if instance_pools_to_use_count is not None:
            pulumi.set(__self__, "instance_pools_to_use_count", instance_pools_to_use_count)

    @property
    @pulumi.getter(name="allocationStrategy")
    def allocation_strategy(self) -> str:
        return pulumi.get(self, "allocation_strategy")

    @property
    @pulumi.getter(name="instancePoolsToUseCount")
    def instance_pools_to_use_count(self) -> Optional[int]:
        return pulumi.get(self, "instance_pools_to_use_count")


@pulumi.output_type
class InstancePoolInstancePoolFleetAttributesFleetSpotOption(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "allocationStrategy":
            suggest = "allocation_strategy"
        elif key == "instancePoolsToUseCount":
            suggest = "instance_pools_to_use_count"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in InstancePoolInstancePoolFleetAttributesFleetSpotOption. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        InstancePoolInstancePoolFleetAttributesFleetSpotOption.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        InstancePoolInstancePoolFleetAttributesFleetSpotOption.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 allocation_strategy: str,
                 instance_pools_to_use_count: Optional[int] = None):
        pulumi.set(__self__, "allocation_strategy", allocation_strategy)
        if instance_pools_to_use_count is not None:
            pulumi.set(__self__, "instance_pools_to_use_count", instance_pools_to_use_count)

    @property
    @pulumi.getter(name="allocationStrategy")
    def allocation_strategy(self) -> str:
        return pulumi.get(self, "allocation_strategy")

    @property
    @pulumi.getter(name="instancePoolsToUseCount")
    def instance_pools_to_use_count(self) -> Optional[int]:
        return pulumi.get(self, "instance_pools_to_use_count")


@pulumi.output_type
class InstancePoolInstancePoolFleetAttributesLaunchTemplateOverride(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "availabilityZone":
            suggest = "availability_zone"
        elif key == "instanceType":
            suggest = "instance_type"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in InstancePoolInstancePoolFleetAttributesLaunchTemplateOverride. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        InstancePoolInstancePoolFleetAttributesLaunchTemplateOverride.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        InstancePoolInstancePoolFleetAttributesLaunchTemplateOverride.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 availability_zone: str,
                 instance_type: str):
        pulumi.set(__self__, "availability_zone", availability_zone)
        pulumi.set(__self__, "instance_type", instance_type)

    @property
    @pulumi.getter(name="availabilityZone")
    def availability_zone(self) -> str:
        return pulumi.get(self, "availability_zone")

    @property
    @pulumi.getter(name="instanceType")
    def instance_type(self) -> str:
        return pulumi.get(self, "instance_type")


@pulumi.output_type
class InstancePoolPreloadedDockerImage(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "basicAuth":
            suggest = "basic_auth"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in InstancePoolPreloadedDockerImage. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        InstancePoolPreloadedDockerImage.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        InstancePoolPreloadedDockerImage.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 url: str,
                 basic_auth: Optional['outputs.InstancePoolPreloadedDockerImageBasicAuth'] = None):
        """
        :param str url: URL for the Docker image
        :param 'InstancePoolPreloadedDockerImageBasicAuthArgs' basic_auth: `basic_auth.username` and `basic_auth.password` for Docker repository. Docker registry credentials are encrypted when they are stored in Databricks internal storage and when they are passed to a registry upon fetching Docker images at cluster launch. However, other authenticated and authorized API users of this workspace can access the username and password.
               
               Example usage with azurerm_container_registry, that you can adapt to your specific use-case:
               
               ```python
               import pulumi
               import pulumi_databricks as databricks
               import pulumi_docker as docker
               
               this = docker.index.RegistryImage("this",
                   build=[{}],
                   name=f{this_azurerm_container_registry.login_server}/sample:latest)
               this_instance_pool = databricks.InstancePool("this", preloaded_docker_images=[{
                   "url": this["name"],
                   "basic_auth": {
                       "username": this_azurerm_container_registry["adminUsername"],
                       "password": this_azurerm_container_registry["adminPassword"],
                   },
               }])
               ```
        """
        pulumi.set(__self__, "url", url)
        if basic_auth is not None:
            pulumi.set(__self__, "basic_auth", basic_auth)

    @property
    @pulumi.getter
    def url(self) -> str:
        """
        URL for the Docker image
        """
        return pulumi.get(self, "url")

    @property
    @pulumi.getter(name="basicAuth")
    def basic_auth(self) -> Optional['outputs.InstancePoolPreloadedDockerImageBasicAuth']:
        """
        `basic_auth.username` and `basic_auth.password` for Docker repository. Docker registry credentials are encrypted when they are stored in Databricks internal storage and when they are passed to a registry upon fetching Docker images at cluster launch. However, other authenticated and authorized API users of this workspace can access the username and password.

        Example usage with azurerm_container_registry, that you can adapt to your specific use-case:

        ```python
        import pulumi
        import pulumi_databricks as databricks
        import pulumi_docker as docker

        this = docker.index.RegistryImage("this",
            build=[{}],
            name=f{this_azurerm_container_registry.login_server}/sample:latest)
        this_instance_pool = databricks.InstancePool("this", preloaded_docker_images=[{
            "url": this["name"],
            "basic_auth": {
                "username": this_azurerm_container_registry["adminUsername"],
                "password": this_azurerm_container_registry["adminPassword"],
            },
        }])
        ```
        """
        return pulumi.get(self, "basic_auth")


@pulumi.output_type
class InstancePoolPreloadedDockerImageBasicAuth(dict):
    def __init__(__self__, *,
                 password: str,
                 username: str):
        pulumi.set(__self__, "password", password)
        pulumi.set(__self__, "username", username)

    @property
    @pulumi.getter
    def password(self) -> str:
        return pulumi.get(self, "password")

    @property
    @pulumi.getter
    def username(self) -> str:
        return pulumi.get(self, "username")


@pulumi.output_type
class JobContinuous(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "pauseStatus":
            suggest = "pause_status"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in JobContinuous. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        JobContinuous.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        JobContinuous.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 pause_status: Optional[str] = None):
        """
        :param str pause_status: Indicate whether this continuous job is paused or not. Either `PAUSED` or `UNPAUSED`. When the `pause_status` field is omitted in the block, the server will default to using `UNPAUSED` as a value for `pause_status`.
        """
        if pause_status is not None:
            pulumi.set(__self__, "pause_status", pause_status)

    @property
    @pulumi.getter(name="pauseStatus")
    def pause_status(self) -> Optional[str]:
        """
        Indicate whether this continuous job is paused or not. Either `PAUSED` or `UNPAUSED`. When the `pause_status` field is omitted in the block, the server will default to using `UNPAUSED` as a value for `pause_status`.
        """
        return pulumi.get(self, "pause_status")


@pulumi.output_type
class JobDbtTask(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "profilesDirectory":
            suggest = "profiles_directory"
        elif key == "projectDirectory":
            suggest = "project_directory"
        elif key == "warehouseId":
            suggest = "warehouse_id"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in JobDbtTask. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        JobDbtTask.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        JobDbtTask.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 commands: Sequence[str],
                 catalog: Optional[str] = None,
                 profiles_directory: Optional[str] = None,
                 project_directory: Optional[str] = None,
                 schema: Optional[str] = None,
                 source: Optional[str] = None,
                 warehouse_id: Optional[str] = None):
        """
        :param Sequence[str] commands: (Array) Series of dbt commands to execute in sequence. Every command must start with "dbt".
        :param str catalog: The name of the catalog to use inside Unity Catalog.
        :param str profiles_directory: The relative path to the directory in the repository specified by `git_source` where dbt should look in for the `profiles.yml` file. If not specified, defaults to the repository's root directory. Equivalent to passing `--profile-dir` to a dbt command.
        :param str project_directory: The path where dbt should look for `dbt_project.yml`. Equivalent to passing `--project-dir` to the dbt CLI.
               * If `source` is `GIT`: Relative path to the directory in the repository specified in the `git_source` block. Defaults to the repository's root directory when not specified.
               * If `source` is `WORKSPACE`: Absolute path to the folder in the workspace.
        :param str schema: The name of the schema dbt should run in. Defaults to `default`.
        :param str source: The source of the project. Possible values are `WORKSPACE` and `GIT`.  Defaults to `GIT` if a `git_source` block is present in the job definition.
        :param str warehouse_id: The ID of the SQL warehouse that dbt should execute against.
               
               You also need to include a `git_source` block to configure the repository that contains the dbt project.
        """
        pulumi.set(__self__, "commands", commands)
        if catalog is not None:
            pulumi.set(__self__, "catalog", catalog)
        if profiles_directory is not None:
            pulumi.set(__self__, "profiles_directory", profiles_directory)
        if project_directory is not None:
            pulumi.set(__self__, "project_directory", project_directory)
        if schema is not None:
            pulumi.set(__self__, "schema", schema)
        if source is not None:
            pulumi.set(__self__, "source", source)
        if warehouse_id is not None:
            pulumi.set(__self__, "warehouse_id", warehouse_id)

    @property
    @pulumi.getter
    def commands(self) -> Sequence[str]:
        """
        (Array) Series of dbt commands to execute in sequence. Every command must start with "dbt".
        """
        return pulumi.get(self, "commands")

    @property
    @pulumi.getter
    def catalog(self) -> Optional[str]:
        """
        The name of the catalog to use inside Unity Catalog.
        """
        return pulumi.get(self, "catalog")

    @property
    @pulumi.getter(name="profilesDirectory")
    def profiles_directory(self) -> Optional[str]:
        """
        The relative path to the directory in the repository specified by `git_source` where dbt should look in for the `profiles.yml` file. If not specified, defaults to the repository's root directory. Equivalent to passing `--profile-dir` to a dbt command.
        """
        return pulumi.get(self, "profiles_directory")

    @property
    @pulumi.getter(name="projectDirectory")
    def project_directory(self) -> Optional[str]:
        """
        The path where dbt should look for `dbt_project.yml`. Equivalent to passing `--project-dir` to the dbt CLI.
        * If `source` is `GIT`: Relative path to the directory in the repository specified in the `git_source` block. Defaults to the repository's root directory when not specified.
        * If `source` is `WORKSPACE`: Absolute path to the folder in the workspace.
        """
        return pulumi.get(self, "project_directory")

    @property
    @pulumi.getter
    def schema(self) -> Optional[str]:
        """
        The name of the schema dbt should run in. Defaults to `default`.
        """
        return pulumi.get(self, "schema")

    @property
    @pulumi.getter
    def source(self) -> Optional[str]:
        """
        The source of the project. Possible values are `WORKSPACE` and `GIT`.  Defaults to `GIT` if a `git_source` block is present in the job definition.
        """
        return pulumi.get(self, "source")

    @property
    @pulumi.getter(name="warehouseId")
    def warehouse_id(self) -> Optional[str]:
        """
        The ID of the SQL warehouse that dbt should execute against.

        You also need to include a `git_source` block to configure the repository that contains the dbt project.
        """
        return pulumi.get(self, "warehouse_id")


@pulumi.output_type
class JobDeployment(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "metadataFilePath":
            suggest = "metadata_file_path"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in JobDeployment. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        JobDeployment.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        JobDeployment.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 kind: str,
                 metadata_file_path: Optional[str] = None):
        pulumi.set(__self__, "kind", kind)
        if metadata_file_path is not None:
            pulumi.set(__self__, "metadata_file_path", metadata_file_path)

    @property
    @pulumi.getter
    def kind(self) -> str:
        return pulumi.get(self, "kind")

    @property
    @pulumi.getter(name="metadataFilePath")
    def metadata_file_path(self) -> Optional[str]:
        return pulumi.get(self, "metadata_file_path")


@pulumi.output_type
class JobEmailNotifications(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "noAlertForSkippedRuns":
            suggest = "no_alert_for_skipped_runs"
        elif key == "onDurationWarningThresholdExceededs":
            suggest = "on_duration_warning_threshold_exceededs"
        elif key == "onFailures":
            suggest = "on_failures"
        elif key == "onStarts":
            suggest = "on_starts"
        elif key == "onStreamingBacklogExceededs":
            suggest = "on_streaming_backlog_exceededs"
        elif key == "onSuccesses":
            suggest = "on_successes"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in JobEmailNotifications. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        JobEmailNotifications.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        JobEmailNotifications.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 no_alert_for_skipped_runs: Optional[bool] = None,
                 on_duration_warning_threshold_exceededs: Optional[Sequence[str]] = None,
                 on_failures: Optional[Sequence[str]] = None,
                 on_starts: Optional[Sequence[str]] = None,
                 on_streaming_backlog_exceededs: Optional[Sequence[str]] = None,
                 on_successes: Optional[Sequence[str]] = None):
        """
        :param bool no_alert_for_skipped_runs: (Bool) don't send alert for skipped runs. (It's recommended to use the corresponding setting in the `notification_settings` configuration block).
        :param Sequence[str] on_duration_warning_threshold_exceededs: (List) list of emails to notify when the duration of a run exceeds the threshold specified by the `RUN_DURATION_SECONDS` metric in the `health` block.
               
               The following parameter is only available for the job level configuration.
        :param Sequence[str] on_failures: (List) list of emails to notify when the run fails.
        :param Sequence[str] on_starts: (List) list of emails to notify when the run starts.
        :param Sequence[str] on_successes: (List) list of emails to notify when the run completes successfully.
        """
        if no_alert_for_skipped_runs is not None:
            pulumi.set(__self__, "no_alert_for_skipped_runs", no_alert_for_skipped_runs)
        if on_duration_warning_threshold_exceededs is not None:
            pulumi.set(__self__, "on_duration_warning_threshold_exceededs", on_duration_warning_threshold_exceededs)
        if on_failures is not None:
            pulumi.set(__self__, "on_failures", on_failures)
        if on_starts is not None:
            pulumi.set(__self__, "on_starts", on_starts)
        if on_streaming_backlog_exceededs is not None:
            pulumi.set(__self__, "on_streaming_backlog_exceededs", on_streaming_backlog_exceededs)
        if on_successes is not None:
            pulumi.set(__self__, "on_successes", on_successes)

    @property
    @pulumi.getter(name="noAlertForSkippedRuns")
    def no_alert_for_skipped_runs(self) -> Optional[bool]:
        """
        (Bool) don't send alert for skipped runs. (It's recommended to use the corresponding setting in the `notification_settings` configuration block).
        """
        return pulumi.get(self, "no_alert_for_skipped_runs")

    @property
    @pulumi.getter(name="onDurationWarningThresholdExceededs")
    def on_duration_warning_threshold_exceededs(self) -> Optional[Sequence[str]]:
        """
        (List) list of emails to notify when the duration of a run exceeds the threshold specified by the `RUN_DURATION_SECONDS` metric in the `health` block.

        The following parameter is only available for the job level configuration.
        """
        return pulumi.get(self, "on_duration_warning_threshold_exceededs")

    @property
    @pulumi.getter(name="onFailures")
    def on_failures(self) -> Optional[Sequence[str]]:
        """
        (List) list of emails to notify when the run fails.
        """
        return pulumi.get(self, "on_failures")

    @property
    @pulumi.getter(name="onStarts")
    def on_starts(self) -> Optional[Sequence[str]]:
        """
        (List) list of emails to notify when the run starts.
        """
        return pulumi.get(self, "on_starts")

    @property
    @pulumi.getter(name="onStreamingBacklogExceededs")
    def on_streaming_backlog_exceededs(self) -> Optional[Sequence[str]]:
        return pulumi.get(self, "on_streaming_backlog_exceededs")

    @property
    @pulumi.getter(name="onSuccesses")
    def on_successes(self) -> Optional[Sequence[str]]:
        """
        (List) list of emails to notify when the run completes successfully.
        """
        return pulumi.get(self, "on_successes")


@pulumi.output_type
class JobEnvironment(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "environmentKey":
            suggest = "environment_key"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in JobEnvironment. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        JobEnvironment.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        JobEnvironment.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 environment_key: str,
                 spec: Optional['outputs.JobEnvironmentSpec'] = None):
        """
        :param str environment_key: an unique identifier of the Environment.  It will be referenced from `environment_key` attribute of corresponding task.
        :param 'JobEnvironmentSpecArgs' spec: block describing the Environment. Consists of following attributes:
        """
        pulumi.set(__self__, "environment_key", environment_key)
        if spec is not None:
            pulumi.set(__self__, "spec", spec)

    @property
    @pulumi.getter(name="environmentKey")
    def environment_key(self) -> str:
        """
        an unique identifier of the Environment.  It will be referenced from `environment_key` attribute of corresponding task.
        """
        return pulumi.get(self, "environment_key")

    @property
    @pulumi.getter
    def spec(self) -> Optional['outputs.JobEnvironmentSpec']:
        """
        block describing the Environment. Consists of following attributes:
        """
        return pulumi.get(self, "spec")


@pulumi.output_type
class JobEnvironmentSpec(dict):
    def __init__(__self__, *,
                 client: str,
                 dependencies: Optional[Sequence[str]] = None):
        """
        :param str client: client version used by the environment.
        :param Sequence[str] dependencies: List of pip dependencies, as supported by the version of pip in this environment. Each dependency is a pip requirement file line.  See [API docs](https://docs.databricks.com/api/workspace/jobs/create#environments-spec-dependencies) for more information.
        """
        pulumi.set(__self__, "client", client)
        if dependencies is not None:
            pulumi.set(__self__, "dependencies", dependencies)

    @property
    @pulumi.getter
    def client(self) -> str:
        """
        client version used by the environment.
        """
        return pulumi.get(self, "client")

    @property
    @pulumi.getter
    def dependencies(self) -> Optional[Sequence[str]]:
        """
        List of pip dependencies, as supported by the version of pip in this environment. Each dependency is a pip requirement file line.  See [API docs](https://docs.databricks.com/api/workspace/jobs/create#environments-spec-dependencies) for more information.
        """
        return pulumi.get(self, "dependencies")


@pulumi.output_type
class JobGitSource(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "gitSnapshot":
            suggest = "git_snapshot"
        elif key == "jobSource":
            suggest = "job_source"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in JobGitSource. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        JobGitSource.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        JobGitSource.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 url: str,
                 branch: Optional[str] = None,
                 commit: Optional[str] = None,
                 git_snapshot: Optional['outputs.JobGitSourceGitSnapshot'] = None,
                 job_source: Optional['outputs.JobGitSourceJobSource'] = None,
                 provider: Optional[str] = None,
                 tag: Optional[str] = None):
        """
        :param str url: URL of the Git repository to use.
        :param str branch: name of the Git branch to use. Conflicts with `tag` and `commit`.
        :param str commit: hash of Git commit to use. Conflicts with `branch` and `tag`.
        :param str provider: case insensitive name of the Git provider.  Following values are supported right now (could be a subject for change, consult [Repos API documentation](https://docs.databricks.com/dev-tools/api/latest/repos.html)): `gitHub`, `gitHubEnterprise`, `bitbucketCloud`, `bitbucketServer`, `azureDevOpsServices`, `gitLab`, `gitLabEnterpriseEdition`.
        :param str tag: name of the Git branch to use. Conflicts with `branch` and `commit`.
        """
        pulumi.set(__self__, "url", url)
        if branch is not None:
            pulumi.set(__self__, "branch", branch)
        if commit is not None:
            pulumi.set(__self__, "commit", commit)
        if git_snapshot is not None:
            pulumi.set(__self__, "git_snapshot", git_snapshot)
        if job_source is not None:
            pulumi.set(__self__, "job_source", job_source)
        if provider is not None:
            pulumi.set(__self__, "provider", provider)
        if tag is not None:
            pulumi.set(__self__, "tag", tag)

    @property
    @pulumi.getter
    def url(self) -> str:
        """
        URL of the Git repository to use.
        """
        return pulumi.get(self, "url")

    @property
    @pulumi.getter
    def branch(self) -> Optional[str]:
        """
        name of the Git branch to use. Conflicts with `tag` and `commit`.
        """
        return pulumi.get(self, "branch")

    @property
    @pulumi.getter
    def commit(self) -> Optional[str]:
        """
        hash of Git commit to use. Conflicts with `branch` and `tag`.
        """
        return pulumi.get(self, "commit")

    @property
    @pulumi.getter(name="gitSnapshot")
    def git_snapshot(self) -> Optional['outputs.JobGitSourceGitSnapshot']:
        return pulumi.get(self, "git_snapshot")

    @property
    @pulumi.getter(name="jobSource")
    def job_source(self) -> Optional['outputs.JobGitSourceJobSource']:
        return pulumi.get(self, "job_source")

    @property
    @pulumi.getter
    def provider(self) -> Optional[str]:
        """
        case insensitive name of the Git provider.  Following values are supported right now (could be a subject for change, consult [Repos API documentation](https://docs.databricks.com/dev-tools/api/latest/repos.html)): `gitHub`, `gitHubEnterprise`, `bitbucketCloud`, `bitbucketServer`, `azureDevOpsServices`, `gitLab`, `gitLabEnterpriseEdition`.
        """
        return pulumi.get(self, "provider")

    @property
    @pulumi.getter
    def tag(self) -> Optional[str]:
        """
        name of the Git branch to use. Conflicts with `branch` and `commit`.
        """
        return pulumi.get(self, "tag")


@pulumi.output_type
class JobGitSourceGitSnapshot(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "usedCommit":
            suggest = "used_commit"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in JobGitSourceGitSnapshot. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        JobGitSourceGitSnapshot.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        JobGitSourceGitSnapshot.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 used_commit: Optional[str] = None):
        if used_commit is not None:
            pulumi.set(__self__, "used_commit", used_commit)

    @property
    @pulumi.getter(name="usedCommit")
    def used_commit(self) -> Optional[str]:
        return pulumi.get(self, "used_commit")


@pulumi.output_type
class JobGitSourceJobSource(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "importFromGitBranch":
            suggest = "import_from_git_branch"
        elif key == "jobConfigPath":
            suggest = "job_config_path"
        elif key == "dirtyState":
            suggest = "dirty_state"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in JobGitSourceJobSource. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        JobGitSourceJobSource.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        JobGitSourceJobSource.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 import_from_git_branch: str,
                 job_config_path: str,
                 dirty_state: Optional[str] = None):
        pulumi.set(__self__, "import_from_git_branch", import_from_git_branch)
        pulumi.set(__self__, "job_config_path", job_config_path)
        if dirty_state is not None:
            pulumi.set(__self__, "dirty_state", dirty_state)

    @property
    @pulumi.getter(name="importFromGitBranch")
    def import_from_git_branch(self) -> str:
        return pulumi.get(self, "import_from_git_branch")

    @property
    @pulumi.getter(name="jobConfigPath")
    def job_config_path(self) -> str:
        return pulumi.get(self, "job_config_path")

    @property
    @pulumi.getter(name="dirtyState")
    def dirty_state(self) -> Optional[str]:
        return pulumi.get(self, "dirty_state")


@pulumi.output_type
class JobHealth(dict):
    def __init__(__self__, *,
                 rules: Sequence['outputs.JobHealthRule']):
        """
        :param Sequence['JobHealthRuleArgs'] rules: list of rules that are represented as objects with the following attributes:
        """
        pulumi.set(__self__, "rules", rules)

    @property
    @pulumi.getter
    def rules(self) -> Sequence['outputs.JobHealthRule']:
        """
        list of rules that are represented as objects with the following attributes:
        """
        return pulumi.get(self, "rules")


@pulumi.output_type
class JobHealthRule(dict):
    def __init__(__self__, *,
                 metric: str,
                 op: str,
                 value: int):
        """
        :param str metric: string specifying the metric to check.  The only supported metric is `RUN_DURATION_SECONDS` (check [Jobs REST API documentation](https://docs.databricks.com/api/workspace/jobs/create) for the latest information).
        :param str op: string specifying the operation used to evaluate the given metric. The only supported operation is `GREATER_THAN`.
        :param int value: integer value used to compare to the given metric.
        """
        pulumi.set(__self__, "metric", metric)
        pulumi.set(__self__, "op", op)
        pulumi.set(__self__, "value", value)

    @property
    @pulumi.getter
    def metric(self) -> str:
        """
        string specifying the metric to check.  The only supported metric is `RUN_DURATION_SECONDS` (check [Jobs REST API documentation](https://docs.databricks.com/api/workspace/jobs/create) for the latest information).
        """
        return pulumi.get(self, "metric")

    @property
    @pulumi.getter
    def op(self) -> str:
        """
        string specifying the operation used to evaluate the given metric. The only supported operation is `GREATER_THAN`.
        """
        return pulumi.get(self, "op")

    @property
    @pulumi.getter
    def value(self) -> int:
        """
        integer value used to compare to the given metric.
        """
        return pulumi.get(self, "value")


@pulumi.output_type
class JobJobCluster(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "jobClusterKey":
            suggest = "job_cluster_key"
        elif key == "newCluster":
            suggest = "new_cluster"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in JobJobCluster. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        JobJobCluster.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        JobJobCluster.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 job_cluster_key: str,
                 new_cluster: 'outputs.JobJobClusterNewCluster'):
        """
        :param str job_cluster_key: Identifier that can be referenced in `task` block, so that cluster is shared between tasks
        :param 'JobJobClusterNewClusterArgs' new_cluster: Block with almost the same set of parameters as for Cluster resource, except following (check the [REST API documentation for full list of supported parameters](https://docs.databricks.com/api/workspace/jobs/create#job_clusters-new_cluster)):
        """
        pulumi.set(__self__, "job_cluster_key", job_cluster_key)
        pulumi.set(__self__, "new_cluster", new_cluster)

    @property
    @pulumi.getter(name="jobClusterKey")
    def job_cluster_key(self) -> str:
        """
        Identifier that can be referenced in `task` block, so that cluster is shared between tasks
        """
        return pulumi.get(self, "job_cluster_key")

    @property
    @pulumi.getter(name="newCluster")
    def new_cluster(self) -> 'outputs.JobJobClusterNewCluster':
        """
        Block with almost the same set of parameters as for Cluster resource, except following (check the [REST API documentation for full list of supported parameters](https://docs.databricks.com/api/workspace/jobs/create#job_clusters-new_cluster)):
        """
        return pulumi.get(self, "new_cluster")


@pulumi.output_type
class JobJobClusterNewCluster(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "sparkVersion":
            suggest = "spark_version"
        elif key == "applyPolicyDefaultValues":
            suggest = "apply_policy_default_values"
        elif key == "awsAttributes":
            suggest = "aws_attributes"
        elif key == "azureAttributes":
            suggest = "azure_attributes"
        elif key == "clusterId":
            suggest = "cluster_id"
        elif key == "clusterLogConf":
            suggest = "cluster_log_conf"
        elif key == "clusterMountInfos":
            suggest = "cluster_mount_infos"
        elif key == "clusterName":
            suggest = "cluster_name"
        elif key == "customTags":
            suggest = "custom_tags"
        elif key == "dataSecurityMode":
            suggest = "data_security_mode"
        elif key == "dockerImage":
            suggest = "docker_image"
        elif key == "driverInstancePoolId":
            suggest = "driver_instance_pool_id"
        elif key == "driverNodeTypeId":
            suggest = "driver_node_type_id"
        elif key == "enableElasticDisk":
            suggest = "enable_elastic_disk"
        elif key == "enableLocalDiskEncryption":
            suggest = "enable_local_disk_encryption"
        elif key == "gcpAttributes":
            suggest = "gcp_attributes"
        elif key == "idempotencyToken":
            suggest = "idempotency_token"
        elif key == "initScripts":
            suggest = "init_scripts"
        elif key == "instancePoolId":
            suggest = "instance_pool_id"
        elif key == "nodeTypeId":
            suggest = "node_type_id"
        elif key == "numWorkers":
            suggest = "num_workers"
        elif key == "policyId":
            suggest = "policy_id"
        elif key == "runtimeEngine":
            suggest = "runtime_engine"
        elif key == "singleUserName":
            suggest = "single_user_name"
        elif key == "sparkConf":
            suggest = "spark_conf"
        elif key == "sparkEnvVars":
            suggest = "spark_env_vars"
        elif key == "sshPublicKeys":
            suggest = "ssh_public_keys"
        elif key == "workloadType":
            suggest = "workload_type"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in JobJobClusterNewCluster. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        JobJobClusterNewCluster.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        JobJobClusterNewCluster.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 spark_version: str,
                 apply_policy_default_values: Optional[bool] = None,
                 autoscale: Optional['outputs.JobJobClusterNewClusterAutoscale'] = None,
                 aws_attributes: Optional['outputs.JobJobClusterNewClusterAwsAttributes'] = None,
                 azure_attributes: Optional['outputs.JobJobClusterNewClusterAzureAttributes'] = None,
                 cluster_id: Optional[str] = None,
                 cluster_log_conf: Optional['outputs.JobJobClusterNewClusterClusterLogConf'] = None,
                 cluster_mount_infos: Optional[Sequence['outputs.JobJobClusterNewClusterClusterMountInfo']] = None,
                 cluster_name: Optional[str] = None,
                 custom_tags: Optional[Mapping[str, str]] = None,
                 data_security_mode: Optional[str] = None,
                 docker_image: Optional['outputs.JobJobClusterNewClusterDockerImage'] = None,
                 driver_instance_pool_id: Optional[str] = None,
                 driver_node_type_id: Optional[str] = None,
                 enable_elastic_disk: Optional[bool] = None,
                 enable_local_disk_encryption: Optional[bool] = None,
                 gcp_attributes: Optional['outputs.JobJobClusterNewClusterGcpAttributes'] = None,
                 idempotency_token: Optional[str] = None,
                 init_scripts: Optional[Sequence['outputs.JobJobClusterNewClusterInitScript']] = None,
                 instance_pool_id: Optional[str] = None,
                 libraries: Optional[Sequence['outputs.JobJobClusterNewClusterLibrary']] = None,
                 node_type_id: Optional[str] = None,
                 num_workers: Optional[int] = None,
                 policy_id: Optional[str] = None,
                 runtime_engine: Optional[str] = None,
                 single_user_name: Optional[str] = None,
                 spark_conf: Optional[Mapping[str, str]] = None,
                 spark_env_vars: Optional[Mapping[str, str]] = None,
                 ssh_public_keys: Optional[Sequence[str]] = None,
                 workload_type: Optional['outputs.JobJobClusterNewClusterWorkloadType'] = None):
        """
        :param Sequence['JobJobClusterNewClusterLibraryArgs'] libraries: (List) An optional list of libraries to be installed on the cluster that will execute the job. See library Configuration Block below.
        :param 'JobJobClusterNewClusterWorkloadTypeArgs' workload_type: isn't supported
        """
        pulumi.set(__self__, "spark_version", spark_version)
        if apply_policy_default_values is not None:
            pulumi.set(__self__, "apply_policy_default_values", apply_policy_default_values)
        if autoscale is not None:
            pulumi.set(__self__, "autoscale", autoscale)
        if aws_attributes is not None:
            pulumi.set(__self__, "aws_attributes", aws_attributes)
        if azure_attributes is not None:
            pulumi.set(__self__, "azure_attributes", azure_attributes)
        if cluster_id is not None:
            pulumi.set(__self__, "cluster_id", cluster_id)
        if cluster_log_conf is not None:
            pulumi.set(__self__, "cluster_log_conf", cluster_log_conf)
        if cluster_mount_infos is not None:
            pulumi.set(__self__, "cluster_mount_infos", cluster_mount_infos)
        if cluster_name is not None:
            pulumi.set(__self__, "cluster_name", cluster_name)
        if custom_tags is not None:
            pulumi.set(__self__, "custom_tags", custom_tags)
        if data_security_mode is not None:
            pulumi.set(__self__, "data_security_mode", data_security_mode)
        if docker_image is not None:
            pulumi.set(__self__, "docker_image", docker_image)
        if driver_instance_pool_id is not None:
            pulumi.set(__self__, "driver_instance_pool_id", driver_instance_pool_id)
        if driver_node_type_id is not None:
            pulumi.set(__self__, "driver_node_type_id", driver_node_type_id)
        if enable_elastic_disk is not None:
            pulumi.set(__self__, "enable_elastic_disk", enable_elastic_disk)
        if enable_local_disk_encryption is not None:
            pulumi.set(__self__, "enable_local_disk_encryption", enable_local_disk_encryption)
        if gcp_attributes is not None:
            pulumi.set(__self__, "gcp_attributes", gcp_attributes)
        if idempotency_token is not None:
            pulumi.set(__self__, "idempotency_token", idempotency_token)
        if init_scripts is not None:
            pulumi.set(__self__, "init_scripts", init_scripts)
        if instance_pool_id is not None:
            pulumi.set(__self__, "instance_pool_id", instance_pool_id)
        if libraries is not None:
            pulumi.set(__self__, "libraries", libraries)
        if node_type_id is not None:
            pulumi.set(__self__, "node_type_id", node_type_id)
        if num_workers is not None:
            pulumi.set(__self__, "num_workers", num_workers)
        if policy_id is not None:
            pulumi.set(__self__, "policy_id", policy_id)
        if runtime_engine is not None:
            pulumi.set(__self__, "runtime_engine", runtime_engine)
        if single_user_name is not None:
            pulumi.set(__self__, "single_user_name", single_user_name)
        if spark_conf is not None:
            pulumi.set(__self__, "spark_conf", spark_conf)
        if spark_env_vars is not None:
            pulumi.set(__self__, "spark_env_vars", spark_env_vars)
        if ssh_public_keys is not None:
            pulumi.set(__self__, "ssh_public_keys", ssh_public_keys)
        if workload_type is not None:
            pulumi.set(__self__, "workload_type", workload_type)

    @property
    @pulumi.getter(name="sparkVersion")
    def spark_version(self) -> str:
        return pulumi.get(self, "spark_version")

    @property
    @pulumi.getter(name="applyPolicyDefaultValues")
    def apply_policy_default_values(self) -> Optional[bool]:
        return pulumi.get(self, "apply_policy_default_values")

    @property
    @pulumi.getter
    def autoscale(self) -> Optional['outputs.JobJobClusterNewClusterAutoscale']:
        return pulumi.get(self, "autoscale")

    @property
    @pulumi.getter(name="awsAttributes")
    def aws_attributes(self) -> Optional['outputs.JobJobClusterNewClusterAwsAttributes']:
        return pulumi.get(self, "aws_attributes")

    @property
    @pulumi.getter(name="azureAttributes")
    def azure_attributes(self) -> Optional['outputs.JobJobClusterNewClusterAzureAttributes']:
        return pulumi.get(self, "azure_attributes")

    @property
    @pulumi.getter(name="clusterId")
    def cluster_id(self) -> Optional[str]:
        return pulumi.get(self, "cluster_id")

    @property
    @pulumi.getter(name="clusterLogConf")
    def cluster_log_conf(self) -> Optional['outputs.JobJobClusterNewClusterClusterLogConf']:
        return pulumi.get(self, "cluster_log_conf")

    @property
    @pulumi.getter(name="clusterMountInfos")
    def cluster_mount_infos(self) -> Optional[Sequence['outputs.JobJobClusterNewClusterClusterMountInfo']]:
        return pulumi.get(self, "cluster_mount_infos")

    @property
    @pulumi.getter(name="clusterName")
    def cluster_name(self) -> Optional[str]:
        return pulumi.get(self, "cluster_name")

    @property
    @pulumi.getter(name="customTags")
    def custom_tags(self) -> Optional[Mapping[str, str]]:
        return pulumi.get(self, "custom_tags")

    @property
    @pulumi.getter(name="dataSecurityMode")
    def data_security_mode(self) -> Optional[str]:
        return pulumi.get(self, "data_security_mode")

    @property
    @pulumi.getter(name="dockerImage")
    def docker_image(self) -> Optional['outputs.JobJobClusterNewClusterDockerImage']:
        return pulumi.get(self, "docker_image")

    @property
    @pulumi.getter(name="driverInstancePoolId")
    def driver_instance_pool_id(self) -> Optional[str]:
        return pulumi.get(self, "driver_instance_pool_id")

    @property
    @pulumi.getter(name="driverNodeTypeId")
    def driver_node_type_id(self) -> Optional[str]:
        return pulumi.get(self, "driver_node_type_id")

    @property
    @pulumi.getter(name="enableElasticDisk")
    def enable_elastic_disk(self) -> Optional[bool]:
        return pulumi.get(self, "enable_elastic_disk")

    @property
    @pulumi.getter(name="enableLocalDiskEncryption")
    def enable_local_disk_encryption(self) -> Optional[bool]:
        return pulumi.get(self, "enable_local_disk_encryption")

    @property
    @pulumi.getter(name="gcpAttributes")
    def gcp_attributes(self) -> Optional['outputs.JobJobClusterNewClusterGcpAttributes']:
        return pulumi.get(self, "gcp_attributes")

    @property
    @pulumi.getter(name="idempotencyToken")
    def idempotency_token(self) -> Optional[str]:
        return pulumi.get(self, "idempotency_token")

    @property
    @pulumi.getter(name="initScripts")
    def init_scripts(self) -> Optional[Sequence['outputs.JobJobClusterNewClusterInitScript']]:
        return pulumi.get(self, "init_scripts")

    @property
    @pulumi.getter(name="instancePoolId")
    def instance_pool_id(self) -> Optional[str]:
        return pulumi.get(self, "instance_pool_id")

    @property
    @pulumi.getter
    def libraries(self) -> Optional[Sequence['outputs.JobJobClusterNewClusterLibrary']]:
        """
        (List) An optional list of libraries to be installed on the cluster that will execute the job. See library Configuration Block below.
        """
        return pulumi.get(self, "libraries")

    @property
    @pulumi.getter(name="nodeTypeId")
    def node_type_id(self) -> Optional[str]:
        return pulumi.get(self, "node_type_id")

    @property
    @pulumi.getter(name="numWorkers")
    def num_workers(self) -> Optional[int]:
        return pulumi.get(self, "num_workers")

    @property
    @pulumi.getter(name="policyId")
    def policy_id(self) -> Optional[str]:
        return pulumi.get(self, "policy_id")

    @property
    @pulumi.getter(name="runtimeEngine")
    def runtime_engine(self) -> Optional[str]:
        return pulumi.get(self, "runtime_engine")

    @property
    @pulumi.getter(name="singleUserName")
    def single_user_name(self) -> Optional[str]:
        return pulumi.get(self, "single_user_name")

    @property
    @pulumi.getter(name="sparkConf")
    def spark_conf(self) -> Optional[Mapping[str, str]]:
        return pulumi.get(self, "spark_conf")

    @property
    @pulumi.getter(name="sparkEnvVars")
    def spark_env_vars(self) -> Optional[Mapping[str, str]]:
        return pulumi.get(self, "spark_env_vars")

    @property
    @pulumi.getter(name="sshPublicKeys")
    def ssh_public_keys(self) -> Optional[Sequence[str]]:
        return pulumi.get(self, "ssh_public_keys")

    @property
    @pulumi.getter(name="workloadType")
    def workload_type(self) -> Optional['outputs.JobJobClusterNewClusterWorkloadType']:
        """
        isn't supported
        """
        return pulumi.get(self, "workload_type")


@pulumi.output_type
class JobJobClusterNewClusterAutoscale(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "maxWorkers":
            suggest = "max_workers"
        elif key == "minWorkers":
            suggest = "min_workers"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in JobJobClusterNewClusterAutoscale. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        JobJobClusterNewClusterAutoscale.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        JobJobClusterNewClusterAutoscale.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 max_workers: Optional[int] = None,
                 min_workers: Optional[int] = None):
        if max_workers is not None:
            pulumi.set(__self__, "max_workers", max_workers)
        if min_workers is not None:
            pulumi.set(__self__, "min_workers", min_workers)

    @property
    @pulumi.getter(name="maxWorkers")
    def max_workers(self) -> Optional[int]:
        return pulumi.get(self, "max_workers")

    @property
    @pulumi.getter(name="minWorkers")
    def min_workers(self) -> Optional[int]:
        return pulumi.get(self, "min_workers")


@pulumi.output_type
class JobJobClusterNewClusterAwsAttributes(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "ebsVolumeCount":
            suggest = "ebs_volume_count"
        elif key == "ebsVolumeIops":
            suggest = "ebs_volume_iops"
        elif key == "ebsVolumeSize":
            suggest = "ebs_volume_size"
        elif key == "ebsVolumeThroughput":
            suggest = "ebs_volume_throughput"
        elif key == "ebsVolumeType":
            suggest = "ebs_volume_type"
        elif key == "firstOnDemand":
            suggest = "first_on_demand"
        elif key == "instanceProfileArn":
            suggest = "instance_profile_arn"
        elif key == "spotBidPricePercent":
            suggest = "spot_bid_price_percent"
        elif key == "zoneId":
            suggest = "zone_id"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in JobJobClusterNewClusterAwsAttributes. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        JobJobClusterNewClusterAwsAttributes.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        JobJobClusterNewClusterAwsAttributes.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 availability: Optional[str] = None,
                 ebs_volume_count: Optional[int] = None,
                 ebs_volume_iops: Optional[int] = None,
                 ebs_volume_size: Optional[int] = None,
                 ebs_volume_throughput: Optional[int] = None,
                 ebs_volume_type: Optional[str] = None,
                 first_on_demand: Optional[int] = None,
                 instance_profile_arn: Optional[str] = None,
                 spot_bid_price_percent: Optional[int] = None,
                 zone_id: Optional[str] = None):
        if availability is not None:
            pulumi.set(__self__, "availability", availability)
        if ebs_volume_count is not None:
            pulumi.set(__self__, "ebs_volume_count", ebs_volume_count)
        if ebs_volume_iops is not None:
            pulumi.set(__self__, "ebs_volume_iops", ebs_volume_iops)
        if ebs_volume_size is not None:
            pulumi.set(__self__, "ebs_volume_size", ebs_volume_size)
        if ebs_volume_throughput is not None:
            pulumi.set(__self__, "ebs_volume_throughput", ebs_volume_throughput)
        if ebs_volume_type is not None:
            pulumi.set(__self__, "ebs_volume_type", ebs_volume_type)
        if first_on_demand is not None:
            pulumi.set(__self__, "first_on_demand", first_on_demand)
        if instance_profile_arn is not None:
            pulumi.set(__self__, "instance_profile_arn", instance_profile_arn)
        if spot_bid_price_percent is not None:
            pulumi.set(__self__, "spot_bid_price_percent", spot_bid_price_percent)
        if zone_id is not None:
            pulumi.set(__self__, "zone_id", zone_id)

    @property
    @pulumi.getter
    def availability(self) -> Optional[str]:
        return pulumi.get(self, "availability")

    @property
    @pulumi.getter(name="ebsVolumeCount")
    def ebs_volume_count(self) -> Optional[int]:
        return pulumi.get(self, "ebs_volume_count")

    @property
    @pulumi.getter(name="ebsVolumeIops")
    def ebs_volume_iops(self) -> Optional[int]:
        return pulumi.get(self, "ebs_volume_iops")

    @property
    @pulumi.getter(name="ebsVolumeSize")
    def ebs_volume_size(self) -> Optional[int]:
        return pulumi.get(self, "ebs_volume_size")

    @property
    @pulumi.getter(name="ebsVolumeThroughput")
    def ebs_volume_throughput(self) -> Optional[int]:
        return pulumi.get(self, "ebs_volume_throughput")

    @property
    @pulumi.getter(name="ebsVolumeType")
    def ebs_volume_type(self) -> Optional[str]:
        return pulumi.get(self, "ebs_volume_type")

    @property
    @pulumi.getter(name="firstOnDemand")
    def first_on_demand(self) -> Optional[int]:
        return pulumi.get(self, "first_on_demand")

    @property
    @pulumi.getter(name="instanceProfileArn")
    def instance_profile_arn(self) -> Optional[str]:
        return pulumi.get(self, "instance_profile_arn")

    @property
    @pulumi.getter(name="spotBidPricePercent")
    def spot_bid_price_percent(self) -> Optional[int]:
        return pulumi.get(self, "spot_bid_price_percent")

    @property
    @pulumi.getter(name="zoneId")
    def zone_id(self) -> Optional[str]:
        return pulumi.get(self, "zone_id")


@pulumi.output_type
class JobJobClusterNewClusterAzureAttributes(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "firstOnDemand":
            suggest = "first_on_demand"
        elif key == "logAnalyticsInfo":
            suggest = "log_analytics_info"
        elif key == "spotBidMaxPrice":
            suggest = "spot_bid_max_price"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in JobJobClusterNewClusterAzureAttributes. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        JobJobClusterNewClusterAzureAttributes.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        JobJobClusterNewClusterAzureAttributes.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 availability: Optional[str] = None,
                 first_on_demand: Optional[int] = None,
                 log_analytics_info: Optional['outputs.JobJobClusterNewClusterAzureAttributesLogAnalyticsInfo'] = None,
                 spot_bid_max_price: Optional[float] = None):
        if availability is not None:
            pulumi.set(__self__, "availability", availability)
        if first_on_demand is not None:
            pulumi.set(__self__, "first_on_demand", first_on_demand)
        if log_analytics_info is not None:
            pulumi.set(__self__, "log_analytics_info", log_analytics_info)
        if spot_bid_max_price is not None:
            pulumi.set(__self__, "spot_bid_max_price", spot_bid_max_price)

    @property
    @pulumi.getter
    def availability(self) -> Optional[str]:
        return pulumi.get(self, "availability")

    @property
    @pulumi.getter(name="firstOnDemand")
    def first_on_demand(self) -> Optional[int]:
        return pulumi.get(self, "first_on_demand")

    @property
    @pulumi.getter(name="logAnalyticsInfo")
    def log_analytics_info(self) -> Optional['outputs.JobJobClusterNewClusterAzureAttributesLogAnalyticsInfo']:
        return pulumi.get(self, "log_analytics_info")

    @property
    @pulumi.getter(name="spotBidMaxPrice")
    def spot_bid_max_price(self) -> Optional[float]:
        return pulumi.get(self, "spot_bid_max_price")


@pulumi.output_type
class JobJobClusterNewClusterAzureAttributesLogAnalyticsInfo(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "logAnalyticsPrimaryKey":
            suggest = "log_analytics_primary_key"
        elif key == "logAnalyticsWorkspaceId":
            suggest = "log_analytics_workspace_id"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in JobJobClusterNewClusterAzureAttributesLogAnalyticsInfo. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        JobJobClusterNewClusterAzureAttributesLogAnalyticsInfo.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        JobJobClusterNewClusterAzureAttributesLogAnalyticsInfo.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 log_analytics_primary_key: Optional[str] = None,
                 log_analytics_workspace_id: Optional[str] = None):
        if log_analytics_primary_key is not None:
            pulumi.set(__self__, "log_analytics_primary_key", log_analytics_primary_key)
        if log_analytics_workspace_id is not None:
            pulumi.set(__self__, "log_analytics_workspace_id", log_analytics_workspace_id)

    @property
    @pulumi.getter(name="logAnalyticsPrimaryKey")
    def log_analytics_primary_key(self) -> Optional[str]:
        return pulumi.get(self, "log_analytics_primary_key")

    @property
    @pulumi.getter(name="logAnalyticsWorkspaceId")
    def log_analytics_workspace_id(self) -> Optional[str]:
        return pulumi.get(self, "log_analytics_workspace_id")


@pulumi.output_type
class JobJobClusterNewClusterClusterLogConf(dict):
    def __init__(__self__, *,
                 dbfs: Optional['outputs.JobJobClusterNewClusterClusterLogConfDbfs'] = None,
                 s3: Optional['outputs.JobJobClusterNewClusterClusterLogConfS3'] = None):
        if dbfs is not None:
            pulumi.set(__self__, "dbfs", dbfs)
        if s3 is not None:
            pulumi.set(__self__, "s3", s3)

    @property
    @pulumi.getter
    def dbfs(self) -> Optional['outputs.JobJobClusterNewClusterClusterLogConfDbfs']:
        return pulumi.get(self, "dbfs")

    @property
    @pulumi.getter
    def s3(self) -> Optional['outputs.JobJobClusterNewClusterClusterLogConfS3']:
        return pulumi.get(self, "s3")


@pulumi.output_type
class JobJobClusterNewClusterClusterLogConfDbfs(dict):
    def __init__(__self__, *,
                 destination: str):
        pulumi.set(__self__, "destination", destination)

    @property
    @pulumi.getter
    def destination(self) -> str:
        return pulumi.get(self, "destination")


@pulumi.output_type
class JobJobClusterNewClusterClusterLogConfS3(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "cannedAcl":
            suggest = "canned_acl"
        elif key == "enableEncryption":
            suggest = "enable_encryption"
        elif key == "encryptionType":
            suggest = "encryption_type"
        elif key == "kmsKey":
            suggest = "kms_key"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in JobJobClusterNewClusterClusterLogConfS3. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        JobJobClusterNewClusterClusterLogConfS3.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        JobJobClusterNewClusterClusterLogConfS3.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 destination: str,
                 canned_acl: Optional[str] = None,
                 enable_encryption: Optional[bool] = None,
                 encryption_type: Optional[str] = None,
                 endpoint: Optional[str] = None,
                 kms_key: Optional[str] = None,
                 region: Optional[str] = None):
        pulumi.set(__self__, "destination", destination)
        if canned_acl is not None:
            pulumi.set(__self__, "canned_acl", canned_acl)
        if enable_encryption is not None:
            pulumi.set(__self__, "enable_encryption", enable_encryption)
        if encryption_type is not None:
            pulumi.set(__self__, "encryption_type", encryption_type)
        if endpoint is not None:
            pulumi.set(__self__, "endpoint", endpoint)
        if kms_key is not None:
            pulumi.set(__self__, "kms_key", kms_key)
        if region is not None:
            pulumi.set(__self__, "region", region)

    @property
    @pulumi.getter
    def destination(self) -> str:
        return pulumi.get(self, "destination")

    @property
    @pulumi.getter(name="cannedAcl")
    def canned_acl(self) -> Optional[str]:
        return pulumi.get(self, "canned_acl")

    @property
    @pulumi.getter(name="enableEncryption")
    def enable_encryption(self) -> Optional[bool]:
        return pulumi.get(self, "enable_encryption")

    @property
    @pulumi.getter(name="encryptionType")
    def encryption_type(self) -> Optional[str]:
        return pulumi.get(self, "encryption_type")

    @property
    @pulumi.getter
    def endpoint(self) -> Optional[str]:
        return pulumi.get(self, "endpoint")

    @property
    @pulumi.getter(name="kmsKey")
    def kms_key(self) -> Optional[str]:
        return pulumi.get(self, "kms_key")

    @property
    @pulumi.getter
    def region(self) -> Optional[str]:
        return pulumi.get(self, "region")


@pulumi.output_type
class JobJobClusterNewClusterClusterMountInfo(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "localMountDirPath":
            suggest = "local_mount_dir_path"
        elif key == "networkFilesystemInfo":
            suggest = "network_filesystem_info"
        elif key == "remoteMountDirPath":
            suggest = "remote_mount_dir_path"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in JobJobClusterNewClusterClusterMountInfo. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        JobJobClusterNewClusterClusterMountInfo.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        JobJobClusterNewClusterClusterMountInfo.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 local_mount_dir_path: str,
                 network_filesystem_info: 'outputs.JobJobClusterNewClusterClusterMountInfoNetworkFilesystemInfo',
                 remote_mount_dir_path: Optional[str] = None):
        pulumi.set(__self__, "local_mount_dir_path", local_mount_dir_path)
        pulumi.set(__self__, "network_filesystem_info", network_filesystem_info)
        if remote_mount_dir_path is not None:
            pulumi.set(__self__, "remote_mount_dir_path", remote_mount_dir_path)

    @property
    @pulumi.getter(name="localMountDirPath")
    def local_mount_dir_path(self) -> str:
        return pulumi.get(self, "local_mount_dir_path")

    @property
    @pulumi.getter(name="networkFilesystemInfo")
    def network_filesystem_info(self) -> 'outputs.JobJobClusterNewClusterClusterMountInfoNetworkFilesystemInfo':
        return pulumi.get(self, "network_filesystem_info")

    @property
    @pulumi.getter(name="remoteMountDirPath")
    def remote_mount_dir_path(self) -> Optional[str]:
        return pulumi.get(self, "remote_mount_dir_path")


@pulumi.output_type
class JobJobClusterNewClusterClusterMountInfoNetworkFilesystemInfo(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "serverAddress":
            suggest = "server_address"
        elif key == "mountOptions":
            suggest = "mount_options"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in JobJobClusterNewClusterClusterMountInfoNetworkFilesystemInfo. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        JobJobClusterNewClusterClusterMountInfoNetworkFilesystemInfo.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        JobJobClusterNewClusterClusterMountInfoNetworkFilesystemInfo.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 server_address: str,
                 mount_options: Optional[str] = None):
        pulumi.set(__self__, "server_address", server_address)
        if mount_options is not None:
            pulumi.set(__self__, "mount_options", mount_options)

    @property
    @pulumi.getter(name="serverAddress")
    def server_address(self) -> str:
        return pulumi.get(self, "server_address")

    @property
    @pulumi.getter(name="mountOptions")
    def mount_options(self) -> Optional[str]:
        return pulumi.get(self, "mount_options")


@pulumi.output_type
class JobJobClusterNewClusterDockerImage(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "basicAuth":
            suggest = "basic_auth"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in JobJobClusterNewClusterDockerImage. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        JobJobClusterNewClusterDockerImage.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        JobJobClusterNewClusterDockerImage.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 url: str,
                 basic_auth: Optional['outputs.JobJobClusterNewClusterDockerImageBasicAuth'] = None):
        """
        :param str url: URL of the job on the given workspace
        """
        pulumi.set(__self__, "url", url)
        if basic_auth is not None:
            pulumi.set(__self__, "basic_auth", basic_auth)

    @property
    @pulumi.getter
    def url(self) -> str:
        """
        URL of the job on the given workspace
        """
        return pulumi.get(self, "url")

    @property
    @pulumi.getter(name="basicAuth")
    def basic_auth(self) -> Optional['outputs.JobJobClusterNewClusterDockerImageBasicAuth']:
        return pulumi.get(self, "basic_auth")


@pulumi.output_type
class JobJobClusterNewClusterDockerImageBasicAuth(dict):
    def __init__(__self__, *,
                 password: str,
                 username: str):
        pulumi.set(__self__, "password", password)
        pulumi.set(__self__, "username", username)

    @property
    @pulumi.getter
    def password(self) -> str:
        return pulumi.get(self, "password")

    @property
    @pulumi.getter
    def username(self) -> str:
        return pulumi.get(self, "username")


@pulumi.output_type
class JobJobClusterNewClusterGcpAttributes(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "bootDiskSize":
            suggest = "boot_disk_size"
        elif key == "googleServiceAccount":
            suggest = "google_service_account"
        elif key == "localSsdCount":
            suggest = "local_ssd_count"
        elif key == "usePreemptibleExecutors":
            suggest = "use_preemptible_executors"
        elif key == "zoneId":
            suggest = "zone_id"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in JobJobClusterNewClusterGcpAttributes. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        JobJobClusterNewClusterGcpAttributes.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        JobJobClusterNewClusterGcpAttributes.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 availability: Optional[str] = None,
                 boot_disk_size: Optional[int] = None,
                 google_service_account: Optional[str] = None,
                 local_ssd_count: Optional[int] = None,
                 use_preemptible_executors: Optional[bool] = None,
                 zone_id: Optional[str] = None):
        if availability is not None:
            pulumi.set(__self__, "availability", availability)
        if boot_disk_size is not None:
            pulumi.set(__self__, "boot_disk_size", boot_disk_size)
        if google_service_account is not None:
            pulumi.set(__self__, "google_service_account", google_service_account)
        if local_ssd_count is not None:
            pulumi.set(__self__, "local_ssd_count", local_ssd_count)
        if use_preemptible_executors is not None:
            pulumi.set(__self__, "use_preemptible_executors", use_preemptible_executors)
        if zone_id is not None:
            pulumi.set(__self__, "zone_id", zone_id)

    @property
    @pulumi.getter
    def availability(self) -> Optional[str]:
        return pulumi.get(self, "availability")

    @property
    @pulumi.getter(name="bootDiskSize")
    def boot_disk_size(self) -> Optional[int]:
        return pulumi.get(self, "boot_disk_size")

    @property
    @pulumi.getter(name="googleServiceAccount")
    def google_service_account(self) -> Optional[str]:
        return pulumi.get(self, "google_service_account")

    @property
    @pulumi.getter(name="localSsdCount")
    def local_ssd_count(self) -> Optional[int]:
        return pulumi.get(self, "local_ssd_count")

    @property
    @pulumi.getter(name="usePreemptibleExecutors")
    def use_preemptible_executors(self) -> Optional[bool]:
        return pulumi.get(self, "use_preemptible_executors")

    @property
    @pulumi.getter(name="zoneId")
    def zone_id(self) -> Optional[str]:
        return pulumi.get(self, "zone_id")


@pulumi.output_type
class JobJobClusterNewClusterInitScript(dict):
    def __init__(__self__, *,
                 abfss: Optional['outputs.JobJobClusterNewClusterInitScriptAbfss'] = None,
                 dbfs: Optional['outputs.JobJobClusterNewClusterInitScriptDbfs'] = None,
                 file: Optional['outputs.JobJobClusterNewClusterInitScriptFile'] = None,
                 gcs: Optional['outputs.JobJobClusterNewClusterInitScriptGcs'] = None,
                 s3: Optional['outputs.JobJobClusterNewClusterInitScriptS3'] = None,
                 volumes: Optional['outputs.JobJobClusterNewClusterInitScriptVolumes'] = None,
                 workspace: Optional['outputs.JobJobClusterNewClusterInitScriptWorkspace'] = None):
        """
        :param 'JobJobClusterNewClusterInitScriptFileArgs' file: block consisting of single string fields:
        """
        if abfss is not None:
            pulumi.set(__self__, "abfss", abfss)
        if dbfs is not None:
            pulumi.set(__self__, "dbfs", dbfs)
        if file is not None:
            pulumi.set(__self__, "file", file)
        if gcs is not None:
            pulumi.set(__self__, "gcs", gcs)
        if s3 is not None:
            pulumi.set(__self__, "s3", s3)
        if volumes is not None:
            pulumi.set(__self__, "volumes", volumes)
        if workspace is not None:
            pulumi.set(__self__, "workspace", workspace)

    @property
    @pulumi.getter
    def abfss(self) -> Optional['outputs.JobJobClusterNewClusterInitScriptAbfss']:
        return pulumi.get(self, "abfss")

    @property
    @pulumi.getter
    @_utilities.deprecated("""For init scripts use 'volumes', 'workspace' or cloud storage location instead of 'dbfs'.""")
    def dbfs(self) -> Optional['outputs.JobJobClusterNewClusterInitScriptDbfs']:
        return pulumi.get(self, "dbfs")

    @property
    @pulumi.getter
    def file(self) -> Optional['outputs.JobJobClusterNewClusterInitScriptFile']:
        """
        block consisting of single string fields:
        """
        return pulumi.get(self, "file")

    @property
    @pulumi.getter
    def gcs(self) -> Optional['outputs.JobJobClusterNewClusterInitScriptGcs']:
        return pulumi.get(self, "gcs")

    @property
    @pulumi.getter
    def s3(self) -> Optional['outputs.JobJobClusterNewClusterInitScriptS3']:
        return pulumi.get(self, "s3")

    @property
    @pulumi.getter
    def volumes(self) -> Optional['outputs.JobJobClusterNewClusterInitScriptVolumes']:
        return pulumi.get(self, "volumes")

    @property
    @pulumi.getter
    def workspace(self) -> Optional['outputs.JobJobClusterNewClusterInitScriptWorkspace']:
        return pulumi.get(self, "workspace")


@pulumi.output_type
class JobJobClusterNewClusterInitScriptAbfss(dict):
    def __init__(__self__, *,
                 destination: str):
        pulumi.set(__self__, "destination", destination)

    @property
    @pulumi.getter
    def destination(self) -> str:
        return pulumi.get(self, "destination")


@pulumi.output_type
class JobJobClusterNewClusterInitScriptDbfs(dict):
    def __init__(__self__, *,
                 destination: str):
        pulumi.set(__self__, "destination", destination)

    @property
    @pulumi.getter
    def destination(self) -> str:
        return pulumi.get(self, "destination")


@pulumi.output_type
class JobJobClusterNewClusterInitScriptFile(dict):
    def __init__(__self__, *,
                 destination: str):
        pulumi.set(__self__, "destination", destination)

    @property
    @pulumi.getter
    def destination(self) -> str:
        return pulumi.get(self, "destination")


@pulumi.output_type
class JobJobClusterNewClusterInitScriptGcs(dict):
    def __init__(__self__, *,
                 destination: str):
        pulumi.set(__self__, "destination", destination)

    @property
    @pulumi.getter
    def destination(self) -> str:
        return pulumi.get(self, "destination")


@pulumi.output_type
class JobJobClusterNewClusterInitScriptS3(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "cannedAcl":
            suggest = "canned_acl"
        elif key == "enableEncryption":
            suggest = "enable_encryption"
        elif key == "encryptionType":
            suggest = "encryption_type"
        elif key == "kmsKey":
            suggest = "kms_key"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in JobJobClusterNewClusterInitScriptS3. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        JobJobClusterNewClusterInitScriptS3.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        JobJobClusterNewClusterInitScriptS3.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 destination: str,
                 canned_acl: Optional[str] = None,
                 enable_encryption: Optional[bool] = None,
                 encryption_type: Optional[str] = None,
                 endpoint: Optional[str] = None,
                 kms_key: Optional[str] = None,
                 region: Optional[str] = None):
        pulumi.set(__self__, "destination", destination)
        if canned_acl is not None:
            pulumi.set(__self__, "canned_acl", canned_acl)
        if enable_encryption is not None:
            pulumi.set(__self__, "enable_encryption", enable_encryption)
        if encryption_type is not None:
            pulumi.set(__self__, "encryption_type", encryption_type)
        if endpoint is not None:
            pulumi.set(__self__, "endpoint", endpoint)
        if kms_key is not None:
            pulumi.set(__self__, "kms_key", kms_key)
        if region is not None:
            pulumi.set(__self__, "region", region)

    @property
    @pulumi.getter
    def destination(self) -> str:
        return pulumi.get(self, "destination")

    @property
    @pulumi.getter(name="cannedAcl")
    def canned_acl(self) -> Optional[str]:
        return pulumi.get(self, "canned_acl")

    @property
    @pulumi.getter(name="enableEncryption")
    def enable_encryption(self) -> Optional[bool]:
        return pulumi.get(self, "enable_encryption")

    @property
    @pulumi.getter(name="encryptionType")
    def encryption_type(self) -> Optional[str]:
        return pulumi.get(self, "encryption_type")

    @property
    @pulumi.getter
    def endpoint(self) -> Optional[str]:
        return pulumi.get(self, "endpoint")

    @property
    @pulumi.getter(name="kmsKey")
    def kms_key(self) -> Optional[str]:
        return pulumi.get(self, "kms_key")

    @property
    @pulumi.getter
    def region(self) -> Optional[str]:
        return pulumi.get(self, "region")


@pulumi.output_type
class JobJobClusterNewClusterInitScriptVolumes(dict):
    def __init__(__self__, *,
                 destination: str):
        pulumi.set(__self__, "destination", destination)

    @property
    @pulumi.getter
    def destination(self) -> str:
        return pulumi.get(self, "destination")


@pulumi.output_type
class JobJobClusterNewClusterInitScriptWorkspace(dict):
    def __init__(__self__, *,
                 destination: str):
        pulumi.set(__self__, "destination", destination)

    @property
    @pulumi.getter
    def destination(self) -> str:
        return pulumi.get(self, "destination")


@pulumi.output_type
class JobJobClusterNewClusterLibrary(dict):
    def __init__(__self__, *,
                 cran: Optional['outputs.JobJobClusterNewClusterLibraryCran'] = None,
                 egg: Optional[str] = None,
                 jar: Optional[str] = None,
                 maven: Optional['outputs.JobJobClusterNewClusterLibraryMaven'] = None,
                 pypi: Optional['outputs.JobJobClusterNewClusterLibraryPypi'] = None,
                 requirements: Optional[str] = None,
                 whl: Optional[str] = None):
        if cran is not None:
            pulumi.set(__self__, "cran", cran)
        if egg is not None:
            pulumi.set(__self__, "egg", egg)
        if jar is not None:
            pulumi.set(__self__, "jar", jar)
        if maven is not None:
            pulumi.set(__self__, "maven", maven)
        if pypi is not None:
            pulumi.set(__self__, "pypi", pypi)
        if requirements is not None:
            pulumi.set(__self__, "requirements", requirements)
        if whl is not None:
            pulumi.set(__self__, "whl", whl)

    @property
    @pulumi.getter
    def cran(self) -> Optional['outputs.JobJobClusterNewClusterLibraryCran']:
        return pulumi.get(self, "cran")

    @property
    @pulumi.getter
    def egg(self) -> Optional[str]:
        return pulumi.get(self, "egg")

    @property
    @pulumi.getter
    def jar(self) -> Optional[str]:
        return pulumi.get(self, "jar")

    @property
    @pulumi.getter
    def maven(self) -> Optional['outputs.JobJobClusterNewClusterLibraryMaven']:
        return pulumi.get(self, "maven")

    @property
    @pulumi.getter
    def pypi(self) -> Optional['outputs.JobJobClusterNewClusterLibraryPypi']:
        return pulumi.get(self, "pypi")

    @property
    @pulumi.getter
    def requirements(self) -> Optional[str]:
        return pulumi.get(self, "requirements")

    @property
    @pulumi.getter
    def whl(self) -> Optional[str]:
        return pulumi.get(self, "whl")


@pulumi.output_type
class JobJobClusterNewClusterLibraryCran(dict):
    def __init__(__self__, *,
                 package: str,
                 repo: Optional[str] = None):
        pulumi.set(__self__, "package", package)
        if repo is not None:
            pulumi.set(__self__, "repo", repo)

    @property
    @pulumi.getter
    def package(self) -> str:
        return pulumi.get(self, "package")

    @property
    @pulumi.getter
    def repo(self) -> Optional[str]:
        return pulumi.get(self, "repo")


@pulumi.output_type
class JobJobClusterNewClusterLibraryMaven(dict):
    def __init__(__self__, *,
                 coordinates: str,
                 exclusions: Optional[Sequence[str]] = None,
                 repo: Optional[str] = None):
        pulumi.set(__self__, "coordinates", coordinates)
        if exclusions is not None:
            pulumi.set(__self__, "exclusions", exclusions)
        if repo is not None:
            pulumi.set(__self__, "repo", repo)

    @property
    @pulumi.getter
    def coordinates(self) -> str:
        return pulumi.get(self, "coordinates")

    @property
    @pulumi.getter
    def exclusions(self) -> Optional[Sequence[str]]:
        return pulumi.get(self, "exclusions")

    @property
    @pulumi.getter
    def repo(self) -> Optional[str]:
        return pulumi.get(self, "repo")


@pulumi.output_type
class JobJobClusterNewClusterLibraryPypi(dict):
    def __init__(__self__, *,
                 package: str,
                 repo: Optional[str] = None):
        pulumi.set(__self__, "package", package)
        if repo is not None:
            pulumi.set(__self__, "repo", repo)

    @property
    @pulumi.getter
    def package(self) -> str:
        return pulumi.get(self, "package")

    @property
    @pulumi.getter
    def repo(self) -> Optional[str]:
        return pulumi.get(self, "repo")


@pulumi.output_type
class JobJobClusterNewClusterWorkloadType(dict):
    def __init__(__self__, *,
                 clients: 'outputs.JobJobClusterNewClusterWorkloadTypeClients'):
        pulumi.set(__self__, "clients", clients)

    @property
    @pulumi.getter
    def clients(self) -> 'outputs.JobJobClusterNewClusterWorkloadTypeClients':
        return pulumi.get(self, "clients")


@pulumi.output_type
class JobJobClusterNewClusterWorkloadTypeClients(dict):
    def __init__(__self__, *,
                 jobs: Optional[bool] = None,
                 notebooks: Optional[bool] = None):
        if jobs is not None:
            pulumi.set(__self__, "jobs", jobs)
        if notebooks is not None:
            pulumi.set(__self__, "notebooks", notebooks)

    @property
    @pulumi.getter
    def jobs(self) -> Optional[bool]:
        return pulumi.get(self, "jobs")

    @property
    @pulumi.getter
    def notebooks(self) -> Optional[bool]:
        return pulumi.get(self, "notebooks")


@pulumi.output_type
class JobLibrary(dict):
    def __init__(__self__, *,
                 cran: Optional['outputs.JobLibraryCran'] = None,
                 egg: Optional[str] = None,
                 jar: Optional[str] = None,
                 maven: Optional['outputs.JobLibraryMaven'] = None,
                 pypi: Optional['outputs.JobLibraryPypi'] = None,
                 requirements: Optional[str] = None,
                 whl: Optional[str] = None):
        if cran is not None:
            pulumi.set(__self__, "cran", cran)
        if egg is not None:
            pulumi.set(__self__, "egg", egg)
        if jar is not None:
            pulumi.set(__self__, "jar", jar)
        if maven is not None:
            pulumi.set(__self__, "maven", maven)
        if pypi is not None:
            pulumi.set(__self__, "pypi", pypi)
        if requirements is not None:
            pulumi.set(__self__, "requirements", requirements)
        if whl is not None:
            pulumi.set(__self__, "whl", whl)

    @property
    @pulumi.getter
    def cran(self) -> Optional['outputs.JobLibraryCran']:
        return pulumi.get(self, "cran")

    @property
    @pulumi.getter
    def egg(self) -> Optional[str]:
        return pulumi.get(self, "egg")

    @property
    @pulumi.getter
    def jar(self) -> Optional[str]:
        return pulumi.get(self, "jar")

    @property
    @pulumi.getter
    def maven(self) -> Optional['outputs.JobLibraryMaven']:
        return pulumi.get(self, "maven")

    @property
    @pulumi.getter
    def pypi(self) -> Optional['outputs.JobLibraryPypi']:
        return pulumi.get(self, "pypi")

    @property
    @pulumi.getter
    def requirements(self) -> Optional[str]:
        return pulumi.get(self, "requirements")

    @property
    @pulumi.getter
    def whl(self) -> Optional[str]:
        return pulumi.get(self, "whl")


@pulumi.output_type
class JobLibraryCran(dict):
    def __init__(__self__, *,
                 package: str,
                 repo: Optional[str] = None):
        pulumi.set(__self__, "package", package)
        if repo is not None:
            pulumi.set(__self__, "repo", repo)

    @property
    @pulumi.getter
    def package(self) -> str:
        return pulumi.get(self, "package")

    @property
    @pulumi.getter
    def repo(self) -> Optional[str]:
        return pulumi.get(self, "repo")


@pulumi.output_type
class JobLibraryMaven(dict):
    def __init__(__self__, *,
                 coordinates: str,
                 exclusions: Optional[Sequence[str]] = None,
                 repo: Optional[str] = None):
        pulumi.set(__self__, "coordinates", coordinates)
        if exclusions is not None:
            pulumi.set(__self__, "exclusions", exclusions)
        if repo is not None:
            pulumi.set(__self__, "repo", repo)

    @property
    @pulumi.getter
    def coordinates(self) -> str:
        return pulumi.get(self, "coordinates")

    @property
    @pulumi.getter
    def exclusions(self) -> Optional[Sequence[str]]:
        return pulumi.get(self, "exclusions")

    @property
    @pulumi.getter
    def repo(self) -> Optional[str]:
        return pulumi.get(self, "repo")


@pulumi.output_type
class JobLibraryPypi(dict):
    def __init__(__self__, *,
                 package: str,
                 repo: Optional[str] = None):
        pulumi.set(__self__, "package", package)
        if repo is not None:
            pulumi.set(__self__, "repo", repo)

    @property
    @pulumi.getter
    def package(self) -> str:
        return pulumi.get(self, "package")

    @property
    @pulumi.getter
    def repo(self) -> Optional[str]:
        return pulumi.get(self, "repo")


@pulumi.output_type
class JobNewCluster(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "sparkVersion":
            suggest = "spark_version"
        elif key == "applyPolicyDefaultValues":
            suggest = "apply_policy_default_values"
        elif key == "awsAttributes":
            suggest = "aws_attributes"
        elif key == "azureAttributes":
            suggest = "azure_attributes"
        elif key == "clusterId":
            suggest = "cluster_id"
        elif key == "clusterLogConf":
            suggest = "cluster_log_conf"
        elif key == "clusterMountInfos":
            suggest = "cluster_mount_infos"
        elif key == "clusterName":
            suggest = "cluster_name"
        elif key == "customTags":
            suggest = "custom_tags"
        elif key == "dataSecurityMode":
            suggest = "data_security_mode"
        elif key == "dockerImage":
            suggest = "docker_image"
        elif key == "driverInstancePoolId":
            suggest = "driver_instance_pool_id"
        elif key == "driverNodeTypeId":
            suggest = "driver_node_type_id"
        elif key == "enableElasticDisk":
            suggest = "enable_elastic_disk"
        elif key == "enableLocalDiskEncryption":
            suggest = "enable_local_disk_encryption"
        elif key == "gcpAttributes":
            suggest = "gcp_attributes"
        elif key == "idempotencyToken":
            suggest = "idempotency_token"
        elif key == "initScripts":
            suggest = "init_scripts"
        elif key == "instancePoolId":
            suggest = "instance_pool_id"
        elif key == "nodeTypeId":
            suggest = "node_type_id"
        elif key == "numWorkers":
            suggest = "num_workers"
        elif key == "policyId":
            suggest = "policy_id"
        elif key == "runtimeEngine":
            suggest = "runtime_engine"
        elif key == "singleUserName":
            suggest = "single_user_name"
        elif key == "sparkConf":
            suggest = "spark_conf"
        elif key == "sparkEnvVars":
            suggest = "spark_env_vars"
        elif key == "sshPublicKeys":
            suggest = "ssh_public_keys"
        elif key == "workloadType":
            suggest = "workload_type"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in JobNewCluster. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        JobNewCluster.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        JobNewCluster.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 spark_version: str,
                 apply_policy_default_values: Optional[bool] = None,
                 autoscale: Optional['outputs.JobNewClusterAutoscale'] = None,
                 aws_attributes: Optional['outputs.JobNewClusterAwsAttributes'] = None,
                 azure_attributes: Optional['outputs.JobNewClusterAzureAttributes'] = None,
                 cluster_id: Optional[str] = None,
                 cluster_log_conf: Optional['outputs.JobNewClusterClusterLogConf'] = None,
                 cluster_mount_infos: Optional[Sequence['outputs.JobNewClusterClusterMountInfo']] = None,
                 cluster_name: Optional[str] = None,
                 custom_tags: Optional[Mapping[str, str]] = None,
                 data_security_mode: Optional[str] = None,
                 docker_image: Optional['outputs.JobNewClusterDockerImage'] = None,
                 driver_instance_pool_id: Optional[str] = None,
                 driver_node_type_id: Optional[str] = None,
                 enable_elastic_disk: Optional[bool] = None,
                 enable_local_disk_encryption: Optional[bool] = None,
                 gcp_attributes: Optional['outputs.JobNewClusterGcpAttributes'] = None,
                 idempotency_token: Optional[str] = None,
                 init_scripts: Optional[Sequence['outputs.JobNewClusterInitScript']] = None,
                 instance_pool_id: Optional[str] = None,
                 libraries: Optional[Sequence['outputs.JobNewClusterLibrary']] = None,
                 node_type_id: Optional[str] = None,
                 num_workers: Optional[int] = None,
                 policy_id: Optional[str] = None,
                 runtime_engine: Optional[str] = None,
                 single_user_name: Optional[str] = None,
                 spark_conf: Optional[Mapping[str, str]] = None,
                 spark_env_vars: Optional[Mapping[str, str]] = None,
                 ssh_public_keys: Optional[Sequence[str]] = None,
                 workload_type: Optional['outputs.JobNewClusterWorkloadType'] = None):
        """
        :param Sequence['JobNewClusterLibraryArgs'] libraries: (List) An optional list of libraries to be installed on the cluster that will execute the job. See library Configuration Block below.
        :param 'JobNewClusterWorkloadTypeArgs' workload_type: isn't supported
        """
        pulumi.set(__self__, "spark_version", spark_version)
        if apply_policy_default_values is not None:
            pulumi.set(__self__, "apply_policy_default_values", apply_policy_default_values)
        if autoscale is not None:
            pulumi.set(__self__, "autoscale", autoscale)
        if aws_attributes is not None:
            pulumi.set(__self__, "aws_attributes", aws_attributes)
        if azure_attributes is not None:
            pulumi.set(__self__, "azure_attributes", azure_attributes)
        if cluster_id is not None:
            pulumi.set(__self__, "cluster_id", cluster_id)
        if cluster_log_conf is not None:
            pulumi.set(__self__, "cluster_log_conf", cluster_log_conf)
        if cluster_mount_infos is not None:
            pulumi.set(__self__, "cluster_mount_infos", cluster_mount_infos)
        if cluster_name is not None:
            pulumi.set(__self__, "cluster_name", cluster_name)
        if custom_tags is not None:
            pulumi.set(__self__, "custom_tags", custom_tags)
        if data_security_mode is not None:
            pulumi.set(__self__, "data_security_mode", data_security_mode)
        if docker_image is not None:
            pulumi.set(__self__, "docker_image", docker_image)
        if driver_instance_pool_id is not None:
            pulumi.set(__self__, "driver_instance_pool_id", driver_instance_pool_id)
        if driver_node_type_id is not None:
            pulumi.set(__self__, "driver_node_type_id", driver_node_type_id)
        if enable_elastic_disk is not None:
            pulumi.set(__self__, "enable_elastic_disk", enable_elastic_disk)
        if enable_local_disk_encryption is not None:
            pulumi.set(__self__, "enable_local_disk_encryption", enable_local_disk_encryption)
        if gcp_attributes is not None:
            pulumi.set(__self__, "gcp_attributes", gcp_attributes)
        if idempotency_token is not None:
            pulumi.set(__self__, "idempotency_token", idempotency_token)
        if init_scripts is not None:
            pulumi.set(__self__, "init_scripts", init_scripts)
        if instance_pool_id is not None:
            pulumi.set(__self__, "instance_pool_id", instance_pool_id)
        if libraries is not None:
            pulumi.set(__self__, "libraries", libraries)
        if node_type_id is not None:
            pulumi.set(__self__, "node_type_id", node_type_id)
        if num_workers is not None:
            pulumi.set(__self__, "num_workers", num_workers)
        if policy_id is not None:
            pulumi.set(__self__, "policy_id", policy_id)
        if runtime_engine is not None:
            pulumi.set(__self__, "runtime_engine", runtime_engine)
        if single_user_name is not None:
            pulumi.set(__self__, "single_user_name", single_user_name)
        if spark_conf is not None:
            pulumi.set(__self__, "spark_conf", spark_conf)
        if spark_env_vars is not None:
            pulumi.set(__self__, "spark_env_vars", spark_env_vars)
        if ssh_public_keys is not None:
            pulumi.set(__self__, "ssh_public_keys", ssh_public_keys)
        if workload_type is not None:
            pulumi.set(__self__, "workload_type", workload_type)

    @property
    @pulumi.getter(name="sparkVersion")
    def spark_version(self) -> str:
        return pulumi.get(self, "spark_version")

    @property
    @pulumi.getter(name="applyPolicyDefaultValues")
    def apply_policy_default_values(self) -> Optional[bool]:
        return pulumi.get(self, "apply_policy_default_values")

    @property
    @pulumi.getter
    def autoscale(self) -> Optional['outputs.JobNewClusterAutoscale']:
        return pulumi.get(self, "autoscale")

    @property
    @pulumi.getter(name="awsAttributes")
    def aws_attributes(self) -> Optional['outputs.JobNewClusterAwsAttributes']:
        return pulumi.get(self, "aws_attributes")

    @property
    @pulumi.getter(name="azureAttributes")
    def azure_attributes(self) -> Optional['outputs.JobNewClusterAzureAttributes']:
        return pulumi.get(self, "azure_attributes")

    @property
    @pulumi.getter(name="clusterId")
    def cluster_id(self) -> Optional[str]:
        return pulumi.get(self, "cluster_id")

    @property
    @pulumi.getter(name="clusterLogConf")
    def cluster_log_conf(self) -> Optional['outputs.JobNewClusterClusterLogConf']:
        return pulumi.get(self, "cluster_log_conf")

    @property
    @pulumi.getter(name="clusterMountInfos")
    def cluster_mount_infos(self) -> Optional[Sequence['outputs.JobNewClusterClusterMountInfo']]:
        return pulumi.get(self, "cluster_mount_infos")

    @property
    @pulumi.getter(name="clusterName")
    def cluster_name(self) -> Optional[str]:
        return pulumi.get(self, "cluster_name")

    @property
    @pulumi.getter(name="customTags")
    def custom_tags(self) -> Optional[Mapping[str, str]]:
        return pulumi.get(self, "custom_tags")

    @property
    @pulumi.getter(name="dataSecurityMode")
    def data_security_mode(self) -> Optional[str]:
        return pulumi.get(self, "data_security_mode")

    @property
    @pulumi.getter(name="dockerImage")
    def docker_image(self) -> Optional['outputs.JobNewClusterDockerImage']:
        return pulumi.get(self, "docker_image")

    @property
    @pulumi.getter(name="driverInstancePoolId")
    def driver_instance_pool_id(self) -> Optional[str]:
        return pulumi.get(self, "driver_instance_pool_id")

    @property
    @pulumi.getter(name="driverNodeTypeId")
    def driver_node_type_id(self) -> Optional[str]:
        return pulumi.get(self, "driver_node_type_id")

    @property
    @pulumi.getter(name="enableElasticDisk")
    def enable_elastic_disk(self) -> Optional[bool]:
        return pulumi.get(self, "enable_elastic_disk")

    @property
    @pulumi.getter(name="enableLocalDiskEncryption")
    def enable_local_disk_encryption(self) -> Optional[bool]:
        return pulumi.get(self, "enable_local_disk_encryption")

    @property
    @pulumi.getter(name="gcpAttributes")
    def gcp_attributes(self) -> Optional['outputs.JobNewClusterGcpAttributes']:
        return pulumi.get(self, "gcp_attributes")

    @property
    @pulumi.getter(name="idempotencyToken")
    def idempotency_token(self) -> Optional[str]:
        return pulumi.get(self, "idempotency_token")

    @property
    @pulumi.getter(name="initScripts")
    def init_scripts(self) -> Optional[Sequence['outputs.JobNewClusterInitScript']]:
        return pulumi.get(self, "init_scripts")

    @property
    @pulumi.getter(name="instancePoolId")
    def instance_pool_id(self) -> Optional[str]:
        return pulumi.get(self, "instance_pool_id")

    @property
    @pulumi.getter
    def libraries(self) -> Optional[Sequence['outputs.JobNewClusterLibrary']]:
        """
        (List) An optional list of libraries to be installed on the cluster that will execute the job. See library Configuration Block below.
        """
        return pulumi.get(self, "libraries")

    @property
    @pulumi.getter(name="nodeTypeId")
    def node_type_id(self) -> Optional[str]:
        return pulumi.get(self, "node_type_id")

    @property
    @pulumi.getter(name="numWorkers")
    def num_workers(self) -> Optional[int]:
        return pulumi.get(self, "num_workers")

    @property
    @pulumi.getter(name="policyId")
    def policy_id(self) -> Optional[str]:
        return pulumi.get(self, "policy_id")

    @property
    @pulumi.getter(name="runtimeEngine")
    def runtime_engine(self) -> Optional[str]:
        return pulumi.get(self, "runtime_engine")

    @property
    @pulumi.getter(name="singleUserName")
    def single_user_name(self) -> Optional[str]:
        return pulumi.get(self, "single_user_name")

    @property
    @pulumi.getter(name="sparkConf")
    def spark_conf(self) -> Optional[Mapping[str, str]]:
        return pulumi.get(self, "spark_conf")

    @property
    @pulumi.getter(name="sparkEnvVars")
    def spark_env_vars(self) -> Optional[Mapping[str, str]]:
        return pulumi.get(self, "spark_env_vars")

    @property
    @pulumi.getter(name="sshPublicKeys")
    def ssh_public_keys(self) -> Optional[Sequence[str]]:
        return pulumi.get(self, "ssh_public_keys")

    @property
    @pulumi.getter(name="workloadType")
    def workload_type(self) -> Optional['outputs.JobNewClusterWorkloadType']:
        """
        isn't supported
        """
        return pulumi.get(self, "workload_type")


@pulumi.output_type
class JobNewClusterAutoscale(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "maxWorkers":
            suggest = "max_workers"
        elif key == "minWorkers":
            suggest = "min_workers"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in JobNewClusterAutoscale. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        JobNewClusterAutoscale.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        JobNewClusterAutoscale.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 max_workers: Optional[int] = None,
                 min_workers: Optional[int] = None):
        if max_workers is not None:
            pulumi.set(__self__, "max_workers", max_workers)
        if min_workers is not None:
            pulumi.set(__self__, "min_workers", min_workers)

    @property
    @pulumi.getter(name="maxWorkers")
    def max_workers(self) -> Optional[int]:
        return pulumi.get(self, "max_workers")

    @property
    @pulumi.getter(name="minWorkers")
    def min_workers(self) -> Optional[int]:
        return pulumi.get(self, "min_workers")


@pulumi.output_type
class JobNewClusterAwsAttributes(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "ebsVolumeCount":
            suggest = "ebs_volume_count"
        elif key == "ebsVolumeIops":
            suggest = "ebs_volume_iops"
        elif key == "ebsVolumeSize":
            suggest = "ebs_volume_size"
        elif key == "ebsVolumeThroughput":
            suggest = "ebs_volume_throughput"
        elif key == "ebsVolumeType":
            suggest = "ebs_volume_type"
        elif key == "firstOnDemand":
            suggest = "first_on_demand"
        elif key == "instanceProfileArn":
            suggest = "instance_profile_arn"
        elif key == "spotBidPricePercent":
            suggest = "spot_bid_price_percent"
        elif key == "zoneId":
            suggest = "zone_id"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in JobNewClusterAwsAttributes. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        JobNewClusterAwsAttributes.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        JobNewClusterAwsAttributes.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 availability: Optional[str] = None,
                 ebs_volume_count: Optional[int] = None,
                 ebs_volume_iops: Optional[int] = None,
                 ebs_volume_size: Optional[int] = None,
                 ebs_volume_throughput: Optional[int] = None,
                 ebs_volume_type: Optional[str] = None,
                 first_on_demand: Optional[int] = None,
                 instance_profile_arn: Optional[str] = None,
                 spot_bid_price_percent: Optional[int] = None,
                 zone_id: Optional[str] = None):
        if availability is not None:
            pulumi.set(__self__, "availability", availability)
        if ebs_volume_count is not None:
            pulumi.set(__self__, "ebs_volume_count", ebs_volume_count)
        if ebs_volume_iops is not None:
            pulumi.set(__self__, "ebs_volume_iops", ebs_volume_iops)
        if ebs_volume_size is not None:
            pulumi.set(__self__, "ebs_volume_size", ebs_volume_size)
        if ebs_volume_throughput is not None:
            pulumi.set(__self__, "ebs_volume_throughput", ebs_volume_throughput)
        if ebs_volume_type is not None:
            pulumi.set(__self__, "ebs_volume_type", ebs_volume_type)
        if first_on_demand is not None:
            pulumi.set(__self__, "first_on_demand", first_on_demand)
        if instance_profile_arn is not None:
            pulumi.set(__self__, "instance_profile_arn", instance_profile_arn)
        if spot_bid_price_percent is not None:
            pulumi.set(__self__, "spot_bid_price_percent", spot_bid_price_percent)
        if zone_id is not None:
            pulumi.set(__self__, "zone_id", zone_id)

    @property
    @pulumi.getter
    def availability(self) -> Optional[str]:
        return pulumi.get(self, "availability")

    @property
    @pulumi.getter(name="ebsVolumeCount")
    def ebs_volume_count(self) -> Optional[int]:
        return pulumi.get(self, "ebs_volume_count")

    @property
    @pulumi.getter(name="ebsVolumeIops")
    def ebs_volume_iops(self) -> Optional[int]:
        return pulumi.get(self, "ebs_volume_iops")

    @property
    @pulumi.getter(name="ebsVolumeSize")
    def ebs_volume_size(self) -> Optional[int]:
        return pulumi.get(self, "ebs_volume_size")

    @property
    @pulumi.getter(name="ebsVolumeThroughput")
    def ebs_volume_throughput(self) -> Optional[int]:
        return pulumi.get(self, "ebs_volume_throughput")

    @property
    @pulumi.getter(name="ebsVolumeType")
    def ebs_volume_type(self) -> Optional[str]:
        return pulumi.get(self, "ebs_volume_type")

    @property
    @pulumi.getter(name="firstOnDemand")
    def first_on_demand(self) -> Optional[int]:
        return pulumi.get(self, "first_on_demand")

    @property
    @pulumi.getter(name="instanceProfileArn")
    def instance_profile_arn(self) -> Optional[str]:
        return pulumi.get(self, "instance_profile_arn")

    @property
    @pulumi.getter(name="spotBidPricePercent")
    def spot_bid_price_percent(self) -> Optional[int]:
        return pulumi.get(self, "spot_bid_price_percent")

    @property
    @pulumi.getter(name="zoneId")
    def zone_id(self) -> Optional[str]:
        return pulumi.get(self, "zone_id")


@pulumi.output_type
class JobNewClusterAzureAttributes(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "firstOnDemand":
            suggest = "first_on_demand"
        elif key == "logAnalyticsInfo":
            suggest = "log_analytics_info"
        elif key == "spotBidMaxPrice":
            suggest = "spot_bid_max_price"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in JobNewClusterAzureAttributes. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        JobNewClusterAzureAttributes.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        JobNewClusterAzureAttributes.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 availability: Optional[str] = None,
                 first_on_demand: Optional[int] = None,
                 log_analytics_info: Optional['outputs.JobNewClusterAzureAttributesLogAnalyticsInfo'] = None,
                 spot_bid_max_price: Optional[float] = None):
        if availability is not None:
            pulumi.set(__self__, "availability", availability)
        if first_on_demand is not None:
            pulumi.set(__self__, "first_on_demand", first_on_demand)
        if log_analytics_info is not None:
            pulumi.set(__self__, "log_analytics_info", log_analytics_info)
        if spot_bid_max_price is not None:
            pulumi.set(__self__, "spot_bid_max_price", spot_bid_max_price)

    @property
    @pulumi.getter
    def availability(self) -> Optional[str]:
        return pulumi.get(self, "availability")

    @property
    @pulumi.getter(name="firstOnDemand")
    def first_on_demand(self) -> Optional[int]:
        return pulumi.get(self, "first_on_demand")

    @property
    @pulumi.getter(name="logAnalyticsInfo")
    def log_analytics_info(self) -> Optional['outputs.JobNewClusterAzureAttributesLogAnalyticsInfo']:
        return pulumi.get(self, "log_analytics_info")

    @property
    @pulumi.getter(name="spotBidMaxPrice")
    def spot_bid_max_price(self) -> Optional[float]:
        return pulumi.get(self, "spot_bid_max_price")


@pulumi.output_type
class JobNewClusterAzureAttributesLogAnalyticsInfo(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "logAnalyticsPrimaryKey":
            suggest = "log_analytics_primary_key"
        elif key == "logAnalyticsWorkspaceId":
            suggest = "log_analytics_workspace_id"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in JobNewClusterAzureAttributesLogAnalyticsInfo. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        JobNewClusterAzureAttributesLogAnalyticsInfo.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        JobNewClusterAzureAttributesLogAnalyticsInfo.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 log_analytics_primary_key: Optional[str] = None,
                 log_analytics_workspace_id: Optional[str] = None):
        if log_analytics_primary_key is not None:
            pulumi.set(__self__, "log_analytics_primary_key", log_analytics_primary_key)
        if log_analytics_workspace_id is not None:
            pulumi.set(__self__, "log_analytics_workspace_id", log_analytics_workspace_id)

    @property
    @pulumi.getter(name="logAnalyticsPrimaryKey")
    def log_analytics_primary_key(self) -> Optional[str]:
        return pulumi.get(self, "log_analytics_primary_key")

    @property
    @pulumi.getter(name="logAnalyticsWorkspaceId")
    def log_analytics_workspace_id(self) -> Optional[str]:
        return pulumi.get(self, "log_analytics_workspace_id")


@pulumi.output_type
class JobNewClusterClusterLogConf(dict):
    def __init__(__self__, *,
                 dbfs: Optional['outputs.JobNewClusterClusterLogConfDbfs'] = None,
                 s3: Optional['outputs.JobNewClusterClusterLogConfS3'] = None):
        if dbfs is not None:
            pulumi.set(__self__, "dbfs", dbfs)
        if s3 is not None:
            pulumi.set(__self__, "s3", s3)

    @property
    @pulumi.getter
    def dbfs(self) -> Optional['outputs.JobNewClusterClusterLogConfDbfs']:
        return pulumi.get(self, "dbfs")

    @property
    @pulumi.getter
    def s3(self) -> Optional['outputs.JobNewClusterClusterLogConfS3']:
        return pulumi.get(self, "s3")


@pulumi.output_type
class JobNewClusterClusterLogConfDbfs(dict):
    def __init__(__self__, *,
                 destination: str):
        pulumi.set(__self__, "destination", destination)

    @property
    @pulumi.getter
    def destination(self) -> str:
        return pulumi.get(self, "destination")


@pulumi.output_type
class JobNewClusterClusterLogConfS3(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "cannedAcl":
            suggest = "canned_acl"
        elif key == "enableEncryption":
            suggest = "enable_encryption"
        elif key == "encryptionType":
            suggest = "encryption_type"
        elif key == "kmsKey":
            suggest = "kms_key"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in JobNewClusterClusterLogConfS3. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        JobNewClusterClusterLogConfS3.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        JobNewClusterClusterLogConfS3.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 destination: str,
                 canned_acl: Optional[str] = None,
                 enable_encryption: Optional[bool] = None,
                 encryption_type: Optional[str] = None,
                 endpoint: Optional[str] = None,
                 kms_key: Optional[str] = None,
                 region: Optional[str] = None):
        pulumi.set(__self__, "destination", destination)
        if canned_acl is not None:
            pulumi.set(__self__, "canned_acl", canned_acl)
        if enable_encryption is not None:
            pulumi.set(__self__, "enable_encryption", enable_encryption)
        if encryption_type is not None:
            pulumi.set(__self__, "encryption_type", encryption_type)
        if endpoint is not None:
            pulumi.set(__self__, "endpoint", endpoint)
        if kms_key is not None:
            pulumi.set(__self__, "kms_key", kms_key)
        if region is not None:
            pulumi.set(__self__, "region", region)

    @property
    @pulumi.getter
    def destination(self) -> str:
        return pulumi.get(self, "destination")

    @property
    @pulumi.getter(name="cannedAcl")
    def canned_acl(self) -> Optional[str]:
        return pulumi.get(self, "canned_acl")

    @property
    @pulumi.getter(name="enableEncryption")
    def enable_encryption(self) -> Optional[bool]:
        return pulumi.get(self, "enable_encryption")

    @property
    @pulumi.getter(name="encryptionType")
    def encryption_type(self) -> Optional[str]:
        return pulumi.get(self, "encryption_type")

    @property
    @pulumi.getter
    def endpoint(self) -> Optional[str]:
        return pulumi.get(self, "endpoint")

    @property
    @pulumi.getter(name="kmsKey")
    def kms_key(self) -> Optional[str]:
        return pulumi.get(self, "kms_key")

    @property
    @pulumi.getter
    def region(self) -> Optional[str]:
        return pulumi.get(self, "region")


@pulumi.output_type
class JobNewClusterClusterMountInfo(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "localMountDirPath":
            suggest = "local_mount_dir_path"
        elif key == "networkFilesystemInfo":
            suggest = "network_filesystem_info"
        elif key == "remoteMountDirPath":
            suggest = "remote_mount_dir_path"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in JobNewClusterClusterMountInfo. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        JobNewClusterClusterMountInfo.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        JobNewClusterClusterMountInfo.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 local_mount_dir_path: str,
                 network_filesystem_info: 'outputs.JobNewClusterClusterMountInfoNetworkFilesystemInfo',
                 remote_mount_dir_path: Optional[str] = None):
        pulumi.set(__self__, "local_mount_dir_path", local_mount_dir_path)
        pulumi.set(__self__, "network_filesystem_info", network_filesystem_info)
        if remote_mount_dir_path is not None:
            pulumi.set(__self__, "remote_mount_dir_path", remote_mount_dir_path)

    @property
    @pulumi.getter(name="localMountDirPath")
    def local_mount_dir_path(self) -> str:
        return pulumi.get(self, "local_mount_dir_path")

    @property
    @pulumi.getter(name="networkFilesystemInfo")
    def network_filesystem_info(self) -> 'outputs.JobNewClusterClusterMountInfoNetworkFilesystemInfo':
        return pulumi.get(self, "network_filesystem_info")

    @property
    @pulumi.getter(name="remoteMountDirPath")
    def remote_mount_dir_path(self) -> Optional[str]:
        return pulumi.get(self, "remote_mount_dir_path")


@pulumi.output_type
class JobNewClusterClusterMountInfoNetworkFilesystemInfo(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "serverAddress":
            suggest = "server_address"
        elif key == "mountOptions":
            suggest = "mount_options"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in JobNewClusterClusterMountInfoNetworkFilesystemInfo. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        JobNewClusterClusterMountInfoNetworkFilesystemInfo.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        JobNewClusterClusterMountInfoNetworkFilesystemInfo.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 server_address: str,
                 mount_options: Optional[str] = None):
        pulumi.set(__self__, "server_address", server_address)
        if mount_options is not None:
            pulumi.set(__self__, "mount_options", mount_options)

    @property
    @pulumi.getter(name="serverAddress")
    def server_address(self) -> str:
        return pulumi.get(self, "server_address")

    @property
    @pulumi.getter(name="mountOptions")
    def mount_options(self) -> Optional[str]:
        return pulumi.get(self, "mount_options")


@pulumi.output_type
class JobNewClusterDockerImage(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "basicAuth":
            suggest = "basic_auth"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in JobNewClusterDockerImage. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        JobNewClusterDockerImage.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        JobNewClusterDockerImage.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 url: str,
                 basic_auth: Optional['outputs.JobNewClusterDockerImageBasicAuth'] = None):
        """
        :param str url: URL of the job on the given workspace
        """
        pulumi.set(__self__, "url", url)
        if basic_auth is not None:
            pulumi.set(__self__, "basic_auth", basic_auth)

    @property
    @pulumi.getter
    def url(self) -> str:
        """
        URL of the job on the given workspace
        """
        return pulumi.get(self, "url")

    @property
    @pulumi.getter(name="basicAuth")
    def basic_auth(self) -> Optional['outputs.JobNewClusterDockerImageBasicAuth']:
        return pulumi.get(self, "basic_auth")


@pulumi.output_type
class JobNewClusterDockerImageBasicAuth(dict):
    def __init__(__self__, *,
                 password: str,
                 username: str):
        pulumi.set(__self__, "password", password)
        pulumi.set(__self__, "username", username)

    @property
    @pulumi.getter
    def password(self) -> str:
        return pulumi.get(self, "password")

    @property
    @pulumi.getter
    def username(self) -> str:
        return pulumi.get(self, "username")


@pulumi.output_type
class JobNewClusterGcpAttributes(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "bootDiskSize":
            suggest = "boot_disk_size"
        elif key == "googleServiceAccount":
            suggest = "google_service_account"
        elif key == "localSsdCount":
            suggest = "local_ssd_count"
        elif key == "usePreemptibleExecutors":
            suggest = "use_preemptible_executors"
        elif key == "zoneId":
            suggest = "zone_id"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in JobNewClusterGcpAttributes. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        JobNewClusterGcpAttributes.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        JobNewClusterGcpAttributes.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 availability: Optional[str] = None,
                 boot_disk_size: Optional[int] = None,
                 google_service_account: Optional[str] = None,
                 local_ssd_count: Optional[int] = None,
                 use_preemptible_executors: Optional[bool] = None,
                 zone_id: Optional[str] = None):
        if availability is not None:
            pulumi.set(__self__, "availability", availability)
        if boot_disk_size is not None:
            pulumi.set(__self__, "boot_disk_size", boot_disk_size)
        if google_service_account is not None:
            pulumi.set(__self__, "google_service_account", google_service_account)
        if local_ssd_count is not None:
            pulumi.set(__self__, "local_ssd_count", local_ssd_count)
        if use_preemptible_executors is not None:
            pulumi.set(__self__, "use_preemptible_executors", use_preemptible_executors)
        if zone_id is not None:
            pulumi.set(__self__, "zone_id", zone_id)

    @property
    @pulumi.getter
    def availability(self) -> Optional[str]:
        return pulumi.get(self, "availability")

    @property
    @pulumi.getter(name="bootDiskSize")
    def boot_disk_size(self) -> Optional[int]:
        return pulumi.get(self, "boot_disk_size")

    @property
    @pulumi.getter(name="googleServiceAccount")
    def google_service_account(self) -> Optional[str]:
        return pulumi.get(self, "google_service_account")

    @property
    @pulumi.getter(name="localSsdCount")
    def local_ssd_count(self) -> Optional[int]:
        return pulumi.get(self, "local_ssd_count")

    @property
    @pulumi.getter(name="usePreemptibleExecutors")
    def use_preemptible_executors(self) -> Optional[bool]:
        return pulumi.get(self, "use_preemptible_executors")

    @property
    @pulumi.getter(name="zoneId")
    def zone_id(self) -> Optional[str]:
        return pulumi.get(self, "zone_id")


@pulumi.output_type
class JobNewClusterInitScript(dict):
    def __init__(__self__, *,
                 abfss: Optional['outputs.JobNewClusterInitScriptAbfss'] = None,
                 dbfs: Optional['outputs.JobNewClusterInitScriptDbfs'] = None,
                 file: Optional['outputs.JobNewClusterInitScriptFile'] = None,
                 gcs: Optional['outputs.JobNewClusterInitScriptGcs'] = None,
                 s3: Optional['outputs.JobNewClusterInitScriptS3'] = None,
                 volumes: Optional['outputs.JobNewClusterInitScriptVolumes'] = None,
                 workspace: Optional['outputs.JobNewClusterInitScriptWorkspace'] = None):
        """
        :param 'JobNewClusterInitScriptFileArgs' file: block consisting of single string fields:
        """
        if abfss is not None:
            pulumi.set(__self__, "abfss", abfss)
        if dbfs is not None:
            pulumi.set(__self__, "dbfs", dbfs)
        if file is not None:
            pulumi.set(__self__, "file", file)
        if gcs is not None:
            pulumi.set(__self__, "gcs", gcs)
        if s3 is not None:
            pulumi.set(__self__, "s3", s3)
        if volumes is not None:
            pulumi.set(__self__, "volumes", volumes)
        if workspace is not None:
            pulumi.set(__self__, "workspace", workspace)

    @property
    @pulumi.getter
    def abfss(self) -> Optional['outputs.JobNewClusterInitScriptAbfss']:
        return pulumi.get(self, "abfss")

    @property
    @pulumi.getter
    @_utilities.deprecated("""For init scripts use 'volumes', 'workspace' or cloud storage location instead of 'dbfs'.""")
    def dbfs(self) -> Optional['outputs.JobNewClusterInitScriptDbfs']:
        return pulumi.get(self, "dbfs")

    @property
    @pulumi.getter
    def file(self) -> Optional['outputs.JobNewClusterInitScriptFile']:
        """
        block consisting of single string fields:
        """
        return pulumi.get(self, "file")

    @property
    @pulumi.getter
    def gcs(self) -> Optional['outputs.JobNewClusterInitScriptGcs']:
        return pulumi.get(self, "gcs")

    @property
    @pulumi.getter
    def s3(self) -> Optional['outputs.JobNewClusterInitScriptS3']:
        return pulumi.get(self, "s3")

    @property
    @pulumi.getter
    def volumes(self) -> Optional['outputs.JobNewClusterInitScriptVolumes']:
        return pulumi.get(self, "volumes")

    @property
    @pulumi.getter
    def workspace(self) -> Optional['outputs.JobNewClusterInitScriptWorkspace']:
        return pulumi.get(self, "workspace")


@pulumi.output_type
class JobNewClusterInitScriptAbfss(dict):
    def __init__(__self__, *,
                 destination: str):
        pulumi.set(__self__, "destination", destination)

    @property
    @pulumi.getter
    def destination(self) -> str:
        return pulumi.get(self, "destination")


@pulumi.output_type
class JobNewClusterInitScriptDbfs(dict):
    def __init__(__self__, *,
                 destination: str):
        pulumi.set(__self__, "destination", destination)

    @property
    @pulumi.getter
    def destination(self) -> str:
        return pulumi.get(self, "destination")


@pulumi.output_type
class JobNewClusterInitScriptFile(dict):
    def __init__(__self__, *,
                 destination: str):
        pulumi.set(__self__, "destination", destination)

    @property
    @pulumi.getter
    def destination(self) -> str:
        return pulumi.get(self, "destination")


@pulumi.output_type
class JobNewClusterInitScriptGcs(dict):
    def __init__(__self__, *,
                 destination: str):
        pulumi.set(__self__, "destination", destination)

    @property
    @pulumi.getter
    def destination(self) -> str:
        return pulumi.get(self, "destination")


@pulumi.output_type
class JobNewClusterInitScriptS3(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "cannedAcl":
            suggest = "canned_acl"
        elif key == "enableEncryption":
            suggest = "enable_encryption"
        elif key == "encryptionType":
            suggest = "encryption_type"
        elif key == "kmsKey":
            suggest = "kms_key"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in JobNewClusterInitScriptS3. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        JobNewClusterInitScriptS3.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        JobNewClusterInitScriptS3.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 destination: str,
                 canned_acl: Optional[str] = None,
                 enable_encryption: Optional[bool] = None,
                 encryption_type: Optional[str] = None,
                 endpoint: Optional[str] = None,
                 kms_key: Optional[str] = None,
                 region: Optional[str] = None):
        pulumi.set(__self__, "destination", destination)
        if canned_acl is not None:
            pulumi.set(__self__, "canned_acl", canned_acl)
        if enable_encryption is not None:
            pulumi.set(__self__, "enable_encryption", enable_encryption)
        if encryption_type is not None:
            pulumi.set(__self__, "encryption_type", encryption_type)
        if endpoint is not None:
            pulumi.set(__self__, "endpoint", endpoint)
        if kms_key is not None:
            pulumi.set(__self__, "kms_key", kms_key)
        if region is not None:
            pulumi.set(__self__, "region", region)

    @property
    @pulumi.getter
    def destination(self) -> str:
        return pulumi.get(self, "destination")

    @property
    @pulumi.getter(name="cannedAcl")
    def canned_acl(self) -> Optional[str]:
        return pulumi.get(self, "canned_acl")

    @property
    @pulumi.getter(name="enableEncryption")
    def enable_encryption(self) -> Optional[bool]:
        return pulumi.get(self, "enable_encryption")

    @property
    @pulumi.getter(name="encryptionType")
    def encryption_type(self) -> Optional[str]:
        return pulumi.get(self, "encryption_type")

    @property
    @pulumi.getter
    def endpoint(self) -> Optional[str]:
        return pulumi.get(self, "endpoint")

    @property
    @pulumi.getter(name="kmsKey")
    def kms_key(self) -> Optional[str]:
        return pulumi.get(self, "kms_key")

    @property
    @pulumi.getter
    def region(self) -> Optional[str]:
        return pulumi.get(self, "region")


@pulumi.output_type
class JobNewClusterInitScriptVolumes(dict):
    def __init__(__self__, *,
                 destination: str):
        pulumi.set(__self__, "destination", destination)

    @property
    @pulumi.getter
    def destination(self) -> str:
        return pulumi.get(self, "destination")


@pulumi.output_type
class JobNewClusterInitScriptWorkspace(dict):
    def __init__(__self__, *,
                 destination: str):
        pulumi.set(__self__, "destination", destination)

    @property
    @pulumi.getter
    def destination(self) -> str:
        return pulumi.get(self, "destination")


@pulumi.output_type
class JobNewClusterLibrary(dict):
    def __init__(__self__, *,
                 cran: Optional['outputs.JobNewClusterLibraryCran'] = None,
                 egg: Optional[str] = None,
                 jar: Optional[str] = None,
                 maven: Optional['outputs.JobNewClusterLibraryMaven'] = None,
                 pypi: Optional['outputs.JobNewClusterLibraryPypi'] = None,
                 requirements: Optional[str] = None,
                 whl: Optional[str] = None):
        if cran is not None:
            pulumi.set(__self__, "cran", cran)
        if egg is not None:
            pulumi.set(__self__, "egg", egg)
        if jar is not None:
            pulumi.set(__self__, "jar", jar)
        if maven is not None:
            pulumi.set(__self__, "maven", maven)
        if pypi is not None:
            pulumi.set(__self__, "pypi", pypi)
        if requirements is not None:
            pulumi.set(__self__, "requirements", requirements)
        if whl is not None:
            pulumi.set(__self__, "whl", whl)

    @property
    @pulumi.getter
    def cran(self) -> Optional['outputs.JobNewClusterLibraryCran']:
        return pulumi.get(self, "cran")

    @property
    @pulumi.getter
    def egg(self) -> Optional[str]:
        return pulumi.get(self, "egg")

    @property
    @pulumi.getter
    def jar(self) -> Optional[str]:
        return pulumi.get(self, "jar")

    @property
    @pulumi.getter
    def maven(self) -> Optional['outputs.JobNewClusterLibraryMaven']:
        return pulumi.get(self, "maven")

    @property
    @pulumi.getter
    def pypi(self) -> Optional['outputs.JobNewClusterLibraryPypi']:
        return pulumi.get(self, "pypi")

    @property
    @pulumi.getter
    def requirements(self) -> Optional[str]:
        return pulumi.get(self, "requirements")

    @property
    @pulumi.getter
    def whl(self) -> Optional[str]:
        return pulumi.get(self, "whl")


@pulumi.output_type
class JobNewClusterLibraryCran(dict):
    def __init__(__self__, *,
                 package: str,
                 repo: Optional[str] = None):
        pulumi.set(__self__, "package", package)
        if repo is not None:
            pulumi.set(__self__, "repo", repo)

    @property
    @pulumi.getter
    def package(self) -> str:
        return pulumi.get(self, "package")

    @property
    @pulumi.getter
    def repo(self) -> Optional[str]:
        return pulumi.get(self, "repo")


@pulumi.output_type
class JobNewClusterLibraryMaven(dict):
    def __init__(__self__, *,
                 coordinates: str,
                 exclusions: Optional[Sequence[str]] = None,
                 repo: Optional[str] = None):
        pulumi.set(__self__, "coordinates", coordinates)
        if exclusions is not None:
            pulumi.set(__self__, "exclusions", exclusions)
        if repo is not None:
            pulumi.set(__self__, "repo", repo)

    @property
    @pulumi.getter
    def coordinates(self) -> str:
        return pulumi.get(self, "coordinates")

    @property
    @pulumi.getter
    def exclusions(self) -> Optional[Sequence[str]]:
        return pulumi.get(self, "exclusions")

    @property
    @pulumi.getter
    def repo(self) -> Optional[str]:
        return pulumi.get(self, "repo")


@pulumi.output_type
class JobNewClusterLibraryPypi(dict):
    def __init__(__self__, *,
                 package: str,
                 repo: Optional[str] = None):
        pulumi.set(__self__, "package", package)
        if repo is not None:
            pulumi.set(__self__, "repo", repo)

    @property
    @pulumi.getter
    def package(self) -> str:
        return pulumi.get(self, "package")

    @property
    @pulumi.getter
    def repo(self) -> Optional[str]:
        return pulumi.get(self, "repo")


@pulumi.output_type
class JobNewClusterWorkloadType(dict):
    def __init__(__self__, *,
                 clients: 'outputs.JobNewClusterWorkloadTypeClients'):
        pulumi.set(__self__, "clients", clients)

    @property
    @pulumi.getter
    def clients(self) -> 'outputs.JobNewClusterWorkloadTypeClients':
        return pulumi.get(self, "clients")


@pulumi.output_type
class JobNewClusterWorkloadTypeClients(dict):
    def __init__(__self__, *,
                 jobs: Optional[bool] = None,
                 notebooks: Optional[bool] = None):
        if jobs is not None:
            pulumi.set(__self__, "jobs", jobs)
        if notebooks is not None:
            pulumi.set(__self__, "notebooks", notebooks)

    @property
    @pulumi.getter
    def jobs(self) -> Optional[bool]:
        return pulumi.get(self, "jobs")

    @property
    @pulumi.getter
    def notebooks(self) -> Optional[bool]:
        return pulumi.get(self, "notebooks")


@pulumi.output_type
class JobNotebookTask(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "notebookPath":
            suggest = "notebook_path"
        elif key == "baseParameters":
            suggest = "base_parameters"
        elif key == "warehouseId":
            suggest = "warehouse_id"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in JobNotebookTask. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        JobNotebookTask.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        JobNotebookTask.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 notebook_path: str,
                 base_parameters: Optional[Mapping[str, str]] = None,
                 source: Optional[str] = None,
                 warehouse_id: Optional[str] = None):
        """
        :param str notebook_path: The path of the Notebook to be run in the Databricks workspace or remote repository. For notebooks stored in the Databricks workspace, the path must be absolute and begin with a slash. For notebooks stored in a remote repository, the path must be relative. This field is required.
        :param Mapping[str, str] base_parameters: (Map) Base parameters to be used for each run of this job. If the run is initiated by a call to run-now with parameters specified, the two parameters maps will be merged. If the same key is specified in base_parameters and in run-now, the value from run-now will be used. If the notebook takes a parameter that is not specified in the jobs base_parameters or the run-now override parameters, the default value from the notebook will be used. Retrieve these parameters in a notebook using `dbutils.widgets.get`.
        :param str source: Location type of the notebook, can only be `WORKSPACE` or `GIT`. When set to `WORKSPACE`, the notebook will be retrieved from the local Databricks workspace. When set to `GIT`, the notebook will be retrieved from a Git repository defined in `git_source`. If the value is empty, the task will use `GIT` if `git_source` is defined and `WORKSPACE` otherwise.
        :param str warehouse_id: ID of the (the databricks_sql_endpoint) that will be used to execute the task with SQL notebook.
        """
        pulumi.set(__self__, "notebook_path", notebook_path)
        if base_parameters is not None:
            pulumi.set(__self__, "base_parameters", base_parameters)
        if source is not None:
            pulumi.set(__self__, "source", source)
        if warehouse_id is not None:
            pulumi.set(__self__, "warehouse_id", warehouse_id)

    @property
    @pulumi.getter(name="notebookPath")
    def notebook_path(self) -> str:
        """
        The path of the Notebook to be run in the Databricks workspace or remote repository. For notebooks stored in the Databricks workspace, the path must be absolute and begin with a slash. For notebooks stored in a remote repository, the path must be relative. This field is required.
        """
        return pulumi.get(self, "notebook_path")

    @property
    @pulumi.getter(name="baseParameters")
    def base_parameters(self) -> Optional[Mapping[str, str]]:
        """
        (Map) Base parameters to be used for each run of this job. If the run is initiated by a call to run-now with parameters specified, the two parameters maps will be merged. If the same key is specified in base_parameters and in run-now, the value from run-now will be used. If the notebook takes a parameter that is not specified in the jobs base_parameters or the run-now override parameters, the default value from the notebook will be used. Retrieve these parameters in a notebook using `dbutils.widgets.get`.
        """
        return pulumi.get(self, "base_parameters")

    @property
    @pulumi.getter
    def source(self) -> Optional[str]:
        """
        Location type of the notebook, can only be `WORKSPACE` or `GIT`. When set to `WORKSPACE`, the notebook will be retrieved from the local Databricks workspace. When set to `GIT`, the notebook will be retrieved from a Git repository defined in `git_source`. If the value is empty, the task will use `GIT` if `git_source` is defined and `WORKSPACE` otherwise.
        """
        return pulumi.get(self, "source")

    @property
    @pulumi.getter(name="warehouseId")
    def warehouse_id(self) -> Optional[str]:
        """
        ID of the (the databricks_sql_endpoint) that will be used to execute the task with SQL notebook.
        """
        return pulumi.get(self, "warehouse_id")


@pulumi.output_type
class JobNotificationSettings(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "noAlertForCanceledRuns":
            suggest = "no_alert_for_canceled_runs"
        elif key == "noAlertForSkippedRuns":
            suggest = "no_alert_for_skipped_runs"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in JobNotificationSettings. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        JobNotificationSettings.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        JobNotificationSettings.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 no_alert_for_canceled_runs: Optional[bool] = None,
                 no_alert_for_skipped_runs: Optional[bool] = None):
        """
        :param bool no_alert_for_canceled_runs: (Bool) don't send alert for cancelled runs.
               
               The following parameter is only available on task level.
        :param bool no_alert_for_skipped_runs: (Bool) don't send alert for skipped runs.
        """
        if no_alert_for_canceled_runs is not None:
            pulumi.set(__self__, "no_alert_for_canceled_runs", no_alert_for_canceled_runs)
        if no_alert_for_skipped_runs is not None:
            pulumi.set(__self__, "no_alert_for_skipped_runs", no_alert_for_skipped_runs)

    @property
    @pulumi.getter(name="noAlertForCanceledRuns")
    def no_alert_for_canceled_runs(self) -> Optional[bool]:
        """
        (Bool) don't send alert for cancelled runs.

        The following parameter is only available on task level.
        """
        return pulumi.get(self, "no_alert_for_canceled_runs")

    @property
    @pulumi.getter(name="noAlertForSkippedRuns")
    def no_alert_for_skipped_runs(self) -> Optional[bool]:
        """
        (Bool) don't send alert for skipped runs.
        """
        return pulumi.get(self, "no_alert_for_skipped_runs")


@pulumi.output_type
class JobParameter(dict):
    def __init__(__self__, *,
                 default: str,
                 name: str):
        """
        :param str default: Default value of the parameter.
               
               *You can use this block only together with `task` blocks, not with the legacy tasks specification!*
        :param str name: The name of the defined parameter. May only contain alphanumeric characters, `_`, `-`, and `.`.
        """
        pulumi.set(__self__, "default", default)
        pulumi.set(__self__, "name", name)

    @property
    @pulumi.getter
    def default(self) -> str:
        """
        Default value of the parameter.

        *You can use this block only together with `task` blocks, not with the legacy tasks specification!*
        """
        return pulumi.get(self, "default")

    @property
    @pulumi.getter
    def name(self) -> str:
        """
        The name of the defined parameter. May only contain alphanumeric characters, `_`, `-`, and `.`.
        """
        return pulumi.get(self, "name")


@pulumi.output_type
class JobPipelineTask(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "pipelineId":
            suggest = "pipeline_id"
        elif key == "fullRefresh":
            suggest = "full_refresh"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in JobPipelineTask. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        JobPipelineTask.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        JobPipelineTask.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 pipeline_id: str,
                 full_refresh: Optional[bool] = None):
        """
        :param str pipeline_id: The pipeline's unique ID.
        :param bool full_refresh: (Bool) Specifies if there should be full refresh of the pipeline.
               
               > **Note** The following configuration blocks are only supported inside a `task` block
        """
        pulumi.set(__self__, "pipeline_id", pipeline_id)
        if full_refresh is not None:
            pulumi.set(__self__, "full_refresh", full_refresh)

    @property
    @pulumi.getter(name="pipelineId")
    def pipeline_id(self) -> str:
        """
        The pipeline's unique ID.
        """
        return pulumi.get(self, "pipeline_id")

    @property
    @pulumi.getter(name="fullRefresh")
    def full_refresh(self) -> Optional[bool]:
        """
        (Bool) Specifies if there should be full refresh of the pipeline.

        > **Note** The following configuration blocks are only supported inside a `task` block
        """
        return pulumi.get(self, "full_refresh")


@pulumi.output_type
class JobPythonWheelTask(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "entryPoint":
            suggest = "entry_point"
        elif key == "namedParameters":
            suggest = "named_parameters"
        elif key == "packageName":
            suggest = "package_name"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in JobPythonWheelTask. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        JobPythonWheelTask.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        JobPythonWheelTask.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 entry_point: Optional[str] = None,
                 named_parameters: Optional[Mapping[str, str]] = None,
                 package_name: Optional[str] = None,
                 parameters: Optional[Sequence[str]] = None):
        """
        :param str entry_point: Python function as entry point for the task
        :param Mapping[str, str] named_parameters: Named parameters for the task
        :param str package_name: Name of Python package
        :param Sequence[str] parameters: Parameters for the task
        """
        if entry_point is not None:
            pulumi.set(__self__, "entry_point", entry_point)
        if named_parameters is not None:
            pulumi.set(__self__, "named_parameters", named_parameters)
        if package_name is not None:
            pulumi.set(__self__, "package_name", package_name)
        if parameters is not None:
            pulumi.set(__self__, "parameters", parameters)

    @property
    @pulumi.getter(name="entryPoint")
    def entry_point(self) -> Optional[str]:
        """
        Python function as entry point for the task
        """
        return pulumi.get(self, "entry_point")

    @property
    @pulumi.getter(name="namedParameters")
    def named_parameters(self) -> Optional[Mapping[str, str]]:
        """
        Named parameters for the task
        """
        return pulumi.get(self, "named_parameters")

    @property
    @pulumi.getter(name="packageName")
    def package_name(self) -> Optional[str]:
        """
        Name of Python package
        """
        return pulumi.get(self, "package_name")

    @property
    @pulumi.getter
    def parameters(self) -> Optional[Sequence[str]]:
        """
        Parameters for the task
        """
        return pulumi.get(self, "parameters")


@pulumi.output_type
class JobQueue(dict):
    def __init__(__self__, *,
                 enabled: bool):
        """
        :param bool enabled: If true, enable queueing for the job.
        """
        pulumi.set(__self__, "enabled", enabled)

    @property
    @pulumi.getter
    def enabled(self) -> bool:
        """
        If true, enable queueing for the job.
        """
        return pulumi.get(self, "enabled")


@pulumi.output_type
class JobRunAs(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "servicePrincipalName":
            suggest = "service_principal_name"
        elif key == "userName":
            suggest = "user_name"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in JobRunAs. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        JobRunAs.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        JobRunAs.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 service_principal_name: Optional[str] = None,
                 user_name: Optional[str] = None):
        """
        :param str service_principal_name: The application ID of an active service principal. Setting this field requires the `servicePrincipal/user` role.
               
               Example:
               
               ```python
               import pulumi
               import pulumi_databricks as databricks
               
               this = databricks.Job("this", run_as={
                   "service_principal_name": "8d23ae77-912e-4a19-81e4-b9c3f5cc9349",
               })
               ```
        :param str user_name: The email of an active workspace user. Non-admin users can only set this field to their own email.
        """
        if service_principal_name is not None:
            pulumi.set(__self__, "service_principal_name", service_principal_name)
        if user_name is not None:
            pulumi.set(__self__, "user_name", user_name)

    @property
    @pulumi.getter(name="servicePrincipalName")
    def service_principal_name(self) -> Optional[str]:
        """
        The application ID of an active service principal. Setting this field requires the `servicePrincipal/user` role.

        Example:

        ```python
        import pulumi
        import pulumi_databricks as databricks

        this = databricks.Job("this", run_as={
            "service_principal_name": "8d23ae77-912e-4a19-81e4-b9c3f5cc9349",
        })
        ```
        """
        return pulumi.get(self, "service_principal_name")

    @property
    @pulumi.getter(name="userName")
    def user_name(self) -> Optional[str]:
        """
        The email of an active workspace user. Non-admin users can only set this field to their own email.
        """
        return pulumi.get(self, "user_name")


@pulumi.output_type
class JobRunJobTask(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "jobId":
            suggest = "job_id"
        elif key == "jobParameters":
            suggest = "job_parameters"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in JobRunJobTask. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        JobRunJobTask.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        JobRunJobTask.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 job_id: int,
                 job_parameters: Optional[Mapping[str, str]] = None):
        """
        :param int job_id: (String) ID of the job
        :param Mapping[str, str] job_parameters: (Map) Job parameters for the task
        """
        pulumi.set(__self__, "job_id", job_id)
        if job_parameters is not None:
            pulumi.set(__self__, "job_parameters", job_parameters)

    @property
    @pulumi.getter(name="jobId")
    def job_id(self) -> int:
        """
        (String) ID of the job
        """
        return pulumi.get(self, "job_id")

    @property
    @pulumi.getter(name="jobParameters")
    def job_parameters(self) -> Optional[Mapping[str, str]]:
        """
        (Map) Job parameters for the task
        """
        return pulumi.get(self, "job_parameters")


@pulumi.output_type
class JobSchedule(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "quartzCronExpression":
            suggest = "quartz_cron_expression"
        elif key == "timezoneId":
            suggest = "timezone_id"
        elif key == "pauseStatus":
            suggest = "pause_status"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in JobSchedule. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        JobSchedule.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        JobSchedule.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 quartz_cron_expression: str,
                 timezone_id: str,
                 pause_status: Optional[str] = None):
        """
        :param str quartz_cron_expression: A [Cron expression using Quartz syntax](http://www.quartz-scheduler.org/documentation/quartz-2.3.0/tutorials/crontrigger.html) that describes the schedule for a job. This field is required.
        :param str timezone_id: A Java timezone ID. The schedule for a job will be resolved with respect to this timezone. See Java TimeZone for details. This field is required.
        :param str pause_status: Indicate whether this schedule is paused or not. Either `PAUSED` or `UNPAUSED`. When the `pause_status` field is omitted and a schedule is provided, the server will default to using `UNPAUSED` as a value for `pause_status`.
        """
        pulumi.set(__self__, "quartz_cron_expression", quartz_cron_expression)
        pulumi.set(__self__, "timezone_id", timezone_id)
        if pause_status is not None:
            pulumi.set(__self__, "pause_status", pause_status)

    @property
    @pulumi.getter(name="quartzCronExpression")
    def quartz_cron_expression(self) -> str:
        """
        A [Cron expression using Quartz syntax](http://www.quartz-scheduler.org/documentation/quartz-2.3.0/tutorials/crontrigger.html) that describes the schedule for a job. This field is required.
        """
        return pulumi.get(self, "quartz_cron_expression")

    @property
    @pulumi.getter(name="timezoneId")
    def timezone_id(self) -> str:
        """
        A Java timezone ID. The schedule for a job will be resolved with respect to this timezone. See Java TimeZone for details. This field is required.
        """
        return pulumi.get(self, "timezone_id")

    @property
    @pulumi.getter(name="pauseStatus")
    def pause_status(self) -> Optional[str]:
        """
        Indicate whether this schedule is paused or not. Either `PAUSED` or `UNPAUSED`. When the `pause_status` field is omitted and a schedule is provided, the server will default to using `UNPAUSED` as a value for `pause_status`.
        """
        return pulumi.get(self, "pause_status")


@pulumi.output_type
class JobSparkJarTask(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "jarUri":
            suggest = "jar_uri"
        elif key == "mainClassName":
            suggest = "main_class_name"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in JobSparkJarTask. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        JobSparkJarTask.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        JobSparkJarTask.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 jar_uri: Optional[str] = None,
                 main_class_name: Optional[str] = None,
                 parameters: Optional[Sequence[str]] = None):
        """
        :param str main_class_name: The full name of the class containing the main method to be executed. This class must be contained in a JAR provided as a library. The code should use `SparkContext.getOrCreate` to obtain a Spark context; otherwise, runs of the job will fail.
        :param Sequence[str] parameters: (List) Parameters passed to the main method.
        """
        if jar_uri is not None:
            pulumi.set(__self__, "jar_uri", jar_uri)
        if main_class_name is not None:
            pulumi.set(__self__, "main_class_name", main_class_name)
        if parameters is not None:
            pulumi.set(__self__, "parameters", parameters)

    @property
    @pulumi.getter(name="jarUri")
    def jar_uri(self) -> Optional[str]:
        return pulumi.get(self, "jar_uri")

    @property
    @pulumi.getter(name="mainClassName")
    def main_class_name(self) -> Optional[str]:
        """
        The full name of the class containing the main method to be executed. This class must be contained in a JAR provided as a library. The code should use `SparkContext.getOrCreate` to obtain a Spark context; otherwise, runs of the job will fail.
        """
        return pulumi.get(self, "main_class_name")

    @property
    @pulumi.getter
    def parameters(self) -> Optional[Sequence[str]]:
        """
        (List) Parameters passed to the main method.
        """
        return pulumi.get(self, "parameters")


@pulumi.output_type
class JobSparkPythonTask(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "pythonFile":
            suggest = "python_file"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in JobSparkPythonTask. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        JobSparkPythonTask.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        JobSparkPythonTask.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 python_file: str,
                 parameters: Optional[Sequence[str]] = None,
                 source: Optional[str] = None):
        """
        :param str python_file: The URI of the Python file to be executed. databricks_dbfs_file, cloud file URIs (e.g. `s3:/`, `abfss:/`, `gs:/`), workspace paths and remote repository are supported. For Python files stored in the Databricks workspace, the path must be absolute and begin with `/Repos`. For files stored in a remote repository, the path must be relative. This field is required.
        :param Sequence[str] parameters: (List) Command line parameters passed to the Python file.
        :param str source: Location type of the Python file, can only be `GIT`. When set to `GIT`, the Python file will be retrieved from a Git repository defined in `git_source`.
        """
        pulumi.set(__self__, "python_file", python_file)
        if parameters is not None:
            pulumi.set(__self__, "parameters", parameters)
        if source is not None:
            pulumi.set(__self__, "source", source)

    @property
    @pulumi.getter(name="pythonFile")
    def python_file(self) -> str:
        """
        The URI of the Python file to be executed. databricks_dbfs_file, cloud file URIs (e.g. `s3:/`, `abfss:/`, `gs:/`), workspace paths and remote repository are supported. For Python files stored in the Databricks workspace, the path must be absolute and begin with `/Repos`. For files stored in a remote repository, the path must be relative. This field is required.
        """
        return pulumi.get(self, "python_file")

    @property
    @pulumi.getter
    def parameters(self) -> Optional[Sequence[str]]:
        """
        (List) Command line parameters passed to the Python file.
        """
        return pulumi.get(self, "parameters")

    @property
    @pulumi.getter
    def source(self) -> Optional[str]:
        """
        Location type of the Python file, can only be `GIT`. When set to `GIT`, the Python file will be retrieved from a Git repository defined in `git_source`.
        """
        return pulumi.get(self, "source")


@pulumi.output_type
class JobSparkSubmitTask(dict):
    def __init__(__self__, *,
                 parameters: Optional[Sequence[str]] = None):
        """
        :param Sequence[str] parameters: (List) Command-line parameters passed to spark submit.
        """
        if parameters is not None:
            pulumi.set(__self__, "parameters", parameters)

    @property
    @pulumi.getter
    def parameters(self) -> Optional[Sequence[str]]:
        """
        (List) Command-line parameters passed to spark submit.
        """
        return pulumi.get(self, "parameters")


@pulumi.output_type
class JobTask(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "taskKey":
            suggest = "task_key"
        elif key == "conditionTask":
            suggest = "condition_task"
        elif key == "dbtTask":
            suggest = "dbt_task"
        elif key == "dependsOns":
            suggest = "depends_ons"
        elif key == "disableAutoOptimization":
            suggest = "disable_auto_optimization"
        elif key == "emailNotifications":
            suggest = "email_notifications"
        elif key == "environmentKey":
            suggest = "environment_key"
        elif key == "existingClusterId":
            suggest = "existing_cluster_id"
        elif key == "forEachTask":
            suggest = "for_each_task"
        elif key == "jobClusterKey":
            suggest = "job_cluster_key"
        elif key == "maxRetries":
            suggest = "max_retries"
        elif key == "minRetryIntervalMillis":
            suggest = "min_retry_interval_millis"
        elif key == "newCluster":
            suggest = "new_cluster"
        elif key == "notebookTask":
            suggest = "notebook_task"
        elif key == "notificationSettings":
            suggest = "notification_settings"
        elif key == "pipelineTask":
            suggest = "pipeline_task"
        elif key == "pythonWheelTask":
            suggest = "python_wheel_task"
        elif key == "retryOnTimeout":
            suggest = "retry_on_timeout"
        elif key == "runIf":
            suggest = "run_if"
        elif key == "runJobTask":
            suggest = "run_job_task"
        elif key == "sparkJarTask":
            suggest = "spark_jar_task"
        elif key == "sparkPythonTask":
            suggest = "spark_python_task"
        elif key == "sparkSubmitTask":
            suggest = "spark_submit_task"
        elif key == "sqlTask":
            suggest = "sql_task"
        elif key == "timeoutSeconds":
            suggest = "timeout_seconds"
        elif key == "webhookNotifications":
            suggest = "webhook_notifications"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in JobTask. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        JobTask.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        JobTask.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 task_key: str,
                 condition_task: Optional['outputs.JobTaskConditionTask'] = None,
                 dbt_task: Optional['outputs.JobTaskDbtTask'] = None,
                 depends_ons: Optional[Sequence['outputs.JobTaskDependsOn']] = None,
                 description: Optional[str] = None,
                 disable_auto_optimization: Optional[bool] = None,
                 email_notifications: Optional['outputs.JobTaskEmailNotifications'] = None,
                 environment_key: Optional[str] = None,
                 existing_cluster_id: Optional[str] = None,
                 for_each_task: Optional['outputs.JobTaskForEachTask'] = None,
                 health: Optional['outputs.JobTaskHealth'] = None,
                 job_cluster_key: Optional[str] = None,
                 libraries: Optional[Sequence['outputs.JobTaskLibrary']] = None,
                 max_retries: Optional[int] = None,
                 min_retry_interval_millis: Optional[int] = None,
                 new_cluster: Optional['outputs.JobTaskNewCluster'] = None,
                 notebook_task: Optional['outputs.JobTaskNotebookTask'] = None,
                 notification_settings: Optional['outputs.JobTaskNotificationSettings'] = None,
                 pipeline_task: Optional['outputs.JobTaskPipelineTask'] = None,
                 python_wheel_task: Optional['outputs.JobTaskPythonWheelTask'] = None,
                 retry_on_timeout: Optional[bool] = None,
                 run_if: Optional[str] = None,
                 run_job_task: Optional['outputs.JobTaskRunJobTask'] = None,
                 spark_jar_task: Optional['outputs.JobTaskSparkJarTask'] = None,
                 spark_python_task: Optional['outputs.JobTaskSparkPythonTask'] = None,
                 spark_submit_task: Optional['outputs.JobTaskSparkSubmitTask'] = None,
                 sql_task: Optional['outputs.JobTaskSqlTask'] = None,
                 timeout_seconds: Optional[int] = None,
                 webhook_notifications: Optional['outputs.JobTaskWebhookNotifications'] = None):
        """
        :param str task_key: string specifying an unique key for a given task.
               * `*_task` - (Required) one of the specific task blocks described below:
        :param Sequence['JobTaskDependsOnArgs'] depends_ons: block specifying dependency(-ies) for a given task.
        :param str description: description for this task.
        :param bool disable_auto_optimization: A flag to disable auto optimization in serverless tasks.
        :param 'JobTaskEmailNotificationsArgs' email_notifications: An optional block to specify a set of email addresses notified when this task begins, completes or fails. The default behavior is to not send any emails. This block is documented below.
        :param str environment_key: identifier of an `environment` block that is used to specify libraries.  Required for some tasks (`spark_python_task`, `python_wheel_task`, ...) running on serverless compute.
        :param str existing_cluster_id: Identifier of the interactive cluster to run job on.  *Note: running tasks on interactive clusters may lead to increased costs!*
        :param 'JobTaskHealthArgs' health: block described below that specifies health conditions for a given task.
        :param str job_cluster_key: Identifier of the Job cluster specified in the `job_cluster` block.
        :param Sequence['JobTaskLibraryArgs'] libraries: (Set) An optional list of libraries to be installed on the cluster that will execute the job.
        :param int max_retries: (Integer) An optional maximum number of times to retry an unsuccessful run. A run is considered to be unsuccessful if it completes with a `FAILED` or `INTERNAL_ERROR` lifecycle state. The value -1 means to retry indefinitely and the value 0 means to never retry. The default behavior is to never retry. A run can have the following lifecycle state: `PENDING`, `RUNNING`, `TERMINATING`, `TERMINATED`, `SKIPPED` or `INTERNAL_ERROR`.
        :param int min_retry_interval_millis: (Integer) An optional minimal interval in milliseconds between the start of the failed run and the subsequent retry run. The default behavior is that unsuccessful runs are immediately retried.
        :param 'JobTaskNewClusterArgs' new_cluster: Task will run on a dedicated cluster.  See Cluster documentation for specification. *Some parameters, such as `autotermination_minutes`, `is_pinned`, `workload_type` aren't supported!*
        :param 'JobTaskNotificationSettingsArgs' notification_settings: An optional block controlling the notification settings on the job level documented below.
        :param bool retry_on_timeout: (Bool) An optional policy to specify whether to retry a job when it times out. The default behavior is to not retry on timeout.
        :param str run_if: An optional value indicating the condition that determines whether the task should be run once its dependencies have been completed. One of `ALL_SUCCESS`, `AT_LEAST_ONE_SUCCESS`, `NONE_FAILED`, `ALL_DONE`, `AT_LEAST_ONE_FAILED` or `ALL_FAILED`. When omitted, defaults to `ALL_SUCCESS`.
        :param int timeout_seconds: (Integer) An optional timeout applied to each run of this job. The default behavior is to have no timeout.
        :param 'JobTaskWebhookNotificationsArgs' webhook_notifications: (List) An optional set of system destinations (for example, webhook destinations or Slack) to be notified when runs of this task begins, completes or fails. The default behavior is to not send any notifications. This field is a block and is documented below.
               
               > **Note** If no `job_cluster_key`, `existing_cluster_id`, or `new_cluster` were specified in task definition, then task will executed using serverless compute.
        """
        pulumi.set(__self__, "task_key", task_key)
        if condition_task is not None:
            pulumi.set(__self__, "condition_task", condition_task)
        if dbt_task is not None:
            pulumi.set(__self__, "dbt_task", dbt_task)
        if depends_ons is not None:
            pulumi.set(__self__, "depends_ons", depends_ons)
        if description is not None:
            pulumi.set(__self__, "description", description)
        if disable_auto_optimization is not None:
            pulumi.set(__self__, "disable_auto_optimization", disable_auto_optimization)
        if email_notifications is not None:
            pulumi.set(__self__, "email_notifications", email_notifications)
        if environment_key is not None:
            pulumi.set(__self__, "environment_key", environment_key)
        if existing_cluster_id is not None:
            pulumi.set(__self__, "existing_cluster_id", existing_cluster_id)
        if for_each_task is not None:
            pulumi.set(__self__, "for_each_task", for_each_task)
        if health is not None:
            pulumi.set(__self__, "health", health)
        if job_cluster_key is not None:
            pulumi.set(__self__, "job_cluster_key", job_cluster_key)
        if libraries is not None:
            pulumi.set(__self__, "libraries", libraries)
        if max_retries is not None:
            pulumi.set(__self__, "max_retries", max_retries)
        if min_retry_interval_millis is not None:
            pulumi.set(__self__, "min_retry_interval_millis", min_retry_interval_millis)
        if new_cluster is not None:
            pulumi.set(__self__, "new_cluster", new_cluster)
        if notebook_task is not None:
            pulumi.set(__self__, "notebook_task", notebook_task)
        if notification_settings is not None:
            pulumi.set(__self__, "notification_settings", notification_settings)
        if pipeline_task is not None:
            pulumi.set(__self__, "pipeline_task", pipeline_task)
        if python_wheel_task is not None:
            pulumi.set(__self__, "python_wheel_task", python_wheel_task)
        if retry_on_timeout is not None:
            pulumi.set(__self__, "retry_on_timeout", retry_on_timeout)
        if run_if is not None:
            pulumi.set(__self__, "run_if", run_if)
        if run_job_task is not None:
            pulumi.set(__self__, "run_job_task", run_job_task)
        if spark_jar_task is not None:
            pulumi.set(__self__, "spark_jar_task", spark_jar_task)
        if spark_python_task is not None:
            pulumi.set(__self__, "spark_python_task", spark_python_task)
        if spark_submit_task is not None:
            pulumi.set(__self__, "spark_submit_task", spark_submit_task)
        if sql_task is not None:
            pulumi.set(__self__, "sql_task", sql_task)
        if timeout_seconds is not None:
            pulumi.set(__self__, "timeout_seconds", timeout_seconds)
        if webhook_notifications is not None:
            pulumi.set(__self__, "webhook_notifications", webhook_notifications)

    @property
    @pulumi.getter(name="taskKey")
    def task_key(self) -> str:
        """
        string specifying an unique key for a given task.
        * `*_task` - (Required) one of the specific task blocks described below:
        """
        return pulumi.get(self, "task_key")

    @property
    @pulumi.getter(name="conditionTask")
    def condition_task(self) -> Optional['outputs.JobTaskConditionTask']:
        return pulumi.get(self, "condition_task")

    @property
    @pulumi.getter(name="dbtTask")
    def dbt_task(self) -> Optional['outputs.JobTaskDbtTask']:
        return pulumi.get(self, "dbt_task")

    @property
    @pulumi.getter(name="dependsOns")
    def depends_ons(self) -> Optional[Sequence['outputs.JobTaskDependsOn']]:
        """
        block specifying dependency(-ies) for a given task.
        """
        return pulumi.get(self, "depends_ons")

    @property
    @pulumi.getter
    def description(self) -> Optional[str]:
        """
        description for this task.
        """
        return pulumi.get(self, "description")

    @property
    @pulumi.getter(name="disableAutoOptimization")
    def disable_auto_optimization(self) -> Optional[bool]:
        """
        A flag to disable auto optimization in serverless tasks.
        """
        return pulumi.get(self, "disable_auto_optimization")

    @property
    @pulumi.getter(name="emailNotifications")
    def email_notifications(self) -> Optional['outputs.JobTaskEmailNotifications']:
        """
        An optional block to specify a set of email addresses notified when this task begins, completes or fails. The default behavior is to not send any emails. This block is documented below.
        """
        return pulumi.get(self, "email_notifications")

    @property
    @pulumi.getter(name="environmentKey")
    def environment_key(self) -> Optional[str]:
        """
        identifier of an `environment` block that is used to specify libraries.  Required for some tasks (`spark_python_task`, `python_wheel_task`, ...) running on serverless compute.
        """
        return pulumi.get(self, "environment_key")

    @property
    @pulumi.getter(name="existingClusterId")
    def existing_cluster_id(self) -> Optional[str]:
        """
        Identifier of the interactive cluster to run job on.  *Note: running tasks on interactive clusters may lead to increased costs!*
        """
        return pulumi.get(self, "existing_cluster_id")

    @property
    @pulumi.getter(name="forEachTask")
    def for_each_task(self) -> Optional['outputs.JobTaskForEachTask']:
        return pulumi.get(self, "for_each_task")

    @property
    @pulumi.getter
    def health(self) -> Optional['outputs.JobTaskHealth']:
        """
        block described below that specifies health conditions for a given task.
        """
        return pulumi.get(self, "health")

    @property
    @pulumi.getter(name="jobClusterKey")
    def job_cluster_key(self) -> Optional[str]:
        """
        Identifier of the Job cluster specified in the `job_cluster` block.
        """
        return pulumi.get(self, "job_cluster_key")

    @property
    @pulumi.getter
    def libraries(self) -> Optional[Sequence['outputs.JobTaskLibrary']]:
        """
        (Set) An optional list of libraries to be installed on the cluster that will execute the job.
        """
        return pulumi.get(self, "libraries")

    @property
    @pulumi.getter(name="maxRetries")
    def max_retries(self) -> Optional[int]:
        """
        (Integer) An optional maximum number of times to retry an unsuccessful run. A run is considered to be unsuccessful if it completes with a `FAILED` or `INTERNAL_ERROR` lifecycle state. The value -1 means to retry indefinitely and the value 0 means to never retry. The default behavior is to never retry. A run can have the following lifecycle state: `PENDING`, `RUNNING`, `TERMINATING`, `TERMINATED`, `SKIPPED` or `INTERNAL_ERROR`.
        """
        return pulumi.get(self, "max_retries")

    @property
    @pulumi.getter(name="minRetryIntervalMillis")
    def min_retry_interval_millis(self) -> Optional[int]:
        """
        (Integer) An optional minimal interval in milliseconds between the start of the failed run and the subsequent retry run. The default behavior is that unsuccessful runs are immediately retried.
        """
        return pulumi.get(self, "min_retry_interval_millis")

    @property
    @pulumi.getter(name="newCluster")
    def new_cluster(self) -> Optional['outputs.JobTaskNewCluster']:
        """
        Task will run on a dedicated cluster.  See Cluster documentation for specification. *Some parameters, such as `autotermination_minutes`, `is_pinned`, `workload_type` aren't supported!*
        """
        return pulumi.get(self, "new_cluster")

    @property
    @pulumi.getter(name="notebookTask")
    def notebook_task(self) -> Optional['outputs.JobTaskNotebookTask']:
        return pulumi.get(self, "notebook_task")

    @property
    @pulumi.getter(name="notificationSettings")
    def notification_settings(self) -> Optional['outputs.JobTaskNotificationSettings']:
        """
        An optional block controlling the notification settings on the job level documented below.
        """
        return pulumi.get(self, "notification_settings")

    @property
    @pulumi.getter(name="pipelineTask")
    def pipeline_task(self) -> Optional['outputs.JobTaskPipelineTask']:
        return pulumi.get(self, "pipeline_task")

    @property
    @pulumi.getter(name="pythonWheelTask")
    def python_wheel_task(self) -> Optional['outputs.JobTaskPythonWheelTask']:
        return pulumi.get(self, "python_wheel_task")

    @property
    @pulumi.getter(name="retryOnTimeout")
    def retry_on_timeout(self) -> Optional[bool]:
        """
        (Bool) An optional policy to specify whether to retry a job when it times out. The default behavior is to not retry on timeout.
        """
        return pulumi.get(self, "retry_on_timeout")

    @property
    @pulumi.getter(name="runIf")
    def run_if(self) -> Optional[str]:
        """
        An optional value indicating the condition that determines whether the task should be run once its dependencies have been completed. One of `ALL_SUCCESS`, `AT_LEAST_ONE_SUCCESS`, `NONE_FAILED`, `ALL_DONE`, `AT_LEAST_ONE_FAILED` or `ALL_FAILED`. When omitted, defaults to `ALL_SUCCESS`.
        """
        return pulumi.get(self, "run_if")

    @property
    @pulumi.getter(name="runJobTask")
    def run_job_task(self) -> Optional['outputs.JobTaskRunJobTask']:
        return pulumi.get(self, "run_job_task")

    @property
    @pulumi.getter(name="sparkJarTask")
    def spark_jar_task(self) -> Optional['outputs.JobTaskSparkJarTask']:
        return pulumi.get(self, "spark_jar_task")

    @property
    @pulumi.getter(name="sparkPythonTask")
    def spark_python_task(self) -> Optional['outputs.JobTaskSparkPythonTask']:
        return pulumi.get(self, "spark_python_task")

    @property
    @pulumi.getter(name="sparkSubmitTask")
    def spark_submit_task(self) -> Optional['outputs.JobTaskSparkSubmitTask']:
        return pulumi.get(self, "spark_submit_task")

    @property
    @pulumi.getter(name="sqlTask")
    def sql_task(self) -> Optional['outputs.JobTaskSqlTask']:
        return pulumi.get(self, "sql_task")

    @property
    @pulumi.getter(name="timeoutSeconds")
    def timeout_seconds(self) -> Optional[int]:
        """
        (Integer) An optional timeout applied to each run of this job. The default behavior is to have no timeout.
        """
        return pulumi.get(self, "timeout_seconds")

    @property
    @pulumi.getter(name="webhookNotifications")
    def webhook_notifications(self) -> Optional['outputs.JobTaskWebhookNotifications']:
        """
        (List) An optional set of system destinations (for example, webhook destinations or Slack) to be notified when runs of this task begins, completes or fails. The default behavior is to not send any notifications. This field is a block and is documented below.

        > **Note** If no `job_cluster_key`, `existing_cluster_id`, or `new_cluster` were specified in task definition, then task will executed using serverless compute.
        """
        return pulumi.get(self, "webhook_notifications")


@pulumi.output_type
class JobTaskConditionTask(dict):
    def __init__(__self__, *,
                 left: str,
                 op: str,
                 right: str):
        """
        :param str left: The left operand of the condition task. It could be a string value, job state, or a parameter reference.
        :param str op: The string specifying the operation used to compare operands.  Currently, following operators are supported: `EQUAL_TO`, `GREATER_THAN`, `GREATER_THAN_OR_EQUAL`, `LESS_THAN`, `LESS_THAN_OR_EQUAL`, `NOT_EQUAL`. (Check the [API docs](https://docs.databricks.com/api/workspace/jobs/create) for the latest information).
               
               This task does not require a cluster to execute and does not support retries or notifications.
        :param str right: The right operand of the condition task. It could be a string value, job state, or parameter reference.
        """
        pulumi.set(__self__, "left", left)
        pulumi.set(__self__, "op", op)
        pulumi.set(__self__, "right", right)

    @property
    @pulumi.getter
    def left(self) -> str:
        """
        The left operand of the condition task. It could be a string value, job state, or a parameter reference.
        """
        return pulumi.get(self, "left")

    @property
    @pulumi.getter
    def op(self) -> str:
        """
        The string specifying the operation used to compare operands.  Currently, following operators are supported: `EQUAL_TO`, `GREATER_THAN`, `GREATER_THAN_OR_EQUAL`, `LESS_THAN`, `LESS_THAN_OR_EQUAL`, `NOT_EQUAL`. (Check the [API docs](https://docs.databricks.com/api/workspace/jobs/create) for the latest information).

        This task does not require a cluster to execute and does not support retries or notifications.
        """
        return pulumi.get(self, "op")

    @property
    @pulumi.getter
    def right(self) -> str:
        """
        The right operand of the condition task. It could be a string value, job state, or parameter reference.
        """
        return pulumi.get(self, "right")


@pulumi.output_type
class JobTaskDbtTask(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "profilesDirectory":
            suggest = "profiles_directory"
        elif key == "projectDirectory":
            suggest = "project_directory"
        elif key == "warehouseId":
            suggest = "warehouse_id"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in JobTaskDbtTask. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        JobTaskDbtTask.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        JobTaskDbtTask.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 commands: Sequence[str],
                 catalog: Optional[str] = None,
                 profiles_directory: Optional[str] = None,
                 project_directory: Optional[str] = None,
                 schema: Optional[str] = None,
                 source: Optional[str] = None,
                 warehouse_id: Optional[str] = None):
        """
        :param Sequence[str] commands: (Array) Series of dbt commands to execute in sequence. Every command must start with "dbt".
        :param str catalog: The name of the catalog to use inside Unity Catalog.
        :param str profiles_directory: The relative path to the directory in the repository specified by `git_source` where dbt should look in for the `profiles.yml` file. If not specified, defaults to the repository's root directory. Equivalent to passing `--profile-dir` to a dbt command.
        :param str project_directory: The path where dbt should look for `dbt_project.yml`. Equivalent to passing `--project-dir` to the dbt CLI.
               * If `source` is `GIT`: Relative path to the directory in the repository specified in the `git_source` block. Defaults to the repository's root directory when not specified.
               * If `source` is `WORKSPACE`: Absolute path to the folder in the workspace.
        :param str schema: The name of the schema dbt should run in. Defaults to `default`.
        :param str source: The source of the project. Possible values are `WORKSPACE` and `GIT`.  Defaults to `GIT` if a `git_source` block is present in the job definition.
        :param str warehouse_id: The ID of the SQL warehouse that dbt should execute against.
               
               You also need to include a `git_source` block to configure the repository that contains the dbt project.
        """
        pulumi.set(__self__, "commands", commands)
        if catalog is not None:
            pulumi.set(__self__, "catalog", catalog)
        if profiles_directory is not None:
            pulumi.set(__self__, "profiles_directory", profiles_directory)
        if project_directory is not None:
            pulumi.set(__self__, "project_directory", project_directory)
        if schema is not None:
            pulumi.set(__self__, "schema", schema)
        if source is not None:
            pulumi.set(__self__, "source", source)
        if warehouse_id is not None:
            pulumi.set(__self__, "warehouse_id", warehouse_id)

    @property
    @pulumi.getter
    def commands(self) -> Sequence[str]:
        """
        (Array) Series of dbt commands to execute in sequence. Every command must start with "dbt".
        """
        return pulumi.get(self, "commands")

    @property
    @pulumi.getter
    def catalog(self) -> Optional[str]:
        """
        The name of the catalog to use inside Unity Catalog.
        """
        return pulumi.get(self, "catalog")

    @property
    @pulumi.getter(name="profilesDirectory")
    def profiles_directory(self) -> Optional[str]:
        """
        The relative path to the directory in the repository specified by `git_source` where dbt should look in for the `profiles.yml` file. If not specified, defaults to the repository's root directory. Equivalent to passing `--profile-dir` to a dbt command.
        """
        return pulumi.get(self, "profiles_directory")

    @property
    @pulumi.getter(name="projectDirectory")
    def project_directory(self) -> Optional[str]:
        """
        The path where dbt should look for `dbt_project.yml`. Equivalent to passing `--project-dir` to the dbt CLI.
        * If `source` is `GIT`: Relative path to the directory in the repository specified in the `git_source` block. Defaults to the repository's root directory when not specified.
        * If `source` is `WORKSPACE`: Absolute path to the folder in the workspace.
        """
        return pulumi.get(self, "project_directory")

    @property
    @pulumi.getter
    def schema(self) -> Optional[str]:
        """
        The name of the schema dbt should run in. Defaults to `default`.
        """
        return pulumi.get(self, "schema")

    @property
    @pulumi.getter
    def source(self) -> Optional[str]:
        """
        The source of the project. Possible values are `WORKSPACE` and `GIT`.  Defaults to `GIT` if a `git_source` block is present in the job definition.
        """
        return pulumi.get(self, "source")

    @property
    @pulumi.getter(name="warehouseId")
    def warehouse_id(self) -> Optional[str]:
        """
        The ID of the SQL warehouse that dbt should execute against.

        You also need to include a `git_source` block to configure the repository that contains the dbt project.
        """
        return pulumi.get(self, "warehouse_id")


@pulumi.output_type
class JobTaskDependsOn(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "taskKey":
            suggest = "task_key"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in JobTaskDependsOn. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        JobTaskDependsOn.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        JobTaskDependsOn.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 task_key: str,
                 outcome: Optional[str] = None):
        """
        :param str task_key: The name of the task this task depends on.
        :param str outcome: Can only be specified on condition task dependencies. The outcome of the dependent task that must be met for this task to run. Possible values are `"true"` or `"false"`.
               
               > **Note** Similar to the tasks themselves, each dependency inside the task need to be declared in alphabetical order with respect to task_key in order to get consistent Pulumi diffs.
        """
        pulumi.set(__self__, "task_key", task_key)
        if outcome is not None:
            pulumi.set(__self__, "outcome", outcome)

    @property
    @pulumi.getter(name="taskKey")
    def task_key(self) -> str:
        """
        The name of the task this task depends on.
        """
        return pulumi.get(self, "task_key")

    @property
    @pulumi.getter
    def outcome(self) -> Optional[str]:
        """
        Can only be specified on condition task dependencies. The outcome of the dependent task that must be met for this task to run. Possible values are `"true"` or `"false"`.

        > **Note** Similar to the tasks themselves, each dependency inside the task need to be declared in alphabetical order with respect to task_key in order to get consistent Pulumi diffs.
        """
        return pulumi.get(self, "outcome")


@pulumi.output_type
class JobTaskEmailNotifications(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "noAlertForSkippedRuns":
            suggest = "no_alert_for_skipped_runs"
        elif key == "onDurationWarningThresholdExceededs":
            suggest = "on_duration_warning_threshold_exceededs"
        elif key == "onFailures":
            suggest = "on_failures"
        elif key == "onStarts":
            suggest = "on_starts"
        elif key == "onStreamingBacklogExceededs":
            suggest = "on_streaming_backlog_exceededs"
        elif key == "onSuccesses":
            suggest = "on_successes"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in JobTaskEmailNotifications. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        JobTaskEmailNotifications.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        JobTaskEmailNotifications.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 no_alert_for_skipped_runs: Optional[bool] = None,
                 on_duration_warning_threshold_exceededs: Optional[Sequence[str]] = None,
                 on_failures: Optional[Sequence[str]] = None,
                 on_starts: Optional[Sequence[str]] = None,
                 on_streaming_backlog_exceededs: Optional[Sequence[str]] = None,
                 on_successes: Optional[Sequence[str]] = None):
        """
        :param bool no_alert_for_skipped_runs: (Bool) don't send alert for skipped runs. (It's recommended to use the corresponding setting in the `notification_settings` configuration block).
        :param Sequence[str] on_duration_warning_threshold_exceededs: (List) list of emails to notify when the duration of a run exceeds the threshold specified by the `RUN_DURATION_SECONDS` metric in the `health` block.
               
               The following parameter is only available for the job level configuration.
        :param Sequence[str] on_failures: (List) list of emails to notify when the run fails.
        :param Sequence[str] on_starts: (List) list of emails to notify when the run starts.
        :param Sequence[str] on_successes: (List) list of emails to notify when the run completes successfully.
        """
        if no_alert_for_skipped_runs is not None:
            pulumi.set(__self__, "no_alert_for_skipped_runs", no_alert_for_skipped_runs)
        if on_duration_warning_threshold_exceededs is not None:
            pulumi.set(__self__, "on_duration_warning_threshold_exceededs", on_duration_warning_threshold_exceededs)
        if on_failures is not None:
            pulumi.set(__self__, "on_failures", on_failures)
        if on_starts is not None:
            pulumi.set(__self__, "on_starts", on_starts)
        if on_streaming_backlog_exceededs is not None:
            pulumi.set(__self__, "on_streaming_backlog_exceededs", on_streaming_backlog_exceededs)
        if on_successes is not None:
            pulumi.set(__self__, "on_successes", on_successes)

    @property
    @pulumi.getter(name="noAlertForSkippedRuns")
    def no_alert_for_skipped_runs(self) -> Optional[bool]:
        """
        (Bool) don't send alert for skipped runs. (It's recommended to use the corresponding setting in the `notification_settings` configuration block).
        """
        return pulumi.get(self, "no_alert_for_skipped_runs")

    @property
    @pulumi.getter(name="onDurationWarningThresholdExceededs")
    def on_duration_warning_threshold_exceededs(self) -> Optional[Sequence[str]]:
        """
        (List) list of emails to notify when the duration of a run exceeds the threshold specified by the `RUN_DURATION_SECONDS` metric in the `health` block.

        The following parameter is only available for the job level configuration.
        """
        return pulumi.get(self, "on_duration_warning_threshold_exceededs")

    @property
    @pulumi.getter(name="onFailures")
    def on_failures(self) -> Optional[Sequence[str]]:
        """
        (List) list of emails to notify when the run fails.
        """
        return pulumi.get(self, "on_failures")

    @property
    @pulumi.getter(name="onStarts")
    def on_starts(self) -> Optional[Sequence[str]]:
        """
        (List) list of emails to notify when the run starts.
        """
        return pulumi.get(self, "on_starts")

    @property
    @pulumi.getter(name="onStreamingBacklogExceededs")
    def on_streaming_backlog_exceededs(self) -> Optional[Sequence[str]]:
        return pulumi.get(self, "on_streaming_backlog_exceededs")

    @property
    @pulumi.getter(name="onSuccesses")
    def on_successes(self) -> Optional[Sequence[str]]:
        """
        (List) list of emails to notify when the run completes successfully.
        """
        return pulumi.get(self, "on_successes")


@pulumi.output_type
class JobTaskForEachTask(dict):
    def __init__(__self__, *,
                 inputs: str,
                 task: 'outputs.JobTaskForEachTaskTask',
                 concurrency: Optional[int] = None):
        """
        :param str inputs: (String) Array for task to iterate on. This can be a JSON string or a reference to an array parameter.
        :param 'JobTaskForEachTaskTaskArgs' task: Task to run against the `inputs` list.
        :param int concurrency: Controls the number of active iteration task runs. Default is 20, maximum allowed is 100.
        """
        pulumi.set(__self__, "inputs", inputs)
        pulumi.set(__self__, "task", task)
        if concurrency is not None:
            pulumi.set(__self__, "concurrency", concurrency)

    @property
    @pulumi.getter
    def inputs(self) -> str:
        """
        (String) Array for task to iterate on. This can be a JSON string or a reference to an array parameter.
        """
        return pulumi.get(self, "inputs")

    @property
    @pulumi.getter
    def task(self) -> 'outputs.JobTaskForEachTaskTask':
        """
        Task to run against the `inputs` list.
        """
        return pulumi.get(self, "task")

    @property
    @pulumi.getter
    def concurrency(self) -> Optional[int]:
        """
        Controls the number of active iteration task runs. Default is 20, maximum allowed is 100.
        """
        return pulumi.get(self, "concurrency")


@pulumi.output_type
class JobTaskForEachTaskTask(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "taskKey":
            suggest = "task_key"
        elif key == "conditionTask":
            suggest = "condition_task"
        elif key == "dbtTask":
            suggest = "dbt_task"
        elif key == "dependsOns":
            suggest = "depends_ons"
        elif key == "disableAutoOptimization":
            suggest = "disable_auto_optimization"
        elif key == "emailNotifications":
            suggest = "email_notifications"
        elif key == "environmentKey":
            suggest = "environment_key"
        elif key == "existingClusterId":
            suggest = "existing_cluster_id"
        elif key == "jobClusterKey":
            suggest = "job_cluster_key"
        elif key == "maxRetries":
            suggest = "max_retries"
        elif key == "minRetryIntervalMillis":
            suggest = "min_retry_interval_millis"
        elif key == "newCluster":
            suggest = "new_cluster"
        elif key == "notebookTask":
            suggest = "notebook_task"
        elif key == "notificationSettings":
            suggest = "notification_settings"
        elif key == "pipelineTask":
            suggest = "pipeline_task"
        elif key == "pythonWheelTask":
            suggest = "python_wheel_task"
        elif key == "retryOnTimeout":
            suggest = "retry_on_timeout"
        elif key == "runIf":
            suggest = "run_if"
        elif key == "runJobTask":
            suggest = "run_job_task"
        elif key == "sparkJarTask":
            suggest = "spark_jar_task"
        elif key == "sparkPythonTask":
            suggest = "spark_python_task"
        elif key == "sparkSubmitTask":
            suggest = "spark_submit_task"
        elif key == "sqlTask":
            suggest = "sql_task"
        elif key == "timeoutSeconds":
            suggest = "timeout_seconds"
        elif key == "webhookNotifications":
            suggest = "webhook_notifications"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in JobTaskForEachTaskTask. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        JobTaskForEachTaskTask.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        JobTaskForEachTaskTask.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 task_key: str,
                 condition_task: Optional['outputs.JobTaskForEachTaskTaskConditionTask'] = None,
                 dbt_task: Optional['outputs.JobTaskForEachTaskTaskDbtTask'] = None,
                 depends_ons: Optional[Sequence['outputs.JobTaskForEachTaskTaskDependsOn']] = None,
                 description: Optional[str] = None,
                 disable_auto_optimization: Optional[bool] = None,
                 email_notifications: Optional['outputs.JobTaskForEachTaskTaskEmailNotifications'] = None,
                 environment_key: Optional[str] = None,
                 existing_cluster_id: Optional[str] = None,
                 health: Optional['outputs.JobTaskForEachTaskTaskHealth'] = None,
                 job_cluster_key: Optional[str] = None,
                 libraries: Optional[Sequence['outputs.JobTaskForEachTaskTaskLibrary']] = None,
                 max_retries: Optional[int] = None,
                 min_retry_interval_millis: Optional[int] = None,
                 new_cluster: Optional['outputs.JobTaskForEachTaskTaskNewCluster'] = None,
                 notebook_task: Optional['outputs.JobTaskForEachTaskTaskNotebookTask'] = None,
                 notification_settings: Optional['outputs.JobTaskForEachTaskTaskNotificationSettings'] = None,
                 pipeline_task: Optional['outputs.JobTaskForEachTaskTaskPipelineTask'] = None,
                 python_wheel_task: Optional['outputs.JobTaskForEachTaskTaskPythonWheelTask'] = None,
                 retry_on_timeout: Optional[bool] = None,
                 run_if: Optional[str] = None,
                 run_job_task: Optional['outputs.JobTaskForEachTaskTaskRunJobTask'] = None,
                 spark_jar_task: Optional['outputs.JobTaskForEachTaskTaskSparkJarTask'] = None,
                 spark_python_task: Optional['outputs.JobTaskForEachTaskTaskSparkPythonTask'] = None,
                 spark_submit_task: Optional['outputs.JobTaskForEachTaskTaskSparkSubmitTask'] = None,
                 sql_task: Optional['outputs.JobTaskForEachTaskTaskSqlTask'] = None,
                 timeout_seconds: Optional[int] = None,
                 webhook_notifications: Optional['outputs.JobTaskForEachTaskTaskWebhookNotifications'] = None):
        """
        :param str task_key: string specifying an unique key for a given task.
               * `*_task` - (Required) one of the specific task blocks described below:
        :param Sequence['JobTaskForEachTaskTaskDependsOnArgs'] depends_ons: block specifying dependency(-ies) for a given task.
        :param str description: description for this task.
        :param bool disable_auto_optimization: A flag to disable auto optimization in serverless tasks.
        :param 'JobTaskForEachTaskTaskEmailNotificationsArgs' email_notifications: An optional block to specify a set of email addresses notified when this task begins, completes or fails. The default behavior is to not send any emails. This block is documented below.
        :param str environment_key: identifier of an `environment` block that is used to specify libraries.  Required for some tasks (`spark_python_task`, `python_wheel_task`, ...) running on serverless compute.
        :param str existing_cluster_id: Identifier of the interactive cluster to run job on.  *Note: running tasks on interactive clusters may lead to increased costs!*
        :param 'JobTaskForEachTaskTaskHealthArgs' health: block described below that specifies health conditions for a given task.
        :param str job_cluster_key: Identifier of the Job cluster specified in the `job_cluster` block.
        :param Sequence['JobTaskForEachTaskTaskLibraryArgs'] libraries: (Set) An optional list of libraries to be installed on the cluster that will execute the job.
        :param int max_retries: (Integer) An optional maximum number of times to retry an unsuccessful run. A run is considered to be unsuccessful if it completes with a `FAILED` or `INTERNAL_ERROR` lifecycle state. The value -1 means to retry indefinitely and the value 0 means to never retry. The default behavior is to never retry. A run can have the following lifecycle state: `PENDING`, `RUNNING`, `TERMINATING`, `TERMINATED`, `SKIPPED` or `INTERNAL_ERROR`.
        :param int min_retry_interval_millis: (Integer) An optional minimal interval in milliseconds between the start of the failed run and the subsequent retry run. The default behavior is that unsuccessful runs are immediately retried.
        :param 'JobTaskForEachTaskTaskNewClusterArgs' new_cluster: Task will run on a dedicated cluster.  See Cluster documentation for specification. *Some parameters, such as `autotermination_minutes`, `is_pinned`, `workload_type` aren't supported!*
        :param 'JobTaskForEachTaskTaskNotificationSettingsArgs' notification_settings: An optional block controlling the notification settings on the job level documented below.
        :param bool retry_on_timeout: (Bool) An optional policy to specify whether to retry a job when it times out. The default behavior is to not retry on timeout.
        :param str run_if: An optional value indicating the condition that determines whether the task should be run once its dependencies have been completed. One of `ALL_SUCCESS`, `AT_LEAST_ONE_SUCCESS`, `NONE_FAILED`, `ALL_DONE`, `AT_LEAST_ONE_FAILED` or `ALL_FAILED`. When omitted, defaults to `ALL_SUCCESS`.
        :param int timeout_seconds: (Integer) An optional timeout applied to each run of this job. The default behavior is to have no timeout.
        :param 'JobTaskForEachTaskTaskWebhookNotificationsArgs' webhook_notifications: (List) An optional set of system destinations (for example, webhook destinations or Slack) to be notified when runs of this task begins, completes or fails. The default behavior is to not send any notifications. This field is a block and is documented below.
               
               > **Note** If no `job_cluster_key`, `existing_cluster_id`, or `new_cluster` were specified in task definition, then task will executed using serverless compute.
        """
        pulumi.set(__self__, "task_key", task_key)
        if condition_task is not None:
            pulumi.set(__self__, "condition_task", condition_task)
        if dbt_task is not None:
            pulumi.set(__self__, "dbt_task", dbt_task)
        if depends_ons is not None:
            pulumi.set(__self__, "depends_ons", depends_ons)
        if description is not None:
            pulumi.set(__self__, "description", description)
        if disable_auto_optimization is not None:
            pulumi.set(__self__, "disable_auto_optimization", disable_auto_optimization)
        if email_notifications is not None:
            pulumi.set(__self__, "email_notifications", email_notifications)
        if environment_key is not None:
            pulumi.set(__self__, "environment_key", environment_key)
        if existing_cluster_id is not None:
            pulumi.set(__self__, "existing_cluster_id", existing_cluster_id)
        if health is not None:
            pulumi.set(__self__, "health", health)
        if job_cluster_key is not None:
            pulumi.set(__self__, "job_cluster_key", job_cluster_key)
        if libraries is not None:
            pulumi.set(__self__, "libraries", libraries)
        if max_retries is not None:
            pulumi.set(__self__, "max_retries", max_retries)
        if min_retry_interval_millis is not None:
            pulumi.set(__self__, "min_retry_interval_millis", min_retry_interval_millis)
        if new_cluster is not None:
            pulumi.set(__self__, "new_cluster", new_cluster)
        if notebook_task is not None:
            pulumi.set(__self__, "notebook_task", notebook_task)
        if notification_settings is not None:
            pulumi.set(__self__, "notification_settings", notification_settings)
        if pipeline_task is not None:
            pulumi.set(__self__, "pipeline_task", pipeline_task)
        if python_wheel_task is not None:
            pulumi.set(__self__, "python_wheel_task", python_wheel_task)
        if retry_on_timeout is not None:
            pulumi.set(__self__, "retry_on_timeout", retry_on_timeout)
        if run_if is not None:
            pulumi.set(__self__, "run_if", run_if)
        if run_job_task is not None:
            pulumi.set(__self__, "run_job_task", run_job_task)
        if spark_jar_task is not None:
            pulumi.set(__self__, "spark_jar_task", spark_jar_task)
        if spark_python_task is not None:
            pulumi.set(__self__, "spark_python_task", spark_python_task)
        if spark_submit_task is not None:
            pulumi.set(__self__, "spark_submit_task", spark_submit_task)
        if sql_task is not None:
            pulumi.set(__self__, "sql_task", sql_task)
        if timeout_seconds is not None:
            pulumi.set(__self__, "timeout_seconds", timeout_seconds)
        if webhook_notifications is not None:
            pulumi.set(__self__, "webhook_notifications", webhook_notifications)

    @property
    @pulumi.getter(name="taskKey")
    def task_key(self) -> str:
        """
        string specifying an unique key for a given task.
        * `*_task` - (Required) one of the specific task blocks described below:
        """
        return pulumi.get(self, "task_key")

    @property
    @pulumi.getter(name="conditionTask")
    def condition_task(self) -> Optional['outputs.JobTaskForEachTaskTaskConditionTask']:
        return pulumi.get(self, "condition_task")

    @property
    @pulumi.getter(name="dbtTask")
    def dbt_task(self) -> Optional['outputs.JobTaskForEachTaskTaskDbtTask']:
        return pulumi.get(self, "dbt_task")

    @property
    @pulumi.getter(name="dependsOns")
    def depends_ons(self) -> Optional[Sequence['outputs.JobTaskForEachTaskTaskDependsOn']]:
        """
        block specifying dependency(-ies) for a given task.
        """
        return pulumi.get(self, "depends_ons")

    @property
    @pulumi.getter
    def description(self) -> Optional[str]:
        """
        description for this task.
        """
        return pulumi.get(self, "description")

    @property
    @pulumi.getter(name="disableAutoOptimization")
    def disable_auto_optimization(self) -> Optional[bool]:
        """
        A flag to disable auto optimization in serverless tasks.
        """
        return pulumi.get(self, "disable_auto_optimization")

    @property
    @pulumi.getter(name="emailNotifications")
    def email_notifications(self) -> Optional['outputs.JobTaskForEachTaskTaskEmailNotifications']:
        """
        An optional block to specify a set of email addresses notified when this task begins, completes or fails. The default behavior is to not send any emails. This block is documented below.
        """
        return pulumi.get(self, "email_notifications")

    @property
    @pulumi.getter(name="environmentKey")
    def environment_key(self) -> Optional[str]:
        """
        identifier of an `environment` block that is used to specify libraries.  Required for some tasks (`spark_python_task`, `python_wheel_task`, ...) running on serverless compute.
        """
        return pulumi.get(self, "environment_key")

    @property
    @pulumi.getter(name="existingClusterId")
    def existing_cluster_id(self) -> Optional[str]:
        """
        Identifier of the interactive cluster to run job on.  *Note: running tasks on interactive clusters may lead to increased costs!*
        """
        return pulumi.get(self, "existing_cluster_id")

    @property
    @pulumi.getter
    def health(self) -> Optional['outputs.JobTaskForEachTaskTaskHealth']:
        """
        block described below that specifies health conditions for a given task.
        """
        return pulumi.get(self, "health")

    @property
    @pulumi.getter(name="jobClusterKey")
    def job_cluster_key(self) -> Optional[str]:
        """
        Identifier of the Job cluster specified in the `job_cluster` block.
        """
        return pulumi.get(self, "job_cluster_key")

    @property
    @pulumi.getter
    def libraries(self) -> Optional[Sequence['outputs.JobTaskForEachTaskTaskLibrary']]:
        """
        (Set) An optional list of libraries to be installed on the cluster that will execute the job.
        """
        return pulumi.get(self, "libraries")

    @property
    @pulumi.getter(name="maxRetries")
    def max_retries(self) -> Optional[int]:
        """
        (Integer) An optional maximum number of times to retry an unsuccessful run. A run is considered to be unsuccessful if it completes with a `FAILED` or `INTERNAL_ERROR` lifecycle state. The value -1 means to retry indefinitely and the value 0 means to never retry. The default behavior is to never retry. A run can have the following lifecycle state: `PENDING`, `RUNNING`, `TERMINATING`, `TERMINATED`, `SKIPPED` or `INTERNAL_ERROR`.
        """
        return pulumi.get(self, "max_retries")

    @property
    @pulumi.getter(name="minRetryIntervalMillis")
    def min_retry_interval_millis(self) -> Optional[int]:
        """
        (Integer) An optional minimal interval in milliseconds between the start of the failed run and the subsequent retry run. The default behavior is that unsuccessful runs are immediately retried.
        """
        return pulumi.get(self, "min_retry_interval_millis")

    @property
    @pulumi.getter(name="newCluster")
    def new_cluster(self) -> Optional['outputs.JobTaskForEachTaskTaskNewCluster']:
        """
        Task will run on a dedicated cluster.  See Cluster documentation for specification. *Some parameters, such as `autotermination_minutes`, `is_pinned`, `workload_type` aren't supported!*
        """
        return pulumi.get(self, "new_cluster")

    @property
    @pulumi.getter(name="notebookTask")
    def notebook_task(self) -> Optional['outputs.JobTaskForEachTaskTaskNotebookTask']:
        return pulumi.get(self, "notebook_task")

    @property
    @pulumi.getter(name="notificationSettings")
    def notification_settings(self) -> Optional['outputs.JobTaskForEachTaskTaskNotificationSettings']:
        """
        An optional block controlling the notification settings on the job level documented below.
        """
        return pulumi.get(self, "notification_settings")

    @property
    @pulumi.getter(name="pipelineTask")
    def pipeline_task(self) -> Optional['outputs.JobTaskForEachTaskTaskPipelineTask']:
        return pulumi.get(self, "pipeline_task")

    @property
    @pulumi.getter(name="pythonWheelTask")
    def python_wheel_task(self) -> Optional['outputs.JobTaskForEachTaskTaskPythonWheelTask']:
        return pulumi.get(self, "python_wheel_task")

    @property
    @pulumi.getter(name="retryOnTimeout")
    def retry_on_timeout(self) -> Optional[bool]:
        """
        (Bool) An optional policy to specify whether to retry a job when it times out. The default behavior is to not retry on timeout.
        """
        return pulumi.get(self, "retry_on_timeout")

    @property
    @pulumi.getter(name="runIf")
    def run_if(self) -> Optional[str]:
        """
        An optional value indicating the condition that determines whether the task should be run once its dependencies have been completed. One of `ALL_SUCCESS`, `AT_LEAST_ONE_SUCCESS`, `NONE_FAILED`, `ALL_DONE`, `AT_LEAST_ONE_FAILED` or `ALL_FAILED`. When omitted, defaults to `ALL_SUCCESS`.
        """
        return pulumi.get(self, "run_if")

    @property
    @pulumi.getter(name="runJobTask")
    def run_job_task(self) -> Optional['outputs.JobTaskForEachTaskTaskRunJobTask']:
        return pulumi.get(self, "run_job_task")

    @property
    @pulumi.getter(name="sparkJarTask")
    def spark_jar_task(self) -> Optional['outputs.JobTaskForEachTaskTaskSparkJarTask']:
        return pulumi.get(self, "spark_jar_task")

    @property
    @pulumi.getter(name="sparkPythonTask")
    def spark_python_task(self) -> Optional['outputs.JobTaskForEachTaskTaskSparkPythonTask']:
        return pulumi.get(self, "spark_python_task")

    @property
    @pulumi.getter(name="sparkSubmitTask")
    def spark_submit_task(self) -> Optional['outputs.JobTaskForEachTaskTaskSparkSubmitTask']:
        return pulumi.get(self, "spark_submit_task")

    @property
    @pulumi.getter(name="sqlTask")
    def sql_task(self) -> Optional['outputs.JobTaskForEachTaskTaskSqlTask']:
        return pulumi.get(self, "sql_task")

    @property
    @pulumi.getter(name="timeoutSeconds")
    def timeout_seconds(self) -> Optional[int]:
        """
        (Integer) An optional timeout applied to each run of this job. The default behavior is to have no timeout.
        """
        return pulumi.get(self, "timeout_seconds")

    @property
    @pulumi.getter(name="webhookNotifications")
    def webhook_notifications(self) -> Optional['outputs.JobTaskForEachTaskTaskWebhookNotifications']:
        """
        (List) An optional set of system destinations (for example, webhook destinations or Slack) to be notified when runs of this task begins, completes or fails. The default behavior is to not send any notifications. This field is a block and is documented below.

        > **Note** If no `job_cluster_key`, `existing_cluster_id`, or `new_cluster` were specified in task definition, then task will executed using serverless compute.
        """
        return pulumi.get(self, "webhook_notifications")


@pulumi.output_type
class JobTaskForEachTaskTaskConditionTask(dict):
    def __init__(__self__, *,
                 left: str,
                 op: str,
                 right: str):
        """
        :param str left: The left operand of the condition task. It could be a string value, job state, or a parameter reference.
        :param str op: The string specifying the operation used to compare operands.  Currently, following operators are supported: `EQUAL_TO`, `GREATER_THAN`, `GREATER_THAN_OR_EQUAL`, `LESS_THAN`, `LESS_THAN_OR_EQUAL`, `NOT_EQUAL`. (Check the [API docs](https://docs.databricks.com/api/workspace/jobs/create) for the latest information).
               
               This task does not require a cluster to execute and does not support retries or notifications.
        :param str right: The right operand of the condition task. It could be a string value, job state, or parameter reference.
        """
        pulumi.set(__self__, "left", left)
        pulumi.set(__self__, "op", op)
        pulumi.set(__self__, "right", right)

    @property
    @pulumi.getter
    def left(self) -> str:
        """
        The left operand of the condition task. It could be a string value, job state, or a parameter reference.
        """
        return pulumi.get(self, "left")

    @property
    @pulumi.getter
    def op(self) -> str:
        """
        The string specifying the operation used to compare operands.  Currently, following operators are supported: `EQUAL_TO`, `GREATER_THAN`, `GREATER_THAN_OR_EQUAL`, `LESS_THAN`, `LESS_THAN_OR_EQUAL`, `NOT_EQUAL`. (Check the [API docs](https://docs.databricks.com/api/workspace/jobs/create) for the latest information).

        This task does not require a cluster to execute and does not support retries or notifications.
        """
        return pulumi.get(self, "op")

    @property
    @pulumi.getter
    def right(self) -> str:
        """
        The right operand of the condition task. It could be a string value, job state, or parameter reference.
        """
        return pulumi.get(self, "right")


@pulumi.output_type
class JobTaskForEachTaskTaskDbtTask(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "profilesDirectory":
            suggest = "profiles_directory"
        elif key == "projectDirectory":
            suggest = "project_directory"
        elif key == "warehouseId":
            suggest = "warehouse_id"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in JobTaskForEachTaskTaskDbtTask. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        JobTaskForEachTaskTaskDbtTask.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        JobTaskForEachTaskTaskDbtTask.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 commands: Sequence[str],
                 catalog: Optional[str] = None,
                 profiles_directory: Optional[str] = None,
                 project_directory: Optional[str] = None,
                 schema: Optional[str] = None,
                 source: Optional[str] = None,
                 warehouse_id: Optional[str] = None):
        """
        :param Sequence[str] commands: (Array) Series of dbt commands to execute in sequence. Every command must start with "dbt".
        :param str catalog: The name of the catalog to use inside Unity Catalog.
        :param str profiles_directory: The relative path to the directory in the repository specified by `git_source` where dbt should look in for the `profiles.yml` file. If not specified, defaults to the repository's root directory. Equivalent to passing `--profile-dir` to a dbt command.
        :param str project_directory: The path where dbt should look for `dbt_project.yml`. Equivalent to passing `--project-dir` to the dbt CLI.
               * If `source` is `GIT`: Relative path to the directory in the repository specified in the `git_source` block. Defaults to the repository's root directory when not specified.
               * If `source` is `WORKSPACE`: Absolute path to the folder in the workspace.
        :param str schema: The name of the schema dbt should run in. Defaults to `default`.
        :param str source: The source of the project. Possible values are `WORKSPACE` and `GIT`.  Defaults to `GIT` if a `git_source` block is present in the job definition.
        :param str warehouse_id: The ID of the SQL warehouse that dbt should execute against.
               
               You also need to include a `git_source` block to configure the repository that contains the dbt project.
        """
        pulumi.set(__self__, "commands", commands)
        if catalog is not None:
            pulumi.set(__self__, "catalog", catalog)
        if profiles_directory is not None:
            pulumi.set(__self__, "profiles_directory", profiles_directory)
        if project_directory is not None:
            pulumi.set(__self__, "project_directory", project_directory)
        if schema is not None:
            pulumi.set(__self__, "schema", schema)
        if source is not None:
            pulumi.set(__self__, "source", source)
        if warehouse_id is not None:
            pulumi.set(__self__, "warehouse_id", warehouse_id)

    @property
    @pulumi.getter
    def commands(self) -> Sequence[str]:
        """
        (Array) Series of dbt commands to execute in sequence. Every command must start with "dbt".
        """
        return pulumi.get(self, "commands")

    @property
    @pulumi.getter
    def catalog(self) -> Optional[str]:
        """
        The name of the catalog to use inside Unity Catalog.
        """
        return pulumi.get(self, "catalog")

    @property
    @pulumi.getter(name="profilesDirectory")
    def profiles_directory(self) -> Optional[str]:
        """
        The relative path to the directory in the repository specified by `git_source` where dbt should look in for the `profiles.yml` file. If not specified, defaults to the repository's root directory. Equivalent to passing `--profile-dir` to a dbt command.
        """
        return pulumi.get(self, "profiles_directory")

    @property
    @pulumi.getter(name="projectDirectory")
    def project_directory(self) -> Optional[str]:
        """
        The path where dbt should look for `dbt_project.yml`. Equivalent to passing `--project-dir` to the dbt CLI.
        * If `source` is `GIT`: Relative path to the directory in the repository specified in the `git_source` block. Defaults to the repository's root directory when not specified.
        * If `source` is `WORKSPACE`: Absolute path to the folder in the workspace.
        """
        return pulumi.get(self, "project_directory")

    @property
    @pulumi.getter
    def schema(self) -> Optional[str]:
        """
        The name of the schema dbt should run in. Defaults to `default`.
        """
        return pulumi.get(self, "schema")

    @property
    @pulumi.getter
    def source(self) -> Optional[str]:
        """
        The source of the project. Possible values are `WORKSPACE` and `GIT`.  Defaults to `GIT` if a `git_source` block is present in the job definition.
        """
        return pulumi.get(self, "source")

    @property
    @pulumi.getter(name="warehouseId")
    def warehouse_id(self) -> Optional[str]:
        """
        The ID of the SQL warehouse that dbt should execute against.

        You also need to include a `git_source` block to configure the repository that contains the dbt project.
        """
        return pulumi.get(self, "warehouse_id")


@pulumi.output_type
class JobTaskForEachTaskTaskDependsOn(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "taskKey":
            suggest = "task_key"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in JobTaskForEachTaskTaskDependsOn. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        JobTaskForEachTaskTaskDependsOn.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        JobTaskForEachTaskTaskDependsOn.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 task_key: str,
                 outcome: Optional[str] = None):
        """
        :param str task_key: The name of the task this task depends on.
        :param str outcome: Can only be specified on condition task dependencies. The outcome of the dependent task that must be met for this task to run. Possible values are `"true"` or `"false"`.
               
               > **Note** Similar to the tasks themselves, each dependency inside the task need to be declared in alphabetical order with respect to task_key in order to get consistent Pulumi diffs.
        """
        pulumi.set(__self__, "task_key", task_key)
        if outcome is not None:
            pulumi.set(__self__, "outcome", outcome)

    @property
    @pulumi.getter(name="taskKey")
    def task_key(self) -> str:
        """
        The name of the task this task depends on.
        """
        return pulumi.get(self, "task_key")

    @property
    @pulumi.getter
    def outcome(self) -> Optional[str]:
        """
        Can only be specified on condition task dependencies. The outcome of the dependent task that must be met for this task to run. Possible values are `"true"` or `"false"`.

        > **Note** Similar to the tasks themselves, each dependency inside the task need to be declared in alphabetical order with respect to task_key in order to get consistent Pulumi diffs.
        """
        return pulumi.get(self, "outcome")


@pulumi.output_type
class JobTaskForEachTaskTaskEmailNotifications(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "noAlertForSkippedRuns":
            suggest = "no_alert_for_skipped_runs"
        elif key == "onDurationWarningThresholdExceededs":
            suggest = "on_duration_warning_threshold_exceededs"
        elif key == "onFailures":
            suggest = "on_failures"
        elif key == "onStarts":
            suggest = "on_starts"
        elif key == "onStreamingBacklogExceededs":
            suggest = "on_streaming_backlog_exceededs"
        elif key == "onSuccesses":
            suggest = "on_successes"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in JobTaskForEachTaskTaskEmailNotifications. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        JobTaskForEachTaskTaskEmailNotifications.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        JobTaskForEachTaskTaskEmailNotifications.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 no_alert_for_skipped_runs: Optional[bool] = None,
                 on_duration_warning_threshold_exceededs: Optional[Sequence[str]] = None,
                 on_failures: Optional[Sequence[str]] = None,
                 on_starts: Optional[Sequence[str]] = None,
                 on_streaming_backlog_exceededs: Optional[Sequence[str]] = None,
                 on_successes: Optional[Sequence[str]] = None):
        """
        :param bool no_alert_for_skipped_runs: (Bool) don't send alert for skipped runs. (It's recommended to use the corresponding setting in the `notification_settings` configuration block).
        :param Sequence[str] on_duration_warning_threshold_exceededs: (List) list of emails to notify when the duration of a run exceeds the threshold specified by the `RUN_DURATION_SECONDS` metric in the `health` block.
               
               The following parameter is only available for the job level configuration.
        :param Sequence[str] on_failures: (List) list of emails to notify when the run fails.
        :param Sequence[str] on_starts: (List) list of emails to notify when the run starts.
        :param Sequence[str] on_successes: (List) list of emails to notify when the run completes successfully.
        """
        if no_alert_for_skipped_runs is not None:
            pulumi.set(__self__, "no_alert_for_skipped_runs", no_alert_for_skipped_runs)
        if on_duration_warning_threshold_exceededs is not None:
            pulumi.set(__self__, "on_duration_warning_threshold_exceededs", on_duration_warning_threshold_exceededs)
        if on_failures is not None:
            pulumi.set(__self__, "on_failures", on_failures)
        if on_starts is not None:
            pulumi.set(__self__, "on_starts", on_starts)
        if on_streaming_backlog_exceededs is not None:
            pulumi.set(__self__, "on_streaming_backlog_exceededs", on_streaming_backlog_exceededs)
        if on_successes is not None:
            pulumi.set(__self__, "on_successes", on_successes)

    @property
    @pulumi.getter(name="noAlertForSkippedRuns")
    def no_alert_for_skipped_runs(self) -> Optional[bool]:
        """
        (Bool) don't send alert for skipped runs. (It's recommended to use the corresponding setting in the `notification_settings` configuration block).
        """
        return pulumi.get(self, "no_alert_for_skipped_runs")

    @property
    @pulumi.getter(name="onDurationWarningThresholdExceededs")
    def on_duration_warning_threshold_exceededs(self) -> Optional[Sequence[str]]:
        """
        (List) list of emails to notify when the duration of a run exceeds the threshold specified by the `RUN_DURATION_SECONDS` metric in the `health` block.

        The following parameter is only available for the job level configuration.
        """
        return pulumi.get(self, "on_duration_warning_threshold_exceededs")

    @property
    @pulumi.getter(name="onFailures")
    def on_failures(self) -> Optional[Sequence[str]]:
        """
        (List) list of emails to notify when the run fails.
        """
        return pulumi.get(self, "on_failures")

    @property
    @pulumi.getter(name="onStarts")
    def on_starts(self) -> Optional[Sequence[str]]:
        """
        (List) list of emails to notify when the run starts.
        """
        return pulumi.get(self, "on_starts")

    @property
    @pulumi.getter(name="onStreamingBacklogExceededs")
    def on_streaming_backlog_exceededs(self) -> Optional[Sequence[str]]:
        return pulumi.get(self, "on_streaming_backlog_exceededs")

    @property
    @pulumi.getter(name="onSuccesses")
    def on_successes(self) -> Optional[Sequence[str]]:
        """
        (List) list of emails to notify when the run completes successfully.
        """
        return pulumi.get(self, "on_successes")


@pulumi.output_type
class JobTaskForEachTaskTaskHealth(dict):
    def __init__(__self__, *,
                 rules: Sequence['outputs.JobTaskForEachTaskTaskHealthRule']):
        """
        :param Sequence['JobTaskForEachTaskTaskHealthRuleArgs'] rules: list of rules that are represented as objects with the following attributes:
        """
        pulumi.set(__self__, "rules", rules)

    @property
    @pulumi.getter
    def rules(self) -> Sequence['outputs.JobTaskForEachTaskTaskHealthRule']:
        """
        list of rules that are represented as objects with the following attributes:
        """
        return pulumi.get(self, "rules")


@pulumi.output_type
class JobTaskForEachTaskTaskHealthRule(dict):
    def __init__(__self__, *,
                 metric: str,
                 op: str,
                 value: int):
        """
        :param str metric: string specifying the metric to check.  The only supported metric is `RUN_DURATION_SECONDS` (check [Jobs REST API documentation](https://docs.databricks.com/api/workspace/jobs/create) for the latest information).
        :param str op: string specifying the operation used to evaluate the given metric. The only supported operation is `GREATER_THAN`.
        :param int value: integer value used to compare to the given metric.
        """
        pulumi.set(__self__, "metric", metric)
        pulumi.set(__self__, "op", op)
        pulumi.set(__self__, "value", value)

    @property
    @pulumi.getter
    def metric(self) -> str:
        """
        string specifying the metric to check.  The only supported metric is `RUN_DURATION_SECONDS` (check [Jobs REST API documentation](https://docs.databricks.com/api/workspace/jobs/create) for the latest information).
        """
        return pulumi.get(self, "metric")

    @property
    @pulumi.getter
    def op(self) -> str:
        """
        string specifying the operation used to evaluate the given metric. The only supported operation is `GREATER_THAN`.
        """
        return pulumi.get(self, "op")

    @property
    @pulumi.getter
    def value(self) -> int:
        """
        integer value used to compare to the given metric.
        """
        return pulumi.get(self, "value")


@pulumi.output_type
class JobTaskForEachTaskTaskLibrary(dict):
    def __init__(__self__, *,
                 cran: Optional['outputs.JobTaskForEachTaskTaskLibraryCran'] = None,
                 egg: Optional[str] = None,
                 jar: Optional[str] = None,
                 maven: Optional['outputs.JobTaskForEachTaskTaskLibraryMaven'] = None,
                 pypi: Optional['outputs.JobTaskForEachTaskTaskLibraryPypi'] = None,
                 requirements: Optional[str] = None,
                 whl: Optional[str] = None):
        if cran is not None:
            pulumi.set(__self__, "cran", cran)
        if egg is not None:
            pulumi.set(__self__, "egg", egg)
        if jar is not None:
            pulumi.set(__self__, "jar", jar)
        if maven is not None:
            pulumi.set(__self__, "maven", maven)
        if pypi is not None:
            pulumi.set(__self__, "pypi", pypi)
        if requirements is not None:
            pulumi.set(__self__, "requirements", requirements)
        if whl is not None:
            pulumi.set(__self__, "whl", whl)

    @property
    @pulumi.getter
    def cran(self) -> Optional['outputs.JobTaskForEachTaskTaskLibraryCran']:
        return pulumi.get(self, "cran")

    @property
    @pulumi.getter
    def egg(self) -> Optional[str]:
        return pulumi.get(self, "egg")

    @property
    @pulumi.getter
    def jar(self) -> Optional[str]:
        return pulumi.get(self, "jar")

    @property
    @pulumi.getter
    def maven(self) -> Optional['outputs.JobTaskForEachTaskTaskLibraryMaven']:
        return pulumi.get(self, "maven")

    @property
    @pulumi.getter
    def pypi(self) -> Optional['outputs.JobTaskForEachTaskTaskLibraryPypi']:
        return pulumi.get(self, "pypi")

    @property
    @pulumi.getter
    def requirements(self) -> Optional[str]:
        return pulumi.get(self, "requirements")

    @property
    @pulumi.getter
    def whl(self) -> Optional[str]:
        return pulumi.get(self, "whl")


@pulumi.output_type
class JobTaskForEachTaskTaskLibraryCran(dict):
    def __init__(__self__, *,
                 package: str,
                 repo: Optional[str] = None):
        pulumi.set(__self__, "package", package)
        if repo is not None:
            pulumi.set(__self__, "repo", repo)

    @property
    @pulumi.getter
    def package(self) -> str:
        return pulumi.get(self, "package")

    @property
    @pulumi.getter
    def repo(self) -> Optional[str]:
        return pulumi.get(self, "repo")


@pulumi.output_type
class JobTaskForEachTaskTaskLibraryMaven(dict):
    def __init__(__self__, *,
                 coordinates: str,
                 exclusions: Optional[Sequence[str]] = None,
                 repo: Optional[str] = None):
        pulumi.set(__self__, "coordinates", coordinates)
        if exclusions is not None:
            pulumi.set(__self__, "exclusions", exclusions)
        if repo is not None:
            pulumi.set(__self__, "repo", repo)

    @property
    @pulumi.getter
    def coordinates(self) -> str:
        return pulumi.get(self, "coordinates")

    @property
    @pulumi.getter
    def exclusions(self) -> Optional[Sequence[str]]:
        return pulumi.get(self, "exclusions")

    @property
    @pulumi.getter
    def repo(self) -> Optional[str]:
        return pulumi.get(self, "repo")


@pulumi.output_type
class JobTaskForEachTaskTaskLibraryPypi(dict):
    def __init__(__self__, *,
                 package: str,
                 repo: Optional[str] = None):
        pulumi.set(__self__, "package", package)
        if repo is not None:
            pulumi.set(__self__, "repo", repo)

    @property
    @pulumi.getter
    def package(self) -> str:
        return pulumi.get(self, "package")

    @property
    @pulumi.getter
    def repo(self) -> Optional[str]:
        return pulumi.get(self, "repo")


@pulumi.output_type
class JobTaskForEachTaskTaskNewCluster(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "sparkVersion":
            suggest = "spark_version"
        elif key == "applyPolicyDefaultValues":
            suggest = "apply_policy_default_values"
        elif key == "awsAttributes":
            suggest = "aws_attributes"
        elif key == "azureAttributes":
            suggest = "azure_attributes"
        elif key == "clusterId":
            suggest = "cluster_id"
        elif key == "clusterLogConf":
            suggest = "cluster_log_conf"
        elif key == "clusterMountInfos":
            suggest = "cluster_mount_infos"
        elif key == "clusterName":
            suggest = "cluster_name"
        elif key == "customTags":
            suggest = "custom_tags"
        elif key == "dataSecurityMode":
            suggest = "data_security_mode"
        elif key == "dockerImage":
            suggest = "docker_image"
        elif key == "driverInstancePoolId":
            suggest = "driver_instance_pool_id"
        elif key == "driverNodeTypeId":
            suggest = "driver_node_type_id"
        elif key == "enableElasticDisk":
            suggest = "enable_elastic_disk"
        elif key == "enableLocalDiskEncryption":
            suggest = "enable_local_disk_encryption"
        elif key == "gcpAttributes":
            suggest = "gcp_attributes"
        elif key == "idempotencyToken":
            suggest = "idempotency_token"
        elif key == "initScripts":
            suggest = "init_scripts"
        elif key == "instancePoolId":
            suggest = "instance_pool_id"
        elif key == "nodeTypeId":
            suggest = "node_type_id"
        elif key == "numWorkers":
            suggest = "num_workers"
        elif key == "policyId":
            suggest = "policy_id"
        elif key == "runtimeEngine":
            suggest = "runtime_engine"
        elif key == "singleUserName":
            suggest = "single_user_name"
        elif key == "sparkConf":
            suggest = "spark_conf"
        elif key == "sparkEnvVars":
            suggest = "spark_env_vars"
        elif key == "sshPublicKeys":
            suggest = "ssh_public_keys"
        elif key == "workloadType":
            suggest = "workload_type"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in JobTaskForEachTaskTaskNewCluster. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        JobTaskForEachTaskTaskNewCluster.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        JobTaskForEachTaskTaskNewCluster.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 spark_version: str,
                 apply_policy_default_values: Optional[bool] = None,
                 autoscale: Optional['outputs.JobTaskForEachTaskTaskNewClusterAutoscale'] = None,
                 aws_attributes: Optional['outputs.JobTaskForEachTaskTaskNewClusterAwsAttributes'] = None,
                 azure_attributes: Optional['outputs.JobTaskForEachTaskTaskNewClusterAzureAttributes'] = None,
                 cluster_id: Optional[str] = None,
                 cluster_log_conf: Optional['outputs.JobTaskForEachTaskTaskNewClusterClusterLogConf'] = None,
                 cluster_mount_infos: Optional[Sequence['outputs.JobTaskForEachTaskTaskNewClusterClusterMountInfo']] = None,
                 cluster_name: Optional[str] = None,
                 custom_tags: Optional[Mapping[str, str]] = None,
                 data_security_mode: Optional[str] = None,
                 docker_image: Optional['outputs.JobTaskForEachTaskTaskNewClusterDockerImage'] = None,
                 driver_instance_pool_id: Optional[str] = None,
                 driver_node_type_id: Optional[str] = None,
                 enable_elastic_disk: Optional[bool] = None,
                 enable_local_disk_encryption: Optional[bool] = None,
                 gcp_attributes: Optional['outputs.JobTaskForEachTaskTaskNewClusterGcpAttributes'] = None,
                 idempotency_token: Optional[str] = None,
                 init_scripts: Optional[Sequence['outputs.JobTaskForEachTaskTaskNewClusterInitScript']] = None,
                 instance_pool_id: Optional[str] = None,
                 libraries: Optional[Sequence['outputs.JobTaskForEachTaskTaskNewClusterLibrary']] = None,
                 node_type_id: Optional[str] = None,
                 num_workers: Optional[int] = None,
                 policy_id: Optional[str] = None,
                 runtime_engine: Optional[str] = None,
                 single_user_name: Optional[str] = None,
                 spark_conf: Optional[Mapping[str, str]] = None,
                 spark_env_vars: Optional[Mapping[str, str]] = None,
                 ssh_public_keys: Optional[Sequence[str]] = None,
                 workload_type: Optional['outputs.JobTaskForEachTaskTaskNewClusterWorkloadType'] = None):
        """
        :param Sequence['JobTaskForEachTaskTaskNewClusterLibraryArgs'] libraries: (List) An optional list of libraries to be installed on the cluster that will execute the job. See library Configuration Block below.
        :param 'JobTaskForEachTaskTaskNewClusterWorkloadTypeArgs' workload_type: isn't supported
        """
        pulumi.set(__self__, "spark_version", spark_version)
        if apply_policy_default_values is not None:
            pulumi.set(__self__, "apply_policy_default_values", apply_policy_default_values)
        if autoscale is not None:
            pulumi.set(__self__, "autoscale", autoscale)
        if aws_attributes is not None:
            pulumi.set(__self__, "aws_attributes", aws_attributes)
        if azure_attributes is not None:
            pulumi.set(__self__, "azure_attributes", azure_attributes)
        if cluster_id is not None:
            pulumi.set(__self__, "cluster_id", cluster_id)
        if cluster_log_conf is not None:
            pulumi.set(__self__, "cluster_log_conf", cluster_log_conf)
        if cluster_mount_infos is not None:
            pulumi.set(__self__, "cluster_mount_infos", cluster_mount_infos)
        if cluster_name is not None:
            pulumi.set(__self__, "cluster_name", cluster_name)
        if custom_tags is not None:
            pulumi.set(__self__, "custom_tags", custom_tags)
        if data_security_mode is not None:
            pulumi.set(__self__, "data_security_mode", data_security_mode)
        if docker_image is not None:
            pulumi.set(__self__, "docker_image", docker_image)
        if driver_instance_pool_id is not None:
            pulumi.set(__self__, "driver_instance_pool_id", driver_instance_pool_id)
        if driver_node_type_id is not None:
            pulumi.set(__self__, "driver_node_type_id", driver_node_type_id)
        if enable_elastic_disk is not None:
            pulumi.set(__self__, "enable_elastic_disk", enable_elastic_disk)
        if enable_local_disk_encryption is not None:
            pulumi.set(__self__, "enable_local_disk_encryption", enable_local_disk_encryption)
        if gcp_attributes is not None:
            pulumi.set(__self__, "gcp_attributes", gcp_attributes)
        if idempotency_token is not None:
            pulumi.set(__self__, "idempotency_token", idempotency_token)
        if init_scripts is not None:
            pulumi.set(__self__, "init_scripts", init_scripts)
        if instance_pool_id is not None:
            pulumi.set(__self__, "instance_pool_id", instance_pool_id)
        if libraries is not None:
            pulumi.set(__self__, "libraries", libraries)
        if node_type_id is not None:
            pulumi.set(__self__, "node_type_id", node_type_id)
        if num_workers is not None:
            pulumi.set(__self__, "num_workers", num_workers)
        if policy_id is not None:
            pulumi.set(__self__, "policy_id", policy_id)
        if runtime_engine is not None:
            pulumi.set(__self__, "runtime_engine", runtime_engine)
        if single_user_name is not None:
            pulumi.set(__self__, "single_user_name", single_user_name)
        if spark_conf is not None:
            pulumi.set(__self__, "spark_conf", spark_conf)
        if spark_env_vars is not None:
            pulumi.set(__self__, "spark_env_vars", spark_env_vars)
        if ssh_public_keys is not None:
            pulumi.set(__self__, "ssh_public_keys", ssh_public_keys)
        if workload_type is not None:
            pulumi.set(__self__, "workload_type", workload_type)

    @property
    @pulumi.getter(name="sparkVersion")
    def spark_version(self) -> str:
        return pulumi.get(self, "spark_version")

    @property
    @pulumi.getter(name="applyPolicyDefaultValues")
    def apply_policy_default_values(self) -> Optional[bool]:
        return pulumi.get(self, "apply_policy_default_values")

    @property
    @pulumi.getter
    def autoscale(self) -> Optional['outputs.JobTaskForEachTaskTaskNewClusterAutoscale']:
        return pulumi.get(self, "autoscale")

    @property
    @pulumi.getter(name="awsAttributes")
    def aws_attributes(self) -> Optional['outputs.JobTaskForEachTaskTaskNewClusterAwsAttributes']:
        return pulumi.get(self, "aws_attributes")

    @property
    @pulumi.getter(name="azureAttributes")
    def azure_attributes(self) -> Optional['outputs.JobTaskForEachTaskTaskNewClusterAzureAttributes']:
        return pulumi.get(self, "azure_attributes")

    @property
    @pulumi.getter(name="clusterId")
    def cluster_id(self) -> Optional[str]:
        return pulumi.get(self, "cluster_id")

    @property
    @pulumi.getter(name="clusterLogConf")
    def cluster_log_conf(self) -> Optional['outputs.JobTaskForEachTaskTaskNewClusterClusterLogConf']:
        return pulumi.get(self, "cluster_log_conf")

    @property
    @pulumi.getter(name="clusterMountInfos")
    def cluster_mount_infos(self) -> Optional[Sequence['outputs.JobTaskForEachTaskTaskNewClusterClusterMountInfo']]:
        return pulumi.get(self, "cluster_mount_infos")

    @property
    @pulumi.getter(name="clusterName")
    def cluster_name(self) -> Optional[str]:
        return pulumi.get(self, "cluster_name")

    @property
    @pulumi.getter(name="customTags")
    def custom_tags(self) -> Optional[Mapping[str, str]]:
        return pulumi.get(self, "custom_tags")

    @property
    @pulumi.getter(name="dataSecurityMode")
    def data_security_mode(self) -> Optional[str]:
        return pulumi.get(self, "data_security_mode")

    @property
    @pulumi.getter(name="dockerImage")
    def docker_image(self) -> Optional['outputs.JobTaskForEachTaskTaskNewClusterDockerImage']:
        return pulumi.get(self, "docker_image")

    @property
    @pulumi.getter(name="driverInstancePoolId")
    def driver_instance_pool_id(self) -> Optional[str]:
        return pulumi.get(self, "driver_instance_pool_id")

    @property
    @pulumi.getter(name="driverNodeTypeId")
    def driver_node_type_id(self) -> Optional[str]:
        return pulumi.get(self, "driver_node_type_id")

    @property
    @pulumi.getter(name="enableElasticDisk")
    def enable_elastic_disk(self) -> Optional[bool]:
        return pulumi.get(self, "enable_elastic_disk")

    @property
    @pulumi.getter(name="enableLocalDiskEncryption")
    def enable_local_disk_encryption(self) -> Optional[bool]:
        return pulumi.get(self, "enable_local_disk_encryption")

    @property
    @pulumi.getter(name="gcpAttributes")
    def gcp_attributes(self) -> Optional['outputs.JobTaskForEachTaskTaskNewClusterGcpAttributes']:
        return pulumi.get(self, "gcp_attributes")

    @property
    @pulumi.getter(name="idempotencyToken")
    def idempotency_token(self) -> Optional[str]:
        return pulumi.get(self, "idempotency_token")

    @property
    @pulumi.getter(name="initScripts")
    def init_scripts(self) -> Optional[Sequence['outputs.JobTaskForEachTaskTaskNewClusterInitScript']]:
        return pulumi.get(self, "init_scripts")

    @property
    @pulumi.getter(name="instancePoolId")
    def instance_pool_id(self) -> Optional[str]:
        return pulumi.get(self, "instance_pool_id")

    @property
    @pulumi.getter
    def libraries(self) -> Optional[Sequence['outputs.JobTaskForEachTaskTaskNewClusterLibrary']]:
        """
        (List) An optional list of libraries to be installed on the cluster that will execute the job. See library Configuration Block below.
        """
        return pulumi.get(self, "libraries")

    @property
    @pulumi.getter(name="nodeTypeId")
    def node_type_id(self) -> Optional[str]:
        return pulumi.get(self, "node_type_id")

    @property
    @pulumi.getter(name="numWorkers")
    def num_workers(self) -> Optional[int]:
        return pulumi.get(self, "num_workers")

    @property
    @pulumi.getter(name="policyId")
    def policy_id(self) -> Optional[str]:
        return pulumi.get(self, "policy_id")

    @property
    @pulumi.getter(name="runtimeEngine")
    def runtime_engine(self) -> Optional[str]:
        return pulumi.get(self, "runtime_engine")

    @property
    @pulumi.getter(name="singleUserName")
    def single_user_name(self) -> Optional[str]:
        return pulumi.get(self, "single_user_name")

    @property
    @pulumi.getter(name="sparkConf")
    def spark_conf(self) -> Optional[Mapping[str, str]]:
        return pulumi.get(self, "spark_conf")

    @property
    @pulumi.getter(name="sparkEnvVars")
    def spark_env_vars(self) -> Optional[Mapping[str, str]]:
        return pulumi.get(self, "spark_env_vars")

    @property
    @pulumi.getter(name="sshPublicKeys")
    def ssh_public_keys(self) -> Optional[Sequence[str]]:
        return pulumi.get(self, "ssh_public_keys")

    @property
    @pulumi.getter(name="workloadType")
    def workload_type(self) -> Optional['outputs.JobTaskForEachTaskTaskNewClusterWorkloadType']:
        """
        isn't supported
        """
        return pulumi.get(self, "workload_type")


@pulumi.output_type
class JobTaskForEachTaskTaskNewClusterAutoscale(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "maxWorkers":
            suggest = "max_workers"
        elif key == "minWorkers":
            suggest = "min_workers"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in JobTaskForEachTaskTaskNewClusterAutoscale. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        JobTaskForEachTaskTaskNewClusterAutoscale.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        JobTaskForEachTaskTaskNewClusterAutoscale.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 max_workers: Optional[int] = None,
                 min_workers: Optional[int] = None):
        if max_workers is not None:
            pulumi.set(__self__, "max_workers", max_workers)
        if min_workers is not None:
            pulumi.set(__self__, "min_workers", min_workers)

    @property
    @pulumi.getter(name="maxWorkers")
    def max_workers(self) -> Optional[int]:
        return pulumi.get(self, "max_workers")

    @property
    @pulumi.getter(name="minWorkers")
    def min_workers(self) -> Optional[int]:
        return pulumi.get(self, "min_workers")


@pulumi.output_type
class JobTaskForEachTaskTaskNewClusterAwsAttributes(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "ebsVolumeCount":
            suggest = "ebs_volume_count"
        elif key == "ebsVolumeIops":
            suggest = "ebs_volume_iops"
        elif key == "ebsVolumeSize":
            suggest = "ebs_volume_size"
        elif key == "ebsVolumeThroughput":
            suggest = "ebs_volume_throughput"
        elif key == "ebsVolumeType":
            suggest = "ebs_volume_type"
        elif key == "firstOnDemand":
            suggest = "first_on_demand"
        elif key == "instanceProfileArn":
            suggest = "instance_profile_arn"
        elif key == "spotBidPricePercent":
            suggest = "spot_bid_price_percent"
        elif key == "zoneId":
            suggest = "zone_id"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in JobTaskForEachTaskTaskNewClusterAwsAttributes. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        JobTaskForEachTaskTaskNewClusterAwsAttributes.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        JobTaskForEachTaskTaskNewClusterAwsAttributes.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 availability: Optional[str] = None,
                 ebs_volume_count: Optional[int] = None,
                 ebs_volume_iops: Optional[int] = None,
                 ebs_volume_size: Optional[int] = None,
                 ebs_volume_throughput: Optional[int] = None,
                 ebs_volume_type: Optional[str] = None,
                 first_on_demand: Optional[int] = None,
                 instance_profile_arn: Optional[str] = None,
                 spot_bid_price_percent: Optional[int] = None,
                 zone_id: Optional[str] = None):
        if availability is not None:
            pulumi.set(__self__, "availability", availability)
        if ebs_volume_count is not None:
            pulumi.set(__self__, "ebs_volume_count", ebs_volume_count)
        if ebs_volume_iops is not None:
            pulumi.set(__self__, "ebs_volume_iops", ebs_volume_iops)
        if ebs_volume_size is not None:
            pulumi.set(__self__, "ebs_volume_size", ebs_volume_size)
        if ebs_volume_throughput is not None:
            pulumi.set(__self__, "ebs_volume_throughput", ebs_volume_throughput)
        if ebs_volume_type is not None:
            pulumi.set(__self__, "ebs_volume_type", ebs_volume_type)
        if first_on_demand is not None:
            pulumi.set(__self__, "first_on_demand", first_on_demand)
        if instance_profile_arn is not None:
            pulumi.set(__self__, "instance_profile_arn", instance_profile_arn)
        if spot_bid_price_percent is not None:
            pulumi.set(__self__, "spot_bid_price_percent", spot_bid_price_percent)
        if zone_id is not None:
            pulumi.set(__self__, "zone_id", zone_id)

    @property
    @pulumi.getter
    def availability(self) -> Optional[str]:
        return pulumi.get(self, "availability")

    @property
    @pulumi.getter(name="ebsVolumeCount")
    def ebs_volume_count(self) -> Optional[int]:
        return pulumi.get(self, "ebs_volume_count")

    @property
    @pulumi.getter(name="ebsVolumeIops")
    def ebs_volume_iops(self) -> Optional[int]:
        return pulumi.get(self, "ebs_volume_iops")

    @property
    @pulumi.getter(name="ebsVolumeSize")
    def ebs_volume_size(self) -> Optional[int]:
        return pulumi.get(self, "ebs_volume_size")

    @property
    @pulumi.getter(name="ebsVolumeThroughput")
    def ebs_volume_throughput(self) -> Optional[int]:
        return pulumi.get(self, "ebs_volume_throughput")

    @property
    @pulumi.getter(name="ebsVolumeType")
    def ebs_volume_type(self) -> Optional[str]:
        return pulumi.get(self, "ebs_volume_type")

    @property
    @pulumi.getter(name="firstOnDemand")
    def first_on_demand(self) -> Optional[int]:
        return pulumi.get(self, "first_on_demand")

    @property
    @pulumi.getter(name="instanceProfileArn")
    def instance_profile_arn(self) -> Optional[str]:
        return pulumi.get(self, "instance_profile_arn")

    @property
    @pulumi.getter(name="spotBidPricePercent")
    def spot_bid_price_percent(self) -> Optional[int]:
        return pulumi.get(self, "spot_bid_price_percent")

    @property
    @pulumi.getter(name="zoneId")
    def zone_id(self) -> Optional[str]:
        return pulumi.get(self, "zone_id")


@pulumi.output_type
class JobTaskForEachTaskTaskNewClusterAzureAttributes(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "firstOnDemand":
            suggest = "first_on_demand"
        elif key == "logAnalyticsInfo":
            suggest = "log_analytics_info"
        elif key == "spotBidMaxPrice":
            suggest = "spot_bid_max_price"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in JobTaskForEachTaskTaskNewClusterAzureAttributes. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        JobTaskForEachTaskTaskNewClusterAzureAttributes.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        JobTaskForEachTaskTaskNewClusterAzureAttributes.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 availability: Optional[str] = None,
                 first_on_demand: Optional[int] = None,
                 log_analytics_info: Optional['outputs.JobTaskForEachTaskTaskNewClusterAzureAttributesLogAnalyticsInfo'] = None,
                 spot_bid_max_price: Optional[float] = None):
        if availability is not None:
            pulumi.set(__self__, "availability", availability)
        if first_on_demand is not None:
            pulumi.set(__self__, "first_on_demand", first_on_demand)
        if log_analytics_info is not None:
            pulumi.set(__self__, "log_analytics_info", log_analytics_info)
        if spot_bid_max_price is not None:
            pulumi.set(__self__, "spot_bid_max_price", spot_bid_max_price)

    @property
    @pulumi.getter
    def availability(self) -> Optional[str]:
        return pulumi.get(self, "availability")

    @property
    @pulumi.getter(name="firstOnDemand")
    def first_on_demand(self) -> Optional[int]:
        return pulumi.get(self, "first_on_demand")

    @property
    @pulumi.getter(name="logAnalyticsInfo")
    def log_analytics_info(self) -> Optional['outputs.JobTaskForEachTaskTaskNewClusterAzureAttributesLogAnalyticsInfo']:
        return pulumi.get(self, "log_analytics_info")

    @property
    @pulumi.getter(name="spotBidMaxPrice")
    def spot_bid_max_price(self) -> Optional[float]:
        return pulumi.get(self, "spot_bid_max_price")


@pulumi.output_type
class JobTaskForEachTaskTaskNewClusterAzureAttributesLogAnalyticsInfo(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "logAnalyticsPrimaryKey":
            suggest = "log_analytics_primary_key"
        elif key == "logAnalyticsWorkspaceId":
            suggest = "log_analytics_workspace_id"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in JobTaskForEachTaskTaskNewClusterAzureAttributesLogAnalyticsInfo. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        JobTaskForEachTaskTaskNewClusterAzureAttributesLogAnalyticsInfo.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        JobTaskForEachTaskTaskNewClusterAzureAttributesLogAnalyticsInfo.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 log_analytics_primary_key: Optional[str] = None,
                 log_analytics_workspace_id: Optional[str] = None):
        if log_analytics_primary_key is not None:
            pulumi.set(__self__, "log_analytics_primary_key", log_analytics_primary_key)
        if log_analytics_workspace_id is not None:
            pulumi.set(__self__, "log_analytics_workspace_id", log_analytics_workspace_id)

    @property
    @pulumi.getter(name="logAnalyticsPrimaryKey")
    def log_analytics_primary_key(self) -> Optional[str]:
        return pulumi.get(self, "log_analytics_primary_key")

    @property
    @pulumi.getter(name="logAnalyticsWorkspaceId")
    def log_analytics_workspace_id(self) -> Optional[str]:
        return pulumi.get(self, "log_analytics_workspace_id")


@pulumi.output_type
class JobTaskForEachTaskTaskNewClusterClusterLogConf(dict):
    def __init__(__self__, *,
                 dbfs: Optional['outputs.JobTaskForEachTaskTaskNewClusterClusterLogConfDbfs'] = None,
                 s3: Optional['outputs.JobTaskForEachTaskTaskNewClusterClusterLogConfS3'] = None):
        if dbfs is not None:
            pulumi.set(__self__, "dbfs", dbfs)
        if s3 is not None:
            pulumi.set(__self__, "s3", s3)

    @property
    @pulumi.getter
    def dbfs(self) -> Optional['outputs.JobTaskForEachTaskTaskNewClusterClusterLogConfDbfs']:
        return pulumi.get(self, "dbfs")

    @property
    @pulumi.getter
    def s3(self) -> Optional['outputs.JobTaskForEachTaskTaskNewClusterClusterLogConfS3']:
        return pulumi.get(self, "s3")


@pulumi.output_type
class JobTaskForEachTaskTaskNewClusterClusterLogConfDbfs(dict):
    def __init__(__self__, *,
                 destination: str):
        pulumi.set(__self__, "destination", destination)

    @property
    @pulumi.getter
    def destination(self) -> str:
        return pulumi.get(self, "destination")


@pulumi.output_type
class JobTaskForEachTaskTaskNewClusterClusterLogConfS3(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "cannedAcl":
            suggest = "canned_acl"
        elif key == "enableEncryption":
            suggest = "enable_encryption"
        elif key == "encryptionType":
            suggest = "encryption_type"
        elif key == "kmsKey":
            suggest = "kms_key"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in JobTaskForEachTaskTaskNewClusterClusterLogConfS3. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        JobTaskForEachTaskTaskNewClusterClusterLogConfS3.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        JobTaskForEachTaskTaskNewClusterClusterLogConfS3.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 destination: str,
                 canned_acl: Optional[str] = None,
                 enable_encryption: Optional[bool] = None,
                 encryption_type: Optional[str] = None,
                 endpoint: Optional[str] = None,
                 kms_key: Optional[str] = None,
                 region: Optional[str] = None):
        pulumi.set(__self__, "destination", destination)
        if canned_acl is not None:
            pulumi.set(__self__, "canned_acl", canned_acl)
        if enable_encryption is not None:
            pulumi.set(__self__, "enable_encryption", enable_encryption)
        if encryption_type is not None:
            pulumi.set(__self__, "encryption_type", encryption_type)
        if endpoint is not None:
            pulumi.set(__self__, "endpoint", endpoint)
        if kms_key is not None:
            pulumi.set(__self__, "kms_key", kms_key)
        if region is not None:
            pulumi.set(__self__, "region", region)

    @property
    @pulumi.getter
    def destination(self) -> str:
        return pulumi.get(self, "destination")

    @property
    @pulumi.getter(name="cannedAcl")
    def canned_acl(self) -> Optional[str]:
        return pulumi.get(self, "canned_acl")

    @property
    @pulumi.getter(name="enableEncryption")
    def enable_encryption(self) -> Optional[bool]:
        return pulumi.get(self, "enable_encryption")

    @property
    @pulumi.getter(name="encryptionType")
    def encryption_type(self) -> Optional[str]:
        return pulumi.get(self, "encryption_type")

    @property
    @pulumi.getter
    def endpoint(self) -> Optional[str]:
        return pulumi.get(self, "endpoint")

    @property
    @pulumi.getter(name="kmsKey")
    def kms_key(self) -> Optional[str]:
        return pulumi.get(self, "kms_key")

    @property
    @pulumi.getter
    def region(self) -> Optional[str]:
        return pulumi.get(self, "region")


@pulumi.output_type
class JobTaskForEachTaskTaskNewClusterClusterMountInfo(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "localMountDirPath":
            suggest = "local_mount_dir_path"
        elif key == "networkFilesystemInfo":
            suggest = "network_filesystem_info"
        elif key == "remoteMountDirPath":
            suggest = "remote_mount_dir_path"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in JobTaskForEachTaskTaskNewClusterClusterMountInfo. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        JobTaskForEachTaskTaskNewClusterClusterMountInfo.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        JobTaskForEachTaskTaskNewClusterClusterMountInfo.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 local_mount_dir_path: str,
                 network_filesystem_info: 'outputs.JobTaskForEachTaskTaskNewClusterClusterMountInfoNetworkFilesystemInfo',
                 remote_mount_dir_path: Optional[str] = None):
        pulumi.set(__self__, "local_mount_dir_path", local_mount_dir_path)
        pulumi.set(__self__, "network_filesystem_info", network_filesystem_info)
        if remote_mount_dir_path is not None:
            pulumi.set(__self__, "remote_mount_dir_path", remote_mount_dir_path)

    @property
    @pulumi.getter(name="localMountDirPath")
    def local_mount_dir_path(self) -> str:
        return pulumi.get(self, "local_mount_dir_path")

    @property
    @pulumi.getter(name="networkFilesystemInfo")
    def network_filesystem_info(self) -> 'outputs.JobTaskForEachTaskTaskNewClusterClusterMountInfoNetworkFilesystemInfo':
        return pulumi.get(self, "network_filesystem_info")

    @property
    @pulumi.getter(name="remoteMountDirPath")
    def remote_mount_dir_path(self) -> Optional[str]:
        return pulumi.get(self, "remote_mount_dir_path")


@pulumi.output_type
class JobTaskForEachTaskTaskNewClusterClusterMountInfoNetworkFilesystemInfo(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "serverAddress":
            suggest = "server_address"
        elif key == "mountOptions":
            suggest = "mount_options"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in JobTaskForEachTaskTaskNewClusterClusterMountInfoNetworkFilesystemInfo. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        JobTaskForEachTaskTaskNewClusterClusterMountInfoNetworkFilesystemInfo.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        JobTaskForEachTaskTaskNewClusterClusterMountInfoNetworkFilesystemInfo.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 server_address: str,
                 mount_options: Optional[str] = None):
        pulumi.set(__self__, "server_address", server_address)
        if mount_options is not None:
            pulumi.set(__self__, "mount_options", mount_options)

    @property
    @pulumi.getter(name="serverAddress")
    def server_address(self) -> str:
        return pulumi.get(self, "server_address")

    @property
    @pulumi.getter(name="mountOptions")
    def mount_options(self) -> Optional[str]:
        return pulumi.get(self, "mount_options")


@pulumi.output_type
class JobTaskForEachTaskTaskNewClusterDockerImage(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "basicAuth":
            suggest = "basic_auth"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in JobTaskForEachTaskTaskNewClusterDockerImage. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        JobTaskForEachTaskTaskNewClusterDockerImage.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        JobTaskForEachTaskTaskNewClusterDockerImage.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 url: str,
                 basic_auth: Optional['outputs.JobTaskForEachTaskTaskNewClusterDockerImageBasicAuth'] = None):
        """
        :param str url: URL of the job on the given workspace
        """
        pulumi.set(__self__, "url", url)
        if basic_auth is not None:
            pulumi.set(__self__, "basic_auth", basic_auth)

    @property
    @pulumi.getter
    def url(self) -> str:
        """
        URL of the job on the given workspace
        """
        return pulumi.get(self, "url")

    @property
    @pulumi.getter(name="basicAuth")
    def basic_auth(self) -> Optional['outputs.JobTaskForEachTaskTaskNewClusterDockerImageBasicAuth']:
        return pulumi.get(self, "basic_auth")


@pulumi.output_type
class JobTaskForEachTaskTaskNewClusterDockerImageBasicAuth(dict):
    def __init__(__self__, *,
                 password: str,
                 username: str):
        pulumi.set(__self__, "password", password)
        pulumi.set(__self__, "username", username)

    @property
    @pulumi.getter
    def password(self) -> str:
        return pulumi.get(self, "password")

    @property
    @pulumi.getter
    def username(self) -> str:
        return pulumi.get(self, "username")


@pulumi.output_type
class JobTaskForEachTaskTaskNewClusterGcpAttributes(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "bootDiskSize":
            suggest = "boot_disk_size"
        elif key == "googleServiceAccount":
            suggest = "google_service_account"
        elif key == "localSsdCount":
            suggest = "local_ssd_count"
        elif key == "usePreemptibleExecutors":
            suggest = "use_preemptible_executors"
        elif key == "zoneId":
            suggest = "zone_id"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in JobTaskForEachTaskTaskNewClusterGcpAttributes. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        JobTaskForEachTaskTaskNewClusterGcpAttributes.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        JobTaskForEachTaskTaskNewClusterGcpAttributes.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 availability: Optional[str] = None,
                 boot_disk_size: Optional[int] = None,
                 google_service_account: Optional[str] = None,
                 local_ssd_count: Optional[int] = None,
                 use_preemptible_executors: Optional[bool] = None,
                 zone_id: Optional[str] = None):
        if availability is not None:
            pulumi.set(__self__, "availability", availability)
        if boot_disk_size is not None:
            pulumi.set(__self__, "boot_disk_size", boot_disk_size)
        if google_service_account is not None:
            pulumi.set(__self__, "google_service_account", google_service_account)
        if local_ssd_count is not None:
            pulumi.set(__self__, "local_ssd_count", local_ssd_count)
        if use_preemptible_executors is not None:
            pulumi.set(__self__, "use_preemptible_executors", use_preemptible_executors)
        if zone_id is not None:
            pulumi.set(__self__, "zone_id", zone_id)

    @property
    @pulumi.getter
    def availability(self) -> Optional[str]:
        return pulumi.get(self, "availability")

    @property
    @pulumi.getter(name="bootDiskSize")
    def boot_disk_size(self) -> Optional[int]:
        return pulumi.get(self, "boot_disk_size")

    @property
    @pulumi.getter(name="googleServiceAccount")
    def google_service_account(self) -> Optional[str]:
        return pulumi.get(self, "google_service_account")

    @property
    @pulumi.getter(name="localSsdCount")
    def local_ssd_count(self) -> Optional[int]:
        return pulumi.get(self, "local_ssd_count")

    @property
    @pulumi.getter(name="usePreemptibleExecutors")
    def use_preemptible_executors(self) -> Optional[bool]:
        return pulumi.get(self, "use_preemptible_executors")

    @property
    @pulumi.getter(name="zoneId")
    def zone_id(self) -> Optional[str]:
        return pulumi.get(self, "zone_id")


@pulumi.output_type
class JobTaskForEachTaskTaskNewClusterInitScript(dict):
    def __init__(__self__, *,
                 abfss: Optional['outputs.JobTaskForEachTaskTaskNewClusterInitScriptAbfss'] = None,
                 dbfs: Optional['outputs.JobTaskForEachTaskTaskNewClusterInitScriptDbfs'] = None,
                 file: Optional['outputs.JobTaskForEachTaskTaskNewClusterInitScriptFile'] = None,
                 gcs: Optional['outputs.JobTaskForEachTaskTaskNewClusterInitScriptGcs'] = None,
                 s3: Optional['outputs.JobTaskForEachTaskTaskNewClusterInitScriptS3'] = None,
                 volumes: Optional['outputs.JobTaskForEachTaskTaskNewClusterInitScriptVolumes'] = None,
                 workspace: Optional['outputs.JobTaskForEachTaskTaskNewClusterInitScriptWorkspace'] = None):
        """
        :param 'JobTaskForEachTaskTaskNewClusterInitScriptFileArgs' file: block consisting of single string fields:
        """
        if abfss is not None:
            pulumi.set(__self__, "abfss", abfss)
        if dbfs is not None:
            pulumi.set(__self__, "dbfs", dbfs)
        if file is not None:
            pulumi.set(__self__, "file", file)
        if gcs is not None:
            pulumi.set(__self__, "gcs", gcs)
        if s3 is not None:
            pulumi.set(__self__, "s3", s3)
        if volumes is not None:
            pulumi.set(__self__, "volumes", volumes)
        if workspace is not None:
            pulumi.set(__self__, "workspace", workspace)

    @property
    @pulumi.getter
    def abfss(self) -> Optional['outputs.JobTaskForEachTaskTaskNewClusterInitScriptAbfss']:
        return pulumi.get(self, "abfss")

    @property
    @pulumi.getter
    @_utilities.deprecated("""For init scripts use 'volumes', 'workspace' or cloud storage location instead of 'dbfs'.""")
    def dbfs(self) -> Optional['outputs.JobTaskForEachTaskTaskNewClusterInitScriptDbfs']:
        return pulumi.get(self, "dbfs")

    @property
    @pulumi.getter
    def file(self) -> Optional['outputs.JobTaskForEachTaskTaskNewClusterInitScriptFile']:
        """
        block consisting of single string fields:
        """
        return pulumi.get(self, "file")

    @property
    @pulumi.getter
    def gcs(self) -> Optional['outputs.JobTaskForEachTaskTaskNewClusterInitScriptGcs']:
        return pulumi.get(self, "gcs")

    @property
    @pulumi.getter
    def s3(self) -> Optional['outputs.JobTaskForEachTaskTaskNewClusterInitScriptS3']:
        return pulumi.get(self, "s3")

    @property
    @pulumi.getter
    def volumes(self) -> Optional['outputs.JobTaskForEachTaskTaskNewClusterInitScriptVolumes']:
        return pulumi.get(self, "volumes")

    @property
    @pulumi.getter
    def workspace(self) -> Optional['outputs.JobTaskForEachTaskTaskNewClusterInitScriptWorkspace']:
        return pulumi.get(self, "workspace")


@pulumi.output_type
class JobTaskForEachTaskTaskNewClusterInitScriptAbfss(dict):
    def __init__(__self__, *,
                 destination: str):
        pulumi.set(__self__, "destination", destination)

    @property
    @pulumi.getter
    def destination(self) -> str:
        return pulumi.get(self, "destination")


@pulumi.output_type
class JobTaskForEachTaskTaskNewClusterInitScriptDbfs(dict):
    def __init__(__self__, *,
                 destination: str):
        pulumi.set(__self__, "destination", destination)

    @property
    @pulumi.getter
    def destination(self) -> str:
        return pulumi.get(self, "destination")


@pulumi.output_type
class JobTaskForEachTaskTaskNewClusterInitScriptFile(dict):
    def __init__(__self__, *,
                 destination: str):
        pulumi.set(__self__, "destination", destination)

    @property
    @pulumi.getter
    def destination(self) -> str:
        return pulumi.get(self, "destination")


@pulumi.output_type
class JobTaskForEachTaskTaskNewClusterInitScriptGcs(dict):
    def __init__(__self__, *,
                 destination: str):
        pulumi.set(__self__, "destination", destination)

    @property
    @pulumi.getter
    def destination(self) -> str:
        return pulumi.get(self, "destination")


@pulumi.output_type
class JobTaskForEachTaskTaskNewClusterInitScriptS3(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "cannedAcl":
            suggest = "canned_acl"
        elif key == "enableEncryption":
            suggest = "enable_encryption"
        elif key == "encryptionType":
            suggest = "encryption_type"
        elif key == "kmsKey":
            suggest = "kms_key"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in JobTaskForEachTaskTaskNewClusterInitScriptS3. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        JobTaskForEachTaskTaskNewClusterInitScriptS3.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        JobTaskForEachTaskTaskNewClusterInitScriptS3.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 destination: str,
                 canned_acl: Optional[str] = None,
                 enable_encryption: Optional[bool] = None,
                 encryption_type: Optional[str] = None,
                 endpoint: Optional[str] = None,
                 kms_key: Optional[str] = None,
                 region: Optional[str] = None):
        pulumi.set(__self__, "destination", destination)
        if canned_acl is not None:
            pulumi.set(__self__, "canned_acl", canned_acl)
        if enable_encryption is not None:
            pulumi.set(__self__, "enable_encryption", enable_encryption)
        if encryption_type is not None:
            pulumi.set(__self__, "encryption_type", encryption_type)
        if endpoint is not None:
            pulumi.set(__self__, "endpoint", endpoint)
        if kms_key is not None:
            pulumi.set(__self__, "kms_key", kms_key)
        if region is not None:
            pulumi.set(__self__, "region", region)

    @property
    @pulumi.getter
    def destination(self) -> str:
        return pulumi.get(self, "destination")

    @property
    @pulumi.getter(name="cannedAcl")
    def canned_acl(self) -> Optional[str]:
        return pulumi.get(self, "canned_acl")

    @property
    @pulumi.getter(name="enableEncryption")
    def enable_encryption(self) -> Optional[bool]:
        return pulumi.get(self, "enable_encryption")

    @property
    @pulumi.getter(name="encryptionType")
    def encryption_type(self) -> Optional[str]:
        return pulumi.get(self, "encryption_type")

    @property
    @pulumi.getter
    def endpoint(self) -> Optional[str]:
        return pulumi.get(self, "endpoint")

    @property
    @pulumi.getter(name="kmsKey")
    def kms_key(self) -> Optional[str]:
        return pulumi.get(self, "kms_key")

    @property
    @pulumi.getter
    def region(self) -> Optional[str]:
        return pulumi.get(self, "region")


@pulumi.output_type
class JobTaskForEachTaskTaskNewClusterInitScriptVolumes(dict):
    def __init__(__self__, *,
                 destination: str):
        pulumi.set(__self__, "destination", destination)

    @property
    @pulumi.getter
    def destination(self) -> str:
        return pulumi.get(self, "destination")


@pulumi.output_type
class JobTaskForEachTaskTaskNewClusterInitScriptWorkspace(dict):
    def __init__(__self__, *,
                 destination: str):
        pulumi.set(__self__, "destination", destination)

    @property
    @pulumi.getter
    def destination(self) -> str:
        return pulumi.get(self, "destination")


@pulumi.output_type
class JobTaskForEachTaskTaskNewClusterLibrary(dict):
    def __init__(__self__, *,
                 cran: Optional['outputs.JobTaskForEachTaskTaskNewClusterLibraryCran'] = None,
                 egg: Optional[str] = None,
                 jar: Optional[str] = None,
                 maven: Optional['outputs.JobTaskForEachTaskTaskNewClusterLibraryMaven'] = None,
                 pypi: Optional['outputs.JobTaskForEachTaskTaskNewClusterLibraryPypi'] = None,
                 requirements: Optional[str] = None,
                 whl: Optional[str] = None):
        if cran is not None:
            pulumi.set(__self__, "cran", cran)
        if egg is not None:
            pulumi.set(__self__, "egg", egg)
        if jar is not None:
            pulumi.set(__self__, "jar", jar)
        if maven is not None:
            pulumi.set(__self__, "maven", maven)
        if pypi is not None:
            pulumi.set(__self__, "pypi", pypi)
        if requirements is not None:
            pulumi.set(__self__, "requirements", requirements)
        if whl is not None:
            pulumi.set(__self__, "whl", whl)

    @property
    @pulumi.getter
    def cran(self) -> Optional['outputs.JobTaskForEachTaskTaskNewClusterLibraryCran']:
        return pulumi.get(self, "cran")

    @property
    @pulumi.getter
    def egg(self) -> Optional[str]:
        return pulumi.get(self, "egg")

    @property
    @pulumi.getter
    def jar(self) -> Optional[str]:
        return pulumi.get(self, "jar")

    @property
    @pulumi.getter
    def maven(self) -> Optional['outputs.JobTaskForEachTaskTaskNewClusterLibraryMaven']:
        return pulumi.get(self, "maven")

    @property
    @pulumi.getter
    def pypi(self) -> Optional['outputs.JobTaskForEachTaskTaskNewClusterLibraryPypi']:
        return pulumi.get(self, "pypi")

    @property
    @pulumi.getter
    def requirements(self) -> Optional[str]:
        return pulumi.get(self, "requirements")

    @property
    @pulumi.getter
    def whl(self) -> Optional[str]:
        return pulumi.get(self, "whl")


@pulumi.output_type
class JobTaskForEachTaskTaskNewClusterLibraryCran(dict):
    def __init__(__self__, *,
                 package: str,
                 repo: Optional[str] = None):
        pulumi.set(__self__, "package", package)
        if repo is not None:
            pulumi.set(__self__, "repo", repo)

    @property
    @pulumi.getter
    def package(self) -> str:
        return pulumi.get(self, "package")

    @property
    @pulumi.getter
    def repo(self) -> Optional[str]:
        return pulumi.get(self, "repo")


@pulumi.output_type
class JobTaskForEachTaskTaskNewClusterLibraryMaven(dict):
    def __init__(__self__, *,
                 coordinates: str,
                 exclusions: Optional[Sequence[str]] = None,
                 repo: Optional[str] = None):
        pulumi.set(__self__, "coordinates", coordinates)
        if exclusions is not None:
            pulumi.set(__self__, "exclusions", exclusions)
        if repo is not None:
            pulumi.set(__self__, "repo", repo)

    @property
    @pulumi.getter
    def coordinates(self) -> str:
        return pulumi.get(self, "coordinates")

    @property
    @pulumi.getter
    def exclusions(self) -> Optional[Sequence[str]]:
        return pulumi.get(self, "exclusions")

    @property
    @pulumi.getter
    def repo(self) -> Optional[str]:
        return pulumi.get(self, "repo")


@pulumi.output_type
class JobTaskForEachTaskTaskNewClusterLibraryPypi(dict):
    def __init__(__self__, *,
                 package: str,
                 repo: Optional[str] = None):
        pulumi.set(__self__, "package", package)
        if repo is not None:
            pulumi.set(__self__, "repo", repo)

    @property
    @pulumi.getter
    def package(self) -> str:
        return pulumi.get(self, "package")

    @property
    @pulumi.getter
    def repo(self) -> Optional[str]:
        return pulumi.get(self, "repo")


@pulumi.output_type
class JobTaskForEachTaskTaskNewClusterWorkloadType(dict):
    def __init__(__self__, *,
                 clients: 'outputs.JobTaskForEachTaskTaskNewClusterWorkloadTypeClients'):
        pulumi.set(__self__, "clients", clients)

    @property
    @pulumi.getter
    def clients(self) -> 'outputs.JobTaskForEachTaskTaskNewClusterWorkloadTypeClients':
        return pulumi.get(self, "clients")


@pulumi.output_type
class JobTaskForEachTaskTaskNewClusterWorkloadTypeClients(dict):
    def __init__(__self__, *,
                 jobs: Optional[bool] = None,
                 notebooks: Optional[bool] = None):
        if jobs is not None:
            pulumi.set(__self__, "jobs", jobs)
        if notebooks is not None:
            pulumi.set(__self__, "notebooks", notebooks)

    @property
    @pulumi.getter
    def jobs(self) -> Optional[bool]:
        return pulumi.get(self, "jobs")

    @property
    @pulumi.getter
    def notebooks(self) -> Optional[bool]:
        return pulumi.get(self, "notebooks")


@pulumi.output_type
class JobTaskForEachTaskTaskNotebookTask(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "notebookPath":
            suggest = "notebook_path"
        elif key == "baseParameters":
            suggest = "base_parameters"
        elif key == "warehouseId":
            suggest = "warehouse_id"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in JobTaskForEachTaskTaskNotebookTask. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        JobTaskForEachTaskTaskNotebookTask.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        JobTaskForEachTaskTaskNotebookTask.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 notebook_path: str,
                 base_parameters: Optional[Mapping[str, str]] = None,
                 source: Optional[str] = None,
                 warehouse_id: Optional[str] = None):
        """
        :param str notebook_path: The path of the Notebook to be run in the Databricks workspace or remote repository. For notebooks stored in the Databricks workspace, the path must be absolute and begin with a slash. For notebooks stored in a remote repository, the path must be relative. This field is required.
        :param Mapping[str, str] base_parameters: (Map) Base parameters to be used for each run of this job. If the run is initiated by a call to run-now with parameters specified, the two parameters maps will be merged. If the same key is specified in base_parameters and in run-now, the value from run-now will be used. If the notebook takes a parameter that is not specified in the jobs base_parameters or the run-now override parameters, the default value from the notebook will be used. Retrieve these parameters in a notebook using `dbutils.widgets.get`.
        :param str source: Location type of the notebook, can only be `WORKSPACE` or `GIT`. When set to `WORKSPACE`, the notebook will be retrieved from the local Databricks workspace. When set to `GIT`, the notebook will be retrieved from a Git repository defined in `git_source`. If the value is empty, the task will use `GIT` if `git_source` is defined and `WORKSPACE` otherwise.
        :param str warehouse_id: ID of the (the databricks_sql_endpoint) that will be used to execute the task with SQL notebook.
        """
        pulumi.set(__self__, "notebook_path", notebook_path)
        if base_parameters is not None:
            pulumi.set(__self__, "base_parameters", base_parameters)
        if source is not None:
            pulumi.set(__self__, "source", source)
        if warehouse_id is not None:
            pulumi.set(__self__, "warehouse_id", warehouse_id)

    @property
    @pulumi.getter(name="notebookPath")
    def notebook_path(self) -> str:
        """
        The path of the Notebook to be run in the Databricks workspace or remote repository. For notebooks stored in the Databricks workspace, the path must be absolute and begin with a slash. For notebooks stored in a remote repository, the path must be relative. This field is required.
        """
        return pulumi.get(self, "notebook_path")

    @property
    @pulumi.getter(name="baseParameters")
    def base_parameters(self) -> Optional[Mapping[str, str]]:
        """
        (Map) Base parameters to be used for each run of this job. If the run is initiated by a call to run-now with parameters specified, the two parameters maps will be merged. If the same key is specified in base_parameters and in run-now, the value from run-now will be used. If the notebook takes a parameter that is not specified in the jobs base_parameters or the run-now override parameters, the default value from the notebook will be used. Retrieve these parameters in a notebook using `dbutils.widgets.get`.
        """
        return pulumi.get(self, "base_parameters")

    @property
    @pulumi.getter
    def source(self) -> Optional[str]:
        """
        Location type of the notebook, can only be `WORKSPACE` or `GIT`. When set to `WORKSPACE`, the notebook will be retrieved from the local Databricks workspace. When set to `GIT`, the notebook will be retrieved from a Git repository defined in `git_source`. If the value is empty, the task will use `GIT` if `git_source` is defined and `WORKSPACE` otherwise.
        """
        return pulumi.get(self, "source")

    @property
    @pulumi.getter(name="warehouseId")
    def warehouse_id(self) -> Optional[str]:
        """
        ID of the (the databricks_sql_endpoint) that will be used to execute the task with SQL notebook.
        """
        return pulumi.get(self, "warehouse_id")


@pulumi.output_type
class JobTaskForEachTaskTaskNotificationSettings(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "alertOnLastAttempt":
            suggest = "alert_on_last_attempt"
        elif key == "noAlertForCanceledRuns":
            suggest = "no_alert_for_canceled_runs"
        elif key == "noAlertForSkippedRuns":
            suggest = "no_alert_for_skipped_runs"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in JobTaskForEachTaskTaskNotificationSettings. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        JobTaskForEachTaskTaskNotificationSettings.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        JobTaskForEachTaskTaskNotificationSettings.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 alert_on_last_attempt: Optional[bool] = None,
                 no_alert_for_canceled_runs: Optional[bool] = None,
                 no_alert_for_skipped_runs: Optional[bool] = None):
        """
        :param bool alert_on_last_attempt: (Bool) do not send notifications to recipients specified in `on_start` for the retried runs and do not send notifications to recipients specified in `on_failure` until the last retry of the run.
        :param bool no_alert_for_canceled_runs: (Bool) don't send alert for cancelled runs.
               
               The following parameter is only available on task level.
        :param bool no_alert_for_skipped_runs: (Bool) don't send alert for skipped runs.
        """
        if alert_on_last_attempt is not None:
            pulumi.set(__self__, "alert_on_last_attempt", alert_on_last_attempt)
        if no_alert_for_canceled_runs is not None:
            pulumi.set(__self__, "no_alert_for_canceled_runs", no_alert_for_canceled_runs)
        if no_alert_for_skipped_runs is not None:
            pulumi.set(__self__, "no_alert_for_skipped_runs", no_alert_for_skipped_runs)

    @property
    @pulumi.getter(name="alertOnLastAttempt")
    def alert_on_last_attempt(self) -> Optional[bool]:
        """
        (Bool) do not send notifications to recipients specified in `on_start` for the retried runs and do not send notifications to recipients specified in `on_failure` until the last retry of the run.
        """
        return pulumi.get(self, "alert_on_last_attempt")

    @property
    @pulumi.getter(name="noAlertForCanceledRuns")
    def no_alert_for_canceled_runs(self) -> Optional[bool]:
        """
        (Bool) don't send alert for cancelled runs.

        The following parameter is only available on task level.
        """
        return pulumi.get(self, "no_alert_for_canceled_runs")

    @property
    @pulumi.getter(name="noAlertForSkippedRuns")
    def no_alert_for_skipped_runs(self) -> Optional[bool]:
        """
        (Bool) don't send alert for skipped runs.
        """
        return pulumi.get(self, "no_alert_for_skipped_runs")


@pulumi.output_type
class JobTaskForEachTaskTaskPipelineTask(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "pipelineId":
            suggest = "pipeline_id"
        elif key == "fullRefresh":
            suggest = "full_refresh"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in JobTaskForEachTaskTaskPipelineTask. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        JobTaskForEachTaskTaskPipelineTask.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        JobTaskForEachTaskTaskPipelineTask.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 pipeline_id: str,
                 full_refresh: Optional[bool] = None):
        """
        :param str pipeline_id: The pipeline's unique ID.
        :param bool full_refresh: (Bool) Specifies if there should be full refresh of the pipeline.
               
               > **Note** The following configuration blocks are only supported inside a `task` block
        """
        pulumi.set(__self__, "pipeline_id", pipeline_id)
        if full_refresh is not None:
            pulumi.set(__self__, "full_refresh", full_refresh)

    @property
    @pulumi.getter(name="pipelineId")
    def pipeline_id(self) -> str:
        """
        The pipeline's unique ID.
        """
        return pulumi.get(self, "pipeline_id")

    @property
    @pulumi.getter(name="fullRefresh")
    def full_refresh(self) -> Optional[bool]:
        """
        (Bool) Specifies if there should be full refresh of the pipeline.

        > **Note** The following configuration blocks are only supported inside a `task` block
        """
        return pulumi.get(self, "full_refresh")


@pulumi.output_type
class JobTaskForEachTaskTaskPythonWheelTask(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "entryPoint":
            suggest = "entry_point"
        elif key == "namedParameters":
            suggest = "named_parameters"
        elif key == "packageName":
            suggest = "package_name"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in JobTaskForEachTaskTaskPythonWheelTask. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        JobTaskForEachTaskTaskPythonWheelTask.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        JobTaskForEachTaskTaskPythonWheelTask.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 entry_point: Optional[str] = None,
                 named_parameters: Optional[Mapping[str, str]] = None,
                 package_name: Optional[str] = None,
                 parameters: Optional[Sequence[str]] = None):
        """
        :param str entry_point: Python function as entry point for the task
        :param Mapping[str, str] named_parameters: Named parameters for the task
        :param str package_name: Name of Python package
        :param Sequence[str] parameters: Parameters for the task
        """
        if entry_point is not None:
            pulumi.set(__self__, "entry_point", entry_point)
        if named_parameters is not None:
            pulumi.set(__self__, "named_parameters", named_parameters)
        if package_name is not None:
            pulumi.set(__self__, "package_name", package_name)
        if parameters is not None:
            pulumi.set(__self__, "parameters", parameters)

    @property
    @pulumi.getter(name="entryPoint")
    def entry_point(self) -> Optional[str]:
        """
        Python function as entry point for the task
        """
        return pulumi.get(self, "entry_point")

    @property
    @pulumi.getter(name="namedParameters")
    def named_parameters(self) -> Optional[Mapping[str, str]]:
        """
        Named parameters for the task
        """
        return pulumi.get(self, "named_parameters")

    @property
    @pulumi.getter(name="packageName")
    def package_name(self) -> Optional[str]:
        """
        Name of Python package
        """
        return pulumi.get(self, "package_name")

    @property
    @pulumi.getter
    def parameters(self) -> Optional[Sequence[str]]:
        """
        Parameters for the task
        """
        return pulumi.get(self, "parameters")


@pulumi.output_type
class JobTaskForEachTaskTaskRunJobTask(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "jobId":
            suggest = "job_id"
        elif key == "dbtCommands":
            suggest = "dbt_commands"
        elif key == "jarParams":
            suggest = "jar_params"
        elif key == "jobParameters":
            suggest = "job_parameters"
        elif key == "notebookParams":
            suggest = "notebook_params"
        elif key == "pipelineParams":
            suggest = "pipeline_params"
        elif key == "pythonNamedParams":
            suggest = "python_named_params"
        elif key == "pythonParams":
            suggest = "python_params"
        elif key == "sparkSubmitParams":
            suggest = "spark_submit_params"
        elif key == "sqlParams":
            suggest = "sql_params"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in JobTaskForEachTaskTaskRunJobTask. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        JobTaskForEachTaskTaskRunJobTask.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        JobTaskForEachTaskTaskRunJobTask.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 job_id: int,
                 dbt_commands: Optional[Sequence[str]] = None,
                 jar_params: Optional[Sequence[str]] = None,
                 job_parameters: Optional[Mapping[str, str]] = None,
                 notebook_params: Optional[Mapping[str, str]] = None,
                 pipeline_params: Optional['outputs.JobTaskForEachTaskTaskRunJobTaskPipelineParams'] = None,
                 python_named_params: Optional[Mapping[str, str]] = None,
                 python_params: Optional[Sequence[str]] = None,
                 spark_submit_params: Optional[Sequence[str]] = None,
                 sql_params: Optional[Mapping[str, str]] = None):
        """
        :param int job_id: (String) ID of the job
        :param Mapping[str, str] job_parameters: (Map) Job parameters for the task
        """
        pulumi.set(__self__, "job_id", job_id)
        if dbt_commands is not None:
            pulumi.set(__self__, "dbt_commands", dbt_commands)
        if jar_params is not None:
            pulumi.set(__self__, "jar_params", jar_params)
        if job_parameters is not None:
            pulumi.set(__self__, "job_parameters", job_parameters)
        if notebook_params is not None:
            pulumi.set(__self__, "notebook_params", notebook_params)
        if pipeline_params is not None:
            pulumi.set(__self__, "pipeline_params", pipeline_params)
        if python_named_params is not None:
            pulumi.set(__self__, "python_named_params", python_named_params)
        if python_params is not None:
            pulumi.set(__self__, "python_params", python_params)
        if spark_submit_params is not None:
            pulumi.set(__self__, "spark_submit_params", spark_submit_params)
        if sql_params is not None:
            pulumi.set(__self__, "sql_params", sql_params)

    @property
    @pulumi.getter(name="jobId")
    def job_id(self) -> int:
        """
        (String) ID of the job
        """
        return pulumi.get(self, "job_id")

    @property
    @pulumi.getter(name="dbtCommands")
    def dbt_commands(self) -> Optional[Sequence[str]]:
        return pulumi.get(self, "dbt_commands")

    @property
    @pulumi.getter(name="jarParams")
    def jar_params(self) -> Optional[Sequence[str]]:
        return pulumi.get(self, "jar_params")

    @property
    @pulumi.getter(name="jobParameters")
    def job_parameters(self) -> Optional[Mapping[str, str]]:
        """
        (Map) Job parameters for the task
        """
        return pulumi.get(self, "job_parameters")

    @property
    @pulumi.getter(name="notebookParams")
    def notebook_params(self) -> Optional[Mapping[str, str]]:
        return pulumi.get(self, "notebook_params")

    @property
    @pulumi.getter(name="pipelineParams")
    def pipeline_params(self) -> Optional['outputs.JobTaskForEachTaskTaskRunJobTaskPipelineParams']:
        return pulumi.get(self, "pipeline_params")

    @property
    @pulumi.getter(name="pythonNamedParams")
    def python_named_params(self) -> Optional[Mapping[str, str]]:
        return pulumi.get(self, "python_named_params")

    @property
    @pulumi.getter(name="pythonParams")
    def python_params(self) -> Optional[Sequence[str]]:
        return pulumi.get(self, "python_params")

    @property
    @pulumi.getter(name="sparkSubmitParams")
    def spark_submit_params(self) -> Optional[Sequence[str]]:
        return pulumi.get(self, "spark_submit_params")

    @property
    @pulumi.getter(name="sqlParams")
    def sql_params(self) -> Optional[Mapping[str, str]]:
        return pulumi.get(self, "sql_params")


@pulumi.output_type
class JobTaskForEachTaskTaskRunJobTaskPipelineParams(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "fullRefresh":
            suggest = "full_refresh"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in JobTaskForEachTaskTaskRunJobTaskPipelineParams. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        JobTaskForEachTaskTaskRunJobTaskPipelineParams.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        JobTaskForEachTaskTaskRunJobTaskPipelineParams.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 full_refresh: Optional[bool] = None):
        """
        :param bool full_refresh: (Bool) Specifies if there should be full refresh of the pipeline.
               
               > **Note** The following configuration blocks are only supported inside a `task` block
        """
        if full_refresh is not None:
            pulumi.set(__self__, "full_refresh", full_refresh)

    @property
    @pulumi.getter(name="fullRefresh")
    def full_refresh(self) -> Optional[bool]:
        """
        (Bool) Specifies if there should be full refresh of the pipeline.

        > **Note** The following configuration blocks are only supported inside a `task` block
        """
        return pulumi.get(self, "full_refresh")


@pulumi.output_type
class JobTaskForEachTaskTaskSparkJarTask(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "jarUri":
            suggest = "jar_uri"
        elif key == "mainClassName":
            suggest = "main_class_name"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in JobTaskForEachTaskTaskSparkJarTask. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        JobTaskForEachTaskTaskSparkJarTask.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        JobTaskForEachTaskTaskSparkJarTask.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 jar_uri: Optional[str] = None,
                 main_class_name: Optional[str] = None,
                 parameters: Optional[Sequence[str]] = None):
        """
        :param str main_class_name: The full name of the class containing the main method to be executed. This class must be contained in a JAR provided as a library. The code should use `SparkContext.getOrCreate` to obtain a Spark context; otherwise, runs of the job will fail.
        :param Sequence[str] parameters: (List) Parameters passed to the main method.
        """
        if jar_uri is not None:
            pulumi.set(__self__, "jar_uri", jar_uri)
        if main_class_name is not None:
            pulumi.set(__self__, "main_class_name", main_class_name)
        if parameters is not None:
            pulumi.set(__self__, "parameters", parameters)

    @property
    @pulumi.getter(name="jarUri")
    def jar_uri(self) -> Optional[str]:
        return pulumi.get(self, "jar_uri")

    @property
    @pulumi.getter(name="mainClassName")
    def main_class_name(self) -> Optional[str]:
        """
        The full name of the class containing the main method to be executed. This class must be contained in a JAR provided as a library. The code should use `SparkContext.getOrCreate` to obtain a Spark context; otherwise, runs of the job will fail.
        """
        return pulumi.get(self, "main_class_name")

    @property
    @pulumi.getter
    def parameters(self) -> Optional[Sequence[str]]:
        """
        (List) Parameters passed to the main method.
        """
        return pulumi.get(self, "parameters")


@pulumi.output_type
class JobTaskForEachTaskTaskSparkPythonTask(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "pythonFile":
            suggest = "python_file"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in JobTaskForEachTaskTaskSparkPythonTask. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        JobTaskForEachTaskTaskSparkPythonTask.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        JobTaskForEachTaskTaskSparkPythonTask.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 python_file: str,
                 parameters: Optional[Sequence[str]] = None,
                 source: Optional[str] = None):
        """
        :param str python_file: The URI of the Python file to be executed. databricks_dbfs_file, cloud file URIs (e.g. `s3:/`, `abfss:/`, `gs:/`), workspace paths and remote repository are supported. For Python files stored in the Databricks workspace, the path must be absolute and begin with `/Repos`. For files stored in a remote repository, the path must be relative. This field is required.
        :param Sequence[str] parameters: (List) Command line parameters passed to the Python file.
        :param str source: Location type of the Python file, can only be `GIT`. When set to `GIT`, the Python file will be retrieved from a Git repository defined in `git_source`.
        """
        pulumi.set(__self__, "python_file", python_file)
        if parameters is not None:
            pulumi.set(__self__, "parameters", parameters)
        if source is not None:
            pulumi.set(__self__, "source", source)

    @property
    @pulumi.getter(name="pythonFile")
    def python_file(self) -> str:
        """
        The URI of the Python file to be executed. databricks_dbfs_file, cloud file URIs (e.g. `s3:/`, `abfss:/`, `gs:/`), workspace paths and remote repository are supported. For Python files stored in the Databricks workspace, the path must be absolute and begin with `/Repos`. For files stored in a remote repository, the path must be relative. This field is required.
        """
        return pulumi.get(self, "python_file")

    @property
    @pulumi.getter
    def parameters(self) -> Optional[Sequence[str]]:
        """
        (List) Command line parameters passed to the Python file.
        """
        return pulumi.get(self, "parameters")

    @property
    @pulumi.getter
    def source(self) -> Optional[str]:
        """
        Location type of the Python file, can only be `GIT`. When set to `GIT`, the Python file will be retrieved from a Git repository defined in `git_source`.
        """
        return pulumi.get(self, "source")


@pulumi.output_type
class JobTaskForEachTaskTaskSparkSubmitTask(dict):
    def __init__(__self__, *,
                 parameters: Optional[Sequence[str]] = None):
        """
        :param Sequence[str] parameters: (List) Command-line parameters passed to spark submit.
        """
        if parameters is not None:
            pulumi.set(__self__, "parameters", parameters)

    @property
    @pulumi.getter
    def parameters(self) -> Optional[Sequence[str]]:
        """
        (List) Command-line parameters passed to spark submit.
        """
        return pulumi.get(self, "parameters")


@pulumi.output_type
class JobTaskForEachTaskTaskSqlTask(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "warehouseId":
            suggest = "warehouse_id"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in JobTaskForEachTaskTaskSqlTask. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        JobTaskForEachTaskTaskSqlTask.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        JobTaskForEachTaskTaskSqlTask.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 warehouse_id: str,
                 alert: Optional['outputs.JobTaskForEachTaskTaskSqlTaskAlert'] = None,
                 dashboard: Optional['outputs.JobTaskForEachTaskTaskSqlTaskDashboard'] = None,
                 file: Optional['outputs.JobTaskForEachTaskTaskSqlTaskFile'] = None,
                 parameters: Optional[Mapping[str, str]] = None,
                 query: Optional['outputs.JobTaskForEachTaskTaskSqlTaskQuery'] = None):
        """
        :param str warehouse_id: ID of the (the databricks_sql_endpoint) that will be used to execute the task.  Only Serverless & Pro warehouses are supported right now.
        :param 'JobTaskForEachTaskTaskSqlTaskAlertArgs' alert: block consisting of following fields:
        :param 'JobTaskForEachTaskTaskSqlTaskDashboardArgs' dashboard: block consisting of following fields:
        :param 'JobTaskForEachTaskTaskSqlTaskFileArgs' file: block consisting of single string fields:
        :param Mapping[str, str] parameters: (Map) parameters to be used for each run of this task. The SQL alert task does not support custom parameters.
        :param 'JobTaskForEachTaskTaskSqlTaskQueryArgs' query: block consisting of single string field: `query_id` - identifier of the Databricks SQL Query (databricks_sql_query).
        """
        pulumi.set(__self__, "warehouse_id", warehouse_id)
        if alert is not None:
            pulumi.set(__self__, "alert", alert)
        if dashboard is not None:
            pulumi.set(__self__, "dashboard", dashboard)
        if file is not None:
            pulumi.set(__self__, "file", file)
        if parameters is not None:
            pulumi.set(__self__, "parameters", parameters)
        if query is not None:
            pulumi.set(__self__, "query", query)

    @property
    @pulumi.getter(name="warehouseId")
    def warehouse_id(self) -> str:
        """
        ID of the (the databricks_sql_endpoint) that will be used to execute the task.  Only Serverless & Pro warehouses are supported right now.
        """
        return pulumi.get(self, "warehouse_id")

    @property
    @pulumi.getter
    def alert(self) -> Optional['outputs.JobTaskForEachTaskTaskSqlTaskAlert']:
        """
        block consisting of following fields:
        """
        return pulumi.get(self, "alert")

    @property
    @pulumi.getter
    def dashboard(self) -> Optional['outputs.JobTaskForEachTaskTaskSqlTaskDashboard']:
        """
        block consisting of following fields:
        """
        return pulumi.get(self, "dashboard")

    @property
    @pulumi.getter
    def file(self) -> Optional['outputs.JobTaskForEachTaskTaskSqlTaskFile']:
        """
        block consisting of single string fields:
        """
        return pulumi.get(self, "file")

    @property
    @pulumi.getter
    def parameters(self) -> Optional[Mapping[str, str]]:
        """
        (Map) parameters to be used for each run of this task. The SQL alert task does not support custom parameters.
        """
        return pulumi.get(self, "parameters")

    @property
    @pulumi.getter
    def query(self) -> Optional['outputs.JobTaskForEachTaskTaskSqlTaskQuery']:
        """
        block consisting of single string field: `query_id` - identifier of the Databricks SQL Query (databricks_sql_query).
        """
        return pulumi.get(self, "query")


@pulumi.output_type
class JobTaskForEachTaskTaskSqlTaskAlert(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "alertId":
            suggest = "alert_id"
        elif key == "pauseSubscriptions":
            suggest = "pause_subscriptions"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in JobTaskForEachTaskTaskSqlTaskAlert. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        JobTaskForEachTaskTaskSqlTaskAlert.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        JobTaskForEachTaskTaskSqlTaskAlert.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 alert_id: str,
                 subscriptions: Sequence['outputs.JobTaskForEachTaskTaskSqlTaskAlertSubscription'],
                 pause_subscriptions: Optional[bool] = None):
        """
        :param str alert_id: (String) identifier of the Databricks SQL Alert.
        :param Sequence['JobTaskForEachTaskTaskSqlTaskAlertSubscriptionArgs'] subscriptions: a list of subscription blocks consisting out of one of the required fields: `user_name` for user emails or `destination_id` - for Alert destination's identifier.
        :param bool pause_subscriptions: flag that specifies if subscriptions are paused or not.
        """
        pulumi.set(__self__, "alert_id", alert_id)
        pulumi.set(__self__, "subscriptions", subscriptions)
        if pause_subscriptions is not None:
            pulumi.set(__self__, "pause_subscriptions", pause_subscriptions)

    @property
    @pulumi.getter(name="alertId")
    def alert_id(self) -> str:
        """
        (String) identifier of the Databricks SQL Alert.
        """
        return pulumi.get(self, "alert_id")

    @property
    @pulumi.getter
    def subscriptions(self) -> Sequence['outputs.JobTaskForEachTaskTaskSqlTaskAlertSubscription']:
        """
        a list of subscription blocks consisting out of one of the required fields: `user_name` for user emails or `destination_id` - for Alert destination's identifier.
        """
        return pulumi.get(self, "subscriptions")

    @property
    @pulumi.getter(name="pauseSubscriptions")
    def pause_subscriptions(self) -> Optional[bool]:
        """
        flag that specifies if subscriptions are paused or not.
        """
        return pulumi.get(self, "pause_subscriptions")


@pulumi.output_type
class JobTaskForEachTaskTaskSqlTaskAlertSubscription(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "destinationId":
            suggest = "destination_id"
        elif key == "userName":
            suggest = "user_name"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in JobTaskForEachTaskTaskSqlTaskAlertSubscription. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        JobTaskForEachTaskTaskSqlTaskAlertSubscription.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        JobTaskForEachTaskTaskSqlTaskAlertSubscription.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 destination_id: Optional[str] = None,
                 user_name: Optional[str] = None):
        """
        :param str user_name: The email of an active workspace user. Non-admin users can only set this field to their own email.
        """
        if destination_id is not None:
            pulumi.set(__self__, "destination_id", destination_id)
        if user_name is not None:
            pulumi.set(__self__, "user_name", user_name)

    @property
    @pulumi.getter(name="destinationId")
    def destination_id(self) -> Optional[str]:
        return pulumi.get(self, "destination_id")

    @property
    @pulumi.getter(name="userName")
    def user_name(self) -> Optional[str]:
        """
        The email of an active workspace user. Non-admin users can only set this field to their own email.
        """
        return pulumi.get(self, "user_name")


@pulumi.output_type
class JobTaskForEachTaskTaskSqlTaskDashboard(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "dashboardId":
            suggest = "dashboard_id"
        elif key == "customSubject":
            suggest = "custom_subject"
        elif key == "pauseSubscriptions":
            suggest = "pause_subscriptions"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in JobTaskForEachTaskTaskSqlTaskDashboard. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        JobTaskForEachTaskTaskSqlTaskDashboard.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        JobTaskForEachTaskTaskSqlTaskDashboard.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 dashboard_id: str,
                 custom_subject: Optional[str] = None,
                 pause_subscriptions: Optional[bool] = None,
                 subscriptions: Optional[Sequence['outputs.JobTaskForEachTaskTaskSqlTaskDashboardSubscription']] = None):
        """
        :param str dashboard_id: (String) identifier of the Databricks SQL Dashboard databricks_sql_dashboard.
        :param str custom_subject: string specifying a custom subject of email sent.
        :param bool pause_subscriptions: flag that specifies if subscriptions are paused or not.
        :param Sequence['JobTaskForEachTaskTaskSqlTaskDashboardSubscriptionArgs'] subscriptions: a list of subscription blocks consisting out of one of the required fields: `user_name` for user emails or `destination_id` - for Alert destination's identifier.
        """
        pulumi.set(__self__, "dashboard_id", dashboard_id)
        if custom_subject is not None:
            pulumi.set(__self__, "custom_subject", custom_subject)
        if pause_subscriptions is not None:
            pulumi.set(__self__, "pause_subscriptions", pause_subscriptions)
        if subscriptions is not None:
            pulumi.set(__self__, "subscriptions", subscriptions)

    @property
    @pulumi.getter(name="dashboardId")
    def dashboard_id(self) -> str:
        """
        (String) identifier of the Databricks SQL Dashboard databricks_sql_dashboard.
        """
        return pulumi.get(self, "dashboard_id")

    @property
    @pulumi.getter(name="customSubject")
    def custom_subject(self) -> Optional[str]:
        """
        string specifying a custom subject of email sent.
        """
        return pulumi.get(self, "custom_subject")

    @property
    @pulumi.getter(name="pauseSubscriptions")
    def pause_subscriptions(self) -> Optional[bool]:
        """
        flag that specifies if subscriptions are paused or not.
        """
        return pulumi.get(self, "pause_subscriptions")

    @property
    @pulumi.getter
    def subscriptions(self) -> Optional[Sequence['outputs.JobTaskForEachTaskTaskSqlTaskDashboardSubscription']]:
        """
        a list of subscription blocks consisting out of one of the required fields: `user_name` for user emails or `destination_id` - for Alert destination's identifier.
        """
        return pulumi.get(self, "subscriptions")


@pulumi.output_type
class JobTaskForEachTaskTaskSqlTaskDashboardSubscription(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "destinationId":
            suggest = "destination_id"
        elif key == "userName":
            suggest = "user_name"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in JobTaskForEachTaskTaskSqlTaskDashboardSubscription. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        JobTaskForEachTaskTaskSqlTaskDashboardSubscription.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        JobTaskForEachTaskTaskSqlTaskDashboardSubscription.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 destination_id: Optional[str] = None,
                 user_name: Optional[str] = None):
        """
        :param str user_name: The email of an active workspace user. Non-admin users can only set this field to their own email.
        """
        if destination_id is not None:
            pulumi.set(__self__, "destination_id", destination_id)
        if user_name is not None:
            pulumi.set(__self__, "user_name", user_name)

    @property
    @pulumi.getter(name="destinationId")
    def destination_id(self) -> Optional[str]:
        return pulumi.get(self, "destination_id")

    @property
    @pulumi.getter(name="userName")
    def user_name(self) -> Optional[str]:
        """
        The email of an active workspace user. Non-admin users can only set this field to their own email.
        """
        return pulumi.get(self, "user_name")


@pulumi.output_type
class JobTaskForEachTaskTaskSqlTaskFile(dict):
    def __init__(__self__, *,
                 path: str,
                 source: Optional[str] = None):
        """
        :param str path: If `source` is `GIT`: Relative path to the file in the repository specified in the `git_source` block with SQL commands to execute. If `source` is `WORKSPACE`: Absolute path to the file in the workspace with SQL commands to execute.
               
               Example
               
               ```python
               import pulumi
               import pulumi_databricks as databricks
               
               sql_aggregation_job = databricks.Job("sql_aggregation_job",
                   name="Example SQL Job",
                   tasks=[
                       {
                           "task_key": "run_agg_query",
                           "sql_task": {
                               "warehouse_id": sql_job_warehouse["id"],
                               "query": {
                                   "query_id": agg_query["id"],
                               },
                           },
                       },
                       {
                           "task_key": "run_dashboard",
                           "sql_task": {
                               "warehouse_id": sql_job_warehouse["id"],
                               "dashboard": {
                                   "dashboard_id": dash["id"],
                                   "subscriptions": [{
                                       "user_name": "user@domain.com",
                                   }],
                               },
                           },
                       },
                       {
                           "task_key": "run_alert",
                           "sql_task": {
                               "warehouse_id": sql_job_warehouse["id"],
                               "alert": {
                                   "alert_id": alert["id"],
                                   "subscriptions": [{
                                       "user_name": "user@domain.com",
                                   }],
                               },
                           },
                       },
                   ])
               ```
        :param str source: The source of the project. Possible values are `WORKSPACE` and `GIT`.
        """
        pulumi.set(__self__, "path", path)
        if source is not None:
            pulumi.set(__self__, "source", source)

    @property
    @pulumi.getter
    def path(self) -> str:
        """
        If `source` is `GIT`: Relative path to the file in the repository specified in the `git_source` block with SQL commands to execute. If `source` is `WORKSPACE`: Absolute path to the file in the workspace with SQL commands to execute.

        Example

        ```python
        import pulumi
        import pulumi_databricks as databricks

        sql_aggregation_job = databricks.Job("sql_aggregation_job",
            name="Example SQL Job",
            tasks=[
                {
                    "task_key": "run_agg_query",
                    "sql_task": {
                        "warehouse_id": sql_job_warehouse["id"],
                        "query": {
                            "query_id": agg_query["id"],
                        },
                    },
                },
                {
                    "task_key": "run_dashboard",
                    "sql_task": {
                        "warehouse_id": sql_job_warehouse["id"],
                        "dashboard": {
                            "dashboard_id": dash["id"],
                            "subscriptions": [{
                                "user_name": "user@domain.com",
                            }],
                        },
                    },
                },
                {
                    "task_key": "run_alert",
                    "sql_task": {
                        "warehouse_id": sql_job_warehouse["id"],
                        "alert": {
                            "alert_id": alert["id"],
                            "subscriptions": [{
                                "user_name": "user@domain.com",
                            }],
                        },
                    },
                },
            ])
        ```
        """
        return pulumi.get(self, "path")

    @property
    @pulumi.getter
    def source(self) -> Optional[str]:
        """
        The source of the project. Possible values are `WORKSPACE` and `GIT`.
        """
        return pulumi.get(self, "source")


@pulumi.output_type
class JobTaskForEachTaskTaskSqlTaskQuery(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "queryId":
            suggest = "query_id"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in JobTaskForEachTaskTaskSqlTaskQuery. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        JobTaskForEachTaskTaskSqlTaskQuery.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        JobTaskForEachTaskTaskSqlTaskQuery.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 query_id: str):
        pulumi.set(__self__, "query_id", query_id)

    @property
    @pulumi.getter(name="queryId")
    def query_id(self) -> str:
        return pulumi.get(self, "query_id")


@pulumi.output_type
class JobTaskForEachTaskTaskWebhookNotifications(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "onDurationWarningThresholdExceededs":
            suggest = "on_duration_warning_threshold_exceededs"
        elif key == "onFailures":
            suggest = "on_failures"
        elif key == "onStarts":
            suggest = "on_starts"
        elif key == "onStreamingBacklogExceededs":
            suggest = "on_streaming_backlog_exceededs"
        elif key == "onSuccesses":
            suggest = "on_successes"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in JobTaskForEachTaskTaskWebhookNotifications. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        JobTaskForEachTaskTaskWebhookNotifications.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        JobTaskForEachTaskTaskWebhookNotifications.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 on_duration_warning_threshold_exceededs: Optional[Sequence['outputs.JobTaskForEachTaskTaskWebhookNotificationsOnDurationWarningThresholdExceeded']] = None,
                 on_failures: Optional[Sequence['outputs.JobTaskForEachTaskTaskWebhookNotificationsOnFailure']] = None,
                 on_starts: Optional[Sequence['outputs.JobTaskForEachTaskTaskWebhookNotificationsOnStart']] = None,
                 on_streaming_backlog_exceededs: Optional[Sequence['outputs.JobTaskForEachTaskTaskWebhookNotificationsOnStreamingBacklogExceeded']] = None,
                 on_successes: Optional[Sequence['outputs.JobTaskForEachTaskTaskWebhookNotificationsOnSuccess']] = None):
        """
        :param Sequence['JobTaskForEachTaskTaskWebhookNotificationsOnDurationWarningThresholdExceededArgs'] on_duration_warning_threshold_exceededs: (List) list of notification IDs to call when the duration of a run exceeds the threshold specified by the `RUN_DURATION_SECONDS` metric in the `health` block.
               
               Note that the `id` is not to be confused with the name of the alert destination. The `id` can be retrieved through the API or the URL of Databricks UI `https://<workspace host>/sql/destinations/<notification id>?o=<workspace id>`
               
               Example
        :param Sequence['JobTaskForEachTaskTaskWebhookNotificationsOnFailureArgs'] on_failures: (List) list of notification IDs to call when the run fails. A maximum of 3 destinations can be specified.
        :param Sequence['JobTaskForEachTaskTaskWebhookNotificationsOnStartArgs'] on_starts: (List) list of notification IDs to call when the run starts. A maximum of 3 destinations can be specified.
        :param Sequence['JobTaskForEachTaskTaskWebhookNotificationsOnSuccessArgs'] on_successes: (List) list of notification IDs to call when the run completes successfully. A maximum of 3 destinations can be specified.
        """
        if on_duration_warning_threshold_exceededs is not None:
            pulumi.set(__self__, "on_duration_warning_threshold_exceededs", on_duration_warning_threshold_exceededs)
        if on_failures is not None:
            pulumi.set(__self__, "on_failures", on_failures)
        if on_starts is not None:
            pulumi.set(__self__, "on_starts", on_starts)
        if on_streaming_backlog_exceededs is not None:
            pulumi.set(__self__, "on_streaming_backlog_exceededs", on_streaming_backlog_exceededs)
        if on_successes is not None:
            pulumi.set(__self__, "on_successes", on_successes)

    @property
    @pulumi.getter(name="onDurationWarningThresholdExceededs")
    def on_duration_warning_threshold_exceededs(self) -> Optional[Sequence['outputs.JobTaskForEachTaskTaskWebhookNotificationsOnDurationWarningThresholdExceeded']]:
        """
        (List) list of notification IDs to call when the duration of a run exceeds the threshold specified by the `RUN_DURATION_SECONDS` metric in the `health` block.

        Note that the `id` is not to be confused with the name of the alert destination. The `id` can be retrieved through the API or the URL of Databricks UI `https://<workspace host>/sql/destinations/<notification id>?o=<workspace id>`

        Example
        """
        return pulumi.get(self, "on_duration_warning_threshold_exceededs")

    @property
    @pulumi.getter(name="onFailures")
    def on_failures(self) -> Optional[Sequence['outputs.JobTaskForEachTaskTaskWebhookNotificationsOnFailure']]:
        """
        (List) list of notification IDs to call when the run fails. A maximum of 3 destinations can be specified.
        """
        return pulumi.get(self, "on_failures")

    @property
    @pulumi.getter(name="onStarts")
    def on_starts(self) -> Optional[Sequence['outputs.JobTaskForEachTaskTaskWebhookNotificationsOnStart']]:
        """
        (List) list of notification IDs to call when the run starts. A maximum of 3 destinations can be specified.
        """
        return pulumi.get(self, "on_starts")

    @property
    @pulumi.getter(name="onStreamingBacklogExceededs")
    def on_streaming_backlog_exceededs(self) -> Optional[Sequence['outputs.JobTaskForEachTaskTaskWebhookNotificationsOnStreamingBacklogExceeded']]:
        return pulumi.get(self, "on_streaming_backlog_exceededs")

    @property
    @pulumi.getter(name="onSuccesses")
    def on_successes(self) -> Optional[Sequence['outputs.JobTaskForEachTaskTaskWebhookNotificationsOnSuccess']]:
        """
        (List) list of notification IDs to call when the run completes successfully. A maximum of 3 destinations can be specified.
        """
        return pulumi.get(self, "on_successes")


@pulumi.output_type
class JobTaskForEachTaskTaskWebhookNotificationsOnDurationWarningThresholdExceeded(dict):
    def __init__(__self__, *,
                 id: str):
        """
        :param str id: ID of the job
        """
        pulumi.set(__self__, "id", id)

    @property
    @pulumi.getter
    def id(self) -> str:
        """
        ID of the job
        """
        return pulumi.get(self, "id")


@pulumi.output_type
class JobTaskForEachTaskTaskWebhookNotificationsOnFailure(dict):
    def __init__(__self__, *,
                 id: str):
        """
        :param str id: ID of the job
        """
        pulumi.set(__self__, "id", id)

    @property
    @pulumi.getter
    def id(self) -> str:
        """
        ID of the job
        """
        return pulumi.get(self, "id")


@pulumi.output_type
class JobTaskForEachTaskTaskWebhookNotificationsOnStart(dict):
    def __init__(__self__, *,
                 id: str):
        """
        :param str id: ID of the job
        """
        pulumi.set(__self__, "id", id)

    @property
    @pulumi.getter
    def id(self) -> str:
        """
        ID of the job
        """
        return pulumi.get(self, "id")


@pulumi.output_type
class JobTaskForEachTaskTaskWebhookNotificationsOnStreamingBacklogExceeded(dict):
    def __init__(__self__, *,
                 id: str):
        """
        :param str id: ID of the job
        """
        pulumi.set(__self__, "id", id)

    @property
    @pulumi.getter
    def id(self) -> str:
        """
        ID of the job
        """
        return pulumi.get(self, "id")


@pulumi.output_type
class JobTaskForEachTaskTaskWebhookNotificationsOnSuccess(dict):
    def __init__(__self__, *,
                 id: str):
        """
        :param str id: ID of the job
        """
        pulumi.set(__self__, "id", id)

    @property
    @pulumi.getter
    def id(self) -> str:
        """
        ID of the job
        """
        return pulumi.get(self, "id")


@pulumi.output_type
class JobTaskHealth(dict):
    def __init__(__self__, *,
                 rules: Sequence['outputs.JobTaskHealthRule']):
        """
        :param Sequence['JobTaskHealthRuleArgs'] rules: list of rules that are represented as objects with the following attributes:
        """
        pulumi.set(__self__, "rules", rules)

    @property
    @pulumi.getter
    def rules(self) -> Sequence['outputs.JobTaskHealthRule']:
        """
        list of rules that are represented as objects with the following attributes:
        """
        return pulumi.get(self, "rules")


@pulumi.output_type
class JobTaskHealthRule(dict):
    def __init__(__self__, *,
                 metric: str,
                 op: str,
                 value: int):
        """
        :param str metric: string specifying the metric to check.  The only supported metric is `RUN_DURATION_SECONDS` (check [Jobs REST API documentation](https://docs.databricks.com/api/workspace/jobs/create) for the latest information).
        :param str op: string specifying the operation used to evaluate the given metric. The only supported operation is `GREATER_THAN`.
        :param int value: integer value used to compare to the given metric.
        """
        pulumi.set(__self__, "metric", metric)
        pulumi.set(__self__, "op", op)
        pulumi.set(__self__, "value", value)

    @property
    @pulumi.getter
    def metric(self) -> str:
        """
        string specifying the metric to check.  The only supported metric is `RUN_DURATION_SECONDS` (check [Jobs REST API documentation](https://docs.databricks.com/api/workspace/jobs/create) for the latest information).
        """
        return pulumi.get(self, "metric")

    @property
    @pulumi.getter
    def op(self) -> str:
        """
        string specifying the operation used to evaluate the given metric. The only supported operation is `GREATER_THAN`.
        """
        return pulumi.get(self, "op")

    @property
    @pulumi.getter
    def value(self) -> int:
        """
        integer value used to compare to the given metric.
        """
        return pulumi.get(self, "value")


@pulumi.output_type
class JobTaskLibrary(dict):
    def __init__(__self__, *,
                 cran: Optional['outputs.JobTaskLibraryCran'] = None,
                 egg: Optional[str] = None,
                 jar: Optional[str] = None,
                 maven: Optional['outputs.JobTaskLibraryMaven'] = None,
                 pypi: Optional['outputs.JobTaskLibraryPypi'] = None,
                 requirements: Optional[str] = None,
                 whl: Optional[str] = None):
        if cran is not None:
            pulumi.set(__self__, "cran", cran)
        if egg is not None:
            pulumi.set(__self__, "egg", egg)
        if jar is not None:
            pulumi.set(__self__, "jar", jar)
        if maven is not None:
            pulumi.set(__self__, "maven", maven)
        if pypi is not None:
            pulumi.set(__self__, "pypi", pypi)
        if requirements is not None:
            pulumi.set(__self__, "requirements", requirements)
        if whl is not None:
            pulumi.set(__self__, "whl", whl)

    @property
    @pulumi.getter
    def cran(self) -> Optional['outputs.JobTaskLibraryCran']:
        return pulumi.get(self, "cran")

    @property
    @pulumi.getter
    def egg(self) -> Optional[str]:
        return pulumi.get(self, "egg")

    @property
    @pulumi.getter
    def jar(self) -> Optional[str]:
        return pulumi.get(self, "jar")

    @property
    @pulumi.getter
    def maven(self) -> Optional['outputs.JobTaskLibraryMaven']:
        return pulumi.get(self, "maven")

    @property
    @pulumi.getter
    def pypi(self) -> Optional['outputs.JobTaskLibraryPypi']:
        return pulumi.get(self, "pypi")

    @property
    @pulumi.getter
    def requirements(self) -> Optional[str]:
        return pulumi.get(self, "requirements")

    @property
    @pulumi.getter
    def whl(self) -> Optional[str]:
        return pulumi.get(self, "whl")


@pulumi.output_type
class JobTaskLibraryCran(dict):
    def __init__(__self__, *,
                 package: str,
                 repo: Optional[str] = None):
        pulumi.set(__self__, "package", package)
        if repo is not None:
            pulumi.set(__self__, "repo", repo)

    @property
    @pulumi.getter
    def package(self) -> str:
        return pulumi.get(self, "package")

    @property
    @pulumi.getter
    def repo(self) -> Optional[str]:
        return pulumi.get(self, "repo")


@pulumi.output_type
class JobTaskLibraryMaven(dict):
    def __init__(__self__, *,
                 coordinates: str,
                 exclusions: Optional[Sequence[str]] = None,
                 repo: Optional[str] = None):
        pulumi.set(__self__, "coordinates", coordinates)
        if exclusions is not None:
            pulumi.set(__self__, "exclusions", exclusions)
        if repo is not None:
            pulumi.set(__self__, "repo", repo)

    @property
    @pulumi.getter
    def coordinates(self) -> str:
        return pulumi.get(self, "coordinates")

    @property
    @pulumi.getter
    def exclusions(self) -> Optional[Sequence[str]]:
        return pulumi.get(self, "exclusions")

    @property
    @pulumi.getter
    def repo(self) -> Optional[str]:
        return pulumi.get(self, "repo")


@pulumi.output_type
class JobTaskLibraryPypi(dict):
    def __init__(__self__, *,
                 package: str,
                 repo: Optional[str] = None):
        pulumi.set(__self__, "package", package)
        if repo is not None:
            pulumi.set(__self__, "repo", repo)

    @property
    @pulumi.getter
    def package(self) -> str:
        return pulumi.get(self, "package")

    @property
    @pulumi.getter
    def repo(self) -> Optional[str]:
        return pulumi.get(self, "repo")


@pulumi.output_type
class JobTaskNewCluster(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "sparkVersion":
            suggest = "spark_version"
        elif key == "applyPolicyDefaultValues":
            suggest = "apply_policy_default_values"
        elif key == "awsAttributes":
            suggest = "aws_attributes"
        elif key == "azureAttributes":
            suggest = "azure_attributes"
        elif key == "clusterId":
            suggest = "cluster_id"
        elif key == "clusterLogConf":
            suggest = "cluster_log_conf"
        elif key == "clusterMountInfos":
            suggest = "cluster_mount_infos"
        elif key == "clusterName":
            suggest = "cluster_name"
        elif key == "customTags":
            suggest = "custom_tags"
        elif key == "dataSecurityMode":
            suggest = "data_security_mode"
        elif key == "dockerImage":
            suggest = "docker_image"
        elif key == "driverInstancePoolId":
            suggest = "driver_instance_pool_id"
        elif key == "driverNodeTypeId":
            suggest = "driver_node_type_id"
        elif key == "enableElasticDisk":
            suggest = "enable_elastic_disk"
        elif key == "enableLocalDiskEncryption":
            suggest = "enable_local_disk_encryption"
        elif key == "gcpAttributes":
            suggest = "gcp_attributes"
        elif key == "idempotencyToken":
            suggest = "idempotency_token"
        elif key == "initScripts":
            suggest = "init_scripts"
        elif key == "instancePoolId":
            suggest = "instance_pool_id"
        elif key == "nodeTypeId":
            suggest = "node_type_id"
        elif key == "numWorkers":
            suggest = "num_workers"
        elif key == "policyId":
            suggest = "policy_id"
        elif key == "runtimeEngine":
            suggest = "runtime_engine"
        elif key == "singleUserName":
            suggest = "single_user_name"
        elif key == "sparkConf":
            suggest = "spark_conf"
        elif key == "sparkEnvVars":
            suggest = "spark_env_vars"
        elif key == "sshPublicKeys":
            suggest = "ssh_public_keys"
        elif key == "workloadType":
            suggest = "workload_type"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in JobTaskNewCluster. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        JobTaskNewCluster.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        JobTaskNewCluster.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 spark_version: str,
                 apply_policy_default_values: Optional[bool] = None,
                 autoscale: Optional['outputs.JobTaskNewClusterAutoscale'] = None,
                 aws_attributes: Optional['outputs.JobTaskNewClusterAwsAttributes'] = None,
                 azure_attributes: Optional['outputs.JobTaskNewClusterAzureAttributes'] = None,
                 cluster_id: Optional[str] = None,
                 cluster_log_conf: Optional['outputs.JobTaskNewClusterClusterLogConf'] = None,
                 cluster_mount_infos: Optional[Sequence['outputs.JobTaskNewClusterClusterMountInfo']] = None,
                 cluster_name: Optional[str] = None,
                 custom_tags: Optional[Mapping[str, str]] = None,
                 data_security_mode: Optional[str] = None,
                 docker_image: Optional['outputs.JobTaskNewClusterDockerImage'] = None,
                 driver_instance_pool_id: Optional[str] = None,
                 driver_node_type_id: Optional[str] = None,
                 enable_elastic_disk: Optional[bool] = None,
                 enable_local_disk_encryption: Optional[bool] = None,
                 gcp_attributes: Optional['outputs.JobTaskNewClusterGcpAttributes'] = None,
                 idempotency_token: Optional[str] = None,
                 init_scripts: Optional[Sequence['outputs.JobTaskNewClusterInitScript']] = None,
                 instance_pool_id: Optional[str] = None,
                 libraries: Optional[Sequence['outputs.JobTaskNewClusterLibrary']] = None,
                 node_type_id: Optional[str] = None,
                 num_workers: Optional[int] = None,
                 policy_id: Optional[str] = None,
                 runtime_engine: Optional[str] = None,
                 single_user_name: Optional[str] = None,
                 spark_conf: Optional[Mapping[str, str]] = None,
                 spark_env_vars: Optional[Mapping[str, str]] = None,
                 ssh_public_keys: Optional[Sequence[str]] = None,
                 workload_type: Optional['outputs.JobTaskNewClusterWorkloadType'] = None):
        """
        :param Sequence['JobTaskNewClusterLibraryArgs'] libraries: (List) An optional list of libraries to be installed on the cluster that will execute the job. See library Configuration Block below.
        :param 'JobTaskNewClusterWorkloadTypeArgs' workload_type: isn't supported
        """
        pulumi.set(__self__, "spark_version", spark_version)
        if apply_policy_default_values is not None:
            pulumi.set(__self__, "apply_policy_default_values", apply_policy_default_values)
        if autoscale is not None:
            pulumi.set(__self__, "autoscale", autoscale)
        if aws_attributes is not None:
            pulumi.set(__self__, "aws_attributes", aws_attributes)
        if azure_attributes is not None:
            pulumi.set(__self__, "azure_attributes", azure_attributes)
        if cluster_id is not None:
            pulumi.set(__self__, "cluster_id", cluster_id)
        if cluster_log_conf is not None:
            pulumi.set(__self__, "cluster_log_conf", cluster_log_conf)
        if cluster_mount_infos is not None:
            pulumi.set(__self__, "cluster_mount_infos", cluster_mount_infos)
        if cluster_name is not None:
            pulumi.set(__self__, "cluster_name", cluster_name)
        if custom_tags is not None:
            pulumi.set(__self__, "custom_tags", custom_tags)
        if data_security_mode is not None:
            pulumi.set(__self__, "data_security_mode", data_security_mode)
        if docker_image is not None:
            pulumi.set(__self__, "docker_image", docker_image)
        if driver_instance_pool_id is not None:
            pulumi.set(__self__, "driver_instance_pool_id", driver_instance_pool_id)
        if driver_node_type_id is not None:
            pulumi.set(__self__, "driver_node_type_id", driver_node_type_id)
        if enable_elastic_disk is not None:
            pulumi.set(__self__, "enable_elastic_disk", enable_elastic_disk)
        if enable_local_disk_encryption is not None:
            pulumi.set(__self__, "enable_local_disk_encryption", enable_local_disk_encryption)
        if gcp_attributes is not None:
            pulumi.set(__self__, "gcp_attributes", gcp_attributes)
        if idempotency_token is not None:
            pulumi.set(__self__, "idempotency_token", idempotency_token)
        if init_scripts is not None:
            pulumi.set(__self__, "init_scripts", init_scripts)
        if instance_pool_id is not None:
            pulumi.set(__self__, "instance_pool_id", instance_pool_id)
        if libraries is not None:
            pulumi.set(__self__, "libraries", libraries)
        if node_type_id is not None:
            pulumi.set(__self__, "node_type_id", node_type_id)
        if num_workers is not None:
            pulumi.set(__self__, "num_workers", num_workers)
        if policy_id is not None:
            pulumi.set(__self__, "policy_id", policy_id)
        if runtime_engine is not None:
            pulumi.set(__self__, "runtime_engine", runtime_engine)
        if single_user_name is not None:
            pulumi.set(__self__, "single_user_name", single_user_name)
        if spark_conf is not None:
            pulumi.set(__self__, "spark_conf", spark_conf)
        if spark_env_vars is not None:
            pulumi.set(__self__, "spark_env_vars", spark_env_vars)
        if ssh_public_keys is not None:
            pulumi.set(__self__, "ssh_public_keys", ssh_public_keys)
        if workload_type is not None:
            pulumi.set(__self__, "workload_type", workload_type)

    @property
    @pulumi.getter(name="sparkVersion")
    def spark_version(self) -> str:
        return pulumi.get(self, "spark_version")

    @property
    @pulumi.getter(name="applyPolicyDefaultValues")
    def apply_policy_default_values(self) -> Optional[bool]:
        return pulumi.get(self, "apply_policy_default_values")

    @property
    @pulumi.getter
    def autoscale(self) -> Optional['outputs.JobTaskNewClusterAutoscale']:
        return pulumi.get(self, "autoscale")

    @property
    @pulumi.getter(name="awsAttributes")
    def aws_attributes(self) -> Optional['outputs.JobTaskNewClusterAwsAttributes']:
        return pulumi.get(self, "aws_attributes")

    @property
    @pulumi.getter(name="azureAttributes")
    def azure_attributes(self) -> Optional['outputs.JobTaskNewClusterAzureAttributes']:
        return pulumi.get(self, "azure_attributes")

    @property
    @pulumi.getter(name="clusterId")
    def cluster_id(self) -> Optional[str]:
        return pulumi.get(self, "cluster_id")

    @property
    @pulumi.getter(name="clusterLogConf")
    def cluster_log_conf(self) -> Optional['outputs.JobTaskNewClusterClusterLogConf']:
        return pulumi.get(self, "cluster_log_conf")

    @property
    @pulumi.getter(name="clusterMountInfos")
    def cluster_mount_infos(self) -> Optional[Sequence['outputs.JobTaskNewClusterClusterMountInfo']]:
        return pulumi.get(self, "cluster_mount_infos")

    @property
    @pulumi.getter(name="clusterName")
    def cluster_name(self) -> Optional[str]:
        return pulumi.get(self, "cluster_name")

    @property
    @pulumi.getter(name="customTags")
    def custom_tags(self) -> Optional[Mapping[str, str]]:
        return pulumi.get(self, "custom_tags")

    @property
    @pulumi.getter(name="dataSecurityMode")
    def data_security_mode(self) -> Optional[str]:
        return pulumi.get(self, "data_security_mode")

    @property
    @pulumi.getter(name="dockerImage")
    def docker_image(self) -> Optional['outputs.JobTaskNewClusterDockerImage']:
        return pulumi.get(self, "docker_image")

    @property
    @pulumi.getter(name="driverInstancePoolId")
    def driver_instance_pool_id(self) -> Optional[str]:
        return pulumi.get(self, "driver_instance_pool_id")

    @property
    @pulumi.getter(name="driverNodeTypeId")
    def driver_node_type_id(self) -> Optional[str]:
        return pulumi.get(self, "driver_node_type_id")

    @property
    @pulumi.getter(name="enableElasticDisk")
    def enable_elastic_disk(self) -> Optional[bool]:
        return pulumi.get(self, "enable_elastic_disk")

    @property
    @pulumi.getter(name="enableLocalDiskEncryption")
    def enable_local_disk_encryption(self) -> Optional[bool]:
        return pulumi.get(self, "enable_local_disk_encryption")

    @property
    @pulumi.getter(name="gcpAttributes")
    def gcp_attributes(self) -> Optional['outputs.JobTaskNewClusterGcpAttributes']:
        return pulumi.get(self, "gcp_attributes")

    @property
    @pulumi.getter(name="idempotencyToken")
    def idempotency_token(self) -> Optional[str]:
        return pulumi.get(self, "idempotency_token")

    @property
    @pulumi.getter(name="initScripts")
    def init_scripts(self) -> Optional[Sequence['outputs.JobTaskNewClusterInitScript']]:
        return pulumi.get(self, "init_scripts")

    @property
    @pulumi.getter(name="instancePoolId")
    def instance_pool_id(self) -> Optional[str]:
        return pulumi.get(self, "instance_pool_id")

    @property
    @pulumi.getter
    def libraries(self) -> Optional[Sequence['outputs.JobTaskNewClusterLibrary']]:
        """
        (List) An optional list of libraries to be installed on the cluster that will execute the job. See library Configuration Block below.
        """
        return pulumi.get(self, "libraries")

    @property
    @pulumi.getter(name="nodeTypeId")
    def node_type_id(self) -> Optional[str]:
        return pulumi.get(self, "node_type_id")

    @property
    @pulumi.getter(name="numWorkers")
    def num_workers(self) -> Optional[int]:
        return pulumi.get(self, "num_workers")

    @property
    @pulumi.getter(name="policyId")
    def policy_id(self) -> Optional[str]:
        return pulumi.get(self, "policy_id")

    @property
    @pulumi.getter(name="runtimeEngine")
    def runtime_engine(self) -> Optional[str]:
        return pulumi.get(self, "runtime_engine")

    @property
    @pulumi.getter(name="singleUserName")
    def single_user_name(self) -> Optional[str]:
        return pulumi.get(self, "single_user_name")

    @property
    @pulumi.getter(name="sparkConf")
    def spark_conf(self) -> Optional[Mapping[str, str]]:
        return pulumi.get(self, "spark_conf")

    @property
    @pulumi.getter(name="sparkEnvVars")
    def spark_env_vars(self) -> Optional[Mapping[str, str]]:
        return pulumi.get(self, "spark_env_vars")

    @property
    @pulumi.getter(name="sshPublicKeys")
    def ssh_public_keys(self) -> Optional[Sequence[str]]:
        return pulumi.get(self, "ssh_public_keys")

    @property
    @pulumi.getter(name="workloadType")
    def workload_type(self) -> Optional['outputs.JobTaskNewClusterWorkloadType']:
        """
        isn't supported
        """
        return pulumi.get(self, "workload_type")


@pulumi.output_type
class JobTaskNewClusterAutoscale(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "maxWorkers":
            suggest = "max_workers"
        elif key == "minWorkers":
            suggest = "min_workers"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in JobTaskNewClusterAutoscale. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        JobTaskNewClusterAutoscale.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        JobTaskNewClusterAutoscale.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 max_workers: Optional[int] = None,
                 min_workers: Optional[int] = None):
        if max_workers is not None:
            pulumi.set(__self__, "max_workers", max_workers)
        if min_workers is not None:
            pulumi.set(__self__, "min_workers", min_workers)

    @property
    @pulumi.getter(name="maxWorkers")
    def max_workers(self) -> Optional[int]:
        return pulumi.get(self, "max_workers")

    @property
    @pulumi.getter(name="minWorkers")
    def min_workers(self) -> Optional[int]:
        return pulumi.get(self, "min_workers")


@pulumi.output_type
class JobTaskNewClusterAwsAttributes(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "ebsVolumeCount":
            suggest = "ebs_volume_count"
        elif key == "ebsVolumeIops":
            suggest = "ebs_volume_iops"
        elif key == "ebsVolumeSize":
            suggest = "ebs_volume_size"
        elif key == "ebsVolumeThroughput":
            suggest = "ebs_volume_throughput"
        elif key == "ebsVolumeType":
            suggest = "ebs_volume_type"
        elif key == "firstOnDemand":
            suggest = "first_on_demand"
        elif key == "instanceProfileArn":
            suggest = "instance_profile_arn"
        elif key == "spotBidPricePercent":
            suggest = "spot_bid_price_percent"
        elif key == "zoneId":
            suggest = "zone_id"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in JobTaskNewClusterAwsAttributes. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        JobTaskNewClusterAwsAttributes.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        JobTaskNewClusterAwsAttributes.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 availability: Optional[str] = None,
                 ebs_volume_count: Optional[int] = None,
                 ebs_volume_iops: Optional[int] = None,
                 ebs_volume_size: Optional[int] = None,
                 ebs_volume_throughput: Optional[int] = None,
                 ebs_volume_type: Optional[str] = None,
                 first_on_demand: Optional[int] = None,
                 instance_profile_arn: Optional[str] = None,
                 spot_bid_price_percent: Optional[int] = None,
                 zone_id: Optional[str] = None):
        if availability is not None:
            pulumi.set(__self__, "availability", availability)
        if ebs_volume_count is not None:
            pulumi.set(__self__, "ebs_volume_count", ebs_volume_count)
        if ebs_volume_iops is not None:
            pulumi.set(__self__, "ebs_volume_iops", ebs_volume_iops)
        if ebs_volume_size is not None:
            pulumi.set(__self__, "ebs_volume_size", ebs_volume_size)
        if ebs_volume_throughput is not None:
            pulumi.set(__self__, "ebs_volume_throughput", ebs_volume_throughput)
        if ebs_volume_type is not None:
            pulumi.set(__self__, "ebs_volume_type", ebs_volume_type)
        if first_on_demand is not None:
            pulumi.set(__self__, "first_on_demand", first_on_demand)
        if instance_profile_arn is not None:
            pulumi.set(__self__, "instance_profile_arn", instance_profile_arn)
        if spot_bid_price_percent is not None:
            pulumi.set(__self__, "spot_bid_price_percent", spot_bid_price_percent)
        if zone_id is not None:
            pulumi.set(__self__, "zone_id", zone_id)

    @property
    @pulumi.getter
    def availability(self) -> Optional[str]:
        return pulumi.get(self, "availability")

    @property
    @pulumi.getter(name="ebsVolumeCount")
    def ebs_volume_count(self) -> Optional[int]:
        return pulumi.get(self, "ebs_volume_count")

    @property
    @pulumi.getter(name="ebsVolumeIops")
    def ebs_volume_iops(self) -> Optional[int]:
        return pulumi.get(self, "ebs_volume_iops")

    @property
    @pulumi.getter(name="ebsVolumeSize")
    def ebs_volume_size(self) -> Optional[int]:
        return pulumi.get(self, "ebs_volume_size")

    @property
    @pulumi.getter(name="ebsVolumeThroughput")
    def ebs_volume_throughput(self) -> Optional[int]:
        return pulumi.get(self, "ebs_volume_throughput")

    @property
    @pulumi.getter(name="ebsVolumeType")
    def ebs_volume_type(self) -> Optional[str]:
        return pulumi.get(self, "ebs_volume_type")

    @property
    @pulumi.getter(name="firstOnDemand")
    def first_on_demand(self) -> Optional[int]:
        return pulumi.get(self, "first_on_demand")

    @property
    @pulumi.getter(name="instanceProfileArn")
    def instance_profile_arn(self) -> Optional[str]:
        return pulumi.get(self, "instance_profile_arn")

    @property
    @pulumi.getter(name="spotBidPricePercent")
    def spot_bid_price_percent(self) -> Optional[int]:
        return pulumi.get(self, "spot_bid_price_percent")

    @property
    @pulumi.getter(name="zoneId")
    def zone_id(self) -> Optional[str]:
        return pulumi.get(self, "zone_id")


@pulumi.output_type
class JobTaskNewClusterAzureAttributes(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "firstOnDemand":
            suggest = "first_on_demand"
        elif key == "logAnalyticsInfo":
            suggest = "log_analytics_info"
        elif key == "spotBidMaxPrice":
            suggest = "spot_bid_max_price"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in JobTaskNewClusterAzureAttributes. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        JobTaskNewClusterAzureAttributes.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        JobTaskNewClusterAzureAttributes.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 availability: Optional[str] = None,
                 first_on_demand: Optional[int] = None,
                 log_analytics_info: Optional['outputs.JobTaskNewClusterAzureAttributesLogAnalyticsInfo'] = None,
                 spot_bid_max_price: Optional[float] = None):
        if availability is not None:
            pulumi.set(__self__, "availability", availability)
        if first_on_demand is not None:
            pulumi.set(__self__, "first_on_demand", first_on_demand)
        if log_analytics_info is not None:
            pulumi.set(__self__, "log_analytics_info", log_analytics_info)
        if spot_bid_max_price is not None:
            pulumi.set(__self__, "spot_bid_max_price", spot_bid_max_price)

    @property
    @pulumi.getter
    def availability(self) -> Optional[str]:
        return pulumi.get(self, "availability")

    @property
    @pulumi.getter(name="firstOnDemand")
    def first_on_demand(self) -> Optional[int]:
        return pulumi.get(self, "first_on_demand")

    @property
    @pulumi.getter(name="logAnalyticsInfo")
    def log_analytics_info(self) -> Optional['outputs.JobTaskNewClusterAzureAttributesLogAnalyticsInfo']:
        return pulumi.get(self, "log_analytics_info")

    @property
    @pulumi.getter(name="spotBidMaxPrice")
    def spot_bid_max_price(self) -> Optional[float]:
        return pulumi.get(self, "spot_bid_max_price")


@pulumi.output_type
class JobTaskNewClusterAzureAttributesLogAnalyticsInfo(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "logAnalyticsPrimaryKey":
            suggest = "log_analytics_primary_key"
        elif key == "logAnalyticsWorkspaceId":
            suggest = "log_analytics_workspace_id"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in JobTaskNewClusterAzureAttributesLogAnalyticsInfo. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        JobTaskNewClusterAzureAttributesLogAnalyticsInfo.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        JobTaskNewClusterAzureAttributesLogAnalyticsInfo.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 log_analytics_primary_key: Optional[str] = None,
                 log_analytics_workspace_id: Optional[str] = None):
        if log_analytics_primary_key is not None:
            pulumi.set(__self__, "log_analytics_primary_key", log_analytics_primary_key)
        if log_analytics_workspace_id is not None:
            pulumi.set(__self__, "log_analytics_workspace_id", log_analytics_workspace_id)

    @property
    @pulumi.getter(name="logAnalyticsPrimaryKey")
    def log_analytics_primary_key(self) -> Optional[str]:
        return pulumi.get(self, "log_analytics_primary_key")

    @property
    @pulumi.getter(name="logAnalyticsWorkspaceId")
    def log_analytics_workspace_id(self) -> Optional[str]:
        return pulumi.get(self, "log_analytics_workspace_id")


@pulumi.output_type
class JobTaskNewClusterClusterLogConf(dict):
    def __init__(__self__, *,
                 dbfs: Optional['outputs.JobTaskNewClusterClusterLogConfDbfs'] = None,
                 s3: Optional['outputs.JobTaskNewClusterClusterLogConfS3'] = None):
        if dbfs is not None:
            pulumi.set(__self__, "dbfs", dbfs)
        if s3 is not None:
            pulumi.set(__self__, "s3", s3)

    @property
    @pulumi.getter
    def dbfs(self) -> Optional['outputs.JobTaskNewClusterClusterLogConfDbfs']:
        return pulumi.get(self, "dbfs")

    @property
    @pulumi.getter
    def s3(self) -> Optional['outputs.JobTaskNewClusterClusterLogConfS3']:
        return pulumi.get(self, "s3")


@pulumi.output_type
class JobTaskNewClusterClusterLogConfDbfs(dict):
    def __init__(__self__, *,
                 destination: str):
        pulumi.set(__self__, "destination", destination)

    @property
    @pulumi.getter
    def destination(self) -> str:
        return pulumi.get(self, "destination")


@pulumi.output_type
class JobTaskNewClusterClusterLogConfS3(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "cannedAcl":
            suggest = "canned_acl"
        elif key == "enableEncryption":
            suggest = "enable_encryption"
        elif key == "encryptionType":
            suggest = "encryption_type"
        elif key == "kmsKey":
            suggest = "kms_key"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in JobTaskNewClusterClusterLogConfS3. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        JobTaskNewClusterClusterLogConfS3.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        JobTaskNewClusterClusterLogConfS3.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 destination: str,
                 canned_acl: Optional[str] = None,
                 enable_encryption: Optional[bool] = None,
                 encryption_type: Optional[str] = None,
                 endpoint: Optional[str] = None,
                 kms_key: Optional[str] = None,
                 region: Optional[str] = None):
        pulumi.set(__self__, "destination", destination)
        if canned_acl is not None:
            pulumi.set(__self__, "canned_acl", canned_acl)
        if enable_encryption is not None:
            pulumi.set(__self__, "enable_encryption", enable_encryption)
        if encryption_type is not None:
            pulumi.set(__self__, "encryption_type", encryption_type)
        if endpoint is not None:
            pulumi.set(__self__, "endpoint", endpoint)
        if kms_key is not None:
            pulumi.set(__self__, "kms_key", kms_key)
        if region is not None:
            pulumi.set(__self__, "region", region)

    @property
    @pulumi.getter
    def destination(self) -> str:
        return pulumi.get(self, "destination")

    @property
    @pulumi.getter(name="cannedAcl")
    def canned_acl(self) -> Optional[str]:
        return pulumi.get(self, "canned_acl")

    @property
    @pulumi.getter(name="enableEncryption")
    def enable_encryption(self) -> Optional[bool]:
        return pulumi.get(self, "enable_encryption")

    @property
    @pulumi.getter(name="encryptionType")
    def encryption_type(self) -> Optional[str]:
        return pulumi.get(self, "encryption_type")

    @property
    @pulumi.getter
    def endpoint(self) -> Optional[str]:
        return pulumi.get(self, "endpoint")

    @property
    @pulumi.getter(name="kmsKey")
    def kms_key(self) -> Optional[str]:
        return pulumi.get(self, "kms_key")

    @property
    @pulumi.getter
    def region(self) -> Optional[str]:
        return pulumi.get(self, "region")


@pulumi.output_type
class JobTaskNewClusterClusterMountInfo(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "localMountDirPath":
            suggest = "local_mount_dir_path"
        elif key == "networkFilesystemInfo":
            suggest = "network_filesystem_info"
        elif key == "remoteMountDirPath":
            suggest = "remote_mount_dir_path"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in JobTaskNewClusterClusterMountInfo. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        JobTaskNewClusterClusterMountInfo.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        JobTaskNewClusterClusterMountInfo.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 local_mount_dir_path: str,
                 network_filesystem_info: 'outputs.JobTaskNewClusterClusterMountInfoNetworkFilesystemInfo',
                 remote_mount_dir_path: Optional[str] = None):
        pulumi.set(__self__, "local_mount_dir_path", local_mount_dir_path)
        pulumi.set(__self__, "network_filesystem_info", network_filesystem_info)
        if remote_mount_dir_path is not None:
            pulumi.set(__self__, "remote_mount_dir_path", remote_mount_dir_path)

    @property
    @pulumi.getter(name="localMountDirPath")
    def local_mount_dir_path(self) -> str:
        return pulumi.get(self, "local_mount_dir_path")

    @property
    @pulumi.getter(name="networkFilesystemInfo")
    def network_filesystem_info(self) -> 'outputs.JobTaskNewClusterClusterMountInfoNetworkFilesystemInfo':
        return pulumi.get(self, "network_filesystem_info")

    @property
    @pulumi.getter(name="remoteMountDirPath")
    def remote_mount_dir_path(self) -> Optional[str]:
        return pulumi.get(self, "remote_mount_dir_path")


@pulumi.output_type
class JobTaskNewClusterClusterMountInfoNetworkFilesystemInfo(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "serverAddress":
            suggest = "server_address"
        elif key == "mountOptions":
            suggest = "mount_options"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in JobTaskNewClusterClusterMountInfoNetworkFilesystemInfo. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        JobTaskNewClusterClusterMountInfoNetworkFilesystemInfo.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        JobTaskNewClusterClusterMountInfoNetworkFilesystemInfo.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 server_address: str,
                 mount_options: Optional[str] = None):
        pulumi.set(__self__, "server_address", server_address)
        if mount_options is not None:
            pulumi.set(__self__, "mount_options", mount_options)

    @property
    @pulumi.getter(name="serverAddress")
    def server_address(self) -> str:
        return pulumi.get(self, "server_address")

    @property
    @pulumi.getter(name="mountOptions")
    def mount_options(self) -> Optional[str]:
        return pulumi.get(self, "mount_options")


@pulumi.output_type
class JobTaskNewClusterDockerImage(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "basicAuth":
            suggest = "basic_auth"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in JobTaskNewClusterDockerImage. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        JobTaskNewClusterDockerImage.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        JobTaskNewClusterDockerImage.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 url: str,
                 basic_auth: Optional['outputs.JobTaskNewClusterDockerImageBasicAuth'] = None):
        """
        :param str url: URL of the job on the given workspace
        """
        pulumi.set(__self__, "url", url)
        if basic_auth is not None:
            pulumi.set(__self__, "basic_auth", basic_auth)

    @property
    @pulumi.getter
    def url(self) -> str:
        """
        URL of the job on the given workspace
        """
        return pulumi.get(self, "url")

    @property
    @pulumi.getter(name="basicAuth")
    def basic_auth(self) -> Optional['outputs.JobTaskNewClusterDockerImageBasicAuth']:
        return pulumi.get(self, "basic_auth")


@pulumi.output_type
class JobTaskNewClusterDockerImageBasicAuth(dict):
    def __init__(__self__, *,
                 password: str,
                 username: str):
        pulumi.set(__self__, "password", password)
        pulumi.set(__self__, "username", username)

    @property
    @pulumi.getter
    def password(self) -> str:
        return pulumi.get(self, "password")

    @property
    @pulumi.getter
    def username(self) -> str:
        return pulumi.get(self, "username")


@pulumi.output_type
class JobTaskNewClusterGcpAttributes(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "bootDiskSize":
            suggest = "boot_disk_size"
        elif key == "googleServiceAccount":
            suggest = "google_service_account"
        elif key == "localSsdCount":
            suggest = "local_ssd_count"
        elif key == "usePreemptibleExecutors":
            suggest = "use_preemptible_executors"
        elif key == "zoneId":
            suggest = "zone_id"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in JobTaskNewClusterGcpAttributes. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        JobTaskNewClusterGcpAttributes.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        JobTaskNewClusterGcpAttributes.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 availability: Optional[str] = None,
                 boot_disk_size: Optional[int] = None,
                 google_service_account: Optional[str] = None,
                 local_ssd_count: Optional[int] = None,
                 use_preemptible_executors: Optional[bool] = None,
                 zone_id: Optional[str] = None):
        if availability is not None:
            pulumi.set(__self__, "availability", availability)
        if boot_disk_size is not None:
            pulumi.set(__self__, "boot_disk_size", boot_disk_size)
        if google_service_account is not None:
            pulumi.set(__self__, "google_service_account", google_service_account)
        if local_ssd_count is not None:
            pulumi.set(__self__, "local_ssd_count", local_ssd_count)
        if use_preemptible_executors is not None:
            pulumi.set(__self__, "use_preemptible_executors", use_preemptible_executors)
        if zone_id is not None:
            pulumi.set(__self__, "zone_id", zone_id)

    @property
    @pulumi.getter
    def availability(self) -> Optional[str]:
        return pulumi.get(self, "availability")

    @property
    @pulumi.getter(name="bootDiskSize")
    def boot_disk_size(self) -> Optional[int]:
        return pulumi.get(self, "boot_disk_size")

    @property
    @pulumi.getter(name="googleServiceAccount")
    def google_service_account(self) -> Optional[str]:
        return pulumi.get(self, "google_service_account")

    @property
    @pulumi.getter(name="localSsdCount")
    def local_ssd_count(self) -> Optional[int]:
        return pulumi.get(self, "local_ssd_count")

    @property
    @pulumi.getter(name="usePreemptibleExecutors")
    def use_preemptible_executors(self) -> Optional[bool]:
        return pulumi.get(self, "use_preemptible_executors")

    @property
    @pulumi.getter(name="zoneId")
    def zone_id(self) -> Optional[str]:
        return pulumi.get(self, "zone_id")


@pulumi.output_type
class JobTaskNewClusterInitScript(dict):
    def __init__(__self__, *,
                 abfss: Optional['outputs.JobTaskNewClusterInitScriptAbfss'] = None,
                 dbfs: Optional['outputs.JobTaskNewClusterInitScriptDbfs'] = None,
                 file: Optional['outputs.JobTaskNewClusterInitScriptFile'] = None,
                 gcs: Optional['outputs.JobTaskNewClusterInitScriptGcs'] = None,
                 s3: Optional['outputs.JobTaskNewClusterInitScriptS3'] = None,
                 volumes: Optional['outputs.JobTaskNewClusterInitScriptVolumes'] = None,
                 workspace: Optional['outputs.JobTaskNewClusterInitScriptWorkspace'] = None):
        """
        :param 'JobTaskNewClusterInitScriptFileArgs' file: block consisting of single string fields:
        """
        if abfss is not None:
            pulumi.set(__self__, "abfss", abfss)
        if dbfs is not None:
            pulumi.set(__self__, "dbfs", dbfs)
        if file is not None:
            pulumi.set(__self__, "file", file)
        if gcs is not None:
            pulumi.set(__self__, "gcs", gcs)
        if s3 is not None:
            pulumi.set(__self__, "s3", s3)
        if volumes is not None:
            pulumi.set(__self__, "volumes", volumes)
        if workspace is not None:
            pulumi.set(__self__, "workspace", workspace)

    @property
    @pulumi.getter
    def abfss(self) -> Optional['outputs.JobTaskNewClusterInitScriptAbfss']:
        return pulumi.get(self, "abfss")

    @property
    @pulumi.getter
    @_utilities.deprecated("""For init scripts use 'volumes', 'workspace' or cloud storage location instead of 'dbfs'.""")
    def dbfs(self) -> Optional['outputs.JobTaskNewClusterInitScriptDbfs']:
        return pulumi.get(self, "dbfs")

    @property
    @pulumi.getter
    def file(self) -> Optional['outputs.JobTaskNewClusterInitScriptFile']:
        """
        block consisting of single string fields:
        """
        return pulumi.get(self, "file")

    @property
    @pulumi.getter
    def gcs(self) -> Optional['outputs.JobTaskNewClusterInitScriptGcs']:
        return pulumi.get(self, "gcs")

    @property
    @pulumi.getter
    def s3(self) -> Optional['outputs.JobTaskNewClusterInitScriptS3']:
        return pulumi.get(self, "s3")

    @property
    @pulumi.getter
    def volumes(self) -> Optional['outputs.JobTaskNewClusterInitScriptVolumes']:
        return pulumi.get(self, "volumes")

    @property
    @pulumi.getter
    def workspace(self) -> Optional['outputs.JobTaskNewClusterInitScriptWorkspace']:
        return pulumi.get(self, "workspace")


@pulumi.output_type
class JobTaskNewClusterInitScriptAbfss(dict):
    def __init__(__self__, *,
                 destination: str):
        pulumi.set(__self__, "destination", destination)

    @property
    @pulumi.getter
    def destination(self) -> str:
        return pulumi.get(self, "destination")


@pulumi.output_type
class JobTaskNewClusterInitScriptDbfs(dict):
    def __init__(__self__, *,
                 destination: str):
        pulumi.set(__self__, "destination", destination)

    @property
    @pulumi.getter
    def destination(self) -> str:
        return pulumi.get(self, "destination")


@pulumi.output_type
class JobTaskNewClusterInitScriptFile(dict):
    def __init__(__self__, *,
                 destination: str):
        pulumi.set(__self__, "destination", destination)

    @property
    @pulumi.getter
    def destination(self) -> str:
        return pulumi.get(self, "destination")


@pulumi.output_type
class JobTaskNewClusterInitScriptGcs(dict):
    def __init__(__self__, *,
                 destination: str):
        pulumi.set(__self__, "destination", destination)

    @property
    @pulumi.getter
    def destination(self) -> str:
        return pulumi.get(self, "destination")


@pulumi.output_type
class JobTaskNewClusterInitScriptS3(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "cannedAcl":
            suggest = "canned_acl"
        elif key == "enableEncryption":
            suggest = "enable_encryption"
        elif key == "encryptionType":
            suggest = "encryption_type"
        elif key == "kmsKey":
            suggest = "kms_key"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in JobTaskNewClusterInitScriptS3. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        JobTaskNewClusterInitScriptS3.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        JobTaskNewClusterInitScriptS3.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 destination: str,
                 canned_acl: Optional[str] = None,
                 enable_encryption: Optional[bool] = None,
                 encryption_type: Optional[str] = None,
                 endpoint: Optional[str] = None,
                 kms_key: Optional[str] = None,
                 region: Optional[str] = None):
        pulumi.set(__self__, "destination", destination)
        if canned_acl is not None:
            pulumi.set(__self__, "canned_acl", canned_acl)
        if enable_encryption is not None:
            pulumi.set(__self__, "enable_encryption", enable_encryption)
        if encryption_type is not None:
            pulumi.set(__self__, "encryption_type", encryption_type)
        if endpoint is not None:
            pulumi.set(__self__, "endpoint", endpoint)
        if kms_key is not None:
            pulumi.set(__self__, "kms_key", kms_key)
        if region is not None:
            pulumi.set(__self__, "region", region)

    @property
    @pulumi.getter
    def destination(self) -> str:
        return pulumi.get(self, "destination")

    @property
    @pulumi.getter(name="cannedAcl")
    def canned_acl(self) -> Optional[str]:
        return pulumi.get(self, "canned_acl")

    @property
    @pulumi.getter(name="enableEncryption")
    def enable_encryption(self) -> Optional[bool]:
        return pulumi.get(self, "enable_encryption")

    @property
    @pulumi.getter(name="encryptionType")
    def encryption_type(self) -> Optional[str]:
        return pulumi.get(self, "encryption_type")

    @property
    @pulumi.getter
    def endpoint(self) -> Optional[str]:
        return pulumi.get(self, "endpoint")

    @property
    @pulumi.getter(name="kmsKey")
    def kms_key(self) -> Optional[str]:
        return pulumi.get(self, "kms_key")

    @property
    @pulumi.getter
    def region(self) -> Optional[str]:
        return pulumi.get(self, "region")


@pulumi.output_type
class JobTaskNewClusterInitScriptVolumes(dict):
    def __init__(__self__, *,
                 destination: str):
        pulumi.set(__self__, "destination", destination)

    @property
    @pulumi.getter
    def destination(self) -> str:
        return pulumi.get(self, "destination")


@pulumi.output_type
class JobTaskNewClusterInitScriptWorkspace(dict):
    def __init__(__self__, *,
                 destination: str):
        pulumi.set(__self__, "destination", destination)

    @property
    @pulumi.getter
    def destination(self) -> str:
        return pulumi.get(self, "destination")


@pulumi.output_type
class JobTaskNewClusterLibrary(dict):
    def __init__(__self__, *,
                 cran: Optional['outputs.JobTaskNewClusterLibraryCran'] = None,
                 egg: Optional[str] = None,
                 jar: Optional[str] = None,
                 maven: Optional['outputs.JobTaskNewClusterLibraryMaven'] = None,
                 pypi: Optional['outputs.JobTaskNewClusterLibraryPypi'] = None,
                 requirements: Optional[str] = None,
                 whl: Optional[str] = None):
        if cran is not None:
            pulumi.set(__self__, "cran", cran)
        if egg is not None:
            pulumi.set(__self__, "egg", egg)
        if jar is not None:
            pulumi.set(__self__, "jar", jar)
        if maven is not None:
            pulumi.set(__self__, "maven", maven)
        if pypi is not None:
            pulumi.set(__self__, "pypi", pypi)
        if requirements is not None:
            pulumi.set(__self__, "requirements", requirements)
        if whl is not None:
            pulumi.set(__self__, "whl", whl)

    @property
    @pulumi.getter
    def cran(self) -> Optional['outputs.JobTaskNewClusterLibraryCran']:
        return pulumi.get(self, "cran")

    @property
    @pulumi.getter
    def egg(self) -> Optional[str]:
        return pulumi.get(self, "egg")

    @property
    @pulumi.getter
    def jar(self) -> Optional[str]:
        return pulumi.get(self, "jar")

    @property
    @pulumi.getter
    def maven(self) -> Optional['outputs.JobTaskNewClusterLibraryMaven']:
        return pulumi.get(self, "maven")

    @property
    @pulumi.getter
    def pypi(self) -> Optional['outputs.JobTaskNewClusterLibraryPypi']:
        return pulumi.get(self, "pypi")

    @property
    @pulumi.getter
    def requirements(self) -> Optional[str]:
        return pulumi.get(self, "requirements")

    @property
    @pulumi.getter
    def whl(self) -> Optional[str]:
        return pulumi.get(self, "whl")


@pulumi.output_type
class JobTaskNewClusterLibraryCran(dict):
    def __init__(__self__, *,
                 package: str,
                 repo: Optional[str] = None):
        pulumi.set(__self__, "package", package)
        if repo is not None:
            pulumi.set(__self__, "repo", repo)

    @property
    @pulumi.getter
    def package(self) -> str:
        return pulumi.get(self, "package")

    @property
    @pulumi.getter
    def repo(self) -> Optional[str]:
        return pulumi.get(self, "repo")


@pulumi.output_type
class JobTaskNewClusterLibraryMaven(dict):
    def __init__(__self__, *,
                 coordinates: str,
                 exclusions: Optional[Sequence[str]] = None,
                 repo: Optional[str] = None):
        pulumi.set(__self__, "coordinates", coordinates)
        if exclusions is not None:
            pulumi.set(__self__, "exclusions", exclusions)
        if repo is not None:
            pulumi.set(__self__, "repo", repo)

    @property
    @pulumi.getter
    def coordinates(self) -> str:
        return pulumi.get(self, "coordinates")

    @property
    @pulumi.getter
    def exclusions(self) -> Optional[Sequence[str]]:
        return pulumi.get(self, "exclusions")

    @property
    @pulumi.getter
    def repo(self) -> Optional[str]:
        return pulumi.get(self, "repo")


@pulumi.output_type
class JobTaskNewClusterLibraryPypi(dict):
    def __init__(__self__, *,
                 package: str,
                 repo: Optional[str] = None):
        pulumi.set(__self__, "package", package)
        if repo is not None:
            pulumi.set(__self__, "repo", repo)

    @property
    @pulumi.getter
    def package(self) -> str:
        return pulumi.get(self, "package")

    @property
    @pulumi.getter
    def repo(self) -> Optional[str]:
        return pulumi.get(self, "repo")


@pulumi.output_type
class JobTaskNewClusterWorkloadType(dict):
    def __init__(__self__, *,
                 clients: 'outputs.JobTaskNewClusterWorkloadTypeClients'):
        pulumi.set(__self__, "clients", clients)

    @property
    @pulumi.getter
    def clients(self) -> 'outputs.JobTaskNewClusterWorkloadTypeClients':
        return pulumi.get(self, "clients")


@pulumi.output_type
class JobTaskNewClusterWorkloadTypeClients(dict):
    def __init__(__self__, *,
                 jobs: Optional[bool] = None,
                 notebooks: Optional[bool] = None):
        if jobs is not None:
            pulumi.set(__self__, "jobs", jobs)
        if notebooks is not None:
            pulumi.set(__self__, "notebooks", notebooks)

    @property
    @pulumi.getter
    def jobs(self) -> Optional[bool]:
        return pulumi.get(self, "jobs")

    @property
    @pulumi.getter
    def notebooks(self) -> Optional[bool]:
        return pulumi.get(self, "notebooks")


@pulumi.output_type
class JobTaskNotebookTask(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "notebookPath":
            suggest = "notebook_path"
        elif key == "baseParameters":
            suggest = "base_parameters"
        elif key == "warehouseId":
            suggest = "warehouse_id"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in JobTaskNotebookTask. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        JobTaskNotebookTask.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        JobTaskNotebookTask.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 notebook_path: str,
                 base_parameters: Optional[Mapping[str, str]] = None,
                 source: Optional[str] = None,
                 warehouse_id: Optional[str] = None):
        """
        :param str notebook_path: The path of the Notebook to be run in the Databricks workspace or remote repository. For notebooks stored in the Databricks workspace, the path must be absolute and begin with a slash. For notebooks stored in a remote repository, the path must be relative. This field is required.
        :param Mapping[str, str] base_parameters: (Map) Base parameters to be used for each run of this job. If the run is initiated by a call to run-now with parameters specified, the two parameters maps will be merged. If the same key is specified in base_parameters and in run-now, the value from run-now will be used. If the notebook takes a parameter that is not specified in the jobs base_parameters or the run-now override parameters, the default value from the notebook will be used. Retrieve these parameters in a notebook using `dbutils.widgets.get`.
        :param str source: Location type of the notebook, can only be `WORKSPACE` or `GIT`. When set to `WORKSPACE`, the notebook will be retrieved from the local Databricks workspace. When set to `GIT`, the notebook will be retrieved from a Git repository defined in `git_source`. If the value is empty, the task will use `GIT` if `git_source` is defined and `WORKSPACE` otherwise.
        :param str warehouse_id: ID of the (the databricks_sql_endpoint) that will be used to execute the task with SQL notebook.
        """
        pulumi.set(__self__, "notebook_path", notebook_path)
        if base_parameters is not None:
            pulumi.set(__self__, "base_parameters", base_parameters)
        if source is not None:
            pulumi.set(__self__, "source", source)
        if warehouse_id is not None:
            pulumi.set(__self__, "warehouse_id", warehouse_id)

    @property
    @pulumi.getter(name="notebookPath")
    def notebook_path(self) -> str:
        """
        The path of the Notebook to be run in the Databricks workspace or remote repository. For notebooks stored in the Databricks workspace, the path must be absolute and begin with a slash. For notebooks stored in a remote repository, the path must be relative. This field is required.
        """
        return pulumi.get(self, "notebook_path")

    @property
    @pulumi.getter(name="baseParameters")
    def base_parameters(self) -> Optional[Mapping[str, str]]:
        """
        (Map) Base parameters to be used for each run of this job. If the run is initiated by a call to run-now with parameters specified, the two parameters maps will be merged. If the same key is specified in base_parameters and in run-now, the value from run-now will be used. If the notebook takes a parameter that is not specified in the jobs base_parameters or the run-now override parameters, the default value from the notebook will be used. Retrieve these parameters in a notebook using `dbutils.widgets.get`.
        """
        return pulumi.get(self, "base_parameters")

    @property
    @pulumi.getter
    def source(self) -> Optional[str]:
        """
        Location type of the notebook, can only be `WORKSPACE` or `GIT`. When set to `WORKSPACE`, the notebook will be retrieved from the local Databricks workspace. When set to `GIT`, the notebook will be retrieved from a Git repository defined in `git_source`. If the value is empty, the task will use `GIT` if `git_source` is defined and `WORKSPACE` otherwise.
        """
        return pulumi.get(self, "source")

    @property
    @pulumi.getter(name="warehouseId")
    def warehouse_id(self) -> Optional[str]:
        """
        ID of the (the databricks_sql_endpoint) that will be used to execute the task with SQL notebook.
        """
        return pulumi.get(self, "warehouse_id")


@pulumi.output_type
class JobTaskNotificationSettings(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "alertOnLastAttempt":
            suggest = "alert_on_last_attempt"
        elif key == "noAlertForCanceledRuns":
            suggest = "no_alert_for_canceled_runs"
        elif key == "noAlertForSkippedRuns":
            suggest = "no_alert_for_skipped_runs"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in JobTaskNotificationSettings. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        JobTaskNotificationSettings.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        JobTaskNotificationSettings.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 alert_on_last_attempt: Optional[bool] = None,
                 no_alert_for_canceled_runs: Optional[bool] = None,
                 no_alert_for_skipped_runs: Optional[bool] = None):
        """
        :param bool alert_on_last_attempt: (Bool) do not send notifications to recipients specified in `on_start` for the retried runs and do not send notifications to recipients specified in `on_failure` until the last retry of the run.
        :param bool no_alert_for_canceled_runs: (Bool) don't send alert for cancelled runs.
               
               The following parameter is only available on task level.
        :param bool no_alert_for_skipped_runs: (Bool) don't send alert for skipped runs.
        """
        if alert_on_last_attempt is not None:
            pulumi.set(__self__, "alert_on_last_attempt", alert_on_last_attempt)
        if no_alert_for_canceled_runs is not None:
            pulumi.set(__self__, "no_alert_for_canceled_runs", no_alert_for_canceled_runs)
        if no_alert_for_skipped_runs is not None:
            pulumi.set(__self__, "no_alert_for_skipped_runs", no_alert_for_skipped_runs)

    @property
    @pulumi.getter(name="alertOnLastAttempt")
    def alert_on_last_attempt(self) -> Optional[bool]:
        """
        (Bool) do not send notifications to recipients specified in `on_start` for the retried runs and do not send notifications to recipients specified in `on_failure` until the last retry of the run.
        """
        return pulumi.get(self, "alert_on_last_attempt")

    @property
    @pulumi.getter(name="noAlertForCanceledRuns")
    def no_alert_for_canceled_runs(self) -> Optional[bool]:
        """
        (Bool) don't send alert for cancelled runs.

        The following parameter is only available on task level.
        """
        return pulumi.get(self, "no_alert_for_canceled_runs")

    @property
    @pulumi.getter(name="noAlertForSkippedRuns")
    def no_alert_for_skipped_runs(self) -> Optional[bool]:
        """
        (Bool) don't send alert for skipped runs.
        """
        return pulumi.get(self, "no_alert_for_skipped_runs")


@pulumi.output_type
class JobTaskPipelineTask(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "pipelineId":
            suggest = "pipeline_id"
        elif key == "fullRefresh":
            suggest = "full_refresh"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in JobTaskPipelineTask. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        JobTaskPipelineTask.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        JobTaskPipelineTask.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 pipeline_id: str,
                 full_refresh: Optional[bool] = None):
        """
        :param str pipeline_id: The pipeline's unique ID.
        :param bool full_refresh: (Bool) Specifies if there should be full refresh of the pipeline.
               
               > **Note** The following configuration blocks are only supported inside a `task` block
        """
        pulumi.set(__self__, "pipeline_id", pipeline_id)
        if full_refresh is not None:
            pulumi.set(__self__, "full_refresh", full_refresh)

    @property
    @pulumi.getter(name="pipelineId")
    def pipeline_id(self) -> str:
        """
        The pipeline's unique ID.
        """
        return pulumi.get(self, "pipeline_id")

    @property
    @pulumi.getter(name="fullRefresh")
    def full_refresh(self) -> Optional[bool]:
        """
        (Bool) Specifies if there should be full refresh of the pipeline.

        > **Note** The following configuration blocks are only supported inside a `task` block
        """
        return pulumi.get(self, "full_refresh")


@pulumi.output_type
class JobTaskPythonWheelTask(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "entryPoint":
            suggest = "entry_point"
        elif key == "namedParameters":
            suggest = "named_parameters"
        elif key == "packageName":
            suggest = "package_name"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in JobTaskPythonWheelTask. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        JobTaskPythonWheelTask.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        JobTaskPythonWheelTask.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 entry_point: Optional[str] = None,
                 named_parameters: Optional[Mapping[str, str]] = None,
                 package_name: Optional[str] = None,
                 parameters: Optional[Sequence[str]] = None):
        """
        :param str entry_point: Python function as entry point for the task
        :param Mapping[str, str] named_parameters: Named parameters for the task
        :param str package_name: Name of Python package
        :param Sequence[str] parameters: Parameters for the task
        """
        if entry_point is not None:
            pulumi.set(__self__, "entry_point", entry_point)
        if named_parameters is not None:
            pulumi.set(__self__, "named_parameters", named_parameters)
        if package_name is not None:
            pulumi.set(__self__, "package_name", package_name)
        if parameters is not None:
            pulumi.set(__self__, "parameters", parameters)

    @property
    @pulumi.getter(name="entryPoint")
    def entry_point(self) -> Optional[str]:
        """
        Python function as entry point for the task
        """
        return pulumi.get(self, "entry_point")

    @property
    @pulumi.getter(name="namedParameters")
    def named_parameters(self) -> Optional[Mapping[str, str]]:
        """
        Named parameters for the task
        """
        return pulumi.get(self, "named_parameters")

    @property
    @pulumi.getter(name="packageName")
    def package_name(self) -> Optional[str]:
        """
        Name of Python package
        """
        return pulumi.get(self, "package_name")

    @property
    @pulumi.getter
    def parameters(self) -> Optional[Sequence[str]]:
        """
        Parameters for the task
        """
        return pulumi.get(self, "parameters")


@pulumi.output_type
class JobTaskRunJobTask(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "jobId":
            suggest = "job_id"
        elif key == "dbtCommands":
            suggest = "dbt_commands"
        elif key == "jarParams":
            suggest = "jar_params"
        elif key == "jobParameters":
            suggest = "job_parameters"
        elif key == "notebookParams":
            suggest = "notebook_params"
        elif key == "pipelineParams":
            suggest = "pipeline_params"
        elif key == "pythonNamedParams":
            suggest = "python_named_params"
        elif key == "pythonParams":
            suggest = "python_params"
        elif key == "sparkSubmitParams":
            suggest = "spark_submit_params"
        elif key == "sqlParams":
            suggest = "sql_params"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in JobTaskRunJobTask. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        JobTaskRunJobTask.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        JobTaskRunJobTask.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 job_id: int,
                 dbt_commands: Optional[Sequence[str]] = None,
                 jar_params: Optional[Sequence[str]] = None,
                 job_parameters: Optional[Mapping[str, str]] = None,
                 notebook_params: Optional[Mapping[str, str]] = None,
                 pipeline_params: Optional['outputs.JobTaskRunJobTaskPipelineParams'] = None,
                 python_named_params: Optional[Mapping[str, str]] = None,
                 python_params: Optional[Sequence[str]] = None,
                 spark_submit_params: Optional[Sequence[str]] = None,
                 sql_params: Optional[Mapping[str, str]] = None):
        """
        :param int job_id: (String) ID of the job
        :param Mapping[str, str] job_parameters: (Map) Job parameters for the task
        """
        pulumi.set(__self__, "job_id", job_id)
        if dbt_commands is not None:
            pulumi.set(__self__, "dbt_commands", dbt_commands)
        if jar_params is not None:
            pulumi.set(__self__, "jar_params", jar_params)
        if job_parameters is not None:
            pulumi.set(__self__, "job_parameters", job_parameters)
        if notebook_params is not None:
            pulumi.set(__self__, "notebook_params", notebook_params)
        if pipeline_params is not None:
            pulumi.set(__self__, "pipeline_params", pipeline_params)
        if python_named_params is not None:
            pulumi.set(__self__, "python_named_params", python_named_params)
        if python_params is not None:
            pulumi.set(__self__, "python_params", python_params)
        if spark_submit_params is not None:
            pulumi.set(__self__, "spark_submit_params", spark_submit_params)
        if sql_params is not None:
            pulumi.set(__self__, "sql_params", sql_params)

    @property
    @pulumi.getter(name="jobId")
    def job_id(self) -> int:
        """
        (String) ID of the job
        """
        return pulumi.get(self, "job_id")

    @property
    @pulumi.getter(name="dbtCommands")
    def dbt_commands(self) -> Optional[Sequence[str]]:
        return pulumi.get(self, "dbt_commands")

    @property
    @pulumi.getter(name="jarParams")
    def jar_params(self) -> Optional[Sequence[str]]:
        return pulumi.get(self, "jar_params")

    @property
    @pulumi.getter(name="jobParameters")
    def job_parameters(self) -> Optional[Mapping[str, str]]:
        """
        (Map) Job parameters for the task
        """
        return pulumi.get(self, "job_parameters")

    @property
    @pulumi.getter(name="notebookParams")
    def notebook_params(self) -> Optional[Mapping[str, str]]:
        return pulumi.get(self, "notebook_params")

    @property
    @pulumi.getter(name="pipelineParams")
    def pipeline_params(self) -> Optional['outputs.JobTaskRunJobTaskPipelineParams']:
        return pulumi.get(self, "pipeline_params")

    @property
    @pulumi.getter(name="pythonNamedParams")
    def python_named_params(self) -> Optional[Mapping[str, str]]:
        return pulumi.get(self, "python_named_params")

    @property
    @pulumi.getter(name="pythonParams")
    def python_params(self) -> Optional[Sequence[str]]:
        return pulumi.get(self, "python_params")

    @property
    @pulumi.getter(name="sparkSubmitParams")
    def spark_submit_params(self) -> Optional[Sequence[str]]:
        return pulumi.get(self, "spark_submit_params")

    @property
    @pulumi.getter(name="sqlParams")
    def sql_params(self) -> Optional[Mapping[str, str]]:
        return pulumi.get(self, "sql_params")


@pulumi.output_type
class JobTaskRunJobTaskPipelineParams(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "fullRefresh":
            suggest = "full_refresh"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in JobTaskRunJobTaskPipelineParams. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        JobTaskRunJobTaskPipelineParams.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        JobTaskRunJobTaskPipelineParams.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 full_refresh: Optional[bool] = None):
        """
        :param bool full_refresh: (Bool) Specifies if there should be full refresh of the pipeline.
               
               > **Note** The following configuration blocks are only supported inside a `task` block
        """
        if full_refresh is not None:
            pulumi.set(__self__, "full_refresh", full_refresh)

    @property
    @pulumi.getter(name="fullRefresh")
    def full_refresh(self) -> Optional[bool]:
        """
        (Bool) Specifies if there should be full refresh of the pipeline.

        > **Note** The following configuration blocks are only supported inside a `task` block
        """
        return pulumi.get(self, "full_refresh")


@pulumi.output_type
class JobTaskSparkJarTask(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "jarUri":
            suggest = "jar_uri"
        elif key == "mainClassName":
            suggest = "main_class_name"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in JobTaskSparkJarTask. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        JobTaskSparkJarTask.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        JobTaskSparkJarTask.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 jar_uri: Optional[str] = None,
                 main_class_name: Optional[str] = None,
                 parameters: Optional[Sequence[str]] = None):
        """
        :param str main_class_name: The full name of the class containing the main method to be executed. This class must be contained in a JAR provided as a library. The code should use `SparkContext.getOrCreate` to obtain a Spark context; otherwise, runs of the job will fail.
        :param Sequence[str] parameters: (List) Parameters passed to the main method.
        """
        if jar_uri is not None:
            pulumi.set(__self__, "jar_uri", jar_uri)
        if main_class_name is not None:
            pulumi.set(__self__, "main_class_name", main_class_name)
        if parameters is not None:
            pulumi.set(__self__, "parameters", parameters)

    @property
    @pulumi.getter(name="jarUri")
    def jar_uri(self) -> Optional[str]:
        return pulumi.get(self, "jar_uri")

    @property
    @pulumi.getter(name="mainClassName")
    def main_class_name(self) -> Optional[str]:
        """
        The full name of the class containing the main method to be executed. This class must be contained in a JAR provided as a library. The code should use `SparkContext.getOrCreate` to obtain a Spark context; otherwise, runs of the job will fail.
        """
        return pulumi.get(self, "main_class_name")

    @property
    @pulumi.getter
    def parameters(self) -> Optional[Sequence[str]]:
        """
        (List) Parameters passed to the main method.
        """
        return pulumi.get(self, "parameters")


@pulumi.output_type
class JobTaskSparkPythonTask(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "pythonFile":
            suggest = "python_file"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in JobTaskSparkPythonTask. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        JobTaskSparkPythonTask.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        JobTaskSparkPythonTask.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 python_file: str,
                 parameters: Optional[Sequence[str]] = None,
                 source: Optional[str] = None):
        """
        :param str python_file: The URI of the Python file to be executed. databricks_dbfs_file, cloud file URIs (e.g. `s3:/`, `abfss:/`, `gs:/`), workspace paths and remote repository are supported. For Python files stored in the Databricks workspace, the path must be absolute and begin with `/Repos`. For files stored in a remote repository, the path must be relative. This field is required.
        :param Sequence[str] parameters: (List) Command line parameters passed to the Python file.
        :param str source: Location type of the Python file, can only be `GIT`. When set to `GIT`, the Python file will be retrieved from a Git repository defined in `git_source`.
        """
        pulumi.set(__self__, "python_file", python_file)
        if parameters is not None:
            pulumi.set(__self__, "parameters", parameters)
        if source is not None:
            pulumi.set(__self__, "source", source)

    @property
    @pulumi.getter(name="pythonFile")
    def python_file(self) -> str:
        """
        The URI of the Python file to be executed. databricks_dbfs_file, cloud file URIs (e.g. `s3:/`, `abfss:/`, `gs:/`), workspace paths and remote repository are supported. For Python files stored in the Databricks workspace, the path must be absolute and begin with `/Repos`. For files stored in a remote repository, the path must be relative. This field is required.
        """
        return pulumi.get(self, "python_file")

    @property
    @pulumi.getter
    def parameters(self) -> Optional[Sequence[str]]:
        """
        (List) Command line parameters passed to the Python file.
        """
        return pulumi.get(self, "parameters")

    @property
    @pulumi.getter
    def source(self) -> Optional[str]:
        """
        Location type of the Python file, can only be `GIT`. When set to `GIT`, the Python file will be retrieved from a Git repository defined in `git_source`.
        """
        return pulumi.get(self, "source")


@pulumi.output_type
class JobTaskSparkSubmitTask(dict):
    def __init__(__self__, *,
                 parameters: Optional[Sequence[str]] = None):
        """
        :param Sequence[str] parameters: (List) Command-line parameters passed to spark submit.
        """
        if parameters is not None:
            pulumi.set(__self__, "parameters", parameters)

    @property
    @pulumi.getter
    def parameters(self) -> Optional[Sequence[str]]:
        """
        (List) Command-line parameters passed to spark submit.
        """
        return pulumi.get(self, "parameters")


@pulumi.output_type
class JobTaskSqlTask(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "warehouseId":
            suggest = "warehouse_id"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in JobTaskSqlTask. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        JobTaskSqlTask.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        JobTaskSqlTask.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 warehouse_id: str,
                 alert: Optional['outputs.JobTaskSqlTaskAlert'] = None,
                 dashboard: Optional['outputs.JobTaskSqlTaskDashboard'] = None,
                 file: Optional['outputs.JobTaskSqlTaskFile'] = None,
                 parameters: Optional[Mapping[str, str]] = None,
                 query: Optional['outputs.JobTaskSqlTaskQuery'] = None):
        """
        :param str warehouse_id: ID of the (the databricks_sql_endpoint) that will be used to execute the task.  Only Serverless & Pro warehouses are supported right now.
        :param 'JobTaskSqlTaskAlertArgs' alert: block consisting of following fields:
        :param 'JobTaskSqlTaskDashboardArgs' dashboard: block consisting of following fields:
        :param 'JobTaskSqlTaskFileArgs' file: block consisting of single string fields:
        :param Mapping[str, str] parameters: (Map) parameters to be used for each run of this task. The SQL alert task does not support custom parameters.
        :param 'JobTaskSqlTaskQueryArgs' query: block consisting of single string field: `query_id` - identifier of the Databricks SQL Query (databricks_sql_query).
        """
        pulumi.set(__self__, "warehouse_id", warehouse_id)
        if alert is not None:
            pulumi.set(__self__, "alert", alert)
        if dashboard is not None:
            pulumi.set(__self__, "dashboard", dashboard)
        if file is not None:
            pulumi.set(__self__, "file", file)
        if parameters is not None:
            pulumi.set(__self__, "parameters", parameters)
        if query is not None:
            pulumi.set(__self__, "query", query)

    @property
    @pulumi.getter(name="warehouseId")
    def warehouse_id(self) -> str:
        """
        ID of the (the databricks_sql_endpoint) that will be used to execute the task.  Only Serverless & Pro warehouses are supported right now.
        """
        return pulumi.get(self, "warehouse_id")

    @property
    @pulumi.getter
    def alert(self) -> Optional['outputs.JobTaskSqlTaskAlert']:
        """
        block consisting of following fields:
        """
        return pulumi.get(self, "alert")

    @property
    @pulumi.getter
    def dashboard(self) -> Optional['outputs.JobTaskSqlTaskDashboard']:
        """
        block consisting of following fields:
        """
        return pulumi.get(self, "dashboard")

    @property
    @pulumi.getter
    def file(self) -> Optional['outputs.JobTaskSqlTaskFile']:
        """
        block consisting of single string fields:
        """
        return pulumi.get(self, "file")

    @property
    @pulumi.getter
    def parameters(self) -> Optional[Mapping[str, str]]:
        """
        (Map) parameters to be used for each run of this task. The SQL alert task does not support custom parameters.
        """
        return pulumi.get(self, "parameters")

    @property
    @pulumi.getter
    def query(self) -> Optional['outputs.JobTaskSqlTaskQuery']:
        """
        block consisting of single string field: `query_id` - identifier of the Databricks SQL Query (databricks_sql_query).
        """
        return pulumi.get(self, "query")


@pulumi.output_type
class JobTaskSqlTaskAlert(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "alertId":
            suggest = "alert_id"
        elif key == "pauseSubscriptions":
            suggest = "pause_subscriptions"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in JobTaskSqlTaskAlert. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        JobTaskSqlTaskAlert.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        JobTaskSqlTaskAlert.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 alert_id: str,
                 subscriptions: Sequence['outputs.JobTaskSqlTaskAlertSubscription'],
                 pause_subscriptions: Optional[bool] = None):
        """
        :param str alert_id: (String) identifier of the Databricks SQL Alert.
        :param Sequence['JobTaskSqlTaskAlertSubscriptionArgs'] subscriptions: a list of subscription blocks consisting out of one of the required fields: `user_name` for user emails or `destination_id` - for Alert destination's identifier.
        :param bool pause_subscriptions: flag that specifies if subscriptions are paused or not.
        """
        pulumi.set(__self__, "alert_id", alert_id)
        pulumi.set(__self__, "subscriptions", subscriptions)
        if pause_subscriptions is not None:
            pulumi.set(__self__, "pause_subscriptions", pause_subscriptions)

    @property
    @pulumi.getter(name="alertId")
    def alert_id(self) -> str:
        """
        (String) identifier of the Databricks SQL Alert.
        """
        return pulumi.get(self, "alert_id")

    @property
    @pulumi.getter
    def subscriptions(self) -> Sequence['outputs.JobTaskSqlTaskAlertSubscription']:
        """
        a list of subscription blocks consisting out of one of the required fields: `user_name` for user emails or `destination_id` - for Alert destination's identifier.
        """
        return pulumi.get(self, "subscriptions")

    @property
    @pulumi.getter(name="pauseSubscriptions")
    def pause_subscriptions(self) -> Optional[bool]:
        """
        flag that specifies if subscriptions are paused or not.
        """
        return pulumi.get(self, "pause_subscriptions")


@pulumi.output_type
class JobTaskSqlTaskAlertSubscription(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "destinationId":
            suggest = "destination_id"
        elif key == "userName":
            suggest = "user_name"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in JobTaskSqlTaskAlertSubscription. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        JobTaskSqlTaskAlertSubscription.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        JobTaskSqlTaskAlertSubscription.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 destination_id: Optional[str] = None,
                 user_name: Optional[str] = None):
        """
        :param str user_name: The email of an active workspace user. Non-admin users can only set this field to their own email.
        """
        if destination_id is not None:
            pulumi.set(__self__, "destination_id", destination_id)
        if user_name is not None:
            pulumi.set(__self__, "user_name", user_name)

    @property
    @pulumi.getter(name="destinationId")
    def destination_id(self) -> Optional[str]:
        return pulumi.get(self, "destination_id")

    @property
    @pulumi.getter(name="userName")
    def user_name(self) -> Optional[str]:
        """
        The email of an active workspace user. Non-admin users can only set this field to their own email.
        """
        return pulumi.get(self, "user_name")


@pulumi.output_type
class JobTaskSqlTaskDashboard(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "dashboardId":
            suggest = "dashboard_id"
        elif key == "customSubject":
            suggest = "custom_subject"
        elif key == "pauseSubscriptions":
            suggest = "pause_subscriptions"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in JobTaskSqlTaskDashboard. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        JobTaskSqlTaskDashboard.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        JobTaskSqlTaskDashboard.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 dashboard_id: str,
                 custom_subject: Optional[str] = None,
                 pause_subscriptions: Optional[bool] = None,
                 subscriptions: Optional[Sequence['outputs.JobTaskSqlTaskDashboardSubscription']] = None):
        """
        :param str dashboard_id: (String) identifier of the Databricks SQL Dashboard databricks_sql_dashboard.
        :param str custom_subject: string specifying a custom subject of email sent.
        :param bool pause_subscriptions: flag that specifies if subscriptions are paused or not.
        :param Sequence['JobTaskSqlTaskDashboardSubscriptionArgs'] subscriptions: a list of subscription blocks consisting out of one of the required fields: `user_name` for user emails or `destination_id` - for Alert destination's identifier.
        """
        pulumi.set(__self__, "dashboard_id", dashboard_id)
        if custom_subject is not None:
            pulumi.set(__self__, "custom_subject", custom_subject)
        if pause_subscriptions is not None:
            pulumi.set(__self__, "pause_subscriptions", pause_subscriptions)
        if subscriptions is not None:
            pulumi.set(__self__, "subscriptions", subscriptions)

    @property
    @pulumi.getter(name="dashboardId")
    def dashboard_id(self) -> str:
        """
        (String) identifier of the Databricks SQL Dashboard databricks_sql_dashboard.
        """
        return pulumi.get(self, "dashboard_id")

    @property
    @pulumi.getter(name="customSubject")
    def custom_subject(self) -> Optional[str]:
        """
        string specifying a custom subject of email sent.
        """
        return pulumi.get(self, "custom_subject")

    @property
    @pulumi.getter(name="pauseSubscriptions")
    def pause_subscriptions(self) -> Optional[bool]:
        """
        flag that specifies if subscriptions are paused or not.
        """
        return pulumi.get(self, "pause_subscriptions")

    @property
    @pulumi.getter
    def subscriptions(self) -> Optional[Sequence['outputs.JobTaskSqlTaskDashboardSubscription']]:
        """
        a list of subscription blocks consisting out of one of the required fields: `user_name` for user emails or `destination_id` - for Alert destination's identifier.
        """
        return pulumi.get(self, "subscriptions")


@pulumi.output_type
class JobTaskSqlTaskDashboardSubscription(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "destinationId":
            suggest = "destination_id"
        elif key == "userName":
            suggest = "user_name"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in JobTaskSqlTaskDashboardSubscription. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        JobTaskSqlTaskDashboardSubscription.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        JobTaskSqlTaskDashboardSubscription.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 destination_id: Optional[str] = None,
                 user_name: Optional[str] = None):
        """
        :param str user_name: The email of an active workspace user. Non-admin users can only set this field to their own email.
        """
        if destination_id is not None:
            pulumi.set(__self__, "destination_id", destination_id)
        if user_name is not None:
            pulumi.set(__self__, "user_name", user_name)

    @property
    @pulumi.getter(name="destinationId")
    def destination_id(self) -> Optional[str]:
        return pulumi.get(self, "destination_id")

    @property
    @pulumi.getter(name="userName")
    def user_name(self) -> Optional[str]:
        """
        The email of an active workspace user. Non-admin users can only set this field to their own email.
        """
        return pulumi.get(self, "user_name")


@pulumi.output_type
class JobTaskSqlTaskFile(dict):
    def __init__(__self__, *,
                 path: str,
                 source: Optional[str] = None):
        """
        :param str path: If `source` is `GIT`: Relative path to the file in the repository specified in the `git_source` block with SQL commands to execute. If `source` is `WORKSPACE`: Absolute path to the file in the workspace with SQL commands to execute.
               
               Example
               
               ```python
               import pulumi
               import pulumi_databricks as databricks
               
               sql_aggregation_job = databricks.Job("sql_aggregation_job",
                   name="Example SQL Job",
                   tasks=[
                       {
                           "task_key": "run_agg_query",
                           "sql_task": {
                               "warehouse_id": sql_job_warehouse["id"],
                               "query": {
                                   "query_id": agg_query["id"],
                               },
                           },
                       },
                       {
                           "task_key": "run_dashboard",
                           "sql_task": {
                               "warehouse_id": sql_job_warehouse["id"],
                               "dashboard": {
                                   "dashboard_id": dash["id"],
                                   "subscriptions": [{
                                       "user_name": "user@domain.com",
                                   }],
                               },
                           },
                       },
                       {
                           "task_key": "run_alert",
                           "sql_task": {
                               "warehouse_id": sql_job_warehouse["id"],
                               "alert": {
                                   "alert_id": alert["id"],
                                   "subscriptions": [{
                                       "user_name": "user@domain.com",
                                   }],
                               },
                           },
                       },
                   ])
               ```
        :param str source: The source of the project. Possible values are `WORKSPACE` and `GIT`.
        """
        pulumi.set(__self__, "path", path)
        if source is not None:
            pulumi.set(__self__, "source", source)

    @property
    @pulumi.getter
    def path(self) -> str:
        """
        If `source` is `GIT`: Relative path to the file in the repository specified in the `git_source` block with SQL commands to execute. If `source` is `WORKSPACE`: Absolute path to the file in the workspace with SQL commands to execute.

        Example

        ```python
        import pulumi
        import pulumi_databricks as databricks

        sql_aggregation_job = databricks.Job("sql_aggregation_job",
            name="Example SQL Job",
            tasks=[
                {
                    "task_key": "run_agg_query",
                    "sql_task": {
                        "warehouse_id": sql_job_warehouse["id"],
                        "query": {
                            "query_id": agg_query["id"],
                        },
                    },
                },
                {
                    "task_key": "run_dashboard",
                    "sql_task": {
                        "warehouse_id": sql_job_warehouse["id"],
                        "dashboard": {
                            "dashboard_id": dash["id"],
                            "subscriptions": [{
                                "user_name": "user@domain.com",
                            }],
                        },
                    },
                },
                {
                    "task_key": "run_alert",
                    "sql_task": {
                        "warehouse_id": sql_job_warehouse["id"],
                        "alert": {
                            "alert_id": alert["id"],
                            "subscriptions": [{
                                "user_name": "user@domain.com",
                            }],
                        },
                    },
                },
            ])
        ```
        """
        return pulumi.get(self, "path")

    @property
    @pulumi.getter
    def source(self) -> Optional[str]:
        """
        The source of the project. Possible values are `WORKSPACE` and `GIT`.
        """
        return pulumi.get(self, "source")


@pulumi.output_type
class JobTaskSqlTaskQuery(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "queryId":
            suggest = "query_id"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in JobTaskSqlTaskQuery. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        JobTaskSqlTaskQuery.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        JobTaskSqlTaskQuery.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 query_id: str):
        pulumi.set(__self__, "query_id", query_id)

    @property
    @pulumi.getter(name="queryId")
    def query_id(self) -> str:
        return pulumi.get(self, "query_id")


@pulumi.output_type
class JobTaskWebhookNotifications(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "onDurationWarningThresholdExceededs":
            suggest = "on_duration_warning_threshold_exceededs"
        elif key == "onFailures":
            suggest = "on_failures"
        elif key == "onStarts":
            suggest = "on_starts"
        elif key == "onStreamingBacklogExceededs":
            suggest = "on_streaming_backlog_exceededs"
        elif key == "onSuccesses":
            suggest = "on_successes"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in JobTaskWebhookNotifications. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        JobTaskWebhookNotifications.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        JobTaskWebhookNotifications.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 on_duration_warning_threshold_exceededs: Optional[Sequence['outputs.JobTaskWebhookNotificationsOnDurationWarningThresholdExceeded']] = None,
                 on_failures: Optional[Sequence['outputs.JobTaskWebhookNotificationsOnFailure']] = None,
                 on_starts: Optional[Sequence['outputs.JobTaskWebhookNotificationsOnStart']] = None,
                 on_streaming_backlog_exceededs: Optional[Sequence['outputs.JobTaskWebhookNotificationsOnStreamingBacklogExceeded']] = None,
                 on_successes: Optional[Sequence['outputs.JobTaskWebhookNotificationsOnSuccess']] = None):
        """
        :param Sequence['JobTaskWebhookNotificationsOnDurationWarningThresholdExceededArgs'] on_duration_warning_threshold_exceededs: (List) list of notification IDs to call when the duration of a run exceeds the threshold specified by the `RUN_DURATION_SECONDS` metric in the `health` block.
               
               Note that the `id` is not to be confused with the name of the alert destination. The `id` can be retrieved through the API or the URL of Databricks UI `https://<workspace host>/sql/destinations/<notification id>?o=<workspace id>`
               
               Example
        :param Sequence['JobTaskWebhookNotificationsOnFailureArgs'] on_failures: (List) list of notification IDs to call when the run fails. A maximum of 3 destinations can be specified.
        :param Sequence['JobTaskWebhookNotificationsOnStartArgs'] on_starts: (List) list of notification IDs to call when the run starts. A maximum of 3 destinations can be specified.
        :param Sequence['JobTaskWebhookNotificationsOnSuccessArgs'] on_successes: (List) list of notification IDs to call when the run completes successfully. A maximum of 3 destinations can be specified.
        """
        if on_duration_warning_threshold_exceededs is not None:
            pulumi.set(__self__, "on_duration_warning_threshold_exceededs", on_duration_warning_threshold_exceededs)
        if on_failures is not None:
            pulumi.set(__self__, "on_failures", on_failures)
        if on_starts is not None:
            pulumi.set(__self__, "on_starts", on_starts)
        if on_streaming_backlog_exceededs is not None:
            pulumi.set(__self__, "on_streaming_backlog_exceededs", on_streaming_backlog_exceededs)
        if on_successes is not None:
            pulumi.set(__self__, "on_successes", on_successes)

    @property
    @pulumi.getter(name="onDurationWarningThresholdExceededs")
    def on_duration_warning_threshold_exceededs(self) -> Optional[Sequence['outputs.JobTaskWebhookNotificationsOnDurationWarningThresholdExceeded']]:
        """
        (List) list of notification IDs to call when the duration of a run exceeds the threshold specified by the `RUN_DURATION_SECONDS` metric in the `health` block.

        Note that the `id` is not to be confused with the name of the alert destination. The `id` can be retrieved through the API or the URL of Databricks UI `https://<workspace host>/sql/destinations/<notification id>?o=<workspace id>`

        Example
        """
        return pulumi.get(self, "on_duration_warning_threshold_exceededs")

    @property
    @pulumi.getter(name="onFailures")
    def on_failures(self) -> Optional[Sequence['outputs.JobTaskWebhookNotificationsOnFailure']]:
        """
        (List) list of notification IDs to call when the run fails. A maximum of 3 destinations can be specified.
        """
        return pulumi.get(self, "on_failures")

    @property
    @pulumi.getter(name="onStarts")
    def on_starts(self) -> Optional[Sequence['outputs.JobTaskWebhookNotificationsOnStart']]:
        """
        (List) list of notification IDs to call when the run starts. A maximum of 3 destinations can be specified.
        """
        return pulumi.get(self, "on_starts")

    @property
    @pulumi.getter(name="onStreamingBacklogExceededs")
    def on_streaming_backlog_exceededs(self) -> Optional[Sequence['outputs.JobTaskWebhookNotificationsOnStreamingBacklogExceeded']]:
        return pulumi.get(self, "on_streaming_backlog_exceededs")

    @property
    @pulumi.getter(name="onSuccesses")
    def on_successes(self) -> Optional[Sequence['outputs.JobTaskWebhookNotificationsOnSuccess']]:
        """
        (List) list of notification IDs to call when the run completes successfully. A maximum of 3 destinations can be specified.
        """
        return pulumi.get(self, "on_successes")


@pulumi.output_type
class JobTaskWebhookNotificationsOnDurationWarningThresholdExceeded(dict):
    def __init__(__self__, *,
                 id: str):
        """
        :param str id: ID of the job
        """
        pulumi.set(__self__, "id", id)

    @property
    @pulumi.getter
    def id(self) -> str:
        """
        ID of the job
        """
        return pulumi.get(self, "id")


@pulumi.output_type
class JobTaskWebhookNotificationsOnFailure(dict):
    def __init__(__self__, *,
                 id: str):
        """
        :param str id: ID of the job
        """
        pulumi.set(__self__, "id", id)

    @property
    @pulumi.getter
    def id(self) -> str:
        """
        ID of the job
        """
        return pulumi.get(self, "id")


@pulumi.output_type
class JobTaskWebhookNotificationsOnStart(dict):
    def __init__(__self__, *,
                 id: str):
        """
        :param str id: ID of the job
        """
        pulumi.set(__self__, "id", id)

    @property
    @pulumi.getter
    def id(self) -> str:
        """
        ID of the job
        """
        return pulumi.get(self, "id")


@pulumi.output_type
class JobTaskWebhookNotificationsOnStreamingBacklogExceeded(dict):
    def __init__(__self__, *,
                 id: str):
        """
        :param str id: ID of the job
        """
        pulumi.set(__self__, "id", id)

    @property
    @pulumi.getter
    def id(self) -> str:
        """
        ID of the job
        """
        return pulumi.get(self, "id")


@pulumi.output_type
class JobTaskWebhookNotificationsOnSuccess(dict):
    def __init__(__self__, *,
                 id: str):
        """
        :param str id: ID of the job
        """
        pulumi.set(__self__, "id", id)

    @property
    @pulumi.getter
    def id(self) -> str:
        """
        ID of the job
        """
        return pulumi.get(self, "id")


@pulumi.output_type
class JobTrigger(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "fileArrival":
            suggest = "file_arrival"
        elif key == "pauseStatus":
            suggest = "pause_status"
        elif key == "tableUpdate":
            suggest = "table_update"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in JobTrigger. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        JobTrigger.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        JobTrigger.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 file_arrival: Optional['outputs.JobTriggerFileArrival'] = None,
                 pause_status: Optional[str] = None,
                 periodic: Optional['outputs.JobTriggerPeriodic'] = None,
                 table: Optional['outputs.JobTriggerTable'] = None,
                 table_update: Optional['outputs.JobTriggerTableUpdate'] = None):
        """
        :param 'JobTriggerFileArrivalArgs' file_arrival: configuration block to define a trigger for [File Arrival events](https://learn.microsoft.com/en-us/azure/databricks/workflows/jobs/file-arrival-triggers) consisting of following attributes:
        :param str pause_status: Indicate whether this trigger is paused or not. Either `PAUSED` or `UNPAUSED`. When the `pause_status` field is omitted in the block, the server will default to using `UNPAUSED` as a value for `pause_status`.
        :param 'JobTriggerPeriodicArgs' periodic: configuration block to define a trigger for Periodic Triggers consisting of the following attributes:
        """
        if file_arrival is not None:
            pulumi.set(__self__, "file_arrival", file_arrival)
        if pause_status is not None:
            pulumi.set(__self__, "pause_status", pause_status)
        if periodic is not None:
            pulumi.set(__self__, "periodic", periodic)
        if table is not None:
            pulumi.set(__self__, "table", table)
        if table_update is not None:
            pulumi.set(__self__, "table_update", table_update)

    @property
    @pulumi.getter(name="fileArrival")
    def file_arrival(self) -> Optional['outputs.JobTriggerFileArrival']:
        """
        configuration block to define a trigger for [File Arrival events](https://learn.microsoft.com/en-us/azure/databricks/workflows/jobs/file-arrival-triggers) consisting of following attributes:
        """
        return pulumi.get(self, "file_arrival")

    @property
    @pulumi.getter(name="pauseStatus")
    def pause_status(self) -> Optional[str]:
        """
        Indicate whether this trigger is paused or not. Either `PAUSED` or `UNPAUSED`. When the `pause_status` field is omitted in the block, the server will default to using `UNPAUSED` as a value for `pause_status`.
        """
        return pulumi.get(self, "pause_status")

    @property
    @pulumi.getter
    def periodic(self) -> Optional['outputs.JobTriggerPeriodic']:
        """
        configuration block to define a trigger for Periodic Triggers consisting of the following attributes:
        """
        return pulumi.get(self, "periodic")

    @property
    @pulumi.getter
    def table(self) -> Optional['outputs.JobTriggerTable']:
        return pulumi.get(self, "table")

    @property
    @pulumi.getter(name="tableUpdate")
    def table_update(self) -> Optional['outputs.JobTriggerTableUpdate']:
        return pulumi.get(self, "table_update")


@pulumi.output_type
class JobTriggerFileArrival(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "minTimeBetweenTriggersSeconds":
            suggest = "min_time_between_triggers_seconds"
        elif key == "waitAfterLastChangeSeconds":
            suggest = "wait_after_last_change_seconds"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in JobTriggerFileArrival. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        JobTriggerFileArrival.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        JobTriggerFileArrival.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 url: str,
                 min_time_between_triggers_seconds: Optional[int] = None,
                 wait_after_last_change_seconds: Optional[int] = None):
        """
        :param str url: URL to be monitored for file arrivals. The path must point to the root or a subpath of the external location. Please note that the URL must have a trailing slash character (`/`).
        :param int min_time_between_triggers_seconds: If set, the trigger starts a run only after the specified amount of time passed since the last time the trigger fired. The minimum allowed value is 60 seconds.
        :param int wait_after_last_change_seconds: If set, the trigger starts a run only after no file activity has occurred for the specified amount of time. This makes it possible to wait for a batch of incoming files to arrive before triggering a run. The minimum allowed value is 60 seconds.
        """
        pulumi.set(__self__, "url", url)
        if min_time_between_triggers_seconds is not None:
            pulumi.set(__self__, "min_time_between_triggers_seconds", min_time_between_triggers_seconds)
        if wait_after_last_change_seconds is not None:
            pulumi.set(__self__, "wait_after_last_change_seconds", wait_after_last_change_seconds)

    @property
    @pulumi.getter
    def url(self) -> str:
        """
        URL to be monitored for file arrivals. The path must point to the root or a subpath of the external location. Please note that the URL must have a trailing slash character (`/`).
        """
        return pulumi.get(self, "url")

    @property
    @pulumi.getter(name="minTimeBetweenTriggersSeconds")
    def min_time_between_triggers_seconds(self) -> Optional[int]:
        """
        If set, the trigger starts a run only after the specified amount of time passed since the last time the trigger fired. The minimum allowed value is 60 seconds.
        """
        return pulumi.get(self, "min_time_between_triggers_seconds")

    @property
    @pulumi.getter(name="waitAfterLastChangeSeconds")
    def wait_after_last_change_seconds(self) -> Optional[int]:
        """
        If set, the trigger starts a run only after no file activity has occurred for the specified amount of time. This makes it possible to wait for a batch of incoming files to arrive before triggering a run. The minimum allowed value is 60 seconds.
        """
        return pulumi.get(self, "wait_after_last_change_seconds")


@pulumi.output_type
class JobTriggerPeriodic(dict):
    def __init__(__self__, *,
                 interval: int,
                 unit: str):
        """
        :param int interval: Specifies the interval at which the job should run. This value is required.
        :param str unit: Options are {"DAYS", "HOURS", "WEEKS"}.
        """
        pulumi.set(__self__, "interval", interval)
        pulumi.set(__self__, "unit", unit)

    @property
    @pulumi.getter
    def interval(self) -> int:
        """
        Specifies the interval at which the job should run. This value is required.
        """
        return pulumi.get(self, "interval")

    @property
    @pulumi.getter
    def unit(self) -> str:
        """
        Options are {"DAYS", "HOURS", "WEEKS"}.
        """
        return pulumi.get(self, "unit")


@pulumi.output_type
class JobTriggerTable(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "minTimeBetweenTriggersSeconds":
            suggest = "min_time_between_triggers_seconds"
        elif key == "tableNames":
            suggest = "table_names"
        elif key == "waitAfterLastChangeSeconds":
            suggest = "wait_after_last_change_seconds"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in JobTriggerTable. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        JobTriggerTable.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        JobTriggerTable.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 condition: Optional[str] = None,
                 min_time_between_triggers_seconds: Optional[int] = None,
                 table_names: Optional[Sequence[str]] = None,
                 wait_after_last_change_seconds: Optional[int] = None):
        """
        :param int min_time_between_triggers_seconds: If set, the trigger starts a run only after the specified amount of time passed since the last time the trigger fired. The minimum allowed value is 60 seconds.
        :param int wait_after_last_change_seconds: If set, the trigger starts a run only after no file activity has occurred for the specified amount of time. This makes it possible to wait for a batch of incoming files to arrive before triggering a run. The minimum allowed value is 60 seconds.
        """
        if condition is not None:
            pulumi.set(__self__, "condition", condition)
        if min_time_between_triggers_seconds is not None:
            pulumi.set(__self__, "min_time_between_triggers_seconds", min_time_between_triggers_seconds)
        if table_names is not None:
            pulumi.set(__self__, "table_names", table_names)
        if wait_after_last_change_seconds is not None:
            pulumi.set(__self__, "wait_after_last_change_seconds", wait_after_last_change_seconds)

    @property
    @pulumi.getter
    def condition(self) -> Optional[str]:
        return pulumi.get(self, "condition")

    @property
    @pulumi.getter(name="minTimeBetweenTriggersSeconds")
    def min_time_between_triggers_seconds(self) -> Optional[int]:
        """
        If set, the trigger starts a run only after the specified amount of time passed since the last time the trigger fired. The minimum allowed value is 60 seconds.
        """
        return pulumi.get(self, "min_time_between_triggers_seconds")

    @property
    @pulumi.getter(name="tableNames")
    def table_names(self) -> Optional[Sequence[str]]:
        return pulumi.get(self, "table_names")

    @property
    @pulumi.getter(name="waitAfterLastChangeSeconds")
    def wait_after_last_change_seconds(self) -> Optional[int]:
        """
        If set, the trigger starts a run only after no file activity has occurred for the specified amount of time. This makes it possible to wait for a batch of incoming files to arrive before triggering a run. The minimum allowed value is 60 seconds.
        """
        return pulumi.get(self, "wait_after_last_change_seconds")


@pulumi.output_type
class JobTriggerTableUpdate(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "tableNames":
            suggest = "table_names"
        elif key == "minTimeBetweenTriggersSeconds":
            suggest = "min_time_between_triggers_seconds"
        elif key == "waitAfterLastChangeSeconds":
            suggest = "wait_after_last_change_seconds"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in JobTriggerTableUpdate. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        JobTriggerTableUpdate.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        JobTriggerTableUpdate.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 table_names: Sequence[str],
                 condition: Optional[str] = None,
                 min_time_between_triggers_seconds: Optional[int] = None,
                 wait_after_last_change_seconds: Optional[int] = None):
        """
        :param int min_time_between_triggers_seconds: If set, the trigger starts a run only after the specified amount of time passed since the last time the trigger fired. The minimum allowed value is 60 seconds.
        :param int wait_after_last_change_seconds: If set, the trigger starts a run only after no file activity has occurred for the specified amount of time. This makes it possible to wait for a batch of incoming files to arrive before triggering a run. The minimum allowed value is 60 seconds.
        """
        pulumi.set(__self__, "table_names", table_names)
        if condition is not None:
            pulumi.set(__self__, "condition", condition)
        if min_time_between_triggers_seconds is not None:
            pulumi.set(__self__, "min_time_between_triggers_seconds", min_time_between_triggers_seconds)
        if wait_after_last_change_seconds is not None:
            pulumi.set(__self__, "wait_after_last_change_seconds", wait_after_last_change_seconds)

    @property
    @pulumi.getter(name="tableNames")
    def table_names(self) -> Sequence[str]:
        return pulumi.get(self, "table_names")

    @property
    @pulumi.getter
    def condition(self) -> Optional[str]:
        return pulumi.get(self, "condition")

    @property
    @pulumi.getter(name="minTimeBetweenTriggersSeconds")
    def min_time_between_triggers_seconds(self) -> Optional[int]:
        """
        If set, the trigger starts a run only after the specified amount of time passed since the last time the trigger fired. The minimum allowed value is 60 seconds.
        """
        return pulumi.get(self, "min_time_between_triggers_seconds")

    @property
    @pulumi.getter(name="waitAfterLastChangeSeconds")
    def wait_after_last_change_seconds(self) -> Optional[int]:
        """
        If set, the trigger starts a run only after no file activity has occurred for the specified amount of time. This makes it possible to wait for a batch of incoming files to arrive before triggering a run. The minimum allowed value is 60 seconds.
        """
        return pulumi.get(self, "wait_after_last_change_seconds")


@pulumi.output_type
class JobWebhookNotifications(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "onDurationWarningThresholdExceededs":
            suggest = "on_duration_warning_threshold_exceededs"
        elif key == "onFailures":
            suggest = "on_failures"
        elif key == "onStarts":
            suggest = "on_starts"
        elif key == "onStreamingBacklogExceededs":
            suggest = "on_streaming_backlog_exceededs"
        elif key == "onSuccesses":
            suggest = "on_successes"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in JobWebhookNotifications. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        JobWebhookNotifications.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        JobWebhookNotifications.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 on_duration_warning_threshold_exceededs: Optional[Sequence['outputs.JobWebhookNotificationsOnDurationWarningThresholdExceeded']] = None,
                 on_failures: Optional[Sequence['outputs.JobWebhookNotificationsOnFailure']] = None,
                 on_starts: Optional[Sequence['outputs.JobWebhookNotificationsOnStart']] = None,
                 on_streaming_backlog_exceededs: Optional[Sequence['outputs.JobWebhookNotificationsOnStreamingBacklogExceeded']] = None,
                 on_successes: Optional[Sequence['outputs.JobWebhookNotificationsOnSuccess']] = None):
        """
        :param Sequence['JobWebhookNotificationsOnDurationWarningThresholdExceededArgs'] on_duration_warning_threshold_exceededs: (List) list of notification IDs to call when the duration of a run exceeds the threshold specified by the `RUN_DURATION_SECONDS` metric in the `health` block.
               
               Note that the `id` is not to be confused with the name of the alert destination. The `id` can be retrieved through the API or the URL of Databricks UI `https://<workspace host>/sql/destinations/<notification id>?o=<workspace id>`
               
               Example
        :param Sequence['JobWebhookNotificationsOnFailureArgs'] on_failures: (List) list of notification IDs to call when the run fails. A maximum of 3 destinations can be specified.
        :param Sequence['JobWebhookNotificationsOnStartArgs'] on_starts: (List) list of notification IDs to call when the run starts. A maximum of 3 destinations can be specified.
        :param Sequence['JobWebhookNotificationsOnSuccessArgs'] on_successes: (List) list of notification IDs to call when the run completes successfully. A maximum of 3 destinations can be specified.
        """
        if on_duration_warning_threshold_exceededs is not None:
            pulumi.set(__self__, "on_duration_warning_threshold_exceededs", on_duration_warning_threshold_exceededs)
        if on_failures is not None:
            pulumi.set(__self__, "on_failures", on_failures)
        if on_starts is not None:
            pulumi.set(__self__, "on_starts", on_starts)
        if on_streaming_backlog_exceededs is not None:
            pulumi.set(__self__, "on_streaming_backlog_exceededs", on_streaming_backlog_exceededs)
        if on_successes is not None:
            pulumi.set(__self__, "on_successes", on_successes)

    @property
    @pulumi.getter(name="onDurationWarningThresholdExceededs")
    def on_duration_warning_threshold_exceededs(self) -> Optional[Sequence['outputs.JobWebhookNotificationsOnDurationWarningThresholdExceeded']]:
        """
        (List) list of notification IDs to call when the duration of a run exceeds the threshold specified by the `RUN_DURATION_SECONDS` metric in the `health` block.

        Note that the `id` is not to be confused with the name of the alert destination. The `id` can be retrieved through the API or the URL of Databricks UI `https://<workspace host>/sql/destinations/<notification id>?o=<workspace id>`

        Example
        """
        return pulumi.get(self, "on_duration_warning_threshold_exceededs")

    @property
    @pulumi.getter(name="onFailures")
    def on_failures(self) -> Optional[Sequence['outputs.JobWebhookNotificationsOnFailure']]:
        """
        (List) list of notification IDs to call when the run fails. A maximum of 3 destinations can be specified.
        """
        return pulumi.get(self, "on_failures")

    @property
    @pulumi.getter(name="onStarts")
    def on_starts(self) -> Optional[Sequence['outputs.JobWebhookNotificationsOnStart']]:
        """
        (List) list of notification IDs to call when the run starts. A maximum of 3 destinations can be specified.
        """
        return pulumi.get(self, "on_starts")

    @property
    @pulumi.getter(name="onStreamingBacklogExceededs")
    def on_streaming_backlog_exceededs(self) -> Optional[Sequence['outputs.JobWebhookNotificationsOnStreamingBacklogExceeded']]:
        return pulumi.get(self, "on_streaming_backlog_exceededs")

    @property
    @pulumi.getter(name="onSuccesses")
    def on_successes(self) -> Optional[Sequence['outputs.JobWebhookNotificationsOnSuccess']]:
        """
        (List) list of notification IDs to call when the run completes successfully. A maximum of 3 destinations can be specified.
        """
        return pulumi.get(self, "on_successes")


@pulumi.output_type
class JobWebhookNotificationsOnDurationWarningThresholdExceeded(dict):
    def __init__(__self__, *,
                 id: str):
        """
        :param str id: ID of the job
        """
        pulumi.set(__self__, "id", id)

    @property
    @pulumi.getter
    def id(self) -> str:
        """
        ID of the job
        """
        return pulumi.get(self, "id")


@pulumi.output_type
class JobWebhookNotificationsOnFailure(dict):
    def __init__(__self__, *,
                 id: str):
        """
        :param str id: ID of the job
        """
        pulumi.set(__self__, "id", id)

    @property
    @pulumi.getter
    def id(self) -> str:
        """
        ID of the job
        """
        return pulumi.get(self, "id")


@pulumi.output_type
class JobWebhookNotificationsOnStart(dict):
    def __init__(__self__, *,
                 id: str):
        """
        :param str id: ID of the job
        """
        pulumi.set(__self__, "id", id)

    @property
    @pulumi.getter
    def id(self) -> str:
        """
        ID of the job
        """
        return pulumi.get(self, "id")


@pulumi.output_type
class JobWebhookNotificationsOnStreamingBacklogExceeded(dict):
    def __init__(__self__, *,
                 id: str):
        """
        :param str id: ID of the job
        """
        pulumi.set(__self__, "id", id)

    @property
    @pulumi.getter
    def id(self) -> str:
        """
        ID of the job
        """
        return pulumi.get(self, "id")


@pulumi.output_type
class JobWebhookNotificationsOnSuccess(dict):
    def __init__(__self__, *,
                 id: str):
        """
        :param str id: ID of the job
        """
        pulumi.set(__self__, "id", id)

    @property
    @pulumi.getter
    def id(self) -> str:
        """
        ID of the job
        """
        return pulumi.get(self, "id")


@pulumi.output_type
class LakehouseMonitorCustomMetric(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "inputColumns":
            suggest = "input_columns"
        elif key == "outputDataType":
            suggest = "output_data_type"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in LakehouseMonitorCustomMetric. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        LakehouseMonitorCustomMetric.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        LakehouseMonitorCustomMetric.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 definition: str,
                 input_columns: Sequence[str],
                 name: str,
                 output_data_type: str,
                 type: str):
        """
        :param str definition: [create metric definition](https://docs.databricks.com/en/lakehouse-monitoring/custom-metrics.html#create-definition)
        :param Sequence[str] input_columns: Columns on the monitored table to apply the custom metrics to.
        :param str name: Name of the custom metric.
        :param str output_data_type: The output type of the custom metric.
        :param str type: The type of the custom metric.
        """
        pulumi.set(__self__, "definition", definition)
        pulumi.set(__self__, "input_columns", input_columns)
        pulumi.set(__self__, "name", name)
        pulumi.set(__self__, "output_data_type", output_data_type)
        pulumi.set(__self__, "type", type)

    @property
    @pulumi.getter
    def definition(self) -> str:
        """
        [create metric definition](https://docs.databricks.com/en/lakehouse-monitoring/custom-metrics.html#create-definition)
        """
        return pulumi.get(self, "definition")

    @property
    @pulumi.getter(name="inputColumns")
    def input_columns(self) -> Sequence[str]:
        """
        Columns on the monitored table to apply the custom metrics to.
        """
        return pulumi.get(self, "input_columns")

    @property
    @pulumi.getter
    def name(self) -> str:
        """
        Name of the custom metric.
        """
        return pulumi.get(self, "name")

    @property
    @pulumi.getter(name="outputDataType")
    def output_data_type(self) -> str:
        """
        The output type of the custom metric.
        """
        return pulumi.get(self, "output_data_type")

    @property
    @pulumi.getter
    def type(self) -> str:
        """
        The type of the custom metric.
        """
        return pulumi.get(self, "type")


@pulumi.output_type
class LakehouseMonitorDataClassificationConfig(dict):
    def __init__(__self__, *,
                 enabled: Optional[bool] = None):
        if enabled is not None:
            pulumi.set(__self__, "enabled", enabled)

    @property
    @pulumi.getter
    def enabled(self) -> Optional[bool]:
        return pulumi.get(self, "enabled")


@pulumi.output_type
class LakehouseMonitorInferenceLog(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "modelIdCol":
            suggest = "model_id_col"
        elif key == "predictionCol":
            suggest = "prediction_col"
        elif key == "problemType":
            suggest = "problem_type"
        elif key == "timestampCol":
            suggest = "timestamp_col"
        elif key == "labelCol":
            suggest = "label_col"
        elif key == "predictionProbaCol":
            suggest = "prediction_proba_col"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in LakehouseMonitorInferenceLog. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        LakehouseMonitorInferenceLog.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        LakehouseMonitorInferenceLog.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 granularities: Sequence[str],
                 model_id_col: str,
                 prediction_col: str,
                 problem_type: str,
                 timestamp_col: str,
                 label_col: Optional[str] = None,
                 prediction_proba_col: Optional[str] = None):
        """
        :param Sequence[str] granularities: List of granularities to use when aggregating data into time windows based on their timestamp.
        :param str model_id_col: Column of the model id or version
        :param str prediction_col: Column of the model prediction
        :param str problem_type: Problem type the model aims to solve. Either `PROBLEM_TYPE_CLASSIFICATION` or `PROBLEM_TYPE_REGRESSION`
        :param str timestamp_col: Column of the timestamp of predictions
        :param str label_col: Column of the model label
        :param str prediction_proba_col: Column of the model prediction probabilities
        """
        pulumi.set(__self__, "granularities", granularities)
        pulumi.set(__self__, "model_id_col", model_id_col)
        pulumi.set(__self__, "prediction_col", prediction_col)
        pulumi.set(__self__, "problem_type", problem_type)
        pulumi.set(__self__, "timestamp_col", timestamp_col)
        if label_col is not None:
            pulumi.set(__self__, "label_col", label_col)
        if prediction_proba_col is not None:
            pulumi.set(__self__, "prediction_proba_col", prediction_proba_col)

    @property
    @pulumi.getter
    def granularities(self) -> Sequence[str]:
        """
        List of granularities to use when aggregating data into time windows based on their timestamp.
        """
        return pulumi.get(self, "granularities")

    @property
    @pulumi.getter(name="modelIdCol")
    def model_id_col(self) -> str:
        """
        Column of the model id or version
        """
        return pulumi.get(self, "model_id_col")

    @property
    @pulumi.getter(name="predictionCol")
    def prediction_col(self) -> str:
        """
        Column of the model prediction
        """
        return pulumi.get(self, "prediction_col")

    @property
    @pulumi.getter(name="problemType")
    def problem_type(self) -> str:
        """
        Problem type the model aims to solve. Either `PROBLEM_TYPE_CLASSIFICATION` or `PROBLEM_TYPE_REGRESSION`
        """
        return pulumi.get(self, "problem_type")

    @property
    @pulumi.getter(name="timestampCol")
    def timestamp_col(self) -> str:
        """
        Column of the timestamp of predictions
        """
        return pulumi.get(self, "timestamp_col")

    @property
    @pulumi.getter(name="labelCol")
    def label_col(self) -> Optional[str]:
        """
        Column of the model label
        """
        return pulumi.get(self, "label_col")

    @property
    @pulumi.getter(name="predictionProbaCol")
    def prediction_proba_col(self) -> Optional[str]:
        """
        Column of the model prediction probabilities
        """
        return pulumi.get(self, "prediction_proba_col")


@pulumi.output_type
class LakehouseMonitorNotifications(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "onFailure":
            suggest = "on_failure"
        elif key == "onNewClassificationTagDetected":
            suggest = "on_new_classification_tag_detected"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in LakehouseMonitorNotifications. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        LakehouseMonitorNotifications.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        LakehouseMonitorNotifications.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 on_failure: Optional['outputs.LakehouseMonitorNotificationsOnFailure'] = None,
                 on_new_classification_tag_detected: Optional['outputs.LakehouseMonitorNotificationsOnNewClassificationTagDetected'] = None):
        """
        :param 'LakehouseMonitorNotificationsOnFailureArgs' on_failure: who to send notifications to on monitor failure.
        :param 'LakehouseMonitorNotificationsOnNewClassificationTagDetectedArgs' on_new_classification_tag_detected: Who to send notifications to when new data classification tags are detected.
        """
        if on_failure is not None:
            pulumi.set(__self__, "on_failure", on_failure)
        if on_new_classification_tag_detected is not None:
            pulumi.set(__self__, "on_new_classification_tag_detected", on_new_classification_tag_detected)

    @property
    @pulumi.getter(name="onFailure")
    def on_failure(self) -> Optional['outputs.LakehouseMonitorNotificationsOnFailure']:
        """
        who to send notifications to on monitor failure.
        """
        return pulumi.get(self, "on_failure")

    @property
    @pulumi.getter(name="onNewClassificationTagDetected")
    def on_new_classification_tag_detected(self) -> Optional['outputs.LakehouseMonitorNotificationsOnNewClassificationTagDetected']:
        """
        Who to send notifications to when new data classification tags are detected.
        """
        return pulumi.get(self, "on_new_classification_tag_detected")


@pulumi.output_type
class LakehouseMonitorNotificationsOnFailure(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "emailAddresses":
            suggest = "email_addresses"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in LakehouseMonitorNotificationsOnFailure. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        LakehouseMonitorNotificationsOnFailure.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        LakehouseMonitorNotificationsOnFailure.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 email_addresses: Optional[Sequence[str]] = None):
        if email_addresses is not None:
            pulumi.set(__self__, "email_addresses", email_addresses)

    @property
    @pulumi.getter(name="emailAddresses")
    def email_addresses(self) -> Optional[Sequence[str]]:
        return pulumi.get(self, "email_addresses")


@pulumi.output_type
class LakehouseMonitorNotificationsOnNewClassificationTagDetected(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "emailAddresses":
            suggest = "email_addresses"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in LakehouseMonitorNotificationsOnNewClassificationTagDetected. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        LakehouseMonitorNotificationsOnNewClassificationTagDetected.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        LakehouseMonitorNotificationsOnNewClassificationTagDetected.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 email_addresses: Optional[Sequence[str]] = None):
        if email_addresses is not None:
            pulumi.set(__self__, "email_addresses", email_addresses)

    @property
    @pulumi.getter(name="emailAddresses")
    def email_addresses(self) -> Optional[Sequence[str]]:
        return pulumi.get(self, "email_addresses")


@pulumi.output_type
class LakehouseMonitorSchedule(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "quartzCronExpression":
            suggest = "quartz_cron_expression"
        elif key == "timezoneId":
            suggest = "timezone_id"
        elif key == "pauseStatus":
            suggest = "pause_status"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in LakehouseMonitorSchedule. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        LakehouseMonitorSchedule.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        LakehouseMonitorSchedule.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 quartz_cron_expression: str,
                 timezone_id: str,
                 pause_status: Optional[str] = None):
        """
        :param str quartz_cron_expression: string expression that determines when to run the monitor. See [Quartz documentation](https://www.quartz-scheduler.org/documentation/quartz-2.3.0/tutorials/crontrigger.html) for examples.
        :param str timezone_id: string with timezone id (e.g., `PST`) in which to evaluate the Quartz expression.
        :param str pause_status: optional string field that indicates whether a schedule is paused (`PAUSED`) or not (`UNPAUSED`).
        """
        pulumi.set(__self__, "quartz_cron_expression", quartz_cron_expression)
        pulumi.set(__self__, "timezone_id", timezone_id)
        if pause_status is not None:
            pulumi.set(__self__, "pause_status", pause_status)

    @property
    @pulumi.getter(name="quartzCronExpression")
    def quartz_cron_expression(self) -> str:
        """
        string expression that determines when to run the monitor. See [Quartz documentation](https://www.quartz-scheduler.org/documentation/quartz-2.3.0/tutorials/crontrigger.html) for examples.
        """
        return pulumi.get(self, "quartz_cron_expression")

    @property
    @pulumi.getter(name="timezoneId")
    def timezone_id(self) -> str:
        """
        string with timezone id (e.g., `PST`) in which to evaluate the Quartz expression.
        """
        return pulumi.get(self, "timezone_id")

    @property
    @pulumi.getter(name="pauseStatus")
    def pause_status(self) -> Optional[str]:
        """
        optional string field that indicates whether a schedule is paused (`PAUSED`) or not (`UNPAUSED`).
        """
        return pulumi.get(self, "pause_status")


@pulumi.output_type
class LakehouseMonitorSnapshot(dict):
    def __init__(__self__):
        pass


@pulumi.output_type
class LakehouseMonitorTimeSeries(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "timestampCol":
            suggest = "timestamp_col"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in LakehouseMonitorTimeSeries. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        LakehouseMonitorTimeSeries.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        LakehouseMonitorTimeSeries.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 granularities: Sequence[str],
                 timestamp_col: str):
        """
        :param Sequence[str] granularities: List of granularities to use when aggregating data into time windows based on their timestamp.
        :param str timestamp_col: Column of the timestamp of predictions
        """
        pulumi.set(__self__, "granularities", granularities)
        pulumi.set(__self__, "timestamp_col", timestamp_col)

    @property
    @pulumi.getter
    def granularities(self) -> Sequence[str]:
        """
        List of granularities to use when aggregating data into time windows based on their timestamp.
        """
        return pulumi.get(self, "granularities")

    @property
    @pulumi.getter(name="timestampCol")
    def timestamp_col(self) -> str:
        """
        Column of the timestamp of predictions
        """
        return pulumi.get(self, "timestamp_col")


@pulumi.output_type
class LibraryCran(dict):
    def __init__(__self__, *,
                 package: str,
                 repo: Optional[str] = None):
        pulumi.set(__self__, "package", package)
        if repo is not None:
            pulumi.set(__self__, "repo", repo)

    @property
    @pulumi.getter
    def package(self) -> str:
        return pulumi.get(self, "package")

    @property
    @pulumi.getter
    def repo(self) -> Optional[str]:
        return pulumi.get(self, "repo")


@pulumi.output_type
class LibraryMaven(dict):
    def __init__(__self__, *,
                 coordinates: str,
                 exclusions: Optional[Sequence[str]] = None,
                 repo: Optional[str] = None):
        pulumi.set(__self__, "coordinates", coordinates)
        if exclusions is not None:
            pulumi.set(__self__, "exclusions", exclusions)
        if repo is not None:
            pulumi.set(__self__, "repo", repo)

    @property
    @pulumi.getter
    def coordinates(self) -> str:
        return pulumi.get(self, "coordinates")

    @property
    @pulumi.getter
    def exclusions(self) -> Optional[Sequence[str]]:
        return pulumi.get(self, "exclusions")

    @property
    @pulumi.getter
    def repo(self) -> Optional[str]:
        return pulumi.get(self, "repo")


@pulumi.output_type
class LibraryPypi(dict):
    def __init__(__self__, *,
                 package: str,
                 repo: Optional[str] = None):
        pulumi.set(__self__, "package", package)
        if repo is not None:
            pulumi.set(__self__, "repo", repo)

    @property
    @pulumi.getter
    def package(self) -> str:
        return pulumi.get(self, "package")

    @property
    @pulumi.getter
    def repo(self) -> Optional[str]:
        return pulumi.get(self, "repo")


@pulumi.output_type
class MetastoreDataAccessAwsIamRole(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "roleArn":
            suggest = "role_arn"
        elif key == "externalId":
            suggest = "external_id"
        elif key == "unityCatalogIamArn":
            suggest = "unity_catalog_iam_arn"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in MetastoreDataAccessAwsIamRole. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        MetastoreDataAccessAwsIamRole.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        MetastoreDataAccessAwsIamRole.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 role_arn: str,
                 external_id: Optional[str] = None,
                 unity_catalog_iam_arn: Optional[str] = None):
        pulumi.set(__self__, "role_arn", role_arn)
        if external_id is not None:
            pulumi.set(__self__, "external_id", external_id)
        if unity_catalog_iam_arn is not None:
            pulumi.set(__self__, "unity_catalog_iam_arn", unity_catalog_iam_arn)

    @property
    @pulumi.getter(name="roleArn")
    def role_arn(self) -> str:
        return pulumi.get(self, "role_arn")

    @property
    @pulumi.getter(name="externalId")
    def external_id(self) -> Optional[str]:
        return pulumi.get(self, "external_id")

    @property
    @pulumi.getter(name="unityCatalogIamArn")
    def unity_catalog_iam_arn(self) -> Optional[str]:
        return pulumi.get(self, "unity_catalog_iam_arn")


@pulumi.output_type
class MetastoreDataAccessAzureManagedIdentity(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "accessConnectorId":
            suggest = "access_connector_id"
        elif key == "credentialId":
            suggest = "credential_id"
        elif key == "managedIdentityId":
            suggest = "managed_identity_id"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in MetastoreDataAccessAzureManagedIdentity. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        MetastoreDataAccessAzureManagedIdentity.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        MetastoreDataAccessAzureManagedIdentity.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 access_connector_id: str,
                 credential_id: Optional[str] = None,
                 managed_identity_id: Optional[str] = None):
        pulumi.set(__self__, "access_connector_id", access_connector_id)
        if credential_id is not None:
            pulumi.set(__self__, "credential_id", credential_id)
        if managed_identity_id is not None:
            pulumi.set(__self__, "managed_identity_id", managed_identity_id)

    @property
    @pulumi.getter(name="accessConnectorId")
    def access_connector_id(self) -> str:
        return pulumi.get(self, "access_connector_id")

    @property
    @pulumi.getter(name="credentialId")
    def credential_id(self) -> Optional[str]:
        return pulumi.get(self, "credential_id")

    @property
    @pulumi.getter(name="managedIdentityId")
    def managed_identity_id(self) -> Optional[str]:
        return pulumi.get(self, "managed_identity_id")


@pulumi.output_type
class MetastoreDataAccessAzureServicePrincipal(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "applicationId":
            suggest = "application_id"
        elif key == "clientSecret":
            suggest = "client_secret"
        elif key == "directoryId":
            suggest = "directory_id"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in MetastoreDataAccessAzureServicePrincipal. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        MetastoreDataAccessAzureServicePrincipal.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        MetastoreDataAccessAzureServicePrincipal.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 application_id: str,
                 client_secret: str,
                 directory_id: str):
        pulumi.set(__self__, "application_id", application_id)
        pulumi.set(__self__, "client_secret", client_secret)
        pulumi.set(__self__, "directory_id", directory_id)

    @property
    @pulumi.getter(name="applicationId")
    def application_id(self) -> str:
        return pulumi.get(self, "application_id")

    @property
    @pulumi.getter(name="clientSecret")
    def client_secret(self) -> str:
        return pulumi.get(self, "client_secret")

    @property
    @pulumi.getter(name="directoryId")
    def directory_id(self) -> str:
        return pulumi.get(self, "directory_id")


@pulumi.output_type
class MetastoreDataAccessCloudflareApiToken(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "accessKeyId":
            suggest = "access_key_id"
        elif key == "accountId":
            suggest = "account_id"
        elif key == "secretAccessKey":
            suggest = "secret_access_key"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in MetastoreDataAccessCloudflareApiToken. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        MetastoreDataAccessCloudflareApiToken.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        MetastoreDataAccessCloudflareApiToken.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 access_key_id: str,
                 account_id: str,
                 secret_access_key: str):
        pulumi.set(__self__, "access_key_id", access_key_id)
        pulumi.set(__self__, "account_id", account_id)
        pulumi.set(__self__, "secret_access_key", secret_access_key)

    @property
    @pulumi.getter(name="accessKeyId")
    def access_key_id(self) -> str:
        return pulumi.get(self, "access_key_id")

    @property
    @pulumi.getter(name="accountId")
    def account_id(self) -> str:
        return pulumi.get(self, "account_id")

    @property
    @pulumi.getter(name="secretAccessKey")
    def secret_access_key(self) -> str:
        return pulumi.get(self, "secret_access_key")


@pulumi.output_type
class MetastoreDataAccessDatabricksGcpServiceAccount(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "credentialId":
            suggest = "credential_id"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in MetastoreDataAccessDatabricksGcpServiceAccount. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        MetastoreDataAccessDatabricksGcpServiceAccount.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        MetastoreDataAccessDatabricksGcpServiceAccount.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 credential_id: Optional[str] = None,
                 email: Optional[str] = None):
        if credential_id is not None:
            pulumi.set(__self__, "credential_id", credential_id)
        if email is not None:
            pulumi.set(__self__, "email", email)

    @property
    @pulumi.getter(name="credentialId")
    def credential_id(self) -> Optional[str]:
        return pulumi.get(self, "credential_id")

    @property
    @pulumi.getter
    def email(self) -> Optional[str]:
        return pulumi.get(self, "email")


@pulumi.output_type
class MetastoreDataAccessGcpServiceAccountKey(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "privateKey":
            suggest = "private_key"
        elif key == "privateKeyId":
            suggest = "private_key_id"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in MetastoreDataAccessGcpServiceAccountKey. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        MetastoreDataAccessGcpServiceAccountKey.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        MetastoreDataAccessGcpServiceAccountKey.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 email: str,
                 private_key: str,
                 private_key_id: str):
        pulumi.set(__self__, "email", email)
        pulumi.set(__self__, "private_key", private_key)
        pulumi.set(__self__, "private_key_id", private_key_id)

    @property
    @pulumi.getter
    def email(self) -> str:
        return pulumi.get(self, "email")

    @property
    @pulumi.getter(name="privateKey")
    def private_key(self) -> str:
        return pulumi.get(self, "private_key")

    @property
    @pulumi.getter(name="privateKeyId")
    def private_key_id(self) -> str:
        return pulumi.get(self, "private_key_id")


@pulumi.output_type
class MlflowModelTag(dict):
    def __init__(__self__, *,
                 key: Optional[str] = None,
                 value: Optional[str] = None):
        if key is not None:
            pulumi.set(__self__, "key", key)
        if value is not None:
            pulumi.set(__self__, "value", value)

    @property
    @pulumi.getter
    def key(self) -> Optional[str]:
        return pulumi.get(self, "key")

    @property
    @pulumi.getter
    def value(self) -> Optional[str]:
        return pulumi.get(self, "value")


@pulumi.output_type
class MlflowWebhookHttpUrlSpec(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "enableSslVerification":
            suggest = "enable_ssl_verification"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in MlflowWebhookHttpUrlSpec. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        MlflowWebhookHttpUrlSpec.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        MlflowWebhookHttpUrlSpec.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 url: str,
                 authorization: Optional[str] = None,
                 enable_ssl_verification: Optional[bool] = None,
                 secret: Optional[str] = None):
        """
        :param str url: External HTTPS URL called on event trigger (by using a POST request). Structure of payload depends on the event type, refer to [documentation](https://docs.databricks.com/applications/mlflow/model-registry-webhooks.html) for more details.
        :param str authorization: Value of the authorization header that should be sent in the request sent by the wehbook.  It should be of the form `<auth type> <credentials>`, e.g. `Bearer <access_token>`. If set to an empty string, no authorization header will be included in the request.
        :param bool enable_ssl_verification: Enable/disable SSL certificate validation. Default is `true`. For self-signed certificates, this field must be `false` AND the destination server must disable certificate validation as well. For security purposes, it is encouraged to perform secret validation with the HMAC-encoded portion of the payload and acknowledge the risk associated with disabling hostname validation whereby it becomes more likely that requests can be maliciously routed to an unintended host.
        :param str secret: Shared secret required for HMAC encoding payload. The HMAC-encoded payload will be sent in the header as `X-Databricks-Signature: encoded_payload`.
        """
        pulumi.set(__self__, "url", url)
        if authorization is not None:
            pulumi.set(__self__, "authorization", authorization)
        if enable_ssl_verification is not None:
            pulumi.set(__self__, "enable_ssl_verification", enable_ssl_verification)
        if secret is not None:
            pulumi.set(__self__, "secret", secret)

    @property
    @pulumi.getter
    def url(self) -> str:
        """
        External HTTPS URL called on event trigger (by using a POST request). Structure of payload depends on the event type, refer to [documentation](https://docs.databricks.com/applications/mlflow/model-registry-webhooks.html) for more details.
        """
        return pulumi.get(self, "url")

    @property
    @pulumi.getter
    def authorization(self) -> Optional[str]:
        """
        Value of the authorization header that should be sent in the request sent by the wehbook.  It should be of the form `<auth type> <credentials>`, e.g. `Bearer <access_token>`. If set to an empty string, no authorization header will be included in the request.
        """
        return pulumi.get(self, "authorization")

    @property
    @pulumi.getter(name="enableSslVerification")
    def enable_ssl_verification(self) -> Optional[bool]:
        """
        Enable/disable SSL certificate validation. Default is `true`. For self-signed certificates, this field must be `false` AND the destination server must disable certificate validation as well. For security purposes, it is encouraged to perform secret validation with the HMAC-encoded portion of the payload and acknowledge the risk associated with disabling hostname validation whereby it becomes more likely that requests can be maliciously routed to an unintended host.
        """
        return pulumi.get(self, "enable_ssl_verification")

    @property
    @pulumi.getter
    def secret(self) -> Optional[str]:
        """
        Shared secret required for HMAC encoding payload. The HMAC-encoded payload will be sent in the header as `X-Databricks-Signature: encoded_payload`.
        """
        return pulumi.get(self, "secret")


@pulumi.output_type
class MlflowWebhookJobSpec(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "accessToken":
            suggest = "access_token"
        elif key == "jobId":
            suggest = "job_id"
        elif key == "workspaceUrl":
            suggest = "workspace_url"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in MlflowWebhookJobSpec. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        MlflowWebhookJobSpec.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        MlflowWebhookJobSpec.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 access_token: str,
                 job_id: str,
                 workspace_url: Optional[str] = None):
        """
        :param str access_token: The personal access token used to authorize webhook's job runs.
        :param str job_id: ID of the Databricks job that the webhook runs.
        :param str workspace_url: URL of the workspace containing the job that this webhook runs. If not specified, the jobs workspace URL is assumed to be the same as the workspace where the webhook is created.
        """
        pulumi.set(__self__, "access_token", access_token)
        pulumi.set(__self__, "job_id", job_id)
        if workspace_url is not None:
            pulumi.set(__self__, "workspace_url", workspace_url)

    @property
    @pulumi.getter(name="accessToken")
    def access_token(self) -> str:
        """
        The personal access token used to authorize webhook's job runs.
        """
        return pulumi.get(self, "access_token")

    @property
    @pulumi.getter(name="jobId")
    def job_id(self) -> str:
        """
        ID of the Databricks job that the webhook runs.
        """
        return pulumi.get(self, "job_id")

    @property
    @pulumi.getter(name="workspaceUrl")
    def workspace_url(self) -> Optional[str]:
        """
        URL of the workspace containing the job that this webhook runs. If not specified, the jobs workspace URL is assumed to be the same as the workspace where the webhook is created.
        """
        return pulumi.get(self, "workspace_url")


@pulumi.output_type
class ModelServingConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "autoCaptureConfig":
            suggest = "auto_capture_config"
        elif key == "servedEntities":
            suggest = "served_entities"
        elif key == "servedModels":
            suggest = "served_models"
        elif key == "trafficConfig":
            suggest = "traffic_config"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ModelServingConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ModelServingConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ModelServingConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 auto_capture_config: Optional['outputs.ModelServingConfigAutoCaptureConfig'] = None,
                 served_entities: Optional[Sequence['outputs.ModelServingConfigServedEntity']] = None,
                 served_models: Optional[Sequence['outputs.ModelServingConfigServedModel']] = None,
                 traffic_config: Optional['outputs.ModelServingConfigTrafficConfig'] = None):
        """
        :param 'ModelServingConfigAutoCaptureConfigArgs' auto_capture_config: Configuration for Inference Tables which automatically logs requests and responses to Unity Catalog.
        :param Sequence['ModelServingConfigServedEntityArgs'] served_entities: A list of served entities for the endpoint to serve. A serving endpoint can have up to 10 served entities.
        :param Sequence['ModelServingConfigServedModelArgs'] served_models: Each block represents a served model for the endpoint to serve. A model serving endpoint can have up to 10 served models.
        :param 'ModelServingConfigTrafficConfigArgs' traffic_config: A single block represents the traffic split configuration amongst the served models.
        """
        if auto_capture_config is not None:
            pulumi.set(__self__, "auto_capture_config", auto_capture_config)
        if served_entities is not None:
            pulumi.set(__self__, "served_entities", served_entities)
        if served_models is not None:
            pulumi.set(__self__, "served_models", served_models)
        if traffic_config is not None:
            pulumi.set(__self__, "traffic_config", traffic_config)

    @property
    @pulumi.getter(name="autoCaptureConfig")
    def auto_capture_config(self) -> Optional['outputs.ModelServingConfigAutoCaptureConfig']:
        """
        Configuration for Inference Tables which automatically logs requests and responses to Unity Catalog.
        """
        return pulumi.get(self, "auto_capture_config")

    @property
    @pulumi.getter(name="servedEntities")
    def served_entities(self) -> Optional[Sequence['outputs.ModelServingConfigServedEntity']]:
        """
        A list of served entities for the endpoint to serve. A serving endpoint can have up to 10 served entities.
        """
        return pulumi.get(self, "served_entities")

    @property
    @pulumi.getter(name="servedModels")
    @_utilities.deprecated("""Please use 'config.served_entities' instead of 'config.served_models'.""")
    def served_models(self) -> Optional[Sequence['outputs.ModelServingConfigServedModel']]:
        """
        Each block represents a served model for the endpoint to serve. A model serving endpoint can have up to 10 served models.
        """
        return pulumi.get(self, "served_models")

    @property
    @pulumi.getter(name="trafficConfig")
    def traffic_config(self) -> Optional['outputs.ModelServingConfigTrafficConfig']:
        """
        A single block represents the traffic split configuration amongst the served models.
        """
        return pulumi.get(self, "traffic_config")


@pulumi.output_type
class ModelServingConfigAutoCaptureConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "catalogName":
            suggest = "catalog_name"
        elif key == "schemaName":
            suggest = "schema_name"
        elif key == "tableNamePrefix":
            suggest = "table_name_prefix"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ModelServingConfigAutoCaptureConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ModelServingConfigAutoCaptureConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ModelServingConfigAutoCaptureConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 catalog_name: Optional[str] = None,
                 enabled: Optional[bool] = None,
                 schema_name: Optional[str] = None,
                 table_name_prefix: Optional[str] = None):
        """
        :param str catalog_name: The name of the catalog in Unity Catalog. NOTE: On update, you cannot change the catalog name if it was already set.
        :param bool enabled: If inference tables are enabled or not. NOTE: If you have already disabled payload logging once, you cannot enable again.
        :param str schema_name: The name of the schema in Unity Catalog. NOTE: On update, you cannot change the schema name if it was already set.
        :param str table_name_prefix: The prefix of the table in Unity Catalog. NOTE: On update, you cannot change the prefix name if it was already set.
        """
        if catalog_name is not None:
            pulumi.set(__self__, "catalog_name", catalog_name)
        if enabled is not None:
            pulumi.set(__self__, "enabled", enabled)
        if schema_name is not None:
            pulumi.set(__self__, "schema_name", schema_name)
        if table_name_prefix is not None:
            pulumi.set(__self__, "table_name_prefix", table_name_prefix)

    @property
    @pulumi.getter(name="catalogName")
    def catalog_name(self) -> Optional[str]:
        """
        The name of the catalog in Unity Catalog. NOTE: On update, you cannot change the catalog name if it was already set.
        """
        return pulumi.get(self, "catalog_name")

    @property
    @pulumi.getter
    def enabled(self) -> Optional[bool]:
        """
        If inference tables are enabled or not. NOTE: If you have already disabled payload logging once, you cannot enable again.
        """
        return pulumi.get(self, "enabled")

    @property
    @pulumi.getter(name="schemaName")
    def schema_name(self) -> Optional[str]:
        """
        The name of the schema in Unity Catalog. NOTE: On update, you cannot change the schema name if it was already set.
        """
        return pulumi.get(self, "schema_name")

    @property
    @pulumi.getter(name="tableNamePrefix")
    def table_name_prefix(self) -> Optional[str]:
        """
        The prefix of the table in Unity Catalog. NOTE: On update, you cannot change the prefix name if it was already set.
        """
        return pulumi.get(self, "table_name_prefix")


@pulumi.output_type
class ModelServingConfigServedEntity(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "entityName":
            suggest = "entity_name"
        elif key == "entityVersion":
            suggest = "entity_version"
        elif key == "environmentVars":
            suggest = "environment_vars"
        elif key == "externalModel":
            suggest = "external_model"
        elif key == "instanceProfileArn":
            suggest = "instance_profile_arn"
        elif key == "maxProvisionedThroughput":
            suggest = "max_provisioned_throughput"
        elif key == "minProvisionedThroughput":
            suggest = "min_provisioned_throughput"
        elif key == "scaleToZeroEnabled":
            suggest = "scale_to_zero_enabled"
        elif key == "workloadSize":
            suggest = "workload_size"
        elif key == "workloadType":
            suggest = "workload_type"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ModelServingConfigServedEntity. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ModelServingConfigServedEntity.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ModelServingConfigServedEntity.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 entity_name: Optional[str] = None,
                 entity_version: Optional[str] = None,
                 environment_vars: Optional[Mapping[str, str]] = None,
                 external_model: Optional['outputs.ModelServingConfigServedEntityExternalModel'] = None,
                 instance_profile_arn: Optional[str] = None,
                 max_provisioned_throughput: Optional[int] = None,
                 min_provisioned_throughput: Optional[int] = None,
                 name: Optional[str] = None,
                 scale_to_zero_enabled: Optional[bool] = None,
                 workload_size: Optional[str] = None,
                 workload_type: Optional[str] = None):
        """
        :param str entity_name: The name of the entity to be served. The entity may be a model in the Databricks Model Registry, a model in the Unity Catalog (UC), or a function of type `FEATURE_SPEC` in the UC. If it is a UC object, the full name of the object should be given in the form of `catalog_name.schema_name.model_name`.
        :param str entity_version: The version of the model in Databricks Model Registry to be served or empty if the entity is a `FEATURE_SPEC`.
        :param Mapping[str, str] environment_vars: An object containing a set of optional, user-specified environment variable key-value pairs used for serving this entity. Note: this is an experimental feature and subject to change. Example entity environment variables that refer to Databricks secrets: ```{"OPENAI_API_KEY": "{{secrets/my_scope/my_key}}", "DATABRICKS_TOKEN": "{{secrets/my_scope2/my_key2}}"}```
        :param 'ModelServingConfigServedEntityExternalModelArgs' external_model: The external model to be served. NOTE: Only one of `external_model` and (`entity_name`, `entity_version`, `workload_size`, `workload_type`, and `scale_to_zero_enabled`) can be specified with the latter set being used for custom model serving for a Databricks registered model. When an `external_model` is present, the served entities list can only have one `served_entity` object. For an existing endpoint with `external_model`, it can not be updated to an endpoint without `external_model`. If the endpoint is created without `external_model`, users cannot update it to add `external_model` later.
        :param str instance_profile_arn: ARN of the instance profile that the served entity uses to access AWS resources.
        :param int max_provisioned_throughput: The maximum tokens per second that the endpoint can scale up to.
        :param int min_provisioned_throughput: The minimum tokens per second that the endpoint can scale down to.
        :param str name: The name of a served entity. It must be unique across an endpoint. A served entity name can consist of alphanumeric characters, dashes, and underscores. If not specified for an external model, this field defaults to `external_model.name`, with '.' and ':' replaced with '-', and if not specified for other entities, it defaults to -.
        :param bool scale_to_zero_enabled: Whether the compute resources for the served entity should scale down to zero.
        :param str workload_size: The workload size of the served entity. The workload size corresponds to a range of provisioned concurrency that the compute autoscales between. A single unit of provisioned concurrency can process one request at a time. Valid workload sizes are `Small` (4 - 4 provisioned concurrency), `Medium` (8 - 16 provisioned concurrency), and `Large` (16 - 64 provisioned concurrency). If `scale-to-zero` is enabled, the lower bound of the provisioned concurrency for each workload size is 0.
        :param str workload_type: The workload type of the served entity. The workload type selects which type of compute to use in the endpoint. The default value for this parameter is `CPU`. For deep learning workloads, GPU acceleration is available by selecting workload types like `GPU_SMALL` and others. See the available [GPU types](https://docs.databricks.com/machine-learning/model-serving/create-manage-serving-endpoints.html#gpu-workload-types).
        """
        if entity_name is not None:
            pulumi.set(__self__, "entity_name", entity_name)
        if entity_version is not None:
            pulumi.set(__self__, "entity_version", entity_version)
        if environment_vars is not None:
            pulumi.set(__self__, "environment_vars", environment_vars)
        if external_model is not None:
            pulumi.set(__self__, "external_model", external_model)
        if instance_profile_arn is not None:
            pulumi.set(__self__, "instance_profile_arn", instance_profile_arn)
        if max_provisioned_throughput is not None:
            pulumi.set(__self__, "max_provisioned_throughput", max_provisioned_throughput)
        if min_provisioned_throughput is not None:
            pulumi.set(__self__, "min_provisioned_throughput", min_provisioned_throughput)
        if name is not None:
            pulumi.set(__self__, "name", name)
        if scale_to_zero_enabled is not None:
            pulumi.set(__self__, "scale_to_zero_enabled", scale_to_zero_enabled)
        if workload_size is not None:
            pulumi.set(__self__, "workload_size", workload_size)
        if workload_type is not None:
            pulumi.set(__self__, "workload_type", workload_type)

    @property
    @pulumi.getter(name="entityName")
    def entity_name(self) -> Optional[str]:
        """
        The name of the entity to be served. The entity may be a model in the Databricks Model Registry, a model in the Unity Catalog (UC), or a function of type `FEATURE_SPEC` in the UC. If it is a UC object, the full name of the object should be given in the form of `catalog_name.schema_name.model_name`.
        """
        return pulumi.get(self, "entity_name")

    @property
    @pulumi.getter(name="entityVersion")
    def entity_version(self) -> Optional[str]:
        """
        The version of the model in Databricks Model Registry to be served or empty if the entity is a `FEATURE_SPEC`.
        """
        return pulumi.get(self, "entity_version")

    @property
    @pulumi.getter(name="environmentVars")
    def environment_vars(self) -> Optional[Mapping[str, str]]:
        """
        An object containing a set of optional, user-specified environment variable key-value pairs used for serving this entity. Note: this is an experimental feature and subject to change. Example entity environment variables that refer to Databricks secrets: ```{"OPENAI_API_KEY": "{{secrets/my_scope/my_key}}", "DATABRICKS_TOKEN": "{{secrets/my_scope2/my_key2}}"}```
        """
        return pulumi.get(self, "environment_vars")

    @property
    @pulumi.getter(name="externalModel")
    def external_model(self) -> Optional['outputs.ModelServingConfigServedEntityExternalModel']:
        """
        The external model to be served. NOTE: Only one of `external_model` and (`entity_name`, `entity_version`, `workload_size`, `workload_type`, and `scale_to_zero_enabled`) can be specified with the latter set being used for custom model serving for a Databricks registered model. When an `external_model` is present, the served entities list can only have one `served_entity` object. For an existing endpoint with `external_model`, it can not be updated to an endpoint without `external_model`. If the endpoint is created without `external_model`, users cannot update it to add `external_model` later.
        """
        return pulumi.get(self, "external_model")

    @property
    @pulumi.getter(name="instanceProfileArn")
    def instance_profile_arn(self) -> Optional[str]:
        """
        ARN of the instance profile that the served entity uses to access AWS resources.
        """
        return pulumi.get(self, "instance_profile_arn")

    @property
    @pulumi.getter(name="maxProvisionedThroughput")
    def max_provisioned_throughput(self) -> Optional[int]:
        """
        The maximum tokens per second that the endpoint can scale up to.
        """
        return pulumi.get(self, "max_provisioned_throughput")

    @property
    @pulumi.getter(name="minProvisionedThroughput")
    def min_provisioned_throughput(self) -> Optional[int]:
        """
        The minimum tokens per second that the endpoint can scale down to.
        """
        return pulumi.get(self, "min_provisioned_throughput")

    @property
    @pulumi.getter
    def name(self) -> Optional[str]:
        """
        The name of a served entity. It must be unique across an endpoint. A served entity name can consist of alphanumeric characters, dashes, and underscores. If not specified for an external model, this field defaults to `external_model.name`, with '.' and ':' replaced with '-', and if not specified for other entities, it defaults to -.
        """
        return pulumi.get(self, "name")

    @property
    @pulumi.getter(name="scaleToZeroEnabled")
    def scale_to_zero_enabled(self) -> Optional[bool]:
        """
        Whether the compute resources for the served entity should scale down to zero.
        """
        return pulumi.get(self, "scale_to_zero_enabled")

    @property
    @pulumi.getter(name="workloadSize")
    def workload_size(self) -> Optional[str]:
        """
        The workload size of the served entity. The workload size corresponds to a range of provisioned concurrency that the compute autoscales between. A single unit of provisioned concurrency can process one request at a time. Valid workload sizes are `Small` (4 - 4 provisioned concurrency), `Medium` (8 - 16 provisioned concurrency), and `Large` (16 - 64 provisioned concurrency). If `scale-to-zero` is enabled, the lower bound of the provisioned concurrency for each workload size is 0.
        """
        return pulumi.get(self, "workload_size")

    @property
    @pulumi.getter(name="workloadType")
    def workload_type(self) -> Optional[str]:
        """
        The workload type of the served entity. The workload type selects which type of compute to use in the endpoint. The default value for this parameter is `CPU`. For deep learning workloads, GPU acceleration is available by selecting workload types like `GPU_SMALL` and others. See the available [GPU types](https://docs.databricks.com/machine-learning/model-serving/create-manage-serving-endpoints.html#gpu-workload-types).
        """
        return pulumi.get(self, "workload_type")


@pulumi.output_type
class ModelServingConfigServedEntityExternalModel(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "ai21labsConfig":
            suggest = "ai21labs_config"
        elif key == "amazonBedrockConfig":
            suggest = "amazon_bedrock_config"
        elif key == "anthropicConfig":
            suggest = "anthropic_config"
        elif key == "cohereConfig":
            suggest = "cohere_config"
        elif key == "databricksModelServingConfig":
            suggest = "databricks_model_serving_config"
        elif key == "googleCloudVertexAiConfig":
            suggest = "google_cloud_vertex_ai_config"
        elif key == "openaiConfig":
            suggest = "openai_config"
        elif key == "palmConfig":
            suggest = "palm_config"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ModelServingConfigServedEntityExternalModel. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ModelServingConfigServedEntityExternalModel.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ModelServingConfigServedEntityExternalModel.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 name: str,
                 provider: str,
                 task: str,
                 ai21labs_config: Optional['outputs.ModelServingConfigServedEntityExternalModelAi21labsConfig'] = None,
                 amazon_bedrock_config: Optional['outputs.ModelServingConfigServedEntityExternalModelAmazonBedrockConfig'] = None,
                 anthropic_config: Optional['outputs.ModelServingConfigServedEntityExternalModelAnthropicConfig'] = None,
                 cohere_config: Optional['outputs.ModelServingConfigServedEntityExternalModelCohereConfig'] = None,
                 databricks_model_serving_config: Optional['outputs.ModelServingConfigServedEntityExternalModelDatabricksModelServingConfig'] = None,
                 google_cloud_vertex_ai_config: Optional['outputs.ModelServingConfigServedEntityExternalModelGoogleCloudVertexAiConfig'] = None,
                 openai_config: Optional['outputs.ModelServingConfigServedEntityExternalModelOpenaiConfig'] = None,
                 palm_config: Optional['outputs.ModelServingConfigServedEntityExternalModelPalmConfig'] = None):
        """
        :param str name: The name of the external model.
        :param str provider: The name of the provider for the external model. Currently, the supported providers are `ai21labs`, `anthropic`, `amazon-bedrock`, `cohere`, `databricks-model-serving`, `openai`, and `palm`.
        :param str task: The task type of the external model.
        :param 'ModelServingConfigServedEntityExternalModelAi21labsConfigArgs' ai21labs_config: AI21Labs Config
        :param 'ModelServingConfigServedEntityExternalModelAmazonBedrockConfigArgs' amazon_bedrock_config: Amazon Bedrock Config
        :param 'ModelServingConfigServedEntityExternalModelAnthropicConfigArgs' anthropic_config: Anthropic Config
        :param 'ModelServingConfigServedEntityExternalModelCohereConfigArgs' cohere_config: Cohere Config
        :param 'ModelServingConfigServedEntityExternalModelDatabricksModelServingConfigArgs' databricks_model_serving_config: Databricks Model Serving Config
        :param 'ModelServingConfigServedEntityExternalModelOpenaiConfigArgs' openai_config: OpenAI Config
        :param 'ModelServingConfigServedEntityExternalModelPalmConfigArgs' palm_config: PaLM Config
        """
        pulumi.set(__self__, "name", name)
        pulumi.set(__self__, "provider", provider)
        pulumi.set(__self__, "task", task)
        if ai21labs_config is not None:
            pulumi.set(__self__, "ai21labs_config", ai21labs_config)
        if amazon_bedrock_config is not None:
            pulumi.set(__self__, "amazon_bedrock_config", amazon_bedrock_config)
        if anthropic_config is not None:
            pulumi.set(__self__, "anthropic_config", anthropic_config)
        if cohere_config is not None:
            pulumi.set(__self__, "cohere_config", cohere_config)
        if databricks_model_serving_config is not None:
            pulumi.set(__self__, "databricks_model_serving_config", databricks_model_serving_config)
        if google_cloud_vertex_ai_config is not None:
            pulumi.set(__self__, "google_cloud_vertex_ai_config", google_cloud_vertex_ai_config)
        if openai_config is not None:
            pulumi.set(__self__, "openai_config", openai_config)
        if palm_config is not None:
            pulumi.set(__self__, "palm_config", palm_config)

    @property
    @pulumi.getter
    def name(self) -> str:
        """
        The name of the external model.
        """
        return pulumi.get(self, "name")

    @property
    @pulumi.getter
    def provider(self) -> str:
        """
        The name of the provider for the external model. Currently, the supported providers are `ai21labs`, `anthropic`, `amazon-bedrock`, `cohere`, `databricks-model-serving`, `openai`, and `palm`.
        """
        return pulumi.get(self, "provider")

    @property
    @pulumi.getter
    def task(self) -> str:
        """
        The task type of the external model.
        """
        return pulumi.get(self, "task")

    @property
    @pulumi.getter(name="ai21labsConfig")
    def ai21labs_config(self) -> Optional['outputs.ModelServingConfigServedEntityExternalModelAi21labsConfig']:
        """
        AI21Labs Config
        """
        return pulumi.get(self, "ai21labs_config")

    @property
    @pulumi.getter(name="amazonBedrockConfig")
    def amazon_bedrock_config(self) -> Optional['outputs.ModelServingConfigServedEntityExternalModelAmazonBedrockConfig']:
        """
        Amazon Bedrock Config
        """
        return pulumi.get(self, "amazon_bedrock_config")

    @property
    @pulumi.getter(name="anthropicConfig")
    def anthropic_config(self) -> Optional['outputs.ModelServingConfigServedEntityExternalModelAnthropicConfig']:
        """
        Anthropic Config
        """
        return pulumi.get(self, "anthropic_config")

    @property
    @pulumi.getter(name="cohereConfig")
    def cohere_config(self) -> Optional['outputs.ModelServingConfigServedEntityExternalModelCohereConfig']:
        """
        Cohere Config
        """
        return pulumi.get(self, "cohere_config")

    @property
    @pulumi.getter(name="databricksModelServingConfig")
    def databricks_model_serving_config(self) -> Optional['outputs.ModelServingConfigServedEntityExternalModelDatabricksModelServingConfig']:
        """
        Databricks Model Serving Config
        """
        return pulumi.get(self, "databricks_model_serving_config")

    @property
    @pulumi.getter(name="googleCloudVertexAiConfig")
    def google_cloud_vertex_ai_config(self) -> Optional['outputs.ModelServingConfigServedEntityExternalModelGoogleCloudVertexAiConfig']:
        return pulumi.get(self, "google_cloud_vertex_ai_config")

    @property
    @pulumi.getter(name="openaiConfig")
    def openai_config(self) -> Optional['outputs.ModelServingConfigServedEntityExternalModelOpenaiConfig']:
        """
        OpenAI Config
        """
        return pulumi.get(self, "openai_config")

    @property
    @pulumi.getter(name="palmConfig")
    def palm_config(self) -> Optional['outputs.ModelServingConfigServedEntityExternalModelPalmConfig']:
        """
        PaLM Config
        """
        return pulumi.get(self, "palm_config")


@pulumi.output_type
class ModelServingConfigServedEntityExternalModelAi21labsConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "ai21labsApiKey":
            suggest = "ai21labs_api_key"
        elif key == "ai21labsApiKeyPlaintext":
            suggest = "ai21labs_api_key_plaintext"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ModelServingConfigServedEntityExternalModelAi21labsConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ModelServingConfigServedEntityExternalModelAi21labsConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ModelServingConfigServedEntityExternalModelAi21labsConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 ai21labs_api_key: Optional[str] = None,
                 ai21labs_api_key_plaintext: Optional[str] = None):
        """
        :param str ai21labs_api_key: The Databricks secret key reference for an AI21Labs API key.
        """
        if ai21labs_api_key is not None:
            pulumi.set(__self__, "ai21labs_api_key", ai21labs_api_key)
        if ai21labs_api_key_plaintext is not None:
            pulumi.set(__self__, "ai21labs_api_key_plaintext", ai21labs_api_key_plaintext)

    @property
    @pulumi.getter(name="ai21labsApiKey")
    def ai21labs_api_key(self) -> Optional[str]:
        """
        The Databricks secret key reference for an AI21Labs API key.
        """
        return pulumi.get(self, "ai21labs_api_key")

    @property
    @pulumi.getter(name="ai21labsApiKeyPlaintext")
    def ai21labs_api_key_plaintext(self) -> Optional[str]:
        return pulumi.get(self, "ai21labs_api_key_plaintext")


@pulumi.output_type
class ModelServingConfigServedEntityExternalModelAmazonBedrockConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "awsRegion":
            suggest = "aws_region"
        elif key == "bedrockProvider":
            suggest = "bedrock_provider"
        elif key == "awsAccessKeyId":
            suggest = "aws_access_key_id"
        elif key == "awsAccessKeyIdPlaintext":
            suggest = "aws_access_key_id_plaintext"
        elif key == "awsSecretAccessKey":
            suggest = "aws_secret_access_key"
        elif key == "awsSecretAccessKeyPlaintext":
            suggest = "aws_secret_access_key_plaintext"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ModelServingConfigServedEntityExternalModelAmazonBedrockConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ModelServingConfigServedEntityExternalModelAmazonBedrockConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ModelServingConfigServedEntityExternalModelAmazonBedrockConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 aws_region: str,
                 bedrock_provider: str,
                 aws_access_key_id: Optional[str] = None,
                 aws_access_key_id_plaintext: Optional[str] = None,
                 aws_secret_access_key: Optional[str] = None,
                 aws_secret_access_key_plaintext: Optional[str] = None):
        """
        :param str aws_region: The AWS region to use. Bedrock has to be enabled there.
        :param str bedrock_provider: The underlying provider in Amazon Bedrock. Supported values (case insensitive) include: `Anthropic`, `Cohere`, `AI21Labs`, `Amazon`.
        :param str aws_access_key_id: The Databricks secret key reference for an AWS Access Key ID with permissions to interact with Bedrock services.
        :param str aws_secret_access_key: The Databricks secret key reference for an AWS Secret Access Key paired with the access key ID, with permissions to interact with Bedrock services.
        """
        pulumi.set(__self__, "aws_region", aws_region)
        pulumi.set(__self__, "bedrock_provider", bedrock_provider)
        if aws_access_key_id is not None:
            pulumi.set(__self__, "aws_access_key_id", aws_access_key_id)
        if aws_access_key_id_plaintext is not None:
            pulumi.set(__self__, "aws_access_key_id_plaintext", aws_access_key_id_plaintext)
        if aws_secret_access_key is not None:
            pulumi.set(__self__, "aws_secret_access_key", aws_secret_access_key)
        if aws_secret_access_key_plaintext is not None:
            pulumi.set(__self__, "aws_secret_access_key_plaintext", aws_secret_access_key_plaintext)

    @property
    @pulumi.getter(name="awsRegion")
    def aws_region(self) -> str:
        """
        The AWS region to use. Bedrock has to be enabled there.
        """
        return pulumi.get(self, "aws_region")

    @property
    @pulumi.getter(name="bedrockProvider")
    def bedrock_provider(self) -> str:
        """
        The underlying provider in Amazon Bedrock. Supported values (case insensitive) include: `Anthropic`, `Cohere`, `AI21Labs`, `Amazon`.
        """
        return pulumi.get(self, "bedrock_provider")

    @property
    @pulumi.getter(name="awsAccessKeyId")
    def aws_access_key_id(self) -> Optional[str]:
        """
        The Databricks secret key reference for an AWS Access Key ID with permissions to interact with Bedrock services.
        """
        return pulumi.get(self, "aws_access_key_id")

    @property
    @pulumi.getter(name="awsAccessKeyIdPlaintext")
    def aws_access_key_id_plaintext(self) -> Optional[str]:
        return pulumi.get(self, "aws_access_key_id_plaintext")

    @property
    @pulumi.getter(name="awsSecretAccessKey")
    def aws_secret_access_key(self) -> Optional[str]:
        """
        The Databricks secret key reference for an AWS Secret Access Key paired with the access key ID, with permissions to interact with Bedrock services.
        """
        return pulumi.get(self, "aws_secret_access_key")

    @property
    @pulumi.getter(name="awsSecretAccessKeyPlaintext")
    def aws_secret_access_key_plaintext(self) -> Optional[str]:
        return pulumi.get(self, "aws_secret_access_key_plaintext")


@pulumi.output_type
class ModelServingConfigServedEntityExternalModelAnthropicConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "anthropicApiKey":
            suggest = "anthropic_api_key"
        elif key == "anthropicApiKeyPlaintext":
            suggest = "anthropic_api_key_plaintext"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ModelServingConfigServedEntityExternalModelAnthropicConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ModelServingConfigServedEntityExternalModelAnthropicConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ModelServingConfigServedEntityExternalModelAnthropicConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 anthropic_api_key: Optional[str] = None,
                 anthropic_api_key_plaintext: Optional[str] = None):
        """
        :param str anthropic_api_key: The Databricks secret key reference for an Anthropic API key.
               The Databricks secret key reference for an Anthropic API key.
        """
        if anthropic_api_key is not None:
            pulumi.set(__self__, "anthropic_api_key", anthropic_api_key)
        if anthropic_api_key_plaintext is not None:
            pulumi.set(__self__, "anthropic_api_key_plaintext", anthropic_api_key_plaintext)

    @property
    @pulumi.getter(name="anthropicApiKey")
    def anthropic_api_key(self) -> Optional[str]:
        """
        The Databricks secret key reference for an Anthropic API key.
        The Databricks secret key reference for an Anthropic API key.
        """
        return pulumi.get(self, "anthropic_api_key")

    @property
    @pulumi.getter(name="anthropicApiKeyPlaintext")
    def anthropic_api_key_plaintext(self) -> Optional[str]:
        return pulumi.get(self, "anthropic_api_key_plaintext")


@pulumi.output_type
class ModelServingConfigServedEntityExternalModelCohereConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "cohereApiBase":
            suggest = "cohere_api_base"
        elif key == "cohereApiKey":
            suggest = "cohere_api_key"
        elif key == "cohereApiKeyPlaintext":
            suggest = "cohere_api_key_plaintext"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ModelServingConfigServedEntityExternalModelCohereConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ModelServingConfigServedEntityExternalModelCohereConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ModelServingConfigServedEntityExternalModelCohereConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 cohere_api_base: Optional[str] = None,
                 cohere_api_key: Optional[str] = None,
                 cohere_api_key_plaintext: Optional[str] = None):
        """
        :param str cohere_api_key: The Databricks secret key reference for a Cohere API key.
        """
        if cohere_api_base is not None:
            pulumi.set(__self__, "cohere_api_base", cohere_api_base)
        if cohere_api_key is not None:
            pulumi.set(__self__, "cohere_api_key", cohere_api_key)
        if cohere_api_key_plaintext is not None:
            pulumi.set(__self__, "cohere_api_key_plaintext", cohere_api_key_plaintext)

    @property
    @pulumi.getter(name="cohereApiBase")
    def cohere_api_base(self) -> Optional[str]:
        return pulumi.get(self, "cohere_api_base")

    @property
    @pulumi.getter(name="cohereApiKey")
    def cohere_api_key(self) -> Optional[str]:
        """
        The Databricks secret key reference for a Cohere API key.
        """
        return pulumi.get(self, "cohere_api_key")

    @property
    @pulumi.getter(name="cohereApiKeyPlaintext")
    def cohere_api_key_plaintext(self) -> Optional[str]:
        return pulumi.get(self, "cohere_api_key_plaintext")


@pulumi.output_type
class ModelServingConfigServedEntityExternalModelDatabricksModelServingConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "databricksWorkspaceUrl":
            suggest = "databricks_workspace_url"
        elif key == "databricksApiToken":
            suggest = "databricks_api_token"
        elif key == "databricksApiTokenPlaintext":
            suggest = "databricks_api_token_plaintext"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ModelServingConfigServedEntityExternalModelDatabricksModelServingConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ModelServingConfigServedEntityExternalModelDatabricksModelServingConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ModelServingConfigServedEntityExternalModelDatabricksModelServingConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 databricks_workspace_url: str,
                 databricks_api_token: Optional[str] = None,
                 databricks_api_token_plaintext: Optional[str] = None):
        """
        :param str databricks_workspace_url: The URL of the Databricks workspace containing the model serving endpoint pointed to by this external model.
        :param str databricks_api_token: The Databricks secret key reference for a Databricks API token that corresponds to a user or service principal with Can Query access to the model serving endpoint pointed to by this external model.
        """
        pulumi.set(__self__, "databricks_workspace_url", databricks_workspace_url)
        if databricks_api_token is not None:
            pulumi.set(__self__, "databricks_api_token", databricks_api_token)
        if databricks_api_token_plaintext is not None:
            pulumi.set(__self__, "databricks_api_token_plaintext", databricks_api_token_plaintext)

    @property
    @pulumi.getter(name="databricksWorkspaceUrl")
    def databricks_workspace_url(self) -> str:
        """
        The URL of the Databricks workspace containing the model serving endpoint pointed to by this external model.
        """
        return pulumi.get(self, "databricks_workspace_url")

    @property
    @pulumi.getter(name="databricksApiToken")
    def databricks_api_token(self) -> Optional[str]:
        """
        The Databricks secret key reference for a Databricks API token that corresponds to a user or service principal with Can Query access to the model serving endpoint pointed to by this external model.
        """
        return pulumi.get(self, "databricks_api_token")

    @property
    @pulumi.getter(name="databricksApiTokenPlaintext")
    def databricks_api_token_plaintext(self) -> Optional[str]:
        return pulumi.get(self, "databricks_api_token_plaintext")


@pulumi.output_type
class ModelServingConfigServedEntityExternalModelGoogleCloudVertexAiConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "privateKey":
            suggest = "private_key"
        elif key == "privateKeyPlaintext":
            suggest = "private_key_plaintext"
        elif key == "projectId":
            suggest = "project_id"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ModelServingConfigServedEntityExternalModelGoogleCloudVertexAiConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ModelServingConfigServedEntityExternalModelGoogleCloudVertexAiConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ModelServingConfigServedEntityExternalModelGoogleCloudVertexAiConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 private_key: Optional[str] = None,
                 private_key_plaintext: Optional[str] = None,
                 project_id: Optional[str] = None,
                 region: Optional[str] = None):
        if private_key is not None:
            pulumi.set(__self__, "private_key", private_key)
        if private_key_plaintext is not None:
            pulumi.set(__self__, "private_key_plaintext", private_key_plaintext)
        if project_id is not None:
            pulumi.set(__self__, "project_id", project_id)
        if region is not None:
            pulumi.set(__self__, "region", region)

    @property
    @pulumi.getter(name="privateKey")
    def private_key(self) -> Optional[str]:
        return pulumi.get(self, "private_key")

    @property
    @pulumi.getter(name="privateKeyPlaintext")
    def private_key_plaintext(self) -> Optional[str]:
        return pulumi.get(self, "private_key_plaintext")

    @property
    @pulumi.getter(name="projectId")
    def project_id(self) -> Optional[str]:
        return pulumi.get(self, "project_id")

    @property
    @pulumi.getter
    def region(self) -> Optional[str]:
        return pulumi.get(self, "region")


@pulumi.output_type
class ModelServingConfigServedEntityExternalModelOpenaiConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "microsoftEntraClientId":
            suggest = "microsoft_entra_client_id"
        elif key == "microsoftEntraClientSecret":
            suggest = "microsoft_entra_client_secret"
        elif key == "microsoftEntraClientSecretPlaintext":
            suggest = "microsoft_entra_client_secret_plaintext"
        elif key == "microsoftEntraTenantId":
            suggest = "microsoft_entra_tenant_id"
        elif key == "openaiApiBase":
            suggest = "openai_api_base"
        elif key == "openaiApiKey":
            suggest = "openai_api_key"
        elif key == "openaiApiKeyPlaintext":
            suggest = "openai_api_key_plaintext"
        elif key == "openaiApiType":
            suggest = "openai_api_type"
        elif key == "openaiApiVersion":
            suggest = "openai_api_version"
        elif key == "openaiDeploymentName":
            suggest = "openai_deployment_name"
        elif key == "openaiOrganization":
            suggest = "openai_organization"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ModelServingConfigServedEntityExternalModelOpenaiConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ModelServingConfigServedEntityExternalModelOpenaiConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ModelServingConfigServedEntityExternalModelOpenaiConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 microsoft_entra_client_id: Optional[str] = None,
                 microsoft_entra_client_secret: Optional[str] = None,
                 microsoft_entra_client_secret_plaintext: Optional[str] = None,
                 microsoft_entra_tenant_id: Optional[str] = None,
                 openai_api_base: Optional[str] = None,
                 openai_api_key: Optional[str] = None,
                 openai_api_key_plaintext: Optional[str] = None,
                 openai_api_type: Optional[str] = None,
                 openai_api_version: Optional[str] = None,
                 openai_deployment_name: Optional[str] = None,
                 openai_organization: Optional[str] = None):
        """
        :param str openai_api_base: This is the base URL for the OpenAI API (default: "https://api.openai.com/v1"). For Azure OpenAI, this field is required, and is the base URL for the Azure OpenAI API service provided by Azure.
        :param str openai_api_key: The Databricks secret key reference for an OpenAI or Azure OpenAI API key.
        :param str openai_api_type: This is an optional field to specify the type of OpenAI API to use. For Azure OpenAI, this field is required, and adjust this parameter to represent the preferred security access validation protocol. For access token validation, use azure. For authentication using Azure Active Directory (Azure AD) use, azuread.
        :param str openai_api_version: This is an optional field to specify the OpenAI API version. For Azure OpenAI, this field is required, and is the version of the Azure OpenAI service to utilize, specified by a date.
        :param str openai_deployment_name: This field is only required for Azure OpenAI and is the name of the deployment resource for the Azure OpenAI service.
        :param str openai_organization: This is an optional field to specify the organization in OpenAI or Azure OpenAI.
        """
        if microsoft_entra_client_id is not None:
            pulumi.set(__self__, "microsoft_entra_client_id", microsoft_entra_client_id)
        if microsoft_entra_client_secret is not None:
            pulumi.set(__self__, "microsoft_entra_client_secret", microsoft_entra_client_secret)
        if microsoft_entra_client_secret_plaintext is not None:
            pulumi.set(__self__, "microsoft_entra_client_secret_plaintext", microsoft_entra_client_secret_plaintext)
        if microsoft_entra_tenant_id is not None:
            pulumi.set(__self__, "microsoft_entra_tenant_id", microsoft_entra_tenant_id)
        if openai_api_base is not None:
            pulumi.set(__self__, "openai_api_base", openai_api_base)
        if openai_api_key is not None:
            pulumi.set(__self__, "openai_api_key", openai_api_key)
        if openai_api_key_plaintext is not None:
            pulumi.set(__self__, "openai_api_key_plaintext", openai_api_key_plaintext)
        if openai_api_type is not None:
            pulumi.set(__self__, "openai_api_type", openai_api_type)
        if openai_api_version is not None:
            pulumi.set(__self__, "openai_api_version", openai_api_version)
        if openai_deployment_name is not None:
            pulumi.set(__self__, "openai_deployment_name", openai_deployment_name)
        if openai_organization is not None:
            pulumi.set(__self__, "openai_organization", openai_organization)

    @property
    @pulumi.getter(name="microsoftEntraClientId")
    def microsoft_entra_client_id(self) -> Optional[str]:
        return pulumi.get(self, "microsoft_entra_client_id")

    @property
    @pulumi.getter(name="microsoftEntraClientSecret")
    def microsoft_entra_client_secret(self) -> Optional[str]:
        return pulumi.get(self, "microsoft_entra_client_secret")

    @property
    @pulumi.getter(name="microsoftEntraClientSecretPlaintext")
    def microsoft_entra_client_secret_plaintext(self) -> Optional[str]:
        return pulumi.get(self, "microsoft_entra_client_secret_plaintext")

    @property
    @pulumi.getter(name="microsoftEntraTenantId")
    def microsoft_entra_tenant_id(self) -> Optional[str]:
        return pulumi.get(self, "microsoft_entra_tenant_id")

    @property
    @pulumi.getter(name="openaiApiBase")
    def openai_api_base(self) -> Optional[str]:
        """
        This is the base URL for the OpenAI API (default: "https://api.openai.com/v1"). For Azure OpenAI, this field is required, and is the base URL for the Azure OpenAI API service provided by Azure.
        """
        return pulumi.get(self, "openai_api_base")

    @property
    @pulumi.getter(name="openaiApiKey")
    def openai_api_key(self) -> Optional[str]:
        """
        The Databricks secret key reference for an OpenAI or Azure OpenAI API key.
        """
        return pulumi.get(self, "openai_api_key")

    @property
    @pulumi.getter(name="openaiApiKeyPlaintext")
    def openai_api_key_plaintext(self) -> Optional[str]:
        return pulumi.get(self, "openai_api_key_plaintext")

    @property
    @pulumi.getter(name="openaiApiType")
    def openai_api_type(self) -> Optional[str]:
        """
        This is an optional field to specify the type of OpenAI API to use. For Azure OpenAI, this field is required, and adjust this parameter to represent the preferred security access validation protocol. For access token validation, use azure. For authentication using Azure Active Directory (Azure AD) use, azuread.
        """
        return pulumi.get(self, "openai_api_type")

    @property
    @pulumi.getter(name="openaiApiVersion")
    def openai_api_version(self) -> Optional[str]:
        """
        This is an optional field to specify the OpenAI API version. For Azure OpenAI, this field is required, and is the version of the Azure OpenAI service to utilize, specified by a date.
        """
        return pulumi.get(self, "openai_api_version")

    @property
    @pulumi.getter(name="openaiDeploymentName")
    def openai_deployment_name(self) -> Optional[str]:
        """
        This field is only required for Azure OpenAI and is the name of the deployment resource for the Azure OpenAI service.
        """
        return pulumi.get(self, "openai_deployment_name")

    @property
    @pulumi.getter(name="openaiOrganization")
    def openai_organization(self) -> Optional[str]:
        """
        This is an optional field to specify the organization in OpenAI or Azure OpenAI.
        """
        return pulumi.get(self, "openai_organization")


@pulumi.output_type
class ModelServingConfigServedEntityExternalModelPalmConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "palmApiKey":
            suggest = "palm_api_key"
        elif key == "palmApiKeyPlaintext":
            suggest = "palm_api_key_plaintext"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ModelServingConfigServedEntityExternalModelPalmConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ModelServingConfigServedEntityExternalModelPalmConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ModelServingConfigServedEntityExternalModelPalmConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 palm_api_key: Optional[str] = None,
                 palm_api_key_plaintext: Optional[str] = None):
        """
        :param str palm_api_key: The Databricks secret key reference for a PaLM API key.
        """
        if palm_api_key is not None:
            pulumi.set(__self__, "palm_api_key", palm_api_key)
        if palm_api_key_plaintext is not None:
            pulumi.set(__self__, "palm_api_key_plaintext", palm_api_key_plaintext)

    @property
    @pulumi.getter(name="palmApiKey")
    def palm_api_key(self) -> Optional[str]:
        """
        The Databricks secret key reference for a PaLM API key.
        """
        return pulumi.get(self, "palm_api_key")

    @property
    @pulumi.getter(name="palmApiKeyPlaintext")
    def palm_api_key_plaintext(self) -> Optional[str]:
        return pulumi.get(self, "palm_api_key_plaintext")


@pulumi.output_type
class ModelServingConfigServedModel(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "modelName":
            suggest = "model_name"
        elif key == "modelVersion":
            suggest = "model_version"
        elif key == "workloadSize":
            suggest = "workload_size"
        elif key == "environmentVars":
            suggest = "environment_vars"
        elif key == "instanceProfileArn":
            suggest = "instance_profile_arn"
        elif key == "scaleToZeroEnabled":
            suggest = "scale_to_zero_enabled"
        elif key == "workloadType":
            suggest = "workload_type"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ModelServingConfigServedModel. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ModelServingConfigServedModel.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ModelServingConfigServedModel.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 model_name: str,
                 model_version: str,
                 workload_size: str,
                 environment_vars: Optional[Mapping[str, str]] = None,
                 instance_profile_arn: Optional[str] = None,
                 name: Optional[str] = None,
                 scale_to_zero_enabled: Optional[bool] = None,
                 workload_type: Optional[str] = None):
        """
        :param str model_name: The name of the model in Databricks Model Registry to be served.
        :param str model_version: The version of the model in Databricks Model Registry to be served.
        :param str workload_size: The workload size of the served model. The workload size corresponds to a range of provisioned concurrency that the compute will autoscale between. A single unit of provisioned concurrency can process one request at a time. Valid workload sizes are `Small` (4 - 4 provisioned concurrency), `Medium` (8 - 16 provisioned concurrency), and `Large` (16 - 64 provisioned concurrency).
        :param Mapping[str, str] environment_vars: a map of environment variable name/values that will be used for serving this model.  Environment variables may refer to Databricks secrets using the standard syntax: `{{secrets/secret_scope/secret_key}}`.
        :param str instance_profile_arn: ARN of the instance profile that the served model will use to access AWS resources.
        :param str name: The name of a served model. It must be unique across an endpoint. If not specified, this field will default to `modelname-modelversion`. A served model name can consist of alphanumeric characters, dashes, and underscores.
        :param bool scale_to_zero_enabled: Whether the compute resources for the served model should scale down to zero. If `scale-to-zero` is enabled, the lower bound of the provisioned concurrency for each workload size will be 0. The default value is `true`.
        :param str workload_type: The workload type of the served model. The workload type selects which type of compute to use in the endpoint. For deep learning workloads, GPU acceleration is available by selecting workload types like `GPU_SMALL` and others. See documentation for all options. The default value is `CPU`.
        """
        pulumi.set(__self__, "model_name", model_name)
        pulumi.set(__self__, "model_version", model_version)
        pulumi.set(__self__, "workload_size", workload_size)
        if environment_vars is not None:
            pulumi.set(__self__, "environment_vars", environment_vars)
        if instance_profile_arn is not None:
            pulumi.set(__self__, "instance_profile_arn", instance_profile_arn)
        if name is not None:
            pulumi.set(__self__, "name", name)
        if scale_to_zero_enabled is not None:
            pulumi.set(__self__, "scale_to_zero_enabled", scale_to_zero_enabled)
        if workload_type is not None:
            pulumi.set(__self__, "workload_type", workload_type)

    @property
    @pulumi.getter(name="modelName")
    def model_name(self) -> str:
        """
        The name of the model in Databricks Model Registry to be served.
        """
        return pulumi.get(self, "model_name")

    @property
    @pulumi.getter(name="modelVersion")
    def model_version(self) -> str:
        """
        The version of the model in Databricks Model Registry to be served.
        """
        return pulumi.get(self, "model_version")

    @property
    @pulumi.getter(name="workloadSize")
    def workload_size(self) -> str:
        """
        The workload size of the served model. The workload size corresponds to a range of provisioned concurrency that the compute will autoscale between. A single unit of provisioned concurrency can process one request at a time. Valid workload sizes are `Small` (4 - 4 provisioned concurrency), `Medium` (8 - 16 provisioned concurrency), and `Large` (16 - 64 provisioned concurrency).
        """
        return pulumi.get(self, "workload_size")

    @property
    @pulumi.getter(name="environmentVars")
    def environment_vars(self) -> Optional[Mapping[str, str]]:
        """
        a map of environment variable name/values that will be used for serving this model.  Environment variables may refer to Databricks secrets using the standard syntax: `{{secrets/secret_scope/secret_key}}`.
        """
        return pulumi.get(self, "environment_vars")

    @property
    @pulumi.getter(name="instanceProfileArn")
    def instance_profile_arn(self) -> Optional[str]:
        """
        ARN of the instance profile that the served model will use to access AWS resources.
        """
        return pulumi.get(self, "instance_profile_arn")

    @property
    @pulumi.getter
    def name(self) -> Optional[str]:
        """
        The name of a served model. It must be unique across an endpoint. If not specified, this field will default to `modelname-modelversion`. A served model name can consist of alphanumeric characters, dashes, and underscores.
        """
        return pulumi.get(self, "name")

    @property
    @pulumi.getter(name="scaleToZeroEnabled")
    def scale_to_zero_enabled(self) -> Optional[bool]:
        """
        Whether the compute resources for the served model should scale down to zero. If `scale-to-zero` is enabled, the lower bound of the provisioned concurrency for each workload size will be 0. The default value is `true`.
        """
        return pulumi.get(self, "scale_to_zero_enabled")

    @property
    @pulumi.getter(name="workloadType")
    def workload_type(self) -> Optional[str]:
        """
        The workload type of the served model. The workload type selects which type of compute to use in the endpoint. For deep learning workloads, GPU acceleration is available by selecting workload types like `GPU_SMALL` and others. See documentation for all options. The default value is `CPU`.
        """
        return pulumi.get(self, "workload_type")


@pulumi.output_type
class ModelServingConfigTrafficConfig(dict):
    def __init__(__self__, *,
                 routes: Optional[Sequence['outputs.ModelServingConfigTrafficConfigRoute']] = None):
        """
        :param Sequence['ModelServingConfigTrafficConfigRouteArgs'] routes: Each block represents a route that defines traffic to each served entity. Each `served_entity` block needs to have a corresponding `routes` block.
        """
        if routes is not None:
            pulumi.set(__self__, "routes", routes)

    @property
    @pulumi.getter
    def routes(self) -> Optional[Sequence['outputs.ModelServingConfigTrafficConfigRoute']]:
        """
        Each block represents a route that defines traffic to each served entity. Each `served_entity` block needs to have a corresponding `routes` block.
        """
        return pulumi.get(self, "routes")


@pulumi.output_type
class ModelServingConfigTrafficConfigRoute(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "servedModelName":
            suggest = "served_model_name"
        elif key == "trafficPercentage":
            suggest = "traffic_percentage"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ModelServingConfigTrafficConfigRoute. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ModelServingConfigTrafficConfigRoute.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ModelServingConfigTrafficConfigRoute.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 served_model_name: str,
                 traffic_percentage: int):
        """
        :param int traffic_percentage: The percentage of endpoint traffic to send to this route. It must be an integer between 0 and 100 inclusive.
        """
        pulumi.set(__self__, "served_model_name", served_model_name)
        pulumi.set(__self__, "traffic_percentage", traffic_percentage)

    @property
    @pulumi.getter(name="servedModelName")
    def served_model_name(self) -> str:
        return pulumi.get(self, "served_model_name")

    @property
    @pulumi.getter(name="trafficPercentage")
    def traffic_percentage(self) -> int:
        """
        The percentage of endpoint traffic to send to this route. It must be an integer between 0 and 100 inclusive.
        """
        return pulumi.get(self, "traffic_percentage")


@pulumi.output_type
class ModelServingRateLimit(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "renewalPeriod":
            suggest = "renewal_period"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ModelServingRateLimit. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ModelServingRateLimit.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ModelServingRateLimit.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 calls: int,
                 renewal_period: str,
                 key: Optional[str] = None):
        """
        :param int calls: Used to specify how many calls are allowed for a key within the renewal_period.
        :param str renewal_period: Renewal period field for a serving endpoint rate limit. Currently, only `minute` is supported.
        :param str key: Key field for a serving endpoint rate limit. Currently, only `user` and `endpoint` are supported, with `endpoint` being the default if not specified.
        """
        pulumi.set(__self__, "calls", calls)
        pulumi.set(__self__, "renewal_period", renewal_period)
        if key is not None:
            pulumi.set(__self__, "key", key)

    @property
    @pulumi.getter
    def calls(self) -> int:
        """
        Used to specify how many calls are allowed for a key within the renewal_period.
        """
        return pulumi.get(self, "calls")

    @property
    @pulumi.getter(name="renewalPeriod")
    def renewal_period(self) -> str:
        """
        Renewal period field for a serving endpoint rate limit. Currently, only `minute` is supported.
        """
        return pulumi.get(self, "renewal_period")

    @property
    @pulumi.getter
    def key(self) -> Optional[str]:
        """
        Key field for a serving endpoint rate limit. Currently, only `user` and `endpoint` are supported, with `endpoint` being the default if not specified.
        """
        return pulumi.get(self, "key")


@pulumi.output_type
class ModelServingTag(dict):
    def __init__(__self__, *,
                 key: str,
                 value: Optional[str] = None):
        """
        :param str key: The key field for a tag.
        :param str value: The value field for a tag.
        """
        pulumi.set(__self__, "key", key)
        if value is not None:
            pulumi.set(__self__, "value", value)

    @property
    @pulumi.getter
    def key(self) -> str:
        """
        The key field for a tag.
        """
        return pulumi.get(self, "key")

    @property
    @pulumi.getter
    def value(self) -> Optional[str]:
        """
        The value field for a tag.
        """
        return pulumi.get(self, "value")


@pulumi.output_type
class MountAbfs(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "clientId":
            suggest = "client_id"
        elif key == "clientSecretKey":
            suggest = "client_secret_key"
        elif key == "clientSecretScope":
            suggest = "client_secret_scope"
        elif key == "initializeFileSystem":
            suggest = "initialize_file_system"
        elif key == "containerName":
            suggest = "container_name"
        elif key == "storageAccountName":
            suggest = "storage_account_name"
        elif key == "tenantId":
            suggest = "tenant_id"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in MountAbfs. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        MountAbfs.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        MountAbfs.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 client_id: str,
                 client_secret_key: str,
                 client_secret_scope: str,
                 initialize_file_system: bool,
                 container_name: Optional[str] = None,
                 directory: Optional[str] = None,
                 storage_account_name: Optional[str] = None,
                 tenant_id: Optional[str] = None):
        pulumi.set(__self__, "client_id", client_id)
        pulumi.set(__self__, "client_secret_key", client_secret_key)
        pulumi.set(__self__, "client_secret_scope", client_secret_scope)
        pulumi.set(__self__, "initialize_file_system", initialize_file_system)
        if container_name is not None:
            pulumi.set(__self__, "container_name", container_name)
        if directory is not None:
            pulumi.set(__self__, "directory", directory)
        if storage_account_name is not None:
            pulumi.set(__self__, "storage_account_name", storage_account_name)
        if tenant_id is not None:
            pulumi.set(__self__, "tenant_id", tenant_id)

    @property
    @pulumi.getter(name="clientId")
    def client_id(self) -> str:
        return pulumi.get(self, "client_id")

    @property
    @pulumi.getter(name="clientSecretKey")
    def client_secret_key(self) -> str:
        return pulumi.get(self, "client_secret_key")

    @property
    @pulumi.getter(name="clientSecretScope")
    def client_secret_scope(self) -> str:
        return pulumi.get(self, "client_secret_scope")

    @property
    @pulumi.getter(name="initializeFileSystem")
    def initialize_file_system(self) -> bool:
        return pulumi.get(self, "initialize_file_system")

    @property
    @pulumi.getter(name="containerName")
    def container_name(self) -> Optional[str]:
        return pulumi.get(self, "container_name")

    @property
    @pulumi.getter
    def directory(self) -> Optional[str]:
        return pulumi.get(self, "directory")

    @property
    @pulumi.getter(name="storageAccountName")
    def storage_account_name(self) -> Optional[str]:
        return pulumi.get(self, "storage_account_name")

    @property
    @pulumi.getter(name="tenantId")
    def tenant_id(self) -> Optional[str]:
        return pulumi.get(self, "tenant_id")


@pulumi.output_type
class MountAdl(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "clientId":
            suggest = "client_id"
        elif key == "clientSecretKey":
            suggest = "client_secret_key"
        elif key == "clientSecretScope":
            suggest = "client_secret_scope"
        elif key == "sparkConfPrefix":
            suggest = "spark_conf_prefix"
        elif key == "storageResourceName":
            suggest = "storage_resource_name"
        elif key == "tenantId":
            suggest = "tenant_id"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in MountAdl. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        MountAdl.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        MountAdl.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 client_id: str,
                 client_secret_key: str,
                 client_secret_scope: str,
                 directory: Optional[str] = None,
                 spark_conf_prefix: Optional[str] = None,
                 storage_resource_name: Optional[str] = None,
                 tenant_id: Optional[str] = None):
        pulumi.set(__self__, "client_id", client_id)
        pulumi.set(__self__, "client_secret_key", client_secret_key)
        pulumi.set(__self__, "client_secret_scope", client_secret_scope)
        if directory is not None:
            pulumi.set(__self__, "directory", directory)
        if spark_conf_prefix is not None:
            pulumi.set(__self__, "spark_conf_prefix", spark_conf_prefix)
        if storage_resource_name is not None:
            pulumi.set(__self__, "storage_resource_name", storage_resource_name)
        if tenant_id is not None:
            pulumi.set(__self__, "tenant_id", tenant_id)

    @property
    @pulumi.getter(name="clientId")
    def client_id(self) -> str:
        return pulumi.get(self, "client_id")

    @property
    @pulumi.getter(name="clientSecretKey")
    def client_secret_key(self) -> str:
        return pulumi.get(self, "client_secret_key")

    @property
    @pulumi.getter(name="clientSecretScope")
    def client_secret_scope(self) -> str:
        return pulumi.get(self, "client_secret_scope")

    @property
    @pulumi.getter
    def directory(self) -> Optional[str]:
        return pulumi.get(self, "directory")

    @property
    @pulumi.getter(name="sparkConfPrefix")
    def spark_conf_prefix(self) -> Optional[str]:
        return pulumi.get(self, "spark_conf_prefix")

    @property
    @pulumi.getter(name="storageResourceName")
    def storage_resource_name(self) -> Optional[str]:
        return pulumi.get(self, "storage_resource_name")

    @property
    @pulumi.getter(name="tenantId")
    def tenant_id(self) -> Optional[str]:
        return pulumi.get(self, "tenant_id")


@pulumi.output_type
class MountGs(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "bucketName":
            suggest = "bucket_name"
        elif key == "serviceAccount":
            suggest = "service_account"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in MountGs. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        MountGs.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        MountGs.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 bucket_name: str,
                 service_account: Optional[str] = None):
        pulumi.set(__self__, "bucket_name", bucket_name)
        if service_account is not None:
            pulumi.set(__self__, "service_account", service_account)

    @property
    @pulumi.getter(name="bucketName")
    def bucket_name(self) -> str:
        return pulumi.get(self, "bucket_name")

    @property
    @pulumi.getter(name="serviceAccount")
    def service_account(self) -> Optional[str]:
        return pulumi.get(self, "service_account")


@pulumi.output_type
class MountS3(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "bucketName":
            suggest = "bucket_name"
        elif key == "instanceProfile":
            suggest = "instance_profile"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in MountS3. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        MountS3.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        MountS3.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 bucket_name: str,
                 instance_profile: Optional[str] = None):
        pulumi.set(__self__, "bucket_name", bucket_name)
        if instance_profile is not None:
            pulumi.set(__self__, "instance_profile", instance_profile)

    @property
    @pulumi.getter(name="bucketName")
    def bucket_name(self) -> str:
        return pulumi.get(self, "bucket_name")

    @property
    @pulumi.getter(name="instanceProfile")
    def instance_profile(self) -> Optional[str]:
        return pulumi.get(self, "instance_profile")


@pulumi.output_type
class MountWasb(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "authType":
            suggest = "auth_type"
        elif key == "tokenSecretKey":
            suggest = "token_secret_key"
        elif key == "tokenSecretScope":
            suggest = "token_secret_scope"
        elif key == "containerName":
            suggest = "container_name"
        elif key == "storageAccountName":
            suggest = "storage_account_name"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in MountWasb. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        MountWasb.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        MountWasb.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 auth_type: str,
                 token_secret_key: str,
                 token_secret_scope: str,
                 container_name: Optional[str] = None,
                 directory: Optional[str] = None,
                 storage_account_name: Optional[str] = None):
        pulumi.set(__self__, "auth_type", auth_type)
        pulumi.set(__self__, "token_secret_key", token_secret_key)
        pulumi.set(__self__, "token_secret_scope", token_secret_scope)
        if container_name is not None:
            pulumi.set(__self__, "container_name", container_name)
        if directory is not None:
            pulumi.set(__self__, "directory", directory)
        if storage_account_name is not None:
            pulumi.set(__self__, "storage_account_name", storage_account_name)

    @property
    @pulumi.getter(name="authType")
    def auth_type(self) -> str:
        return pulumi.get(self, "auth_type")

    @property
    @pulumi.getter(name="tokenSecretKey")
    def token_secret_key(self) -> str:
        return pulumi.get(self, "token_secret_key")

    @property
    @pulumi.getter(name="tokenSecretScope")
    def token_secret_scope(self) -> str:
        return pulumi.get(self, "token_secret_scope")

    @property
    @pulumi.getter(name="containerName")
    def container_name(self) -> Optional[str]:
        return pulumi.get(self, "container_name")

    @property
    @pulumi.getter
    def directory(self) -> Optional[str]:
        return pulumi.get(self, "directory")

    @property
    @pulumi.getter(name="storageAccountName")
    def storage_account_name(self) -> Optional[str]:
        return pulumi.get(self, "storage_account_name")


@pulumi.output_type
class MwsCustomerManagedKeysAwsKeyInfo(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "keyArn":
            suggest = "key_arn"
        elif key == "keyAlias":
            suggest = "key_alias"
        elif key == "keyRegion":
            suggest = "key_region"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in MwsCustomerManagedKeysAwsKeyInfo. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        MwsCustomerManagedKeysAwsKeyInfo.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        MwsCustomerManagedKeysAwsKeyInfo.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 key_arn: str,
                 key_alias: Optional[str] = None,
                 key_region: Optional[str] = None):
        """
        :param str key_arn: The AWS KMS key's Amazon Resource Name (ARN).
        :param str key_alias: The AWS KMS key alias.
        :param str key_region: (Computed) The AWS region in which KMS key is deployed to. This is not required.
        """
        pulumi.set(__self__, "key_arn", key_arn)
        if key_alias is not None:
            pulumi.set(__self__, "key_alias", key_alias)
        if key_region is not None:
            pulumi.set(__self__, "key_region", key_region)

    @property
    @pulumi.getter(name="keyArn")
    def key_arn(self) -> str:
        """
        The AWS KMS key's Amazon Resource Name (ARN).
        """
        return pulumi.get(self, "key_arn")

    @property
    @pulumi.getter(name="keyAlias")
    def key_alias(self) -> Optional[str]:
        """
        The AWS KMS key alias.
        """
        return pulumi.get(self, "key_alias")

    @property
    @pulumi.getter(name="keyRegion")
    def key_region(self) -> Optional[str]:
        """
        (Computed) The AWS region in which KMS key is deployed to. This is not required.
        """
        return pulumi.get(self, "key_region")


@pulumi.output_type
class MwsCustomerManagedKeysGcpKeyInfo(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "kmsKeyId":
            suggest = "kms_key_id"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in MwsCustomerManagedKeysGcpKeyInfo. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        MwsCustomerManagedKeysGcpKeyInfo.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        MwsCustomerManagedKeysGcpKeyInfo.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 kms_key_id: str):
        """
        :param str kms_key_id: The GCP KMS key's resource name.
        """
        pulumi.set(__self__, "kms_key_id", kms_key_id)

    @property
    @pulumi.getter(name="kmsKeyId")
    def kms_key_id(self) -> str:
        """
        The GCP KMS key's resource name.
        """
        return pulumi.get(self, "kms_key_id")


@pulumi.output_type
class MwsNetworkConnectivityConfigEgressConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "defaultRules":
            suggest = "default_rules"
        elif key == "targetRules":
            suggest = "target_rules"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in MwsNetworkConnectivityConfigEgressConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        MwsNetworkConnectivityConfigEgressConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        MwsNetworkConnectivityConfigEgressConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 default_rules: Optional['outputs.MwsNetworkConnectivityConfigEgressConfigDefaultRules'] = None,
                 target_rules: Optional['outputs.MwsNetworkConnectivityConfigEgressConfigTargetRules'] = None):
        """
        :param 'MwsNetworkConnectivityConfigEgressConfigDefaultRulesArgs' default_rules: block describing network connectivity rules that are applied by default without resource specific configurations.  Consists of the following fields:
        :param 'MwsNetworkConnectivityConfigEgressConfigTargetRulesArgs' target_rules: block describing network connectivity rules that configured for each destinations. These rules override default rules.  Consists of the following fields:
        """
        if default_rules is not None:
            pulumi.set(__self__, "default_rules", default_rules)
        if target_rules is not None:
            pulumi.set(__self__, "target_rules", target_rules)

    @property
    @pulumi.getter(name="defaultRules")
    def default_rules(self) -> Optional['outputs.MwsNetworkConnectivityConfigEgressConfigDefaultRules']:
        """
        block describing network connectivity rules that are applied by default without resource specific configurations.  Consists of the following fields:
        """
        return pulumi.get(self, "default_rules")

    @property
    @pulumi.getter(name="targetRules")
    def target_rules(self) -> Optional['outputs.MwsNetworkConnectivityConfigEgressConfigTargetRules']:
        """
        block describing network connectivity rules that configured for each destinations. These rules override default rules.  Consists of the following fields:
        """
        return pulumi.get(self, "target_rules")


@pulumi.output_type
class MwsNetworkConnectivityConfigEgressConfigDefaultRules(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "awsStableIpRule":
            suggest = "aws_stable_ip_rule"
        elif key == "azureServiceEndpointRule":
            suggest = "azure_service_endpoint_rule"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in MwsNetworkConnectivityConfigEgressConfigDefaultRules. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        MwsNetworkConnectivityConfigEgressConfigDefaultRules.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        MwsNetworkConnectivityConfigEgressConfigDefaultRules.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 aws_stable_ip_rule: Optional['outputs.MwsNetworkConnectivityConfigEgressConfigDefaultRulesAwsStableIpRule'] = None,
                 azure_service_endpoint_rule: Optional['outputs.MwsNetworkConnectivityConfigEgressConfigDefaultRulesAzureServiceEndpointRule'] = None):
        """
        :param 'MwsNetworkConnectivityConfigEgressConfigDefaultRulesAwsStableIpRuleArgs' aws_stable_ip_rule: (AWS only) - block with information about stable AWS IP CIDR blocks. You can use these to configure the firewall of your resources to allow traffic from your Databricks workspace.  Consists of the following fields:
        :param 'MwsNetworkConnectivityConfigEgressConfigDefaultRulesAzureServiceEndpointRuleArgs' azure_service_endpoint_rule: (Azure only) - block with information about stable Azure service endpoints. You can configure the firewall of your Azure resources to allow traffic from your Databricks serverless compute resources.  Consists of the following fields:
        """
        if aws_stable_ip_rule is not None:
            pulumi.set(__self__, "aws_stable_ip_rule", aws_stable_ip_rule)
        if azure_service_endpoint_rule is not None:
            pulumi.set(__self__, "azure_service_endpoint_rule", azure_service_endpoint_rule)

    @property
    @pulumi.getter(name="awsStableIpRule")
    def aws_stable_ip_rule(self) -> Optional['outputs.MwsNetworkConnectivityConfigEgressConfigDefaultRulesAwsStableIpRule']:
        """
        (AWS only) - block with information about stable AWS IP CIDR blocks. You can use these to configure the firewall of your resources to allow traffic from your Databricks workspace.  Consists of the following fields:
        """
        return pulumi.get(self, "aws_stable_ip_rule")

    @property
    @pulumi.getter(name="azureServiceEndpointRule")
    def azure_service_endpoint_rule(self) -> Optional['outputs.MwsNetworkConnectivityConfigEgressConfigDefaultRulesAzureServiceEndpointRule']:
        """
        (Azure only) - block with information about stable Azure service endpoints. You can configure the firewall of your Azure resources to allow traffic from your Databricks serverless compute resources.  Consists of the following fields:
        """
        return pulumi.get(self, "azure_service_endpoint_rule")


@pulumi.output_type
class MwsNetworkConnectivityConfigEgressConfigDefaultRulesAwsStableIpRule(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "cidrBlocks":
            suggest = "cidr_blocks"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in MwsNetworkConnectivityConfigEgressConfigDefaultRulesAwsStableIpRule. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        MwsNetworkConnectivityConfigEgressConfigDefaultRulesAwsStableIpRule.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        MwsNetworkConnectivityConfigEgressConfigDefaultRulesAwsStableIpRule.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 cidr_blocks: Optional[Sequence[str]] = None):
        """
        :param Sequence[str] cidr_blocks: list of IP CIDR blocks.
        """
        if cidr_blocks is not None:
            pulumi.set(__self__, "cidr_blocks", cidr_blocks)

    @property
    @pulumi.getter(name="cidrBlocks")
    def cidr_blocks(self) -> Optional[Sequence[str]]:
        """
        list of IP CIDR blocks.
        """
        return pulumi.get(self, "cidr_blocks")


@pulumi.output_type
class MwsNetworkConnectivityConfigEgressConfigDefaultRulesAzureServiceEndpointRule(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "targetRegion":
            suggest = "target_region"
        elif key == "targetServices":
            suggest = "target_services"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in MwsNetworkConnectivityConfigEgressConfigDefaultRulesAzureServiceEndpointRule. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        MwsNetworkConnectivityConfigEgressConfigDefaultRulesAzureServiceEndpointRule.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        MwsNetworkConnectivityConfigEgressConfigDefaultRulesAzureServiceEndpointRule.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 subnets: Optional[Sequence[str]] = None,
                 target_region: Optional[str] = None,
                 target_services: Optional[Sequence[str]] = None):
        """
        :param Sequence[str] subnets: list of subnets from which Databricks network traffic originates when accessing your Azure resources.
        :param str target_region: the Azure region in which this service endpoint rule applies.
        :param Sequence[str] target_services: the Azure services to which this service endpoint rule applies to.
        """
        if subnets is not None:
            pulumi.set(__self__, "subnets", subnets)
        if target_region is not None:
            pulumi.set(__self__, "target_region", target_region)
        if target_services is not None:
            pulumi.set(__self__, "target_services", target_services)

    @property
    @pulumi.getter
    def subnets(self) -> Optional[Sequence[str]]:
        """
        list of subnets from which Databricks network traffic originates when accessing your Azure resources.
        """
        return pulumi.get(self, "subnets")

    @property
    @pulumi.getter(name="targetRegion")
    def target_region(self) -> Optional[str]:
        """
        the Azure region in which this service endpoint rule applies.
        """
        return pulumi.get(self, "target_region")

    @property
    @pulumi.getter(name="targetServices")
    def target_services(self) -> Optional[Sequence[str]]:
        """
        the Azure services to which this service endpoint rule applies to.
        """
        return pulumi.get(self, "target_services")


@pulumi.output_type
class MwsNetworkConnectivityConfigEgressConfigTargetRules(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "azurePrivateEndpointRules":
            suggest = "azure_private_endpoint_rules"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in MwsNetworkConnectivityConfigEgressConfigTargetRules. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        MwsNetworkConnectivityConfigEgressConfigTargetRules.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        MwsNetworkConnectivityConfigEgressConfigTargetRules.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 azure_private_endpoint_rules: Optional[Sequence['outputs.MwsNetworkConnectivityConfigEgressConfigTargetRulesAzurePrivateEndpointRule']] = None):
        """
        :param Sequence['MwsNetworkConnectivityConfigEgressConfigTargetRulesAzurePrivateEndpointRuleArgs'] azure_private_endpoint_rules: (Azure only) - list containing information about configure Azure Private Endpoints.
        """
        if azure_private_endpoint_rules is not None:
            pulumi.set(__self__, "azure_private_endpoint_rules", azure_private_endpoint_rules)

    @property
    @pulumi.getter(name="azurePrivateEndpointRules")
    def azure_private_endpoint_rules(self) -> Optional[Sequence['outputs.MwsNetworkConnectivityConfigEgressConfigTargetRulesAzurePrivateEndpointRule']]:
        """
        (Azure only) - list containing information about configure Azure Private Endpoints.
        """
        return pulumi.get(self, "azure_private_endpoint_rules")


@pulumi.output_type
class MwsNetworkConnectivityConfigEgressConfigTargetRulesAzurePrivateEndpointRule(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "connectionState":
            suggest = "connection_state"
        elif key == "creationTime":
            suggest = "creation_time"
        elif key == "deactivatedAt":
            suggest = "deactivated_at"
        elif key == "endpointName":
            suggest = "endpoint_name"
        elif key == "groupId":
            suggest = "group_id"
        elif key == "networkConnectivityConfigId":
            suggest = "network_connectivity_config_id"
        elif key == "resourceId":
            suggest = "resource_id"
        elif key == "ruleId":
            suggest = "rule_id"
        elif key == "updatedTime":
            suggest = "updated_time"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in MwsNetworkConnectivityConfigEgressConfigTargetRulesAzurePrivateEndpointRule. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        MwsNetworkConnectivityConfigEgressConfigTargetRulesAzurePrivateEndpointRule.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        MwsNetworkConnectivityConfigEgressConfigTargetRulesAzurePrivateEndpointRule.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 connection_state: Optional[str] = None,
                 creation_time: Optional[int] = None,
                 deactivated: Optional[bool] = None,
                 deactivated_at: Optional[int] = None,
                 endpoint_name: Optional[str] = None,
                 group_id: Optional[str] = None,
                 network_connectivity_config_id: Optional[str] = None,
                 resource_id: Optional[str] = None,
                 rule_id: Optional[str] = None,
                 updated_time: Optional[int] = None):
        """
        :param str network_connectivity_config_id: Canonical unique identifier of Network Connectivity Config in Databricks Account
        """
        if connection_state is not None:
            pulumi.set(__self__, "connection_state", connection_state)
        if creation_time is not None:
            pulumi.set(__self__, "creation_time", creation_time)
        if deactivated is not None:
            pulumi.set(__self__, "deactivated", deactivated)
        if deactivated_at is not None:
            pulumi.set(__self__, "deactivated_at", deactivated_at)
        if endpoint_name is not None:
            pulumi.set(__self__, "endpoint_name", endpoint_name)
        if group_id is not None:
            pulumi.set(__self__, "group_id", group_id)
        if network_connectivity_config_id is not None:
            pulumi.set(__self__, "network_connectivity_config_id", network_connectivity_config_id)
        if resource_id is not None:
            pulumi.set(__self__, "resource_id", resource_id)
        if rule_id is not None:
            pulumi.set(__self__, "rule_id", rule_id)
        if updated_time is not None:
            pulumi.set(__self__, "updated_time", updated_time)

    @property
    @pulumi.getter(name="connectionState")
    def connection_state(self) -> Optional[str]:
        return pulumi.get(self, "connection_state")

    @property
    @pulumi.getter(name="creationTime")
    def creation_time(self) -> Optional[int]:
        return pulumi.get(self, "creation_time")

    @property
    @pulumi.getter
    def deactivated(self) -> Optional[bool]:
        return pulumi.get(self, "deactivated")

    @property
    @pulumi.getter(name="deactivatedAt")
    def deactivated_at(self) -> Optional[int]:
        return pulumi.get(self, "deactivated_at")

    @property
    @pulumi.getter(name="endpointName")
    def endpoint_name(self) -> Optional[str]:
        return pulumi.get(self, "endpoint_name")

    @property
    @pulumi.getter(name="groupId")
    def group_id(self) -> Optional[str]:
        return pulumi.get(self, "group_id")

    @property
    @pulumi.getter(name="networkConnectivityConfigId")
    def network_connectivity_config_id(self) -> Optional[str]:
        """
        Canonical unique identifier of Network Connectivity Config in Databricks Account
        """
        return pulumi.get(self, "network_connectivity_config_id")

    @property
    @pulumi.getter(name="resourceId")
    def resource_id(self) -> Optional[str]:
        return pulumi.get(self, "resource_id")

    @property
    @pulumi.getter(name="ruleId")
    def rule_id(self) -> Optional[str]:
        return pulumi.get(self, "rule_id")

    @property
    @pulumi.getter(name="updatedTime")
    def updated_time(self) -> Optional[int]:
        return pulumi.get(self, "updated_time")


@pulumi.output_type
class MwsNetworksErrorMessage(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "errorMessage":
            suggest = "error_message"
        elif key == "errorType":
            suggest = "error_type"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in MwsNetworksErrorMessage. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        MwsNetworksErrorMessage.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        MwsNetworksErrorMessage.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 error_message: Optional[str] = None,
                 error_type: Optional[str] = None):
        if error_message is not None:
            pulumi.set(__self__, "error_message", error_message)
        if error_type is not None:
            pulumi.set(__self__, "error_type", error_type)

    @property
    @pulumi.getter(name="errorMessage")
    def error_message(self) -> Optional[str]:
        return pulumi.get(self, "error_message")

    @property
    @pulumi.getter(name="errorType")
    def error_type(self) -> Optional[str]:
        return pulumi.get(self, "error_type")


@pulumi.output_type
class MwsNetworksGcpNetworkInfo(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "networkProjectId":
            suggest = "network_project_id"
        elif key == "podIpRangeName":
            suggest = "pod_ip_range_name"
        elif key == "serviceIpRangeName":
            suggest = "service_ip_range_name"
        elif key == "subnetId":
            suggest = "subnet_id"
        elif key == "subnetRegion":
            suggest = "subnet_region"
        elif key == "vpcId":
            suggest = "vpc_id"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in MwsNetworksGcpNetworkInfo. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        MwsNetworksGcpNetworkInfo.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        MwsNetworksGcpNetworkInfo.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 network_project_id: str,
                 pod_ip_range_name: str,
                 service_ip_range_name: str,
                 subnet_id: str,
                 subnet_region: str,
                 vpc_id: str):
        """
        :param str network_project_id: The Google Cloud project ID of the VPC network.
        :param str pod_ip_range_name: The name of the secondary IP range for pods. A Databricks-managed GKE cluster uses this IP range for its pods. This secondary IP range can only be used by one workspace.
        :param str service_ip_range_name: The name of the secondary IP range for services. A Databricks-managed GKE cluster uses this IP range for its services. This secondary IP range can only be used by one workspace.
        :param str subnet_id: The ID of the subnet associated with this network.
        :param str subnet_region: The Google Cloud region of the workspace data plane. For example, `us-east4`.
        :param str vpc_id: The ID of the VPC associated with this network. VPC IDs can be used in multiple network configurations.
        """
        pulumi.set(__self__, "network_project_id", network_project_id)
        pulumi.set(__self__, "pod_ip_range_name", pod_ip_range_name)
        pulumi.set(__self__, "service_ip_range_name", service_ip_range_name)
        pulumi.set(__self__, "subnet_id", subnet_id)
        pulumi.set(__self__, "subnet_region", subnet_region)
        pulumi.set(__self__, "vpc_id", vpc_id)

    @property
    @pulumi.getter(name="networkProjectId")
    def network_project_id(self) -> str:
        """
        The Google Cloud project ID of the VPC network.
        """
        return pulumi.get(self, "network_project_id")

    @property
    @pulumi.getter(name="podIpRangeName")
    def pod_ip_range_name(self) -> str:
        """
        The name of the secondary IP range for pods. A Databricks-managed GKE cluster uses this IP range for its pods. This secondary IP range can only be used by one workspace.
        """
        return pulumi.get(self, "pod_ip_range_name")

    @property
    @pulumi.getter(name="serviceIpRangeName")
    def service_ip_range_name(self) -> str:
        """
        The name of the secondary IP range for services. A Databricks-managed GKE cluster uses this IP range for its services. This secondary IP range can only be used by one workspace.
        """
        return pulumi.get(self, "service_ip_range_name")

    @property
    @pulumi.getter(name="subnetId")
    def subnet_id(self) -> str:
        """
        The ID of the subnet associated with this network.
        """
        return pulumi.get(self, "subnet_id")

    @property
    @pulumi.getter(name="subnetRegion")
    def subnet_region(self) -> str:
        """
        The Google Cloud region of the workspace data plane. For example, `us-east4`.
        """
        return pulumi.get(self, "subnet_region")

    @property
    @pulumi.getter(name="vpcId")
    def vpc_id(self) -> str:
        """
        The ID of the VPC associated with this network. VPC IDs can be used in multiple network configurations.
        """
        return pulumi.get(self, "vpc_id")


@pulumi.output_type
class MwsNetworksVpcEndpoints(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "dataplaneRelays":
            suggest = "dataplane_relays"
        elif key == "restApis":
            suggest = "rest_apis"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in MwsNetworksVpcEndpoints. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        MwsNetworksVpcEndpoints.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        MwsNetworksVpcEndpoints.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 dataplane_relays: Sequence[str],
                 rest_apis: Sequence[str]):
        pulumi.set(__self__, "dataplane_relays", dataplane_relays)
        pulumi.set(__self__, "rest_apis", rest_apis)

    @property
    @pulumi.getter(name="dataplaneRelays")
    def dataplane_relays(self) -> Sequence[str]:
        return pulumi.get(self, "dataplane_relays")

    @property
    @pulumi.getter(name="restApis")
    def rest_apis(self) -> Sequence[str]:
        return pulumi.get(self, "rest_apis")


@pulumi.output_type
class MwsVpcEndpointGcpVpcEndpointInfo(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "endpointRegion":
            suggest = "endpoint_region"
        elif key == "projectId":
            suggest = "project_id"
        elif key == "pscEndpointName":
            suggest = "psc_endpoint_name"
        elif key == "pscConnectionId":
            suggest = "psc_connection_id"
        elif key == "serviceAttachmentId":
            suggest = "service_attachment_id"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in MwsVpcEndpointGcpVpcEndpointInfo. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        MwsVpcEndpointGcpVpcEndpointInfo.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        MwsVpcEndpointGcpVpcEndpointInfo.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 endpoint_region: str,
                 project_id: str,
                 psc_endpoint_name: str,
                 psc_connection_id: Optional[str] = None,
                 service_attachment_id: Optional[str] = None):
        """
        :param str endpoint_region: Region of the PSC endpoint.
        :param str project_id: The Google Cloud project ID of the VPC network where the PSC connection resides.
        :param str psc_endpoint_name: The name of the PSC endpoint in the Google Cloud project.
        :param str psc_connection_id: The unique ID of this PSC connection.
        :param str service_attachment_id: The service attachment this PSC connection connects to.
        """
        pulumi.set(__self__, "endpoint_region", endpoint_region)
        pulumi.set(__self__, "project_id", project_id)
        pulumi.set(__self__, "psc_endpoint_name", psc_endpoint_name)
        if psc_connection_id is not None:
            pulumi.set(__self__, "psc_connection_id", psc_connection_id)
        if service_attachment_id is not None:
            pulumi.set(__self__, "service_attachment_id", service_attachment_id)

    @property
    @pulumi.getter(name="endpointRegion")
    def endpoint_region(self) -> str:
        """
        Region of the PSC endpoint.
        """
        return pulumi.get(self, "endpoint_region")

    @property
    @pulumi.getter(name="projectId")
    def project_id(self) -> str:
        """
        The Google Cloud project ID of the VPC network where the PSC connection resides.
        """
        return pulumi.get(self, "project_id")

    @property
    @pulumi.getter(name="pscEndpointName")
    def psc_endpoint_name(self) -> str:
        """
        The name of the PSC endpoint in the Google Cloud project.
        """
        return pulumi.get(self, "psc_endpoint_name")

    @property
    @pulumi.getter(name="pscConnectionId")
    def psc_connection_id(self) -> Optional[str]:
        """
        The unique ID of this PSC connection.
        """
        return pulumi.get(self, "psc_connection_id")

    @property
    @pulumi.getter(name="serviceAttachmentId")
    def service_attachment_id(self) -> Optional[str]:
        """
        The service attachment this PSC connection connects to.
        """
        return pulumi.get(self, "service_attachment_id")


@pulumi.output_type
class MwsWorkspacesCloudResourceContainer(dict):
    def __init__(__self__, *,
                 gcp: 'outputs.MwsWorkspacesCloudResourceContainerGcp'):
        """
        :param 'MwsWorkspacesCloudResourceContainerGcpArgs' gcp: A block that consists of the following field:
        """
        pulumi.set(__self__, "gcp", gcp)

    @property
    @pulumi.getter
    def gcp(self) -> 'outputs.MwsWorkspacesCloudResourceContainerGcp':
        """
        A block that consists of the following field:
        """
        return pulumi.get(self, "gcp")


@pulumi.output_type
class MwsWorkspacesCloudResourceContainerGcp(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "projectId":
            suggest = "project_id"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in MwsWorkspacesCloudResourceContainerGcp. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        MwsWorkspacesCloudResourceContainerGcp.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        MwsWorkspacesCloudResourceContainerGcp.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 project_id: str):
        """
        :param str project_id: The Google Cloud project ID, which the workspace uses to instantiate cloud resources for your workspace.
        """
        pulumi.set(__self__, "project_id", project_id)

    @property
    @pulumi.getter(name="projectId")
    def project_id(self) -> str:
        """
        The Google Cloud project ID, which the workspace uses to instantiate cloud resources for your workspace.
        """
        return pulumi.get(self, "project_id")


@pulumi.output_type
class MwsWorkspacesExternalCustomerInfo(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "authoritativeUserEmail":
            suggest = "authoritative_user_email"
        elif key == "authoritativeUserFullName":
            suggest = "authoritative_user_full_name"
        elif key == "customerName":
            suggest = "customer_name"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in MwsWorkspacesExternalCustomerInfo. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        MwsWorkspacesExternalCustomerInfo.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        MwsWorkspacesExternalCustomerInfo.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 authoritative_user_email: str,
                 authoritative_user_full_name: str,
                 customer_name: str):
        pulumi.set(__self__, "authoritative_user_email", authoritative_user_email)
        pulumi.set(__self__, "authoritative_user_full_name", authoritative_user_full_name)
        pulumi.set(__self__, "customer_name", customer_name)

    @property
    @pulumi.getter(name="authoritativeUserEmail")
    def authoritative_user_email(self) -> str:
        return pulumi.get(self, "authoritative_user_email")

    @property
    @pulumi.getter(name="authoritativeUserFullName")
    def authoritative_user_full_name(self) -> str:
        return pulumi.get(self, "authoritative_user_full_name")

    @property
    @pulumi.getter(name="customerName")
    def customer_name(self) -> str:
        return pulumi.get(self, "customer_name")


@pulumi.output_type
class MwsWorkspacesGcpManagedNetworkConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "gkeClusterPodIpRange":
            suggest = "gke_cluster_pod_ip_range"
        elif key == "gkeClusterServiceIpRange":
            suggest = "gke_cluster_service_ip_range"
        elif key == "subnetCidr":
            suggest = "subnet_cidr"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in MwsWorkspacesGcpManagedNetworkConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        MwsWorkspacesGcpManagedNetworkConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        MwsWorkspacesGcpManagedNetworkConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 gke_cluster_pod_ip_range: str,
                 gke_cluster_service_ip_range: str,
                 subnet_cidr: str):
        pulumi.set(__self__, "gke_cluster_pod_ip_range", gke_cluster_pod_ip_range)
        pulumi.set(__self__, "gke_cluster_service_ip_range", gke_cluster_service_ip_range)
        pulumi.set(__self__, "subnet_cidr", subnet_cidr)

    @property
    @pulumi.getter(name="gkeClusterPodIpRange")
    def gke_cluster_pod_ip_range(self) -> str:
        return pulumi.get(self, "gke_cluster_pod_ip_range")

    @property
    @pulumi.getter(name="gkeClusterServiceIpRange")
    def gke_cluster_service_ip_range(self) -> str:
        return pulumi.get(self, "gke_cluster_service_ip_range")

    @property
    @pulumi.getter(name="subnetCidr")
    def subnet_cidr(self) -> str:
        return pulumi.get(self, "subnet_cidr")


@pulumi.output_type
class MwsWorkspacesGkeConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "connectivityType":
            suggest = "connectivity_type"
        elif key == "masterIpRange":
            suggest = "master_ip_range"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in MwsWorkspacesGkeConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        MwsWorkspacesGkeConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        MwsWorkspacesGkeConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 connectivity_type: str,
                 master_ip_range: str):
        """
        :param str connectivity_type: Specifies the network connectivity types for the GKE nodes and the GKE master network. Possible values are: `PRIVATE_NODE_PUBLIC_MASTER`, `PUBLIC_NODE_PUBLIC_MASTER`.
        :param str master_ip_range: The IP range from which to allocate GKE cluster master resources. This field will be ignored if GKE private cluster is not enabled. It must be exactly as big as `/28`.
        """
        pulumi.set(__self__, "connectivity_type", connectivity_type)
        pulumi.set(__self__, "master_ip_range", master_ip_range)

    @property
    @pulumi.getter(name="connectivityType")
    def connectivity_type(self) -> str:
        """
        Specifies the network connectivity types for the GKE nodes and the GKE master network. Possible values are: `PRIVATE_NODE_PUBLIC_MASTER`, `PUBLIC_NODE_PUBLIC_MASTER`.
        """
        return pulumi.get(self, "connectivity_type")

    @property
    @pulumi.getter(name="masterIpRange")
    def master_ip_range(self) -> str:
        """
        The IP range from which to allocate GKE cluster master resources. This field will be ignored if GKE private cluster is not enabled. It must be exactly as big as `/28`.
        """
        return pulumi.get(self, "master_ip_range")


@pulumi.output_type
class MwsWorkspacesToken(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "lifetimeSeconds":
            suggest = "lifetime_seconds"
        elif key == "tokenId":
            suggest = "token_id"
        elif key == "tokenValue":
            suggest = "token_value"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in MwsWorkspacesToken. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        MwsWorkspacesToken.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        MwsWorkspacesToken.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 comment: Optional[str] = None,
                 lifetime_seconds: Optional[int] = None,
                 token_id: Optional[str] = None,
                 token_value: Optional[str] = None):
        """
        :param str comment: Comment, that will appear in "User Settings / Access Tokens" page on Workspace UI. By default it's "Pulumi PAT".
        :param int lifetime_seconds: Token expiry lifetime. By default its 2592000 (30 days).
        """
        if comment is not None:
            pulumi.set(__self__, "comment", comment)
        if lifetime_seconds is not None:
            pulumi.set(__self__, "lifetime_seconds", lifetime_seconds)
        if token_id is not None:
            pulumi.set(__self__, "token_id", token_id)
        if token_value is not None:
            pulumi.set(__self__, "token_value", token_value)

    @property
    @pulumi.getter
    def comment(self) -> Optional[str]:
        """
        Comment, that will appear in "User Settings / Access Tokens" page on Workspace UI. By default it's "Pulumi PAT".
        """
        return pulumi.get(self, "comment")

    @property
    @pulumi.getter(name="lifetimeSeconds")
    def lifetime_seconds(self) -> Optional[int]:
        """
        Token expiry lifetime. By default its 2592000 (30 days).
        """
        return pulumi.get(self, "lifetime_seconds")

    @property
    @pulumi.getter(name="tokenId")
    def token_id(self) -> Optional[str]:
        return pulumi.get(self, "token_id")

    @property
    @pulumi.getter(name="tokenValue")
    def token_value(self) -> Optional[str]:
        return pulumi.get(self, "token_value")


@pulumi.output_type
class NotificationDestinationConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "genericWebhook":
            suggest = "generic_webhook"
        elif key == "microsoftTeams":
            suggest = "microsoft_teams"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in NotificationDestinationConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        NotificationDestinationConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        NotificationDestinationConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 email: Optional['outputs.NotificationDestinationConfigEmail'] = None,
                 generic_webhook: Optional['outputs.NotificationDestinationConfigGenericWebhook'] = None,
                 microsoft_teams: Optional['outputs.NotificationDestinationConfigMicrosoftTeams'] = None,
                 pagerduty: Optional['outputs.NotificationDestinationConfigPagerduty'] = None,
                 slack: Optional['outputs.NotificationDestinationConfigSlack'] = None):
        """
        :param 'NotificationDestinationConfigEmailArgs' email: The email configuration of the Notification Destination. It must contain the following:
        :param 'NotificationDestinationConfigGenericWebhookArgs' generic_webhook: The Generic Webhook configuration of the Notification Destination. It must contain the following:
        :param 'NotificationDestinationConfigMicrosoftTeamsArgs' microsoft_teams: The Microsoft Teams configuration of the Notification Destination. It must contain the following:
        :param 'NotificationDestinationConfigPagerdutyArgs' pagerduty: The PagerDuty configuration of the Notification Destination. It must contain the following:
        :param 'NotificationDestinationConfigSlackArgs' slack: The Slack configuration of the Notification Destination. It must contain the following:
        """
        if email is not None:
            pulumi.set(__self__, "email", email)
        if generic_webhook is not None:
            pulumi.set(__self__, "generic_webhook", generic_webhook)
        if microsoft_teams is not None:
            pulumi.set(__self__, "microsoft_teams", microsoft_teams)
        if pagerduty is not None:
            pulumi.set(__self__, "pagerduty", pagerduty)
        if slack is not None:
            pulumi.set(__self__, "slack", slack)

    @property
    @pulumi.getter
    def email(self) -> Optional['outputs.NotificationDestinationConfigEmail']:
        """
        The email configuration of the Notification Destination. It must contain the following:
        """
        return pulumi.get(self, "email")

    @property
    @pulumi.getter(name="genericWebhook")
    def generic_webhook(self) -> Optional['outputs.NotificationDestinationConfigGenericWebhook']:
        """
        The Generic Webhook configuration of the Notification Destination. It must contain the following:
        """
        return pulumi.get(self, "generic_webhook")

    @property
    @pulumi.getter(name="microsoftTeams")
    def microsoft_teams(self) -> Optional['outputs.NotificationDestinationConfigMicrosoftTeams']:
        """
        The Microsoft Teams configuration of the Notification Destination. It must contain the following:
        """
        return pulumi.get(self, "microsoft_teams")

    @property
    @pulumi.getter
    def pagerduty(self) -> Optional['outputs.NotificationDestinationConfigPagerduty']:
        """
        The PagerDuty configuration of the Notification Destination. It must contain the following:
        """
        return pulumi.get(self, "pagerduty")

    @property
    @pulumi.getter
    def slack(self) -> Optional['outputs.NotificationDestinationConfigSlack']:
        """
        The Slack configuration of the Notification Destination. It must contain the following:
        """
        return pulumi.get(self, "slack")


@pulumi.output_type
class NotificationDestinationConfigEmail(dict):
    def __init__(__self__, *,
                 addresses: Optional[Sequence[str]] = None):
        """
        :param Sequence[str] addresses: The list of email addresses to send notifications to.
        """
        if addresses is not None:
            pulumi.set(__self__, "addresses", addresses)

    @property
    @pulumi.getter
    def addresses(self) -> Optional[Sequence[str]]:
        """
        The list of email addresses to send notifications to.
        """
        return pulumi.get(self, "addresses")


@pulumi.output_type
class NotificationDestinationConfigGenericWebhook(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "passwordSet":
            suggest = "password_set"
        elif key == "urlSet":
            suggest = "url_set"
        elif key == "usernameSet":
            suggest = "username_set"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in NotificationDestinationConfigGenericWebhook. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        NotificationDestinationConfigGenericWebhook.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        NotificationDestinationConfigGenericWebhook.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 password: Optional[str] = None,
                 password_set: Optional[bool] = None,
                 url: Optional[str] = None,
                 url_set: Optional[bool] = None,
                 username: Optional[str] = None,
                 username_set: Optional[bool] = None):
        """
        :param str password: The password for basic authentication.
               
               > **NOTE** If the type of notification destination is changed, the existing notification destination will be deleted and a new notification destination will be created with the new type.
        :param str url: The Generic Webhook URL.
        :param str username: The username for basic authentication.
        """
        if password is not None:
            pulumi.set(__self__, "password", password)
        if password_set is not None:
            pulumi.set(__self__, "password_set", password_set)
        if url is not None:
            pulumi.set(__self__, "url", url)
        if url_set is not None:
            pulumi.set(__self__, "url_set", url_set)
        if username is not None:
            pulumi.set(__self__, "username", username)
        if username_set is not None:
            pulumi.set(__self__, "username_set", username_set)

    @property
    @pulumi.getter
    def password(self) -> Optional[str]:
        """
        The password for basic authentication.

        > **NOTE** If the type of notification destination is changed, the existing notification destination will be deleted and a new notification destination will be created with the new type.
        """
        return pulumi.get(self, "password")

    @property
    @pulumi.getter(name="passwordSet")
    def password_set(self) -> Optional[bool]:
        return pulumi.get(self, "password_set")

    @property
    @pulumi.getter
    def url(self) -> Optional[str]:
        """
        The Generic Webhook URL.
        """
        return pulumi.get(self, "url")

    @property
    @pulumi.getter(name="urlSet")
    def url_set(self) -> Optional[bool]:
        return pulumi.get(self, "url_set")

    @property
    @pulumi.getter
    def username(self) -> Optional[str]:
        """
        The username for basic authentication.
        """
        return pulumi.get(self, "username")

    @property
    @pulumi.getter(name="usernameSet")
    def username_set(self) -> Optional[bool]:
        return pulumi.get(self, "username_set")


@pulumi.output_type
class NotificationDestinationConfigMicrosoftTeams(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "urlSet":
            suggest = "url_set"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in NotificationDestinationConfigMicrosoftTeams. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        NotificationDestinationConfigMicrosoftTeams.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        NotificationDestinationConfigMicrosoftTeams.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 url: Optional[str] = None,
                 url_set: Optional[bool] = None):
        """
        :param str url: The Microsoft Teams webhook URL.
        """
        if url is not None:
            pulumi.set(__self__, "url", url)
        if url_set is not None:
            pulumi.set(__self__, "url_set", url_set)

    @property
    @pulumi.getter
    def url(self) -> Optional[str]:
        """
        The Microsoft Teams webhook URL.
        """
        return pulumi.get(self, "url")

    @property
    @pulumi.getter(name="urlSet")
    def url_set(self) -> Optional[bool]:
        return pulumi.get(self, "url_set")


@pulumi.output_type
class NotificationDestinationConfigPagerduty(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "integrationKey":
            suggest = "integration_key"
        elif key == "integrationKeySet":
            suggest = "integration_key_set"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in NotificationDestinationConfigPagerduty. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        NotificationDestinationConfigPagerduty.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        NotificationDestinationConfigPagerduty.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 integration_key: Optional[str] = None,
                 integration_key_set: Optional[bool] = None):
        """
        :param str integration_key: The PagerDuty integration key.
        """
        if integration_key is not None:
            pulumi.set(__self__, "integration_key", integration_key)
        if integration_key_set is not None:
            pulumi.set(__self__, "integration_key_set", integration_key_set)

    @property
    @pulumi.getter(name="integrationKey")
    def integration_key(self) -> Optional[str]:
        """
        The PagerDuty integration key.
        """
        return pulumi.get(self, "integration_key")

    @property
    @pulumi.getter(name="integrationKeySet")
    def integration_key_set(self) -> Optional[bool]:
        return pulumi.get(self, "integration_key_set")


@pulumi.output_type
class NotificationDestinationConfigSlack(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "urlSet":
            suggest = "url_set"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in NotificationDestinationConfigSlack. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        NotificationDestinationConfigSlack.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        NotificationDestinationConfigSlack.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 url: Optional[str] = None,
                 url_set: Optional[bool] = None):
        """
        :param str url: The Slack webhook URL.
        """
        if url is not None:
            pulumi.set(__self__, "url", url)
        if url_set is not None:
            pulumi.set(__self__, "url_set", url_set)

    @property
    @pulumi.getter
    def url(self) -> Optional[str]:
        """
        The Slack webhook URL.
        """
        return pulumi.get(self, "url")

    @property
    @pulumi.getter(name="urlSet")
    def url_set(self) -> Optional[bool]:
        return pulumi.get(self, "url_set")


@pulumi.output_type
class OnlineTableSpec(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "performFullCopy":
            suggest = "perform_full_copy"
        elif key == "pipelineId":
            suggest = "pipeline_id"
        elif key == "primaryKeyColumns":
            suggest = "primary_key_columns"
        elif key == "runContinuously":
            suggest = "run_continuously"
        elif key == "runTriggered":
            suggest = "run_triggered"
        elif key == "sourceTableFullName":
            suggest = "source_table_full_name"
        elif key == "timeseriesKey":
            suggest = "timeseries_key"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in OnlineTableSpec. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        OnlineTableSpec.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        OnlineTableSpec.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 perform_full_copy: Optional[bool] = None,
                 pipeline_id: Optional[str] = None,
                 primary_key_columns: Optional[Sequence[str]] = None,
                 run_continuously: Optional['outputs.OnlineTableSpecRunContinuously'] = None,
                 run_triggered: Optional['outputs.OnlineTableSpecRunTriggered'] = None,
                 source_table_full_name: Optional[str] = None,
                 timeseries_key: Optional[str] = None):
        """
        :param bool perform_full_copy: Whether to create a full-copy pipeline -- a pipeline that stops after creates a full copy of the source table upon initialization and does not process any change data feeds (CDFs) afterwards. The pipeline can still be manually triggered afterwards, but it always perform a full copy of the source table and there are no incremental updates. This mode is useful for syncing views or tables without CDFs to online tables. Note that the full-copy pipeline only supports "triggered" scheduling policy.
        :param str pipeline_id: ID of the associated Delta Live Table pipeline.
        :param Sequence[str] primary_key_columns: list of the columns comprising the primary key.
        :param 'OnlineTableSpecRunContinuouslyArgs' run_continuously: empty block that specifies that pipeline runs continuously after generating the initial data.  Conflicts with `run_triggered`.
        :param 'OnlineTableSpecRunTriggeredArgs' run_triggered: empty block that specifies that pipeline stops after generating the initial data and can be triggered later (manually, through a cron job or through data triggers).
        :param str source_table_full_name: full name of the source table.
        :param str timeseries_key: Time series key to deduplicate (tie-break) rows with the same primary key.
        """
        if perform_full_copy is not None:
            pulumi.set(__self__, "perform_full_copy", perform_full_copy)
        if pipeline_id is not None:
            pulumi.set(__self__, "pipeline_id", pipeline_id)
        if primary_key_columns is not None:
            pulumi.set(__self__, "primary_key_columns", primary_key_columns)
        if run_continuously is not None:
            pulumi.set(__self__, "run_continuously", run_continuously)
        if run_triggered is not None:
            pulumi.set(__self__, "run_triggered", run_triggered)
        if source_table_full_name is not None:
            pulumi.set(__self__, "source_table_full_name", source_table_full_name)
        if timeseries_key is not None:
            pulumi.set(__self__, "timeseries_key", timeseries_key)

    @property
    @pulumi.getter(name="performFullCopy")
    def perform_full_copy(self) -> Optional[bool]:
        """
        Whether to create a full-copy pipeline -- a pipeline that stops after creates a full copy of the source table upon initialization and does not process any change data feeds (CDFs) afterwards. The pipeline can still be manually triggered afterwards, but it always perform a full copy of the source table and there are no incremental updates. This mode is useful for syncing views or tables without CDFs to online tables. Note that the full-copy pipeline only supports "triggered" scheduling policy.
        """
        return pulumi.get(self, "perform_full_copy")

    @property
    @pulumi.getter(name="pipelineId")
    def pipeline_id(self) -> Optional[str]:
        """
        ID of the associated Delta Live Table pipeline.
        """
        return pulumi.get(self, "pipeline_id")

    @property
    @pulumi.getter(name="primaryKeyColumns")
    def primary_key_columns(self) -> Optional[Sequence[str]]:
        """
        list of the columns comprising the primary key.
        """
        return pulumi.get(self, "primary_key_columns")

    @property
    @pulumi.getter(name="runContinuously")
    def run_continuously(self) -> Optional['outputs.OnlineTableSpecRunContinuously']:
        """
        empty block that specifies that pipeline runs continuously after generating the initial data.  Conflicts with `run_triggered`.
        """
        return pulumi.get(self, "run_continuously")

    @property
    @pulumi.getter(name="runTriggered")
    def run_triggered(self) -> Optional['outputs.OnlineTableSpecRunTriggered']:
        """
        empty block that specifies that pipeline stops after generating the initial data and can be triggered later (manually, through a cron job or through data triggers).
        """
        return pulumi.get(self, "run_triggered")

    @property
    @pulumi.getter(name="sourceTableFullName")
    def source_table_full_name(self) -> Optional[str]:
        """
        full name of the source table.
        """
        return pulumi.get(self, "source_table_full_name")

    @property
    @pulumi.getter(name="timeseriesKey")
    def timeseries_key(self) -> Optional[str]:
        """
        Time series key to deduplicate (tie-break) rows with the same primary key.
        """
        return pulumi.get(self, "timeseries_key")


@pulumi.output_type
class OnlineTableSpecRunContinuously(dict):
    def __init__(__self__):
        pass


@pulumi.output_type
class OnlineTableSpecRunTriggered(dict):
    def __init__(__self__):
        pass


@pulumi.output_type
class OnlineTableStatus(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "continuousUpdateStatus":
            suggest = "continuous_update_status"
        elif key == "detailedState":
            suggest = "detailed_state"
        elif key == "failedStatus":
            suggest = "failed_status"
        elif key == "provisioningStatus":
            suggest = "provisioning_status"
        elif key == "triggeredUpdateStatus":
            suggest = "triggered_update_status"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in OnlineTableStatus. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        OnlineTableStatus.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        OnlineTableStatus.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 continuous_update_status: Optional['outputs.OnlineTableStatusContinuousUpdateStatus'] = None,
                 detailed_state: Optional[str] = None,
                 failed_status: Optional['outputs.OnlineTableStatusFailedStatus'] = None,
                 message: Optional[str] = None,
                 provisioning_status: Optional['outputs.OnlineTableStatusProvisioningStatus'] = None,
                 triggered_update_status: Optional['outputs.OnlineTableStatusTriggeredUpdateStatus'] = None):
        """
        :param str detailed_state: The state of the online table.
        :param str message: A text description of the current state of the online table.
        """
        if continuous_update_status is not None:
            pulumi.set(__self__, "continuous_update_status", continuous_update_status)
        if detailed_state is not None:
            pulumi.set(__self__, "detailed_state", detailed_state)
        if failed_status is not None:
            pulumi.set(__self__, "failed_status", failed_status)
        if message is not None:
            pulumi.set(__self__, "message", message)
        if provisioning_status is not None:
            pulumi.set(__self__, "provisioning_status", provisioning_status)
        if triggered_update_status is not None:
            pulumi.set(__self__, "triggered_update_status", triggered_update_status)

    @property
    @pulumi.getter(name="continuousUpdateStatus")
    def continuous_update_status(self) -> Optional['outputs.OnlineTableStatusContinuousUpdateStatus']:
        return pulumi.get(self, "continuous_update_status")

    @property
    @pulumi.getter(name="detailedState")
    def detailed_state(self) -> Optional[str]:
        """
        The state of the online table.
        """
        return pulumi.get(self, "detailed_state")

    @property
    @pulumi.getter(name="failedStatus")
    def failed_status(self) -> Optional['outputs.OnlineTableStatusFailedStatus']:
        return pulumi.get(self, "failed_status")

    @property
    @pulumi.getter
    def message(self) -> Optional[str]:
        """
        A text description of the current state of the online table.
        """
        return pulumi.get(self, "message")

    @property
    @pulumi.getter(name="provisioningStatus")
    def provisioning_status(self) -> Optional['outputs.OnlineTableStatusProvisioningStatus']:
        return pulumi.get(self, "provisioning_status")

    @property
    @pulumi.getter(name="triggeredUpdateStatus")
    def triggered_update_status(self) -> Optional['outputs.OnlineTableStatusTriggeredUpdateStatus']:
        return pulumi.get(self, "triggered_update_status")


@pulumi.output_type
class OnlineTableStatusContinuousUpdateStatus(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "initialPipelineSyncProgress":
            suggest = "initial_pipeline_sync_progress"
        elif key == "lastProcessedCommitVersion":
            suggest = "last_processed_commit_version"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in OnlineTableStatusContinuousUpdateStatus. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        OnlineTableStatusContinuousUpdateStatus.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        OnlineTableStatusContinuousUpdateStatus.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 initial_pipeline_sync_progress: Optional['outputs.OnlineTableStatusContinuousUpdateStatusInitialPipelineSyncProgress'] = None,
                 last_processed_commit_version: Optional[int] = None,
                 timestamp: Optional[str] = None):
        if initial_pipeline_sync_progress is not None:
            pulumi.set(__self__, "initial_pipeline_sync_progress", initial_pipeline_sync_progress)
        if last_processed_commit_version is not None:
            pulumi.set(__self__, "last_processed_commit_version", last_processed_commit_version)
        if timestamp is not None:
            pulumi.set(__self__, "timestamp", timestamp)

    @property
    @pulumi.getter(name="initialPipelineSyncProgress")
    def initial_pipeline_sync_progress(self) -> Optional['outputs.OnlineTableStatusContinuousUpdateStatusInitialPipelineSyncProgress']:
        return pulumi.get(self, "initial_pipeline_sync_progress")

    @property
    @pulumi.getter(name="lastProcessedCommitVersion")
    def last_processed_commit_version(self) -> Optional[int]:
        return pulumi.get(self, "last_processed_commit_version")

    @property
    @pulumi.getter
    def timestamp(self) -> Optional[str]:
        return pulumi.get(self, "timestamp")


@pulumi.output_type
class OnlineTableStatusContinuousUpdateStatusInitialPipelineSyncProgress(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "estimatedCompletionTimeSeconds":
            suggest = "estimated_completion_time_seconds"
        elif key == "latestVersionCurrentlyProcessing":
            suggest = "latest_version_currently_processing"
        elif key == "syncProgressCompletion":
            suggest = "sync_progress_completion"
        elif key == "syncedRowCount":
            suggest = "synced_row_count"
        elif key == "totalRowCount":
            suggest = "total_row_count"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in OnlineTableStatusContinuousUpdateStatusInitialPipelineSyncProgress. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        OnlineTableStatusContinuousUpdateStatusInitialPipelineSyncProgress.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        OnlineTableStatusContinuousUpdateStatusInitialPipelineSyncProgress.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 estimated_completion_time_seconds: Optional[float] = None,
                 latest_version_currently_processing: Optional[int] = None,
                 sync_progress_completion: Optional[float] = None,
                 synced_row_count: Optional[int] = None,
                 total_row_count: Optional[int] = None):
        if estimated_completion_time_seconds is not None:
            pulumi.set(__self__, "estimated_completion_time_seconds", estimated_completion_time_seconds)
        if latest_version_currently_processing is not None:
            pulumi.set(__self__, "latest_version_currently_processing", latest_version_currently_processing)
        if sync_progress_completion is not None:
            pulumi.set(__self__, "sync_progress_completion", sync_progress_completion)
        if synced_row_count is not None:
            pulumi.set(__self__, "synced_row_count", synced_row_count)
        if total_row_count is not None:
            pulumi.set(__self__, "total_row_count", total_row_count)

    @property
    @pulumi.getter(name="estimatedCompletionTimeSeconds")
    def estimated_completion_time_seconds(self) -> Optional[float]:
        return pulumi.get(self, "estimated_completion_time_seconds")

    @property
    @pulumi.getter(name="latestVersionCurrentlyProcessing")
    def latest_version_currently_processing(self) -> Optional[int]:
        return pulumi.get(self, "latest_version_currently_processing")

    @property
    @pulumi.getter(name="syncProgressCompletion")
    def sync_progress_completion(self) -> Optional[float]:
        return pulumi.get(self, "sync_progress_completion")

    @property
    @pulumi.getter(name="syncedRowCount")
    def synced_row_count(self) -> Optional[int]:
        return pulumi.get(self, "synced_row_count")

    @property
    @pulumi.getter(name="totalRowCount")
    def total_row_count(self) -> Optional[int]:
        return pulumi.get(self, "total_row_count")


@pulumi.output_type
class OnlineTableStatusFailedStatus(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "lastProcessedCommitVersion":
            suggest = "last_processed_commit_version"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in OnlineTableStatusFailedStatus. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        OnlineTableStatusFailedStatus.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        OnlineTableStatusFailedStatus.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 last_processed_commit_version: Optional[int] = None,
                 timestamp: Optional[str] = None):
        if last_processed_commit_version is not None:
            pulumi.set(__self__, "last_processed_commit_version", last_processed_commit_version)
        if timestamp is not None:
            pulumi.set(__self__, "timestamp", timestamp)

    @property
    @pulumi.getter(name="lastProcessedCommitVersion")
    def last_processed_commit_version(self) -> Optional[int]:
        return pulumi.get(self, "last_processed_commit_version")

    @property
    @pulumi.getter
    def timestamp(self) -> Optional[str]:
        return pulumi.get(self, "timestamp")


@pulumi.output_type
class OnlineTableStatusProvisioningStatus(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "initialPipelineSyncProgress":
            suggest = "initial_pipeline_sync_progress"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in OnlineTableStatusProvisioningStatus. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        OnlineTableStatusProvisioningStatus.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        OnlineTableStatusProvisioningStatus.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 initial_pipeline_sync_progress: Optional['outputs.OnlineTableStatusProvisioningStatusInitialPipelineSyncProgress'] = None):
        if initial_pipeline_sync_progress is not None:
            pulumi.set(__self__, "initial_pipeline_sync_progress", initial_pipeline_sync_progress)

    @property
    @pulumi.getter(name="initialPipelineSyncProgress")
    def initial_pipeline_sync_progress(self) -> Optional['outputs.OnlineTableStatusProvisioningStatusInitialPipelineSyncProgress']:
        return pulumi.get(self, "initial_pipeline_sync_progress")


@pulumi.output_type
class OnlineTableStatusProvisioningStatusInitialPipelineSyncProgress(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "estimatedCompletionTimeSeconds":
            suggest = "estimated_completion_time_seconds"
        elif key == "latestVersionCurrentlyProcessing":
            suggest = "latest_version_currently_processing"
        elif key == "syncProgressCompletion":
            suggest = "sync_progress_completion"
        elif key == "syncedRowCount":
            suggest = "synced_row_count"
        elif key == "totalRowCount":
            suggest = "total_row_count"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in OnlineTableStatusProvisioningStatusInitialPipelineSyncProgress. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        OnlineTableStatusProvisioningStatusInitialPipelineSyncProgress.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        OnlineTableStatusProvisioningStatusInitialPipelineSyncProgress.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 estimated_completion_time_seconds: Optional[float] = None,
                 latest_version_currently_processing: Optional[int] = None,
                 sync_progress_completion: Optional[float] = None,
                 synced_row_count: Optional[int] = None,
                 total_row_count: Optional[int] = None):
        if estimated_completion_time_seconds is not None:
            pulumi.set(__self__, "estimated_completion_time_seconds", estimated_completion_time_seconds)
        if latest_version_currently_processing is not None:
            pulumi.set(__self__, "latest_version_currently_processing", latest_version_currently_processing)
        if sync_progress_completion is not None:
            pulumi.set(__self__, "sync_progress_completion", sync_progress_completion)
        if synced_row_count is not None:
            pulumi.set(__self__, "synced_row_count", synced_row_count)
        if total_row_count is not None:
            pulumi.set(__self__, "total_row_count", total_row_count)

    @property
    @pulumi.getter(name="estimatedCompletionTimeSeconds")
    def estimated_completion_time_seconds(self) -> Optional[float]:
        return pulumi.get(self, "estimated_completion_time_seconds")

    @property
    @pulumi.getter(name="latestVersionCurrentlyProcessing")
    def latest_version_currently_processing(self) -> Optional[int]:
        return pulumi.get(self, "latest_version_currently_processing")

    @property
    @pulumi.getter(name="syncProgressCompletion")
    def sync_progress_completion(self) -> Optional[float]:
        return pulumi.get(self, "sync_progress_completion")

    @property
    @pulumi.getter(name="syncedRowCount")
    def synced_row_count(self) -> Optional[int]:
        return pulumi.get(self, "synced_row_count")

    @property
    @pulumi.getter(name="totalRowCount")
    def total_row_count(self) -> Optional[int]:
        return pulumi.get(self, "total_row_count")


@pulumi.output_type
class OnlineTableStatusTriggeredUpdateStatus(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "lastProcessedCommitVersion":
            suggest = "last_processed_commit_version"
        elif key == "triggeredUpdateProgress":
            suggest = "triggered_update_progress"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in OnlineTableStatusTriggeredUpdateStatus. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        OnlineTableStatusTriggeredUpdateStatus.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        OnlineTableStatusTriggeredUpdateStatus.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 last_processed_commit_version: Optional[int] = None,
                 timestamp: Optional[str] = None,
                 triggered_update_progress: Optional['outputs.OnlineTableStatusTriggeredUpdateStatusTriggeredUpdateProgress'] = None):
        if last_processed_commit_version is not None:
            pulumi.set(__self__, "last_processed_commit_version", last_processed_commit_version)
        if timestamp is not None:
            pulumi.set(__self__, "timestamp", timestamp)
        if triggered_update_progress is not None:
            pulumi.set(__self__, "triggered_update_progress", triggered_update_progress)

    @property
    @pulumi.getter(name="lastProcessedCommitVersion")
    def last_processed_commit_version(self) -> Optional[int]:
        return pulumi.get(self, "last_processed_commit_version")

    @property
    @pulumi.getter
    def timestamp(self) -> Optional[str]:
        return pulumi.get(self, "timestamp")

    @property
    @pulumi.getter(name="triggeredUpdateProgress")
    def triggered_update_progress(self) -> Optional['outputs.OnlineTableStatusTriggeredUpdateStatusTriggeredUpdateProgress']:
        return pulumi.get(self, "triggered_update_progress")


@pulumi.output_type
class OnlineTableStatusTriggeredUpdateStatusTriggeredUpdateProgress(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "estimatedCompletionTimeSeconds":
            suggest = "estimated_completion_time_seconds"
        elif key == "latestVersionCurrentlyProcessing":
            suggest = "latest_version_currently_processing"
        elif key == "syncProgressCompletion":
            suggest = "sync_progress_completion"
        elif key == "syncedRowCount":
            suggest = "synced_row_count"
        elif key == "totalRowCount":
            suggest = "total_row_count"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in OnlineTableStatusTriggeredUpdateStatusTriggeredUpdateProgress. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        OnlineTableStatusTriggeredUpdateStatusTriggeredUpdateProgress.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        OnlineTableStatusTriggeredUpdateStatusTriggeredUpdateProgress.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 estimated_completion_time_seconds: Optional[float] = None,
                 latest_version_currently_processing: Optional[int] = None,
                 sync_progress_completion: Optional[float] = None,
                 synced_row_count: Optional[int] = None,
                 total_row_count: Optional[int] = None):
        if estimated_completion_time_seconds is not None:
            pulumi.set(__self__, "estimated_completion_time_seconds", estimated_completion_time_seconds)
        if latest_version_currently_processing is not None:
            pulumi.set(__self__, "latest_version_currently_processing", latest_version_currently_processing)
        if sync_progress_completion is not None:
            pulumi.set(__self__, "sync_progress_completion", sync_progress_completion)
        if synced_row_count is not None:
            pulumi.set(__self__, "synced_row_count", synced_row_count)
        if total_row_count is not None:
            pulumi.set(__self__, "total_row_count", total_row_count)

    @property
    @pulumi.getter(name="estimatedCompletionTimeSeconds")
    def estimated_completion_time_seconds(self) -> Optional[float]:
        return pulumi.get(self, "estimated_completion_time_seconds")

    @property
    @pulumi.getter(name="latestVersionCurrentlyProcessing")
    def latest_version_currently_processing(self) -> Optional[int]:
        return pulumi.get(self, "latest_version_currently_processing")

    @property
    @pulumi.getter(name="syncProgressCompletion")
    def sync_progress_completion(self) -> Optional[float]:
        return pulumi.get(self, "sync_progress_completion")

    @property
    @pulumi.getter(name="syncedRowCount")
    def synced_row_count(self) -> Optional[int]:
        return pulumi.get(self, "synced_row_count")

    @property
    @pulumi.getter(name="totalRowCount")
    def total_row_count(self) -> Optional[int]:
        return pulumi.get(self, "total_row_count")


@pulumi.output_type
class PermissionsAccessControl(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "permissionLevel":
            suggest = "permission_level"
        elif key == "groupName":
            suggest = "group_name"
        elif key == "servicePrincipalName":
            suggest = "service_principal_name"
        elif key == "userName":
            suggest = "user_name"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in PermissionsAccessControl. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        PermissionsAccessControl.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        PermissionsAccessControl.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 permission_level: str,
                 group_name: Optional[str] = None,
                 service_principal_name: Optional[str] = None,
                 user_name: Optional[str] = None):
        """
        :param str permission_level: permission level according to specific resource. See examples above for the reference.
               
               Exactly one of the below arguments is required:
        :param str group_name: name of the group. We recommend setting permissions on groups.
        :param str service_principal_name: Application ID of the service_principal.
        :param str user_name: name of the user.
        """
        pulumi.set(__self__, "permission_level", permission_level)
        if group_name is not None:
            pulumi.set(__self__, "group_name", group_name)
        if service_principal_name is not None:
            pulumi.set(__self__, "service_principal_name", service_principal_name)
        if user_name is not None:
            pulumi.set(__self__, "user_name", user_name)

    @property
    @pulumi.getter(name="permissionLevel")
    def permission_level(self) -> str:
        """
        permission level according to specific resource. See examples above for the reference.

        Exactly one of the below arguments is required:
        """
        return pulumi.get(self, "permission_level")

    @property
    @pulumi.getter(name="groupName")
    def group_name(self) -> Optional[str]:
        """
        name of the group. We recommend setting permissions on groups.
        """
        return pulumi.get(self, "group_name")

    @property
    @pulumi.getter(name="servicePrincipalName")
    def service_principal_name(self) -> Optional[str]:
        """
        Application ID of the service_principal.
        """
        return pulumi.get(self, "service_principal_name")

    @property
    @pulumi.getter(name="userName")
    def user_name(self) -> Optional[str]:
        """
        name of the user.
        """
        return pulumi.get(self, "user_name")


@pulumi.output_type
class PipelineCluster(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "applyPolicyDefaultValues":
            suggest = "apply_policy_default_values"
        elif key == "awsAttributes":
            suggest = "aws_attributes"
        elif key == "azureAttributes":
            suggest = "azure_attributes"
        elif key == "clusterLogConf":
            suggest = "cluster_log_conf"
        elif key == "customTags":
            suggest = "custom_tags"
        elif key == "driverInstancePoolId":
            suggest = "driver_instance_pool_id"
        elif key == "driverNodeTypeId":
            suggest = "driver_node_type_id"
        elif key == "enableLocalDiskEncryption":
            suggest = "enable_local_disk_encryption"
        elif key == "gcpAttributes":
            suggest = "gcp_attributes"
        elif key == "initScripts":
            suggest = "init_scripts"
        elif key == "instancePoolId":
            suggest = "instance_pool_id"
        elif key == "nodeTypeId":
            suggest = "node_type_id"
        elif key == "numWorkers":
            suggest = "num_workers"
        elif key == "policyId":
            suggest = "policy_id"
        elif key == "sparkConf":
            suggest = "spark_conf"
        elif key == "sparkEnvVars":
            suggest = "spark_env_vars"
        elif key == "sshPublicKeys":
            suggest = "ssh_public_keys"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in PipelineCluster. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        PipelineCluster.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        PipelineCluster.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 apply_policy_default_values: Optional[bool] = None,
                 autoscale: Optional['outputs.PipelineClusterAutoscale'] = None,
                 aws_attributes: Optional['outputs.PipelineClusterAwsAttributes'] = None,
                 azure_attributes: Optional['outputs.PipelineClusterAzureAttributes'] = None,
                 cluster_log_conf: Optional['outputs.PipelineClusterClusterLogConf'] = None,
                 custom_tags: Optional[Mapping[str, str]] = None,
                 driver_instance_pool_id: Optional[str] = None,
                 driver_node_type_id: Optional[str] = None,
                 enable_local_disk_encryption: Optional[bool] = None,
                 gcp_attributes: Optional['outputs.PipelineClusterGcpAttributes'] = None,
                 init_scripts: Optional[Sequence['outputs.PipelineClusterInitScript']] = None,
                 instance_pool_id: Optional[str] = None,
                 label: Optional[str] = None,
                 node_type_id: Optional[str] = None,
                 num_workers: Optional[int] = None,
                 policy_id: Optional[str] = None,
                 spark_conf: Optional[Mapping[str, str]] = None,
                 spark_env_vars: Optional[Mapping[str, str]] = None,
                 ssh_public_keys: Optional[Sequence[str]] = None):
        if apply_policy_default_values is not None:
            pulumi.set(__self__, "apply_policy_default_values", apply_policy_default_values)
        if autoscale is not None:
            pulumi.set(__self__, "autoscale", autoscale)
        if aws_attributes is not None:
            pulumi.set(__self__, "aws_attributes", aws_attributes)
        if azure_attributes is not None:
            pulumi.set(__self__, "azure_attributes", azure_attributes)
        if cluster_log_conf is not None:
            pulumi.set(__self__, "cluster_log_conf", cluster_log_conf)
        if custom_tags is not None:
            pulumi.set(__self__, "custom_tags", custom_tags)
        if driver_instance_pool_id is not None:
            pulumi.set(__self__, "driver_instance_pool_id", driver_instance_pool_id)
        if driver_node_type_id is not None:
            pulumi.set(__self__, "driver_node_type_id", driver_node_type_id)
        if enable_local_disk_encryption is not None:
            pulumi.set(__self__, "enable_local_disk_encryption", enable_local_disk_encryption)
        if gcp_attributes is not None:
            pulumi.set(__self__, "gcp_attributes", gcp_attributes)
        if init_scripts is not None:
            pulumi.set(__self__, "init_scripts", init_scripts)
        if instance_pool_id is not None:
            pulumi.set(__self__, "instance_pool_id", instance_pool_id)
        if label is not None:
            pulumi.set(__self__, "label", label)
        if node_type_id is not None:
            pulumi.set(__self__, "node_type_id", node_type_id)
        if num_workers is not None:
            pulumi.set(__self__, "num_workers", num_workers)
        if policy_id is not None:
            pulumi.set(__self__, "policy_id", policy_id)
        if spark_conf is not None:
            pulumi.set(__self__, "spark_conf", spark_conf)
        if spark_env_vars is not None:
            pulumi.set(__self__, "spark_env_vars", spark_env_vars)
        if ssh_public_keys is not None:
            pulumi.set(__self__, "ssh_public_keys", ssh_public_keys)

    @property
    @pulumi.getter(name="applyPolicyDefaultValues")
    def apply_policy_default_values(self) -> Optional[bool]:
        return pulumi.get(self, "apply_policy_default_values")

    @property
    @pulumi.getter
    def autoscale(self) -> Optional['outputs.PipelineClusterAutoscale']:
        return pulumi.get(self, "autoscale")

    @property
    @pulumi.getter(name="awsAttributes")
    def aws_attributes(self) -> Optional['outputs.PipelineClusterAwsAttributes']:
        return pulumi.get(self, "aws_attributes")

    @property
    @pulumi.getter(name="azureAttributes")
    def azure_attributes(self) -> Optional['outputs.PipelineClusterAzureAttributes']:
        return pulumi.get(self, "azure_attributes")

    @property
    @pulumi.getter(name="clusterLogConf")
    def cluster_log_conf(self) -> Optional['outputs.PipelineClusterClusterLogConf']:
        return pulumi.get(self, "cluster_log_conf")

    @property
    @pulumi.getter(name="customTags")
    def custom_tags(self) -> Optional[Mapping[str, str]]:
        return pulumi.get(self, "custom_tags")

    @property
    @pulumi.getter(name="driverInstancePoolId")
    def driver_instance_pool_id(self) -> Optional[str]:
        return pulumi.get(self, "driver_instance_pool_id")

    @property
    @pulumi.getter(name="driverNodeTypeId")
    def driver_node_type_id(self) -> Optional[str]:
        return pulumi.get(self, "driver_node_type_id")

    @property
    @pulumi.getter(name="enableLocalDiskEncryption")
    def enable_local_disk_encryption(self) -> Optional[bool]:
        return pulumi.get(self, "enable_local_disk_encryption")

    @property
    @pulumi.getter(name="gcpAttributes")
    def gcp_attributes(self) -> Optional['outputs.PipelineClusterGcpAttributes']:
        return pulumi.get(self, "gcp_attributes")

    @property
    @pulumi.getter(name="initScripts")
    def init_scripts(self) -> Optional[Sequence['outputs.PipelineClusterInitScript']]:
        return pulumi.get(self, "init_scripts")

    @property
    @pulumi.getter(name="instancePoolId")
    def instance_pool_id(self) -> Optional[str]:
        return pulumi.get(self, "instance_pool_id")

    @property
    @pulumi.getter
    def label(self) -> Optional[str]:
        return pulumi.get(self, "label")

    @property
    @pulumi.getter(name="nodeTypeId")
    def node_type_id(self) -> Optional[str]:
        return pulumi.get(self, "node_type_id")

    @property
    @pulumi.getter(name="numWorkers")
    def num_workers(self) -> Optional[int]:
        return pulumi.get(self, "num_workers")

    @property
    @pulumi.getter(name="policyId")
    def policy_id(self) -> Optional[str]:
        return pulumi.get(self, "policy_id")

    @property
    @pulumi.getter(name="sparkConf")
    def spark_conf(self) -> Optional[Mapping[str, str]]:
        return pulumi.get(self, "spark_conf")

    @property
    @pulumi.getter(name="sparkEnvVars")
    def spark_env_vars(self) -> Optional[Mapping[str, str]]:
        return pulumi.get(self, "spark_env_vars")

    @property
    @pulumi.getter(name="sshPublicKeys")
    def ssh_public_keys(self) -> Optional[Sequence[str]]:
        return pulumi.get(self, "ssh_public_keys")


@pulumi.output_type
class PipelineClusterAutoscale(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "maxWorkers":
            suggest = "max_workers"
        elif key == "minWorkers":
            suggest = "min_workers"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in PipelineClusterAutoscale. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        PipelineClusterAutoscale.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        PipelineClusterAutoscale.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 max_workers: int,
                 min_workers: int,
                 mode: Optional[str] = None):
        pulumi.set(__self__, "max_workers", max_workers)
        pulumi.set(__self__, "min_workers", min_workers)
        if mode is not None:
            pulumi.set(__self__, "mode", mode)

    @property
    @pulumi.getter(name="maxWorkers")
    def max_workers(self) -> int:
        return pulumi.get(self, "max_workers")

    @property
    @pulumi.getter(name="minWorkers")
    def min_workers(self) -> int:
        return pulumi.get(self, "min_workers")

    @property
    @pulumi.getter
    def mode(self) -> Optional[str]:
        return pulumi.get(self, "mode")


@pulumi.output_type
class PipelineClusterAwsAttributes(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "ebsVolumeCount":
            suggest = "ebs_volume_count"
        elif key == "ebsVolumeIops":
            suggest = "ebs_volume_iops"
        elif key == "ebsVolumeSize":
            suggest = "ebs_volume_size"
        elif key == "ebsVolumeThroughput":
            suggest = "ebs_volume_throughput"
        elif key == "ebsVolumeType":
            suggest = "ebs_volume_type"
        elif key == "firstOnDemand":
            suggest = "first_on_demand"
        elif key == "instanceProfileArn":
            suggest = "instance_profile_arn"
        elif key == "spotBidPricePercent":
            suggest = "spot_bid_price_percent"
        elif key == "zoneId":
            suggest = "zone_id"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in PipelineClusterAwsAttributes. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        PipelineClusterAwsAttributes.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        PipelineClusterAwsAttributes.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 availability: Optional[str] = None,
                 ebs_volume_count: Optional[int] = None,
                 ebs_volume_iops: Optional[int] = None,
                 ebs_volume_size: Optional[int] = None,
                 ebs_volume_throughput: Optional[int] = None,
                 ebs_volume_type: Optional[str] = None,
                 first_on_demand: Optional[int] = None,
                 instance_profile_arn: Optional[str] = None,
                 spot_bid_price_percent: Optional[int] = None,
                 zone_id: Optional[str] = None):
        if availability is not None:
            pulumi.set(__self__, "availability", availability)
        if ebs_volume_count is not None:
            pulumi.set(__self__, "ebs_volume_count", ebs_volume_count)
        if ebs_volume_iops is not None:
            pulumi.set(__self__, "ebs_volume_iops", ebs_volume_iops)
        if ebs_volume_size is not None:
            pulumi.set(__self__, "ebs_volume_size", ebs_volume_size)
        if ebs_volume_throughput is not None:
            pulumi.set(__self__, "ebs_volume_throughput", ebs_volume_throughput)
        if ebs_volume_type is not None:
            pulumi.set(__self__, "ebs_volume_type", ebs_volume_type)
        if first_on_demand is not None:
            pulumi.set(__self__, "first_on_demand", first_on_demand)
        if instance_profile_arn is not None:
            pulumi.set(__self__, "instance_profile_arn", instance_profile_arn)
        if spot_bid_price_percent is not None:
            pulumi.set(__self__, "spot_bid_price_percent", spot_bid_price_percent)
        if zone_id is not None:
            pulumi.set(__self__, "zone_id", zone_id)

    @property
    @pulumi.getter
    def availability(self) -> Optional[str]:
        return pulumi.get(self, "availability")

    @property
    @pulumi.getter(name="ebsVolumeCount")
    def ebs_volume_count(self) -> Optional[int]:
        return pulumi.get(self, "ebs_volume_count")

    @property
    @pulumi.getter(name="ebsVolumeIops")
    def ebs_volume_iops(self) -> Optional[int]:
        return pulumi.get(self, "ebs_volume_iops")

    @property
    @pulumi.getter(name="ebsVolumeSize")
    def ebs_volume_size(self) -> Optional[int]:
        return pulumi.get(self, "ebs_volume_size")

    @property
    @pulumi.getter(name="ebsVolumeThroughput")
    def ebs_volume_throughput(self) -> Optional[int]:
        return pulumi.get(self, "ebs_volume_throughput")

    @property
    @pulumi.getter(name="ebsVolumeType")
    def ebs_volume_type(self) -> Optional[str]:
        return pulumi.get(self, "ebs_volume_type")

    @property
    @pulumi.getter(name="firstOnDemand")
    def first_on_demand(self) -> Optional[int]:
        return pulumi.get(self, "first_on_demand")

    @property
    @pulumi.getter(name="instanceProfileArn")
    def instance_profile_arn(self) -> Optional[str]:
        return pulumi.get(self, "instance_profile_arn")

    @property
    @pulumi.getter(name="spotBidPricePercent")
    def spot_bid_price_percent(self) -> Optional[int]:
        return pulumi.get(self, "spot_bid_price_percent")

    @property
    @pulumi.getter(name="zoneId")
    def zone_id(self) -> Optional[str]:
        return pulumi.get(self, "zone_id")


@pulumi.output_type
class PipelineClusterAzureAttributes(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "firstOnDemand":
            suggest = "first_on_demand"
        elif key == "logAnalyticsInfo":
            suggest = "log_analytics_info"
        elif key == "spotBidMaxPrice":
            suggest = "spot_bid_max_price"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in PipelineClusterAzureAttributes. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        PipelineClusterAzureAttributes.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        PipelineClusterAzureAttributes.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 availability: Optional[str] = None,
                 first_on_demand: Optional[int] = None,
                 log_analytics_info: Optional['outputs.PipelineClusterAzureAttributesLogAnalyticsInfo'] = None,
                 spot_bid_max_price: Optional[float] = None):
        if availability is not None:
            pulumi.set(__self__, "availability", availability)
        if first_on_demand is not None:
            pulumi.set(__self__, "first_on_demand", first_on_demand)
        if log_analytics_info is not None:
            pulumi.set(__self__, "log_analytics_info", log_analytics_info)
        if spot_bid_max_price is not None:
            pulumi.set(__self__, "spot_bid_max_price", spot_bid_max_price)

    @property
    @pulumi.getter
    def availability(self) -> Optional[str]:
        return pulumi.get(self, "availability")

    @property
    @pulumi.getter(name="firstOnDemand")
    def first_on_demand(self) -> Optional[int]:
        return pulumi.get(self, "first_on_demand")

    @property
    @pulumi.getter(name="logAnalyticsInfo")
    def log_analytics_info(self) -> Optional['outputs.PipelineClusterAzureAttributesLogAnalyticsInfo']:
        return pulumi.get(self, "log_analytics_info")

    @property
    @pulumi.getter(name="spotBidMaxPrice")
    def spot_bid_max_price(self) -> Optional[float]:
        return pulumi.get(self, "spot_bid_max_price")


@pulumi.output_type
class PipelineClusterAzureAttributesLogAnalyticsInfo(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "logAnalyticsPrimaryKey":
            suggest = "log_analytics_primary_key"
        elif key == "logAnalyticsWorkspaceId":
            suggest = "log_analytics_workspace_id"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in PipelineClusterAzureAttributesLogAnalyticsInfo. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        PipelineClusterAzureAttributesLogAnalyticsInfo.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        PipelineClusterAzureAttributesLogAnalyticsInfo.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 log_analytics_primary_key: Optional[str] = None,
                 log_analytics_workspace_id: Optional[str] = None):
        if log_analytics_primary_key is not None:
            pulumi.set(__self__, "log_analytics_primary_key", log_analytics_primary_key)
        if log_analytics_workspace_id is not None:
            pulumi.set(__self__, "log_analytics_workspace_id", log_analytics_workspace_id)

    @property
    @pulumi.getter(name="logAnalyticsPrimaryKey")
    def log_analytics_primary_key(self) -> Optional[str]:
        return pulumi.get(self, "log_analytics_primary_key")

    @property
    @pulumi.getter(name="logAnalyticsWorkspaceId")
    def log_analytics_workspace_id(self) -> Optional[str]:
        return pulumi.get(self, "log_analytics_workspace_id")


@pulumi.output_type
class PipelineClusterClusterLogConf(dict):
    def __init__(__self__, *,
                 dbfs: Optional['outputs.PipelineClusterClusterLogConfDbfs'] = None,
                 s3: Optional['outputs.PipelineClusterClusterLogConfS3'] = None):
        if dbfs is not None:
            pulumi.set(__self__, "dbfs", dbfs)
        if s3 is not None:
            pulumi.set(__self__, "s3", s3)

    @property
    @pulumi.getter
    def dbfs(self) -> Optional['outputs.PipelineClusterClusterLogConfDbfs']:
        return pulumi.get(self, "dbfs")

    @property
    @pulumi.getter
    def s3(self) -> Optional['outputs.PipelineClusterClusterLogConfS3']:
        return pulumi.get(self, "s3")


@pulumi.output_type
class PipelineClusterClusterLogConfDbfs(dict):
    def __init__(__self__, *,
                 destination: str):
        pulumi.set(__self__, "destination", destination)

    @property
    @pulumi.getter
    def destination(self) -> str:
        return pulumi.get(self, "destination")


@pulumi.output_type
class PipelineClusterClusterLogConfS3(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "cannedAcl":
            suggest = "canned_acl"
        elif key == "enableEncryption":
            suggest = "enable_encryption"
        elif key == "encryptionType":
            suggest = "encryption_type"
        elif key == "kmsKey":
            suggest = "kms_key"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in PipelineClusterClusterLogConfS3. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        PipelineClusterClusterLogConfS3.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        PipelineClusterClusterLogConfS3.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 destination: str,
                 canned_acl: Optional[str] = None,
                 enable_encryption: Optional[bool] = None,
                 encryption_type: Optional[str] = None,
                 endpoint: Optional[str] = None,
                 kms_key: Optional[str] = None,
                 region: Optional[str] = None):
        pulumi.set(__self__, "destination", destination)
        if canned_acl is not None:
            pulumi.set(__self__, "canned_acl", canned_acl)
        if enable_encryption is not None:
            pulumi.set(__self__, "enable_encryption", enable_encryption)
        if encryption_type is not None:
            pulumi.set(__self__, "encryption_type", encryption_type)
        if endpoint is not None:
            pulumi.set(__self__, "endpoint", endpoint)
        if kms_key is not None:
            pulumi.set(__self__, "kms_key", kms_key)
        if region is not None:
            pulumi.set(__self__, "region", region)

    @property
    @pulumi.getter
    def destination(self) -> str:
        return pulumi.get(self, "destination")

    @property
    @pulumi.getter(name="cannedAcl")
    def canned_acl(self) -> Optional[str]:
        return pulumi.get(self, "canned_acl")

    @property
    @pulumi.getter(name="enableEncryption")
    def enable_encryption(self) -> Optional[bool]:
        return pulumi.get(self, "enable_encryption")

    @property
    @pulumi.getter(name="encryptionType")
    def encryption_type(self) -> Optional[str]:
        return pulumi.get(self, "encryption_type")

    @property
    @pulumi.getter
    def endpoint(self) -> Optional[str]:
        return pulumi.get(self, "endpoint")

    @property
    @pulumi.getter(name="kmsKey")
    def kms_key(self) -> Optional[str]:
        return pulumi.get(self, "kms_key")

    @property
    @pulumi.getter
    def region(self) -> Optional[str]:
        return pulumi.get(self, "region")


@pulumi.output_type
class PipelineClusterGcpAttributes(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "googleServiceAccount":
            suggest = "google_service_account"
        elif key == "localSsdCount":
            suggest = "local_ssd_count"
        elif key == "zoneId":
            suggest = "zone_id"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in PipelineClusterGcpAttributes. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        PipelineClusterGcpAttributes.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        PipelineClusterGcpAttributes.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 availability: Optional[str] = None,
                 google_service_account: Optional[str] = None,
                 local_ssd_count: Optional[int] = None,
                 zone_id: Optional[str] = None):
        if availability is not None:
            pulumi.set(__self__, "availability", availability)
        if google_service_account is not None:
            pulumi.set(__self__, "google_service_account", google_service_account)
        if local_ssd_count is not None:
            pulumi.set(__self__, "local_ssd_count", local_ssd_count)
        if zone_id is not None:
            pulumi.set(__self__, "zone_id", zone_id)

    @property
    @pulumi.getter
    def availability(self) -> Optional[str]:
        return pulumi.get(self, "availability")

    @property
    @pulumi.getter(name="googleServiceAccount")
    def google_service_account(self) -> Optional[str]:
        return pulumi.get(self, "google_service_account")

    @property
    @pulumi.getter(name="localSsdCount")
    def local_ssd_count(self) -> Optional[int]:
        return pulumi.get(self, "local_ssd_count")

    @property
    @pulumi.getter(name="zoneId")
    def zone_id(self) -> Optional[str]:
        return pulumi.get(self, "zone_id")


@pulumi.output_type
class PipelineClusterInitScript(dict):
    def __init__(__self__, *,
                 abfss: Optional['outputs.PipelineClusterInitScriptAbfss'] = None,
                 dbfs: Optional['outputs.PipelineClusterInitScriptDbfs'] = None,
                 file: Optional['outputs.PipelineClusterInitScriptFile'] = None,
                 gcs: Optional['outputs.PipelineClusterInitScriptGcs'] = None,
                 s3: Optional['outputs.PipelineClusterInitScriptS3'] = None,
                 volumes: Optional['outputs.PipelineClusterInitScriptVolumes'] = None,
                 workspace: Optional['outputs.PipelineClusterInitScriptWorkspace'] = None):
        if abfss is not None:
            pulumi.set(__self__, "abfss", abfss)
        if dbfs is not None:
            pulumi.set(__self__, "dbfs", dbfs)
        if file is not None:
            pulumi.set(__self__, "file", file)
        if gcs is not None:
            pulumi.set(__self__, "gcs", gcs)
        if s3 is not None:
            pulumi.set(__self__, "s3", s3)
        if volumes is not None:
            pulumi.set(__self__, "volumes", volumes)
        if workspace is not None:
            pulumi.set(__self__, "workspace", workspace)

    @property
    @pulumi.getter
    def abfss(self) -> Optional['outputs.PipelineClusterInitScriptAbfss']:
        return pulumi.get(self, "abfss")

    @property
    @pulumi.getter
    @_utilities.deprecated("""For init scripts use 'volumes', 'workspace' or cloud storage location instead of 'dbfs'.""")
    def dbfs(self) -> Optional['outputs.PipelineClusterInitScriptDbfs']:
        return pulumi.get(self, "dbfs")

    @property
    @pulumi.getter
    def file(self) -> Optional['outputs.PipelineClusterInitScriptFile']:
        return pulumi.get(self, "file")

    @property
    @pulumi.getter
    def gcs(self) -> Optional['outputs.PipelineClusterInitScriptGcs']:
        return pulumi.get(self, "gcs")

    @property
    @pulumi.getter
    def s3(self) -> Optional['outputs.PipelineClusterInitScriptS3']:
        return pulumi.get(self, "s3")

    @property
    @pulumi.getter
    def volumes(self) -> Optional['outputs.PipelineClusterInitScriptVolumes']:
        return pulumi.get(self, "volumes")

    @property
    @pulumi.getter
    def workspace(self) -> Optional['outputs.PipelineClusterInitScriptWorkspace']:
        return pulumi.get(self, "workspace")


@pulumi.output_type
class PipelineClusterInitScriptAbfss(dict):
    def __init__(__self__, *,
                 destination: str):
        pulumi.set(__self__, "destination", destination)

    @property
    @pulumi.getter
    def destination(self) -> str:
        return pulumi.get(self, "destination")


@pulumi.output_type
class PipelineClusterInitScriptDbfs(dict):
    def __init__(__self__, *,
                 destination: str):
        pulumi.set(__self__, "destination", destination)

    @property
    @pulumi.getter
    def destination(self) -> str:
        return pulumi.get(self, "destination")


@pulumi.output_type
class PipelineClusterInitScriptFile(dict):
    def __init__(__self__, *,
                 destination: str):
        pulumi.set(__self__, "destination", destination)

    @property
    @pulumi.getter
    def destination(self) -> str:
        return pulumi.get(self, "destination")


@pulumi.output_type
class PipelineClusterInitScriptGcs(dict):
    def __init__(__self__, *,
                 destination: str):
        pulumi.set(__self__, "destination", destination)

    @property
    @pulumi.getter
    def destination(self) -> str:
        return pulumi.get(self, "destination")


@pulumi.output_type
class PipelineClusterInitScriptS3(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "cannedAcl":
            suggest = "canned_acl"
        elif key == "enableEncryption":
            suggest = "enable_encryption"
        elif key == "encryptionType":
            suggest = "encryption_type"
        elif key == "kmsKey":
            suggest = "kms_key"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in PipelineClusterInitScriptS3. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        PipelineClusterInitScriptS3.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        PipelineClusterInitScriptS3.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 destination: str,
                 canned_acl: Optional[str] = None,
                 enable_encryption: Optional[bool] = None,
                 encryption_type: Optional[str] = None,
                 endpoint: Optional[str] = None,
                 kms_key: Optional[str] = None,
                 region: Optional[str] = None):
        pulumi.set(__self__, "destination", destination)
        if canned_acl is not None:
            pulumi.set(__self__, "canned_acl", canned_acl)
        if enable_encryption is not None:
            pulumi.set(__self__, "enable_encryption", enable_encryption)
        if encryption_type is not None:
            pulumi.set(__self__, "encryption_type", encryption_type)
        if endpoint is not None:
            pulumi.set(__self__, "endpoint", endpoint)
        if kms_key is not None:
            pulumi.set(__self__, "kms_key", kms_key)
        if region is not None:
            pulumi.set(__self__, "region", region)

    @property
    @pulumi.getter
    def destination(self) -> str:
        return pulumi.get(self, "destination")

    @property
    @pulumi.getter(name="cannedAcl")
    def canned_acl(self) -> Optional[str]:
        return pulumi.get(self, "canned_acl")

    @property
    @pulumi.getter(name="enableEncryption")
    def enable_encryption(self) -> Optional[bool]:
        return pulumi.get(self, "enable_encryption")

    @property
    @pulumi.getter(name="encryptionType")
    def encryption_type(self) -> Optional[str]:
        return pulumi.get(self, "encryption_type")

    @property
    @pulumi.getter
    def endpoint(self) -> Optional[str]:
        return pulumi.get(self, "endpoint")

    @property
    @pulumi.getter(name="kmsKey")
    def kms_key(self) -> Optional[str]:
        return pulumi.get(self, "kms_key")

    @property
    @pulumi.getter
    def region(self) -> Optional[str]:
        return pulumi.get(self, "region")


@pulumi.output_type
class PipelineClusterInitScriptVolumes(dict):
    def __init__(__self__, *,
                 destination: str):
        pulumi.set(__self__, "destination", destination)

    @property
    @pulumi.getter
    def destination(self) -> str:
        return pulumi.get(self, "destination")


@pulumi.output_type
class PipelineClusterInitScriptWorkspace(dict):
    def __init__(__self__, *,
                 destination: str):
        pulumi.set(__self__, "destination", destination)

    @property
    @pulumi.getter
    def destination(self) -> str:
        return pulumi.get(self, "destination")


@pulumi.output_type
class PipelineDeployment(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "metadataFilePath":
            suggest = "metadata_file_path"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in PipelineDeployment. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        PipelineDeployment.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        PipelineDeployment.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 kind: Optional[str] = None,
                 metadata_file_path: Optional[str] = None):
        """
        :param str kind: The deployment method that manages the pipeline.
        :param str metadata_file_path: The path to the file containing metadata about the deployment.
        """
        if kind is not None:
            pulumi.set(__self__, "kind", kind)
        if metadata_file_path is not None:
            pulumi.set(__self__, "metadata_file_path", metadata_file_path)

    @property
    @pulumi.getter
    def kind(self) -> Optional[str]:
        """
        The deployment method that manages the pipeline.
        """
        return pulumi.get(self, "kind")

    @property
    @pulumi.getter(name="metadataFilePath")
    def metadata_file_path(self) -> Optional[str]:
        """
        The path to the file containing metadata about the deployment.
        """
        return pulumi.get(self, "metadata_file_path")


@pulumi.output_type
class PipelineFilters(dict):
    def __init__(__self__, *,
                 excludes: Optional[Sequence[str]] = None,
                 includes: Optional[Sequence[str]] = None):
        """
        :param Sequence[str] excludes: Paths to exclude.
        :param Sequence[str] includes: Paths to include.
        """
        if excludes is not None:
            pulumi.set(__self__, "excludes", excludes)
        if includes is not None:
            pulumi.set(__self__, "includes", includes)

    @property
    @pulumi.getter
    def excludes(self) -> Optional[Sequence[str]]:
        """
        Paths to exclude.
        """
        return pulumi.get(self, "excludes")

    @property
    @pulumi.getter
    def includes(self) -> Optional[Sequence[str]]:
        """
        Paths to include.
        """
        return pulumi.get(self, "includes")


@pulumi.output_type
class PipelineGatewayDefinition(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "connectionId":
            suggest = "connection_id"
        elif key == "gatewayStorageCatalog":
            suggest = "gateway_storage_catalog"
        elif key == "gatewayStorageName":
            suggest = "gateway_storage_name"
        elif key == "gatewayStorageSchema":
            suggest = "gateway_storage_schema"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in PipelineGatewayDefinition. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        PipelineGatewayDefinition.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        PipelineGatewayDefinition.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 connection_id: Optional[str] = None,
                 gateway_storage_catalog: Optional[str] = None,
                 gateway_storage_name: Optional[str] = None,
                 gateway_storage_schema: Optional[str] = None):
        """
        :param str connection_id: Immutable. The Unity Catalog connection this gateway pipeline uses to communicate with the source.
        :param str gateway_storage_catalog: Required, Immutable. The name of the catalog for the gateway pipeline's storage location.
        :param str gateway_storage_name: Required. The Unity Catalog-compatible naming for the gateway storage location. This is the destination to use for the data that is extracted by the gateway. Delta Live Tables system will automatically create the storage location under the catalog and schema.
        :param str gateway_storage_schema: Required, Immutable. The name of the schema for the gateway pipelines's storage location.
        """
        if connection_id is not None:
            pulumi.set(__self__, "connection_id", connection_id)
        if gateway_storage_catalog is not None:
            pulumi.set(__self__, "gateway_storage_catalog", gateway_storage_catalog)
        if gateway_storage_name is not None:
            pulumi.set(__self__, "gateway_storage_name", gateway_storage_name)
        if gateway_storage_schema is not None:
            pulumi.set(__self__, "gateway_storage_schema", gateway_storage_schema)

    @property
    @pulumi.getter(name="connectionId")
    def connection_id(self) -> Optional[str]:
        """
        Immutable. The Unity Catalog connection this gateway pipeline uses to communicate with the source.
        """
        return pulumi.get(self, "connection_id")

    @property
    @pulumi.getter(name="gatewayStorageCatalog")
    def gateway_storage_catalog(self) -> Optional[str]:
        """
        Required, Immutable. The name of the catalog for the gateway pipeline's storage location.
        """
        return pulumi.get(self, "gateway_storage_catalog")

    @property
    @pulumi.getter(name="gatewayStorageName")
    def gateway_storage_name(self) -> Optional[str]:
        """
        Required. The Unity Catalog-compatible naming for the gateway storage location. This is the destination to use for the data that is extracted by the gateway. Delta Live Tables system will automatically create the storage location under the catalog and schema.
        """
        return pulumi.get(self, "gateway_storage_name")

    @property
    @pulumi.getter(name="gatewayStorageSchema")
    def gateway_storage_schema(self) -> Optional[str]:
        """
        Required, Immutable. The name of the schema for the gateway pipelines's storage location.
        """
        return pulumi.get(self, "gateway_storage_schema")


@pulumi.output_type
class PipelineIngestionDefinition(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "connectionName":
            suggest = "connection_name"
        elif key == "ingestionGatewayId":
            suggest = "ingestion_gateway_id"
        elif key == "tableConfiguration":
            suggest = "table_configuration"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in PipelineIngestionDefinition. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        PipelineIngestionDefinition.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        PipelineIngestionDefinition.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 connection_name: Optional[str] = None,
                 ingestion_gateway_id: Optional[str] = None,
                 objects: Optional[Sequence['outputs.PipelineIngestionDefinitionObject']] = None,
                 table_configuration: Optional['outputs.PipelineIngestionDefinitionTableConfiguration'] = None):
        if connection_name is not None:
            pulumi.set(__self__, "connection_name", connection_name)
        if ingestion_gateway_id is not None:
            pulumi.set(__self__, "ingestion_gateway_id", ingestion_gateway_id)
        if objects is not None:
            pulumi.set(__self__, "objects", objects)
        if table_configuration is not None:
            pulumi.set(__self__, "table_configuration", table_configuration)

    @property
    @pulumi.getter(name="connectionName")
    def connection_name(self) -> Optional[str]:
        return pulumi.get(self, "connection_name")

    @property
    @pulumi.getter(name="ingestionGatewayId")
    def ingestion_gateway_id(self) -> Optional[str]:
        return pulumi.get(self, "ingestion_gateway_id")

    @property
    @pulumi.getter
    def objects(self) -> Optional[Sequence['outputs.PipelineIngestionDefinitionObject']]:
        return pulumi.get(self, "objects")

    @property
    @pulumi.getter(name="tableConfiguration")
    def table_configuration(self) -> Optional['outputs.PipelineIngestionDefinitionTableConfiguration']:
        return pulumi.get(self, "table_configuration")


@pulumi.output_type
class PipelineIngestionDefinitionObject(dict):
    def __init__(__self__, *,
                 schema: Optional['outputs.PipelineIngestionDefinitionObjectSchema'] = None,
                 table: Optional['outputs.PipelineIngestionDefinitionObjectTable'] = None):
        if schema is not None:
            pulumi.set(__self__, "schema", schema)
        if table is not None:
            pulumi.set(__self__, "table", table)

    @property
    @pulumi.getter
    def schema(self) -> Optional['outputs.PipelineIngestionDefinitionObjectSchema']:
        return pulumi.get(self, "schema")

    @property
    @pulumi.getter
    def table(self) -> Optional['outputs.PipelineIngestionDefinitionObjectTable']:
        return pulumi.get(self, "table")


@pulumi.output_type
class PipelineIngestionDefinitionObjectSchema(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "destinationCatalog":
            suggest = "destination_catalog"
        elif key == "destinationSchema":
            suggest = "destination_schema"
        elif key == "sourceCatalog":
            suggest = "source_catalog"
        elif key == "sourceSchema":
            suggest = "source_schema"
        elif key == "tableConfiguration":
            suggest = "table_configuration"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in PipelineIngestionDefinitionObjectSchema. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        PipelineIngestionDefinitionObjectSchema.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        PipelineIngestionDefinitionObjectSchema.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 destination_catalog: Optional[str] = None,
                 destination_schema: Optional[str] = None,
                 source_catalog: Optional[str] = None,
                 source_schema: Optional[str] = None,
                 table_configuration: Optional['outputs.PipelineIngestionDefinitionObjectSchemaTableConfiguration'] = None):
        if destination_catalog is not None:
            pulumi.set(__self__, "destination_catalog", destination_catalog)
        if destination_schema is not None:
            pulumi.set(__self__, "destination_schema", destination_schema)
        if source_catalog is not None:
            pulumi.set(__self__, "source_catalog", source_catalog)
        if source_schema is not None:
            pulumi.set(__self__, "source_schema", source_schema)
        if table_configuration is not None:
            pulumi.set(__self__, "table_configuration", table_configuration)

    @property
    @pulumi.getter(name="destinationCatalog")
    def destination_catalog(self) -> Optional[str]:
        return pulumi.get(self, "destination_catalog")

    @property
    @pulumi.getter(name="destinationSchema")
    def destination_schema(self) -> Optional[str]:
        return pulumi.get(self, "destination_schema")

    @property
    @pulumi.getter(name="sourceCatalog")
    def source_catalog(self) -> Optional[str]:
        return pulumi.get(self, "source_catalog")

    @property
    @pulumi.getter(name="sourceSchema")
    def source_schema(self) -> Optional[str]:
        return pulumi.get(self, "source_schema")

    @property
    @pulumi.getter(name="tableConfiguration")
    def table_configuration(self) -> Optional['outputs.PipelineIngestionDefinitionObjectSchemaTableConfiguration']:
        return pulumi.get(self, "table_configuration")


@pulumi.output_type
class PipelineIngestionDefinitionObjectSchemaTableConfiguration(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "primaryKeys":
            suggest = "primary_keys"
        elif key == "salesforceIncludeFormulaFields":
            suggest = "salesforce_include_formula_fields"
        elif key == "scdType":
            suggest = "scd_type"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in PipelineIngestionDefinitionObjectSchemaTableConfiguration. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        PipelineIngestionDefinitionObjectSchemaTableConfiguration.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        PipelineIngestionDefinitionObjectSchemaTableConfiguration.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 primary_keys: Optional[Sequence[str]] = None,
                 salesforce_include_formula_fields: Optional[bool] = None,
                 scd_type: Optional[str] = None):
        if primary_keys is not None:
            pulumi.set(__self__, "primary_keys", primary_keys)
        if salesforce_include_formula_fields is not None:
            pulumi.set(__self__, "salesforce_include_formula_fields", salesforce_include_formula_fields)
        if scd_type is not None:
            pulumi.set(__self__, "scd_type", scd_type)

    @property
    @pulumi.getter(name="primaryKeys")
    def primary_keys(self) -> Optional[Sequence[str]]:
        return pulumi.get(self, "primary_keys")

    @property
    @pulumi.getter(name="salesforceIncludeFormulaFields")
    def salesforce_include_formula_fields(self) -> Optional[bool]:
        return pulumi.get(self, "salesforce_include_formula_fields")

    @property
    @pulumi.getter(name="scdType")
    def scd_type(self) -> Optional[str]:
        return pulumi.get(self, "scd_type")


@pulumi.output_type
class PipelineIngestionDefinitionObjectTable(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "destinationCatalog":
            suggest = "destination_catalog"
        elif key == "destinationSchema":
            suggest = "destination_schema"
        elif key == "destinationTable":
            suggest = "destination_table"
        elif key == "sourceCatalog":
            suggest = "source_catalog"
        elif key == "sourceSchema":
            suggest = "source_schema"
        elif key == "sourceTable":
            suggest = "source_table"
        elif key == "tableConfiguration":
            suggest = "table_configuration"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in PipelineIngestionDefinitionObjectTable. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        PipelineIngestionDefinitionObjectTable.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        PipelineIngestionDefinitionObjectTable.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 destination_catalog: Optional[str] = None,
                 destination_schema: Optional[str] = None,
                 destination_table: Optional[str] = None,
                 source_catalog: Optional[str] = None,
                 source_schema: Optional[str] = None,
                 source_table: Optional[str] = None,
                 table_configuration: Optional['outputs.PipelineIngestionDefinitionObjectTableTableConfiguration'] = None):
        if destination_catalog is not None:
            pulumi.set(__self__, "destination_catalog", destination_catalog)
        if destination_schema is not None:
            pulumi.set(__self__, "destination_schema", destination_schema)
        if destination_table is not None:
            pulumi.set(__self__, "destination_table", destination_table)
        if source_catalog is not None:
            pulumi.set(__self__, "source_catalog", source_catalog)
        if source_schema is not None:
            pulumi.set(__self__, "source_schema", source_schema)
        if source_table is not None:
            pulumi.set(__self__, "source_table", source_table)
        if table_configuration is not None:
            pulumi.set(__self__, "table_configuration", table_configuration)

    @property
    @pulumi.getter(name="destinationCatalog")
    def destination_catalog(self) -> Optional[str]:
        return pulumi.get(self, "destination_catalog")

    @property
    @pulumi.getter(name="destinationSchema")
    def destination_schema(self) -> Optional[str]:
        return pulumi.get(self, "destination_schema")

    @property
    @pulumi.getter(name="destinationTable")
    def destination_table(self) -> Optional[str]:
        return pulumi.get(self, "destination_table")

    @property
    @pulumi.getter(name="sourceCatalog")
    def source_catalog(self) -> Optional[str]:
        return pulumi.get(self, "source_catalog")

    @property
    @pulumi.getter(name="sourceSchema")
    def source_schema(self) -> Optional[str]:
        return pulumi.get(self, "source_schema")

    @property
    @pulumi.getter(name="sourceTable")
    def source_table(self) -> Optional[str]:
        return pulumi.get(self, "source_table")

    @property
    @pulumi.getter(name="tableConfiguration")
    def table_configuration(self) -> Optional['outputs.PipelineIngestionDefinitionObjectTableTableConfiguration']:
        return pulumi.get(self, "table_configuration")


@pulumi.output_type
class PipelineIngestionDefinitionObjectTableTableConfiguration(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "primaryKeys":
            suggest = "primary_keys"
        elif key == "salesforceIncludeFormulaFields":
            suggest = "salesforce_include_formula_fields"
        elif key == "scdType":
            suggest = "scd_type"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in PipelineIngestionDefinitionObjectTableTableConfiguration. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        PipelineIngestionDefinitionObjectTableTableConfiguration.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        PipelineIngestionDefinitionObjectTableTableConfiguration.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 primary_keys: Optional[Sequence[str]] = None,
                 salesforce_include_formula_fields: Optional[bool] = None,
                 scd_type: Optional[str] = None):
        if primary_keys is not None:
            pulumi.set(__self__, "primary_keys", primary_keys)
        if salesforce_include_formula_fields is not None:
            pulumi.set(__self__, "salesforce_include_formula_fields", salesforce_include_formula_fields)
        if scd_type is not None:
            pulumi.set(__self__, "scd_type", scd_type)

    @property
    @pulumi.getter(name="primaryKeys")
    def primary_keys(self) -> Optional[Sequence[str]]:
        return pulumi.get(self, "primary_keys")

    @property
    @pulumi.getter(name="salesforceIncludeFormulaFields")
    def salesforce_include_formula_fields(self) -> Optional[bool]:
        return pulumi.get(self, "salesforce_include_formula_fields")

    @property
    @pulumi.getter(name="scdType")
    def scd_type(self) -> Optional[str]:
        return pulumi.get(self, "scd_type")


@pulumi.output_type
class PipelineIngestionDefinitionTableConfiguration(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "primaryKeys":
            suggest = "primary_keys"
        elif key == "salesforceIncludeFormulaFields":
            suggest = "salesforce_include_formula_fields"
        elif key == "scdType":
            suggest = "scd_type"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in PipelineIngestionDefinitionTableConfiguration. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        PipelineIngestionDefinitionTableConfiguration.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        PipelineIngestionDefinitionTableConfiguration.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 primary_keys: Optional[Sequence[str]] = None,
                 salesforce_include_formula_fields: Optional[bool] = None,
                 scd_type: Optional[str] = None):
        if primary_keys is not None:
            pulumi.set(__self__, "primary_keys", primary_keys)
        if salesforce_include_formula_fields is not None:
            pulumi.set(__self__, "salesforce_include_formula_fields", salesforce_include_formula_fields)
        if scd_type is not None:
            pulumi.set(__self__, "scd_type", scd_type)

    @property
    @pulumi.getter(name="primaryKeys")
    def primary_keys(self) -> Optional[Sequence[str]]:
        return pulumi.get(self, "primary_keys")

    @property
    @pulumi.getter(name="salesforceIncludeFormulaFields")
    def salesforce_include_formula_fields(self) -> Optional[bool]:
        return pulumi.get(self, "salesforce_include_formula_fields")

    @property
    @pulumi.getter(name="scdType")
    def scd_type(self) -> Optional[str]:
        return pulumi.get(self, "scd_type")


@pulumi.output_type
class PipelineLatestUpdate(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "creationTime":
            suggest = "creation_time"
        elif key == "updateId":
            suggest = "update_id"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in PipelineLatestUpdate. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        PipelineLatestUpdate.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        PipelineLatestUpdate.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 creation_time: Optional[str] = None,
                 state: Optional[str] = None,
                 update_id: Optional[str] = None):
        if creation_time is not None:
            pulumi.set(__self__, "creation_time", creation_time)
        if state is not None:
            pulumi.set(__self__, "state", state)
        if update_id is not None:
            pulumi.set(__self__, "update_id", update_id)

    @property
    @pulumi.getter(name="creationTime")
    def creation_time(self) -> Optional[str]:
        return pulumi.get(self, "creation_time")

    @property
    @pulumi.getter
    def state(self) -> Optional[str]:
        return pulumi.get(self, "state")

    @property
    @pulumi.getter(name="updateId")
    def update_id(self) -> Optional[str]:
        return pulumi.get(self, "update_id")


@pulumi.output_type
class PipelineLibrary(dict):
    def __init__(__self__, *,
                 file: Optional['outputs.PipelineLibraryFile'] = None,
                 jar: Optional[str] = None,
                 maven: Optional['outputs.PipelineLibraryMaven'] = None,
                 notebook: Optional['outputs.PipelineLibraryNotebook'] = None,
                 whl: Optional[str] = None):
        if file is not None:
            pulumi.set(__self__, "file", file)
        if jar is not None:
            pulumi.set(__self__, "jar", jar)
        if maven is not None:
            pulumi.set(__self__, "maven", maven)
        if notebook is not None:
            pulumi.set(__self__, "notebook", notebook)
        if whl is not None:
            pulumi.set(__self__, "whl", whl)

    @property
    @pulumi.getter
    def file(self) -> Optional['outputs.PipelineLibraryFile']:
        return pulumi.get(self, "file")

    @property
    @pulumi.getter
    def jar(self) -> Optional[str]:
        return pulumi.get(self, "jar")

    @property
    @pulumi.getter
    def maven(self) -> Optional['outputs.PipelineLibraryMaven']:
        return pulumi.get(self, "maven")

    @property
    @pulumi.getter
    def notebook(self) -> Optional['outputs.PipelineLibraryNotebook']:
        return pulumi.get(self, "notebook")

    @property
    @pulumi.getter
    @_utilities.deprecated("""The 'whl' field is deprecated""")
    def whl(self) -> Optional[str]:
        return pulumi.get(self, "whl")


@pulumi.output_type
class PipelineLibraryFile(dict):
    def __init__(__self__, *,
                 path: Optional[str] = None):
        if path is not None:
            pulumi.set(__self__, "path", path)

    @property
    @pulumi.getter
    def path(self) -> Optional[str]:
        return pulumi.get(self, "path")


@pulumi.output_type
class PipelineLibraryMaven(dict):
    def __init__(__self__, *,
                 coordinates: str,
                 exclusions: Optional[Sequence[str]] = None,
                 repo: Optional[str] = None):
        pulumi.set(__self__, "coordinates", coordinates)
        if exclusions is not None:
            pulumi.set(__self__, "exclusions", exclusions)
        if repo is not None:
            pulumi.set(__self__, "repo", repo)

    @property
    @pulumi.getter
    def coordinates(self) -> str:
        return pulumi.get(self, "coordinates")

    @property
    @pulumi.getter
    def exclusions(self) -> Optional[Sequence[str]]:
        return pulumi.get(self, "exclusions")

    @property
    @pulumi.getter
    def repo(self) -> Optional[str]:
        return pulumi.get(self, "repo")


@pulumi.output_type
class PipelineLibraryNotebook(dict):
    def __init__(__self__, *,
                 path: Optional[str] = None):
        if path is not None:
            pulumi.set(__self__, "path", path)

    @property
    @pulumi.getter
    def path(self) -> Optional[str]:
        return pulumi.get(self, "path")


@pulumi.output_type
class PipelineNotification(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "emailRecipients":
            suggest = "email_recipients"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in PipelineNotification. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        PipelineNotification.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        PipelineNotification.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 alerts: Optional[Sequence[str]] = None,
                 email_recipients: Optional[Sequence[str]] = None):
        """
        :param Sequence[str] alerts: non-empty list of alert types. Right now following alert types are supported, consult documentation for actual list
               * `on-update-success` - a pipeline update completes successfully.
               * `on-update-failure` - a pipeline update fails with a retryable error.
               * `on-update-fatal-failure` - a pipeline update fails with a non-retryable (fatal) error.
               * `on-flow-failure` - a single data flow fails.
        :param Sequence[str] email_recipients: non-empty list of emails to notify.
        """
        if alerts is not None:
            pulumi.set(__self__, "alerts", alerts)
        if email_recipients is not None:
            pulumi.set(__self__, "email_recipients", email_recipients)

    @property
    @pulumi.getter
    def alerts(self) -> Optional[Sequence[str]]:
        """
        non-empty list of alert types. Right now following alert types are supported, consult documentation for actual list
        * `on-update-success` - a pipeline update completes successfully.
        * `on-update-failure` - a pipeline update fails with a retryable error.
        * `on-update-fatal-failure` - a pipeline update fails with a non-retryable (fatal) error.
        * `on-flow-failure` - a single data flow fails.
        """
        return pulumi.get(self, "alerts")

    @property
    @pulumi.getter(name="emailRecipients")
    def email_recipients(self) -> Optional[Sequence[str]]:
        """
        non-empty list of emails to notify.
        """
        return pulumi.get(self, "email_recipients")


@pulumi.output_type
class PipelineTrigger(dict):
    def __init__(__self__, *,
                 cron: Optional['outputs.PipelineTriggerCron'] = None,
                 manual: Optional['outputs.PipelineTriggerManual'] = None):
        if cron is not None:
            pulumi.set(__self__, "cron", cron)
        if manual is not None:
            pulumi.set(__self__, "manual", manual)

    @property
    @pulumi.getter
    def cron(self) -> Optional['outputs.PipelineTriggerCron']:
        return pulumi.get(self, "cron")

    @property
    @pulumi.getter
    def manual(self) -> Optional['outputs.PipelineTriggerManual']:
        return pulumi.get(self, "manual")


@pulumi.output_type
class PipelineTriggerCron(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "quartzCronSchedule":
            suggest = "quartz_cron_schedule"
        elif key == "timezoneId":
            suggest = "timezone_id"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in PipelineTriggerCron. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        PipelineTriggerCron.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        PipelineTriggerCron.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 quartz_cron_schedule: Optional[str] = None,
                 timezone_id: Optional[str] = None):
        if quartz_cron_schedule is not None:
            pulumi.set(__self__, "quartz_cron_schedule", quartz_cron_schedule)
        if timezone_id is not None:
            pulumi.set(__self__, "timezone_id", timezone_id)

    @property
    @pulumi.getter(name="quartzCronSchedule")
    def quartz_cron_schedule(self) -> Optional[str]:
        return pulumi.get(self, "quartz_cron_schedule")

    @property
    @pulumi.getter(name="timezoneId")
    def timezone_id(self) -> Optional[str]:
        return pulumi.get(self, "timezone_id")


@pulumi.output_type
class PipelineTriggerManual(dict):
    def __init__(__self__):
        pass


@pulumi.output_type
class QualityMonitorCustomMetric(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "inputColumns":
            suggest = "input_columns"
        elif key == "outputDataType":
            suggest = "output_data_type"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in QualityMonitorCustomMetric. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        QualityMonitorCustomMetric.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        QualityMonitorCustomMetric.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 definition: str,
                 input_columns: Sequence[str],
                 name: str,
                 output_data_type: str,
                 type: str):
        """
        :param str definition: [create metric definition](https://docs.databricks.com/en/lakehouse-monitoring/custom-metrics.html#create-definition)
        :param Sequence[str] input_columns: Columns on the monitored table to apply the custom metrics to.
        :param str name: Name of the custom metric.
        :param str output_data_type: The output type of the custom metric.
        :param str type: The type of the custom metric.
        """
        pulumi.set(__self__, "definition", definition)
        pulumi.set(__self__, "input_columns", input_columns)
        pulumi.set(__self__, "name", name)
        pulumi.set(__self__, "output_data_type", output_data_type)
        pulumi.set(__self__, "type", type)

    @property
    @pulumi.getter
    def definition(self) -> str:
        """
        [create metric definition](https://docs.databricks.com/en/lakehouse-monitoring/custom-metrics.html#create-definition)
        """
        return pulumi.get(self, "definition")

    @property
    @pulumi.getter(name="inputColumns")
    def input_columns(self) -> Sequence[str]:
        """
        Columns on the monitored table to apply the custom metrics to.
        """
        return pulumi.get(self, "input_columns")

    @property
    @pulumi.getter
    def name(self) -> str:
        """
        Name of the custom metric.
        """
        return pulumi.get(self, "name")

    @property
    @pulumi.getter(name="outputDataType")
    def output_data_type(self) -> str:
        """
        The output type of the custom metric.
        """
        return pulumi.get(self, "output_data_type")

    @property
    @pulumi.getter
    def type(self) -> str:
        """
        The type of the custom metric.
        """
        return pulumi.get(self, "type")


@pulumi.output_type
class QualityMonitorDataClassificationConfig(dict):
    def __init__(__self__, *,
                 enabled: Optional[bool] = None):
        if enabled is not None:
            pulumi.set(__self__, "enabled", enabled)

    @property
    @pulumi.getter
    def enabled(self) -> Optional[bool]:
        return pulumi.get(self, "enabled")


@pulumi.output_type
class QualityMonitorInferenceLog(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "modelIdCol":
            suggest = "model_id_col"
        elif key == "predictionCol":
            suggest = "prediction_col"
        elif key == "problemType":
            suggest = "problem_type"
        elif key == "timestampCol":
            suggest = "timestamp_col"
        elif key == "labelCol":
            suggest = "label_col"
        elif key == "predictionProbaCol":
            suggest = "prediction_proba_col"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in QualityMonitorInferenceLog. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        QualityMonitorInferenceLog.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        QualityMonitorInferenceLog.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 granularities: Sequence[str],
                 model_id_col: str,
                 prediction_col: str,
                 problem_type: str,
                 timestamp_col: str,
                 label_col: Optional[str] = None,
                 prediction_proba_col: Optional[str] = None):
        """
        :param Sequence[str] granularities: List of granularities to use when aggregating data into time windows based on their timestamp.
        :param str model_id_col: Column of the model id or version
        :param str prediction_col: Column of the model prediction
        :param str problem_type: Problem type the model aims to solve. Either `PROBLEM_TYPE_CLASSIFICATION` or `PROBLEM_TYPE_REGRESSION`
        :param str timestamp_col: Column of the timestamp of predictions
        :param str label_col: Column of the model label
        :param str prediction_proba_col: Column of the model prediction probabilities
        """
        pulumi.set(__self__, "granularities", granularities)
        pulumi.set(__self__, "model_id_col", model_id_col)
        pulumi.set(__self__, "prediction_col", prediction_col)
        pulumi.set(__self__, "problem_type", problem_type)
        pulumi.set(__self__, "timestamp_col", timestamp_col)
        if label_col is not None:
            pulumi.set(__self__, "label_col", label_col)
        if prediction_proba_col is not None:
            pulumi.set(__self__, "prediction_proba_col", prediction_proba_col)

    @property
    @pulumi.getter
    def granularities(self) -> Sequence[str]:
        """
        List of granularities to use when aggregating data into time windows based on their timestamp.
        """
        return pulumi.get(self, "granularities")

    @property
    @pulumi.getter(name="modelIdCol")
    def model_id_col(self) -> str:
        """
        Column of the model id or version
        """
        return pulumi.get(self, "model_id_col")

    @property
    @pulumi.getter(name="predictionCol")
    def prediction_col(self) -> str:
        """
        Column of the model prediction
        """
        return pulumi.get(self, "prediction_col")

    @property
    @pulumi.getter(name="problemType")
    def problem_type(self) -> str:
        """
        Problem type the model aims to solve. Either `PROBLEM_TYPE_CLASSIFICATION` or `PROBLEM_TYPE_REGRESSION`
        """
        return pulumi.get(self, "problem_type")

    @property
    @pulumi.getter(name="timestampCol")
    def timestamp_col(self) -> str:
        """
        Column of the timestamp of predictions
        """
        return pulumi.get(self, "timestamp_col")

    @property
    @pulumi.getter(name="labelCol")
    def label_col(self) -> Optional[str]:
        """
        Column of the model label
        """
        return pulumi.get(self, "label_col")

    @property
    @pulumi.getter(name="predictionProbaCol")
    def prediction_proba_col(self) -> Optional[str]:
        """
        Column of the model prediction probabilities
        """
        return pulumi.get(self, "prediction_proba_col")


@pulumi.output_type
class QualityMonitorNotifications(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "onFailure":
            suggest = "on_failure"
        elif key == "onNewClassificationTagDetected":
            suggest = "on_new_classification_tag_detected"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in QualityMonitorNotifications. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        QualityMonitorNotifications.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        QualityMonitorNotifications.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 on_failure: Optional['outputs.QualityMonitorNotificationsOnFailure'] = None,
                 on_new_classification_tag_detected: Optional['outputs.QualityMonitorNotificationsOnNewClassificationTagDetected'] = None):
        """
        :param 'QualityMonitorNotificationsOnFailureArgs' on_failure: who to send notifications to on monitor failure.
        :param 'QualityMonitorNotificationsOnNewClassificationTagDetectedArgs' on_new_classification_tag_detected: Who to send notifications to when new data classification tags are detected.
        """
        if on_failure is not None:
            pulumi.set(__self__, "on_failure", on_failure)
        if on_new_classification_tag_detected is not None:
            pulumi.set(__self__, "on_new_classification_tag_detected", on_new_classification_tag_detected)

    @property
    @pulumi.getter(name="onFailure")
    def on_failure(self) -> Optional['outputs.QualityMonitorNotificationsOnFailure']:
        """
        who to send notifications to on monitor failure.
        """
        return pulumi.get(self, "on_failure")

    @property
    @pulumi.getter(name="onNewClassificationTagDetected")
    def on_new_classification_tag_detected(self) -> Optional['outputs.QualityMonitorNotificationsOnNewClassificationTagDetected']:
        """
        Who to send notifications to when new data classification tags are detected.
        """
        return pulumi.get(self, "on_new_classification_tag_detected")


@pulumi.output_type
class QualityMonitorNotificationsOnFailure(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "emailAddresses":
            suggest = "email_addresses"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in QualityMonitorNotificationsOnFailure. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        QualityMonitorNotificationsOnFailure.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        QualityMonitorNotificationsOnFailure.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 email_addresses: Optional[Sequence[str]] = None):
        if email_addresses is not None:
            pulumi.set(__self__, "email_addresses", email_addresses)

    @property
    @pulumi.getter(name="emailAddresses")
    def email_addresses(self) -> Optional[Sequence[str]]:
        return pulumi.get(self, "email_addresses")


@pulumi.output_type
class QualityMonitorNotificationsOnNewClassificationTagDetected(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "emailAddresses":
            suggest = "email_addresses"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in QualityMonitorNotificationsOnNewClassificationTagDetected. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        QualityMonitorNotificationsOnNewClassificationTagDetected.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        QualityMonitorNotificationsOnNewClassificationTagDetected.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 email_addresses: Optional[Sequence[str]] = None):
        if email_addresses is not None:
            pulumi.set(__self__, "email_addresses", email_addresses)

    @property
    @pulumi.getter(name="emailAddresses")
    def email_addresses(self) -> Optional[Sequence[str]]:
        return pulumi.get(self, "email_addresses")


@pulumi.output_type
class QualityMonitorSchedule(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "quartzCronExpression":
            suggest = "quartz_cron_expression"
        elif key == "timezoneId":
            suggest = "timezone_id"
        elif key == "pauseStatus":
            suggest = "pause_status"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in QualityMonitorSchedule. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        QualityMonitorSchedule.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        QualityMonitorSchedule.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 quartz_cron_expression: str,
                 timezone_id: str,
                 pause_status: Optional[str] = None):
        """
        :param str quartz_cron_expression: string expression that determines when to run the monitor. See [Quartz documentation](https://www.quartz-scheduler.org/documentation/quartz-2.3.0/tutorials/crontrigger.html) for examples.
        :param str timezone_id: string with timezone id (e.g., `PST`) in which to evaluate the Quartz expression.
        """
        pulumi.set(__self__, "quartz_cron_expression", quartz_cron_expression)
        pulumi.set(__self__, "timezone_id", timezone_id)
        if pause_status is not None:
            pulumi.set(__self__, "pause_status", pause_status)

    @property
    @pulumi.getter(name="quartzCronExpression")
    def quartz_cron_expression(self) -> str:
        """
        string expression that determines when to run the monitor. See [Quartz documentation](https://www.quartz-scheduler.org/documentation/quartz-2.3.0/tutorials/crontrigger.html) for examples.
        """
        return pulumi.get(self, "quartz_cron_expression")

    @property
    @pulumi.getter(name="timezoneId")
    def timezone_id(self) -> str:
        """
        string with timezone id (e.g., `PST`) in which to evaluate the Quartz expression.
        """
        return pulumi.get(self, "timezone_id")

    @property
    @pulumi.getter(name="pauseStatus")
    def pause_status(self) -> Optional[str]:
        return pulumi.get(self, "pause_status")


@pulumi.output_type
class QualityMonitorSnapshot(dict):
    def __init__(__self__):
        pass


@pulumi.output_type
class QualityMonitorTimeSeries(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "timestampCol":
            suggest = "timestamp_col"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in QualityMonitorTimeSeries. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        QualityMonitorTimeSeries.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        QualityMonitorTimeSeries.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 granularities: Sequence[str],
                 timestamp_col: str):
        """
        :param Sequence[str] granularities: List of granularities to use when aggregating data into time windows based on their timestamp.
        :param str timestamp_col: Column of the timestamp of predictions
        """
        pulumi.set(__self__, "granularities", granularities)
        pulumi.set(__self__, "timestamp_col", timestamp_col)

    @property
    @pulumi.getter
    def granularities(self) -> Sequence[str]:
        """
        List of granularities to use when aggregating data into time windows based on their timestamp.
        """
        return pulumi.get(self, "granularities")

    @property
    @pulumi.getter(name="timestampCol")
    def timestamp_col(self) -> str:
        """
        Column of the timestamp of predictions
        """
        return pulumi.get(self, "timestamp_col")


@pulumi.output_type
class RecipientIpAccessList(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "allowedIpAddresses":
            suggest = "allowed_ip_addresses"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in RecipientIpAccessList. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        RecipientIpAccessList.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        RecipientIpAccessList.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 allowed_ip_addresses: Optional[Sequence[str]] = None):
        """
        :param Sequence[str] allowed_ip_addresses: Allowed IP Addresses in CIDR notation. Limit of 100.
        """
        if allowed_ip_addresses is not None:
            pulumi.set(__self__, "allowed_ip_addresses", allowed_ip_addresses)

    @property
    @pulumi.getter(name="allowedIpAddresses")
    def allowed_ip_addresses(self) -> Optional[Sequence[str]]:
        """
        Allowed IP Addresses in CIDR notation. Limit of 100.
        """
        return pulumi.get(self, "allowed_ip_addresses")


@pulumi.output_type
class RecipientPropertiesKvpairs(dict):
    def __init__(__self__, *,
                 properties: Mapping[str, str]):
        """
        :param Mapping[str, str] properties: a map of string key-value pairs with recipient's properties.  Properties with name starting with `databricks.` are reserved.
        """
        pulumi.set(__self__, "properties", properties)

    @property
    @pulumi.getter
    def properties(self) -> Mapping[str, str]:
        """
        a map of string key-value pairs with recipient's properties.  Properties with name starting with `databricks.` are reserved.
        """
        return pulumi.get(self, "properties")


@pulumi.output_type
class RecipientToken(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "activationUrl":
            suggest = "activation_url"
        elif key == "createdAt":
            suggest = "created_at"
        elif key == "createdBy":
            suggest = "created_by"
        elif key == "expirationTime":
            suggest = "expiration_time"
        elif key == "updatedAt":
            suggest = "updated_at"
        elif key == "updatedBy":
            suggest = "updated_by"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in RecipientToken. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        RecipientToken.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        RecipientToken.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 activation_url: Optional[str] = None,
                 created_at: Optional[int] = None,
                 created_by: Optional[str] = None,
                 expiration_time: Optional[int] = None,
                 id: Optional[str] = None,
                 updated_at: Optional[int] = None,
                 updated_by: Optional[str] = None):
        """
        :param str activation_url: Full activation URL to retrieve the access token. It will be empty if the token is already retrieved.
        :param int created_at: Time at which this recipient was created, in epoch milliseconds.
        :param str created_by: Username of recipient creator.
        :param int expiration_time: Expiration timestamp of the token in epoch milliseconds.
        :param str id: Unique ID of the recipient token.
        :param int updated_at: Time at which this recipient was updated, in epoch milliseconds.
        :param str updated_by: Username of recipient Token updater.
        """
        if activation_url is not None:
            pulumi.set(__self__, "activation_url", activation_url)
        if created_at is not None:
            pulumi.set(__self__, "created_at", created_at)
        if created_by is not None:
            pulumi.set(__self__, "created_by", created_by)
        if expiration_time is not None:
            pulumi.set(__self__, "expiration_time", expiration_time)
        if id is not None:
            pulumi.set(__self__, "id", id)
        if updated_at is not None:
            pulumi.set(__self__, "updated_at", updated_at)
        if updated_by is not None:
            pulumi.set(__self__, "updated_by", updated_by)

    @property
    @pulumi.getter(name="activationUrl")
    def activation_url(self) -> Optional[str]:
        """
        Full activation URL to retrieve the access token. It will be empty if the token is already retrieved.
        """
        return pulumi.get(self, "activation_url")

    @property
    @pulumi.getter(name="createdAt")
    def created_at(self) -> Optional[int]:
        """
        Time at which this recipient was created, in epoch milliseconds.
        """
        return pulumi.get(self, "created_at")

    @property
    @pulumi.getter(name="createdBy")
    def created_by(self) -> Optional[str]:
        """
        Username of recipient creator.
        """
        return pulumi.get(self, "created_by")

    @property
    @pulumi.getter(name="expirationTime")
    def expiration_time(self) -> Optional[int]:
        """
        Expiration timestamp of the token in epoch milliseconds.
        """
        return pulumi.get(self, "expiration_time")

    @property
    @pulumi.getter
    def id(self) -> Optional[str]:
        """
        Unique ID of the recipient token.
        """
        return pulumi.get(self, "id")

    @property
    @pulumi.getter(name="updatedAt")
    def updated_at(self) -> Optional[int]:
        """
        Time at which this recipient was updated, in epoch milliseconds.
        """
        return pulumi.get(self, "updated_at")

    @property
    @pulumi.getter(name="updatedBy")
    def updated_by(self) -> Optional[str]:
        """
        Username of recipient Token updater.
        """
        return pulumi.get(self, "updated_by")


@pulumi.output_type
class RepoSparseCheckout(dict):
    def __init__(__self__, *,
                 patterns: Sequence[str]):
        """
        :param Sequence[str] patterns: array of paths (directories) that will be used for sparse checkout.  List of patterns could be updated in-place.
               
               Addition or removal of the `sparse_checkout` configuration block will lead to recreation of the Git folder.
        """
        pulumi.set(__self__, "patterns", patterns)

    @property
    @pulumi.getter
    def patterns(self) -> Sequence[str]:
        """
        array of paths (directories) that will be used for sparse checkout.  List of patterns could be updated in-place.

        Addition or removal of the `sparse_checkout` configuration block will lead to recreation of the Git folder.
        """
        return pulumi.get(self, "patterns")


@pulumi.output_type
class RestrictWorkspaceAdminsSettingRestrictWorkspaceAdmins(dict):
    def __init__(__self__, *,
                 status: str):
        """
        :param str status: The restrict workspace admins status for the workspace.
        """
        pulumi.set(__self__, "status", status)

    @property
    @pulumi.getter
    def status(self) -> str:
        """
        The restrict workspace admins status for the workspace.
        """
        return pulumi.get(self, "status")


@pulumi.output_type
class SecretScopeKeyvaultMetadata(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "dnsName":
            suggest = "dns_name"
        elif key == "resourceId":
            suggest = "resource_id"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in SecretScopeKeyvaultMetadata. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        SecretScopeKeyvaultMetadata.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        SecretScopeKeyvaultMetadata.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 dns_name: str,
                 resource_id: str):
        pulumi.set(__self__, "dns_name", dns_name)
        pulumi.set(__self__, "resource_id", resource_id)

    @property
    @pulumi.getter(name="dnsName")
    def dns_name(self) -> str:
        return pulumi.get(self, "dns_name")

    @property
    @pulumi.getter(name="resourceId")
    def resource_id(self) -> str:
        return pulumi.get(self, "resource_id")


@pulumi.output_type
class ShareObject(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "dataObjectType":
            suggest = "data_object_type"
        elif key == "addedAt":
            suggest = "added_at"
        elif key == "addedBy":
            suggest = "added_by"
        elif key == "cdfEnabled":
            suggest = "cdf_enabled"
        elif key == "historyDataSharingStatus":
            suggest = "history_data_sharing_status"
        elif key == "sharedAs":
            suggest = "shared_as"
        elif key == "startVersion":
            suggest = "start_version"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ShareObject. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ShareObject.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ShareObject.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 data_object_type: str,
                 name: str,
                 added_at: Optional[int] = None,
                 added_by: Optional[str] = None,
                 cdf_enabled: Optional[bool] = None,
                 comment: Optional[str] = None,
                 history_data_sharing_status: Optional[str] = None,
                 partitions: Optional[Sequence['outputs.ShareObjectPartition']] = None,
                 shared_as: Optional[str] = None,
                 start_version: Optional[int] = None,
                 status: Optional[str] = None):
        """
        :param str data_object_type: Type of the data object, currently `TABLE`, `SCHEMA`, `VOLUME`, and `MODEL` are supported.
        :param str name: Full name of the object, e.g. `catalog.schema.name` for a tables, volumes and models, or `catalog.schema` for schemas.
        :param bool cdf_enabled: Whether to enable Change Data Feed (cdf) on the shared object. When this field is set, field `history_data_sharing_status` can not be set.
        :param str comment: Description about the object.
        :param str history_data_sharing_status: Whether to enable history sharing, one of: `ENABLED`, `DISABLED`. When a table has history sharing enabled, recipients can query table data by version, starting from the current table version. If not specified, clients can only query starting from the version of the object at the time it was added to the share. *NOTE*: The start_version should be less than or equal the current version of the object. When this field is set, field `cdf_enabled` can not be set.
               
               To share only part of a table when you add the table to a share, you can provide partition specifications. This is specified by a number of `partition` blocks. Each entry in `partition` block takes a list of `value` blocks. The field is documented below.
        :param str shared_as: A user-provided new name for the data object within the share. If this new name is not provided, the object's original name will be used as the `shared_as` name. The `shared_as` name must be unique within a Share. Change forces creation of a new resource.
        :param int start_version: The start version associated with the object for cdf. This allows data providers to control the lowest object version that is accessible by clients.
        :param str status: Status of the object, one of: `ACTIVE`, `PERMISSION_DENIED`.
        """
        pulumi.set(__self__, "data_object_type", data_object_type)
        pulumi.set(__self__, "name", name)
        if added_at is not None:
            pulumi.set(__self__, "added_at", added_at)
        if added_by is not None:
            pulumi.set(__self__, "added_by", added_by)
        if cdf_enabled is not None:
            pulumi.set(__self__, "cdf_enabled", cdf_enabled)
        if comment is not None:
            pulumi.set(__self__, "comment", comment)
        if history_data_sharing_status is not None:
            pulumi.set(__self__, "history_data_sharing_status", history_data_sharing_status)
        if partitions is not None:
            pulumi.set(__self__, "partitions", partitions)
        if shared_as is not None:
            pulumi.set(__self__, "shared_as", shared_as)
        if start_version is not None:
            pulumi.set(__self__, "start_version", start_version)
        if status is not None:
            pulumi.set(__self__, "status", status)

    @property
    @pulumi.getter(name="dataObjectType")
    def data_object_type(self) -> str:
        """
        Type of the data object, currently `TABLE`, `SCHEMA`, `VOLUME`, and `MODEL` are supported.
        """
        return pulumi.get(self, "data_object_type")

    @property
    @pulumi.getter
    def name(self) -> str:
        """
        Full name of the object, e.g. `catalog.schema.name` for a tables, volumes and models, or `catalog.schema` for schemas.
        """
        return pulumi.get(self, "name")

    @property
    @pulumi.getter(name="addedAt")
    def added_at(self) -> Optional[int]:
        return pulumi.get(self, "added_at")

    @property
    @pulumi.getter(name="addedBy")
    def added_by(self) -> Optional[str]:
        return pulumi.get(self, "added_by")

    @property
    @pulumi.getter(name="cdfEnabled")
    def cdf_enabled(self) -> Optional[bool]:
        """
        Whether to enable Change Data Feed (cdf) on the shared object. When this field is set, field `history_data_sharing_status` can not be set.
        """
        return pulumi.get(self, "cdf_enabled")

    @property
    @pulumi.getter
    def comment(self) -> Optional[str]:
        """
        Description about the object.
        """
        return pulumi.get(self, "comment")

    @property
    @pulumi.getter(name="historyDataSharingStatus")
    def history_data_sharing_status(self) -> Optional[str]:
        """
        Whether to enable history sharing, one of: `ENABLED`, `DISABLED`. When a table has history sharing enabled, recipients can query table data by version, starting from the current table version. If not specified, clients can only query starting from the version of the object at the time it was added to the share. *NOTE*: The start_version should be less than or equal the current version of the object. When this field is set, field `cdf_enabled` can not be set.

        To share only part of a table when you add the table to a share, you can provide partition specifications. This is specified by a number of `partition` blocks. Each entry in `partition` block takes a list of `value` blocks. The field is documented below.
        """
        return pulumi.get(self, "history_data_sharing_status")

    @property
    @pulumi.getter
    def partitions(self) -> Optional[Sequence['outputs.ShareObjectPartition']]:
        return pulumi.get(self, "partitions")

    @property
    @pulumi.getter(name="sharedAs")
    def shared_as(self) -> Optional[str]:
        """
        A user-provided new name for the data object within the share. If this new name is not provided, the object's original name will be used as the `shared_as` name. The `shared_as` name must be unique within a Share. Change forces creation of a new resource.
        """
        return pulumi.get(self, "shared_as")

    @property
    @pulumi.getter(name="startVersion")
    def start_version(self) -> Optional[int]:
        """
        The start version associated with the object for cdf. This allows data providers to control the lowest object version that is accessible by clients.
        """
        return pulumi.get(self, "start_version")

    @property
    @pulumi.getter
    def status(self) -> Optional[str]:
        """
        Status of the object, one of: `ACTIVE`, `PERMISSION_DENIED`.
        """
        return pulumi.get(self, "status")


@pulumi.output_type
class ShareObjectPartition(dict):
    def __init__(__self__, *,
                 values: Sequence['outputs.ShareObjectPartitionValue']):
        """
        :param Sequence['ShareObjectPartitionValueArgs'] values: The value of the partition column. When this value is not set, it means null value. When this field is set, field `recipient_property_key` can not be set.
        """
        pulumi.set(__self__, "values", values)

    @property
    @pulumi.getter
    def values(self) -> Sequence['outputs.ShareObjectPartitionValue']:
        """
        The value of the partition column. When this value is not set, it means null value. When this field is set, field `recipient_property_key` can not be set.
        """
        return pulumi.get(self, "values")


@pulumi.output_type
class ShareObjectPartitionValue(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "recipientPropertyKey":
            suggest = "recipient_property_key"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ShareObjectPartitionValue. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ShareObjectPartitionValue.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ShareObjectPartitionValue.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 name: str,
                 op: str,
                 recipient_property_key: Optional[str] = None,
                 value: Optional[str] = None):
        """
        :param str name: The name of the partition column.
        :param str op: The operator to apply for the value, one of: `EQUAL`, `LIKE`
        :param str recipient_property_key: The key of a Delta Sharing recipient's property. For example `databricks-account-id`. When this field is set, field `value` can not be set.
        :param str value: The value of the partition column. When this value is not set, it means null value. When this field is set, field `recipient_property_key` can not be set.
        """
        pulumi.set(__self__, "name", name)
        pulumi.set(__self__, "op", op)
        if recipient_property_key is not None:
            pulumi.set(__self__, "recipient_property_key", recipient_property_key)
        if value is not None:
            pulumi.set(__self__, "value", value)

    @property
    @pulumi.getter
    def name(self) -> str:
        """
        The name of the partition column.
        """
        return pulumi.get(self, "name")

    @property
    @pulumi.getter
    def op(self) -> str:
        """
        The operator to apply for the value, one of: `EQUAL`, `LIKE`
        """
        return pulumi.get(self, "op")

    @property
    @pulumi.getter(name="recipientPropertyKey")
    def recipient_property_key(self) -> Optional[str]:
        """
        The key of a Delta Sharing recipient's property. For example `databricks-account-id`. When this field is set, field `value` can not be set.
        """
        return pulumi.get(self, "recipient_property_key")

    @property
    @pulumi.getter
    def value(self) -> Optional[str]:
        """
        The value of the partition column. When this value is not set, it means null value. When this field is set, field `recipient_property_key` can not be set.
        """
        return pulumi.get(self, "value")


@pulumi.output_type
class SqlAlertOptions(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "customBody":
            suggest = "custom_body"
        elif key == "customSubject":
            suggest = "custom_subject"
        elif key == "emptyResultState":
            suggest = "empty_result_state"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in SqlAlertOptions. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        SqlAlertOptions.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        SqlAlertOptions.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 column: str,
                 op: str,
                 value: str,
                 custom_body: Optional[str] = None,
                 custom_subject: Optional[str] = None,
                 empty_result_state: Optional[str] = None,
                 muted: Optional[bool] = None):
        """
        :param str column: Name of column in the query result to compare in alert evaluation.
        :param str op: Operator used to compare in alert evaluation. (Enum: `>`, `>=`, `<`, `<=`, `==`, `!=`)
        :param str value: Value used to compare in alert evaluation.
        :param str custom_body: Custom body of alert notification, if it exists. See [Alerts API reference](https://docs.databricks.com/sql/user/alerts/index.html) for custom templating instructions.
        :param str custom_subject: Custom subject of alert notification, if it exists. This includes email subject, Slack notification header, etc. See [Alerts API reference](https://docs.databricks.com/sql/user/alerts/index.html) for custom templating instructions.
        :param str empty_result_state: State that alert evaluates to when query result is empty.  Currently supported values are `unknown`, `triggered`, `ok` - check [API documentation](https://docs.databricks.com/api/workspace/alerts/create) for full list of supported values.
        :param bool muted: Whether or not the alert is muted. If an alert is muted, it will not notify users and alert destinations when triggered.
        """
        pulumi.set(__self__, "column", column)
        pulumi.set(__self__, "op", op)
        pulumi.set(__self__, "value", value)
        if custom_body is not None:
            pulumi.set(__self__, "custom_body", custom_body)
        if custom_subject is not None:
            pulumi.set(__self__, "custom_subject", custom_subject)
        if empty_result_state is not None:
            pulumi.set(__self__, "empty_result_state", empty_result_state)
        if muted is not None:
            pulumi.set(__self__, "muted", muted)

    @property
    @pulumi.getter
    def column(self) -> str:
        """
        Name of column in the query result to compare in alert evaluation.
        """
        return pulumi.get(self, "column")

    @property
    @pulumi.getter
    def op(self) -> str:
        """
        Operator used to compare in alert evaluation. (Enum: `>`, `>=`, `<`, `<=`, `==`, `!=`)
        """
        return pulumi.get(self, "op")

    @property
    @pulumi.getter
    def value(self) -> str:
        """
        Value used to compare in alert evaluation.
        """
        return pulumi.get(self, "value")

    @property
    @pulumi.getter(name="customBody")
    def custom_body(self) -> Optional[str]:
        """
        Custom body of alert notification, if it exists. See [Alerts API reference](https://docs.databricks.com/sql/user/alerts/index.html) for custom templating instructions.
        """
        return pulumi.get(self, "custom_body")

    @property
    @pulumi.getter(name="customSubject")
    def custom_subject(self) -> Optional[str]:
        """
        Custom subject of alert notification, if it exists. This includes email subject, Slack notification header, etc. See [Alerts API reference](https://docs.databricks.com/sql/user/alerts/index.html) for custom templating instructions.
        """
        return pulumi.get(self, "custom_subject")

    @property
    @pulumi.getter(name="emptyResultState")
    def empty_result_state(self) -> Optional[str]:
        """
        State that alert evaluates to when query result is empty.  Currently supported values are `unknown`, `triggered`, `ok` - check [API documentation](https://docs.databricks.com/api/workspace/alerts/create) for full list of supported values.
        """
        return pulumi.get(self, "empty_result_state")

    @property
    @pulumi.getter
    def muted(self) -> Optional[bool]:
        """
        Whether or not the alert is muted. If an alert is muted, it will not notify users and alert destinations when triggered.
        """
        return pulumi.get(self, "muted")


@pulumi.output_type
class SqlEndpointChannel(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "dbsqlVersion":
            suggest = "dbsql_version"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in SqlEndpointChannel. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        SqlEndpointChannel.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        SqlEndpointChannel.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 dbsql_version: Optional[str] = None,
                 name: Optional[str] = None):
        """
        :param str name: Name of the Databricks SQL release channel. Possible values are: `CHANNEL_NAME_PREVIEW` and `CHANNEL_NAME_CURRENT`. Default is `CHANNEL_NAME_CURRENT`.
        """
        if dbsql_version is not None:
            pulumi.set(__self__, "dbsql_version", dbsql_version)
        if name is not None:
            pulumi.set(__self__, "name", name)

    @property
    @pulumi.getter(name="dbsqlVersion")
    def dbsql_version(self) -> Optional[str]:
        return pulumi.get(self, "dbsql_version")

    @property
    @pulumi.getter
    def name(self) -> Optional[str]:
        """
        Name of the Databricks SQL release channel. Possible values are: `CHANNEL_NAME_PREVIEW` and `CHANNEL_NAME_CURRENT`. Default is `CHANNEL_NAME_CURRENT`.
        """
        return pulumi.get(self, "name")


@pulumi.output_type
class SqlEndpointHealth(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "failureReason":
            suggest = "failure_reason"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in SqlEndpointHealth. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        SqlEndpointHealth.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        SqlEndpointHealth.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 details: Optional[str] = None,
                 failure_reason: Optional['outputs.SqlEndpointHealthFailureReason'] = None,
                 message: Optional[str] = None,
                 status: Optional[str] = None,
                 summary: Optional[str] = None):
        if details is not None:
            pulumi.set(__self__, "details", details)
        if failure_reason is not None:
            pulumi.set(__self__, "failure_reason", failure_reason)
        if message is not None:
            pulumi.set(__self__, "message", message)
        if status is not None:
            pulumi.set(__self__, "status", status)
        if summary is not None:
            pulumi.set(__self__, "summary", summary)

    @property
    @pulumi.getter
    def details(self) -> Optional[str]:
        return pulumi.get(self, "details")

    @property
    @pulumi.getter(name="failureReason")
    def failure_reason(self) -> Optional['outputs.SqlEndpointHealthFailureReason']:
        return pulumi.get(self, "failure_reason")

    @property
    @pulumi.getter
    def message(self) -> Optional[str]:
        return pulumi.get(self, "message")

    @property
    @pulumi.getter
    def status(self) -> Optional[str]:
        return pulumi.get(self, "status")

    @property
    @pulumi.getter
    def summary(self) -> Optional[str]:
        return pulumi.get(self, "summary")


@pulumi.output_type
class SqlEndpointHealthFailureReason(dict):
    def __init__(__self__, *,
                 code: Optional[str] = None,
                 parameters: Optional[Mapping[str, str]] = None,
                 type: Optional[str] = None):
        if code is not None:
            pulumi.set(__self__, "code", code)
        if parameters is not None:
            pulumi.set(__self__, "parameters", parameters)
        if type is not None:
            pulumi.set(__self__, "type", type)

    @property
    @pulumi.getter
    def code(self) -> Optional[str]:
        return pulumi.get(self, "code")

    @property
    @pulumi.getter
    def parameters(self) -> Optional[Mapping[str, str]]:
        return pulumi.get(self, "parameters")

    @property
    @pulumi.getter
    def type(self) -> Optional[str]:
        return pulumi.get(self, "type")


@pulumi.output_type
class SqlEndpointOdbcParams(dict):
    def __init__(__self__, *,
                 hostname: Optional[str] = None,
                 path: Optional[str] = None,
                 port: Optional[int] = None,
                 protocol: Optional[str] = None):
        if hostname is not None:
            pulumi.set(__self__, "hostname", hostname)
        if path is not None:
            pulumi.set(__self__, "path", path)
        if port is not None:
            pulumi.set(__self__, "port", port)
        if protocol is not None:
            pulumi.set(__self__, "protocol", protocol)

    @property
    @pulumi.getter
    def hostname(self) -> Optional[str]:
        return pulumi.get(self, "hostname")

    @property
    @pulumi.getter
    def path(self) -> Optional[str]:
        return pulumi.get(self, "path")

    @property
    @pulumi.getter
    def port(self) -> Optional[int]:
        return pulumi.get(self, "port")

    @property
    @pulumi.getter
    def protocol(self) -> Optional[str]:
        return pulumi.get(self, "protocol")


@pulumi.output_type
class SqlEndpointTags(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "customTags":
            suggest = "custom_tags"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in SqlEndpointTags. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        SqlEndpointTags.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        SqlEndpointTags.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 custom_tags: Optional[Sequence['outputs.SqlEndpointTagsCustomTag']] = None):
        if custom_tags is not None:
            pulumi.set(__self__, "custom_tags", custom_tags)

    @property
    @pulumi.getter(name="customTags")
    def custom_tags(self) -> Optional[Sequence['outputs.SqlEndpointTagsCustomTag']]:
        return pulumi.get(self, "custom_tags")


@pulumi.output_type
class SqlEndpointTagsCustomTag(dict):
    def __init__(__self__, *,
                 key: str,
                 value: str):
        pulumi.set(__self__, "key", key)
        pulumi.set(__self__, "value", value)

    @property
    @pulumi.getter
    def key(self) -> str:
        return pulumi.get(self, "key")

    @property
    @pulumi.getter
    def value(self) -> str:
        return pulumi.get(self, "value")


@pulumi.output_type
class SqlPermissionsPrivilegeAssignment(dict):
    def __init__(__self__, *,
                 principal: str,
                 privileges: Sequence[str]):
        """
        :param str principal: `display_name` for a Group or databricks_user, `application_id` for a databricks_service_principal.
        """
        pulumi.set(__self__, "principal", principal)
        pulumi.set(__self__, "privileges", privileges)

    @property
    @pulumi.getter
    def principal(self) -> str:
        """
        `display_name` for a Group or databricks_user, `application_id` for a databricks_service_principal.
        """
        return pulumi.get(self, "principal")

    @property
    @pulumi.getter
    def privileges(self) -> Sequence[str]:
        return pulumi.get(self, "privileges")


@pulumi.output_type
class SqlQueryParameter(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "dateRange":
            suggest = "date_range"
        elif key == "datetimeRange":
            suggest = "datetime_range"
        elif key == "datetimesecRange":
            suggest = "datetimesec_range"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in SqlQueryParameter. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        SqlQueryParameter.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        SqlQueryParameter.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 name: str,
                 date: Optional['outputs.SqlQueryParameterDate'] = None,
                 date_range: Optional['outputs.SqlQueryParameterDateRange'] = None,
                 datetime: Optional['outputs.SqlQueryParameterDatetime'] = None,
                 datetime_range: Optional['outputs.SqlQueryParameterDatetimeRange'] = None,
                 datetimesec: Optional['outputs.SqlQueryParameterDatetimesec'] = None,
                 datetimesec_range: Optional['outputs.SqlQueryParameterDatetimesecRange'] = None,
                 enum: Optional['outputs.SqlQueryParameterEnum'] = None,
                 number: Optional['outputs.SqlQueryParameterNumber'] = None,
                 query: Optional['outputs.SqlQueryParameterQuery'] = None,
                 text: Optional['outputs.SqlQueryParameterText'] = None,
                 title: Optional[str] = None):
        """
        :param str name: The literal parameter marker that appears between double curly braces in the query text.
               Parameters can have several different types. Type is specified using one of the following configuration blocks: `text`, `number`, `enum`, `query`, `date`, `datetime`, `datetimesec`, `date_range`, `datetime_range`, `datetimesec_range`.
               
               For `text`, `number`, `date`, `datetime`, `datetimesec` block
        :param 'SqlQueryParameterQueryArgs' query: The text of the query to be run.
        :param str title: The text displayed in a parameter picking widget.
        """
        pulumi.set(__self__, "name", name)
        if date is not None:
            pulumi.set(__self__, "date", date)
        if date_range is not None:
            pulumi.set(__self__, "date_range", date_range)
        if datetime is not None:
            pulumi.set(__self__, "datetime", datetime)
        if datetime_range is not None:
            pulumi.set(__self__, "datetime_range", datetime_range)
        if datetimesec is not None:
            pulumi.set(__self__, "datetimesec", datetimesec)
        if datetimesec_range is not None:
            pulumi.set(__self__, "datetimesec_range", datetimesec_range)
        if enum is not None:
            pulumi.set(__self__, "enum", enum)
        if number is not None:
            pulumi.set(__self__, "number", number)
        if query is not None:
            pulumi.set(__self__, "query", query)
        if text is not None:
            pulumi.set(__self__, "text", text)
        if title is not None:
            pulumi.set(__self__, "title", title)

    @property
    @pulumi.getter
    def name(self) -> str:
        """
        The literal parameter marker that appears between double curly braces in the query text.
        Parameters can have several different types. Type is specified using one of the following configuration blocks: `text`, `number`, `enum`, `query`, `date`, `datetime`, `datetimesec`, `date_range`, `datetime_range`, `datetimesec_range`.

        For `text`, `number`, `date`, `datetime`, `datetimesec` block
        """
        return pulumi.get(self, "name")

    @property
    @pulumi.getter
    def date(self) -> Optional['outputs.SqlQueryParameterDate']:
        return pulumi.get(self, "date")

    @property
    @pulumi.getter(name="dateRange")
    def date_range(self) -> Optional['outputs.SqlQueryParameterDateRange']:
        return pulumi.get(self, "date_range")

    @property
    @pulumi.getter
    def datetime(self) -> Optional['outputs.SqlQueryParameterDatetime']:
        return pulumi.get(self, "datetime")

    @property
    @pulumi.getter(name="datetimeRange")
    def datetime_range(self) -> Optional['outputs.SqlQueryParameterDatetimeRange']:
        return pulumi.get(self, "datetime_range")

    @property
    @pulumi.getter
    def datetimesec(self) -> Optional['outputs.SqlQueryParameterDatetimesec']:
        return pulumi.get(self, "datetimesec")

    @property
    @pulumi.getter(name="datetimesecRange")
    def datetimesec_range(self) -> Optional['outputs.SqlQueryParameterDatetimesecRange']:
        return pulumi.get(self, "datetimesec_range")

    @property
    @pulumi.getter
    def enum(self) -> Optional['outputs.SqlQueryParameterEnum']:
        return pulumi.get(self, "enum")

    @property
    @pulumi.getter
    def number(self) -> Optional['outputs.SqlQueryParameterNumber']:
        return pulumi.get(self, "number")

    @property
    @pulumi.getter
    def query(self) -> Optional['outputs.SqlQueryParameterQuery']:
        """
        The text of the query to be run.
        """
        return pulumi.get(self, "query")

    @property
    @pulumi.getter
    def text(self) -> Optional['outputs.SqlQueryParameterText']:
        return pulumi.get(self, "text")

    @property
    @pulumi.getter
    def title(self) -> Optional[str]:
        """
        The text displayed in a parameter picking widget.
        """
        return pulumi.get(self, "title")


@pulumi.output_type
class SqlQueryParameterDate(dict):
    def __init__(__self__, *,
                 value: str):
        """
        :param str value: The default value for this parameter.
        """
        pulumi.set(__self__, "value", value)

    @property
    @pulumi.getter
    def value(self) -> str:
        """
        The default value for this parameter.
        """
        return pulumi.get(self, "value")


@pulumi.output_type
class SqlQueryParameterDateRange(dict):
    def __init__(__self__, *,
                 range: Optional['outputs.SqlQueryParameterDateRangeRange'] = None,
                 value: Optional[str] = None):
        """
        :param str value: The default value for this parameter.
        """
        if range is not None:
            pulumi.set(__self__, "range", range)
        if value is not None:
            pulumi.set(__self__, "value", value)

    @property
    @pulumi.getter
    def range(self) -> Optional['outputs.SqlQueryParameterDateRangeRange']:
        return pulumi.get(self, "range")

    @property
    @pulumi.getter
    def value(self) -> Optional[str]:
        """
        The default value for this parameter.
        """
        return pulumi.get(self, "value")


@pulumi.output_type
class SqlQueryParameterDateRangeRange(dict):
    def __init__(__self__, *,
                 end: str,
                 start: str):
        pulumi.set(__self__, "end", end)
        pulumi.set(__self__, "start", start)

    @property
    @pulumi.getter
    def end(self) -> str:
        return pulumi.get(self, "end")

    @property
    @pulumi.getter
    def start(self) -> str:
        return pulumi.get(self, "start")


@pulumi.output_type
class SqlQueryParameterDatetime(dict):
    def __init__(__self__, *,
                 value: str):
        """
        :param str value: The default value for this parameter.
        """
        pulumi.set(__self__, "value", value)

    @property
    @pulumi.getter
    def value(self) -> str:
        """
        The default value for this parameter.
        """
        return pulumi.get(self, "value")


@pulumi.output_type
class SqlQueryParameterDatetimeRange(dict):
    def __init__(__self__, *,
                 range: Optional['outputs.SqlQueryParameterDatetimeRangeRange'] = None,
                 value: Optional[str] = None):
        """
        :param str value: The default value for this parameter.
        """
        if range is not None:
            pulumi.set(__self__, "range", range)
        if value is not None:
            pulumi.set(__self__, "value", value)

    @property
    @pulumi.getter
    def range(self) -> Optional['outputs.SqlQueryParameterDatetimeRangeRange']:
        return pulumi.get(self, "range")

    @property
    @pulumi.getter
    def value(self) -> Optional[str]:
        """
        The default value for this parameter.
        """
        return pulumi.get(self, "value")


@pulumi.output_type
class SqlQueryParameterDatetimeRangeRange(dict):
    def __init__(__self__, *,
                 end: str,
                 start: str):
        pulumi.set(__self__, "end", end)
        pulumi.set(__self__, "start", start)

    @property
    @pulumi.getter
    def end(self) -> str:
        return pulumi.get(self, "end")

    @property
    @pulumi.getter
    def start(self) -> str:
        return pulumi.get(self, "start")


@pulumi.output_type
class SqlQueryParameterDatetimesec(dict):
    def __init__(__self__, *,
                 value: str):
        """
        :param str value: The default value for this parameter.
        """
        pulumi.set(__self__, "value", value)

    @property
    @pulumi.getter
    def value(self) -> str:
        """
        The default value for this parameter.
        """
        return pulumi.get(self, "value")


@pulumi.output_type
class SqlQueryParameterDatetimesecRange(dict):
    def __init__(__self__, *,
                 range: Optional['outputs.SqlQueryParameterDatetimesecRangeRange'] = None,
                 value: Optional[str] = None):
        """
        :param str value: The default value for this parameter.
        """
        if range is not None:
            pulumi.set(__self__, "range", range)
        if value is not None:
            pulumi.set(__self__, "value", value)

    @property
    @pulumi.getter
    def range(self) -> Optional['outputs.SqlQueryParameterDatetimesecRangeRange']:
        return pulumi.get(self, "range")

    @property
    @pulumi.getter
    def value(self) -> Optional[str]:
        """
        The default value for this parameter.
        """
        return pulumi.get(self, "value")


@pulumi.output_type
class SqlQueryParameterDatetimesecRangeRange(dict):
    def __init__(__self__, *,
                 end: str,
                 start: str):
        pulumi.set(__self__, "end", end)
        pulumi.set(__self__, "start", start)

    @property
    @pulumi.getter
    def end(self) -> str:
        return pulumi.get(self, "end")

    @property
    @pulumi.getter
    def start(self) -> str:
        return pulumi.get(self, "start")


@pulumi.output_type
class SqlQueryParameterEnum(dict):
    def __init__(__self__, *,
                 options: Sequence[str],
                 multiple: Optional['outputs.SqlQueryParameterEnumMultiple'] = None,
                 value: Optional[str] = None,
                 values: Optional[Sequence[str]] = None):
        """
        :param str value: The default value for this parameter.
        """
        pulumi.set(__self__, "options", options)
        if multiple is not None:
            pulumi.set(__self__, "multiple", multiple)
        if value is not None:
            pulumi.set(__self__, "value", value)
        if values is not None:
            pulumi.set(__self__, "values", values)

    @property
    @pulumi.getter
    def options(self) -> Sequence[str]:
        return pulumi.get(self, "options")

    @property
    @pulumi.getter
    def multiple(self) -> Optional['outputs.SqlQueryParameterEnumMultiple']:
        return pulumi.get(self, "multiple")

    @property
    @pulumi.getter
    def value(self) -> Optional[str]:
        """
        The default value for this parameter.
        """
        return pulumi.get(self, "value")

    @property
    @pulumi.getter
    def values(self) -> Optional[Sequence[str]]:
        return pulumi.get(self, "values")


@pulumi.output_type
class SqlQueryParameterEnumMultiple(dict):
    def __init__(__self__, *,
                 separator: str,
                 prefix: Optional[str] = None,
                 suffix: Optional[str] = None):
        pulumi.set(__self__, "separator", separator)
        if prefix is not None:
            pulumi.set(__self__, "prefix", prefix)
        if suffix is not None:
            pulumi.set(__self__, "suffix", suffix)

    @property
    @pulumi.getter
    def separator(self) -> str:
        return pulumi.get(self, "separator")

    @property
    @pulumi.getter
    def prefix(self) -> Optional[str]:
        return pulumi.get(self, "prefix")

    @property
    @pulumi.getter
    def suffix(self) -> Optional[str]:
        return pulumi.get(self, "suffix")


@pulumi.output_type
class SqlQueryParameterNumber(dict):
    def __init__(__self__, *,
                 value: float):
        """
        :param float value: The default value for this parameter.
        """
        pulumi.set(__self__, "value", value)

    @property
    @pulumi.getter
    def value(self) -> float:
        """
        The default value for this parameter.
        """
        return pulumi.get(self, "value")


@pulumi.output_type
class SqlQueryParameterQuery(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "queryId":
            suggest = "query_id"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in SqlQueryParameterQuery. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        SqlQueryParameterQuery.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        SqlQueryParameterQuery.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 query_id: str,
                 multiple: Optional['outputs.SqlQueryParameterQueryMultiple'] = None,
                 value: Optional[str] = None,
                 values: Optional[Sequence[str]] = None):
        """
        :param str value: The default value for this parameter.
        """
        pulumi.set(__self__, "query_id", query_id)
        if multiple is not None:
            pulumi.set(__self__, "multiple", multiple)
        if value is not None:
            pulumi.set(__self__, "value", value)
        if values is not None:
            pulumi.set(__self__, "values", values)

    @property
    @pulumi.getter(name="queryId")
    def query_id(self) -> str:
        return pulumi.get(self, "query_id")

    @property
    @pulumi.getter
    def multiple(self) -> Optional['outputs.SqlQueryParameterQueryMultiple']:
        return pulumi.get(self, "multiple")

    @property
    @pulumi.getter
    def value(self) -> Optional[str]:
        """
        The default value for this parameter.
        """
        return pulumi.get(self, "value")

    @property
    @pulumi.getter
    def values(self) -> Optional[Sequence[str]]:
        return pulumi.get(self, "values")


@pulumi.output_type
class SqlQueryParameterQueryMultiple(dict):
    def __init__(__self__, *,
                 separator: str,
                 prefix: Optional[str] = None,
                 suffix: Optional[str] = None):
        pulumi.set(__self__, "separator", separator)
        if prefix is not None:
            pulumi.set(__self__, "prefix", prefix)
        if suffix is not None:
            pulumi.set(__self__, "suffix", suffix)

    @property
    @pulumi.getter
    def separator(self) -> str:
        return pulumi.get(self, "separator")

    @property
    @pulumi.getter
    def prefix(self) -> Optional[str]:
        return pulumi.get(self, "prefix")

    @property
    @pulumi.getter
    def suffix(self) -> Optional[str]:
        return pulumi.get(self, "suffix")


@pulumi.output_type
class SqlQueryParameterText(dict):
    def __init__(__self__, *,
                 value: str):
        """
        :param str value: The default value for this parameter.
        """
        pulumi.set(__self__, "value", value)

    @property
    @pulumi.getter
    def value(self) -> str:
        """
        The default value for this parameter.
        """
        return pulumi.get(self, "value")


@pulumi.output_type
class SqlQuerySchedule(dict):
    def __init__(__self__, *,
                 continuous: Optional['outputs.SqlQueryScheduleContinuous'] = None,
                 daily: Optional['outputs.SqlQueryScheduleDaily'] = None,
                 weekly: Optional['outputs.SqlQueryScheduleWeekly'] = None):
        if continuous is not None:
            pulumi.set(__self__, "continuous", continuous)
        if daily is not None:
            pulumi.set(__self__, "daily", daily)
        if weekly is not None:
            pulumi.set(__self__, "weekly", weekly)

    @property
    @pulumi.getter
    def continuous(self) -> Optional['outputs.SqlQueryScheduleContinuous']:
        return pulumi.get(self, "continuous")

    @property
    @pulumi.getter
    def daily(self) -> Optional['outputs.SqlQueryScheduleDaily']:
        return pulumi.get(self, "daily")

    @property
    @pulumi.getter
    def weekly(self) -> Optional['outputs.SqlQueryScheduleWeekly']:
        return pulumi.get(self, "weekly")


@pulumi.output_type
class SqlQueryScheduleContinuous(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "intervalSeconds":
            suggest = "interval_seconds"
        elif key == "untilDate":
            suggest = "until_date"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in SqlQueryScheduleContinuous. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        SqlQueryScheduleContinuous.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        SqlQueryScheduleContinuous.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 interval_seconds: int,
                 until_date: Optional[str] = None):
        pulumi.set(__self__, "interval_seconds", interval_seconds)
        if until_date is not None:
            pulumi.set(__self__, "until_date", until_date)

    @property
    @pulumi.getter(name="intervalSeconds")
    def interval_seconds(self) -> int:
        return pulumi.get(self, "interval_seconds")

    @property
    @pulumi.getter(name="untilDate")
    def until_date(self) -> Optional[str]:
        return pulumi.get(self, "until_date")


@pulumi.output_type
class SqlQueryScheduleDaily(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "intervalDays":
            suggest = "interval_days"
        elif key == "timeOfDay":
            suggest = "time_of_day"
        elif key == "untilDate":
            suggest = "until_date"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in SqlQueryScheduleDaily. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        SqlQueryScheduleDaily.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        SqlQueryScheduleDaily.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 interval_days: int,
                 time_of_day: str,
                 until_date: Optional[str] = None):
        pulumi.set(__self__, "interval_days", interval_days)
        pulumi.set(__self__, "time_of_day", time_of_day)
        if until_date is not None:
            pulumi.set(__self__, "until_date", until_date)

    @property
    @pulumi.getter(name="intervalDays")
    def interval_days(self) -> int:
        return pulumi.get(self, "interval_days")

    @property
    @pulumi.getter(name="timeOfDay")
    def time_of_day(self) -> str:
        return pulumi.get(self, "time_of_day")

    @property
    @pulumi.getter(name="untilDate")
    def until_date(self) -> Optional[str]:
        return pulumi.get(self, "until_date")


@pulumi.output_type
class SqlQueryScheduleWeekly(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "dayOfWeek":
            suggest = "day_of_week"
        elif key == "intervalWeeks":
            suggest = "interval_weeks"
        elif key == "timeOfDay":
            suggest = "time_of_day"
        elif key == "untilDate":
            suggest = "until_date"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in SqlQueryScheduleWeekly. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        SqlQueryScheduleWeekly.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        SqlQueryScheduleWeekly.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 day_of_week: str,
                 interval_weeks: int,
                 time_of_day: str,
                 until_date: Optional[str] = None):
        pulumi.set(__self__, "day_of_week", day_of_week)
        pulumi.set(__self__, "interval_weeks", interval_weeks)
        pulumi.set(__self__, "time_of_day", time_of_day)
        if until_date is not None:
            pulumi.set(__self__, "until_date", until_date)

    @property
    @pulumi.getter(name="dayOfWeek")
    def day_of_week(self) -> str:
        return pulumi.get(self, "day_of_week")

    @property
    @pulumi.getter(name="intervalWeeks")
    def interval_weeks(self) -> int:
        return pulumi.get(self, "interval_weeks")

    @property
    @pulumi.getter(name="timeOfDay")
    def time_of_day(self) -> str:
        return pulumi.get(self, "time_of_day")

    @property
    @pulumi.getter(name="untilDate")
    def until_date(self) -> Optional[str]:
        return pulumi.get(self, "until_date")


@pulumi.output_type
class SqlTableColumn(dict):
    def __init__(__self__, *,
                 name: str,
                 comment: Optional[str] = None,
                 nullable: Optional[bool] = None,
                 type: Optional[str] = None):
        """
        :param str name: User-visible name of column
        :param str comment: User-supplied free-form text.
        :param bool nullable: Whether field is nullable (Default: `true`)
        :param str type: Column type spec (with metadata) as SQL text. Not supported for `VIEW` table_type.
        """
        pulumi.set(__self__, "name", name)
        if comment is not None:
            pulumi.set(__self__, "comment", comment)
        if nullable is not None:
            pulumi.set(__self__, "nullable", nullable)
        if type is not None:
            pulumi.set(__self__, "type", type)

    @property
    @pulumi.getter
    def name(self) -> str:
        """
        User-visible name of column
        """
        return pulumi.get(self, "name")

    @property
    @pulumi.getter
    def comment(self) -> Optional[str]:
        """
        User-supplied free-form text.
        """
        return pulumi.get(self, "comment")

    @property
    @pulumi.getter
    def nullable(self) -> Optional[bool]:
        """
        Whether field is nullable (Default: `true`)
        """
        return pulumi.get(self, "nullable")

    @property
    @pulumi.getter
    def type(self) -> Optional[str]:
        """
        Column type spec (with metadata) as SQL text. Not supported for `VIEW` table_type.
        """
        return pulumi.get(self, "type")


@pulumi.output_type
class SqlWidgetParameter(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "mapTo":
            suggest = "map_to"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in SqlWidgetParameter. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        SqlWidgetParameter.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        SqlWidgetParameter.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 name: str,
                 type: str,
                 map_to: Optional[str] = None,
                 title: Optional[str] = None,
                 value: Optional[str] = None,
                 values: Optional[Sequence[str]] = None):
        pulumi.set(__self__, "name", name)
        pulumi.set(__self__, "type", type)
        if map_to is not None:
            pulumi.set(__self__, "map_to", map_to)
        if title is not None:
            pulumi.set(__self__, "title", title)
        if value is not None:
            pulumi.set(__self__, "value", value)
        if values is not None:
            pulumi.set(__self__, "values", values)

    @property
    @pulumi.getter
    def name(self) -> str:
        return pulumi.get(self, "name")

    @property
    @pulumi.getter
    def type(self) -> str:
        return pulumi.get(self, "type")

    @property
    @pulumi.getter(name="mapTo")
    def map_to(self) -> Optional[str]:
        return pulumi.get(self, "map_to")

    @property
    @pulumi.getter
    def title(self) -> Optional[str]:
        return pulumi.get(self, "title")

    @property
    @pulumi.getter
    def value(self) -> Optional[str]:
        return pulumi.get(self, "value")

    @property
    @pulumi.getter
    def values(self) -> Optional[Sequence[str]]:
        return pulumi.get(self, "values")


@pulumi.output_type
class SqlWidgetPosition(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "sizeX":
            suggest = "size_x"
        elif key == "sizeY":
            suggest = "size_y"
        elif key == "autoHeight":
            suggest = "auto_height"
        elif key == "posX":
            suggest = "pos_x"
        elif key == "posY":
            suggest = "pos_y"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in SqlWidgetPosition. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        SqlWidgetPosition.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        SqlWidgetPosition.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 size_x: int,
                 size_y: int,
                 auto_height: Optional[bool] = None,
                 pos_x: Optional[int] = None,
                 pos_y: Optional[int] = None):
        pulumi.set(__self__, "size_x", size_x)
        pulumi.set(__self__, "size_y", size_y)
        if auto_height is not None:
            pulumi.set(__self__, "auto_height", auto_height)
        if pos_x is not None:
            pulumi.set(__self__, "pos_x", pos_x)
        if pos_y is not None:
            pulumi.set(__self__, "pos_y", pos_y)

    @property
    @pulumi.getter(name="sizeX")
    def size_x(self) -> int:
        return pulumi.get(self, "size_x")

    @property
    @pulumi.getter(name="sizeY")
    def size_y(self) -> int:
        return pulumi.get(self, "size_y")

    @property
    @pulumi.getter(name="autoHeight")
    def auto_height(self) -> Optional[bool]:
        return pulumi.get(self, "auto_height")

    @property
    @pulumi.getter(name="posX")
    def pos_x(self) -> Optional[int]:
        return pulumi.get(self, "pos_x")

    @property
    @pulumi.getter(name="posY")
    def pos_y(self) -> Optional[int]:
        return pulumi.get(self, "pos_y")


@pulumi.output_type
class StorageCredentialAwsIamRole(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "roleArn":
            suggest = "role_arn"
        elif key == "externalId":
            suggest = "external_id"
        elif key == "unityCatalogIamArn":
            suggest = "unity_catalog_iam_arn"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in StorageCredentialAwsIamRole. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        StorageCredentialAwsIamRole.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        StorageCredentialAwsIamRole.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 role_arn: str,
                 external_id: Optional[str] = None,
                 unity_catalog_iam_arn: Optional[str] = None):
        """
        :param str role_arn: The Amazon Resource Name (ARN) of the AWS IAM role for S3 data access, of the form `arn:aws:iam::1234567890:role/MyRole-AJJHDSKSDF`
               
               `azure_managed_identity` optional configuration block for using managed identity as credential details for Azure (recommended over service principal):
        """
        pulumi.set(__self__, "role_arn", role_arn)
        if external_id is not None:
            pulumi.set(__self__, "external_id", external_id)
        if unity_catalog_iam_arn is not None:
            pulumi.set(__self__, "unity_catalog_iam_arn", unity_catalog_iam_arn)

    @property
    @pulumi.getter(name="roleArn")
    def role_arn(self) -> str:
        """
        The Amazon Resource Name (ARN) of the AWS IAM role for S3 data access, of the form `arn:aws:iam::1234567890:role/MyRole-AJJHDSKSDF`

        `azure_managed_identity` optional configuration block for using managed identity as credential details for Azure (recommended over service principal):
        """
        return pulumi.get(self, "role_arn")

    @property
    @pulumi.getter(name="externalId")
    def external_id(self) -> Optional[str]:
        return pulumi.get(self, "external_id")

    @property
    @pulumi.getter(name="unityCatalogIamArn")
    def unity_catalog_iam_arn(self) -> Optional[str]:
        return pulumi.get(self, "unity_catalog_iam_arn")


@pulumi.output_type
class StorageCredentialAzureManagedIdentity(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "accessConnectorId":
            suggest = "access_connector_id"
        elif key == "credentialId":
            suggest = "credential_id"
        elif key == "managedIdentityId":
            suggest = "managed_identity_id"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in StorageCredentialAzureManagedIdentity. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        StorageCredentialAzureManagedIdentity.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        StorageCredentialAzureManagedIdentity.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 access_connector_id: str,
                 credential_id: Optional[str] = None,
                 managed_identity_id: Optional[str] = None):
        """
        :param str access_connector_id: The Resource ID of the Azure Databricks Access Connector resource, of the form `/subscriptions/00000000-0000-0000-0000-000000000000/resourceGroups/rg-name/providers/Microsoft.Databricks/accessConnectors/connector-name`.
        :param str managed_identity_id: The Resource ID of the Azure User Assigned Managed Identity associated with Azure Databricks Access Connector, of the form `/subscriptions/00000000-0000-0000-0000-000000000000/resourceGroups/rg-name/providers/Microsoft.ManagedIdentity/userAssignedIdentities/user-managed-identity-name`.
               
               `databricks_gcp_service_account` optional configuration block for creating a Databricks-managed GCP Service Account:
        """
        pulumi.set(__self__, "access_connector_id", access_connector_id)
        if credential_id is not None:
            pulumi.set(__self__, "credential_id", credential_id)
        if managed_identity_id is not None:
            pulumi.set(__self__, "managed_identity_id", managed_identity_id)

    @property
    @pulumi.getter(name="accessConnectorId")
    def access_connector_id(self) -> str:
        """
        The Resource ID of the Azure Databricks Access Connector resource, of the form `/subscriptions/00000000-0000-0000-0000-000000000000/resourceGroups/rg-name/providers/Microsoft.Databricks/accessConnectors/connector-name`.
        """
        return pulumi.get(self, "access_connector_id")

    @property
    @pulumi.getter(name="credentialId")
    def credential_id(self) -> Optional[str]:
        return pulumi.get(self, "credential_id")

    @property
    @pulumi.getter(name="managedIdentityId")
    def managed_identity_id(self) -> Optional[str]:
        """
        The Resource ID of the Azure User Assigned Managed Identity associated with Azure Databricks Access Connector, of the form `/subscriptions/00000000-0000-0000-0000-000000000000/resourceGroups/rg-name/providers/Microsoft.ManagedIdentity/userAssignedIdentities/user-managed-identity-name`.

        `databricks_gcp_service_account` optional configuration block for creating a Databricks-managed GCP Service Account:
        """
        return pulumi.get(self, "managed_identity_id")


@pulumi.output_type
class StorageCredentialAzureServicePrincipal(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "applicationId":
            suggest = "application_id"
        elif key == "clientSecret":
            suggest = "client_secret"
        elif key == "directoryId":
            suggest = "directory_id"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in StorageCredentialAzureServicePrincipal. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        StorageCredentialAzureServicePrincipal.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        StorageCredentialAzureServicePrincipal.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 application_id: str,
                 client_secret: str,
                 directory_id: str):
        """
        :param str application_id: The application ID of the application registration within the referenced AAD tenant
        :param str client_secret: The client secret generated for the above app ID in AAD. **This field is redacted on output**
        :param str directory_id: The directory ID corresponding to the Azure Active Directory (AAD) tenant of the application
        """
        pulumi.set(__self__, "application_id", application_id)
        pulumi.set(__self__, "client_secret", client_secret)
        pulumi.set(__self__, "directory_id", directory_id)

    @property
    @pulumi.getter(name="applicationId")
    def application_id(self) -> str:
        """
        The application ID of the application registration within the referenced AAD tenant
        """
        return pulumi.get(self, "application_id")

    @property
    @pulumi.getter(name="clientSecret")
    def client_secret(self) -> str:
        """
        The client secret generated for the above app ID in AAD. **This field is redacted on output**
        """
        return pulumi.get(self, "client_secret")

    @property
    @pulumi.getter(name="directoryId")
    def directory_id(self) -> str:
        """
        The directory ID corresponding to the Azure Active Directory (AAD) tenant of the application
        """
        return pulumi.get(self, "directory_id")


@pulumi.output_type
class StorageCredentialCloudflareApiToken(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "accessKeyId":
            suggest = "access_key_id"
        elif key == "accountId":
            suggest = "account_id"
        elif key == "secretAccessKey":
            suggest = "secret_access_key"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in StorageCredentialCloudflareApiToken. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        StorageCredentialCloudflareApiToken.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        StorageCredentialCloudflareApiToken.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 access_key_id: str,
                 account_id: str,
                 secret_access_key: str):
        """
        :param str access_key_id: R2 API token access key ID
        :param str account_id: R2 account ID
        :param str secret_access_key: R2 API token secret access key
               
               `azure_service_principal` optional configuration block to use service principal as credential details for Azure (Legacy):
        """
        pulumi.set(__self__, "access_key_id", access_key_id)
        pulumi.set(__self__, "account_id", account_id)
        pulumi.set(__self__, "secret_access_key", secret_access_key)

    @property
    @pulumi.getter(name="accessKeyId")
    def access_key_id(self) -> str:
        """
        R2 API token access key ID
        """
        return pulumi.get(self, "access_key_id")

    @property
    @pulumi.getter(name="accountId")
    def account_id(self) -> str:
        """
        R2 account ID
        """
        return pulumi.get(self, "account_id")

    @property
    @pulumi.getter(name="secretAccessKey")
    def secret_access_key(self) -> str:
        """
        R2 API token secret access key

        `azure_service_principal` optional configuration block to use service principal as credential details for Azure (Legacy):
        """
        return pulumi.get(self, "secret_access_key")


@pulumi.output_type
class StorageCredentialDatabricksGcpServiceAccount(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "credentialId":
            suggest = "credential_id"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in StorageCredentialDatabricksGcpServiceAccount. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        StorageCredentialDatabricksGcpServiceAccount.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        StorageCredentialDatabricksGcpServiceAccount.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 credential_id: Optional[str] = None,
                 email: Optional[str] = None):
        """
        :param str email: The email of the GCP service account created, to be granted access to relevant buckets.
               
               `cloudflare_api_token` optional configuration block for using a Cloudflare API Token as credential details. This requires account admin access:
        """
        if credential_id is not None:
            pulumi.set(__self__, "credential_id", credential_id)
        if email is not None:
            pulumi.set(__self__, "email", email)

    @property
    @pulumi.getter(name="credentialId")
    def credential_id(self) -> Optional[str]:
        return pulumi.get(self, "credential_id")

    @property
    @pulumi.getter
    def email(self) -> Optional[str]:
        """
        The email of the GCP service account created, to be granted access to relevant buckets.

        `cloudflare_api_token` optional configuration block for using a Cloudflare API Token as credential details. This requires account admin access:
        """
        return pulumi.get(self, "email")


@pulumi.output_type
class StorageCredentialGcpServiceAccountKey(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "privateKey":
            suggest = "private_key"
        elif key == "privateKeyId":
            suggest = "private_key_id"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in StorageCredentialGcpServiceAccountKey. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        StorageCredentialGcpServiceAccountKey.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        StorageCredentialGcpServiceAccountKey.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 email: str,
                 private_key: str,
                 private_key_id: str):
        """
        :param str email: The email of the GCP service account created, to be granted access to relevant buckets.
               
               `cloudflare_api_token` optional configuration block for using a Cloudflare API Token as credential details. This requires account admin access:
        """
        pulumi.set(__self__, "email", email)
        pulumi.set(__self__, "private_key", private_key)
        pulumi.set(__self__, "private_key_id", private_key_id)

    @property
    @pulumi.getter
    def email(self) -> str:
        """
        The email of the GCP service account created, to be granted access to relevant buckets.

        `cloudflare_api_token` optional configuration block for using a Cloudflare API Token as credential details. This requires account admin access:
        """
        return pulumi.get(self, "email")

    @property
    @pulumi.getter(name="privateKey")
    def private_key(self) -> str:
        return pulumi.get(self, "private_key")

    @property
    @pulumi.getter(name="privateKeyId")
    def private_key_id(self) -> str:
        return pulumi.get(self, "private_key_id")


@pulumi.output_type
class TableColumn(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "typeName":
            suggest = "type_name"
        elif key == "typeText":
            suggest = "type_text"
        elif key == "partitionIndex":
            suggest = "partition_index"
        elif key == "typeIntervalType":
            suggest = "type_interval_type"
        elif key == "typeJson":
            suggest = "type_json"
        elif key == "typePrecision":
            suggest = "type_precision"
        elif key == "typeScale":
            suggest = "type_scale"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in TableColumn. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        TableColumn.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        TableColumn.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 name: str,
                 position: int,
                 type_name: str,
                 type_text: str,
                 comment: Optional[str] = None,
                 nullable: Optional[bool] = None,
                 partition_index: Optional[int] = None,
                 type_interval_type: Optional[str] = None,
                 type_json: Optional[str] = None,
                 type_precision: Optional[int] = None,
                 type_scale: Optional[int] = None):
        pulumi.set(__self__, "name", name)
        pulumi.set(__self__, "position", position)
        pulumi.set(__self__, "type_name", type_name)
        pulumi.set(__self__, "type_text", type_text)
        if comment is not None:
            pulumi.set(__self__, "comment", comment)
        if nullable is not None:
            pulumi.set(__self__, "nullable", nullable)
        if partition_index is not None:
            pulumi.set(__self__, "partition_index", partition_index)
        if type_interval_type is not None:
            pulumi.set(__self__, "type_interval_type", type_interval_type)
        if type_json is not None:
            pulumi.set(__self__, "type_json", type_json)
        if type_precision is not None:
            pulumi.set(__self__, "type_precision", type_precision)
        if type_scale is not None:
            pulumi.set(__self__, "type_scale", type_scale)

    @property
    @pulumi.getter
    def name(self) -> str:
        return pulumi.get(self, "name")

    @property
    @pulumi.getter
    def position(self) -> int:
        return pulumi.get(self, "position")

    @property
    @pulumi.getter(name="typeName")
    def type_name(self) -> str:
        return pulumi.get(self, "type_name")

    @property
    @pulumi.getter(name="typeText")
    def type_text(self) -> str:
        return pulumi.get(self, "type_text")

    @property
    @pulumi.getter
    def comment(self) -> Optional[str]:
        return pulumi.get(self, "comment")

    @property
    @pulumi.getter
    def nullable(self) -> Optional[bool]:
        return pulumi.get(self, "nullable")

    @property
    @pulumi.getter(name="partitionIndex")
    def partition_index(self) -> Optional[int]:
        return pulumi.get(self, "partition_index")

    @property
    @pulumi.getter(name="typeIntervalType")
    def type_interval_type(self) -> Optional[str]:
        return pulumi.get(self, "type_interval_type")

    @property
    @pulumi.getter(name="typeJson")
    def type_json(self) -> Optional[str]:
        return pulumi.get(self, "type_json")

    @property
    @pulumi.getter(name="typePrecision")
    def type_precision(self) -> Optional[int]:
        return pulumi.get(self, "type_precision")

    @property
    @pulumi.getter(name="typeScale")
    def type_scale(self) -> Optional[int]:
        return pulumi.get(self, "type_scale")


@pulumi.output_type
class VectorSearchEndpointEndpointStatus(dict):
    def __init__(__self__, *,
                 message: Optional[str] = None,
                 state: Optional[str] = None):
        """
        :param str message: Additional status message.
        :param str state: Current state of the endpoint. Currently following values are supported: `PROVISIONING`, `ONLINE`, and `OFFLINE`.
        """
        if message is not None:
            pulumi.set(__self__, "message", message)
        if state is not None:
            pulumi.set(__self__, "state", state)

    @property
    @pulumi.getter
    def message(self) -> Optional[str]:
        """
        Additional status message.
        """
        return pulumi.get(self, "message")

    @property
    @pulumi.getter
    def state(self) -> Optional[str]:
        """
        Current state of the endpoint. Currently following values are supported: `PROVISIONING`, `ONLINE`, and `OFFLINE`.
        """
        return pulumi.get(self, "state")


@pulumi.output_type
class VectorSearchIndexDeltaSyncIndexSpec(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "embeddingSourceColumns":
            suggest = "embedding_source_columns"
        elif key == "embeddingVectorColumns":
            suggest = "embedding_vector_columns"
        elif key == "embeddingWritebackTable":
            suggest = "embedding_writeback_table"
        elif key == "pipelineId":
            suggest = "pipeline_id"
        elif key == "pipelineType":
            suggest = "pipeline_type"
        elif key == "sourceTable":
            suggest = "source_table"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in VectorSearchIndexDeltaSyncIndexSpec. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        VectorSearchIndexDeltaSyncIndexSpec.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        VectorSearchIndexDeltaSyncIndexSpec.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 embedding_source_columns: Optional[Sequence['outputs.VectorSearchIndexDeltaSyncIndexSpecEmbeddingSourceColumn']] = None,
                 embedding_vector_columns: Optional[Sequence['outputs.VectorSearchIndexDeltaSyncIndexSpecEmbeddingVectorColumn']] = None,
                 embedding_writeback_table: Optional[str] = None,
                 pipeline_id: Optional[str] = None,
                 pipeline_type: Optional[str] = None,
                 source_table: Optional[str] = None):
        """
        :param Sequence['VectorSearchIndexDeltaSyncIndexSpecEmbeddingSourceColumnArgs'] embedding_source_columns: array of objects representing columns that contain the embedding source.  Each entry consists of:
        :param str pipeline_id: ID of the associated Delta Live Table pipeline.
        :param str pipeline_type: Pipeline execution mode. Possible values are:
               * `TRIGGERED`: If the pipeline uses the triggered execution mode, the system stops processing after successfully refreshing the source table in the pipeline once, ensuring the table is updated based on the data available when the update started.
               * `CONTINUOUS`: If the pipeline uses continuous execution, the pipeline processes new data as it arrives in the source table to keep the vector index fresh.
        :param str source_table: The name of the source table.
        """
        if embedding_source_columns is not None:
            pulumi.set(__self__, "embedding_source_columns", embedding_source_columns)
        if embedding_vector_columns is not None:
            pulumi.set(__self__, "embedding_vector_columns", embedding_vector_columns)
        if embedding_writeback_table is not None:
            pulumi.set(__self__, "embedding_writeback_table", embedding_writeback_table)
        if pipeline_id is not None:
            pulumi.set(__self__, "pipeline_id", pipeline_id)
        if pipeline_type is not None:
            pulumi.set(__self__, "pipeline_type", pipeline_type)
        if source_table is not None:
            pulumi.set(__self__, "source_table", source_table)

    @property
    @pulumi.getter(name="embeddingSourceColumns")
    def embedding_source_columns(self) -> Optional[Sequence['outputs.VectorSearchIndexDeltaSyncIndexSpecEmbeddingSourceColumn']]:
        """
        array of objects representing columns that contain the embedding source.  Each entry consists of:
        """
        return pulumi.get(self, "embedding_source_columns")

    @property
    @pulumi.getter(name="embeddingVectorColumns")
    def embedding_vector_columns(self) -> Optional[Sequence['outputs.VectorSearchIndexDeltaSyncIndexSpecEmbeddingVectorColumn']]:
        return pulumi.get(self, "embedding_vector_columns")

    @property
    @pulumi.getter(name="embeddingWritebackTable")
    def embedding_writeback_table(self) -> Optional[str]:
        return pulumi.get(self, "embedding_writeback_table")

    @property
    @pulumi.getter(name="pipelineId")
    def pipeline_id(self) -> Optional[str]:
        """
        ID of the associated Delta Live Table pipeline.
        """
        return pulumi.get(self, "pipeline_id")

    @property
    @pulumi.getter(name="pipelineType")
    def pipeline_type(self) -> Optional[str]:
        """
        Pipeline execution mode. Possible values are:
        * `TRIGGERED`: If the pipeline uses the triggered execution mode, the system stops processing after successfully refreshing the source table in the pipeline once, ensuring the table is updated based on the data available when the update started.
        * `CONTINUOUS`: If the pipeline uses continuous execution, the pipeline processes new data as it arrives in the source table to keep the vector index fresh.
        """
        return pulumi.get(self, "pipeline_type")

    @property
    @pulumi.getter(name="sourceTable")
    def source_table(self) -> Optional[str]:
        """
        The name of the source table.
        """
        return pulumi.get(self, "source_table")


@pulumi.output_type
class VectorSearchIndexDeltaSyncIndexSpecEmbeddingSourceColumn(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "embeddingModelEndpointName":
            suggest = "embedding_model_endpoint_name"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in VectorSearchIndexDeltaSyncIndexSpecEmbeddingSourceColumn. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        VectorSearchIndexDeltaSyncIndexSpecEmbeddingSourceColumn.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        VectorSearchIndexDeltaSyncIndexSpecEmbeddingSourceColumn.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 embedding_model_endpoint_name: Optional[str] = None,
                 name: Optional[str] = None):
        """
        :param str name: Three-level name of the Vector Search Index to create (`catalog.schema.index_name`).
        """
        if embedding_model_endpoint_name is not None:
            pulumi.set(__self__, "embedding_model_endpoint_name", embedding_model_endpoint_name)
        if name is not None:
            pulumi.set(__self__, "name", name)

    @property
    @pulumi.getter(name="embeddingModelEndpointName")
    def embedding_model_endpoint_name(self) -> Optional[str]:
        return pulumi.get(self, "embedding_model_endpoint_name")

    @property
    @pulumi.getter
    def name(self) -> Optional[str]:
        """
        Three-level name of the Vector Search Index to create (`catalog.schema.index_name`).
        """
        return pulumi.get(self, "name")


@pulumi.output_type
class VectorSearchIndexDeltaSyncIndexSpecEmbeddingVectorColumn(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "embeddingDimension":
            suggest = "embedding_dimension"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in VectorSearchIndexDeltaSyncIndexSpecEmbeddingVectorColumn. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        VectorSearchIndexDeltaSyncIndexSpecEmbeddingVectorColumn.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        VectorSearchIndexDeltaSyncIndexSpecEmbeddingVectorColumn.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 embedding_dimension: Optional[int] = None,
                 name: Optional[str] = None):
        """
        :param str name: Three-level name of the Vector Search Index to create (`catalog.schema.index_name`).
        """
        if embedding_dimension is not None:
            pulumi.set(__self__, "embedding_dimension", embedding_dimension)
        if name is not None:
            pulumi.set(__self__, "name", name)

    @property
    @pulumi.getter(name="embeddingDimension")
    def embedding_dimension(self) -> Optional[int]:
        return pulumi.get(self, "embedding_dimension")

    @property
    @pulumi.getter
    def name(self) -> Optional[str]:
        """
        Three-level name of the Vector Search Index to create (`catalog.schema.index_name`).
        """
        return pulumi.get(self, "name")


@pulumi.output_type
class VectorSearchIndexDirectAccessIndexSpec(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "embeddingSourceColumns":
            suggest = "embedding_source_columns"
        elif key == "embeddingVectorColumns":
            suggest = "embedding_vector_columns"
        elif key == "schemaJson":
            suggest = "schema_json"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in VectorSearchIndexDirectAccessIndexSpec. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        VectorSearchIndexDirectAccessIndexSpec.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        VectorSearchIndexDirectAccessIndexSpec.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 embedding_source_columns: Optional[Sequence['outputs.VectorSearchIndexDirectAccessIndexSpecEmbeddingSourceColumn']] = None,
                 embedding_vector_columns: Optional[Sequence['outputs.VectorSearchIndexDirectAccessIndexSpecEmbeddingVectorColumn']] = None,
                 schema_json: Optional[str] = None):
        """
        :param Sequence['VectorSearchIndexDirectAccessIndexSpecEmbeddingSourceColumnArgs'] embedding_source_columns: array of objects representing columns that contain the embedding source.  Each entry consists of:
        :param str schema_json: The schema of the index in JSON format.  Check the [API documentation](https://docs.databricks.com/api/workspace/vectorsearchindexes/createindex#direct_access_index_spec-schema_json) for a list of supported data types.
        """
        if embedding_source_columns is not None:
            pulumi.set(__self__, "embedding_source_columns", embedding_source_columns)
        if embedding_vector_columns is not None:
            pulumi.set(__self__, "embedding_vector_columns", embedding_vector_columns)
        if schema_json is not None:
            pulumi.set(__self__, "schema_json", schema_json)

    @property
    @pulumi.getter(name="embeddingSourceColumns")
    def embedding_source_columns(self) -> Optional[Sequence['outputs.VectorSearchIndexDirectAccessIndexSpecEmbeddingSourceColumn']]:
        """
        array of objects representing columns that contain the embedding source.  Each entry consists of:
        """
        return pulumi.get(self, "embedding_source_columns")

    @property
    @pulumi.getter(name="embeddingVectorColumns")
    def embedding_vector_columns(self) -> Optional[Sequence['outputs.VectorSearchIndexDirectAccessIndexSpecEmbeddingVectorColumn']]:
        return pulumi.get(self, "embedding_vector_columns")

    @property
    @pulumi.getter(name="schemaJson")
    def schema_json(self) -> Optional[str]:
        """
        The schema of the index in JSON format.  Check the [API documentation](https://docs.databricks.com/api/workspace/vectorsearchindexes/createindex#direct_access_index_spec-schema_json) for a list of supported data types.
        """
        return pulumi.get(self, "schema_json")


@pulumi.output_type
class VectorSearchIndexDirectAccessIndexSpecEmbeddingSourceColumn(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "embeddingModelEndpointName":
            suggest = "embedding_model_endpoint_name"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in VectorSearchIndexDirectAccessIndexSpecEmbeddingSourceColumn. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        VectorSearchIndexDirectAccessIndexSpecEmbeddingSourceColumn.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        VectorSearchIndexDirectAccessIndexSpecEmbeddingSourceColumn.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 embedding_model_endpoint_name: Optional[str] = None,
                 name: Optional[str] = None):
        """
        :param str name: Three-level name of the Vector Search Index to create (`catalog.schema.index_name`).
        """
        if embedding_model_endpoint_name is not None:
            pulumi.set(__self__, "embedding_model_endpoint_name", embedding_model_endpoint_name)
        if name is not None:
            pulumi.set(__self__, "name", name)

    @property
    @pulumi.getter(name="embeddingModelEndpointName")
    def embedding_model_endpoint_name(self) -> Optional[str]:
        return pulumi.get(self, "embedding_model_endpoint_name")

    @property
    @pulumi.getter
    def name(self) -> Optional[str]:
        """
        Three-level name of the Vector Search Index to create (`catalog.schema.index_name`).
        """
        return pulumi.get(self, "name")


@pulumi.output_type
class VectorSearchIndexDirectAccessIndexSpecEmbeddingVectorColumn(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "embeddingDimension":
            suggest = "embedding_dimension"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in VectorSearchIndexDirectAccessIndexSpecEmbeddingVectorColumn. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        VectorSearchIndexDirectAccessIndexSpecEmbeddingVectorColumn.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        VectorSearchIndexDirectAccessIndexSpecEmbeddingVectorColumn.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 embedding_dimension: Optional[int] = None,
                 name: Optional[str] = None):
        """
        :param str name: Three-level name of the Vector Search Index to create (`catalog.schema.index_name`).
        """
        if embedding_dimension is not None:
            pulumi.set(__self__, "embedding_dimension", embedding_dimension)
        if name is not None:
            pulumi.set(__self__, "name", name)

    @property
    @pulumi.getter(name="embeddingDimension")
    def embedding_dimension(self) -> Optional[int]:
        return pulumi.get(self, "embedding_dimension")

    @property
    @pulumi.getter
    def name(self) -> Optional[str]:
        """
        Three-level name of the Vector Search Index to create (`catalog.schema.index_name`).
        """
        return pulumi.get(self, "name")


@pulumi.output_type
class VectorSearchIndexStatus(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "indexUrl":
            suggest = "index_url"
        elif key == "indexedRowCount":
            suggest = "indexed_row_count"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in VectorSearchIndexStatus. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        VectorSearchIndexStatus.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        VectorSearchIndexStatus.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 index_url: Optional[str] = None,
                 indexed_row_count: Optional[int] = None,
                 message: Optional[str] = None,
                 ready: Optional[bool] = None):
        """
        :param str index_url: Index API Url to be used to perform operations on the index
        :param int indexed_row_count: Number of rows indexed
        :param str message: Message associated with the index status
        :param bool ready: Whether the index is ready for search
        """
        if index_url is not None:
            pulumi.set(__self__, "index_url", index_url)
        if indexed_row_count is not None:
            pulumi.set(__self__, "indexed_row_count", indexed_row_count)
        if message is not None:
            pulumi.set(__self__, "message", message)
        if ready is not None:
            pulumi.set(__self__, "ready", ready)

    @property
    @pulumi.getter(name="indexUrl")
    def index_url(self) -> Optional[str]:
        """
        Index API Url to be used to perform operations on the index
        """
        return pulumi.get(self, "index_url")

    @property
    @pulumi.getter(name="indexedRowCount")
    def indexed_row_count(self) -> Optional[int]:
        """
        Number of rows indexed
        """
        return pulumi.get(self, "indexed_row_count")

    @property
    @pulumi.getter
    def message(self) -> Optional[str]:
        """
        Message associated with the index status
        """
        return pulumi.get(self, "message")

    @property
    @pulumi.getter
    def ready(self) -> Optional[bool]:
        """
        Whether the index is ready for search
        """
        return pulumi.get(self, "ready")


@pulumi.output_type
class GetCatalogCatalogInfoResult(dict):
    def __init__(__self__, *,
                 browse_only: Optional[bool] = None,
                 catalog_type: Optional[str] = None,
                 comment: Optional[str] = None,
                 connection_name: Optional[str] = None,
                 created_at: Optional[int] = None,
                 created_by: Optional[str] = None,
                 effective_predictive_optimization_flag: Optional['outputs.GetCatalogCatalogInfoEffectivePredictiveOptimizationFlagResult'] = None,
                 enable_predictive_optimization: Optional[str] = None,
                 full_name: Optional[str] = None,
                 isolation_mode: Optional[str] = None,
                 metastore_id: Optional[str] = None,
                 name: Optional[str] = None,
                 options: Optional[Mapping[str, str]] = None,
                 owner: Optional[str] = None,
                 properties: Optional[Mapping[str, str]] = None,
                 provider_name: Optional[str] = None,
                 provisioning_info: Optional['outputs.GetCatalogCatalogInfoProvisioningInfoResult'] = None,
                 securable_kind: Optional[str] = None,
                 securable_type: Optional[str] = None,
                 share_name: Optional[str] = None,
                 storage_location: Optional[str] = None,
                 storage_root: Optional[str] = None,
                 updated_at: Optional[int] = None,
                 updated_by: Optional[str] = None):
        """
        :param str catalog_type: Type of the catalog, e.g. `MANAGED_CATALOG`, `DELTASHARING_CATALOG`, `SYSTEM_CATALOG`,
        :param str comment: Free-form text description
        :param str connection_name: The name of the connection to an external data source.
        :param int created_at: Time at which this catalog was created, in epoch milliseconds.
        :param str created_by: Username of catalog creator.
        :param 'GetCatalogCatalogInfoEffectivePredictiveOptimizationFlagArgs' effective_predictive_optimization_flag: object describing applied predictive optimization flag.
        :param str enable_predictive_optimization: Whether predictive optimization should be enabled for this object and objects under it.
        :param str full_name: The full name of the catalog. Corresponds with the name field.
        :param str isolation_mode: Whether the current securable is accessible from all workspaces or a  specific set of workspaces.
        :param str metastore_id: Unique identifier of parent metastore.
        :param str name: name of the catalog
        :param Mapping[str, str] options: A map of key-value properties attached to the securable.
        :param str owner: Current owner of the catalog
        :param Mapping[str, str] properties: A map of key-value properties attached to the securable.
        :param str provider_name: The name of delta sharing provider.
        :param str securable_kind: Kind of catalog securable.
        :param str securable_type: Securable type.
        :param str share_name: The name of the share under the share provider.
        :param str storage_location: Storage Location URL (full path) for managed tables within catalog.
        :param str storage_root: Storage root URL for managed tables within catalog.
        :param int updated_at: Time at which this catalog was last modified, in epoch milliseconds.
        :param str updated_by: Username of user who last modified catalog.
        """
        if browse_only is not None:
            pulumi.set(__self__, "browse_only", browse_only)
        if catalog_type is not None:
            pulumi.set(__self__, "catalog_type", catalog_type)
        if comment is not None:
            pulumi.set(__self__, "comment", comment)
        if connection_name is not None:
            pulumi.set(__self__, "connection_name", connection_name)
        if created_at is not None:
            pulumi.set(__self__, "created_at", created_at)
        if created_by is not None:
            pulumi.set(__self__, "created_by", created_by)
        if effective_predictive_optimization_flag is not None:
            pulumi.set(__self__, "effective_predictive_optimization_flag", effective_predictive_optimization_flag)
        if enable_predictive_optimization is not None:
            pulumi.set(__self__, "enable_predictive_optimization", enable_predictive_optimization)
        if full_name is not None:
            pulumi.set(__self__, "full_name", full_name)
        if isolation_mode is not None:
            pulumi.set(__self__, "isolation_mode", isolation_mode)
        if metastore_id is not None:
            pulumi.set(__self__, "metastore_id", metastore_id)
        if name is not None:
            pulumi.set(__self__, "name", name)
        if options is not None:
            pulumi.set(__self__, "options", options)
        if owner is not None:
            pulumi.set(__self__, "owner", owner)
        if properties is not None:
            pulumi.set(__self__, "properties", properties)
        if provider_name is not None:
            pulumi.set(__self__, "provider_name", provider_name)
        if provisioning_info is not None:
            pulumi.set(__self__, "provisioning_info", provisioning_info)
        if securable_kind is not None:
            pulumi.set(__self__, "securable_kind", securable_kind)
        if securable_type is not None:
            pulumi.set(__self__, "securable_type", securable_type)
        if share_name is not None:
            pulumi.set(__self__, "share_name", share_name)
        if storage_location is not None:
            pulumi.set(__self__, "storage_location", storage_location)
        if storage_root is not None:
            pulumi.set(__self__, "storage_root", storage_root)
        if updated_at is not None:
            pulumi.set(__self__, "updated_at", updated_at)
        if updated_by is not None:
            pulumi.set(__self__, "updated_by", updated_by)

    @property
    @pulumi.getter(name="browseOnly")
    def browse_only(self) -> Optional[bool]:
        return pulumi.get(self, "browse_only")

    @property
    @pulumi.getter(name="catalogType")
    def catalog_type(self) -> Optional[str]:
        """
        Type of the catalog, e.g. `MANAGED_CATALOG`, `DELTASHARING_CATALOG`, `SYSTEM_CATALOG`,
        """
        return pulumi.get(self, "catalog_type")

    @property
    @pulumi.getter
    def comment(self) -> Optional[str]:
        """
        Free-form text description
        """
        return pulumi.get(self, "comment")

    @property
    @pulumi.getter(name="connectionName")
    def connection_name(self) -> Optional[str]:
        """
        The name of the connection to an external data source.
        """
        return pulumi.get(self, "connection_name")

    @property
    @pulumi.getter(name="createdAt")
    def created_at(self) -> Optional[int]:
        """
        Time at which this catalog was created, in epoch milliseconds.
        """
        return pulumi.get(self, "created_at")

    @property
    @pulumi.getter(name="createdBy")
    def created_by(self) -> Optional[str]:
        """
        Username of catalog creator.
        """
        return pulumi.get(self, "created_by")

    @property
    @pulumi.getter(name="effectivePredictiveOptimizationFlag")
    def effective_predictive_optimization_flag(self) -> Optional['outputs.GetCatalogCatalogInfoEffectivePredictiveOptimizationFlagResult']:
        """
        object describing applied predictive optimization flag.
        """
        return pulumi.get(self, "effective_predictive_optimization_flag")

    @property
    @pulumi.getter(name="enablePredictiveOptimization")
    def enable_predictive_optimization(self) -> Optional[str]:
        """
        Whether predictive optimization should be enabled for this object and objects under it.
        """
        return pulumi.get(self, "enable_predictive_optimization")

    @property
    @pulumi.getter(name="fullName")
    def full_name(self) -> Optional[str]:
        """
        The full name of the catalog. Corresponds with the name field.
        """
        return pulumi.get(self, "full_name")

    @property
    @pulumi.getter(name="isolationMode")
    def isolation_mode(self) -> Optional[str]:
        """
        Whether the current securable is accessible from all workspaces or a  specific set of workspaces.
        """
        return pulumi.get(self, "isolation_mode")

    @property
    @pulumi.getter(name="metastoreId")
    def metastore_id(self) -> Optional[str]:
        """
        Unique identifier of parent metastore.
        """
        return pulumi.get(self, "metastore_id")

    @property
    @pulumi.getter
    def name(self) -> Optional[str]:
        """
        name of the catalog
        """
        return pulumi.get(self, "name")

    @property
    @pulumi.getter
    def options(self) -> Optional[Mapping[str, str]]:
        """
        A map of key-value properties attached to the securable.
        """
        return pulumi.get(self, "options")

    @property
    @pulumi.getter
    def owner(self) -> Optional[str]:
        """
        Current owner of the catalog
        """
        return pulumi.get(self, "owner")

    @property
    @pulumi.getter
    def properties(self) -> Optional[Mapping[str, str]]:
        """
        A map of key-value properties attached to the securable.
        """
        return pulumi.get(self, "properties")

    @property
    @pulumi.getter(name="providerName")
    def provider_name(self) -> Optional[str]:
        """
        The name of delta sharing provider.
        """
        return pulumi.get(self, "provider_name")

    @property
    @pulumi.getter(name="provisioningInfo")
    def provisioning_info(self) -> Optional['outputs.GetCatalogCatalogInfoProvisioningInfoResult']:
        return pulumi.get(self, "provisioning_info")

    @property
    @pulumi.getter(name="securableKind")
    def securable_kind(self) -> Optional[str]:
        """
        Kind of catalog securable.
        """
        return pulumi.get(self, "securable_kind")

    @property
    @pulumi.getter(name="securableType")
    def securable_type(self) -> Optional[str]:
        """
        Securable type.
        """
        return pulumi.get(self, "securable_type")

    @property
    @pulumi.getter(name="shareName")
    def share_name(self) -> Optional[str]:
        """
        The name of the share under the share provider.
        """
        return pulumi.get(self, "share_name")

    @property
    @pulumi.getter(name="storageLocation")
    def storage_location(self) -> Optional[str]:
        """
        Storage Location URL (full path) for managed tables within catalog.
        """
        return pulumi.get(self, "storage_location")

    @property
    @pulumi.getter(name="storageRoot")
    def storage_root(self) -> Optional[str]:
        """
        Storage root URL for managed tables within catalog.
        """
        return pulumi.get(self, "storage_root")

    @property
    @pulumi.getter(name="updatedAt")
    def updated_at(self) -> Optional[int]:
        """
        Time at which this catalog was last modified, in epoch milliseconds.
        """
        return pulumi.get(self, "updated_at")

    @property
    @pulumi.getter(name="updatedBy")
    def updated_by(self) -> Optional[str]:
        """
        Username of user who last modified catalog.
        """
        return pulumi.get(self, "updated_by")


@pulumi.output_type
class GetCatalogCatalogInfoEffectivePredictiveOptimizationFlagResult(dict):
    def __init__(__self__, *,
                 value: str,
                 inherited_from_name: Optional[str] = None,
                 inherited_from_type: Optional[str] = None):
        pulumi.set(__self__, "value", value)
        if inherited_from_name is not None:
            pulumi.set(__self__, "inherited_from_name", inherited_from_name)
        if inherited_from_type is not None:
            pulumi.set(__self__, "inherited_from_type", inherited_from_type)

    @property
    @pulumi.getter
    def value(self) -> str:
        return pulumi.get(self, "value")

    @property
    @pulumi.getter(name="inheritedFromName")
    def inherited_from_name(self) -> Optional[str]:
        return pulumi.get(self, "inherited_from_name")

    @property
    @pulumi.getter(name="inheritedFromType")
    def inherited_from_type(self) -> Optional[str]:
        return pulumi.get(self, "inherited_from_type")


@pulumi.output_type
class GetCatalogCatalogInfoProvisioningInfoResult(dict):
    def __init__(__self__, *,
                 state: Optional[str] = None):
        if state is not None:
            pulumi.set(__self__, "state", state)

    @property
    @pulumi.getter
    def state(self) -> Optional[str]:
        return pulumi.get(self, "state")


@pulumi.output_type
class GetClusterClusterInfoResult(dict):
    def __init__(__self__, *,
                 autoscale: Optional['outputs.GetClusterClusterInfoAutoscaleResult'] = None,
                 autotermination_minutes: Optional[int] = None,
                 aws_attributes: Optional['outputs.GetClusterClusterInfoAwsAttributesResult'] = None,
                 azure_attributes: Optional['outputs.GetClusterClusterInfoAzureAttributesResult'] = None,
                 cluster_cores: Optional[float] = None,
                 cluster_id: Optional[str] = None,
                 cluster_log_conf: Optional['outputs.GetClusterClusterInfoClusterLogConfResult'] = None,
                 cluster_log_status: Optional['outputs.GetClusterClusterInfoClusterLogStatusResult'] = None,
                 cluster_memory_mb: Optional[int] = None,
                 cluster_name: Optional[str] = None,
                 cluster_source: Optional[str] = None,
                 creator_user_name: Optional[str] = None,
                 custom_tags: Optional[Mapping[str, str]] = None,
                 data_security_mode: Optional[str] = None,
                 default_tags: Optional[Mapping[str, str]] = None,
                 docker_image: Optional['outputs.GetClusterClusterInfoDockerImageResult'] = None,
                 driver: Optional['outputs.GetClusterClusterInfoDriverResult'] = None,
                 driver_instance_pool_id: Optional[str] = None,
                 driver_node_type_id: Optional[str] = None,
                 enable_elastic_disk: Optional[bool] = None,
                 enable_local_disk_encryption: Optional[bool] = None,
                 executors: Optional[Sequence['outputs.GetClusterClusterInfoExecutorResult']] = None,
                 gcp_attributes: Optional['outputs.GetClusterClusterInfoGcpAttributesResult'] = None,
                 init_scripts: Optional[Sequence['outputs.GetClusterClusterInfoInitScriptResult']] = None,
                 instance_pool_id: Optional[str] = None,
                 jdbc_port: Optional[int] = None,
                 last_restarted_time: Optional[int] = None,
                 last_state_loss_time: Optional[int] = None,
                 node_type_id: Optional[str] = None,
                 num_workers: Optional[int] = None,
                 policy_id: Optional[str] = None,
                 runtime_engine: Optional[str] = None,
                 single_user_name: Optional[str] = None,
                 spark_conf: Optional[Mapping[str, str]] = None,
                 spark_context_id: Optional[int] = None,
                 spark_env_vars: Optional[Mapping[str, str]] = None,
                 spark_version: Optional[str] = None,
                 spec: Optional['outputs.GetClusterClusterInfoSpecResult'] = None,
                 ssh_public_keys: Optional[Sequence[str]] = None,
                 start_time: Optional[int] = None,
                 state: Optional[str] = None,
                 state_message: Optional[str] = None,
                 terminated_time: Optional[int] = None,
                 termination_reason: Optional['outputs.GetClusterClusterInfoTerminationReasonResult'] = None,
                 workload_type: Optional['outputs.GetClusterClusterInfoWorkloadTypeResult'] = None):
        """
        :param int autotermination_minutes: Automatically terminate the cluster after being inactive for this time in minutes. If specified, the threshold must be between 10 and 10000 minutes. You can also set this value to 0 to explicitly disable automatic termination.
        :param str cluster_id: The id of the cluster
        :param str cluster_name: The exact name of the cluster to search
        :param Mapping[str, str] custom_tags: Additional tags for cluster resources.
        :param str data_security_mode: Security features of the cluster. Unity Catalog requires `SINGLE_USER` or `USER_ISOLATION` mode. `LEGACY_PASSTHROUGH` for passthrough cluster and `LEGACY_TABLE_ACL` for Table ACL cluster. Default to `NONE`, i.e. no security feature enabled.
        :param str driver_instance_pool_id: similar to `instance_pool_id`, but for driver node.
        :param str driver_node_type_id: The node type of the Spark driver.
        :param bool enable_elastic_disk: Use autoscaling local storage.
        :param bool enable_local_disk_encryption: Enable local disk encryption.
        :param str instance_pool_id: The pool of idle instances the cluster is attached to.
        :param str node_type_id: Any supported get_node_type id.
        :param str policy_id: Identifier of Cluster Policy to validate cluster and preset certain defaults.
        :param str runtime_engine: The type of runtime of the cluster
        :param str single_user_name: The optional user name of the user to assign to an interactive cluster. This field is required when using standard AAD Passthrough for Azure Data Lake Storage (ADLS) with a single-user cluster (i.e., not high-concurrency clusters).
        :param Mapping[str, str] spark_conf: Map with key-value pairs to fine-tune Spark clusters.
        :param Mapping[str, str] spark_env_vars: Map with environment variable key-value pairs to fine-tune Spark clusters. Key-value pairs of the form (X,Y) are exported (i.e., X='Y') while launching the driver and workers.
        :param str spark_version: [Runtime version](https://docs.databricks.com/runtime/index.html) of the cluster.
        :param Sequence[str] ssh_public_keys: SSH public key contents that will be added to each Spark node in this cluster.
        """
        if autoscale is not None:
            pulumi.set(__self__, "autoscale", autoscale)
        if autotermination_minutes is not None:
            pulumi.set(__self__, "autotermination_minutes", autotermination_minutes)
        if aws_attributes is not None:
            pulumi.set(__self__, "aws_attributes", aws_attributes)
        if azure_attributes is not None:
            pulumi.set(__self__, "azure_attributes", azure_attributes)
        if cluster_cores is not None:
            pulumi.set(__self__, "cluster_cores", cluster_cores)
        if cluster_id is not None:
            pulumi.set(__self__, "cluster_id", cluster_id)
        if cluster_log_conf is not None:
            pulumi.set(__self__, "cluster_log_conf", cluster_log_conf)
        if cluster_log_status is not None:
            pulumi.set(__self__, "cluster_log_status", cluster_log_status)
        if cluster_memory_mb is not None:
            pulumi.set(__self__, "cluster_memory_mb", cluster_memory_mb)
        if cluster_name is not None:
            pulumi.set(__self__, "cluster_name", cluster_name)
        if cluster_source is not None:
            pulumi.set(__self__, "cluster_source", cluster_source)
        if creator_user_name is not None:
            pulumi.set(__self__, "creator_user_name", creator_user_name)
        if custom_tags is not None:
            pulumi.set(__self__, "custom_tags", custom_tags)
        if data_security_mode is not None:
            pulumi.set(__self__, "data_security_mode", data_security_mode)
        if default_tags is not None:
            pulumi.set(__self__, "default_tags", default_tags)
        if docker_image is not None:
            pulumi.set(__self__, "docker_image", docker_image)
        if driver is not None:
            pulumi.set(__self__, "driver", driver)
        if driver_instance_pool_id is not None:
            pulumi.set(__self__, "driver_instance_pool_id", driver_instance_pool_id)
        if driver_node_type_id is not None:
            pulumi.set(__self__, "driver_node_type_id", driver_node_type_id)
        if enable_elastic_disk is not None:
            pulumi.set(__self__, "enable_elastic_disk", enable_elastic_disk)
        if enable_local_disk_encryption is not None:
            pulumi.set(__self__, "enable_local_disk_encryption", enable_local_disk_encryption)
        if executors is not None:
            pulumi.set(__self__, "executors", executors)
        if gcp_attributes is not None:
            pulumi.set(__self__, "gcp_attributes", gcp_attributes)
        if init_scripts is not None:
            pulumi.set(__self__, "init_scripts", init_scripts)
        if instance_pool_id is not None:
            pulumi.set(__self__, "instance_pool_id", instance_pool_id)
        if jdbc_port is not None:
            pulumi.set(__self__, "jdbc_port", jdbc_port)
        if last_restarted_time is not None:
            pulumi.set(__self__, "last_restarted_time", last_restarted_time)
        if last_state_loss_time is not None:
            pulumi.set(__self__, "last_state_loss_time", last_state_loss_time)
        if node_type_id is not None:
            pulumi.set(__self__, "node_type_id", node_type_id)
        if num_workers is not None:
            pulumi.set(__self__, "num_workers", num_workers)
        if policy_id is not None:
            pulumi.set(__self__, "policy_id", policy_id)
        if runtime_engine is not None:
            pulumi.set(__self__, "runtime_engine", runtime_engine)
        if single_user_name is not None:
            pulumi.set(__self__, "single_user_name", single_user_name)
        if spark_conf is not None:
            pulumi.set(__self__, "spark_conf", spark_conf)
        if spark_context_id is not None:
            pulumi.set(__self__, "spark_context_id", spark_context_id)
        if spark_env_vars is not None:
            pulumi.set(__self__, "spark_env_vars", spark_env_vars)
        if spark_version is not None:
            pulumi.set(__self__, "spark_version", spark_version)
        if spec is not None:
            pulumi.set(__self__, "spec", spec)
        if ssh_public_keys is not None:
            pulumi.set(__self__, "ssh_public_keys", ssh_public_keys)
        if start_time is not None:
            pulumi.set(__self__, "start_time", start_time)
        if state is not None:
            pulumi.set(__self__, "state", state)
        if state_message is not None:
            pulumi.set(__self__, "state_message", state_message)
        if terminated_time is not None:
            pulumi.set(__self__, "terminated_time", terminated_time)
        if termination_reason is not None:
            pulumi.set(__self__, "termination_reason", termination_reason)
        if workload_type is not None:
            pulumi.set(__self__, "workload_type", workload_type)

    @property
    @pulumi.getter
    def autoscale(self) -> Optional['outputs.GetClusterClusterInfoAutoscaleResult']:
        return pulumi.get(self, "autoscale")

    @property
    @pulumi.getter(name="autoterminationMinutes")
    def autotermination_minutes(self) -> Optional[int]:
        """
        Automatically terminate the cluster after being inactive for this time in minutes. If specified, the threshold must be between 10 and 10000 minutes. You can also set this value to 0 to explicitly disable automatic termination.
        """
        return pulumi.get(self, "autotermination_minutes")

    @property
    @pulumi.getter(name="awsAttributes")
    def aws_attributes(self) -> Optional['outputs.GetClusterClusterInfoAwsAttributesResult']:
        return pulumi.get(self, "aws_attributes")

    @property
    @pulumi.getter(name="azureAttributes")
    def azure_attributes(self) -> Optional['outputs.GetClusterClusterInfoAzureAttributesResult']:
        return pulumi.get(self, "azure_attributes")

    @property
    @pulumi.getter(name="clusterCores")
    def cluster_cores(self) -> Optional[float]:
        return pulumi.get(self, "cluster_cores")

    @property
    @pulumi.getter(name="clusterId")
    def cluster_id(self) -> Optional[str]:
        """
        The id of the cluster
        """
        return pulumi.get(self, "cluster_id")

    @property
    @pulumi.getter(name="clusterLogConf")
    def cluster_log_conf(self) -> Optional['outputs.GetClusterClusterInfoClusterLogConfResult']:
        return pulumi.get(self, "cluster_log_conf")

    @property
    @pulumi.getter(name="clusterLogStatus")
    def cluster_log_status(self) -> Optional['outputs.GetClusterClusterInfoClusterLogStatusResult']:
        return pulumi.get(self, "cluster_log_status")

    @property
    @pulumi.getter(name="clusterMemoryMb")
    def cluster_memory_mb(self) -> Optional[int]:
        return pulumi.get(self, "cluster_memory_mb")

    @property
    @pulumi.getter(name="clusterName")
    def cluster_name(self) -> Optional[str]:
        """
        The exact name of the cluster to search
        """
        return pulumi.get(self, "cluster_name")

    @property
    @pulumi.getter(name="clusterSource")
    def cluster_source(self) -> Optional[str]:
        return pulumi.get(self, "cluster_source")

    @property
    @pulumi.getter(name="creatorUserName")
    def creator_user_name(self) -> Optional[str]:
        return pulumi.get(self, "creator_user_name")

    @property
    @pulumi.getter(name="customTags")
    def custom_tags(self) -> Optional[Mapping[str, str]]:
        """
        Additional tags for cluster resources.
        """
        return pulumi.get(self, "custom_tags")

    @property
    @pulumi.getter(name="dataSecurityMode")
    def data_security_mode(self) -> Optional[str]:
        """
        Security features of the cluster. Unity Catalog requires `SINGLE_USER` or `USER_ISOLATION` mode. `LEGACY_PASSTHROUGH` for passthrough cluster and `LEGACY_TABLE_ACL` for Table ACL cluster. Default to `NONE`, i.e. no security feature enabled.
        """
        return pulumi.get(self, "data_security_mode")

    @property
    @pulumi.getter(name="defaultTags")
    def default_tags(self) -> Optional[Mapping[str, str]]:
        return pulumi.get(self, "default_tags")

    @property
    @pulumi.getter(name="dockerImage")
    def docker_image(self) -> Optional['outputs.GetClusterClusterInfoDockerImageResult']:
        return pulumi.get(self, "docker_image")

    @property
    @pulumi.getter
    def driver(self) -> Optional['outputs.GetClusterClusterInfoDriverResult']:
        return pulumi.get(self, "driver")

    @property
    @pulumi.getter(name="driverInstancePoolId")
    def driver_instance_pool_id(self) -> Optional[str]:
        """
        similar to `instance_pool_id`, but for driver node.
        """
        return pulumi.get(self, "driver_instance_pool_id")

    @property
    @pulumi.getter(name="driverNodeTypeId")
    def driver_node_type_id(self) -> Optional[str]:
        """
        The node type of the Spark driver.
        """
        return pulumi.get(self, "driver_node_type_id")

    @property
    @pulumi.getter(name="enableElasticDisk")
    def enable_elastic_disk(self) -> Optional[bool]:
        """
        Use autoscaling local storage.
        """
        return pulumi.get(self, "enable_elastic_disk")

    @property
    @pulumi.getter(name="enableLocalDiskEncryption")
    def enable_local_disk_encryption(self) -> Optional[bool]:
        """
        Enable local disk encryption.
        """
        return pulumi.get(self, "enable_local_disk_encryption")

    @property
    @pulumi.getter
    def executors(self) -> Optional[Sequence['outputs.GetClusterClusterInfoExecutorResult']]:
        return pulumi.get(self, "executors")

    @property
    @pulumi.getter(name="gcpAttributes")
    def gcp_attributes(self) -> Optional['outputs.GetClusterClusterInfoGcpAttributesResult']:
        return pulumi.get(self, "gcp_attributes")

    @property
    @pulumi.getter(name="initScripts")
    def init_scripts(self) -> Optional[Sequence['outputs.GetClusterClusterInfoInitScriptResult']]:
        return pulumi.get(self, "init_scripts")

    @property
    @pulumi.getter(name="instancePoolId")
    def instance_pool_id(self) -> Optional[str]:
        """
        The pool of idle instances the cluster is attached to.
        """
        return pulumi.get(self, "instance_pool_id")

    @property
    @pulumi.getter(name="jdbcPort")
    def jdbc_port(self) -> Optional[int]:
        return pulumi.get(self, "jdbc_port")

    @property
    @pulumi.getter(name="lastRestartedTime")
    def last_restarted_time(self) -> Optional[int]:
        return pulumi.get(self, "last_restarted_time")

    @property
    @pulumi.getter(name="lastStateLossTime")
    def last_state_loss_time(self) -> Optional[int]:
        return pulumi.get(self, "last_state_loss_time")

    @property
    @pulumi.getter(name="nodeTypeId")
    def node_type_id(self) -> Optional[str]:
        """
        Any supported get_node_type id.
        """
        return pulumi.get(self, "node_type_id")

    @property
    @pulumi.getter(name="numWorkers")
    def num_workers(self) -> Optional[int]:
        return pulumi.get(self, "num_workers")

    @property
    @pulumi.getter(name="policyId")
    def policy_id(self) -> Optional[str]:
        """
        Identifier of Cluster Policy to validate cluster and preset certain defaults.
        """
        return pulumi.get(self, "policy_id")

    @property
    @pulumi.getter(name="runtimeEngine")
    def runtime_engine(self) -> Optional[str]:
        """
        The type of runtime of the cluster
        """
        return pulumi.get(self, "runtime_engine")

    @property
    @pulumi.getter(name="singleUserName")
    def single_user_name(self) -> Optional[str]:
        """
        The optional user name of the user to assign to an interactive cluster. This field is required when using standard AAD Passthrough for Azure Data Lake Storage (ADLS) with a single-user cluster (i.e., not high-concurrency clusters).
        """
        return pulumi.get(self, "single_user_name")

    @property
    @pulumi.getter(name="sparkConf")
    def spark_conf(self) -> Optional[Mapping[str, str]]:
        """
        Map with key-value pairs to fine-tune Spark clusters.
        """
        return pulumi.get(self, "spark_conf")

    @property
    @pulumi.getter(name="sparkContextId")
    def spark_context_id(self) -> Optional[int]:
        return pulumi.get(self, "spark_context_id")

    @property
    @pulumi.getter(name="sparkEnvVars")
    def spark_env_vars(self) -> Optional[Mapping[str, str]]:
        """
        Map with environment variable key-value pairs to fine-tune Spark clusters. Key-value pairs of the form (X,Y) are exported (i.e., X='Y') while launching the driver and workers.
        """
        return pulumi.get(self, "spark_env_vars")

    @property
    @pulumi.getter(name="sparkVersion")
    def spark_version(self) -> Optional[str]:
        """
        [Runtime version](https://docs.databricks.com/runtime/index.html) of the cluster.
        """
        return pulumi.get(self, "spark_version")

    @property
    @pulumi.getter
    def spec(self) -> Optional['outputs.GetClusterClusterInfoSpecResult']:
        return pulumi.get(self, "spec")

    @property
    @pulumi.getter(name="sshPublicKeys")
    def ssh_public_keys(self) -> Optional[Sequence[str]]:
        """
        SSH public key contents that will be added to each Spark node in this cluster.
        """
        return pulumi.get(self, "ssh_public_keys")

    @property
    @pulumi.getter(name="startTime")
    def start_time(self) -> Optional[int]:
        return pulumi.get(self, "start_time")

    @property
    @pulumi.getter
    def state(self) -> Optional[str]:
        return pulumi.get(self, "state")

    @property
    @pulumi.getter(name="stateMessage")
    def state_message(self) -> Optional[str]:
        return pulumi.get(self, "state_message")

    @property
    @pulumi.getter(name="terminatedTime")
    def terminated_time(self) -> Optional[int]:
        return pulumi.get(self, "terminated_time")

    @property
    @pulumi.getter(name="terminationReason")
    def termination_reason(self) -> Optional['outputs.GetClusterClusterInfoTerminationReasonResult']:
        return pulumi.get(self, "termination_reason")

    @property
    @pulumi.getter(name="workloadType")
    def workload_type(self) -> Optional['outputs.GetClusterClusterInfoWorkloadTypeResult']:
        return pulumi.get(self, "workload_type")


@pulumi.output_type
class GetClusterClusterInfoAutoscaleResult(dict):
    def __init__(__self__, *,
                 max_workers: Optional[int] = None,
                 min_workers: Optional[int] = None):
        if max_workers is not None:
            pulumi.set(__self__, "max_workers", max_workers)
        if min_workers is not None:
            pulumi.set(__self__, "min_workers", min_workers)

    @property
    @pulumi.getter(name="maxWorkers")
    def max_workers(self) -> Optional[int]:
        return pulumi.get(self, "max_workers")

    @property
    @pulumi.getter(name="minWorkers")
    def min_workers(self) -> Optional[int]:
        return pulumi.get(self, "min_workers")


@pulumi.output_type
class GetClusterClusterInfoAwsAttributesResult(dict):
    def __init__(__self__, *,
                 availability: Optional[str] = None,
                 ebs_volume_count: Optional[int] = None,
                 ebs_volume_iops: Optional[int] = None,
                 ebs_volume_size: Optional[int] = None,
                 ebs_volume_throughput: Optional[int] = None,
                 ebs_volume_type: Optional[str] = None,
                 first_on_demand: Optional[int] = None,
                 instance_profile_arn: Optional[str] = None,
                 spot_bid_price_percent: Optional[int] = None,
                 zone_id: Optional[str] = None):
        if availability is not None:
            pulumi.set(__self__, "availability", availability)
        if ebs_volume_count is not None:
            pulumi.set(__self__, "ebs_volume_count", ebs_volume_count)
        if ebs_volume_iops is not None:
            pulumi.set(__self__, "ebs_volume_iops", ebs_volume_iops)
        if ebs_volume_size is not None:
            pulumi.set(__self__, "ebs_volume_size", ebs_volume_size)
        if ebs_volume_throughput is not None:
            pulumi.set(__self__, "ebs_volume_throughput", ebs_volume_throughput)
        if ebs_volume_type is not None:
            pulumi.set(__self__, "ebs_volume_type", ebs_volume_type)
        if first_on_demand is not None:
            pulumi.set(__self__, "first_on_demand", first_on_demand)
        if instance_profile_arn is not None:
            pulumi.set(__self__, "instance_profile_arn", instance_profile_arn)
        if spot_bid_price_percent is not None:
            pulumi.set(__self__, "spot_bid_price_percent", spot_bid_price_percent)
        if zone_id is not None:
            pulumi.set(__self__, "zone_id", zone_id)

    @property
    @pulumi.getter
    def availability(self) -> Optional[str]:
        return pulumi.get(self, "availability")

    @property
    @pulumi.getter(name="ebsVolumeCount")
    def ebs_volume_count(self) -> Optional[int]:
        return pulumi.get(self, "ebs_volume_count")

    @property
    @pulumi.getter(name="ebsVolumeIops")
    def ebs_volume_iops(self) -> Optional[int]:
        return pulumi.get(self, "ebs_volume_iops")

    @property
    @pulumi.getter(name="ebsVolumeSize")
    def ebs_volume_size(self) -> Optional[int]:
        return pulumi.get(self, "ebs_volume_size")

    @property
    @pulumi.getter(name="ebsVolumeThroughput")
    def ebs_volume_throughput(self) -> Optional[int]:
        return pulumi.get(self, "ebs_volume_throughput")

    @property
    @pulumi.getter(name="ebsVolumeType")
    def ebs_volume_type(self) -> Optional[str]:
        return pulumi.get(self, "ebs_volume_type")

    @property
    @pulumi.getter(name="firstOnDemand")
    def first_on_demand(self) -> Optional[int]:
        return pulumi.get(self, "first_on_demand")

    @property
    @pulumi.getter(name="instanceProfileArn")
    def instance_profile_arn(self) -> Optional[str]:
        return pulumi.get(self, "instance_profile_arn")

    @property
    @pulumi.getter(name="spotBidPricePercent")
    def spot_bid_price_percent(self) -> Optional[int]:
        return pulumi.get(self, "spot_bid_price_percent")

    @property
    @pulumi.getter(name="zoneId")
    def zone_id(self) -> Optional[str]:
        return pulumi.get(self, "zone_id")


@pulumi.output_type
class GetClusterClusterInfoAzureAttributesResult(dict):
    def __init__(__self__, *,
                 availability: Optional[str] = None,
                 first_on_demand: Optional[int] = None,
                 log_analytics_info: Optional['outputs.GetClusterClusterInfoAzureAttributesLogAnalyticsInfoResult'] = None,
                 spot_bid_max_price: Optional[float] = None):
        if availability is not None:
            pulumi.set(__self__, "availability", availability)
        if first_on_demand is not None:
            pulumi.set(__self__, "first_on_demand", first_on_demand)
        if log_analytics_info is not None:
            pulumi.set(__self__, "log_analytics_info", log_analytics_info)
        if spot_bid_max_price is not None:
            pulumi.set(__self__, "spot_bid_max_price", spot_bid_max_price)

    @property
    @pulumi.getter
    def availability(self) -> Optional[str]:
        return pulumi.get(self, "availability")

    @property
    @pulumi.getter(name="firstOnDemand")
    def first_on_demand(self) -> Optional[int]:
        return pulumi.get(self, "first_on_demand")

    @property
    @pulumi.getter(name="logAnalyticsInfo")
    def log_analytics_info(self) -> Optional['outputs.GetClusterClusterInfoAzureAttributesLogAnalyticsInfoResult']:
        return pulumi.get(self, "log_analytics_info")

    @property
    @pulumi.getter(name="spotBidMaxPrice")
    def spot_bid_max_price(self) -> Optional[float]:
        return pulumi.get(self, "spot_bid_max_price")


@pulumi.output_type
class GetClusterClusterInfoAzureAttributesLogAnalyticsInfoResult(dict):
    def __init__(__self__, *,
                 log_analytics_primary_key: Optional[str] = None,
                 log_analytics_workspace_id: Optional[str] = None):
        if log_analytics_primary_key is not None:
            pulumi.set(__self__, "log_analytics_primary_key", log_analytics_primary_key)
        if log_analytics_workspace_id is not None:
            pulumi.set(__self__, "log_analytics_workspace_id", log_analytics_workspace_id)

    @property
    @pulumi.getter(name="logAnalyticsPrimaryKey")
    def log_analytics_primary_key(self) -> Optional[str]:
        return pulumi.get(self, "log_analytics_primary_key")

    @property
    @pulumi.getter(name="logAnalyticsWorkspaceId")
    def log_analytics_workspace_id(self) -> Optional[str]:
        return pulumi.get(self, "log_analytics_workspace_id")


@pulumi.output_type
class GetClusterClusterInfoClusterLogConfResult(dict):
    def __init__(__self__, *,
                 dbfs: Optional['outputs.GetClusterClusterInfoClusterLogConfDbfsResult'] = None,
                 s3: Optional['outputs.GetClusterClusterInfoClusterLogConfS3Result'] = None):
        if dbfs is not None:
            pulumi.set(__self__, "dbfs", dbfs)
        if s3 is not None:
            pulumi.set(__self__, "s3", s3)

    @property
    @pulumi.getter
    def dbfs(self) -> Optional['outputs.GetClusterClusterInfoClusterLogConfDbfsResult']:
        return pulumi.get(self, "dbfs")

    @property
    @pulumi.getter
    def s3(self) -> Optional['outputs.GetClusterClusterInfoClusterLogConfS3Result']:
        return pulumi.get(self, "s3")


@pulumi.output_type
class GetClusterClusterInfoClusterLogConfDbfsResult(dict):
    def __init__(__self__, *,
                 destination: str):
        pulumi.set(__self__, "destination", destination)

    @property
    @pulumi.getter
    def destination(self) -> str:
        return pulumi.get(self, "destination")


@pulumi.output_type
class GetClusterClusterInfoClusterLogConfS3Result(dict):
    def __init__(__self__, *,
                 destination: str,
                 canned_acl: Optional[str] = None,
                 enable_encryption: Optional[bool] = None,
                 encryption_type: Optional[str] = None,
                 endpoint: Optional[str] = None,
                 kms_key: Optional[str] = None,
                 region: Optional[str] = None):
        pulumi.set(__self__, "destination", destination)
        if canned_acl is not None:
            pulumi.set(__self__, "canned_acl", canned_acl)
        if enable_encryption is not None:
            pulumi.set(__self__, "enable_encryption", enable_encryption)
        if encryption_type is not None:
            pulumi.set(__self__, "encryption_type", encryption_type)
        if endpoint is not None:
            pulumi.set(__self__, "endpoint", endpoint)
        if kms_key is not None:
            pulumi.set(__self__, "kms_key", kms_key)
        if region is not None:
            pulumi.set(__self__, "region", region)

    @property
    @pulumi.getter
    def destination(self) -> str:
        return pulumi.get(self, "destination")

    @property
    @pulumi.getter(name="cannedAcl")
    def canned_acl(self) -> Optional[str]:
        return pulumi.get(self, "canned_acl")

    @property
    @pulumi.getter(name="enableEncryption")
    def enable_encryption(self) -> Optional[bool]:
        return pulumi.get(self, "enable_encryption")

    @property
    @pulumi.getter(name="encryptionType")
    def encryption_type(self) -> Optional[str]:
        return pulumi.get(self, "encryption_type")

    @property
    @pulumi.getter
    def endpoint(self) -> Optional[str]:
        return pulumi.get(self, "endpoint")

    @property
    @pulumi.getter(name="kmsKey")
    def kms_key(self) -> Optional[str]:
        return pulumi.get(self, "kms_key")

    @property
    @pulumi.getter
    def region(self) -> Optional[str]:
        return pulumi.get(self, "region")


@pulumi.output_type
class GetClusterClusterInfoClusterLogStatusResult(dict):
    def __init__(__self__, *,
                 last_attempted: Optional[int] = None,
                 last_exception: Optional[str] = None):
        if last_attempted is not None:
            pulumi.set(__self__, "last_attempted", last_attempted)
        if last_exception is not None:
            pulumi.set(__self__, "last_exception", last_exception)

    @property
    @pulumi.getter(name="lastAttempted")
    def last_attempted(self) -> Optional[int]:
        return pulumi.get(self, "last_attempted")

    @property
    @pulumi.getter(name="lastException")
    def last_exception(self) -> Optional[str]:
        return pulumi.get(self, "last_exception")


@pulumi.output_type
class GetClusterClusterInfoDockerImageResult(dict):
    def __init__(__self__, *,
                 basic_auth: Optional['outputs.GetClusterClusterInfoDockerImageBasicAuthResult'] = None,
                 url: Optional[str] = None):
        if basic_auth is not None:
            pulumi.set(__self__, "basic_auth", basic_auth)
        if url is not None:
            pulumi.set(__self__, "url", url)

    @property
    @pulumi.getter(name="basicAuth")
    def basic_auth(self) -> Optional['outputs.GetClusterClusterInfoDockerImageBasicAuthResult']:
        return pulumi.get(self, "basic_auth")

    @property
    @pulumi.getter
    def url(self) -> Optional[str]:
        return pulumi.get(self, "url")


@pulumi.output_type
class GetClusterClusterInfoDockerImageBasicAuthResult(dict):
    def __init__(__self__, *,
                 password: Optional[str] = None,
                 username: Optional[str] = None):
        if password is not None:
            pulumi.set(__self__, "password", password)
        if username is not None:
            pulumi.set(__self__, "username", username)

    @property
    @pulumi.getter
    def password(self) -> Optional[str]:
        return pulumi.get(self, "password")

    @property
    @pulumi.getter
    def username(self) -> Optional[str]:
        return pulumi.get(self, "username")


@pulumi.output_type
class GetClusterClusterInfoDriverResult(dict):
    def __init__(__self__, *,
                 host_private_ip: Optional[str] = None,
                 instance_id: Optional[str] = None,
                 node_aws_attributes: Optional['outputs.GetClusterClusterInfoDriverNodeAwsAttributesResult'] = None,
                 node_id: Optional[str] = None,
                 private_ip: Optional[str] = None,
                 public_dns: Optional[str] = None,
                 start_timestamp: Optional[int] = None):
        if host_private_ip is not None:
            pulumi.set(__self__, "host_private_ip", host_private_ip)
        if instance_id is not None:
            pulumi.set(__self__, "instance_id", instance_id)
        if node_aws_attributes is not None:
            pulumi.set(__self__, "node_aws_attributes", node_aws_attributes)
        if node_id is not None:
            pulumi.set(__self__, "node_id", node_id)
        if private_ip is not None:
            pulumi.set(__self__, "private_ip", private_ip)
        if public_dns is not None:
            pulumi.set(__self__, "public_dns", public_dns)
        if start_timestamp is not None:
            pulumi.set(__self__, "start_timestamp", start_timestamp)

    @property
    @pulumi.getter(name="hostPrivateIp")
    def host_private_ip(self) -> Optional[str]:
        return pulumi.get(self, "host_private_ip")

    @property
    @pulumi.getter(name="instanceId")
    def instance_id(self) -> Optional[str]:
        return pulumi.get(self, "instance_id")

    @property
    @pulumi.getter(name="nodeAwsAttributes")
    def node_aws_attributes(self) -> Optional['outputs.GetClusterClusterInfoDriverNodeAwsAttributesResult']:
        return pulumi.get(self, "node_aws_attributes")

    @property
    @pulumi.getter(name="nodeId")
    def node_id(self) -> Optional[str]:
        return pulumi.get(self, "node_id")

    @property
    @pulumi.getter(name="privateIp")
    def private_ip(self) -> Optional[str]:
        return pulumi.get(self, "private_ip")

    @property
    @pulumi.getter(name="publicDns")
    def public_dns(self) -> Optional[str]:
        return pulumi.get(self, "public_dns")

    @property
    @pulumi.getter(name="startTimestamp")
    def start_timestamp(self) -> Optional[int]:
        return pulumi.get(self, "start_timestamp")


@pulumi.output_type
class GetClusterClusterInfoDriverNodeAwsAttributesResult(dict):
    def __init__(__self__, *,
                 is_spot: Optional[bool] = None):
        if is_spot is not None:
            pulumi.set(__self__, "is_spot", is_spot)

    @property
    @pulumi.getter(name="isSpot")
    def is_spot(self) -> Optional[bool]:
        return pulumi.get(self, "is_spot")


@pulumi.output_type
class GetClusterClusterInfoExecutorResult(dict):
    def __init__(__self__, *,
                 host_private_ip: Optional[str] = None,
                 instance_id: Optional[str] = None,
                 node_aws_attributes: Optional['outputs.GetClusterClusterInfoExecutorNodeAwsAttributesResult'] = None,
                 node_id: Optional[str] = None,
                 private_ip: Optional[str] = None,
                 public_dns: Optional[str] = None,
                 start_timestamp: Optional[int] = None):
        if host_private_ip is not None:
            pulumi.set(__self__, "host_private_ip", host_private_ip)
        if instance_id is not None:
            pulumi.set(__self__, "instance_id", instance_id)
        if node_aws_attributes is not None:
            pulumi.set(__self__, "node_aws_attributes", node_aws_attributes)
        if node_id is not None:
            pulumi.set(__self__, "node_id", node_id)
        if private_ip is not None:
            pulumi.set(__self__, "private_ip", private_ip)
        if public_dns is not None:
            pulumi.set(__self__, "public_dns", public_dns)
        if start_timestamp is not None:
            pulumi.set(__self__, "start_timestamp", start_timestamp)

    @property
    @pulumi.getter(name="hostPrivateIp")
    def host_private_ip(self) -> Optional[str]:
        return pulumi.get(self, "host_private_ip")

    @property
    @pulumi.getter(name="instanceId")
    def instance_id(self) -> Optional[str]:
        return pulumi.get(self, "instance_id")

    @property
    @pulumi.getter(name="nodeAwsAttributes")
    def node_aws_attributes(self) -> Optional['outputs.GetClusterClusterInfoExecutorNodeAwsAttributesResult']:
        return pulumi.get(self, "node_aws_attributes")

    @property
    @pulumi.getter(name="nodeId")
    def node_id(self) -> Optional[str]:
        return pulumi.get(self, "node_id")

    @property
    @pulumi.getter(name="privateIp")
    def private_ip(self) -> Optional[str]:
        return pulumi.get(self, "private_ip")

    @property
    @pulumi.getter(name="publicDns")
    def public_dns(self) -> Optional[str]:
        return pulumi.get(self, "public_dns")

    @property
    @pulumi.getter(name="startTimestamp")
    def start_timestamp(self) -> Optional[int]:
        return pulumi.get(self, "start_timestamp")


@pulumi.output_type
class GetClusterClusterInfoExecutorNodeAwsAttributesResult(dict):
    def __init__(__self__, *,
                 is_spot: Optional[bool] = None):
        if is_spot is not None:
            pulumi.set(__self__, "is_spot", is_spot)

    @property
    @pulumi.getter(name="isSpot")
    def is_spot(self) -> Optional[bool]:
        return pulumi.get(self, "is_spot")


@pulumi.output_type
class GetClusterClusterInfoGcpAttributesResult(dict):
    def __init__(__self__, *,
                 availability: Optional[str] = None,
                 boot_disk_size: Optional[int] = None,
                 google_service_account: Optional[str] = None,
                 local_ssd_count: Optional[int] = None,
                 use_preemptible_executors: Optional[bool] = None,
                 zone_id: Optional[str] = None):
        if availability is not None:
            pulumi.set(__self__, "availability", availability)
        if boot_disk_size is not None:
            pulumi.set(__self__, "boot_disk_size", boot_disk_size)
        if google_service_account is not None:
            pulumi.set(__self__, "google_service_account", google_service_account)
        if local_ssd_count is not None:
            pulumi.set(__self__, "local_ssd_count", local_ssd_count)
        if use_preemptible_executors is not None:
            pulumi.set(__self__, "use_preemptible_executors", use_preemptible_executors)
        if zone_id is not None:
            pulumi.set(__self__, "zone_id", zone_id)

    @property
    @pulumi.getter
    def availability(self) -> Optional[str]:
        return pulumi.get(self, "availability")

    @property
    @pulumi.getter(name="bootDiskSize")
    def boot_disk_size(self) -> Optional[int]:
        return pulumi.get(self, "boot_disk_size")

    @property
    @pulumi.getter(name="googleServiceAccount")
    def google_service_account(self) -> Optional[str]:
        return pulumi.get(self, "google_service_account")

    @property
    @pulumi.getter(name="localSsdCount")
    def local_ssd_count(self) -> Optional[int]:
        return pulumi.get(self, "local_ssd_count")

    @property
    @pulumi.getter(name="usePreemptibleExecutors")
    def use_preemptible_executors(self) -> Optional[bool]:
        return pulumi.get(self, "use_preemptible_executors")

    @property
    @pulumi.getter(name="zoneId")
    def zone_id(self) -> Optional[str]:
        return pulumi.get(self, "zone_id")


@pulumi.output_type
class GetClusterClusterInfoInitScriptResult(dict):
    def __init__(__self__, *,
                 abfss: Optional['outputs.GetClusterClusterInfoInitScriptAbfssResult'] = None,
                 dbfs: Optional['outputs.GetClusterClusterInfoInitScriptDbfsResult'] = None,
                 file: Optional['outputs.GetClusterClusterInfoInitScriptFileResult'] = None,
                 gcs: Optional['outputs.GetClusterClusterInfoInitScriptGcsResult'] = None,
                 s3: Optional['outputs.GetClusterClusterInfoInitScriptS3Result'] = None,
                 volumes: Optional['outputs.GetClusterClusterInfoInitScriptVolumesResult'] = None,
                 workspace: Optional['outputs.GetClusterClusterInfoInitScriptWorkspaceResult'] = None):
        if abfss is not None:
            pulumi.set(__self__, "abfss", abfss)
        if dbfs is not None:
            pulumi.set(__self__, "dbfs", dbfs)
        if file is not None:
            pulumi.set(__self__, "file", file)
        if gcs is not None:
            pulumi.set(__self__, "gcs", gcs)
        if s3 is not None:
            pulumi.set(__self__, "s3", s3)
        if volumes is not None:
            pulumi.set(__self__, "volumes", volumes)
        if workspace is not None:
            pulumi.set(__self__, "workspace", workspace)

    @property
    @pulumi.getter
    def abfss(self) -> Optional['outputs.GetClusterClusterInfoInitScriptAbfssResult']:
        return pulumi.get(self, "abfss")

    @property
    @pulumi.getter
    def dbfs(self) -> Optional['outputs.GetClusterClusterInfoInitScriptDbfsResult']:
        return pulumi.get(self, "dbfs")

    @property
    @pulumi.getter
    def file(self) -> Optional['outputs.GetClusterClusterInfoInitScriptFileResult']:
        return pulumi.get(self, "file")

    @property
    @pulumi.getter
    def gcs(self) -> Optional['outputs.GetClusterClusterInfoInitScriptGcsResult']:
        return pulumi.get(self, "gcs")

    @property
    @pulumi.getter
    def s3(self) -> Optional['outputs.GetClusterClusterInfoInitScriptS3Result']:
        return pulumi.get(self, "s3")

    @property
    @pulumi.getter
    def volumes(self) -> Optional['outputs.GetClusterClusterInfoInitScriptVolumesResult']:
        return pulumi.get(self, "volumes")

    @property
    @pulumi.getter
    def workspace(self) -> Optional['outputs.GetClusterClusterInfoInitScriptWorkspaceResult']:
        return pulumi.get(self, "workspace")


@pulumi.output_type
class GetClusterClusterInfoInitScriptAbfssResult(dict):
    def __init__(__self__, *,
                 destination: str):
        pulumi.set(__self__, "destination", destination)

    @property
    @pulumi.getter
    def destination(self) -> str:
        return pulumi.get(self, "destination")


@pulumi.output_type
class GetClusterClusterInfoInitScriptDbfsResult(dict):
    def __init__(__self__, *,
                 destination: str):
        pulumi.set(__self__, "destination", destination)

    @property
    @pulumi.getter
    def destination(self) -> str:
        return pulumi.get(self, "destination")


@pulumi.output_type
class GetClusterClusterInfoInitScriptFileResult(dict):
    def __init__(__self__, *,
                 destination: str):
        pulumi.set(__self__, "destination", destination)

    @property
    @pulumi.getter
    def destination(self) -> str:
        return pulumi.get(self, "destination")


@pulumi.output_type
class GetClusterClusterInfoInitScriptGcsResult(dict):
    def __init__(__self__, *,
                 destination: str):
        pulumi.set(__self__, "destination", destination)

    @property
    @pulumi.getter
    def destination(self) -> str:
        return pulumi.get(self, "destination")


@pulumi.output_type
class GetClusterClusterInfoInitScriptS3Result(dict):
    def __init__(__self__, *,
                 destination: str,
                 canned_acl: Optional[str] = None,
                 enable_encryption: Optional[bool] = None,
                 encryption_type: Optional[str] = None,
                 endpoint: Optional[str] = None,
                 kms_key: Optional[str] = None,
                 region: Optional[str] = None):
        pulumi.set(__self__, "destination", destination)
        if canned_acl is not None:
            pulumi.set(__self__, "canned_acl", canned_acl)
        if enable_encryption is not None:
            pulumi.set(__self__, "enable_encryption", enable_encryption)
        if encryption_type is not None:
            pulumi.set(__self__, "encryption_type", encryption_type)
        if endpoint is not None:
            pulumi.set(__self__, "endpoint", endpoint)
        if kms_key is not None:
            pulumi.set(__self__, "kms_key", kms_key)
        if region is not None:
            pulumi.set(__self__, "region", region)

    @property
    @pulumi.getter
    def destination(self) -> str:
        return pulumi.get(self, "destination")

    @property
    @pulumi.getter(name="cannedAcl")
    def canned_acl(self) -> Optional[str]:
        return pulumi.get(self, "canned_acl")

    @property
    @pulumi.getter(name="enableEncryption")
    def enable_encryption(self) -> Optional[bool]:
        return pulumi.get(self, "enable_encryption")

    @property
    @pulumi.getter(name="encryptionType")
    def encryption_type(self) -> Optional[str]:
        return pulumi.get(self, "encryption_type")

    @property
    @pulumi.getter
    def endpoint(self) -> Optional[str]:
        return pulumi.get(self, "endpoint")

    @property
    @pulumi.getter(name="kmsKey")
    def kms_key(self) -> Optional[str]:
        return pulumi.get(self, "kms_key")

    @property
    @pulumi.getter
    def region(self) -> Optional[str]:
        return pulumi.get(self, "region")


@pulumi.output_type
class GetClusterClusterInfoInitScriptVolumesResult(dict):
    def __init__(__self__, *,
                 destination: str):
        pulumi.set(__self__, "destination", destination)

    @property
    @pulumi.getter
    def destination(self) -> str:
        return pulumi.get(self, "destination")


@pulumi.output_type
class GetClusterClusterInfoInitScriptWorkspaceResult(dict):
    def __init__(__self__, *,
                 destination: str):
        pulumi.set(__self__, "destination", destination)

    @property
    @pulumi.getter
    def destination(self) -> str:
        return pulumi.get(self, "destination")


@pulumi.output_type
class GetClusterClusterInfoSpecResult(dict):
    def __init__(__self__, *,
                 cluster_id: str,
                 driver_instance_pool_id: str,
                 driver_node_type_id: str,
                 enable_elastic_disk: bool,
                 enable_local_disk_encryption: bool,
                 node_type_id: str,
                 spark_version: str,
                 apply_policy_default_values: Optional[bool] = None,
                 autoscale: Optional['outputs.GetClusterClusterInfoSpecAutoscaleResult'] = None,
                 aws_attributes: Optional['outputs.GetClusterClusterInfoSpecAwsAttributesResult'] = None,
                 azure_attributes: Optional['outputs.GetClusterClusterInfoSpecAzureAttributesResult'] = None,
                 cluster_log_conf: Optional['outputs.GetClusterClusterInfoSpecClusterLogConfResult'] = None,
                 cluster_mount_infos: Optional[Sequence['outputs.GetClusterClusterInfoSpecClusterMountInfoResult']] = None,
                 cluster_name: Optional[str] = None,
                 custom_tags: Optional[Mapping[str, str]] = None,
                 data_security_mode: Optional[str] = None,
                 docker_image: Optional['outputs.GetClusterClusterInfoSpecDockerImageResult'] = None,
                 gcp_attributes: Optional['outputs.GetClusterClusterInfoSpecGcpAttributesResult'] = None,
                 idempotency_token: Optional[str] = None,
                 init_scripts: Optional[Sequence['outputs.GetClusterClusterInfoSpecInitScriptResult']] = None,
                 instance_pool_id: Optional[str] = None,
                 libraries: Optional[Sequence['outputs.GetClusterClusterInfoSpecLibraryResult']] = None,
                 num_workers: Optional[int] = None,
                 policy_id: Optional[str] = None,
                 runtime_engine: Optional[str] = None,
                 single_user_name: Optional[str] = None,
                 spark_conf: Optional[Mapping[str, str]] = None,
                 spark_env_vars: Optional[Mapping[str, str]] = None,
                 ssh_public_keys: Optional[Sequence[str]] = None,
                 workload_type: Optional['outputs.GetClusterClusterInfoSpecWorkloadTypeResult'] = None):
        """
        :param str cluster_id: The id of the cluster
        :param str driver_instance_pool_id: similar to `instance_pool_id`, but for driver node.
        :param str driver_node_type_id: The node type of the Spark driver.
        :param bool enable_elastic_disk: Use autoscaling local storage.
        :param bool enable_local_disk_encryption: Enable local disk encryption.
        :param str node_type_id: Any supported get_node_type id.
        :param str spark_version: [Runtime version](https://docs.databricks.com/runtime/index.html) of the cluster.
        :param str cluster_name: The exact name of the cluster to search
        :param Mapping[str, str] custom_tags: Additional tags for cluster resources.
        :param str data_security_mode: Security features of the cluster. Unity Catalog requires `SINGLE_USER` or `USER_ISOLATION` mode. `LEGACY_PASSTHROUGH` for passthrough cluster and `LEGACY_TABLE_ACL` for Table ACL cluster. Default to `NONE`, i.e. no security feature enabled.
        :param str idempotency_token: An optional token to guarantee the idempotency of cluster creation requests.
        :param str instance_pool_id: The pool of idle instances the cluster is attached to.
        :param str policy_id: Identifier of Cluster Policy to validate cluster and preset certain defaults.
        :param str runtime_engine: The type of runtime of the cluster
        :param str single_user_name: The optional user name of the user to assign to an interactive cluster. This field is required when using standard AAD Passthrough for Azure Data Lake Storage (ADLS) with a single-user cluster (i.e., not high-concurrency clusters).
        :param Mapping[str, str] spark_conf: Map with key-value pairs to fine-tune Spark clusters.
        :param Mapping[str, str] spark_env_vars: Map with environment variable key-value pairs to fine-tune Spark clusters. Key-value pairs of the form (X,Y) are exported (i.e., X='Y') while launching the driver and workers.
        :param Sequence[str] ssh_public_keys: SSH public key contents that will be added to each Spark node in this cluster.
        """
        pulumi.set(__self__, "cluster_id", cluster_id)
        pulumi.set(__self__, "driver_instance_pool_id", driver_instance_pool_id)
        pulumi.set(__self__, "driver_node_type_id", driver_node_type_id)
        pulumi.set(__self__, "enable_elastic_disk", enable_elastic_disk)
        pulumi.set(__self__, "enable_local_disk_encryption", enable_local_disk_encryption)
        pulumi.set(__self__, "node_type_id", node_type_id)
        pulumi.set(__self__, "spark_version", spark_version)
        if apply_policy_default_values is not None:
            pulumi.set(__self__, "apply_policy_default_values", apply_policy_default_values)
        if autoscale is not None:
            pulumi.set(__self__, "autoscale", autoscale)
        if aws_attributes is not None:
            pulumi.set(__self__, "aws_attributes", aws_attributes)
        if azure_attributes is not None:
            pulumi.set(__self__, "azure_attributes", azure_attributes)
        if cluster_log_conf is not None:
            pulumi.set(__self__, "cluster_log_conf", cluster_log_conf)
        if cluster_mount_infos is not None:
            pulumi.set(__self__, "cluster_mount_infos", cluster_mount_infos)
        if cluster_name is not None:
            pulumi.set(__self__, "cluster_name", cluster_name)
        if custom_tags is not None:
            pulumi.set(__self__, "custom_tags", custom_tags)
        if data_security_mode is not None:
            pulumi.set(__self__, "data_security_mode", data_security_mode)
        if docker_image is not None:
            pulumi.set(__self__, "docker_image", docker_image)
        if gcp_attributes is not None:
            pulumi.set(__self__, "gcp_attributes", gcp_attributes)
        if idempotency_token is not None:
            pulumi.set(__self__, "idempotency_token", idempotency_token)
        if init_scripts is not None:
            pulumi.set(__self__, "init_scripts", init_scripts)
        if instance_pool_id is not None:
            pulumi.set(__self__, "instance_pool_id", instance_pool_id)
        if libraries is not None:
            pulumi.set(__self__, "libraries", libraries)
        if num_workers is not None:
            pulumi.set(__self__, "num_workers", num_workers)
        if policy_id is not None:
            pulumi.set(__self__, "policy_id", policy_id)
        if runtime_engine is not None:
            pulumi.set(__self__, "runtime_engine", runtime_engine)
        if single_user_name is not None:
            pulumi.set(__self__, "single_user_name", single_user_name)
        if spark_conf is not None:
            pulumi.set(__self__, "spark_conf", spark_conf)
        if spark_env_vars is not None:
            pulumi.set(__self__, "spark_env_vars", spark_env_vars)
        if ssh_public_keys is not None:
            pulumi.set(__self__, "ssh_public_keys", ssh_public_keys)
        if workload_type is not None:
            pulumi.set(__self__, "workload_type", workload_type)

    @property
    @pulumi.getter(name="clusterId")
    def cluster_id(self) -> str:
        """
        The id of the cluster
        """
        return pulumi.get(self, "cluster_id")

    @property
    @pulumi.getter(name="driverInstancePoolId")
    def driver_instance_pool_id(self) -> str:
        """
        similar to `instance_pool_id`, but for driver node.
        """
        return pulumi.get(self, "driver_instance_pool_id")

    @property
    @pulumi.getter(name="driverNodeTypeId")
    def driver_node_type_id(self) -> str:
        """
        The node type of the Spark driver.
        """
        return pulumi.get(self, "driver_node_type_id")

    @property
    @pulumi.getter(name="enableElasticDisk")
    def enable_elastic_disk(self) -> bool:
        """
        Use autoscaling local storage.
        """
        return pulumi.get(self, "enable_elastic_disk")

    @property
    @pulumi.getter(name="enableLocalDiskEncryption")
    def enable_local_disk_encryption(self) -> bool:
        """
        Enable local disk encryption.
        """
        return pulumi.get(self, "enable_local_disk_encryption")

    @property
    @pulumi.getter(name="nodeTypeId")
    def node_type_id(self) -> str:
        """
        Any supported get_node_type id.
        """
        return pulumi.get(self, "node_type_id")

    @property
    @pulumi.getter(name="sparkVersion")
    def spark_version(self) -> str:
        """
        [Runtime version](https://docs.databricks.com/runtime/index.html) of the cluster.
        """
        return pulumi.get(self, "spark_version")

    @property
    @pulumi.getter(name="applyPolicyDefaultValues")
    def apply_policy_default_values(self) -> Optional[bool]:
        return pulumi.get(self, "apply_policy_default_values")

    @property
    @pulumi.getter
    def autoscale(self) -> Optional['outputs.GetClusterClusterInfoSpecAutoscaleResult']:
        return pulumi.get(self, "autoscale")

    @property
    @pulumi.getter(name="awsAttributes")
    def aws_attributes(self) -> Optional['outputs.GetClusterClusterInfoSpecAwsAttributesResult']:
        return pulumi.get(self, "aws_attributes")

    @property
    @pulumi.getter(name="azureAttributes")
    def azure_attributes(self) -> Optional['outputs.GetClusterClusterInfoSpecAzureAttributesResult']:
        return pulumi.get(self, "azure_attributes")

    @property
    @pulumi.getter(name="clusterLogConf")
    def cluster_log_conf(self) -> Optional['outputs.GetClusterClusterInfoSpecClusterLogConfResult']:
        return pulumi.get(self, "cluster_log_conf")

    @property
    @pulumi.getter(name="clusterMountInfos")
    def cluster_mount_infos(self) -> Optional[Sequence['outputs.GetClusterClusterInfoSpecClusterMountInfoResult']]:
        return pulumi.get(self, "cluster_mount_infos")

    @property
    @pulumi.getter(name="clusterName")
    def cluster_name(self) -> Optional[str]:
        """
        The exact name of the cluster to search
        """
        return pulumi.get(self, "cluster_name")

    @property
    @pulumi.getter(name="customTags")
    def custom_tags(self) -> Optional[Mapping[str, str]]:
        """
        Additional tags for cluster resources.
        """
        return pulumi.get(self, "custom_tags")

    @property
    @pulumi.getter(name="dataSecurityMode")
    def data_security_mode(self) -> Optional[str]:
        """
        Security features of the cluster. Unity Catalog requires `SINGLE_USER` or `USER_ISOLATION` mode. `LEGACY_PASSTHROUGH` for passthrough cluster and `LEGACY_TABLE_ACL` for Table ACL cluster. Default to `NONE`, i.e. no security feature enabled.
        """
        return pulumi.get(self, "data_security_mode")

    @property
    @pulumi.getter(name="dockerImage")
    def docker_image(self) -> Optional['outputs.GetClusterClusterInfoSpecDockerImageResult']:
        return pulumi.get(self, "docker_image")

    @property
    @pulumi.getter(name="gcpAttributes")
    def gcp_attributes(self) -> Optional['outputs.GetClusterClusterInfoSpecGcpAttributesResult']:
        return pulumi.get(self, "gcp_attributes")

    @property
    @pulumi.getter(name="idempotencyToken")
    def idempotency_token(self) -> Optional[str]:
        """
        An optional token to guarantee the idempotency of cluster creation requests.
        """
        return pulumi.get(self, "idempotency_token")

    @property
    @pulumi.getter(name="initScripts")
    def init_scripts(self) -> Optional[Sequence['outputs.GetClusterClusterInfoSpecInitScriptResult']]:
        return pulumi.get(self, "init_scripts")

    @property
    @pulumi.getter(name="instancePoolId")
    def instance_pool_id(self) -> Optional[str]:
        """
        The pool of idle instances the cluster is attached to.
        """
        return pulumi.get(self, "instance_pool_id")

    @property
    @pulumi.getter
    def libraries(self) -> Optional[Sequence['outputs.GetClusterClusterInfoSpecLibraryResult']]:
        return pulumi.get(self, "libraries")

    @property
    @pulumi.getter(name="numWorkers")
    def num_workers(self) -> Optional[int]:
        return pulumi.get(self, "num_workers")

    @property
    @pulumi.getter(name="policyId")
    def policy_id(self) -> Optional[str]:
        """
        Identifier of Cluster Policy to validate cluster and preset certain defaults.
        """
        return pulumi.get(self, "policy_id")

    @property
    @pulumi.getter(name="runtimeEngine")
    def runtime_engine(self) -> Optional[str]:
        """
        The type of runtime of the cluster
        """
        return pulumi.get(self, "runtime_engine")

    @property
    @pulumi.getter(name="singleUserName")
    def single_user_name(self) -> Optional[str]:
        """
        The optional user name of the user to assign to an interactive cluster. This field is required when using standard AAD Passthrough for Azure Data Lake Storage (ADLS) with a single-user cluster (i.e., not high-concurrency clusters).
        """
        return pulumi.get(self, "single_user_name")

    @property
    @pulumi.getter(name="sparkConf")
    def spark_conf(self) -> Optional[Mapping[str, str]]:
        """
        Map with key-value pairs to fine-tune Spark clusters.
        """
        return pulumi.get(self, "spark_conf")

    @property
    @pulumi.getter(name="sparkEnvVars")
    def spark_env_vars(self) -> Optional[Mapping[str, str]]:
        """
        Map with environment variable key-value pairs to fine-tune Spark clusters. Key-value pairs of the form (X,Y) are exported (i.e., X='Y') while launching the driver and workers.
        """
        return pulumi.get(self, "spark_env_vars")

    @property
    @pulumi.getter(name="sshPublicKeys")
    def ssh_public_keys(self) -> Optional[Sequence[str]]:
        """
        SSH public key contents that will be added to each Spark node in this cluster.
        """
        return pulumi.get(self, "ssh_public_keys")

    @property
    @pulumi.getter(name="workloadType")
    def workload_type(self) -> Optional['outputs.GetClusterClusterInfoSpecWorkloadTypeResult']:
        return pulumi.get(self, "workload_type")


@pulumi.output_type
class GetClusterClusterInfoSpecAutoscaleResult(dict):
    def __init__(__self__, *,
                 max_workers: Optional[int] = None,
                 min_workers: Optional[int] = None):
        if max_workers is not None:
            pulumi.set(__self__, "max_workers", max_workers)
        if min_workers is not None:
            pulumi.set(__self__, "min_workers", min_workers)

    @property
    @pulumi.getter(name="maxWorkers")
    def max_workers(self) -> Optional[int]:
        return pulumi.get(self, "max_workers")

    @property
    @pulumi.getter(name="minWorkers")
    def min_workers(self) -> Optional[int]:
        return pulumi.get(self, "min_workers")


@pulumi.output_type
class GetClusterClusterInfoSpecAwsAttributesResult(dict):
    def __init__(__self__, *,
                 availability: Optional[str] = None,
                 ebs_volume_count: Optional[int] = None,
                 ebs_volume_iops: Optional[int] = None,
                 ebs_volume_size: Optional[int] = None,
                 ebs_volume_throughput: Optional[int] = None,
                 ebs_volume_type: Optional[str] = None,
                 first_on_demand: Optional[int] = None,
                 instance_profile_arn: Optional[str] = None,
                 spot_bid_price_percent: Optional[int] = None,
                 zone_id: Optional[str] = None):
        if availability is not None:
            pulumi.set(__self__, "availability", availability)
        if ebs_volume_count is not None:
            pulumi.set(__self__, "ebs_volume_count", ebs_volume_count)
        if ebs_volume_iops is not None:
            pulumi.set(__self__, "ebs_volume_iops", ebs_volume_iops)
        if ebs_volume_size is not None:
            pulumi.set(__self__, "ebs_volume_size", ebs_volume_size)
        if ebs_volume_throughput is not None:
            pulumi.set(__self__, "ebs_volume_throughput", ebs_volume_throughput)
        if ebs_volume_type is not None:
            pulumi.set(__self__, "ebs_volume_type", ebs_volume_type)
        if first_on_demand is not None:
            pulumi.set(__self__, "first_on_demand", first_on_demand)
        if instance_profile_arn is not None:
            pulumi.set(__self__, "instance_profile_arn", instance_profile_arn)
        if spot_bid_price_percent is not None:
            pulumi.set(__self__, "spot_bid_price_percent", spot_bid_price_percent)
        if zone_id is not None:
            pulumi.set(__self__, "zone_id", zone_id)

    @property
    @pulumi.getter
    def availability(self) -> Optional[str]:
        return pulumi.get(self, "availability")

    @property
    @pulumi.getter(name="ebsVolumeCount")
    def ebs_volume_count(self) -> Optional[int]:
        return pulumi.get(self, "ebs_volume_count")

    @property
    @pulumi.getter(name="ebsVolumeIops")
    def ebs_volume_iops(self) -> Optional[int]:
        return pulumi.get(self, "ebs_volume_iops")

    @property
    @pulumi.getter(name="ebsVolumeSize")
    def ebs_volume_size(self) -> Optional[int]:
        return pulumi.get(self, "ebs_volume_size")

    @property
    @pulumi.getter(name="ebsVolumeThroughput")
    def ebs_volume_throughput(self) -> Optional[int]:
        return pulumi.get(self, "ebs_volume_throughput")

    @property
    @pulumi.getter(name="ebsVolumeType")
    def ebs_volume_type(self) -> Optional[str]:
        return pulumi.get(self, "ebs_volume_type")

    @property
    @pulumi.getter(name="firstOnDemand")
    def first_on_demand(self) -> Optional[int]:
        return pulumi.get(self, "first_on_demand")

    @property
    @pulumi.getter(name="instanceProfileArn")
    def instance_profile_arn(self) -> Optional[str]:
        return pulumi.get(self, "instance_profile_arn")

    @property
    @pulumi.getter(name="spotBidPricePercent")
    def spot_bid_price_percent(self) -> Optional[int]:
        return pulumi.get(self, "spot_bid_price_percent")

    @property
    @pulumi.getter(name="zoneId")
    def zone_id(self) -> Optional[str]:
        return pulumi.get(self, "zone_id")


@pulumi.output_type
class GetClusterClusterInfoSpecAzureAttributesResult(dict):
    def __init__(__self__, *,
                 availability: Optional[str] = None,
                 first_on_demand: Optional[int] = None,
                 log_analytics_info: Optional['outputs.GetClusterClusterInfoSpecAzureAttributesLogAnalyticsInfoResult'] = None,
                 spot_bid_max_price: Optional[float] = None):
        if availability is not None:
            pulumi.set(__self__, "availability", availability)
        if first_on_demand is not None:
            pulumi.set(__self__, "first_on_demand", first_on_demand)
        if log_analytics_info is not None:
            pulumi.set(__self__, "log_analytics_info", log_analytics_info)
        if spot_bid_max_price is not None:
            pulumi.set(__self__, "spot_bid_max_price", spot_bid_max_price)

    @property
    @pulumi.getter
    def availability(self) -> Optional[str]:
        return pulumi.get(self, "availability")

    @property
    @pulumi.getter(name="firstOnDemand")
    def first_on_demand(self) -> Optional[int]:
        return pulumi.get(self, "first_on_demand")

    @property
    @pulumi.getter(name="logAnalyticsInfo")
    def log_analytics_info(self) -> Optional['outputs.GetClusterClusterInfoSpecAzureAttributesLogAnalyticsInfoResult']:
        return pulumi.get(self, "log_analytics_info")

    @property
    @pulumi.getter(name="spotBidMaxPrice")
    def spot_bid_max_price(self) -> Optional[float]:
        return pulumi.get(self, "spot_bid_max_price")


@pulumi.output_type
class GetClusterClusterInfoSpecAzureAttributesLogAnalyticsInfoResult(dict):
    def __init__(__self__, *,
                 log_analytics_primary_key: Optional[str] = None,
                 log_analytics_workspace_id: Optional[str] = None):
        if log_analytics_primary_key is not None:
            pulumi.set(__self__, "log_analytics_primary_key", log_analytics_primary_key)
        if log_analytics_workspace_id is not None:
            pulumi.set(__self__, "log_analytics_workspace_id", log_analytics_workspace_id)

    @property
    @pulumi.getter(name="logAnalyticsPrimaryKey")
    def log_analytics_primary_key(self) -> Optional[str]:
        return pulumi.get(self, "log_analytics_primary_key")

    @property
    @pulumi.getter(name="logAnalyticsWorkspaceId")
    def log_analytics_workspace_id(self) -> Optional[str]:
        return pulumi.get(self, "log_analytics_workspace_id")


@pulumi.output_type
class GetClusterClusterInfoSpecClusterLogConfResult(dict):
    def __init__(__self__, *,
                 dbfs: Optional['outputs.GetClusterClusterInfoSpecClusterLogConfDbfsResult'] = None,
                 s3: Optional['outputs.GetClusterClusterInfoSpecClusterLogConfS3Result'] = None):
        if dbfs is not None:
            pulumi.set(__self__, "dbfs", dbfs)
        if s3 is not None:
            pulumi.set(__self__, "s3", s3)

    @property
    @pulumi.getter
    def dbfs(self) -> Optional['outputs.GetClusterClusterInfoSpecClusterLogConfDbfsResult']:
        return pulumi.get(self, "dbfs")

    @property
    @pulumi.getter
    def s3(self) -> Optional['outputs.GetClusterClusterInfoSpecClusterLogConfS3Result']:
        return pulumi.get(self, "s3")


@pulumi.output_type
class GetClusterClusterInfoSpecClusterLogConfDbfsResult(dict):
    def __init__(__self__, *,
                 destination: str):
        pulumi.set(__self__, "destination", destination)

    @property
    @pulumi.getter
    def destination(self) -> str:
        return pulumi.get(self, "destination")


@pulumi.output_type
class GetClusterClusterInfoSpecClusterLogConfS3Result(dict):
    def __init__(__self__, *,
                 destination: str,
                 canned_acl: Optional[str] = None,
                 enable_encryption: Optional[bool] = None,
                 encryption_type: Optional[str] = None,
                 endpoint: Optional[str] = None,
                 kms_key: Optional[str] = None,
                 region: Optional[str] = None):
        pulumi.set(__self__, "destination", destination)
        if canned_acl is not None:
            pulumi.set(__self__, "canned_acl", canned_acl)
        if enable_encryption is not None:
            pulumi.set(__self__, "enable_encryption", enable_encryption)
        if encryption_type is not None:
            pulumi.set(__self__, "encryption_type", encryption_type)
        if endpoint is not None:
            pulumi.set(__self__, "endpoint", endpoint)
        if kms_key is not None:
            pulumi.set(__self__, "kms_key", kms_key)
        if region is not None:
            pulumi.set(__self__, "region", region)

    @property
    @pulumi.getter
    def destination(self) -> str:
        return pulumi.get(self, "destination")

    @property
    @pulumi.getter(name="cannedAcl")
    def canned_acl(self) -> Optional[str]:
        return pulumi.get(self, "canned_acl")

    @property
    @pulumi.getter(name="enableEncryption")
    def enable_encryption(self) -> Optional[bool]:
        return pulumi.get(self, "enable_encryption")

    @property
    @pulumi.getter(name="encryptionType")
    def encryption_type(self) -> Optional[str]:
        return pulumi.get(self, "encryption_type")

    @property
    @pulumi.getter
    def endpoint(self) -> Optional[str]:
        return pulumi.get(self, "endpoint")

    @property
    @pulumi.getter(name="kmsKey")
    def kms_key(self) -> Optional[str]:
        return pulumi.get(self, "kms_key")

    @property
    @pulumi.getter
    def region(self) -> Optional[str]:
        return pulumi.get(self, "region")


@pulumi.output_type
class GetClusterClusterInfoSpecClusterMountInfoResult(dict):
    def __init__(__self__, *,
                 local_mount_dir_path: str,
                 network_filesystem_info: 'outputs.GetClusterClusterInfoSpecClusterMountInfoNetworkFilesystemInfoResult',
                 remote_mount_dir_path: Optional[str] = None):
        pulumi.set(__self__, "local_mount_dir_path", local_mount_dir_path)
        pulumi.set(__self__, "network_filesystem_info", network_filesystem_info)
        if remote_mount_dir_path is not None:
            pulumi.set(__self__, "remote_mount_dir_path", remote_mount_dir_path)

    @property
    @pulumi.getter(name="localMountDirPath")
    def local_mount_dir_path(self) -> str:
        return pulumi.get(self, "local_mount_dir_path")

    @property
    @pulumi.getter(name="networkFilesystemInfo")
    def network_filesystem_info(self) -> 'outputs.GetClusterClusterInfoSpecClusterMountInfoNetworkFilesystemInfoResult':
        return pulumi.get(self, "network_filesystem_info")

    @property
    @pulumi.getter(name="remoteMountDirPath")
    def remote_mount_dir_path(self) -> Optional[str]:
        return pulumi.get(self, "remote_mount_dir_path")


@pulumi.output_type
class GetClusterClusterInfoSpecClusterMountInfoNetworkFilesystemInfoResult(dict):
    def __init__(__self__, *,
                 server_address: str,
                 mount_options: Optional[str] = None):
        pulumi.set(__self__, "server_address", server_address)
        if mount_options is not None:
            pulumi.set(__self__, "mount_options", mount_options)

    @property
    @pulumi.getter(name="serverAddress")
    def server_address(self) -> str:
        return pulumi.get(self, "server_address")

    @property
    @pulumi.getter(name="mountOptions")
    def mount_options(self) -> Optional[str]:
        return pulumi.get(self, "mount_options")


@pulumi.output_type
class GetClusterClusterInfoSpecDockerImageResult(dict):
    def __init__(__self__, *,
                 url: str,
                 basic_auth: Optional['outputs.GetClusterClusterInfoSpecDockerImageBasicAuthResult'] = None):
        pulumi.set(__self__, "url", url)
        if basic_auth is not None:
            pulumi.set(__self__, "basic_auth", basic_auth)

    @property
    @pulumi.getter
    def url(self) -> str:
        return pulumi.get(self, "url")

    @property
    @pulumi.getter(name="basicAuth")
    def basic_auth(self) -> Optional['outputs.GetClusterClusterInfoSpecDockerImageBasicAuthResult']:
        return pulumi.get(self, "basic_auth")


@pulumi.output_type
class GetClusterClusterInfoSpecDockerImageBasicAuthResult(dict):
    def __init__(__self__, *,
                 password: str,
                 username: str):
        pulumi.set(__self__, "password", password)
        pulumi.set(__self__, "username", username)

    @property
    @pulumi.getter
    def password(self) -> str:
        return pulumi.get(self, "password")

    @property
    @pulumi.getter
    def username(self) -> str:
        return pulumi.get(self, "username")


@pulumi.output_type
class GetClusterClusterInfoSpecGcpAttributesResult(dict):
    def __init__(__self__, *,
                 availability: Optional[str] = None,
                 boot_disk_size: Optional[int] = None,
                 google_service_account: Optional[str] = None,
                 local_ssd_count: Optional[int] = None,
                 use_preemptible_executors: Optional[bool] = None,
                 zone_id: Optional[str] = None):
        if availability is not None:
            pulumi.set(__self__, "availability", availability)
        if boot_disk_size is not None:
            pulumi.set(__self__, "boot_disk_size", boot_disk_size)
        if google_service_account is not None:
            pulumi.set(__self__, "google_service_account", google_service_account)
        if local_ssd_count is not None:
            pulumi.set(__self__, "local_ssd_count", local_ssd_count)
        if use_preemptible_executors is not None:
            pulumi.set(__self__, "use_preemptible_executors", use_preemptible_executors)
        if zone_id is not None:
            pulumi.set(__self__, "zone_id", zone_id)

    @property
    @pulumi.getter
    def availability(self) -> Optional[str]:
        return pulumi.get(self, "availability")

    @property
    @pulumi.getter(name="bootDiskSize")
    def boot_disk_size(self) -> Optional[int]:
        return pulumi.get(self, "boot_disk_size")

    @property
    @pulumi.getter(name="googleServiceAccount")
    def google_service_account(self) -> Optional[str]:
        return pulumi.get(self, "google_service_account")

    @property
    @pulumi.getter(name="localSsdCount")
    def local_ssd_count(self) -> Optional[int]:
        return pulumi.get(self, "local_ssd_count")

    @property
    @pulumi.getter(name="usePreemptibleExecutors")
    def use_preemptible_executors(self) -> Optional[bool]:
        return pulumi.get(self, "use_preemptible_executors")

    @property
    @pulumi.getter(name="zoneId")
    def zone_id(self) -> Optional[str]:
        return pulumi.get(self, "zone_id")


@pulumi.output_type
class GetClusterClusterInfoSpecInitScriptResult(dict):
    def __init__(__self__, *,
                 abfss: Optional['outputs.GetClusterClusterInfoSpecInitScriptAbfssResult'] = None,
                 dbfs: Optional['outputs.GetClusterClusterInfoSpecInitScriptDbfsResult'] = None,
                 file: Optional['outputs.GetClusterClusterInfoSpecInitScriptFileResult'] = None,
                 gcs: Optional['outputs.GetClusterClusterInfoSpecInitScriptGcsResult'] = None,
                 s3: Optional['outputs.GetClusterClusterInfoSpecInitScriptS3Result'] = None,
                 volumes: Optional['outputs.GetClusterClusterInfoSpecInitScriptVolumesResult'] = None,
                 workspace: Optional['outputs.GetClusterClusterInfoSpecInitScriptWorkspaceResult'] = None):
        if abfss is not None:
            pulumi.set(__self__, "abfss", abfss)
        if dbfs is not None:
            pulumi.set(__self__, "dbfs", dbfs)
        if file is not None:
            pulumi.set(__self__, "file", file)
        if gcs is not None:
            pulumi.set(__self__, "gcs", gcs)
        if s3 is not None:
            pulumi.set(__self__, "s3", s3)
        if volumes is not None:
            pulumi.set(__self__, "volumes", volumes)
        if workspace is not None:
            pulumi.set(__self__, "workspace", workspace)

    @property
    @pulumi.getter
    def abfss(self) -> Optional['outputs.GetClusterClusterInfoSpecInitScriptAbfssResult']:
        return pulumi.get(self, "abfss")

    @property
    @pulumi.getter
    @_utilities.deprecated("""For init scripts use 'volumes', 'workspace' or cloud storage location instead of 'dbfs'.""")
    def dbfs(self) -> Optional['outputs.GetClusterClusterInfoSpecInitScriptDbfsResult']:
        return pulumi.get(self, "dbfs")

    @property
    @pulumi.getter
    def file(self) -> Optional['outputs.GetClusterClusterInfoSpecInitScriptFileResult']:
        return pulumi.get(self, "file")

    @property
    @pulumi.getter
    def gcs(self) -> Optional['outputs.GetClusterClusterInfoSpecInitScriptGcsResult']:
        return pulumi.get(self, "gcs")

    @property
    @pulumi.getter
    def s3(self) -> Optional['outputs.GetClusterClusterInfoSpecInitScriptS3Result']:
        return pulumi.get(self, "s3")

    @property
    @pulumi.getter
    def volumes(self) -> Optional['outputs.GetClusterClusterInfoSpecInitScriptVolumesResult']:
        return pulumi.get(self, "volumes")

    @property
    @pulumi.getter
    def workspace(self) -> Optional['outputs.GetClusterClusterInfoSpecInitScriptWorkspaceResult']:
        return pulumi.get(self, "workspace")


@pulumi.output_type
class GetClusterClusterInfoSpecInitScriptAbfssResult(dict):
    def __init__(__self__, *,
                 destination: str):
        pulumi.set(__self__, "destination", destination)

    @property
    @pulumi.getter
    def destination(self) -> str:
        return pulumi.get(self, "destination")


@pulumi.output_type
class GetClusterClusterInfoSpecInitScriptDbfsResult(dict):
    def __init__(__self__, *,
                 destination: str):
        pulumi.set(__self__, "destination", destination)

    @property
    @pulumi.getter
    def destination(self) -> str:
        return pulumi.get(self, "destination")


@pulumi.output_type
class GetClusterClusterInfoSpecInitScriptFileResult(dict):
    def __init__(__self__, *,
                 destination: str):
        pulumi.set(__self__, "destination", destination)

    @property
    @pulumi.getter
    def destination(self) -> str:
        return pulumi.get(self, "destination")


@pulumi.output_type
class GetClusterClusterInfoSpecInitScriptGcsResult(dict):
    def __init__(__self__, *,
                 destination: str):
        pulumi.set(__self__, "destination", destination)

    @property
    @pulumi.getter
    def destination(self) -> str:
        return pulumi.get(self, "destination")


@pulumi.output_type
class GetClusterClusterInfoSpecInitScriptS3Result(dict):
    def __init__(__self__, *,
                 destination: str,
                 canned_acl: Optional[str] = None,
                 enable_encryption: Optional[bool] = None,
                 encryption_type: Optional[str] = None,
                 endpoint: Optional[str] = None,
                 kms_key: Optional[str] = None,
                 region: Optional[str] = None):
        pulumi.set(__self__, "destination", destination)
        if canned_acl is not None:
            pulumi.set(__self__, "canned_acl", canned_acl)
        if enable_encryption is not None:
            pulumi.set(__self__, "enable_encryption", enable_encryption)
        if encryption_type is not None:
            pulumi.set(__self__, "encryption_type", encryption_type)
        if endpoint is not None:
            pulumi.set(__self__, "endpoint", endpoint)
        if kms_key is not None:
            pulumi.set(__self__, "kms_key", kms_key)
        if region is not None:
            pulumi.set(__self__, "region", region)

    @property
    @pulumi.getter
    def destination(self) -> str:
        return pulumi.get(self, "destination")

    @property
    @pulumi.getter(name="cannedAcl")
    def canned_acl(self) -> Optional[str]:
        return pulumi.get(self, "canned_acl")

    @property
    @pulumi.getter(name="enableEncryption")
    def enable_encryption(self) -> Optional[bool]:
        return pulumi.get(self, "enable_encryption")

    @property
    @pulumi.getter(name="encryptionType")
    def encryption_type(self) -> Optional[str]:
        return pulumi.get(self, "encryption_type")

    @property
    @pulumi.getter
    def endpoint(self) -> Optional[str]:
        return pulumi.get(self, "endpoint")

    @property
    @pulumi.getter(name="kmsKey")
    def kms_key(self) -> Optional[str]:
        return pulumi.get(self, "kms_key")

    @property
    @pulumi.getter
    def region(self) -> Optional[str]:
        return pulumi.get(self, "region")


@pulumi.output_type
class GetClusterClusterInfoSpecInitScriptVolumesResult(dict):
    def __init__(__self__, *,
                 destination: str):
        pulumi.set(__self__, "destination", destination)

    @property
    @pulumi.getter
    def destination(self) -> str:
        return pulumi.get(self, "destination")


@pulumi.output_type
class GetClusterClusterInfoSpecInitScriptWorkspaceResult(dict):
    def __init__(__self__, *,
                 destination: str):
        pulumi.set(__self__, "destination", destination)

    @property
    @pulumi.getter
    def destination(self) -> str:
        return pulumi.get(self, "destination")


@pulumi.output_type
class GetClusterClusterInfoSpecLibraryResult(dict):
    def __init__(__self__, *,
                 cran: Optional['outputs.GetClusterClusterInfoSpecLibraryCranResult'] = None,
                 egg: Optional[str] = None,
                 jar: Optional[str] = None,
                 maven: Optional['outputs.GetClusterClusterInfoSpecLibraryMavenResult'] = None,
                 pypi: Optional['outputs.GetClusterClusterInfoSpecLibraryPypiResult'] = None,
                 requirements: Optional[str] = None,
                 whl: Optional[str] = None):
        if cran is not None:
            pulumi.set(__self__, "cran", cran)
        if egg is not None:
            pulumi.set(__self__, "egg", egg)
        if jar is not None:
            pulumi.set(__self__, "jar", jar)
        if maven is not None:
            pulumi.set(__self__, "maven", maven)
        if pypi is not None:
            pulumi.set(__self__, "pypi", pypi)
        if requirements is not None:
            pulumi.set(__self__, "requirements", requirements)
        if whl is not None:
            pulumi.set(__self__, "whl", whl)

    @property
    @pulumi.getter
    def cran(self) -> Optional['outputs.GetClusterClusterInfoSpecLibraryCranResult']:
        return pulumi.get(self, "cran")

    @property
    @pulumi.getter
    def egg(self) -> Optional[str]:
        return pulumi.get(self, "egg")

    @property
    @pulumi.getter
    def jar(self) -> Optional[str]:
        return pulumi.get(self, "jar")

    @property
    @pulumi.getter
    def maven(self) -> Optional['outputs.GetClusterClusterInfoSpecLibraryMavenResult']:
        return pulumi.get(self, "maven")

    @property
    @pulumi.getter
    def pypi(self) -> Optional['outputs.GetClusterClusterInfoSpecLibraryPypiResult']:
        return pulumi.get(self, "pypi")

    @property
    @pulumi.getter
    def requirements(self) -> Optional[str]:
        return pulumi.get(self, "requirements")

    @property
    @pulumi.getter
    def whl(self) -> Optional[str]:
        return pulumi.get(self, "whl")


@pulumi.output_type
class GetClusterClusterInfoSpecLibraryCranResult(dict):
    def __init__(__self__, *,
                 package: str,
                 repo: Optional[str] = None):
        pulumi.set(__self__, "package", package)
        if repo is not None:
            pulumi.set(__self__, "repo", repo)

    @property
    @pulumi.getter
    def package(self) -> str:
        return pulumi.get(self, "package")

    @property
    @pulumi.getter
    def repo(self) -> Optional[str]:
        return pulumi.get(self, "repo")


@pulumi.output_type
class GetClusterClusterInfoSpecLibraryMavenResult(dict):
    def __init__(__self__, *,
                 coordinates: str,
                 exclusions: Optional[Sequence[str]] = None,
                 repo: Optional[str] = None):
        pulumi.set(__self__, "coordinates", coordinates)
        if exclusions is not None:
            pulumi.set(__self__, "exclusions", exclusions)
        if repo is not None:
            pulumi.set(__self__, "repo", repo)

    @property
    @pulumi.getter
    def coordinates(self) -> str:
        return pulumi.get(self, "coordinates")

    @property
    @pulumi.getter
    def exclusions(self) -> Optional[Sequence[str]]:
        return pulumi.get(self, "exclusions")

    @property
    @pulumi.getter
    def repo(self) -> Optional[str]:
        return pulumi.get(self, "repo")


@pulumi.output_type
class GetClusterClusterInfoSpecLibraryPypiResult(dict):
    def __init__(__self__, *,
                 package: str,
                 repo: Optional[str] = None):
        pulumi.set(__self__, "package", package)
        if repo is not None:
            pulumi.set(__self__, "repo", repo)

    @property
    @pulumi.getter
    def package(self) -> str:
        return pulumi.get(self, "package")

    @property
    @pulumi.getter
    def repo(self) -> Optional[str]:
        return pulumi.get(self, "repo")


@pulumi.output_type
class GetClusterClusterInfoSpecWorkloadTypeResult(dict):
    def __init__(__self__, *,
                 clients: 'outputs.GetClusterClusterInfoSpecWorkloadTypeClientsResult'):
        pulumi.set(__self__, "clients", clients)

    @property
    @pulumi.getter
    def clients(self) -> 'outputs.GetClusterClusterInfoSpecWorkloadTypeClientsResult':
        return pulumi.get(self, "clients")


@pulumi.output_type
class GetClusterClusterInfoSpecWorkloadTypeClientsResult(dict):
    def __init__(__self__, *,
                 jobs: Optional[bool] = None,
                 notebooks: Optional[bool] = None):
        if jobs is not None:
            pulumi.set(__self__, "jobs", jobs)
        if notebooks is not None:
            pulumi.set(__self__, "notebooks", notebooks)

    @property
    @pulumi.getter
    def jobs(self) -> Optional[bool]:
        return pulumi.get(self, "jobs")

    @property
    @pulumi.getter
    def notebooks(self) -> Optional[bool]:
        return pulumi.get(self, "notebooks")


@pulumi.output_type
class GetClusterClusterInfoTerminationReasonResult(dict):
    def __init__(__self__, *,
                 code: Optional[str] = None,
                 parameters: Optional[Mapping[str, str]] = None,
                 type: Optional[str] = None):
        if code is not None:
            pulumi.set(__self__, "code", code)
        if parameters is not None:
            pulumi.set(__self__, "parameters", parameters)
        if type is not None:
            pulumi.set(__self__, "type", type)

    @property
    @pulumi.getter
    def code(self) -> Optional[str]:
        return pulumi.get(self, "code")

    @property
    @pulumi.getter
    def parameters(self) -> Optional[Mapping[str, str]]:
        return pulumi.get(self, "parameters")

    @property
    @pulumi.getter
    def type(self) -> Optional[str]:
        return pulumi.get(self, "type")


@pulumi.output_type
class GetClusterClusterInfoWorkloadTypeResult(dict):
    def __init__(__self__, *,
                 clients: 'outputs.GetClusterClusterInfoWorkloadTypeClientsResult'):
        pulumi.set(__self__, "clients", clients)

    @property
    @pulumi.getter
    def clients(self) -> 'outputs.GetClusterClusterInfoWorkloadTypeClientsResult':
        return pulumi.get(self, "clients")


@pulumi.output_type
class GetClusterClusterInfoWorkloadTypeClientsResult(dict):
    def __init__(__self__, *,
                 jobs: Optional[bool] = None,
                 notebooks: Optional[bool] = None):
        if jobs is not None:
            pulumi.set(__self__, "jobs", jobs)
        if notebooks is not None:
            pulumi.set(__self__, "notebooks", notebooks)

    @property
    @pulumi.getter
    def jobs(self) -> Optional[bool]:
        return pulumi.get(self, "jobs")

    @property
    @pulumi.getter
    def notebooks(self) -> Optional[bool]:
        return pulumi.get(self, "notebooks")


@pulumi.output_type
class GetCurrentMetastoreMetastoreInfoResult(dict):
    def __init__(__self__, *,
                 cloud: Optional[str] = None,
                 created_at: Optional[int] = None,
                 created_by: Optional[str] = None,
                 default_data_access_config_id: Optional[str] = None,
                 delta_sharing_organization_name: Optional[str] = None,
                 delta_sharing_recipient_token_lifetime_in_seconds: Optional[int] = None,
                 delta_sharing_scope: Optional[str] = None,
                 global_metastore_id: Optional[str] = None,
                 metastore_id: Optional[str] = None,
                 name: Optional[str] = None,
                 owner: Optional[str] = None,
                 privilege_model_version: Optional[str] = None,
                 region: Optional[str] = None,
                 storage_root: Optional[str] = None,
                 storage_root_credential_id: Optional[str] = None,
                 storage_root_credential_name: Optional[str] = None,
                 updated_at: Optional[int] = None,
                 updated_by: Optional[str] = None):
        """
        :param int created_at: Timestamp (in milliseconds) when the current metastore was created.
        :param str created_by: the ID of the identity that created the current metastore.
        :param str default_data_access_config_id: the ID of the default data access configuration.
        :param str delta_sharing_organization_name: The organization name of a Delta Sharing entity. This field is used for Databricks to Databricks sharing.
        :param int delta_sharing_recipient_token_lifetime_in_seconds: the expiration duration in seconds on recipient data access tokens.
        :param str delta_sharing_scope: Used to enable delta sharing on the metastore. Valid values: INTERNAL, INTERNAL_AND_EXTERNAL. INTERNAL only allows sharing within the same account, and INTERNAL_AND_EXTERNAL allows cross account sharing and token based sharing.
        :param str global_metastore_id: Identifier in form of `<cloud>:<region>:<metastore_id>` for use in Databricks to Databricks Delta Sharing.
        :param str metastore_id: Metastore ID.
        :param str name: Name of metastore.
        :param str owner: Username/group name/sp application_id of the metastore owner.
        :param str privilege_model_version: the version of the privilege model used by the metastore.
        :param str region: (Mandatory for account-level) The region of the metastore.
        :param str storage_root: Path on cloud storage account, where managed `Table` are stored.
        :param str storage_root_credential_id: ID of a storage credential used for the `storage_root`.
        :param str storage_root_credential_name: Name of a storage credential used for the `storage_root`.
        :param int updated_at: Timestamp (in milliseconds) when the current metastore was updated.
        :param str updated_by: the ID of the identity that updated the current metastore.
        """
        if cloud is not None:
            pulumi.set(__self__, "cloud", cloud)
        if created_at is not None:
            pulumi.set(__self__, "created_at", created_at)
        if created_by is not None:
            pulumi.set(__self__, "created_by", created_by)
        if default_data_access_config_id is not None:
            pulumi.set(__self__, "default_data_access_config_id", default_data_access_config_id)
        if delta_sharing_organization_name is not None:
            pulumi.set(__self__, "delta_sharing_organization_name", delta_sharing_organization_name)
        if delta_sharing_recipient_token_lifetime_in_seconds is not None:
            pulumi.set(__self__, "delta_sharing_recipient_token_lifetime_in_seconds", delta_sharing_recipient_token_lifetime_in_seconds)
        if delta_sharing_scope is not None:
            pulumi.set(__self__, "delta_sharing_scope", delta_sharing_scope)
        if global_metastore_id is not None:
            pulumi.set(__self__, "global_metastore_id", global_metastore_id)
        if metastore_id is not None:
            pulumi.set(__self__, "metastore_id", metastore_id)
        if name is not None:
            pulumi.set(__self__, "name", name)
        if owner is not None:
            pulumi.set(__self__, "owner", owner)
        if privilege_model_version is not None:
            pulumi.set(__self__, "privilege_model_version", privilege_model_version)
        if region is not None:
            pulumi.set(__self__, "region", region)
        if storage_root is not None:
            pulumi.set(__self__, "storage_root", storage_root)
        if storage_root_credential_id is not None:
            pulumi.set(__self__, "storage_root_credential_id", storage_root_credential_id)
        if storage_root_credential_name is not None:
            pulumi.set(__self__, "storage_root_credential_name", storage_root_credential_name)
        if updated_at is not None:
            pulumi.set(__self__, "updated_at", updated_at)
        if updated_by is not None:
            pulumi.set(__self__, "updated_by", updated_by)

    @property
    @pulumi.getter
    def cloud(self) -> Optional[str]:
        return pulumi.get(self, "cloud")

    @property
    @pulumi.getter(name="createdAt")
    def created_at(self) -> Optional[int]:
        """
        Timestamp (in milliseconds) when the current metastore was created.
        """
        return pulumi.get(self, "created_at")

    @property
    @pulumi.getter(name="createdBy")
    def created_by(self) -> Optional[str]:
        """
        the ID of the identity that created the current metastore.
        """
        return pulumi.get(self, "created_by")

    @property
    @pulumi.getter(name="defaultDataAccessConfigId")
    def default_data_access_config_id(self) -> Optional[str]:
        """
        the ID of the default data access configuration.
        """
        return pulumi.get(self, "default_data_access_config_id")

    @property
    @pulumi.getter(name="deltaSharingOrganizationName")
    def delta_sharing_organization_name(self) -> Optional[str]:
        """
        The organization name of a Delta Sharing entity. This field is used for Databricks to Databricks sharing.
        """
        return pulumi.get(self, "delta_sharing_organization_name")

    @property
    @pulumi.getter(name="deltaSharingRecipientTokenLifetimeInSeconds")
    def delta_sharing_recipient_token_lifetime_in_seconds(self) -> Optional[int]:
        """
        the expiration duration in seconds on recipient data access tokens.
        """
        return pulumi.get(self, "delta_sharing_recipient_token_lifetime_in_seconds")

    @property
    @pulumi.getter(name="deltaSharingScope")
    def delta_sharing_scope(self) -> Optional[str]:
        """
        Used to enable delta sharing on the metastore. Valid values: INTERNAL, INTERNAL_AND_EXTERNAL. INTERNAL only allows sharing within the same account, and INTERNAL_AND_EXTERNAL allows cross account sharing and token based sharing.
        """
        return pulumi.get(self, "delta_sharing_scope")

    @property
    @pulumi.getter(name="globalMetastoreId")
    def global_metastore_id(self) -> Optional[str]:
        """
        Identifier in form of `<cloud>:<region>:<metastore_id>` for use in Databricks to Databricks Delta Sharing.
        """
        return pulumi.get(self, "global_metastore_id")

    @property
    @pulumi.getter(name="metastoreId")
    def metastore_id(self) -> Optional[str]:
        """
        Metastore ID.
        """
        return pulumi.get(self, "metastore_id")

    @property
    @pulumi.getter
    def name(self) -> Optional[str]:
        """
        Name of metastore.
        """
        return pulumi.get(self, "name")

    @property
    @pulumi.getter
    def owner(self) -> Optional[str]:
        """
        Username/group name/sp application_id of the metastore owner.
        """
        return pulumi.get(self, "owner")

    @property
    @pulumi.getter(name="privilegeModelVersion")
    def privilege_model_version(self) -> Optional[str]:
        """
        the version of the privilege model used by the metastore.
        """
        return pulumi.get(self, "privilege_model_version")

    @property
    @pulumi.getter
    def region(self) -> Optional[str]:
        """
        (Mandatory for account-level) The region of the metastore.
        """
        return pulumi.get(self, "region")

    @property
    @pulumi.getter(name="storageRoot")
    def storage_root(self) -> Optional[str]:
        """
        Path on cloud storage account, where managed `Table` are stored.
        """
        return pulumi.get(self, "storage_root")

    @property
    @pulumi.getter(name="storageRootCredentialId")
    def storage_root_credential_id(self) -> Optional[str]:
        """
        ID of a storage credential used for the `storage_root`.
        """
        return pulumi.get(self, "storage_root_credential_id")

    @property
    @pulumi.getter(name="storageRootCredentialName")
    def storage_root_credential_name(self) -> Optional[str]:
        """
        Name of a storage credential used for the `storage_root`.
        """
        return pulumi.get(self, "storage_root_credential_name")

    @property
    @pulumi.getter(name="updatedAt")
    def updated_at(self) -> Optional[int]:
        """
        Timestamp (in milliseconds) when the current metastore was updated.
        """
        return pulumi.get(self, "updated_at")

    @property
    @pulumi.getter(name="updatedBy")
    def updated_by(self) -> Optional[str]:
        """
        the ID of the identity that updated the current metastore.
        """
        return pulumi.get(self, "updated_by")


@pulumi.output_type
class GetDbfsFilePathsPathListResult(dict):
    def __init__(__self__, *,
                 file_size: Optional[int] = None,
                 path: Optional[str] = None):
        """
        :param str path: Path on DBFS for the file to perform listing
        """
        if file_size is not None:
            pulumi.set(__self__, "file_size", file_size)
        if path is not None:
            pulumi.set(__self__, "path", path)

    @property
    @pulumi.getter(name="fileSize")
    def file_size(self) -> Optional[int]:
        return pulumi.get(self, "file_size")

    @property
    @pulumi.getter
    def path(self) -> Optional[str]:
        """
        Path on DBFS for the file to perform listing
        """
        return pulumi.get(self, "path")


@pulumi.output_type
class GetExternalLocationExternalLocationInfoResult(dict):
    def __init__(__self__, *,
                 access_point: Optional[str] = None,
                 browse_only: Optional[bool] = None,
                 comment: Optional[str] = None,
                 created_at: Optional[int] = None,
                 created_by: Optional[str] = None,
                 credential_id: Optional[str] = None,
                 credential_name: Optional[str] = None,
                 encryption_details: Optional['outputs.GetExternalLocationExternalLocationInfoEncryptionDetailsResult'] = None,
                 isolation_mode: Optional[str] = None,
                 metastore_id: Optional[str] = None,
                 name: Optional[str] = None,
                 owner: Optional[str] = None,
                 read_only: Optional[bool] = None,
                 updated_at: Optional[int] = None,
                 updated_by: Optional[str] = None,
                 url: Optional[str] = None):
        """
        :param str access_point: The ARN of the s3 access point to use with the external location (AWS).
        :param str comment: User-supplied comment.
        :param int created_at: Time at which this catalog was created, in epoch milliseconds.
        :param str created_by: Username of catalog creator.
        :param str credential_id: Unique ID of storage credential.
        :param str credential_name: Name of the StorageCredential to use with this external location.
        :param 'GetExternalLocationExternalLocationInfoEncryptionDetailsArgs' encryption_details: The options for Server-Side Encryption to be used by each Databricks s3 client when connecting to S3 cloud storage (AWS).
        :param str metastore_id: Unique identifier of the parent Metastore.
        :param str name: The name of the external location
        :param str owner: Username/groupname/sp application_id of the external location owner.
        :param bool read_only: Indicates whether the external location is read-only.
        :param int updated_at: Time at which this catalog was last modified, in epoch milliseconds.
        :param str updated_by: Username of user who last modified catalog.
        :param str url: Path URL in cloud storage, of the form: `s3://[bucket-host]/[bucket-dir]` (AWS), `abfss://[user]@[host]/[path]` (Azure), `gs://[bucket-host]/[bucket-dir]` (GCP).
        """
        if access_point is not None:
            pulumi.set(__self__, "access_point", access_point)
        if browse_only is not None:
            pulumi.set(__self__, "browse_only", browse_only)
        if comment is not None:
            pulumi.set(__self__, "comment", comment)
        if created_at is not None:
            pulumi.set(__self__, "created_at", created_at)
        if created_by is not None:
            pulumi.set(__self__, "created_by", created_by)
        if credential_id is not None:
            pulumi.set(__self__, "credential_id", credential_id)
        if credential_name is not None:
            pulumi.set(__self__, "credential_name", credential_name)
        if encryption_details is not None:
            pulumi.set(__self__, "encryption_details", encryption_details)
        if isolation_mode is not None:
            pulumi.set(__self__, "isolation_mode", isolation_mode)
        if metastore_id is not None:
            pulumi.set(__self__, "metastore_id", metastore_id)
        if name is not None:
            pulumi.set(__self__, "name", name)
        if owner is not None:
            pulumi.set(__self__, "owner", owner)
        if read_only is not None:
            pulumi.set(__self__, "read_only", read_only)
        if updated_at is not None:
            pulumi.set(__self__, "updated_at", updated_at)
        if updated_by is not None:
            pulumi.set(__self__, "updated_by", updated_by)
        if url is not None:
            pulumi.set(__self__, "url", url)

    @property
    @pulumi.getter(name="accessPoint")
    def access_point(self) -> Optional[str]:
        """
        The ARN of the s3 access point to use with the external location (AWS).
        """
        return pulumi.get(self, "access_point")

    @property
    @pulumi.getter(name="browseOnly")
    def browse_only(self) -> Optional[bool]:
        return pulumi.get(self, "browse_only")

    @property
    @pulumi.getter
    def comment(self) -> Optional[str]:
        """
        User-supplied comment.
        """
        return pulumi.get(self, "comment")

    @property
    @pulumi.getter(name="createdAt")
    def created_at(self) -> Optional[int]:
        """
        Time at which this catalog was created, in epoch milliseconds.
        """
        return pulumi.get(self, "created_at")

    @property
    @pulumi.getter(name="createdBy")
    def created_by(self) -> Optional[str]:
        """
        Username of catalog creator.
        """
        return pulumi.get(self, "created_by")

    @property
    @pulumi.getter(name="credentialId")
    def credential_id(self) -> Optional[str]:
        """
        Unique ID of storage credential.
        """
        return pulumi.get(self, "credential_id")

    @property
    @pulumi.getter(name="credentialName")
    def credential_name(self) -> Optional[str]:
        """
        Name of the StorageCredential to use with this external location.
        """
        return pulumi.get(self, "credential_name")

    @property
    @pulumi.getter(name="encryptionDetails")
    def encryption_details(self) -> Optional['outputs.GetExternalLocationExternalLocationInfoEncryptionDetailsResult']:
        """
        The options for Server-Side Encryption to be used by each Databricks s3 client when connecting to S3 cloud storage (AWS).
        """
        return pulumi.get(self, "encryption_details")

    @property
    @pulumi.getter(name="isolationMode")
    def isolation_mode(self) -> Optional[str]:
        return pulumi.get(self, "isolation_mode")

    @property
    @pulumi.getter(name="metastoreId")
    def metastore_id(self) -> Optional[str]:
        """
        Unique identifier of the parent Metastore.
        """
        return pulumi.get(self, "metastore_id")

    @property
    @pulumi.getter
    def name(self) -> Optional[str]:
        """
        The name of the external location
        """
        return pulumi.get(self, "name")

    @property
    @pulumi.getter
    def owner(self) -> Optional[str]:
        """
        Username/groupname/sp application_id of the external location owner.
        """
        return pulumi.get(self, "owner")

    @property
    @pulumi.getter(name="readOnly")
    def read_only(self) -> Optional[bool]:
        """
        Indicates whether the external location is read-only.
        """
        return pulumi.get(self, "read_only")

    @property
    @pulumi.getter(name="updatedAt")
    def updated_at(self) -> Optional[int]:
        """
        Time at which this catalog was last modified, in epoch milliseconds.
        """
        return pulumi.get(self, "updated_at")

    @property
    @pulumi.getter(name="updatedBy")
    def updated_by(self) -> Optional[str]:
        """
        Username of user who last modified catalog.
        """
        return pulumi.get(self, "updated_by")

    @property
    @pulumi.getter
    def url(self) -> Optional[str]:
        """
        Path URL in cloud storage, of the form: `s3://[bucket-host]/[bucket-dir]` (AWS), `abfss://[user]@[host]/[path]` (Azure), `gs://[bucket-host]/[bucket-dir]` (GCP).
        """
        return pulumi.get(self, "url")


@pulumi.output_type
class GetExternalLocationExternalLocationInfoEncryptionDetailsResult(dict):
    def __init__(__self__, *,
                 sse_encryption_details: Optional['outputs.GetExternalLocationExternalLocationInfoEncryptionDetailsSseEncryptionDetailsResult'] = None):
        if sse_encryption_details is not None:
            pulumi.set(__self__, "sse_encryption_details", sse_encryption_details)

    @property
    @pulumi.getter(name="sseEncryptionDetails")
    def sse_encryption_details(self) -> Optional['outputs.GetExternalLocationExternalLocationInfoEncryptionDetailsSseEncryptionDetailsResult']:
        return pulumi.get(self, "sse_encryption_details")


@pulumi.output_type
class GetExternalLocationExternalLocationInfoEncryptionDetailsSseEncryptionDetailsResult(dict):
    def __init__(__self__, *,
                 algorithm: Optional[str] = None,
                 aws_kms_key_arn: Optional[str] = None):
        if algorithm is not None:
            pulumi.set(__self__, "algorithm", algorithm)
        if aws_kms_key_arn is not None:
            pulumi.set(__self__, "aws_kms_key_arn", aws_kms_key_arn)

    @property
    @pulumi.getter
    def algorithm(self) -> Optional[str]:
        return pulumi.get(self, "algorithm")

    @property
    @pulumi.getter(name="awsKmsKeyArn")
    def aws_kms_key_arn(self) -> Optional[str]:
        return pulumi.get(self, "aws_kms_key_arn")


@pulumi.output_type
class GetInstancePoolPoolInfoResult(dict):
    def __init__(__self__, *,
                 default_tags: Mapping[str, str],
                 idle_instance_autotermination_minutes: int,
                 instance_pool_id: str,
                 instance_pool_name: str,
                 aws_attributes: Optional['outputs.GetInstancePoolPoolInfoAwsAttributesResult'] = None,
                 azure_attributes: Optional['outputs.GetInstancePoolPoolInfoAzureAttributesResult'] = None,
                 custom_tags: Optional[Mapping[str, str]] = None,
                 disk_spec: Optional['outputs.GetInstancePoolPoolInfoDiskSpecResult'] = None,
                 enable_elastic_disk: Optional[bool] = None,
                 gcp_attributes: Optional['outputs.GetInstancePoolPoolInfoGcpAttributesResult'] = None,
                 instance_pool_fleet_attributes: Optional[Sequence['outputs.GetInstancePoolPoolInfoInstancePoolFleetAttributeResult']] = None,
                 max_capacity: Optional[int] = None,
                 min_idle_instances: Optional[int] = None,
                 node_type_id: Optional[str] = None,
                 preloaded_docker_images: Optional[Sequence['outputs.GetInstancePoolPoolInfoPreloadedDockerImageResult']] = None,
                 preloaded_spark_versions: Optional[Sequence[str]] = None,
                 state: Optional[str] = None,
                 stats: Optional['outputs.GetInstancePoolPoolInfoStatsResult'] = None):
        pulumi.set(__self__, "default_tags", default_tags)
        pulumi.set(__self__, "idle_instance_autotermination_minutes", idle_instance_autotermination_minutes)
        pulumi.set(__self__, "instance_pool_id", instance_pool_id)
        pulumi.set(__self__, "instance_pool_name", instance_pool_name)
        if aws_attributes is not None:
            pulumi.set(__self__, "aws_attributes", aws_attributes)
        if azure_attributes is not None:
            pulumi.set(__self__, "azure_attributes", azure_attributes)
        if custom_tags is not None:
            pulumi.set(__self__, "custom_tags", custom_tags)
        if disk_spec is not None:
            pulumi.set(__self__, "disk_spec", disk_spec)
        if enable_elastic_disk is not None:
            pulumi.set(__self__, "enable_elastic_disk", enable_elastic_disk)
        if gcp_attributes is not None:
            pulumi.set(__self__, "gcp_attributes", gcp_attributes)
        if instance_pool_fleet_attributes is not None:
            pulumi.set(__self__, "instance_pool_fleet_attributes", instance_pool_fleet_attributes)
        if max_capacity is not None:
            pulumi.set(__self__, "max_capacity", max_capacity)
        if min_idle_instances is not None:
            pulumi.set(__self__, "min_idle_instances", min_idle_instances)
        if node_type_id is not None:
            pulumi.set(__self__, "node_type_id", node_type_id)
        if preloaded_docker_images is not None:
            pulumi.set(__self__, "preloaded_docker_images", preloaded_docker_images)
        if preloaded_spark_versions is not None:
            pulumi.set(__self__, "preloaded_spark_versions", preloaded_spark_versions)
        if state is not None:
            pulumi.set(__self__, "state", state)
        if stats is not None:
            pulumi.set(__self__, "stats", stats)

    @property
    @pulumi.getter(name="defaultTags")
    def default_tags(self) -> Mapping[str, str]:
        return pulumi.get(self, "default_tags")

    @property
    @pulumi.getter(name="idleInstanceAutoterminationMinutes")
    def idle_instance_autotermination_minutes(self) -> int:
        return pulumi.get(self, "idle_instance_autotermination_minutes")

    @property
    @pulumi.getter(name="instancePoolId")
    def instance_pool_id(self) -> str:
        return pulumi.get(self, "instance_pool_id")

    @property
    @pulumi.getter(name="instancePoolName")
    def instance_pool_name(self) -> str:
        return pulumi.get(self, "instance_pool_name")

    @property
    @pulumi.getter(name="awsAttributes")
    def aws_attributes(self) -> Optional['outputs.GetInstancePoolPoolInfoAwsAttributesResult']:
        return pulumi.get(self, "aws_attributes")

    @property
    @pulumi.getter(name="azureAttributes")
    def azure_attributes(self) -> Optional['outputs.GetInstancePoolPoolInfoAzureAttributesResult']:
        return pulumi.get(self, "azure_attributes")

    @property
    @pulumi.getter(name="customTags")
    def custom_tags(self) -> Optional[Mapping[str, str]]:
        return pulumi.get(self, "custom_tags")

    @property
    @pulumi.getter(name="diskSpec")
    def disk_spec(self) -> Optional['outputs.GetInstancePoolPoolInfoDiskSpecResult']:
        return pulumi.get(self, "disk_spec")

    @property
    @pulumi.getter(name="enableElasticDisk")
    def enable_elastic_disk(self) -> Optional[bool]:
        return pulumi.get(self, "enable_elastic_disk")

    @property
    @pulumi.getter(name="gcpAttributes")
    def gcp_attributes(self) -> Optional['outputs.GetInstancePoolPoolInfoGcpAttributesResult']:
        return pulumi.get(self, "gcp_attributes")

    @property
    @pulumi.getter(name="instancePoolFleetAttributes")
    def instance_pool_fleet_attributes(self) -> Optional[Sequence['outputs.GetInstancePoolPoolInfoInstancePoolFleetAttributeResult']]:
        return pulumi.get(self, "instance_pool_fleet_attributes")

    @property
    @pulumi.getter(name="maxCapacity")
    def max_capacity(self) -> Optional[int]:
        return pulumi.get(self, "max_capacity")

    @property
    @pulumi.getter(name="minIdleInstances")
    def min_idle_instances(self) -> Optional[int]:
        return pulumi.get(self, "min_idle_instances")

    @property
    @pulumi.getter(name="nodeTypeId")
    def node_type_id(self) -> Optional[str]:
        return pulumi.get(self, "node_type_id")

    @property
    @pulumi.getter(name="preloadedDockerImages")
    def preloaded_docker_images(self) -> Optional[Sequence['outputs.GetInstancePoolPoolInfoPreloadedDockerImageResult']]:
        return pulumi.get(self, "preloaded_docker_images")

    @property
    @pulumi.getter(name="preloadedSparkVersions")
    def preloaded_spark_versions(self) -> Optional[Sequence[str]]:
        return pulumi.get(self, "preloaded_spark_versions")

    @property
    @pulumi.getter
    def state(self) -> Optional[str]:
        return pulumi.get(self, "state")

    @property
    @pulumi.getter
    def stats(self) -> Optional['outputs.GetInstancePoolPoolInfoStatsResult']:
        return pulumi.get(self, "stats")


@pulumi.output_type
class GetInstancePoolPoolInfoAwsAttributesResult(dict):
    def __init__(__self__, *,
                 zone_id: str,
                 availability: Optional[str] = None,
                 spot_bid_price_percent: Optional[int] = None):
        pulumi.set(__self__, "zone_id", zone_id)
        if availability is not None:
            pulumi.set(__self__, "availability", availability)
        if spot_bid_price_percent is not None:
            pulumi.set(__self__, "spot_bid_price_percent", spot_bid_price_percent)

    @property
    @pulumi.getter(name="zoneId")
    def zone_id(self) -> str:
        return pulumi.get(self, "zone_id")

    @property
    @pulumi.getter
    def availability(self) -> Optional[str]:
        return pulumi.get(self, "availability")

    @property
    @pulumi.getter(name="spotBidPricePercent")
    def spot_bid_price_percent(self) -> Optional[int]:
        return pulumi.get(self, "spot_bid_price_percent")


@pulumi.output_type
class GetInstancePoolPoolInfoAzureAttributesResult(dict):
    def __init__(__self__, *,
                 availability: Optional[str] = None,
                 spot_bid_max_price: Optional[float] = None):
        if availability is not None:
            pulumi.set(__self__, "availability", availability)
        if spot_bid_max_price is not None:
            pulumi.set(__self__, "spot_bid_max_price", spot_bid_max_price)

    @property
    @pulumi.getter
    def availability(self) -> Optional[str]:
        return pulumi.get(self, "availability")

    @property
    @pulumi.getter(name="spotBidMaxPrice")
    def spot_bid_max_price(self) -> Optional[float]:
        return pulumi.get(self, "spot_bid_max_price")


@pulumi.output_type
class GetInstancePoolPoolInfoDiskSpecResult(dict):
    def __init__(__self__, *,
                 disk_count: Optional[int] = None,
                 disk_size: Optional[int] = None,
                 disk_type: Optional['outputs.GetInstancePoolPoolInfoDiskSpecDiskTypeResult'] = None):
        if disk_count is not None:
            pulumi.set(__self__, "disk_count", disk_count)
        if disk_size is not None:
            pulumi.set(__self__, "disk_size", disk_size)
        if disk_type is not None:
            pulumi.set(__self__, "disk_type", disk_type)

    @property
    @pulumi.getter(name="diskCount")
    def disk_count(self) -> Optional[int]:
        return pulumi.get(self, "disk_count")

    @property
    @pulumi.getter(name="diskSize")
    def disk_size(self) -> Optional[int]:
        return pulumi.get(self, "disk_size")

    @property
    @pulumi.getter(name="diskType")
    def disk_type(self) -> Optional['outputs.GetInstancePoolPoolInfoDiskSpecDiskTypeResult']:
        return pulumi.get(self, "disk_type")


@pulumi.output_type
class GetInstancePoolPoolInfoDiskSpecDiskTypeResult(dict):
    def __init__(__self__, *,
                 azure_disk_volume_type: Optional[str] = None,
                 ebs_volume_type: Optional[str] = None):
        if azure_disk_volume_type is not None:
            pulumi.set(__self__, "azure_disk_volume_type", azure_disk_volume_type)
        if ebs_volume_type is not None:
            pulumi.set(__self__, "ebs_volume_type", ebs_volume_type)

    @property
    @pulumi.getter(name="azureDiskVolumeType")
    def azure_disk_volume_type(self) -> Optional[str]:
        return pulumi.get(self, "azure_disk_volume_type")

    @property
    @pulumi.getter(name="ebsVolumeType")
    def ebs_volume_type(self) -> Optional[str]:
        return pulumi.get(self, "ebs_volume_type")


@pulumi.output_type
class GetInstancePoolPoolInfoGcpAttributesResult(dict):
    def __init__(__self__, *,
                 local_ssd_count: int,
                 zone_id: str,
                 gcp_availability: Optional[str] = None):
        pulumi.set(__self__, "local_ssd_count", local_ssd_count)
        pulumi.set(__self__, "zone_id", zone_id)
        if gcp_availability is not None:
            pulumi.set(__self__, "gcp_availability", gcp_availability)

    @property
    @pulumi.getter(name="localSsdCount")
    def local_ssd_count(self) -> int:
        return pulumi.get(self, "local_ssd_count")

    @property
    @pulumi.getter(name="zoneId")
    def zone_id(self) -> str:
        return pulumi.get(self, "zone_id")

    @property
    @pulumi.getter(name="gcpAvailability")
    def gcp_availability(self) -> Optional[str]:
        return pulumi.get(self, "gcp_availability")


@pulumi.output_type
class GetInstancePoolPoolInfoInstancePoolFleetAttributeResult(dict):
    def __init__(__self__, *,
                 launch_template_overrides: Sequence['outputs.GetInstancePoolPoolInfoInstancePoolFleetAttributeLaunchTemplateOverrideResult'],
                 fleet_on_demand_option: Optional['outputs.GetInstancePoolPoolInfoInstancePoolFleetAttributeFleetOnDemandOptionResult'] = None,
                 fleet_spot_option: Optional['outputs.GetInstancePoolPoolInfoInstancePoolFleetAttributeFleetSpotOptionResult'] = None):
        pulumi.set(__self__, "launch_template_overrides", launch_template_overrides)
        if fleet_on_demand_option is not None:
            pulumi.set(__self__, "fleet_on_demand_option", fleet_on_demand_option)
        if fleet_spot_option is not None:
            pulumi.set(__self__, "fleet_spot_option", fleet_spot_option)

    @property
    @pulumi.getter(name="launchTemplateOverrides")
    def launch_template_overrides(self) -> Sequence['outputs.GetInstancePoolPoolInfoInstancePoolFleetAttributeLaunchTemplateOverrideResult']:
        return pulumi.get(self, "launch_template_overrides")

    @property
    @pulumi.getter(name="fleetOnDemandOption")
    def fleet_on_demand_option(self) -> Optional['outputs.GetInstancePoolPoolInfoInstancePoolFleetAttributeFleetOnDemandOptionResult']:
        return pulumi.get(self, "fleet_on_demand_option")

    @property
    @pulumi.getter(name="fleetSpotOption")
    def fleet_spot_option(self) -> Optional['outputs.GetInstancePoolPoolInfoInstancePoolFleetAttributeFleetSpotOptionResult']:
        return pulumi.get(self, "fleet_spot_option")


@pulumi.output_type
class GetInstancePoolPoolInfoInstancePoolFleetAttributeFleetOnDemandOptionResult(dict):
    def __init__(__self__, *,
                 allocation_strategy: str,
                 instance_pools_to_use_count: Optional[int] = None):
        pulumi.set(__self__, "allocation_strategy", allocation_strategy)
        if instance_pools_to_use_count is not None:
            pulumi.set(__self__, "instance_pools_to_use_count", instance_pools_to_use_count)

    @property
    @pulumi.getter(name="allocationStrategy")
    def allocation_strategy(self) -> str:
        return pulumi.get(self, "allocation_strategy")

    @property
    @pulumi.getter(name="instancePoolsToUseCount")
    def instance_pools_to_use_count(self) -> Optional[int]:
        return pulumi.get(self, "instance_pools_to_use_count")


@pulumi.output_type
class GetInstancePoolPoolInfoInstancePoolFleetAttributeFleetSpotOptionResult(dict):
    def __init__(__self__, *,
                 allocation_strategy: str,
                 instance_pools_to_use_count: Optional[int] = None):
        pulumi.set(__self__, "allocation_strategy", allocation_strategy)
        if instance_pools_to_use_count is not None:
            pulumi.set(__self__, "instance_pools_to_use_count", instance_pools_to_use_count)

    @property
    @pulumi.getter(name="allocationStrategy")
    def allocation_strategy(self) -> str:
        return pulumi.get(self, "allocation_strategy")

    @property
    @pulumi.getter(name="instancePoolsToUseCount")
    def instance_pools_to_use_count(self) -> Optional[int]:
        return pulumi.get(self, "instance_pools_to_use_count")


@pulumi.output_type
class GetInstancePoolPoolInfoInstancePoolFleetAttributeLaunchTemplateOverrideResult(dict):
    def __init__(__self__, *,
                 availability_zone: str,
                 instance_type: str):
        pulumi.set(__self__, "availability_zone", availability_zone)
        pulumi.set(__self__, "instance_type", instance_type)

    @property
    @pulumi.getter(name="availabilityZone")
    def availability_zone(self) -> str:
        return pulumi.get(self, "availability_zone")

    @property
    @pulumi.getter(name="instanceType")
    def instance_type(self) -> str:
        return pulumi.get(self, "instance_type")


@pulumi.output_type
class GetInstancePoolPoolInfoPreloadedDockerImageResult(dict):
    def __init__(__self__, *,
                 url: str,
                 basic_auth: Optional['outputs.GetInstancePoolPoolInfoPreloadedDockerImageBasicAuthResult'] = None):
        pulumi.set(__self__, "url", url)
        if basic_auth is not None:
            pulumi.set(__self__, "basic_auth", basic_auth)

    @property
    @pulumi.getter
    def url(self) -> str:
        return pulumi.get(self, "url")

    @property
    @pulumi.getter(name="basicAuth")
    def basic_auth(self) -> Optional['outputs.GetInstancePoolPoolInfoPreloadedDockerImageBasicAuthResult']:
        return pulumi.get(self, "basic_auth")


@pulumi.output_type
class GetInstancePoolPoolInfoPreloadedDockerImageBasicAuthResult(dict):
    def __init__(__self__, *,
                 password: str,
                 username: str):
        pulumi.set(__self__, "password", password)
        pulumi.set(__self__, "username", username)

    @property
    @pulumi.getter
    def password(self) -> str:
        return pulumi.get(self, "password")

    @property
    @pulumi.getter
    def username(self) -> str:
        return pulumi.get(self, "username")


@pulumi.output_type
class GetInstancePoolPoolInfoStatsResult(dict):
    def __init__(__self__, *,
                 idle_count: Optional[int] = None,
                 pending_idle_count: Optional[int] = None,
                 pending_used_count: Optional[int] = None,
                 used_count: Optional[int] = None):
        if idle_count is not None:
            pulumi.set(__self__, "idle_count", idle_count)
        if pending_idle_count is not None:
            pulumi.set(__self__, "pending_idle_count", pending_idle_count)
        if pending_used_count is not None:
            pulumi.set(__self__, "pending_used_count", pending_used_count)
        if used_count is not None:
            pulumi.set(__self__, "used_count", used_count)

    @property
    @pulumi.getter(name="idleCount")
    def idle_count(self) -> Optional[int]:
        return pulumi.get(self, "idle_count")

    @property
    @pulumi.getter(name="pendingIdleCount")
    def pending_idle_count(self) -> Optional[int]:
        return pulumi.get(self, "pending_idle_count")

    @property
    @pulumi.getter(name="pendingUsedCount")
    def pending_used_count(self) -> Optional[int]:
        return pulumi.get(self, "pending_used_count")

    @property
    @pulumi.getter(name="usedCount")
    def used_count(self) -> Optional[int]:
        return pulumi.get(self, "used_count")


@pulumi.output_type
class GetInstanceProfilesInstanceProfileResult(dict):
    def __init__(__self__, *,
                 arn: str,
                 is_meta: bool,
                 name: str,
                 role_arn: str):
        """
        :param str arn: ARN of the instance profile.
        :param bool is_meta: Whether the instance profile is a meta instance profile or not.
        :param str name: Name of the instance profile.
        :param str role_arn: ARN of the role attached to the instance profile.
        """
        pulumi.set(__self__, "arn", arn)
        pulumi.set(__self__, "is_meta", is_meta)
        pulumi.set(__self__, "name", name)
        pulumi.set(__self__, "role_arn", role_arn)

    @property
    @pulumi.getter
    def arn(self) -> str:
        """
        ARN of the instance profile.
        """
        return pulumi.get(self, "arn")

    @property
    @pulumi.getter(name="isMeta")
    def is_meta(self) -> bool:
        """
        Whether the instance profile is a meta instance profile or not.
        """
        return pulumi.get(self, "is_meta")

    @property
    @pulumi.getter
    def name(self) -> str:
        """
        Name of the instance profile.
        """
        return pulumi.get(self, "name")

    @property
    @pulumi.getter(name="roleArn")
    def role_arn(self) -> str:
        """
        ARN of the role attached to the instance profile.
        """
        return pulumi.get(self, "role_arn")


@pulumi.output_type
class GetJobJobSettingsResult(dict):
    def __init__(__self__, *,
                 run_as_user_name: str,
                 created_time: Optional[int] = None,
                 creator_user_name: Optional[str] = None,
                 job_id: Optional[int] = None,
                 settings: Optional['outputs.GetJobJobSettingsSettingsResult'] = None):
        pulumi.set(__self__, "run_as_user_name", run_as_user_name)
        if created_time is not None:
            pulumi.set(__self__, "created_time", created_time)
        if creator_user_name is not None:
            pulumi.set(__self__, "creator_user_name", creator_user_name)
        if job_id is not None:
            pulumi.set(__self__, "job_id", job_id)
        if settings is not None:
            pulumi.set(__self__, "settings", settings)

    @property
    @pulumi.getter(name="runAsUserName")
    def run_as_user_name(self) -> str:
        return pulumi.get(self, "run_as_user_name")

    @property
    @pulumi.getter(name="createdTime")
    def created_time(self) -> Optional[int]:
        return pulumi.get(self, "created_time")

    @property
    @pulumi.getter(name="creatorUserName")
    def creator_user_name(self) -> Optional[str]:
        return pulumi.get(self, "creator_user_name")

    @property
    @pulumi.getter(name="jobId")
    def job_id(self) -> Optional[int]:
        return pulumi.get(self, "job_id")

    @property
    @pulumi.getter
    def settings(self) -> Optional['outputs.GetJobJobSettingsSettingsResult']:
        return pulumi.get(self, "settings")


@pulumi.output_type
class GetJobJobSettingsSettingsResult(dict):
    def __init__(__self__, *,
                 format: str,
                 run_as: 'outputs.GetJobJobSettingsSettingsRunAsResult',
                 continuous: Optional['outputs.GetJobJobSettingsSettingsContinuousResult'] = None,
                 dbt_task: Optional['outputs.GetJobJobSettingsSettingsDbtTaskResult'] = None,
                 deployment: Optional['outputs.GetJobJobSettingsSettingsDeploymentResult'] = None,
                 description: Optional[str] = None,
                 edit_mode: Optional[str] = None,
                 email_notifications: Optional['outputs.GetJobJobSettingsSettingsEmailNotificationsResult'] = None,
                 environments: Optional[Sequence['outputs.GetJobJobSettingsSettingsEnvironmentResult']] = None,
                 existing_cluster_id: Optional[str] = None,
                 git_source: Optional['outputs.GetJobJobSettingsSettingsGitSourceResult'] = None,
                 health: Optional['outputs.GetJobJobSettingsSettingsHealthResult'] = None,
                 job_clusters: Optional[Sequence['outputs.GetJobJobSettingsSettingsJobClusterResult']] = None,
                 libraries: Optional[Sequence['outputs.GetJobJobSettingsSettingsLibraryResult']] = None,
                 max_concurrent_runs: Optional[int] = None,
                 max_retries: Optional[int] = None,
                 min_retry_interval_millis: Optional[int] = None,
                 name: Optional[str] = None,
                 new_cluster: Optional['outputs.GetJobJobSettingsSettingsNewClusterResult'] = None,
                 notebook_task: Optional['outputs.GetJobJobSettingsSettingsNotebookTaskResult'] = None,
                 notification_settings: Optional['outputs.GetJobJobSettingsSettingsNotificationSettingsResult'] = None,
                 parameters: Optional[Sequence['outputs.GetJobJobSettingsSettingsParameterResult']] = None,
                 pipeline_task: Optional['outputs.GetJobJobSettingsSettingsPipelineTaskResult'] = None,
                 python_wheel_task: Optional['outputs.GetJobJobSettingsSettingsPythonWheelTaskResult'] = None,
                 queue: Optional['outputs.GetJobJobSettingsSettingsQueueResult'] = None,
                 retry_on_timeout: Optional[bool] = None,
                 run_job_task: Optional['outputs.GetJobJobSettingsSettingsRunJobTaskResult'] = None,
                 schedule: Optional['outputs.GetJobJobSettingsSettingsScheduleResult'] = None,
                 spark_jar_task: Optional['outputs.GetJobJobSettingsSettingsSparkJarTaskResult'] = None,
                 spark_python_task: Optional['outputs.GetJobJobSettingsSettingsSparkPythonTaskResult'] = None,
                 spark_submit_task: Optional['outputs.GetJobJobSettingsSettingsSparkSubmitTaskResult'] = None,
                 tags: Optional[Mapping[str, str]] = None,
                 tasks: Optional[Sequence['outputs.GetJobJobSettingsSettingsTaskResult']] = None,
                 timeout_seconds: Optional[int] = None,
                 trigger: Optional['outputs.GetJobJobSettingsSettingsTriggerResult'] = None,
                 webhook_notifications: Optional['outputs.GetJobJobSettingsSettingsWebhookNotificationsResult'] = None):
        """
        :param str name: the job name of Job if the resource was matched by id.
        """
        pulumi.set(__self__, "format", format)
        pulumi.set(__self__, "run_as", run_as)
        if continuous is not None:
            pulumi.set(__self__, "continuous", continuous)
        if dbt_task is not None:
            pulumi.set(__self__, "dbt_task", dbt_task)
        if deployment is not None:
            pulumi.set(__self__, "deployment", deployment)
        if description is not None:
            pulumi.set(__self__, "description", description)
        if edit_mode is not None:
            pulumi.set(__self__, "edit_mode", edit_mode)
        if email_notifications is not None:
            pulumi.set(__self__, "email_notifications", email_notifications)
        if environments is not None:
            pulumi.set(__self__, "environments", environments)
        if existing_cluster_id is not None:
            pulumi.set(__self__, "existing_cluster_id", existing_cluster_id)
        if git_source is not None:
            pulumi.set(__self__, "git_source", git_source)
        if health is not None:
            pulumi.set(__self__, "health", health)
        if job_clusters is not None:
            pulumi.set(__self__, "job_clusters", job_clusters)
        if libraries is not None:
            pulumi.set(__self__, "libraries", libraries)
        if max_concurrent_runs is not None:
            pulumi.set(__self__, "max_concurrent_runs", max_concurrent_runs)
        if max_retries is not None:
            pulumi.set(__self__, "max_retries", max_retries)
        if min_retry_interval_millis is not None:
            pulumi.set(__self__, "min_retry_interval_millis", min_retry_interval_millis)
        if name is not None:
            pulumi.set(__self__, "name", name)
        if new_cluster is not None:
            pulumi.set(__self__, "new_cluster", new_cluster)
        if notebook_task is not None:
            pulumi.set(__self__, "notebook_task", notebook_task)
        if notification_settings is not None:
            pulumi.set(__self__, "notification_settings", notification_settings)
        if parameters is not None:
            pulumi.set(__self__, "parameters", parameters)
        if pipeline_task is not None:
            pulumi.set(__self__, "pipeline_task", pipeline_task)
        if python_wheel_task is not None:
            pulumi.set(__self__, "python_wheel_task", python_wheel_task)
        if queue is not None:
            pulumi.set(__self__, "queue", queue)
        if retry_on_timeout is not None:
            pulumi.set(__self__, "retry_on_timeout", retry_on_timeout)
        if run_job_task is not None:
            pulumi.set(__self__, "run_job_task", run_job_task)
        if schedule is not None:
            pulumi.set(__self__, "schedule", schedule)
        if spark_jar_task is not None:
            pulumi.set(__self__, "spark_jar_task", spark_jar_task)
        if spark_python_task is not None:
            pulumi.set(__self__, "spark_python_task", spark_python_task)
        if spark_submit_task is not None:
            pulumi.set(__self__, "spark_submit_task", spark_submit_task)
        if tags is not None:
            pulumi.set(__self__, "tags", tags)
        if tasks is not None:
            pulumi.set(__self__, "tasks", tasks)
        if timeout_seconds is not None:
            pulumi.set(__self__, "timeout_seconds", timeout_seconds)
        if trigger is not None:
            pulumi.set(__self__, "trigger", trigger)
        if webhook_notifications is not None:
            pulumi.set(__self__, "webhook_notifications", webhook_notifications)

    @property
    @pulumi.getter
    def format(self) -> str:
        return pulumi.get(self, "format")

    @property
    @pulumi.getter(name="runAs")
    def run_as(self) -> 'outputs.GetJobJobSettingsSettingsRunAsResult':
        return pulumi.get(self, "run_as")

    @property
    @pulumi.getter
    def continuous(self) -> Optional['outputs.GetJobJobSettingsSettingsContinuousResult']:
        return pulumi.get(self, "continuous")

    @property
    @pulumi.getter(name="dbtTask")
    def dbt_task(self) -> Optional['outputs.GetJobJobSettingsSettingsDbtTaskResult']:
        return pulumi.get(self, "dbt_task")

    @property
    @pulumi.getter
    def deployment(self) -> Optional['outputs.GetJobJobSettingsSettingsDeploymentResult']:
        return pulumi.get(self, "deployment")

    @property
    @pulumi.getter
    def description(self) -> Optional[str]:
        return pulumi.get(self, "description")

    @property
    @pulumi.getter(name="editMode")
    def edit_mode(self) -> Optional[str]:
        return pulumi.get(self, "edit_mode")

    @property
    @pulumi.getter(name="emailNotifications")
    def email_notifications(self) -> Optional['outputs.GetJobJobSettingsSettingsEmailNotificationsResult']:
        return pulumi.get(self, "email_notifications")

    @property
    @pulumi.getter
    def environments(self) -> Optional[Sequence['outputs.GetJobJobSettingsSettingsEnvironmentResult']]:
        return pulumi.get(self, "environments")

    @property
    @pulumi.getter(name="existingClusterId")
    def existing_cluster_id(self) -> Optional[str]:
        return pulumi.get(self, "existing_cluster_id")

    @property
    @pulumi.getter(name="gitSource")
    def git_source(self) -> Optional['outputs.GetJobJobSettingsSettingsGitSourceResult']:
        return pulumi.get(self, "git_source")

    @property
    @pulumi.getter
    def health(self) -> Optional['outputs.GetJobJobSettingsSettingsHealthResult']:
        return pulumi.get(self, "health")

    @property
    @pulumi.getter(name="jobClusters")
    def job_clusters(self) -> Optional[Sequence['outputs.GetJobJobSettingsSettingsJobClusterResult']]:
        return pulumi.get(self, "job_clusters")

    @property
    @pulumi.getter
    def libraries(self) -> Optional[Sequence['outputs.GetJobJobSettingsSettingsLibraryResult']]:
        return pulumi.get(self, "libraries")

    @property
    @pulumi.getter(name="maxConcurrentRuns")
    def max_concurrent_runs(self) -> Optional[int]:
        return pulumi.get(self, "max_concurrent_runs")

    @property
    @pulumi.getter(name="maxRetries")
    def max_retries(self) -> Optional[int]:
        return pulumi.get(self, "max_retries")

    @property
    @pulumi.getter(name="minRetryIntervalMillis")
    def min_retry_interval_millis(self) -> Optional[int]:
        return pulumi.get(self, "min_retry_interval_millis")

    @property
    @pulumi.getter
    def name(self) -> Optional[str]:
        """
        the job name of Job if the resource was matched by id.
        """
        return pulumi.get(self, "name")

    @property
    @pulumi.getter(name="newCluster")
    def new_cluster(self) -> Optional['outputs.GetJobJobSettingsSettingsNewClusterResult']:
        return pulumi.get(self, "new_cluster")

    @property
    @pulumi.getter(name="notebookTask")
    def notebook_task(self) -> Optional['outputs.GetJobJobSettingsSettingsNotebookTaskResult']:
        return pulumi.get(self, "notebook_task")

    @property
    @pulumi.getter(name="notificationSettings")
    def notification_settings(self) -> Optional['outputs.GetJobJobSettingsSettingsNotificationSettingsResult']:
        return pulumi.get(self, "notification_settings")

    @property
    @pulumi.getter
    def parameters(self) -> Optional[Sequence['outputs.GetJobJobSettingsSettingsParameterResult']]:
        return pulumi.get(self, "parameters")

    @property
    @pulumi.getter(name="pipelineTask")
    def pipeline_task(self) -> Optional['outputs.GetJobJobSettingsSettingsPipelineTaskResult']:
        return pulumi.get(self, "pipeline_task")

    @property
    @pulumi.getter(name="pythonWheelTask")
    def python_wheel_task(self) -> Optional['outputs.GetJobJobSettingsSettingsPythonWheelTaskResult']:
        return pulumi.get(self, "python_wheel_task")

    @property
    @pulumi.getter
    def queue(self) -> Optional['outputs.GetJobJobSettingsSettingsQueueResult']:
        return pulumi.get(self, "queue")

    @property
    @pulumi.getter(name="retryOnTimeout")
    def retry_on_timeout(self) -> Optional[bool]:
        return pulumi.get(self, "retry_on_timeout")

    @property
    @pulumi.getter(name="runJobTask")
    def run_job_task(self) -> Optional['outputs.GetJobJobSettingsSettingsRunJobTaskResult']:
        return pulumi.get(self, "run_job_task")

    @property
    @pulumi.getter
    def schedule(self) -> Optional['outputs.GetJobJobSettingsSettingsScheduleResult']:
        return pulumi.get(self, "schedule")

    @property
    @pulumi.getter(name="sparkJarTask")
    def spark_jar_task(self) -> Optional['outputs.GetJobJobSettingsSettingsSparkJarTaskResult']:
        return pulumi.get(self, "spark_jar_task")

    @property
    @pulumi.getter(name="sparkPythonTask")
    def spark_python_task(self) -> Optional['outputs.GetJobJobSettingsSettingsSparkPythonTaskResult']:
        return pulumi.get(self, "spark_python_task")

    @property
    @pulumi.getter(name="sparkSubmitTask")
    def spark_submit_task(self) -> Optional['outputs.GetJobJobSettingsSettingsSparkSubmitTaskResult']:
        return pulumi.get(self, "spark_submit_task")

    @property
    @pulumi.getter
    def tags(self) -> Optional[Mapping[str, str]]:
        return pulumi.get(self, "tags")

    @property
    @pulumi.getter
    def tasks(self) -> Optional[Sequence['outputs.GetJobJobSettingsSettingsTaskResult']]:
        return pulumi.get(self, "tasks")

    @property
    @pulumi.getter(name="timeoutSeconds")
    def timeout_seconds(self) -> Optional[int]:
        return pulumi.get(self, "timeout_seconds")

    @property
    @pulumi.getter
    def trigger(self) -> Optional['outputs.GetJobJobSettingsSettingsTriggerResult']:
        return pulumi.get(self, "trigger")

    @property
    @pulumi.getter(name="webhookNotifications")
    def webhook_notifications(self) -> Optional['outputs.GetJobJobSettingsSettingsWebhookNotificationsResult']:
        return pulumi.get(self, "webhook_notifications")


@pulumi.output_type
class GetJobJobSettingsSettingsContinuousResult(dict):
    def __init__(__self__, *,
                 pause_status: Optional[str] = None):
        if pause_status is not None:
            pulumi.set(__self__, "pause_status", pause_status)

    @property
    @pulumi.getter(name="pauseStatus")
    def pause_status(self) -> Optional[str]:
        return pulumi.get(self, "pause_status")


@pulumi.output_type
class GetJobJobSettingsSettingsDbtTaskResult(dict):
    def __init__(__self__, *,
                 commands: Sequence[str],
                 catalog: Optional[str] = None,
                 profiles_directory: Optional[str] = None,
                 project_directory: Optional[str] = None,
                 schema: Optional[str] = None,
                 source: Optional[str] = None,
                 warehouse_id: Optional[str] = None):
        pulumi.set(__self__, "commands", commands)
        if catalog is not None:
            pulumi.set(__self__, "catalog", catalog)
        if profiles_directory is not None:
            pulumi.set(__self__, "profiles_directory", profiles_directory)
        if project_directory is not None:
            pulumi.set(__self__, "project_directory", project_directory)
        if schema is not None:
            pulumi.set(__self__, "schema", schema)
        if source is not None:
            pulumi.set(__self__, "source", source)
        if warehouse_id is not None:
            pulumi.set(__self__, "warehouse_id", warehouse_id)

    @property
    @pulumi.getter
    def commands(self) -> Sequence[str]:
        return pulumi.get(self, "commands")

    @property
    @pulumi.getter
    def catalog(self) -> Optional[str]:
        return pulumi.get(self, "catalog")

    @property
    @pulumi.getter(name="profilesDirectory")
    def profiles_directory(self) -> Optional[str]:
        return pulumi.get(self, "profiles_directory")

    @property
    @pulumi.getter(name="projectDirectory")
    def project_directory(self) -> Optional[str]:
        return pulumi.get(self, "project_directory")

    @property
    @pulumi.getter
    def schema(self) -> Optional[str]:
        return pulumi.get(self, "schema")

    @property
    @pulumi.getter
    def source(self) -> Optional[str]:
        return pulumi.get(self, "source")

    @property
    @pulumi.getter(name="warehouseId")
    def warehouse_id(self) -> Optional[str]:
        return pulumi.get(self, "warehouse_id")


@pulumi.output_type
class GetJobJobSettingsSettingsDeploymentResult(dict):
    def __init__(__self__, *,
                 kind: str,
                 metadata_file_path: Optional[str] = None):
        pulumi.set(__self__, "kind", kind)
        if metadata_file_path is not None:
            pulumi.set(__self__, "metadata_file_path", metadata_file_path)

    @property
    @pulumi.getter
    def kind(self) -> str:
        return pulumi.get(self, "kind")

    @property
    @pulumi.getter(name="metadataFilePath")
    def metadata_file_path(self) -> Optional[str]:
        return pulumi.get(self, "metadata_file_path")


@pulumi.output_type
class GetJobJobSettingsSettingsEmailNotificationsResult(dict):
    def __init__(__self__, *,
                 no_alert_for_skipped_runs: Optional[bool] = None,
                 on_duration_warning_threshold_exceededs: Optional[Sequence[str]] = None,
                 on_failures: Optional[Sequence[str]] = None,
                 on_starts: Optional[Sequence[str]] = None,
                 on_streaming_backlog_exceededs: Optional[Sequence[str]] = None,
                 on_successes: Optional[Sequence[str]] = None):
        if no_alert_for_skipped_runs is not None:
            pulumi.set(__self__, "no_alert_for_skipped_runs", no_alert_for_skipped_runs)
        if on_duration_warning_threshold_exceededs is not None:
            pulumi.set(__self__, "on_duration_warning_threshold_exceededs", on_duration_warning_threshold_exceededs)
        if on_failures is not None:
            pulumi.set(__self__, "on_failures", on_failures)
        if on_starts is not None:
            pulumi.set(__self__, "on_starts", on_starts)
        if on_streaming_backlog_exceededs is not None:
            pulumi.set(__self__, "on_streaming_backlog_exceededs", on_streaming_backlog_exceededs)
        if on_successes is not None:
            pulumi.set(__self__, "on_successes", on_successes)

    @property
    @pulumi.getter(name="noAlertForSkippedRuns")
    def no_alert_for_skipped_runs(self) -> Optional[bool]:
        return pulumi.get(self, "no_alert_for_skipped_runs")

    @property
    @pulumi.getter(name="onDurationWarningThresholdExceededs")
    def on_duration_warning_threshold_exceededs(self) -> Optional[Sequence[str]]:
        return pulumi.get(self, "on_duration_warning_threshold_exceededs")

    @property
    @pulumi.getter(name="onFailures")
    def on_failures(self) -> Optional[Sequence[str]]:
        return pulumi.get(self, "on_failures")

    @property
    @pulumi.getter(name="onStarts")
    def on_starts(self) -> Optional[Sequence[str]]:
        return pulumi.get(self, "on_starts")

    @property
    @pulumi.getter(name="onStreamingBacklogExceededs")
    def on_streaming_backlog_exceededs(self) -> Optional[Sequence[str]]:
        return pulumi.get(self, "on_streaming_backlog_exceededs")

    @property
    @pulumi.getter(name="onSuccesses")
    def on_successes(self) -> Optional[Sequence[str]]:
        return pulumi.get(self, "on_successes")


@pulumi.output_type
class GetJobJobSettingsSettingsEnvironmentResult(dict):
    def __init__(__self__, *,
                 environment_key: str,
                 spec: Optional['outputs.GetJobJobSettingsSettingsEnvironmentSpecResult'] = None):
        pulumi.set(__self__, "environment_key", environment_key)
        if spec is not None:
            pulumi.set(__self__, "spec", spec)

    @property
    @pulumi.getter(name="environmentKey")
    def environment_key(self) -> str:
        return pulumi.get(self, "environment_key")

    @property
    @pulumi.getter
    def spec(self) -> Optional['outputs.GetJobJobSettingsSettingsEnvironmentSpecResult']:
        return pulumi.get(self, "spec")


@pulumi.output_type
class GetJobJobSettingsSettingsEnvironmentSpecResult(dict):
    def __init__(__self__, *,
                 client: str,
                 dependencies: Optional[Sequence[str]] = None):
        pulumi.set(__self__, "client", client)
        if dependencies is not None:
            pulumi.set(__self__, "dependencies", dependencies)

    @property
    @pulumi.getter
    def client(self) -> str:
        return pulumi.get(self, "client")

    @property
    @pulumi.getter
    def dependencies(self) -> Optional[Sequence[str]]:
        return pulumi.get(self, "dependencies")


@pulumi.output_type
class GetJobJobSettingsSettingsGitSourceResult(dict):
    def __init__(__self__, *,
                 url: str,
                 branch: Optional[str] = None,
                 commit: Optional[str] = None,
                 job_source: Optional['outputs.GetJobJobSettingsSettingsGitSourceJobSourceResult'] = None,
                 provider: Optional[str] = None,
                 tag: Optional[str] = None):
        pulumi.set(__self__, "url", url)
        if branch is not None:
            pulumi.set(__self__, "branch", branch)
        if commit is not None:
            pulumi.set(__self__, "commit", commit)
        if job_source is not None:
            pulumi.set(__self__, "job_source", job_source)
        if provider is not None:
            pulumi.set(__self__, "provider", provider)
        if tag is not None:
            pulumi.set(__self__, "tag", tag)

    @property
    @pulumi.getter
    def url(self) -> str:
        return pulumi.get(self, "url")

    @property
    @pulumi.getter
    def branch(self) -> Optional[str]:
        return pulumi.get(self, "branch")

    @property
    @pulumi.getter
    def commit(self) -> Optional[str]:
        return pulumi.get(self, "commit")

    @property
    @pulumi.getter(name="jobSource")
    def job_source(self) -> Optional['outputs.GetJobJobSettingsSettingsGitSourceJobSourceResult']:
        return pulumi.get(self, "job_source")

    @property
    @pulumi.getter
    def provider(self) -> Optional[str]:
        return pulumi.get(self, "provider")

    @property
    @pulumi.getter
    def tag(self) -> Optional[str]:
        return pulumi.get(self, "tag")


@pulumi.output_type
class GetJobJobSettingsSettingsGitSourceJobSourceResult(dict):
    def __init__(__self__, *,
                 import_from_git_branch: str,
                 job_config_path: str,
                 dirty_state: Optional[str] = None):
        pulumi.set(__self__, "import_from_git_branch", import_from_git_branch)
        pulumi.set(__self__, "job_config_path", job_config_path)
        if dirty_state is not None:
            pulumi.set(__self__, "dirty_state", dirty_state)

    @property
    @pulumi.getter(name="importFromGitBranch")
    def import_from_git_branch(self) -> str:
        return pulumi.get(self, "import_from_git_branch")

    @property
    @pulumi.getter(name="jobConfigPath")
    def job_config_path(self) -> str:
        return pulumi.get(self, "job_config_path")

    @property
    @pulumi.getter(name="dirtyState")
    def dirty_state(self) -> Optional[str]:
        return pulumi.get(self, "dirty_state")


@pulumi.output_type
class GetJobJobSettingsSettingsHealthResult(dict):
    def __init__(__self__, *,
                 rules: Sequence['outputs.GetJobJobSettingsSettingsHealthRuleResult']):
        pulumi.set(__self__, "rules", rules)

    @property
    @pulumi.getter
    def rules(self) -> Sequence['outputs.GetJobJobSettingsSettingsHealthRuleResult']:
        return pulumi.get(self, "rules")


@pulumi.output_type
class GetJobJobSettingsSettingsHealthRuleResult(dict):
    def __init__(__self__, *,
                 metric: str,
                 op: str,
                 value: int):
        pulumi.set(__self__, "metric", metric)
        pulumi.set(__self__, "op", op)
        pulumi.set(__self__, "value", value)

    @property
    @pulumi.getter
    def metric(self) -> str:
        return pulumi.get(self, "metric")

    @property
    @pulumi.getter
    def op(self) -> str:
        return pulumi.get(self, "op")

    @property
    @pulumi.getter
    def value(self) -> int:
        return pulumi.get(self, "value")


@pulumi.output_type
class GetJobJobSettingsSettingsJobClusterResult(dict):
    def __init__(__self__, *,
                 job_cluster_key: str,
                 new_cluster: 'outputs.GetJobJobSettingsSettingsJobClusterNewClusterResult'):
        pulumi.set(__self__, "job_cluster_key", job_cluster_key)
        pulumi.set(__self__, "new_cluster", new_cluster)

    @property
    @pulumi.getter(name="jobClusterKey")
    def job_cluster_key(self) -> str:
        return pulumi.get(self, "job_cluster_key")

    @property
    @pulumi.getter(name="newCluster")
    def new_cluster(self) -> 'outputs.GetJobJobSettingsSettingsJobClusterNewClusterResult':
        return pulumi.get(self, "new_cluster")


@pulumi.output_type
class GetJobJobSettingsSettingsJobClusterNewClusterResult(dict):
    def __init__(__self__, *,
                 driver_instance_pool_id: str,
                 driver_node_type_id: str,
                 enable_elastic_disk: bool,
                 enable_local_disk_encryption: bool,
                 node_type_id: str,
                 num_workers: int,
                 spark_version: str,
                 apply_policy_default_values: Optional[bool] = None,
                 autoscale: Optional['outputs.GetJobJobSettingsSettingsJobClusterNewClusterAutoscaleResult'] = None,
                 autotermination_minutes: Optional[int] = None,
                 aws_attributes: Optional['outputs.GetJobJobSettingsSettingsJobClusterNewClusterAwsAttributesResult'] = None,
                 azure_attributes: Optional['outputs.GetJobJobSettingsSettingsJobClusterNewClusterAzureAttributesResult'] = None,
                 cluster_id: Optional[str] = None,
                 cluster_log_conf: Optional['outputs.GetJobJobSettingsSettingsJobClusterNewClusterClusterLogConfResult'] = None,
                 cluster_mount_infos: Optional[Sequence['outputs.GetJobJobSettingsSettingsJobClusterNewClusterClusterMountInfoResult']] = None,
                 cluster_name: Optional[str] = None,
                 custom_tags: Optional[Mapping[str, str]] = None,
                 data_security_mode: Optional[str] = None,
                 docker_image: Optional['outputs.GetJobJobSettingsSettingsJobClusterNewClusterDockerImageResult'] = None,
                 gcp_attributes: Optional['outputs.GetJobJobSettingsSettingsJobClusterNewClusterGcpAttributesResult'] = None,
                 idempotency_token: Optional[str] = None,
                 init_scripts: Optional[Sequence['outputs.GetJobJobSettingsSettingsJobClusterNewClusterInitScriptResult']] = None,
                 instance_pool_id: Optional[str] = None,
                 policy_id: Optional[str] = None,
                 runtime_engine: Optional[str] = None,
                 single_user_name: Optional[str] = None,
                 spark_conf: Optional[Mapping[str, str]] = None,
                 spark_env_vars: Optional[Mapping[str, str]] = None,
                 ssh_public_keys: Optional[Sequence[str]] = None,
                 workload_type: Optional['outputs.GetJobJobSettingsSettingsJobClusterNewClusterWorkloadTypeResult'] = None):
        pulumi.set(__self__, "driver_instance_pool_id", driver_instance_pool_id)
        pulumi.set(__self__, "driver_node_type_id", driver_node_type_id)
        pulumi.set(__self__, "enable_elastic_disk", enable_elastic_disk)
        pulumi.set(__self__, "enable_local_disk_encryption", enable_local_disk_encryption)
        pulumi.set(__self__, "node_type_id", node_type_id)
        pulumi.set(__self__, "num_workers", num_workers)
        pulumi.set(__self__, "spark_version", spark_version)
        if apply_policy_default_values is not None:
            pulumi.set(__self__, "apply_policy_default_values", apply_policy_default_values)
        if autoscale is not None:
            pulumi.set(__self__, "autoscale", autoscale)
        if autotermination_minutes is not None:
            pulumi.set(__self__, "autotermination_minutes", autotermination_minutes)
        if aws_attributes is not None:
            pulumi.set(__self__, "aws_attributes", aws_attributes)
        if azure_attributes is not None:
            pulumi.set(__self__, "azure_attributes", azure_attributes)
        if cluster_id is not None:
            pulumi.set(__self__, "cluster_id", cluster_id)
        if cluster_log_conf is not None:
            pulumi.set(__self__, "cluster_log_conf", cluster_log_conf)
        if cluster_mount_infos is not None:
            pulumi.set(__self__, "cluster_mount_infos", cluster_mount_infos)
        if cluster_name is not None:
            pulumi.set(__self__, "cluster_name", cluster_name)
        if custom_tags is not None:
            pulumi.set(__self__, "custom_tags", custom_tags)
        if data_security_mode is not None:
            pulumi.set(__self__, "data_security_mode", data_security_mode)
        if docker_image is not None:
            pulumi.set(__self__, "docker_image", docker_image)
        if gcp_attributes is not None:
            pulumi.set(__self__, "gcp_attributes", gcp_attributes)
        if idempotency_token is not None:
            pulumi.set(__self__, "idempotency_token", idempotency_token)
        if init_scripts is not None:
            pulumi.set(__self__, "init_scripts", init_scripts)
        if instance_pool_id is not None:
            pulumi.set(__self__, "instance_pool_id", instance_pool_id)
        if policy_id is not None:
            pulumi.set(__self__, "policy_id", policy_id)
        if runtime_engine is not None:
            pulumi.set(__self__, "runtime_engine", runtime_engine)
        if single_user_name is not None:
            pulumi.set(__self__, "single_user_name", single_user_name)
        if spark_conf is not None:
            pulumi.set(__self__, "spark_conf", spark_conf)
        if spark_env_vars is not None:
            pulumi.set(__self__, "spark_env_vars", spark_env_vars)
        if ssh_public_keys is not None:
            pulumi.set(__self__, "ssh_public_keys", ssh_public_keys)
        if workload_type is not None:
            pulumi.set(__self__, "workload_type", workload_type)

    @property
    @pulumi.getter(name="driverInstancePoolId")
    def driver_instance_pool_id(self) -> str:
        return pulumi.get(self, "driver_instance_pool_id")

    @property
    @pulumi.getter(name="driverNodeTypeId")
    def driver_node_type_id(self) -> str:
        return pulumi.get(self, "driver_node_type_id")

    @property
    @pulumi.getter(name="enableElasticDisk")
    def enable_elastic_disk(self) -> bool:
        return pulumi.get(self, "enable_elastic_disk")

    @property
    @pulumi.getter(name="enableLocalDiskEncryption")
    def enable_local_disk_encryption(self) -> bool:
        return pulumi.get(self, "enable_local_disk_encryption")

    @property
    @pulumi.getter(name="nodeTypeId")
    def node_type_id(self) -> str:
        return pulumi.get(self, "node_type_id")

    @property
    @pulumi.getter(name="numWorkers")
    def num_workers(self) -> int:
        return pulumi.get(self, "num_workers")

    @property
    @pulumi.getter(name="sparkVersion")
    def spark_version(self) -> str:
        return pulumi.get(self, "spark_version")

    @property
    @pulumi.getter(name="applyPolicyDefaultValues")
    def apply_policy_default_values(self) -> Optional[bool]:
        return pulumi.get(self, "apply_policy_default_values")

    @property
    @pulumi.getter
    def autoscale(self) -> Optional['outputs.GetJobJobSettingsSettingsJobClusterNewClusterAutoscaleResult']:
        return pulumi.get(self, "autoscale")

    @property
    @pulumi.getter(name="autoterminationMinutes")
    def autotermination_minutes(self) -> Optional[int]:
        return pulumi.get(self, "autotermination_minutes")

    @property
    @pulumi.getter(name="awsAttributes")
    def aws_attributes(self) -> Optional['outputs.GetJobJobSettingsSettingsJobClusterNewClusterAwsAttributesResult']:
        return pulumi.get(self, "aws_attributes")

    @property
    @pulumi.getter(name="azureAttributes")
    def azure_attributes(self) -> Optional['outputs.GetJobJobSettingsSettingsJobClusterNewClusterAzureAttributesResult']:
        return pulumi.get(self, "azure_attributes")

    @property
    @pulumi.getter(name="clusterId")
    def cluster_id(self) -> Optional[str]:
        return pulumi.get(self, "cluster_id")

    @property
    @pulumi.getter(name="clusterLogConf")
    def cluster_log_conf(self) -> Optional['outputs.GetJobJobSettingsSettingsJobClusterNewClusterClusterLogConfResult']:
        return pulumi.get(self, "cluster_log_conf")

    @property
    @pulumi.getter(name="clusterMountInfos")
    def cluster_mount_infos(self) -> Optional[Sequence['outputs.GetJobJobSettingsSettingsJobClusterNewClusterClusterMountInfoResult']]:
        return pulumi.get(self, "cluster_mount_infos")

    @property
    @pulumi.getter(name="clusterName")
    def cluster_name(self) -> Optional[str]:
        return pulumi.get(self, "cluster_name")

    @property
    @pulumi.getter(name="customTags")
    def custom_tags(self) -> Optional[Mapping[str, str]]:
        return pulumi.get(self, "custom_tags")

    @property
    @pulumi.getter(name="dataSecurityMode")
    def data_security_mode(self) -> Optional[str]:
        return pulumi.get(self, "data_security_mode")

    @property
    @pulumi.getter(name="dockerImage")
    def docker_image(self) -> Optional['outputs.GetJobJobSettingsSettingsJobClusterNewClusterDockerImageResult']:
        return pulumi.get(self, "docker_image")

    @property
    @pulumi.getter(name="gcpAttributes")
    def gcp_attributes(self) -> Optional['outputs.GetJobJobSettingsSettingsJobClusterNewClusterGcpAttributesResult']:
        return pulumi.get(self, "gcp_attributes")

    @property
    @pulumi.getter(name="idempotencyToken")
    def idempotency_token(self) -> Optional[str]:
        return pulumi.get(self, "idempotency_token")

    @property
    @pulumi.getter(name="initScripts")
    def init_scripts(self) -> Optional[Sequence['outputs.GetJobJobSettingsSettingsJobClusterNewClusterInitScriptResult']]:
        return pulumi.get(self, "init_scripts")

    @property
    @pulumi.getter(name="instancePoolId")
    def instance_pool_id(self) -> Optional[str]:
        return pulumi.get(self, "instance_pool_id")

    @property
    @pulumi.getter(name="policyId")
    def policy_id(self) -> Optional[str]:
        return pulumi.get(self, "policy_id")

    @property
    @pulumi.getter(name="runtimeEngine")
    def runtime_engine(self) -> Optional[str]:
        return pulumi.get(self, "runtime_engine")

    @property
    @pulumi.getter(name="singleUserName")
    def single_user_name(self) -> Optional[str]:
        return pulumi.get(self, "single_user_name")

    @property
    @pulumi.getter(name="sparkConf")
    def spark_conf(self) -> Optional[Mapping[str, str]]:
        return pulumi.get(self, "spark_conf")

    @property
    @pulumi.getter(name="sparkEnvVars")
    def spark_env_vars(self) -> Optional[Mapping[str, str]]:
        return pulumi.get(self, "spark_env_vars")

    @property
    @pulumi.getter(name="sshPublicKeys")
    def ssh_public_keys(self) -> Optional[Sequence[str]]:
        return pulumi.get(self, "ssh_public_keys")

    @property
    @pulumi.getter(name="workloadType")
    def workload_type(self) -> Optional['outputs.GetJobJobSettingsSettingsJobClusterNewClusterWorkloadTypeResult']:
        return pulumi.get(self, "workload_type")


@pulumi.output_type
class GetJobJobSettingsSettingsJobClusterNewClusterAutoscaleResult(dict):
    def __init__(__self__, *,
                 max_workers: Optional[int] = None,
                 min_workers: Optional[int] = None):
        if max_workers is not None:
            pulumi.set(__self__, "max_workers", max_workers)
        if min_workers is not None:
            pulumi.set(__self__, "min_workers", min_workers)

    @property
    @pulumi.getter(name="maxWorkers")
    def max_workers(self) -> Optional[int]:
        return pulumi.get(self, "max_workers")

    @property
    @pulumi.getter(name="minWorkers")
    def min_workers(self) -> Optional[int]:
        return pulumi.get(self, "min_workers")


@pulumi.output_type
class GetJobJobSettingsSettingsJobClusterNewClusterAwsAttributesResult(dict):
    def __init__(__self__, *,
                 availability: Optional[str] = None,
                 ebs_volume_count: Optional[int] = None,
                 ebs_volume_size: Optional[int] = None,
                 ebs_volume_type: Optional[str] = None,
                 first_on_demand: Optional[int] = None,
                 instance_profile_arn: Optional[str] = None,
                 spot_bid_price_percent: Optional[int] = None,
                 zone_id: Optional[str] = None):
        if availability is not None:
            pulumi.set(__self__, "availability", availability)
        if ebs_volume_count is not None:
            pulumi.set(__self__, "ebs_volume_count", ebs_volume_count)
        if ebs_volume_size is not None:
            pulumi.set(__self__, "ebs_volume_size", ebs_volume_size)
        if ebs_volume_type is not None:
            pulumi.set(__self__, "ebs_volume_type", ebs_volume_type)
        if first_on_demand is not None:
            pulumi.set(__self__, "first_on_demand", first_on_demand)
        if instance_profile_arn is not None:
            pulumi.set(__self__, "instance_profile_arn", instance_profile_arn)
        if spot_bid_price_percent is not None:
            pulumi.set(__self__, "spot_bid_price_percent", spot_bid_price_percent)
        if zone_id is not None:
            pulumi.set(__self__, "zone_id", zone_id)

    @property
    @pulumi.getter
    def availability(self) -> Optional[str]:
        return pulumi.get(self, "availability")

    @property
    @pulumi.getter(name="ebsVolumeCount")
    def ebs_volume_count(self) -> Optional[int]:
        return pulumi.get(self, "ebs_volume_count")

    @property
    @pulumi.getter(name="ebsVolumeSize")
    def ebs_volume_size(self) -> Optional[int]:
        return pulumi.get(self, "ebs_volume_size")

    @property
    @pulumi.getter(name="ebsVolumeType")
    def ebs_volume_type(self) -> Optional[str]:
        return pulumi.get(self, "ebs_volume_type")

    @property
    @pulumi.getter(name="firstOnDemand")
    def first_on_demand(self) -> Optional[int]:
        return pulumi.get(self, "first_on_demand")

    @property
    @pulumi.getter(name="instanceProfileArn")
    def instance_profile_arn(self) -> Optional[str]:
        return pulumi.get(self, "instance_profile_arn")

    @property
    @pulumi.getter(name="spotBidPricePercent")
    def spot_bid_price_percent(self) -> Optional[int]:
        return pulumi.get(self, "spot_bid_price_percent")

    @property
    @pulumi.getter(name="zoneId")
    def zone_id(self) -> Optional[str]:
        return pulumi.get(self, "zone_id")


@pulumi.output_type
class GetJobJobSettingsSettingsJobClusterNewClusterAzureAttributesResult(dict):
    def __init__(__self__, *,
                 availability: Optional[str] = None,
                 first_on_demand: Optional[int] = None,
                 spot_bid_max_price: Optional[float] = None):
        if availability is not None:
            pulumi.set(__self__, "availability", availability)
        if first_on_demand is not None:
            pulumi.set(__self__, "first_on_demand", first_on_demand)
        if spot_bid_max_price is not None:
            pulumi.set(__self__, "spot_bid_max_price", spot_bid_max_price)

    @property
    @pulumi.getter
    def availability(self) -> Optional[str]:
        return pulumi.get(self, "availability")

    @property
    @pulumi.getter(name="firstOnDemand")
    def first_on_demand(self) -> Optional[int]:
        return pulumi.get(self, "first_on_demand")

    @property
    @pulumi.getter(name="spotBidMaxPrice")
    def spot_bid_max_price(self) -> Optional[float]:
        return pulumi.get(self, "spot_bid_max_price")


@pulumi.output_type
class GetJobJobSettingsSettingsJobClusterNewClusterClusterLogConfResult(dict):
    def __init__(__self__, *,
                 dbfs: Optional['outputs.GetJobJobSettingsSettingsJobClusterNewClusterClusterLogConfDbfsResult'] = None,
                 s3: Optional['outputs.GetJobJobSettingsSettingsJobClusterNewClusterClusterLogConfS3Result'] = None):
        if dbfs is not None:
            pulumi.set(__self__, "dbfs", dbfs)
        if s3 is not None:
            pulumi.set(__self__, "s3", s3)

    @property
    @pulumi.getter
    def dbfs(self) -> Optional['outputs.GetJobJobSettingsSettingsJobClusterNewClusterClusterLogConfDbfsResult']:
        return pulumi.get(self, "dbfs")

    @property
    @pulumi.getter
    def s3(self) -> Optional['outputs.GetJobJobSettingsSettingsJobClusterNewClusterClusterLogConfS3Result']:
        return pulumi.get(self, "s3")


@pulumi.output_type
class GetJobJobSettingsSettingsJobClusterNewClusterClusterLogConfDbfsResult(dict):
    def __init__(__self__, *,
                 destination: str):
        pulumi.set(__self__, "destination", destination)

    @property
    @pulumi.getter
    def destination(self) -> str:
        return pulumi.get(self, "destination")


@pulumi.output_type
class GetJobJobSettingsSettingsJobClusterNewClusterClusterLogConfS3Result(dict):
    def __init__(__self__, *,
                 destination: str,
                 canned_acl: Optional[str] = None,
                 enable_encryption: Optional[bool] = None,
                 encryption_type: Optional[str] = None,
                 endpoint: Optional[str] = None,
                 kms_key: Optional[str] = None,
                 region: Optional[str] = None):
        pulumi.set(__self__, "destination", destination)
        if canned_acl is not None:
            pulumi.set(__self__, "canned_acl", canned_acl)
        if enable_encryption is not None:
            pulumi.set(__self__, "enable_encryption", enable_encryption)
        if encryption_type is not None:
            pulumi.set(__self__, "encryption_type", encryption_type)
        if endpoint is not None:
            pulumi.set(__self__, "endpoint", endpoint)
        if kms_key is not None:
            pulumi.set(__self__, "kms_key", kms_key)
        if region is not None:
            pulumi.set(__self__, "region", region)

    @property
    @pulumi.getter
    def destination(self) -> str:
        return pulumi.get(self, "destination")

    @property
    @pulumi.getter(name="cannedAcl")
    def canned_acl(self) -> Optional[str]:
        return pulumi.get(self, "canned_acl")

    @property
    @pulumi.getter(name="enableEncryption")
    def enable_encryption(self) -> Optional[bool]:
        return pulumi.get(self, "enable_encryption")

    @property
    @pulumi.getter(name="encryptionType")
    def encryption_type(self) -> Optional[str]:
        return pulumi.get(self, "encryption_type")

    @property
    @pulumi.getter
    def endpoint(self) -> Optional[str]:
        return pulumi.get(self, "endpoint")

    @property
    @pulumi.getter(name="kmsKey")
    def kms_key(self) -> Optional[str]:
        return pulumi.get(self, "kms_key")

    @property
    @pulumi.getter
    def region(self) -> Optional[str]:
        return pulumi.get(self, "region")


@pulumi.output_type
class GetJobJobSettingsSettingsJobClusterNewClusterClusterMountInfoResult(dict):
    def __init__(__self__, *,
                 local_mount_dir_path: str,
                 network_filesystem_info: 'outputs.GetJobJobSettingsSettingsJobClusterNewClusterClusterMountInfoNetworkFilesystemInfoResult',
                 remote_mount_dir_path: Optional[str] = None):
        pulumi.set(__self__, "local_mount_dir_path", local_mount_dir_path)
        pulumi.set(__self__, "network_filesystem_info", network_filesystem_info)
        if remote_mount_dir_path is not None:
            pulumi.set(__self__, "remote_mount_dir_path", remote_mount_dir_path)

    @property
    @pulumi.getter(name="localMountDirPath")
    def local_mount_dir_path(self) -> str:
        return pulumi.get(self, "local_mount_dir_path")

    @property
    @pulumi.getter(name="networkFilesystemInfo")
    def network_filesystem_info(self) -> 'outputs.GetJobJobSettingsSettingsJobClusterNewClusterClusterMountInfoNetworkFilesystemInfoResult':
        return pulumi.get(self, "network_filesystem_info")

    @property
    @pulumi.getter(name="remoteMountDirPath")
    def remote_mount_dir_path(self) -> Optional[str]:
        return pulumi.get(self, "remote_mount_dir_path")


@pulumi.output_type
class GetJobJobSettingsSettingsJobClusterNewClusterClusterMountInfoNetworkFilesystemInfoResult(dict):
    def __init__(__self__, *,
                 server_address: str,
                 mount_options: Optional[str] = None):
        pulumi.set(__self__, "server_address", server_address)
        if mount_options is not None:
            pulumi.set(__self__, "mount_options", mount_options)

    @property
    @pulumi.getter(name="serverAddress")
    def server_address(self) -> str:
        return pulumi.get(self, "server_address")

    @property
    @pulumi.getter(name="mountOptions")
    def mount_options(self) -> Optional[str]:
        return pulumi.get(self, "mount_options")


@pulumi.output_type
class GetJobJobSettingsSettingsJobClusterNewClusterDockerImageResult(dict):
    def __init__(__self__, *,
                 url: str,
                 basic_auth: Optional['outputs.GetJobJobSettingsSettingsJobClusterNewClusterDockerImageBasicAuthResult'] = None):
        pulumi.set(__self__, "url", url)
        if basic_auth is not None:
            pulumi.set(__self__, "basic_auth", basic_auth)

    @property
    @pulumi.getter
    def url(self) -> str:
        return pulumi.get(self, "url")

    @property
    @pulumi.getter(name="basicAuth")
    def basic_auth(self) -> Optional['outputs.GetJobJobSettingsSettingsJobClusterNewClusterDockerImageBasicAuthResult']:
        return pulumi.get(self, "basic_auth")


@pulumi.output_type
class GetJobJobSettingsSettingsJobClusterNewClusterDockerImageBasicAuthResult(dict):
    def __init__(__self__, *,
                 password: str,
                 username: str):
        pulumi.set(__self__, "password", password)
        pulumi.set(__self__, "username", username)

    @property
    @pulumi.getter
    def password(self) -> str:
        return pulumi.get(self, "password")

    @property
    @pulumi.getter
    def username(self) -> str:
        return pulumi.get(self, "username")


@pulumi.output_type
class GetJobJobSettingsSettingsJobClusterNewClusterGcpAttributesResult(dict):
    def __init__(__self__, *,
                 availability: Optional[str] = None,
                 boot_disk_size: Optional[int] = None,
                 google_service_account: Optional[str] = None,
                 local_ssd_count: Optional[int] = None,
                 use_preemptible_executors: Optional[bool] = None,
                 zone_id: Optional[str] = None):
        if availability is not None:
            pulumi.set(__self__, "availability", availability)
        if boot_disk_size is not None:
            pulumi.set(__self__, "boot_disk_size", boot_disk_size)
        if google_service_account is not None:
            pulumi.set(__self__, "google_service_account", google_service_account)
        if local_ssd_count is not None:
            pulumi.set(__self__, "local_ssd_count", local_ssd_count)
        if use_preemptible_executors is not None:
            pulumi.set(__self__, "use_preemptible_executors", use_preemptible_executors)
        if zone_id is not None:
            pulumi.set(__self__, "zone_id", zone_id)

    @property
    @pulumi.getter
    def availability(self) -> Optional[str]:
        return pulumi.get(self, "availability")

    @property
    @pulumi.getter(name="bootDiskSize")
    def boot_disk_size(self) -> Optional[int]:
        return pulumi.get(self, "boot_disk_size")

    @property
    @pulumi.getter(name="googleServiceAccount")
    def google_service_account(self) -> Optional[str]:
        return pulumi.get(self, "google_service_account")

    @property
    @pulumi.getter(name="localSsdCount")
    def local_ssd_count(self) -> Optional[int]:
        return pulumi.get(self, "local_ssd_count")

    @property
    @pulumi.getter(name="usePreemptibleExecutors")
    def use_preemptible_executors(self) -> Optional[bool]:
        return pulumi.get(self, "use_preemptible_executors")

    @property
    @pulumi.getter(name="zoneId")
    def zone_id(self) -> Optional[str]:
        return pulumi.get(self, "zone_id")


@pulumi.output_type
class GetJobJobSettingsSettingsJobClusterNewClusterInitScriptResult(dict):
    def __init__(__self__, *,
                 abfss: Optional['outputs.GetJobJobSettingsSettingsJobClusterNewClusterInitScriptAbfssResult'] = None,
                 dbfs: Optional['outputs.GetJobJobSettingsSettingsJobClusterNewClusterInitScriptDbfsResult'] = None,
                 file: Optional['outputs.GetJobJobSettingsSettingsJobClusterNewClusterInitScriptFileResult'] = None,
                 gcs: Optional['outputs.GetJobJobSettingsSettingsJobClusterNewClusterInitScriptGcsResult'] = None,
                 s3: Optional['outputs.GetJobJobSettingsSettingsJobClusterNewClusterInitScriptS3Result'] = None,
                 volumes: Optional['outputs.GetJobJobSettingsSettingsJobClusterNewClusterInitScriptVolumesResult'] = None,
                 workspace: Optional['outputs.GetJobJobSettingsSettingsJobClusterNewClusterInitScriptWorkspaceResult'] = None):
        if abfss is not None:
            pulumi.set(__self__, "abfss", abfss)
        if dbfs is not None:
            pulumi.set(__self__, "dbfs", dbfs)
        if file is not None:
            pulumi.set(__self__, "file", file)
        if gcs is not None:
            pulumi.set(__self__, "gcs", gcs)
        if s3 is not None:
            pulumi.set(__self__, "s3", s3)
        if volumes is not None:
            pulumi.set(__self__, "volumes", volumes)
        if workspace is not None:
            pulumi.set(__self__, "workspace", workspace)

    @property
    @pulumi.getter
    def abfss(self) -> Optional['outputs.GetJobJobSettingsSettingsJobClusterNewClusterInitScriptAbfssResult']:
        return pulumi.get(self, "abfss")

    @property
    @pulumi.getter
    def dbfs(self) -> Optional['outputs.GetJobJobSettingsSettingsJobClusterNewClusterInitScriptDbfsResult']:
        return pulumi.get(self, "dbfs")

    @property
    @pulumi.getter
    def file(self) -> Optional['outputs.GetJobJobSettingsSettingsJobClusterNewClusterInitScriptFileResult']:
        return pulumi.get(self, "file")

    @property
    @pulumi.getter
    def gcs(self) -> Optional['outputs.GetJobJobSettingsSettingsJobClusterNewClusterInitScriptGcsResult']:
        return pulumi.get(self, "gcs")

    @property
    @pulumi.getter
    def s3(self) -> Optional['outputs.GetJobJobSettingsSettingsJobClusterNewClusterInitScriptS3Result']:
        return pulumi.get(self, "s3")

    @property
    @pulumi.getter
    def volumes(self) -> Optional['outputs.GetJobJobSettingsSettingsJobClusterNewClusterInitScriptVolumesResult']:
        return pulumi.get(self, "volumes")

    @property
    @pulumi.getter
    def workspace(self) -> Optional['outputs.GetJobJobSettingsSettingsJobClusterNewClusterInitScriptWorkspaceResult']:
        return pulumi.get(self, "workspace")


@pulumi.output_type
class GetJobJobSettingsSettingsJobClusterNewClusterInitScriptAbfssResult(dict):
    def __init__(__self__, *,
                 destination: str):
        pulumi.set(__self__, "destination", destination)

    @property
    @pulumi.getter
    def destination(self) -> str:
        return pulumi.get(self, "destination")


@pulumi.output_type
class GetJobJobSettingsSettingsJobClusterNewClusterInitScriptDbfsResult(dict):
    def __init__(__self__, *,
                 destination: str):
        pulumi.set(__self__, "destination", destination)

    @property
    @pulumi.getter
    def destination(self) -> str:
        return pulumi.get(self, "destination")


@pulumi.output_type
class GetJobJobSettingsSettingsJobClusterNewClusterInitScriptFileResult(dict):
    def __init__(__self__, *,
                 destination: str):
        pulumi.set(__self__, "destination", destination)

    @property
    @pulumi.getter
    def destination(self) -> str:
        return pulumi.get(self, "destination")


@pulumi.output_type
class GetJobJobSettingsSettingsJobClusterNewClusterInitScriptGcsResult(dict):
    def __init__(__self__, *,
                 destination: str):
        pulumi.set(__self__, "destination", destination)

    @property
    @pulumi.getter
    def destination(self) -> str:
        return pulumi.get(self, "destination")


@pulumi.output_type
class GetJobJobSettingsSettingsJobClusterNewClusterInitScriptS3Result(dict):
    def __init__(__self__, *,
                 destination: str,
                 canned_acl: Optional[str] = None,
                 enable_encryption: Optional[bool] = None,
                 encryption_type: Optional[str] = None,
                 endpoint: Optional[str] = None,
                 kms_key: Optional[str] = None,
                 region: Optional[str] = None):
        pulumi.set(__self__, "destination", destination)
        if canned_acl is not None:
            pulumi.set(__self__, "canned_acl", canned_acl)
        if enable_encryption is not None:
            pulumi.set(__self__, "enable_encryption", enable_encryption)
        if encryption_type is not None:
            pulumi.set(__self__, "encryption_type", encryption_type)
        if endpoint is not None:
            pulumi.set(__self__, "endpoint", endpoint)
        if kms_key is not None:
            pulumi.set(__self__, "kms_key", kms_key)
        if region is not None:
            pulumi.set(__self__, "region", region)

    @property
    @pulumi.getter
    def destination(self) -> str:
        return pulumi.get(self, "destination")

    @property
    @pulumi.getter(name="cannedAcl")
    def canned_acl(self) -> Optional[str]:
        return pulumi.get(self, "canned_acl")

    @property
    @pulumi.getter(name="enableEncryption")
    def enable_encryption(self) -> Optional[bool]:
        return pulumi.get(self, "enable_encryption")

    @property
    @pulumi.getter(name="encryptionType")
    def encryption_type(self) -> Optional[str]:
        return pulumi.get(self, "encryption_type")

    @property
    @pulumi.getter
    def endpoint(self) -> Optional[str]:
        return pulumi.get(self, "endpoint")

    @property
    @pulumi.getter(name="kmsKey")
    def kms_key(self) -> Optional[str]:
        return pulumi.get(self, "kms_key")

    @property
    @pulumi.getter
    def region(self) -> Optional[str]:
        return pulumi.get(self, "region")


@pulumi.output_type
class GetJobJobSettingsSettingsJobClusterNewClusterInitScriptVolumesResult(dict):
    def __init__(__self__, *,
                 destination: str):
        pulumi.set(__self__, "destination", destination)

    @property
    @pulumi.getter
    def destination(self) -> str:
        return pulumi.get(self, "destination")


@pulumi.output_type
class GetJobJobSettingsSettingsJobClusterNewClusterInitScriptWorkspaceResult(dict):
    def __init__(__self__, *,
                 destination: str):
        pulumi.set(__self__, "destination", destination)

    @property
    @pulumi.getter
    def destination(self) -> str:
        return pulumi.get(self, "destination")


@pulumi.output_type
class GetJobJobSettingsSettingsJobClusterNewClusterWorkloadTypeResult(dict):
    def __init__(__self__, *,
                 clients: 'outputs.GetJobJobSettingsSettingsJobClusterNewClusterWorkloadTypeClientsResult'):
        pulumi.set(__self__, "clients", clients)

    @property
    @pulumi.getter
    def clients(self) -> 'outputs.GetJobJobSettingsSettingsJobClusterNewClusterWorkloadTypeClientsResult':
        return pulumi.get(self, "clients")


@pulumi.output_type
class GetJobJobSettingsSettingsJobClusterNewClusterWorkloadTypeClientsResult(dict):
    def __init__(__self__, *,
                 jobs: Optional[bool] = None,
                 notebooks: Optional[bool] = None):
        if jobs is not None:
            pulumi.set(__self__, "jobs", jobs)
        if notebooks is not None:
            pulumi.set(__self__, "notebooks", notebooks)

    @property
    @pulumi.getter
    def jobs(self) -> Optional[bool]:
        return pulumi.get(self, "jobs")

    @property
    @pulumi.getter
    def notebooks(self) -> Optional[bool]:
        return pulumi.get(self, "notebooks")


@pulumi.output_type
class GetJobJobSettingsSettingsLibraryResult(dict):
    def __init__(__self__, *,
                 cran: Optional['outputs.GetJobJobSettingsSettingsLibraryCranResult'] = None,
                 egg: Optional[str] = None,
                 jar: Optional[str] = None,
                 maven: Optional['outputs.GetJobJobSettingsSettingsLibraryMavenResult'] = None,
                 pypi: Optional['outputs.GetJobJobSettingsSettingsLibraryPypiResult'] = None,
                 requirements: Optional[str] = None,
                 whl: Optional[str] = None):
        if cran is not None:
            pulumi.set(__self__, "cran", cran)
        if egg is not None:
            pulumi.set(__self__, "egg", egg)
        if jar is not None:
            pulumi.set(__self__, "jar", jar)
        if maven is not None:
            pulumi.set(__self__, "maven", maven)
        if pypi is not None:
            pulumi.set(__self__, "pypi", pypi)
        if requirements is not None:
            pulumi.set(__self__, "requirements", requirements)
        if whl is not None:
            pulumi.set(__self__, "whl", whl)

    @property
    @pulumi.getter
    def cran(self) -> Optional['outputs.GetJobJobSettingsSettingsLibraryCranResult']:
        return pulumi.get(self, "cran")

    @property
    @pulumi.getter
    def egg(self) -> Optional[str]:
        return pulumi.get(self, "egg")

    @property
    @pulumi.getter
    def jar(self) -> Optional[str]:
        return pulumi.get(self, "jar")

    @property
    @pulumi.getter
    def maven(self) -> Optional['outputs.GetJobJobSettingsSettingsLibraryMavenResult']:
        return pulumi.get(self, "maven")

    @property
    @pulumi.getter
    def pypi(self) -> Optional['outputs.GetJobJobSettingsSettingsLibraryPypiResult']:
        return pulumi.get(self, "pypi")

    @property
    @pulumi.getter
    def requirements(self) -> Optional[str]:
        return pulumi.get(self, "requirements")

    @property
    @pulumi.getter
    def whl(self) -> Optional[str]:
        return pulumi.get(self, "whl")


@pulumi.output_type
class GetJobJobSettingsSettingsLibraryCranResult(dict):
    def __init__(__self__, *,
                 package: str,
                 repo: Optional[str] = None):
        pulumi.set(__self__, "package", package)
        if repo is not None:
            pulumi.set(__self__, "repo", repo)

    @property
    @pulumi.getter
    def package(self) -> str:
        return pulumi.get(self, "package")

    @property
    @pulumi.getter
    def repo(self) -> Optional[str]:
        return pulumi.get(self, "repo")


@pulumi.output_type
class GetJobJobSettingsSettingsLibraryMavenResult(dict):
    def __init__(__self__, *,
                 coordinates: str,
                 exclusions: Optional[Sequence[str]] = None,
                 repo: Optional[str] = None):
        pulumi.set(__self__, "coordinates", coordinates)
        if exclusions is not None:
            pulumi.set(__self__, "exclusions", exclusions)
        if repo is not None:
            pulumi.set(__self__, "repo", repo)

    @property
    @pulumi.getter
    def coordinates(self) -> str:
        return pulumi.get(self, "coordinates")

    @property
    @pulumi.getter
    def exclusions(self) -> Optional[Sequence[str]]:
        return pulumi.get(self, "exclusions")

    @property
    @pulumi.getter
    def repo(self) -> Optional[str]:
        return pulumi.get(self, "repo")


@pulumi.output_type
class GetJobJobSettingsSettingsLibraryPypiResult(dict):
    def __init__(__self__, *,
                 package: str,
                 repo: Optional[str] = None):
        pulumi.set(__self__, "package", package)
        if repo is not None:
            pulumi.set(__self__, "repo", repo)

    @property
    @pulumi.getter
    def package(self) -> str:
        return pulumi.get(self, "package")

    @property
    @pulumi.getter
    def repo(self) -> Optional[str]:
        return pulumi.get(self, "repo")


@pulumi.output_type
class GetJobJobSettingsSettingsNewClusterResult(dict):
    def __init__(__self__, *,
                 driver_instance_pool_id: str,
                 driver_node_type_id: str,
                 enable_elastic_disk: bool,
                 enable_local_disk_encryption: bool,
                 node_type_id: str,
                 num_workers: int,
                 spark_version: str,
                 apply_policy_default_values: Optional[bool] = None,
                 autoscale: Optional['outputs.GetJobJobSettingsSettingsNewClusterAutoscaleResult'] = None,
                 autotermination_minutes: Optional[int] = None,
                 aws_attributes: Optional['outputs.GetJobJobSettingsSettingsNewClusterAwsAttributesResult'] = None,
                 azure_attributes: Optional['outputs.GetJobJobSettingsSettingsNewClusterAzureAttributesResult'] = None,
                 cluster_id: Optional[str] = None,
                 cluster_log_conf: Optional['outputs.GetJobJobSettingsSettingsNewClusterClusterLogConfResult'] = None,
                 cluster_mount_infos: Optional[Sequence['outputs.GetJobJobSettingsSettingsNewClusterClusterMountInfoResult']] = None,
                 cluster_name: Optional[str] = None,
                 custom_tags: Optional[Mapping[str, str]] = None,
                 data_security_mode: Optional[str] = None,
                 docker_image: Optional['outputs.GetJobJobSettingsSettingsNewClusterDockerImageResult'] = None,
                 gcp_attributes: Optional['outputs.GetJobJobSettingsSettingsNewClusterGcpAttributesResult'] = None,
                 idempotency_token: Optional[str] = None,
                 init_scripts: Optional[Sequence['outputs.GetJobJobSettingsSettingsNewClusterInitScriptResult']] = None,
                 instance_pool_id: Optional[str] = None,
                 policy_id: Optional[str] = None,
                 runtime_engine: Optional[str] = None,
                 single_user_name: Optional[str] = None,
                 spark_conf: Optional[Mapping[str, str]] = None,
                 spark_env_vars: Optional[Mapping[str, str]] = None,
                 ssh_public_keys: Optional[Sequence[str]] = None,
                 workload_type: Optional['outputs.GetJobJobSettingsSettingsNewClusterWorkloadTypeResult'] = None):
        pulumi.set(__self__, "driver_instance_pool_id", driver_instance_pool_id)
        pulumi.set(__self__, "driver_node_type_id", driver_node_type_id)
        pulumi.set(__self__, "enable_elastic_disk", enable_elastic_disk)
        pulumi.set(__self__, "enable_local_disk_encryption", enable_local_disk_encryption)
        pulumi.set(__self__, "node_type_id", node_type_id)
        pulumi.set(__self__, "num_workers", num_workers)
        pulumi.set(__self__, "spark_version", spark_version)
        if apply_policy_default_values is not None:
            pulumi.set(__self__, "apply_policy_default_values", apply_policy_default_values)
        if autoscale is not None:
            pulumi.set(__self__, "autoscale", autoscale)
        if autotermination_minutes is not None:
            pulumi.set(__self__, "autotermination_minutes", autotermination_minutes)
        if aws_attributes is not None:
            pulumi.set(__self__, "aws_attributes", aws_attributes)
        if azure_attributes is not None:
            pulumi.set(__self__, "azure_attributes", azure_attributes)
        if cluster_id is not None:
            pulumi.set(__self__, "cluster_id", cluster_id)
        if cluster_log_conf is not None:
            pulumi.set(__self__, "cluster_log_conf", cluster_log_conf)
        if cluster_mount_infos is not None:
            pulumi.set(__self__, "cluster_mount_infos", cluster_mount_infos)
        if cluster_name is not None:
            pulumi.set(__self__, "cluster_name", cluster_name)
        if custom_tags is not None:
            pulumi.set(__self__, "custom_tags", custom_tags)
        if data_security_mode is not None:
            pulumi.set(__self__, "data_security_mode", data_security_mode)
        if docker_image is not None:
            pulumi.set(__self__, "docker_image", docker_image)
        if gcp_attributes is not None:
            pulumi.set(__self__, "gcp_attributes", gcp_attributes)
        if idempotency_token is not None:
            pulumi.set(__self__, "idempotency_token", idempotency_token)
        if init_scripts is not None:
            pulumi.set(__self__, "init_scripts", init_scripts)
        if instance_pool_id is not None:
            pulumi.set(__self__, "instance_pool_id", instance_pool_id)
        if policy_id is not None:
            pulumi.set(__self__, "policy_id", policy_id)
        if runtime_engine is not None:
            pulumi.set(__self__, "runtime_engine", runtime_engine)
        if single_user_name is not None:
            pulumi.set(__self__, "single_user_name", single_user_name)
        if spark_conf is not None:
            pulumi.set(__self__, "spark_conf", spark_conf)
        if spark_env_vars is not None:
            pulumi.set(__self__, "spark_env_vars", spark_env_vars)
        if ssh_public_keys is not None:
            pulumi.set(__self__, "ssh_public_keys", ssh_public_keys)
        if workload_type is not None:
            pulumi.set(__self__, "workload_type", workload_type)

    @property
    @pulumi.getter(name="driverInstancePoolId")
    def driver_instance_pool_id(self) -> str:
        return pulumi.get(self, "driver_instance_pool_id")

    @property
    @pulumi.getter(name="driverNodeTypeId")
    def driver_node_type_id(self) -> str:
        return pulumi.get(self, "driver_node_type_id")

    @property
    @pulumi.getter(name="enableElasticDisk")
    def enable_elastic_disk(self) -> bool:
        return pulumi.get(self, "enable_elastic_disk")

    @property
    @pulumi.getter(name="enableLocalDiskEncryption")
    def enable_local_disk_encryption(self) -> bool:
        return pulumi.get(self, "enable_local_disk_encryption")

    @property
    @pulumi.getter(name="nodeTypeId")
    def node_type_id(self) -> str:
        return pulumi.get(self, "node_type_id")

    @property
    @pulumi.getter(name="numWorkers")
    def num_workers(self) -> int:
        return pulumi.get(self, "num_workers")

    @property
    @pulumi.getter(name="sparkVersion")
    def spark_version(self) -> str:
        return pulumi.get(self, "spark_version")

    @property
    @pulumi.getter(name="applyPolicyDefaultValues")
    def apply_policy_default_values(self) -> Optional[bool]:
        return pulumi.get(self, "apply_policy_default_values")

    @property
    @pulumi.getter
    def autoscale(self) -> Optional['outputs.GetJobJobSettingsSettingsNewClusterAutoscaleResult']:
        return pulumi.get(self, "autoscale")

    @property
    @pulumi.getter(name="autoterminationMinutes")
    def autotermination_minutes(self) -> Optional[int]:
        return pulumi.get(self, "autotermination_minutes")

    @property
    @pulumi.getter(name="awsAttributes")
    def aws_attributes(self) -> Optional['outputs.GetJobJobSettingsSettingsNewClusterAwsAttributesResult']:
        return pulumi.get(self, "aws_attributes")

    @property
    @pulumi.getter(name="azureAttributes")
    def azure_attributes(self) -> Optional['outputs.GetJobJobSettingsSettingsNewClusterAzureAttributesResult']:
        return pulumi.get(self, "azure_attributes")

    @property
    @pulumi.getter(name="clusterId")
    def cluster_id(self) -> Optional[str]:
        return pulumi.get(self, "cluster_id")

    @property
    @pulumi.getter(name="clusterLogConf")
    def cluster_log_conf(self) -> Optional['outputs.GetJobJobSettingsSettingsNewClusterClusterLogConfResult']:
        return pulumi.get(self, "cluster_log_conf")

    @property
    @pulumi.getter(name="clusterMountInfos")
    def cluster_mount_infos(self) -> Optional[Sequence['outputs.GetJobJobSettingsSettingsNewClusterClusterMountInfoResult']]:
        return pulumi.get(self, "cluster_mount_infos")

    @property
    @pulumi.getter(name="clusterName")
    def cluster_name(self) -> Optional[str]:
        return pulumi.get(self, "cluster_name")

    @property
    @pulumi.getter(name="customTags")
    def custom_tags(self) -> Optional[Mapping[str, str]]:
        return pulumi.get(self, "custom_tags")

    @property
    @pulumi.getter(name="dataSecurityMode")
    def data_security_mode(self) -> Optional[str]:
        return pulumi.get(self, "data_security_mode")

    @property
    @pulumi.getter(name="dockerImage")
    def docker_image(self) -> Optional['outputs.GetJobJobSettingsSettingsNewClusterDockerImageResult']:
        return pulumi.get(self, "docker_image")

    @property
    @pulumi.getter(name="gcpAttributes")
    def gcp_attributes(self) -> Optional['outputs.GetJobJobSettingsSettingsNewClusterGcpAttributesResult']:
        return pulumi.get(self, "gcp_attributes")

    @property
    @pulumi.getter(name="idempotencyToken")
    def idempotency_token(self) -> Optional[str]:
        return pulumi.get(self, "idempotency_token")

    @property
    @pulumi.getter(name="initScripts")
    def init_scripts(self) -> Optional[Sequence['outputs.GetJobJobSettingsSettingsNewClusterInitScriptResult']]:
        return pulumi.get(self, "init_scripts")

    @property
    @pulumi.getter(name="instancePoolId")
    def instance_pool_id(self) -> Optional[str]:
        return pulumi.get(self, "instance_pool_id")

    @property
    @pulumi.getter(name="policyId")
    def policy_id(self) -> Optional[str]:
        return pulumi.get(self, "policy_id")

    @property
    @pulumi.getter(name="runtimeEngine")
    def runtime_engine(self) -> Optional[str]:
        return pulumi.get(self, "runtime_engine")

    @property
    @pulumi.getter(name="singleUserName")
    def single_user_name(self) -> Optional[str]:
        return pulumi.get(self, "single_user_name")

    @property
    @pulumi.getter(name="sparkConf")
    def spark_conf(self) -> Optional[Mapping[str, str]]:
        return pulumi.get(self, "spark_conf")

    @property
    @pulumi.getter(name="sparkEnvVars")
    def spark_env_vars(self) -> Optional[Mapping[str, str]]:
        return pulumi.get(self, "spark_env_vars")

    @property
    @pulumi.getter(name="sshPublicKeys")
    def ssh_public_keys(self) -> Optional[Sequence[str]]:
        return pulumi.get(self, "ssh_public_keys")

    @property
    @pulumi.getter(name="workloadType")
    def workload_type(self) -> Optional['outputs.GetJobJobSettingsSettingsNewClusterWorkloadTypeResult']:
        return pulumi.get(self, "workload_type")


@pulumi.output_type
class GetJobJobSettingsSettingsNewClusterAutoscaleResult(dict):
    def __init__(__self__, *,
                 max_workers: Optional[int] = None,
                 min_workers: Optional[int] = None):
        if max_workers is not None:
            pulumi.set(__self__, "max_workers", max_workers)
        if min_workers is not None:
            pulumi.set(__self__, "min_workers", min_workers)

    @property
    @pulumi.getter(name="maxWorkers")
    def max_workers(self) -> Optional[int]:
        return pulumi.get(self, "max_workers")

    @property
    @pulumi.getter(name="minWorkers")
    def min_workers(self) -> Optional[int]:
        return pulumi.get(self, "min_workers")


@pulumi.output_type
class GetJobJobSettingsSettingsNewClusterAwsAttributesResult(dict):
    def __init__(__self__, *,
                 availability: Optional[str] = None,
                 ebs_volume_count: Optional[int] = None,
                 ebs_volume_size: Optional[int] = None,
                 ebs_volume_type: Optional[str] = None,
                 first_on_demand: Optional[int] = None,
                 instance_profile_arn: Optional[str] = None,
                 spot_bid_price_percent: Optional[int] = None,
                 zone_id: Optional[str] = None):
        if availability is not None:
            pulumi.set(__self__, "availability", availability)
        if ebs_volume_count is not None:
            pulumi.set(__self__, "ebs_volume_count", ebs_volume_count)
        if ebs_volume_size is not None:
            pulumi.set(__self__, "ebs_volume_size", ebs_volume_size)
        if ebs_volume_type is not None:
            pulumi.set(__self__, "ebs_volume_type", ebs_volume_type)
        if first_on_demand is not None:
            pulumi.set(__self__, "first_on_demand", first_on_demand)
        if instance_profile_arn is not None:
            pulumi.set(__self__, "instance_profile_arn", instance_profile_arn)
        if spot_bid_price_percent is not None:
            pulumi.set(__self__, "spot_bid_price_percent", spot_bid_price_percent)
        if zone_id is not None:
            pulumi.set(__self__, "zone_id", zone_id)

    @property
    @pulumi.getter
    def availability(self) -> Optional[str]:
        return pulumi.get(self, "availability")

    @property
    @pulumi.getter(name="ebsVolumeCount")
    def ebs_volume_count(self) -> Optional[int]:
        return pulumi.get(self, "ebs_volume_count")

    @property
    @pulumi.getter(name="ebsVolumeSize")
    def ebs_volume_size(self) -> Optional[int]:
        return pulumi.get(self, "ebs_volume_size")

    @property
    @pulumi.getter(name="ebsVolumeType")
    def ebs_volume_type(self) -> Optional[str]:
        return pulumi.get(self, "ebs_volume_type")

    @property
    @pulumi.getter(name="firstOnDemand")
    def first_on_demand(self) -> Optional[int]:
        return pulumi.get(self, "first_on_demand")

    @property
    @pulumi.getter(name="instanceProfileArn")
    def instance_profile_arn(self) -> Optional[str]:
        return pulumi.get(self, "instance_profile_arn")

    @property
    @pulumi.getter(name="spotBidPricePercent")
    def spot_bid_price_percent(self) -> Optional[int]:
        return pulumi.get(self, "spot_bid_price_percent")

    @property
    @pulumi.getter(name="zoneId")
    def zone_id(self) -> Optional[str]:
        return pulumi.get(self, "zone_id")


@pulumi.output_type
class GetJobJobSettingsSettingsNewClusterAzureAttributesResult(dict):
    def __init__(__self__, *,
                 availability: Optional[str] = None,
                 first_on_demand: Optional[int] = None,
                 spot_bid_max_price: Optional[float] = None):
        if availability is not None:
            pulumi.set(__self__, "availability", availability)
        if first_on_demand is not None:
            pulumi.set(__self__, "first_on_demand", first_on_demand)
        if spot_bid_max_price is not None:
            pulumi.set(__self__, "spot_bid_max_price", spot_bid_max_price)

    @property
    @pulumi.getter
    def availability(self) -> Optional[str]:
        return pulumi.get(self, "availability")

    @property
    @pulumi.getter(name="firstOnDemand")
    def first_on_demand(self) -> Optional[int]:
        return pulumi.get(self, "first_on_demand")

    @property
    @pulumi.getter(name="spotBidMaxPrice")
    def spot_bid_max_price(self) -> Optional[float]:
        return pulumi.get(self, "spot_bid_max_price")


@pulumi.output_type
class GetJobJobSettingsSettingsNewClusterClusterLogConfResult(dict):
    def __init__(__self__, *,
                 dbfs: Optional['outputs.GetJobJobSettingsSettingsNewClusterClusterLogConfDbfsResult'] = None,
                 s3: Optional['outputs.GetJobJobSettingsSettingsNewClusterClusterLogConfS3Result'] = None):
        if dbfs is not None:
            pulumi.set(__self__, "dbfs", dbfs)
        if s3 is not None:
            pulumi.set(__self__, "s3", s3)

    @property
    @pulumi.getter
    def dbfs(self) -> Optional['outputs.GetJobJobSettingsSettingsNewClusterClusterLogConfDbfsResult']:
        return pulumi.get(self, "dbfs")

    @property
    @pulumi.getter
    def s3(self) -> Optional['outputs.GetJobJobSettingsSettingsNewClusterClusterLogConfS3Result']:
        return pulumi.get(self, "s3")


@pulumi.output_type
class GetJobJobSettingsSettingsNewClusterClusterLogConfDbfsResult(dict):
    def __init__(__self__, *,
                 destination: str):
        pulumi.set(__self__, "destination", destination)

    @property
    @pulumi.getter
    def destination(self) -> str:
        return pulumi.get(self, "destination")


@pulumi.output_type
class GetJobJobSettingsSettingsNewClusterClusterLogConfS3Result(dict):
    def __init__(__self__, *,
                 destination: str,
                 canned_acl: Optional[str] = None,
                 enable_encryption: Optional[bool] = None,
                 encryption_type: Optional[str] = None,
                 endpoint: Optional[str] = None,
                 kms_key: Optional[str] = None,
                 region: Optional[str] = None):
        pulumi.set(__self__, "destination", destination)
        if canned_acl is not None:
            pulumi.set(__self__, "canned_acl", canned_acl)
        if enable_encryption is not None:
            pulumi.set(__self__, "enable_encryption", enable_encryption)
        if encryption_type is not None:
            pulumi.set(__self__, "encryption_type", encryption_type)
        if endpoint is not None:
            pulumi.set(__self__, "endpoint", endpoint)
        if kms_key is not None:
            pulumi.set(__self__, "kms_key", kms_key)
        if region is not None:
            pulumi.set(__self__, "region", region)

    @property
    @pulumi.getter
    def destination(self) -> str:
        return pulumi.get(self, "destination")

    @property
    @pulumi.getter(name="cannedAcl")
    def canned_acl(self) -> Optional[str]:
        return pulumi.get(self, "canned_acl")

    @property
    @pulumi.getter(name="enableEncryption")
    def enable_encryption(self) -> Optional[bool]:
        return pulumi.get(self, "enable_encryption")

    @property
    @pulumi.getter(name="encryptionType")
    def encryption_type(self) -> Optional[str]:
        return pulumi.get(self, "encryption_type")

    @property
    @pulumi.getter
    def endpoint(self) -> Optional[str]:
        return pulumi.get(self, "endpoint")

    @property
    @pulumi.getter(name="kmsKey")
    def kms_key(self) -> Optional[str]:
        return pulumi.get(self, "kms_key")

    @property
    @pulumi.getter
    def region(self) -> Optional[str]:
        return pulumi.get(self, "region")


@pulumi.output_type
class GetJobJobSettingsSettingsNewClusterClusterMountInfoResult(dict):
    def __init__(__self__, *,
                 local_mount_dir_path: str,
                 network_filesystem_info: 'outputs.GetJobJobSettingsSettingsNewClusterClusterMountInfoNetworkFilesystemInfoResult',
                 remote_mount_dir_path: Optional[str] = None):
        pulumi.set(__self__, "local_mount_dir_path", local_mount_dir_path)
        pulumi.set(__self__, "network_filesystem_info", network_filesystem_info)
        if remote_mount_dir_path is not None:
            pulumi.set(__self__, "remote_mount_dir_path", remote_mount_dir_path)

    @property
    @pulumi.getter(name="localMountDirPath")
    def local_mount_dir_path(self) -> str:
        return pulumi.get(self, "local_mount_dir_path")

    @property
    @pulumi.getter(name="networkFilesystemInfo")
    def network_filesystem_info(self) -> 'outputs.GetJobJobSettingsSettingsNewClusterClusterMountInfoNetworkFilesystemInfoResult':
        return pulumi.get(self, "network_filesystem_info")

    @property
    @pulumi.getter(name="remoteMountDirPath")
    def remote_mount_dir_path(self) -> Optional[str]:
        return pulumi.get(self, "remote_mount_dir_path")


@pulumi.output_type
class GetJobJobSettingsSettingsNewClusterClusterMountInfoNetworkFilesystemInfoResult(dict):
    def __init__(__self__, *,
                 server_address: str,
                 mount_options: Optional[str] = None):
        pulumi.set(__self__, "server_address", server_address)
        if mount_options is not None:
            pulumi.set(__self__, "mount_options", mount_options)

    @property
    @pulumi.getter(name="serverAddress")
    def server_address(self) -> str:
        return pulumi.get(self, "server_address")

    @property
    @pulumi.getter(name="mountOptions")
    def mount_options(self) -> Optional[str]:
        return pulumi.get(self, "mount_options")


@pulumi.output_type
class GetJobJobSettingsSettingsNewClusterDockerImageResult(dict):
    def __init__(__self__, *,
                 url: str,
                 basic_auth: Optional['outputs.GetJobJobSettingsSettingsNewClusterDockerImageBasicAuthResult'] = None):
        pulumi.set(__self__, "url", url)
        if basic_auth is not None:
            pulumi.set(__self__, "basic_auth", basic_auth)

    @property
    @pulumi.getter
    def url(self) -> str:
        return pulumi.get(self, "url")

    @property
    @pulumi.getter(name="basicAuth")
    def basic_auth(self) -> Optional['outputs.GetJobJobSettingsSettingsNewClusterDockerImageBasicAuthResult']:
        return pulumi.get(self, "basic_auth")


@pulumi.output_type
class GetJobJobSettingsSettingsNewClusterDockerImageBasicAuthResult(dict):
    def __init__(__self__, *,
                 password: str,
                 username: str):
        pulumi.set(__self__, "password", password)
        pulumi.set(__self__, "username", username)

    @property
    @pulumi.getter
    def password(self) -> str:
        return pulumi.get(self, "password")

    @property
    @pulumi.getter
    def username(self) -> str:
        return pulumi.get(self, "username")


@pulumi.output_type
class GetJobJobSettingsSettingsNewClusterGcpAttributesResult(dict):
    def __init__(__self__, *,
                 availability: Optional[str] = None,
                 boot_disk_size: Optional[int] = None,
                 google_service_account: Optional[str] = None,
                 local_ssd_count: Optional[int] = None,
                 use_preemptible_executors: Optional[bool] = None,
                 zone_id: Optional[str] = None):
        if availability is not None:
            pulumi.set(__self__, "availability", availability)
        if boot_disk_size is not None:
            pulumi.set(__self__, "boot_disk_size", boot_disk_size)
        if google_service_account is not None:
            pulumi.set(__self__, "google_service_account", google_service_account)
        if local_ssd_count is not None:
            pulumi.set(__self__, "local_ssd_count", local_ssd_count)
        if use_preemptible_executors is not None:
            pulumi.set(__self__, "use_preemptible_executors", use_preemptible_executors)
        if zone_id is not None:
            pulumi.set(__self__, "zone_id", zone_id)

    @property
    @pulumi.getter
    def availability(self) -> Optional[str]:
        return pulumi.get(self, "availability")

    @property
    @pulumi.getter(name="bootDiskSize")
    def boot_disk_size(self) -> Optional[int]:
        return pulumi.get(self, "boot_disk_size")

    @property
    @pulumi.getter(name="googleServiceAccount")
    def google_service_account(self) -> Optional[str]:
        return pulumi.get(self, "google_service_account")

    @property
    @pulumi.getter(name="localSsdCount")
    def local_ssd_count(self) -> Optional[int]:
        return pulumi.get(self, "local_ssd_count")

    @property
    @pulumi.getter(name="usePreemptibleExecutors")
    def use_preemptible_executors(self) -> Optional[bool]:
        return pulumi.get(self, "use_preemptible_executors")

    @property
    @pulumi.getter(name="zoneId")
    def zone_id(self) -> Optional[str]:
        return pulumi.get(self, "zone_id")


@pulumi.output_type
class GetJobJobSettingsSettingsNewClusterInitScriptResult(dict):
    def __init__(__self__, *,
                 abfss: Optional['outputs.GetJobJobSettingsSettingsNewClusterInitScriptAbfssResult'] = None,
                 dbfs: Optional['outputs.GetJobJobSettingsSettingsNewClusterInitScriptDbfsResult'] = None,
                 file: Optional['outputs.GetJobJobSettingsSettingsNewClusterInitScriptFileResult'] = None,
                 gcs: Optional['outputs.GetJobJobSettingsSettingsNewClusterInitScriptGcsResult'] = None,
                 s3: Optional['outputs.GetJobJobSettingsSettingsNewClusterInitScriptS3Result'] = None,
                 volumes: Optional['outputs.GetJobJobSettingsSettingsNewClusterInitScriptVolumesResult'] = None,
                 workspace: Optional['outputs.GetJobJobSettingsSettingsNewClusterInitScriptWorkspaceResult'] = None):
        if abfss is not None:
            pulumi.set(__self__, "abfss", abfss)
        if dbfs is not None:
            pulumi.set(__self__, "dbfs", dbfs)
        if file is not None:
            pulumi.set(__self__, "file", file)
        if gcs is not None:
            pulumi.set(__self__, "gcs", gcs)
        if s3 is not None:
            pulumi.set(__self__, "s3", s3)
        if volumes is not None:
            pulumi.set(__self__, "volumes", volumes)
        if workspace is not None:
            pulumi.set(__self__, "workspace", workspace)

    @property
    @pulumi.getter
    def abfss(self) -> Optional['outputs.GetJobJobSettingsSettingsNewClusterInitScriptAbfssResult']:
        return pulumi.get(self, "abfss")

    @property
    @pulumi.getter
    def dbfs(self) -> Optional['outputs.GetJobJobSettingsSettingsNewClusterInitScriptDbfsResult']:
        return pulumi.get(self, "dbfs")

    @property
    @pulumi.getter
    def file(self) -> Optional['outputs.GetJobJobSettingsSettingsNewClusterInitScriptFileResult']:
        return pulumi.get(self, "file")

    @property
    @pulumi.getter
    def gcs(self) -> Optional['outputs.GetJobJobSettingsSettingsNewClusterInitScriptGcsResult']:
        return pulumi.get(self, "gcs")

    @property
    @pulumi.getter
    def s3(self) -> Optional['outputs.GetJobJobSettingsSettingsNewClusterInitScriptS3Result']:
        return pulumi.get(self, "s3")

    @property
    @pulumi.getter
    def volumes(self) -> Optional['outputs.GetJobJobSettingsSettingsNewClusterInitScriptVolumesResult']:
        return pulumi.get(self, "volumes")

    @property
    @pulumi.getter
    def workspace(self) -> Optional['outputs.GetJobJobSettingsSettingsNewClusterInitScriptWorkspaceResult']:
        return pulumi.get(self, "workspace")


@pulumi.output_type
class GetJobJobSettingsSettingsNewClusterInitScriptAbfssResult(dict):
    def __init__(__self__, *,
                 destination: str):
        pulumi.set(__self__, "destination", destination)

    @property
    @pulumi.getter
    def destination(self) -> str:
        return pulumi.get(self, "destination")


@pulumi.output_type
class GetJobJobSettingsSettingsNewClusterInitScriptDbfsResult(dict):
    def __init__(__self__, *,
                 destination: str):
        pulumi.set(__self__, "destination", destination)

    @property
    @pulumi.getter
    def destination(self) -> str:
        return pulumi.get(self, "destination")


@pulumi.output_type
class GetJobJobSettingsSettingsNewClusterInitScriptFileResult(dict):
    def __init__(__self__, *,
                 destination: str):
        pulumi.set(__self__, "destination", destination)

    @property
    @pulumi.getter
    def destination(self) -> str:
        return pulumi.get(self, "destination")


@pulumi.output_type
class GetJobJobSettingsSettingsNewClusterInitScriptGcsResult(dict):
    def __init__(__self__, *,
                 destination: str):
        pulumi.set(__self__, "destination", destination)

    @property
    @pulumi.getter
    def destination(self) -> str:
        return pulumi.get(self, "destination")


@pulumi.output_type
class GetJobJobSettingsSettingsNewClusterInitScriptS3Result(dict):
    def __init__(__self__, *,
                 destination: str,
                 canned_acl: Optional[str] = None,
                 enable_encryption: Optional[bool] = None,
                 encryption_type: Optional[str] = None,
                 endpoint: Optional[str] = None,
                 kms_key: Optional[str] = None,
                 region: Optional[str] = None):
        pulumi.set(__self__, "destination", destination)
        if canned_acl is not None:
            pulumi.set(__self__, "canned_acl", canned_acl)
        if enable_encryption is not None:
            pulumi.set(__self__, "enable_encryption", enable_encryption)
        if encryption_type is not None:
            pulumi.set(__self__, "encryption_type", encryption_type)
        if endpoint is not None:
            pulumi.set(__self__, "endpoint", endpoint)
        if kms_key is not None:
            pulumi.set(__self__, "kms_key", kms_key)
        if region is not None:
            pulumi.set(__self__, "region", region)

    @property
    @pulumi.getter
    def destination(self) -> str:
        return pulumi.get(self, "destination")

    @property
    @pulumi.getter(name="cannedAcl")
    def canned_acl(self) -> Optional[str]:
        return pulumi.get(self, "canned_acl")

    @property
    @pulumi.getter(name="enableEncryption")
    def enable_encryption(self) -> Optional[bool]:
        return pulumi.get(self, "enable_encryption")

    @property
    @pulumi.getter(name="encryptionType")
    def encryption_type(self) -> Optional[str]:
        return pulumi.get(self, "encryption_type")

    @property
    @pulumi.getter
    def endpoint(self) -> Optional[str]:
        return pulumi.get(self, "endpoint")

    @property
    @pulumi.getter(name="kmsKey")
    def kms_key(self) -> Optional[str]:
        return pulumi.get(self, "kms_key")

    @property
    @pulumi.getter
    def region(self) -> Optional[str]:
        return pulumi.get(self, "region")


@pulumi.output_type
class GetJobJobSettingsSettingsNewClusterInitScriptVolumesResult(dict):
    def __init__(__self__, *,
                 destination: str):
        pulumi.set(__self__, "destination", destination)

    @property
    @pulumi.getter
    def destination(self) -> str:
        return pulumi.get(self, "destination")


@pulumi.output_type
class GetJobJobSettingsSettingsNewClusterInitScriptWorkspaceResult(dict):
    def __init__(__self__, *,
                 destination: str):
        pulumi.set(__self__, "destination", destination)

    @property
    @pulumi.getter
    def destination(self) -> str:
        return pulumi.get(self, "destination")


@pulumi.output_type
class GetJobJobSettingsSettingsNewClusterWorkloadTypeResult(dict):
    def __init__(__self__, *,
                 clients: 'outputs.GetJobJobSettingsSettingsNewClusterWorkloadTypeClientsResult'):
        pulumi.set(__self__, "clients", clients)

    @property
    @pulumi.getter
    def clients(self) -> 'outputs.GetJobJobSettingsSettingsNewClusterWorkloadTypeClientsResult':
        return pulumi.get(self, "clients")


@pulumi.output_type
class GetJobJobSettingsSettingsNewClusterWorkloadTypeClientsResult(dict):
    def __init__(__self__, *,
                 jobs: Optional[bool] = None,
                 notebooks: Optional[bool] = None):
        if jobs is not None:
            pulumi.set(__self__, "jobs", jobs)
        if notebooks is not None:
            pulumi.set(__self__, "notebooks", notebooks)

    @property
    @pulumi.getter
    def jobs(self) -> Optional[bool]:
        return pulumi.get(self, "jobs")

    @property
    @pulumi.getter
    def notebooks(self) -> Optional[bool]:
        return pulumi.get(self, "notebooks")


@pulumi.output_type
class GetJobJobSettingsSettingsNotebookTaskResult(dict):
    def __init__(__self__, *,
                 notebook_path: str,
                 base_parameters: Optional[Mapping[str, str]] = None,
                 source: Optional[str] = None,
                 warehouse_id: Optional[str] = None):
        pulumi.set(__self__, "notebook_path", notebook_path)
        if base_parameters is not None:
            pulumi.set(__self__, "base_parameters", base_parameters)
        if source is not None:
            pulumi.set(__self__, "source", source)
        if warehouse_id is not None:
            pulumi.set(__self__, "warehouse_id", warehouse_id)

    @property
    @pulumi.getter(name="notebookPath")
    def notebook_path(self) -> str:
        return pulumi.get(self, "notebook_path")

    @property
    @pulumi.getter(name="baseParameters")
    def base_parameters(self) -> Optional[Mapping[str, str]]:
        return pulumi.get(self, "base_parameters")

    @property
    @pulumi.getter
    def source(self) -> Optional[str]:
        return pulumi.get(self, "source")

    @property
    @pulumi.getter(name="warehouseId")
    def warehouse_id(self) -> Optional[str]:
        return pulumi.get(self, "warehouse_id")


@pulumi.output_type
class GetJobJobSettingsSettingsNotificationSettingsResult(dict):
    def __init__(__self__, *,
                 no_alert_for_canceled_runs: Optional[bool] = None,
                 no_alert_for_skipped_runs: Optional[bool] = None):
        if no_alert_for_canceled_runs is not None:
            pulumi.set(__self__, "no_alert_for_canceled_runs", no_alert_for_canceled_runs)
        if no_alert_for_skipped_runs is not None:
            pulumi.set(__self__, "no_alert_for_skipped_runs", no_alert_for_skipped_runs)

    @property
    @pulumi.getter(name="noAlertForCanceledRuns")
    def no_alert_for_canceled_runs(self) -> Optional[bool]:
        return pulumi.get(self, "no_alert_for_canceled_runs")

    @property
    @pulumi.getter(name="noAlertForSkippedRuns")
    def no_alert_for_skipped_runs(self) -> Optional[bool]:
        return pulumi.get(self, "no_alert_for_skipped_runs")


@pulumi.output_type
class GetJobJobSettingsSettingsParameterResult(dict):
    def __init__(__self__, *,
                 default: str,
                 name: str):
        """
        :param str name: the job name of Job if the resource was matched by id.
        """
        pulumi.set(__self__, "default", default)
        pulumi.set(__self__, "name", name)

    @property
    @pulumi.getter
    def default(self) -> str:
        return pulumi.get(self, "default")

    @property
    @pulumi.getter
    def name(self) -> str:
        """
        the job name of Job if the resource was matched by id.
        """
        return pulumi.get(self, "name")


@pulumi.output_type
class GetJobJobSettingsSettingsPipelineTaskResult(dict):
    def __init__(__self__, *,
                 pipeline_id: str,
                 full_refresh: Optional[bool] = None):
        pulumi.set(__self__, "pipeline_id", pipeline_id)
        if full_refresh is not None:
            pulumi.set(__self__, "full_refresh", full_refresh)

    @property
    @pulumi.getter(name="pipelineId")
    def pipeline_id(self) -> str:
        return pulumi.get(self, "pipeline_id")

    @property
    @pulumi.getter(name="fullRefresh")
    def full_refresh(self) -> Optional[bool]:
        return pulumi.get(self, "full_refresh")


@pulumi.output_type
class GetJobJobSettingsSettingsPythonWheelTaskResult(dict):
    def __init__(__self__, *,
                 entry_point: Optional[str] = None,
                 named_parameters: Optional[Mapping[str, str]] = None,
                 package_name: Optional[str] = None,
                 parameters: Optional[Sequence[str]] = None):
        if entry_point is not None:
            pulumi.set(__self__, "entry_point", entry_point)
        if named_parameters is not None:
            pulumi.set(__self__, "named_parameters", named_parameters)
        if package_name is not None:
            pulumi.set(__self__, "package_name", package_name)
        if parameters is not None:
            pulumi.set(__self__, "parameters", parameters)

    @property
    @pulumi.getter(name="entryPoint")
    def entry_point(self) -> Optional[str]:
        return pulumi.get(self, "entry_point")

    @property
    @pulumi.getter(name="namedParameters")
    def named_parameters(self) -> Optional[Mapping[str, str]]:
        return pulumi.get(self, "named_parameters")

    @property
    @pulumi.getter(name="packageName")
    def package_name(self) -> Optional[str]:
        return pulumi.get(self, "package_name")

    @property
    @pulumi.getter
    def parameters(self) -> Optional[Sequence[str]]:
        return pulumi.get(self, "parameters")


@pulumi.output_type
class GetJobJobSettingsSettingsQueueResult(dict):
    def __init__(__self__, *,
                 enabled: bool):
        pulumi.set(__self__, "enabled", enabled)

    @property
    @pulumi.getter
    def enabled(self) -> bool:
        return pulumi.get(self, "enabled")


@pulumi.output_type
class GetJobJobSettingsSettingsRunAsResult(dict):
    def __init__(__self__, *,
                 service_principal_name: Optional[str] = None,
                 user_name: Optional[str] = None):
        if service_principal_name is not None:
            pulumi.set(__self__, "service_principal_name", service_principal_name)
        if user_name is not None:
            pulumi.set(__self__, "user_name", user_name)

    @property
    @pulumi.getter(name="servicePrincipalName")
    def service_principal_name(self) -> Optional[str]:
        return pulumi.get(self, "service_principal_name")

    @property
    @pulumi.getter(name="userName")
    def user_name(self) -> Optional[str]:
        return pulumi.get(self, "user_name")


@pulumi.output_type
class GetJobJobSettingsSettingsRunJobTaskResult(dict):
    def __init__(__self__, *,
                 job_id: int,
                 job_parameters: Optional[Mapping[str, str]] = None):
        pulumi.set(__self__, "job_id", job_id)
        if job_parameters is not None:
            pulumi.set(__self__, "job_parameters", job_parameters)

    @property
    @pulumi.getter(name="jobId")
    def job_id(self) -> int:
        return pulumi.get(self, "job_id")

    @property
    @pulumi.getter(name="jobParameters")
    def job_parameters(self) -> Optional[Mapping[str, str]]:
        return pulumi.get(self, "job_parameters")


@pulumi.output_type
class GetJobJobSettingsSettingsScheduleResult(dict):
    def __init__(__self__, *,
                 quartz_cron_expression: str,
                 timezone_id: str,
                 pause_status: Optional[str] = None):
        pulumi.set(__self__, "quartz_cron_expression", quartz_cron_expression)
        pulumi.set(__self__, "timezone_id", timezone_id)
        if pause_status is not None:
            pulumi.set(__self__, "pause_status", pause_status)

    @property
    @pulumi.getter(name="quartzCronExpression")
    def quartz_cron_expression(self) -> str:
        return pulumi.get(self, "quartz_cron_expression")

    @property
    @pulumi.getter(name="timezoneId")
    def timezone_id(self) -> str:
        return pulumi.get(self, "timezone_id")

    @property
    @pulumi.getter(name="pauseStatus")
    def pause_status(self) -> Optional[str]:
        return pulumi.get(self, "pause_status")


@pulumi.output_type
class GetJobJobSettingsSettingsSparkJarTaskResult(dict):
    def __init__(__self__, *,
                 jar_uri: Optional[str] = None,
                 main_class_name: Optional[str] = None,
                 parameters: Optional[Sequence[str]] = None):
        if jar_uri is not None:
            pulumi.set(__self__, "jar_uri", jar_uri)
        if main_class_name is not None:
            pulumi.set(__self__, "main_class_name", main_class_name)
        if parameters is not None:
            pulumi.set(__self__, "parameters", parameters)

    @property
    @pulumi.getter(name="jarUri")
    def jar_uri(self) -> Optional[str]:
        return pulumi.get(self, "jar_uri")

    @property
    @pulumi.getter(name="mainClassName")
    def main_class_name(self) -> Optional[str]:
        return pulumi.get(self, "main_class_name")

    @property
    @pulumi.getter
    def parameters(self) -> Optional[Sequence[str]]:
        return pulumi.get(self, "parameters")


@pulumi.output_type
class GetJobJobSettingsSettingsSparkPythonTaskResult(dict):
    def __init__(__self__, *,
                 python_file: str,
                 parameters: Optional[Sequence[str]] = None,
                 source: Optional[str] = None):
        pulumi.set(__self__, "python_file", python_file)
        if parameters is not None:
            pulumi.set(__self__, "parameters", parameters)
        if source is not None:
            pulumi.set(__self__, "source", source)

    @property
    @pulumi.getter(name="pythonFile")
    def python_file(self) -> str:
        return pulumi.get(self, "python_file")

    @property
    @pulumi.getter
    def parameters(self) -> Optional[Sequence[str]]:
        return pulumi.get(self, "parameters")

    @property
    @pulumi.getter
    def source(self) -> Optional[str]:
        return pulumi.get(self, "source")


@pulumi.output_type
class GetJobJobSettingsSettingsSparkSubmitTaskResult(dict):
    def __init__(__self__, *,
                 parameters: Optional[Sequence[str]] = None):
        if parameters is not None:
            pulumi.set(__self__, "parameters", parameters)

    @property
    @pulumi.getter
    def parameters(self) -> Optional[Sequence[str]]:
        return pulumi.get(self, "parameters")


@pulumi.output_type
class GetJobJobSettingsSettingsTaskResult(dict):
    def __init__(__self__, *,
                 retry_on_timeout: bool,
                 task_key: str,
                 condition_task: Optional['outputs.GetJobJobSettingsSettingsTaskConditionTaskResult'] = None,
                 dbt_task: Optional['outputs.GetJobJobSettingsSettingsTaskDbtTaskResult'] = None,
                 depends_ons: Optional[Sequence['outputs.GetJobJobSettingsSettingsTaskDependsOnResult']] = None,
                 description: Optional[str] = None,
                 email_notifications: Optional['outputs.GetJobJobSettingsSettingsTaskEmailNotificationsResult'] = None,
                 environment_key: Optional[str] = None,
                 existing_cluster_id: Optional[str] = None,
                 for_each_task: Optional['outputs.GetJobJobSettingsSettingsTaskForEachTaskResult'] = None,
                 health: Optional['outputs.GetJobJobSettingsSettingsTaskHealthResult'] = None,
                 job_cluster_key: Optional[str] = None,
                 libraries: Optional[Sequence['outputs.GetJobJobSettingsSettingsTaskLibraryResult']] = None,
                 max_retries: Optional[int] = None,
                 min_retry_interval_millis: Optional[int] = None,
                 new_cluster: Optional['outputs.GetJobJobSettingsSettingsTaskNewClusterResult'] = None,
                 notebook_task: Optional['outputs.GetJobJobSettingsSettingsTaskNotebookTaskResult'] = None,
                 notification_settings: Optional['outputs.GetJobJobSettingsSettingsTaskNotificationSettingsResult'] = None,
                 pipeline_task: Optional['outputs.GetJobJobSettingsSettingsTaskPipelineTaskResult'] = None,
                 python_wheel_task: Optional['outputs.GetJobJobSettingsSettingsTaskPythonWheelTaskResult'] = None,
                 run_if: Optional[str] = None,
                 run_job_task: Optional['outputs.GetJobJobSettingsSettingsTaskRunJobTaskResult'] = None,
                 spark_jar_task: Optional['outputs.GetJobJobSettingsSettingsTaskSparkJarTaskResult'] = None,
                 spark_python_task: Optional['outputs.GetJobJobSettingsSettingsTaskSparkPythonTaskResult'] = None,
                 spark_submit_task: Optional['outputs.GetJobJobSettingsSettingsTaskSparkSubmitTaskResult'] = None,
                 sql_task: Optional['outputs.GetJobJobSettingsSettingsTaskSqlTaskResult'] = None,
                 timeout_seconds: Optional[int] = None,
                 webhook_notifications: Optional['outputs.GetJobJobSettingsSettingsTaskWebhookNotificationsResult'] = None):
        pulumi.set(__self__, "retry_on_timeout", retry_on_timeout)
        pulumi.set(__self__, "task_key", task_key)
        if condition_task is not None:
            pulumi.set(__self__, "condition_task", condition_task)
        if dbt_task is not None:
            pulumi.set(__self__, "dbt_task", dbt_task)
        if depends_ons is not None:
            pulumi.set(__self__, "depends_ons", depends_ons)
        if description is not None:
            pulumi.set(__self__, "description", description)
        if email_notifications is not None:
            pulumi.set(__self__, "email_notifications", email_notifications)
        if environment_key is not None:
            pulumi.set(__self__, "environment_key", environment_key)
        if existing_cluster_id is not None:
            pulumi.set(__self__, "existing_cluster_id", existing_cluster_id)
        if for_each_task is not None:
            pulumi.set(__self__, "for_each_task", for_each_task)
        if health is not None:
            pulumi.set(__self__, "health", health)
        if job_cluster_key is not None:
            pulumi.set(__self__, "job_cluster_key", job_cluster_key)
        if libraries is not None:
            pulumi.set(__self__, "libraries", libraries)
        if max_retries is not None:
            pulumi.set(__self__, "max_retries", max_retries)
        if min_retry_interval_millis is not None:
            pulumi.set(__self__, "min_retry_interval_millis", min_retry_interval_millis)
        if new_cluster is not None:
            pulumi.set(__self__, "new_cluster", new_cluster)
        if notebook_task is not None:
            pulumi.set(__self__, "notebook_task", notebook_task)
        if notification_settings is not None:
            pulumi.set(__self__, "notification_settings", notification_settings)
        if pipeline_task is not None:
            pulumi.set(__self__, "pipeline_task", pipeline_task)
        if python_wheel_task is not None:
            pulumi.set(__self__, "python_wheel_task", python_wheel_task)
        if run_if is not None:
            pulumi.set(__self__, "run_if", run_if)
        if run_job_task is not None:
            pulumi.set(__self__, "run_job_task", run_job_task)
        if spark_jar_task is not None:
            pulumi.set(__self__, "spark_jar_task", spark_jar_task)
        if spark_python_task is not None:
            pulumi.set(__self__, "spark_python_task", spark_python_task)
        if spark_submit_task is not None:
            pulumi.set(__self__, "spark_submit_task", spark_submit_task)
        if sql_task is not None:
            pulumi.set(__self__, "sql_task", sql_task)
        if timeout_seconds is not None:
            pulumi.set(__self__, "timeout_seconds", timeout_seconds)
        if webhook_notifications is not None:
            pulumi.set(__self__, "webhook_notifications", webhook_notifications)

    @property
    @pulumi.getter(name="retryOnTimeout")
    def retry_on_timeout(self) -> bool:
        return pulumi.get(self, "retry_on_timeout")

    @property
    @pulumi.getter(name="taskKey")
    def task_key(self) -> str:
        return pulumi.get(self, "task_key")

    @property
    @pulumi.getter(name="conditionTask")
    def condition_task(self) -> Optional['outputs.GetJobJobSettingsSettingsTaskConditionTaskResult']:
        return pulumi.get(self, "condition_task")

    @property
    @pulumi.getter(name="dbtTask")
    def dbt_task(self) -> Optional['outputs.GetJobJobSettingsSettingsTaskDbtTaskResult']:
        return pulumi.get(self, "dbt_task")

    @property
    @pulumi.getter(name="dependsOns")
    def depends_ons(self) -> Optional[Sequence['outputs.GetJobJobSettingsSettingsTaskDependsOnResult']]:
        return pulumi.get(self, "depends_ons")

    @property
    @pulumi.getter
    def description(self) -> Optional[str]:
        return pulumi.get(self, "description")

    @property
    @pulumi.getter(name="emailNotifications")
    def email_notifications(self) -> Optional['outputs.GetJobJobSettingsSettingsTaskEmailNotificationsResult']:
        return pulumi.get(self, "email_notifications")

    @property
    @pulumi.getter(name="environmentKey")
    def environment_key(self) -> Optional[str]:
        return pulumi.get(self, "environment_key")

    @property
    @pulumi.getter(name="existingClusterId")
    def existing_cluster_id(self) -> Optional[str]:
        return pulumi.get(self, "existing_cluster_id")

    @property
    @pulumi.getter(name="forEachTask")
    def for_each_task(self) -> Optional['outputs.GetJobJobSettingsSettingsTaskForEachTaskResult']:
        return pulumi.get(self, "for_each_task")

    @property
    @pulumi.getter
    def health(self) -> Optional['outputs.GetJobJobSettingsSettingsTaskHealthResult']:
        return pulumi.get(self, "health")

    @property
    @pulumi.getter(name="jobClusterKey")
    def job_cluster_key(self) -> Optional[str]:
        return pulumi.get(self, "job_cluster_key")

    @property
    @pulumi.getter
    def libraries(self) -> Optional[Sequence['outputs.GetJobJobSettingsSettingsTaskLibraryResult']]:
        return pulumi.get(self, "libraries")

    @property
    @pulumi.getter(name="maxRetries")
    def max_retries(self) -> Optional[int]:
        return pulumi.get(self, "max_retries")

    @property
    @pulumi.getter(name="minRetryIntervalMillis")
    def min_retry_interval_millis(self) -> Optional[int]:
        return pulumi.get(self, "min_retry_interval_millis")

    @property
    @pulumi.getter(name="newCluster")
    def new_cluster(self) -> Optional['outputs.GetJobJobSettingsSettingsTaskNewClusterResult']:
        return pulumi.get(self, "new_cluster")

    @property
    @pulumi.getter(name="notebookTask")
    def notebook_task(self) -> Optional['outputs.GetJobJobSettingsSettingsTaskNotebookTaskResult']:
        return pulumi.get(self, "notebook_task")

    @property
    @pulumi.getter(name="notificationSettings")
    def notification_settings(self) -> Optional['outputs.GetJobJobSettingsSettingsTaskNotificationSettingsResult']:
        return pulumi.get(self, "notification_settings")

    @property
    @pulumi.getter(name="pipelineTask")
    def pipeline_task(self) -> Optional['outputs.GetJobJobSettingsSettingsTaskPipelineTaskResult']:
        return pulumi.get(self, "pipeline_task")

    @property
    @pulumi.getter(name="pythonWheelTask")
    def python_wheel_task(self) -> Optional['outputs.GetJobJobSettingsSettingsTaskPythonWheelTaskResult']:
        return pulumi.get(self, "python_wheel_task")

    @property
    @pulumi.getter(name="runIf")
    def run_if(self) -> Optional[str]:
        return pulumi.get(self, "run_if")

    @property
    @pulumi.getter(name="runJobTask")
    def run_job_task(self) -> Optional['outputs.GetJobJobSettingsSettingsTaskRunJobTaskResult']:
        return pulumi.get(self, "run_job_task")

    @property
    @pulumi.getter(name="sparkJarTask")
    def spark_jar_task(self) -> Optional['outputs.GetJobJobSettingsSettingsTaskSparkJarTaskResult']:
        return pulumi.get(self, "spark_jar_task")

    @property
    @pulumi.getter(name="sparkPythonTask")
    def spark_python_task(self) -> Optional['outputs.GetJobJobSettingsSettingsTaskSparkPythonTaskResult']:
        return pulumi.get(self, "spark_python_task")

    @property
    @pulumi.getter(name="sparkSubmitTask")
    def spark_submit_task(self) -> Optional['outputs.GetJobJobSettingsSettingsTaskSparkSubmitTaskResult']:
        return pulumi.get(self, "spark_submit_task")

    @property
    @pulumi.getter(name="sqlTask")
    def sql_task(self) -> Optional['outputs.GetJobJobSettingsSettingsTaskSqlTaskResult']:
        return pulumi.get(self, "sql_task")

    @property
    @pulumi.getter(name="timeoutSeconds")
    def timeout_seconds(self) -> Optional[int]:
        return pulumi.get(self, "timeout_seconds")

    @property
    @pulumi.getter(name="webhookNotifications")
    def webhook_notifications(self) -> Optional['outputs.GetJobJobSettingsSettingsTaskWebhookNotificationsResult']:
        return pulumi.get(self, "webhook_notifications")


@pulumi.output_type
class GetJobJobSettingsSettingsTaskConditionTaskResult(dict):
    def __init__(__self__, *,
                 left: str,
                 op: str,
                 right: str):
        pulumi.set(__self__, "left", left)
        pulumi.set(__self__, "op", op)
        pulumi.set(__self__, "right", right)

    @property
    @pulumi.getter
    def left(self) -> str:
        return pulumi.get(self, "left")

    @property
    @pulumi.getter
    def op(self) -> str:
        return pulumi.get(self, "op")

    @property
    @pulumi.getter
    def right(self) -> str:
        return pulumi.get(self, "right")


@pulumi.output_type
class GetJobJobSettingsSettingsTaskDbtTaskResult(dict):
    def __init__(__self__, *,
                 commands: Sequence[str],
                 catalog: Optional[str] = None,
                 profiles_directory: Optional[str] = None,
                 project_directory: Optional[str] = None,
                 schema: Optional[str] = None,
                 source: Optional[str] = None,
                 warehouse_id: Optional[str] = None):
        pulumi.set(__self__, "commands", commands)
        if catalog is not None:
            pulumi.set(__self__, "catalog", catalog)
        if profiles_directory is not None:
            pulumi.set(__self__, "profiles_directory", profiles_directory)
        if project_directory is not None:
            pulumi.set(__self__, "project_directory", project_directory)
        if schema is not None:
            pulumi.set(__self__, "schema", schema)
        if source is not None:
            pulumi.set(__self__, "source", source)
        if warehouse_id is not None:
            pulumi.set(__self__, "warehouse_id", warehouse_id)

    @property
    @pulumi.getter
    def commands(self) -> Sequence[str]:
        return pulumi.get(self, "commands")

    @property
    @pulumi.getter
    def catalog(self) -> Optional[str]:
        return pulumi.get(self, "catalog")

    @property
    @pulumi.getter(name="profilesDirectory")
    def profiles_directory(self) -> Optional[str]:
        return pulumi.get(self, "profiles_directory")

    @property
    @pulumi.getter(name="projectDirectory")
    def project_directory(self) -> Optional[str]:
        return pulumi.get(self, "project_directory")

    @property
    @pulumi.getter
    def schema(self) -> Optional[str]:
        return pulumi.get(self, "schema")

    @property
    @pulumi.getter
    def source(self) -> Optional[str]:
        return pulumi.get(self, "source")

    @property
    @pulumi.getter(name="warehouseId")
    def warehouse_id(self) -> Optional[str]:
        return pulumi.get(self, "warehouse_id")


@pulumi.output_type
class GetJobJobSettingsSettingsTaskDependsOnResult(dict):
    def __init__(__self__, *,
                 task_key: str,
                 outcome: Optional[str] = None):
        pulumi.set(__self__, "task_key", task_key)
        if outcome is not None:
            pulumi.set(__self__, "outcome", outcome)

    @property
    @pulumi.getter(name="taskKey")
    def task_key(self) -> str:
        return pulumi.get(self, "task_key")

    @property
    @pulumi.getter
    def outcome(self) -> Optional[str]:
        return pulumi.get(self, "outcome")


@pulumi.output_type
class GetJobJobSettingsSettingsTaskEmailNotificationsResult(dict):
    def __init__(__self__, *,
                 no_alert_for_skipped_runs: Optional[bool] = None,
                 on_duration_warning_threshold_exceededs: Optional[Sequence[str]] = None,
                 on_failures: Optional[Sequence[str]] = None,
                 on_starts: Optional[Sequence[str]] = None,
                 on_streaming_backlog_exceededs: Optional[Sequence[str]] = None,
                 on_successes: Optional[Sequence[str]] = None):
        if no_alert_for_skipped_runs is not None:
            pulumi.set(__self__, "no_alert_for_skipped_runs", no_alert_for_skipped_runs)
        if on_duration_warning_threshold_exceededs is not None:
            pulumi.set(__self__, "on_duration_warning_threshold_exceededs", on_duration_warning_threshold_exceededs)
        if on_failures is not None:
            pulumi.set(__self__, "on_failures", on_failures)
        if on_starts is not None:
            pulumi.set(__self__, "on_starts", on_starts)
        if on_streaming_backlog_exceededs is not None:
            pulumi.set(__self__, "on_streaming_backlog_exceededs", on_streaming_backlog_exceededs)
        if on_successes is not None:
            pulumi.set(__self__, "on_successes", on_successes)

    @property
    @pulumi.getter(name="noAlertForSkippedRuns")
    def no_alert_for_skipped_runs(self) -> Optional[bool]:
        return pulumi.get(self, "no_alert_for_skipped_runs")

    @property
    @pulumi.getter(name="onDurationWarningThresholdExceededs")
    def on_duration_warning_threshold_exceededs(self) -> Optional[Sequence[str]]:
        return pulumi.get(self, "on_duration_warning_threshold_exceededs")

    @property
    @pulumi.getter(name="onFailures")
    def on_failures(self) -> Optional[Sequence[str]]:
        return pulumi.get(self, "on_failures")

    @property
    @pulumi.getter(name="onStarts")
    def on_starts(self) -> Optional[Sequence[str]]:
        return pulumi.get(self, "on_starts")

    @property
    @pulumi.getter(name="onStreamingBacklogExceededs")
    def on_streaming_backlog_exceededs(self) -> Optional[Sequence[str]]:
        return pulumi.get(self, "on_streaming_backlog_exceededs")

    @property
    @pulumi.getter(name="onSuccesses")
    def on_successes(self) -> Optional[Sequence[str]]:
        return pulumi.get(self, "on_successes")


@pulumi.output_type
class GetJobJobSettingsSettingsTaskForEachTaskResult(dict):
    def __init__(__self__, *,
                 inputs: str,
                 task: 'outputs.GetJobJobSettingsSettingsTaskForEachTaskTaskResult',
                 concurrency: Optional[int] = None):
        pulumi.set(__self__, "inputs", inputs)
        pulumi.set(__self__, "task", task)
        if concurrency is not None:
            pulumi.set(__self__, "concurrency", concurrency)

    @property
    @pulumi.getter
    def inputs(self) -> str:
        return pulumi.get(self, "inputs")

    @property
    @pulumi.getter
    def task(self) -> 'outputs.GetJobJobSettingsSettingsTaskForEachTaskTaskResult':
        return pulumi.get(self, "task")

    @property
    @pulumi.getter
    def concurrency(self) -> Optional[int]:
        return pulumi.get(self, "concurrency")


@pulumi.output_type
class GetJobJobSettingsSettingsTaskForEachTaskTaskResult(dict):
    def __init__(__self__, *,
                 retry_on_timeout: bool,
                 task_key: str,
                 condition_task: Optional['outputs.GetJobJobSettingsSettingsTaskForEachTaskTaskConditionTaskResult'] = None,
                 dbt_task: Optional['outputs.GetJobJobSettingsSettingsTaskForEachTaskTaskDbtTaskResult'] = None,
                 depends_ons: Optional[Sequence['outputs.GetJobJobSettingsSettingsTaskForEachTaskTaskDependsOnResult']] = None,
                 description: Optional[str] = None,
                 email_notifications: Optional['outputs.GetJobJobSettingsSettingsTaskForEachTaskTaskEmailNotificationsResult'] = None,
                 environment_key: Optional[str] = None,
                 existing_cluster_id: Optional[str] = None,
                 health: Optional['outputs.GetJobJobSettingsSettingsTaskForEachTaskTaskHealthResult'] = None,
                 job_cluster_key: Optional[str] = None,
                 libraries: Optional[Sequence['outputs.GetJobJobSettingsSettingsTaskForEachTaskTaskLibraryResult']] = None,
                 max_retries: Optional[int] = None,
                 min_retry_interval_millis: Optional[int] = None,
                 new_cluster: Optional['outputs.GetJobJobSettingsSettingsTaskForEachTaskTaskNewClusterResult'] = None,
                 notebook_task: Optional['outputs.GetJobJobSettingsSettingsTaskForEachTaskTaskNotebookTaskResult'] = None,
                 notification_settings: Optional['outputs.GetJobJobSettingsSettingsTaskForEachTaskTaskNotificationSettingsResult'] = None,
                 pipeline_task: Optional['outputs.GetJobJobSettingsSettingsTaskForEachTaskTaskPipelineTaskResult'] = None,
                 python_wheel_task: Optional['outputs.GetJobJobSettingsSettingsTaskForEachTaskTaskPythonWheelTaskResult'] = None,
                 run_if: Optional[str] = None,
                 run_job_task: Optional['outputs.GetJobJobSettingsSettingsTaskForEachTaskTaskRunJobTaskResult'] = None,
                 spark_jar_task: Optional['outputs.GetJobJobSettingsSettingsTaskForEachTaskTaskSparkJarTaskResult'] = None,
                 spark_python_task: Optional['outputs.GetJobJobSettingsSettingsTaskForEachTaskTaskSparkPythonTaskResult'] = None,
                 spark_submit_task: Optional['outputs.GetJobJobSettingsSettingsTaskForEachTaskTaskSparkSubmitTaskResult'] = None,
                 sql_task: Optional['outputs.GetJobJobSettingsSettingsTaskForEachTaskTaskSqlTaskResult'] = None,
                 timeout_seconds: Optional[int] = None,
                 webhook_notifications: Optional['outputs.GetJobJobSettingsSettingsTaskForEachTaskTaskWebhookNotificationsResult'] = None):
        pulumi.set(__self__, "retry_on_timeout", retry_on_timeout)
        pulumi.set(__self__, "task_key", task_key)
        if condition_task is not None:
            pulumi.set(__self__, "condition_task", condition_task)
        if dbt_task is not None:
            pulumi.set(__self__, "dbt_task", dbt_task)
        if depends_ons is not None:
            pulumi.set(__self__, "depends_ons", depends_ons)
        if description is not None:
            pulumi.set(__self__, "description", description)
        if email_notifications is not None:
            pulumi.set(__self__, "email_notifications", email_notifications)
        if environment_key is not None:
            pulumi.set(__self__, "environment_key", environment_key)
        if existing_cluster_id is not None:
            pulumi.set(__self__, "existing_cluster_id", existing_cluster_id)
        if health is not None:
            pulumi.set(__self__, "health", health)
        if job_cluster_key is not None:
            pulumi.set(__self__, "job_cluster_key", job_cluster_key)
        if libraries is not None:
            pulumi.set(__self__, "libraries", libraries)
        if max_retries is not None:
            pulumi.set(__self__, "max_retries", max_retries)
        if min_retry_interval_millis is not None:
            pulumi.set(__self__, "min_retry_interval_millis", min_retry_interval_millis)
        if new_cluster is not None:
            pulumi.set(__self__, "new_cluster", new_cluster)
        if notebook_task is not None:
            pulumi.set(__self__, "notebook_task", notebook_task)
        if notification_settings is not None:
            pulumi.set(__self__, "notification_settings", notification_settings)
        if pipeline_task is not None:
            pulumi.set(__self__, "pipeline_task", pipeline_task)
        if python_wheel_task is not None:
            pulumi.set(__self__, "python_wheel_task", python_wheel_task)
        if run_if is not None:
            pulumi.set(__self__, "run_if", run_if)
        if run_job_task is not None:
            pulumi.set(__self__, "run_job_task", run_job_task)
        if spark_jar_task is not None:
            pulumi.set(__self__, "spark_jar_task", spark_jar_task)
        if spark_python_task is not None:
            pulumi.set(__self__, "spark_python_task", spark_python_task)
        if spark_submit_task is not None:
            pulumi.set(__self__, "spark_submit_task", spark_submit_task)
        if sql_task is not None:
            pulumi.set(__self__, "sql_task", sql_task)
        if timeout_seconds is not None:
            pulumi.set(__self__, "timeout_seconds", timeout_seconds)
        if webhook_notifications is not None:
            pulumi.set(__self__, "webhook_notifications", webhook_notifications)

    @property
    @pulumi.getter(name="retryOnTimeout")
    def retry_on_timeout(self) -> bool:
        return pulumi.get(self, "retry_on_timeout")

    @property
    @pulumi.getter(name="taskKey")
    def task_key(self) -> str:
        return pulumi.get(self, "task_key")

    @property
    @pulumi.getter(name="conditionTask")
    def condition_task(self) -> Optional['outputs.GetJobJobSettingsSettingsTaskForEachTaskTaskConditionTaskResult']:
        return pulumi.get(self, "condition_task")

    @property
    @pulumi.getter(name="dbtTask")
    def dbt_task(self) -> Optional['outputs.GetJobJobSettingsSettingsTaskForEachTaskTaskDbtTaskResult']:
        return pulumi.get(self, "dbt_task")

    @property
    @pulumi.getter(name="dependsOns")
    def depends_ons(self) -> Optional[Sequence['outputs.GetJobJobSettingsSettingsTaskForEachTaskTaskDependsOnResult']]:
        return pulumi.get(self, "depends_ons")

    @property
    @pulumi.getter
    def description(self) -> Optional[str]:
        return pulumi.get(self, "description")

    @property
    @pulumi.getter(name="emailNotifications")
    def email_notifications(self) -> Optional['outputs.GetJobJobSettingsSettingsTaskForEachTaskTaskEmailNotificationsResult']:
        return pulumi.get(self, "email_notifications")

    @property
    @pulumi.getter(name="environmentKey")
    def environment_key(self) -> Optional[str]:
        return pulumi.get(self, "environment_key")

    @property
    @pulumi.getter(name="existingClusterId")
    def existing_cluster_id(self) -> Optional[str]:
        return pulumi.get(self, "existing_cluster_id")

    @property
    @pulumi.getter
    def health(self) -> Optional['outputs.GetJobJobSettingsSettingsTaskForEachTaskTaskHealthResult']:
        return pulumi.get(self, "health")

    @property
    @pulumi.getter(name="jobClusterKey")
    def job_cluster_key(self) -> Optional[str]:
        return pulumi.get(self, "job_cluster_key")

    @property
    @pulumi.getter
    def libraries(self) -> Optional[Sequence['outputs.GetJobJobSettingsSettingsTaskForEachTaskTaskLibraryResult']]:
        return pulumi.get(self, "libraries")

    @property
    @pulumi.getter(name="maxRetries")
    def max_retries(self) -> Optional[int]:
        return pulumi.get(self, "max_retries")

    @property
    @pulumi.getter(name="minRetryIntervalMillis")
    def min_retry_interval_millis(self) -> Optional[int]:
        return pulumi.get(self, "min_retry_interval_millis")

    @property
    @pulumi.getter(name="newCluster")
    def new_cluster(self) -> Optional['outputs.GetJobJobSettingsSettingsTaskForEachTaskTaskNewClusterResult']:
        return pulumi.get(self, "new_cluster")

    @property
    @pulumi.getter(name="notebookTask")
    def notebook_task(self) -> Optional['outputs.GetJobJobSettingsSettingsTaskForEachTaskTaskNotebookTaskResult']:
        return pulumi.get(self, "notebook_task")

    @property
    @pulumi.getter(name="notificationSettings")
    def notification_settings(self) -> Optional['outputs.GetJobJobSettingsSettingsTaskForEachTaskTaskNotificationSettingsResult']:
        return pulumi.get(self, "notification_settings")

    @property
    @pulumi.getter(name="pipelineTask")
    def pipeline_task(self) -> Optional['outputs.GetJobJobSettingsSettingsTaskForEachTaskTaskPipelineTaskResult']:
        return pulumi.get(self, "pipeline_task")

    @property
    @pulumi.getter(name="pythonWheelTask")
    def python_wheel_task(self) -> Optional['outputs.GetJobJobSettingsSettingsTaskForEachTaskTaskPythonWheelTaskResult']:
        return pulumi.get(self, "python_wheel_task")

    @property
    @pulumi.getter(name="runIf")
    def run_if(self) -> Optional[str]:
        return pulumi.get(self, "run_if")

    @property
    @pulumi.getter(name="runJobTask")
    def run_job_task(self) -> Optional['outputs.GetJobJobSettingsSettingsTaskForEachTaskTaskRunJobTaskResult']:
        return pulumi.get(self, "run_job_task")

    @property
    @pulumi.getter(name="sparkJarTask")
    def spark_jar_task(self) -> Optional['outputs.GetJobJobSettingsSettingsTaskForEachTaskTaskSparkJarTaskResult']:
        return pulumi.get(self, "spark_jar_task")

    @property
    @pulumi.getter(name="sparkPythonTask")
    def spark_python_task(self) -> Optional['outputs.GetJobJobSettingsSettingsTaskForEachTaskTaskSparkPythonTaskResult']:
        return pulumi.get(self, "spark_python_task")

    @property
    @pulumi.getter(name="sparkSubmitTask")
    def spark_submit_task(self) -> Optional['outputs.GetJobJobSettingsSettingsTaskForEachTaskTaskSparkSubmitTaskResult']:
        return pulumi.get(self, "spark_submit_task")

    @property
    @pulumi.getter(name="sqlTask")
    def sql_task(self) -> Optional['outputs.GetJobJobSettingsSettingsTaskForEachTaskTaskSqlTaskResult']:
        return pulumi.get(self, "sql_task")

    @property
    @pulumi.getter(name="timeoutSeconds")
    def timeout_seconds(self) -> Optional[int]:
        return pulumi.get(self, "timeout_seconds")

    @property
    @pulumi.getter(name="webhookNotifications")
    def webhook_notifications(self) -> Optional['outputs.GetJobJobSettingsSettingsTaskForEachTaskTaskWebhookNotificationsResult']:
        return pulumi.get(self, "webhook_notifications")


@pulumi.output_type
class GetJobJobSettingsSettingsTaskForEachTaskTaskConditionTaskResult(dict):
    def __init__(__self__, *,
                 left: str,
                 op: str,
                 right: str):
        pulumi.set(__self__, "left", left)
        pulumi.set(__self__, "op", op)
        pulumi.set(__self__, "right", right)

    @property
    @pulumi.getter
    def left(self) -> str:
        return pulumi.get(self, "left")

    @property
    @pulumi.getter
    def op(self) -> str:
        return pulumi.get(self, "op")

    @property
    @pulumi.getter
    def right(self) -> str:
        return pulumi.get(self, "right")


@pulumi.output_type
class GetJobJobSettingsSettingsTaskForEachTaskTaskDbtTaskResult(dict):
    def __init__(__self__, *,
                 commands: Sequence[str],
                 catalog: Optional[str] = None,
                 profiles_directory: Optional[str] = None,
                 project_directory: Optional[str] = None,
                 schema: Optional[str] = None,
                 source: Optional[str] = None,
                 warehouse_id: Optional[str] = None):
        pulumi.set(__self__, "commands", commands)
        if catalog is not None:
            pulumi.set(__self__, "catalog", catalog)
        if profiles_directory is not None:
            pulumi.set(__self__, "profiles_directory", profiles_directory)
        if project_directory is not None:
            pulumi.set(__self__, "project_directory", project_directory)
        if schema is not None:
            pulumi.set(__self__, "schema", schema)
        if source is not None:
            pulumi.set(__self__, "source", source)
        if warehouse_id is not None:
            pulumi.set(__self__, "warehouse_id", warehouse_id)

    @property
    @pulumi.getter
    def commands(self) -> Sequence[str]:
        return pulumi.get(self, "commands")

    @property
    @pulumi.getter
    def catalog(self) -> Optional[str]:
        return pulumi.get(self, "catalog")

    @property
    @pulumi.getter(name="profilesDirectory")
    def profiles_directory(self) -> Optional[str]:
        return pulumi.get(self, "profiles_directory")

    @property
    @pulumi.getter(name="projectDirectory")
    def project_directory(self) -> Optional[str]:
        return pulumi.get(self, "project_directory")

    @property
    @pulumi.getter
    def schema(self) -> Optional[str]:
        return pulumi.get(self, "schema")

    @property
    @pulumi.getter
    def source(self) -> Optional[str]:
        return pulumi.get(self, "source")

    @property
    @pulumi.getter(name="warehouseId")
    def warehouse_id(self) -> Optional[str]:
        return pulumi.get(self, "warehouse_id")


@pulumi.output_type
class GetJobJobSettingsSettingsTaskForEachTaskTaskDependsOnResult(dict):
    def __init__(__self__, *,
                 task_key: str,
                 outcome: Optional[str] = None):
        pulumi.set(__self__, "task_key", task_key)
        if outcome is not None:
            pulumi.set(__self__, "outcome", outcome)

    @property
    @pulumi.getter(name="taskKey")
    def task_key(self) -> str:
        return pulumi.get(self, "task_key")

    @property
    @pulumi.getter
    def outcome(self) -> Optional[str]:
        return pulumi.get(self, "outcome")


@pulumi.output_type
class GetJobJobSettingsSettingsTaskForEachTaskTaskEmailNotificationsResult(dict):
    def __init__(__self__, *,
                 no_alert_for_skipped_runs: Optional[bool] = None,
                 on_duration_warning_threshold_exceededs: Optional[Sequence[str]] = None,
                 on_failures: Optional[Sequence[str]] = None,
                 on_starts: Optional[Sequence[str]] = None,
                 on_streaming_backlog_exceededs: Optional[Sequence[str]] = None,
                 on_successes: Optional[Sequence[str]] = None):
        if no_alert_for_skipped_runs is not None:
            pulumi.set(__self__, "no_alert_for_skipped_runs", no_alert_for_skipped_runs)
        if on_duration_warning_threshold_exceededs is not None:
            pulumi.set(__self__, "on_duration_warning_threshold_exceededs", on_duration_warning_threshold_exceededs)
        if on_failures is not None:
            pulumi.set(__self__, "on_failures", on_failures)
        if on_starts is not None:
            pulumi.set(__self__, "on_starts", on_starts)
        if on_streaming_backlog_exceededs is not None:
            pulumi.set(__self__, "on_streaming_backlog_exceededs", on_streaming_backlog_exceededs)
        if on_successes is not None:
            pulumi.set(__self__, "on_successes", on_successes)

    @property
    @pulumi.getter(name="noAlertForSkippedRuns")
    def no_alert_for_skipped_runs(self) -> Optional[bool]:
        return pulumi.get(self, "no_alert_for_skipped_runs")

    @property
    @pulumi.getter(name="onDurationWarningThresholdExceededs")
    def on_duration_warning_threshold_exceededs(self) -> Optional[Sequence[str]]:
        return pulumi.get(self, "on_duration_warning_threshold_exceededs")

    @property
    @pulumi.getter(name="onFailures")
    def on_failures(self) -> Optional[Sequence[str]]:
        return pulumi.get(self, "on_failures")

    @property
    @pulumi.getter(name="onStarts")
    def on_starts(self) -> Optional[Sequence[str]]:
        return pulumi.get(self, "on_starts")

    @property
    @pulumi.getter(name="onStreamingBacklogExceededs")
    def on_streaming_backlog_exceededs(self) -> Optional[Sequence[str]]:
        return pulumi.get(self, "on_streaming_backlog_exceededs")

    @property
    @pulumi.getter(name="onSuccesses")
    def on_successes(self) -> Optional[Sequence[str]]:
        return pulumi.get(self, "on_successes")


@pulumi.output_type
class GetJobJobSettingsSettingsTaskForEachTaskTaskHealthResult(dict):
    def __init__(__self__, *,
                 rules: Sequence['outputs.GetJobJobSettingsSettingsTaskForEachTaskTaskHealthRuleResult']):
        pulumi.set(__self__, "rules", rules)

    @property
    @pulumi.getter
    def rules(self) -> Sequence['outputs.GetJobJobSettingsSettingsTaskForEachTaskTaskHealthRuleResult']:
        return pulumi.get(self, "rules")


@pulumi.output_type
class GetJobJobSettingsSettingsTaskForEachTaskTaskHealthRuleResult(dict):
    def __init__(__self__, *,
                 metric: str,
                 op: str,
                 value: int):
        pulumi.set(__self__, "metric", metric)
        pulumi.set(__self__, "op", op)
        pulumi.set(__self__, "value", value)

    @property
    @pulumi.getter
    def metric(self) -> str:
        return pulumi.get(self, "metric")

    @property
    @pulumi.getter
    def op(self) -> str:
        return pulumi.get(self, "op")

    @property
    @pulumi.getter
    def value(self) -> int:
        return pulumi.get(self, "value")


@pulumi.output_type
class GetJobJobSettingsSettingsTaskForEachTaskTaskLibraryResult(dict):
    def __init__(__self__, *,
                 cran: Optional['outputs.GetJobJobSettingsSettingsTaskForEachTaskTaskLibraryCranResult'] = None,
                 egg: Optional[str] = None,
                 jar: Optional[str] = None,
                 maven: Optional['outputs.GetJobJobSettingsSettingsTaskForEachTaskTaskLibraryMavenResult'] = None,
                 pypi: Optional['outputs.GetJobJobSettingsSettingsTaskForEachTaskTaskLibraryPypiResult'] = None,
                 requirements: Optional[str] = None,
                 whl: Optional[str] = None):
        if cran is not None:
            pulumi.set(__self__, "cran", cran)
        if egg is not None:
            pulumi.set(__self__, "egg", egg)
        if jar is not None:
            pulumi.set(__self__, "jar", jar)
        if maven is not None:
            pulumi.set(__self__, "maven", maven)
        if pypi is not None:
            pulumi.set(__self__, "pypi", pypi)
        if requirements is not None:
            pulumi.set(__self__, "requirements", requirements)
        if whl is not None:
            pulumi.set(__self__, "whl", whl)

    @property
    @pulumi.getter
    def cran(self) -> Optional['outputs.GetJobJobSettingsSettingsTaskForEachTaskTaskLibraryCranResult']:
        return pulumi.get(self, "cran")

    @property
    @pulumi.getter
    def egg(self) -> Optional[str]:
        return pulumi.get(self, "egg")

    @property
    @pulumi.getter
    def jar(self) -> Optional[str]:
        return pulumi.get(self, "jar")

    @property
    @pulumi.getter
    def maven(self) -> Optional['outputs.GetJobJobSettingsSettingsTaskForEachTaskTaskLibraryMavenResult']:
        return pulumi.get(self, "maven")

    @property
    @pulumi.getter
    def pypi(self) -> Optional['outputs.GetJobJobSettingsSettingsTaskForEachTaskTaskLibraryPypiResult']:
        return pulumi.get(self, "pypi")

    @property
    @pulumi.getter
    def requirements(self) -> Optional[str]:
        return pulumi.get(self, "requirements")

    @property
    @pulumi.getter
    def whl(self) -> Optional[str]:
        return pulumi.get(self, "whl")


@pulumi.output_type
class GetJobJobSettingsSettingsTaskForEachTaskTaskLibraryCranResult(dict):
    def __init__(__self__, *,
                 package: str,
                 repo: Optional[str] = None):
        pulumi.set(__self__, "package", package)
        if repo is not None:
            pulumi.set(__self__, "repo", repo)

    @property
    @pulumi.getter
    def package(self) -> str:
        return pulumi.get(self, "package")

    @property
    @pulumi.getter
    def repo(self) -> Optional[str]:
        return pulumi.get(self, "repo")


@pulumi.output_type
class GetJobJobSettingsSettingsTaskForEachTaskTaskLibraryMavenResult(dict):
    def __init__(__self__, *,
                 coordinates: str,
                 exclusions: Optional[Sequence[str]] = None,
                 repo: Optional[str] = None):
        pulumi.set(__self__, "coordinates", coordinates)
        if exclusions is not None:
            pulumi.set(__self__, "exclusions", exclusions)
        if repo is not None:
            pulumi.set(__self__, "repo", repo)

    @property
    @pulumi.getter
    def coordinates(self) -> str:
        return pulumi.get(self, "coordinates")

    @property
    @pulumi.getter
    def exclusions(self) -> Optional[Sequence[str]]:
        return pulumi.get(self, "exclusions")

    @property
    @pulumi.getter
    def repo(self) -> Optional[str]:
        return pulumi.get(self, "repo")


@pulumi.output_type
class GetJobJobSettingsSettingsTaskForEachTaskTaskLibraryPypiResult(dict):
    def __init__(__self__, *,
                 package: str,
                 repo: Optional[str] = None):
        pulumi.set(__self__, "package", package)
        if repo is not None:
            pulumi.set(__self__, "repo", repo)

    @property
    @pulumi.getter
    def package(self) -> str:
        return pulumi.get(self, "package")

    @property
    @pulumi.getter
    def repo(self) -> Optional[str]:
        return pulumi.get(self, "repo")


@pulumi.output_type
class GetJobJobSettingsSettingsTaskForEachTaskTaskNewClusterResult(dict):
    def __init__(__self__, *,
                 driver_instance_pool_id: str,
                 driver_node_type_id: str,
                 enable_elastic_disk: bool,
                 enable_local_disk_encryption: bool,
                 node_type_id: str,
                 num_workers: int,
                 spark_version: str,
                 apply_policy_default_values: Optional[bool] = None,
                 autoscale: Optional['outputs.GetJobJobSettingsSettingsTaskForEachTaskTaskNewClusterAutoscaleResult'] = None,
                 autotermination_minutes: Optional[int] = None,
                 aws_attributes: Optional['outputs.GetJobJobSettingsSettingsTaskForEachTaskTaskNewClusterAwsAttributesResult'] = None,
                 azure_attributes: Optional['outputs.GetJobJobSettingsSettingsTaskForEachTaskTaskNewClusterAzureAttributesResult'] = None,
                 cluster_id: Optional[str] = None,
                 cluster_log_conf: Optional['outputs.GetJobJobSettingsSettingsTaskForEachTaskTaskNewClusterClusterLogConfResult'] = None,
                 cluster_mount_infos: Optional[Sequence['outputs.GetJobJobSettingsSettingsTaskForEachTaskTaskNewClusterClusterMountInfoResult']] = None,
                 cluster_name: Optional[str] = None,
                 custom_tags: Optional[Mapping[str, str]] = None,
                 data_security_mode: Optional[str] = None,
                 docker_image: Optional['outputs.GetJobJobSettingsSettingsTaskForEachTaskTaskNewClusterDockerImageResult'] = None,
                 gcp_attributes: Optional['outputs.GetJobJobSettingsSettingsTaskForEachTaskTaskNewClusterGcpAttributesResult'] = None,
                 idempotency_token: Optional[str] = None,
                 init_scripts: Optional[Sequence['outputs.GetJobJobSettingsSettingsTaskForEachTaskTaskNewClusterInitScriptResult']] = None,
                 instance_pool_id: Optional[str] = None,
                 policy_id: Optional[str] = None,
                 runtime_engine: Optional[str] = None,
                 single_user_name: Optional[str] = None,
                 spark_conf: Optional[Mapping[str, str]] = None,
                 spark_env_vars: Optional[Mapping[str, str]] = None,
                 ssh_public_keys: Optional[Sequence[str]] = None,
                 workload_type: Optional['outputs.GetJobJobSettingsSettingsTaskForEachTaskTaskNewClusterWorkloadTypeResult'] = None):
        pulumi.set(__self__, "driver_instance_pool_id", driver_instance_pool_id)
        pulumi.set(__self__, "driver_node_type_id", driver_node_type_id)
        pulumi.set(__self__, "enable_elastic_disk", enable_elastic_disk)
        pulumi.set(__self__, "enable_local_disk_encryption", enable_local_disk_encryption)
        pulumi.set(__self__, "node_type_id", node_type_id)
        pulumi.set(__self__, "num_workers", num_workers)
        pulumi.set(__self__, "spark_version", spark_version)
        if apply_policy_default_values is not None:
            pulumi.set(__self__, "apply_policy_default_values", apply_policy_default_values)
        if autoscale is not None:
            pulumi.set(__self__, "autoscale", autoscale)
        if autotermination_minutes is not None:
            pulumi.set(__self__, "autotermination_minutes", autotermination_minutes)
        if aws_attributes is not None:
            pulumi.set(__self__, "aws_attributes", aws_attributes)
        if azure_attributes is not None:
            pulumi.set(__self__, "azure_attributes", azure_attributes)
        if cluster_id is not None:
            pulumi.set(__self__, "cluster_id", cluster_id)
        if cluster_log_conf is not None:
            pulumi.set(__self__, "cluster_log_conf", cluster_log_conf)
        if cluster_mount_infos is not None:
            pulumi.set(__self__, "cluster_mount_infos", cluster_mount_infos)
        if cluster_name is not None:
            pulumi.set(__self__, "cluster_name", cluster_name)
        if custom_tags is not None:
            pulumi.set(__self__, "custom_tags", custom_tags)
        if data_security_mode is not None:
            pulumi.set(__self__, "data_security_mode", data_security_mode)
        if docker_image is not None:
            pulumi.set(__self__, "docker_image", docker_image)
        if gcp_attributes is not None:
            pulumi.set(__self__, "gcp_attributes", gcp_attributes)
        if idempotency_token is not None:
            pulumi.set(__self__, "idempotency_token", idempotency_token)
        if init_scripts is not None:
            pulumi.set(__self__, "init_scripts", init_scripts)
        if instance_pool_id is not None:
            pulumi.set(__self__, "instance_pool_id", instance_pool_id)
        if policy_id is not None:
            pulumi.set(__self__, "policy_id", policy_id)
        if runtime_engine is not None:
            pulumi.set(__self__, "runtime_engine", runtime_engine)
        if single_user_name is not None:
            pulumi.set(__self__, "single_user_name", single_user_name)
        if spark_conf is not None:
            pulumi.set(__self__, "spark_conf", spark_conf)
        if spark_env_vars is not None:
            pulumi.set(__self__, "spark_env_vars", spark_env_vars)
        if ssh_public_keys is not None:
            pulumi.set(__self__, "ssh_public_keys", ssh_public_keys)
        if workload_type is not None:
            pulumi.set(__self__, "workload_type", workload_type)

    @property
    @pulumi.getter(name="driverInstancePoolId")
    def driver_instance_pool_id(self) -> str:
        return pulumi.get(self, "driver_instance_pool_id")

    @property
    @pulumi.getter(name="driverNodeTypeId")
    def driver_node_type_id(self) -> str:
        return pulumi.get(self, "driver_node_type_id")

    @property
    @pulumi.getter(name="enableElasticDisk")
    def enable_elastic_disk(self) -> bool:
        return pulumi.get(self, "enable_elastic_disk")

    @property
    @pulumi.getter(name="enableLocalDiskEncryption")
    def enable_local_disk_encryption(self) -> bool:
        return pulumi.get(self, "enable_local_disk_encryption")

    @property
    @pulumi.getter(name="nodeTypeId")
    def node_type_id(self) -> str:
        return pulumi.get(self, "node_type_id")

    @property
    @pulumi.getter(name="numWorkers")
    def num_workers(self) -> int:
        return pulumi.get(self, "num_workers")

    @property
    @pulumi.getter(name="sparkVersion")
    def spark_version(self) -> str:
        return pulumi.get(self, "spark_version")

    @property
    @pulumi.getter(name="applyPolicyDefaultValues")
    def apply_policy_default_values(self) -> Optional[bool]:
        return pulumi.get(self, "apply_policy_default_values")

    @property
    @pulumi.getter
    def autoscale(self) -> Optional['outputs.GetJobJobSettingsSettingsTaskForEachTaskTaskNewClusterAutoscaleResult']:
        return pulumi.get(self, "autoscale")

    @property
    @pulumi.getter(name="autoterminationMinutes")
    def autotermination_minutes(self) -> Optional[int]:
        return pulumi.get(self, "autotermination_minutes")

    @property
    @pulumi.getter(name="awsAttributes")
    def aws_attributes(self) -> Optional['outputs.GetJobJobSettingsSettingsTaskForEachTaskTaskNewClusterAwsAttributesResult']:
        return pulumi.get(self, "aws_attributes")

    @property
    @pulumi.getter(name="azureAttributes")
    def azure_attributes(self) -> Optional['outputs.GetJobJobSettingsSettingsTaskForEachTaskTaskNewClusterAzureAttributesResult']:
        return pulumi.get(self, "azure_attributes")

    @property
    @pulumi.getter(name="clusterId")
    def cluster_id(self) -> Optional[str]:
        return pulumi.get(self, "cluster_id")

    @property
    @pulumi.getter(name="clusterLogConf")
    def cluster_log_conf(self) -> Optional['outputs.GetJobJobSettingsSettingsTaskForEachTaskTaskNewClusterClusterLogConfResult']:
        return pulumi.get(self, "cluster_log_conf")

    @property
    @pulumi.getter(name="clusterMountInfos")
    def cluster_mount_infos(self) -> Optional[Sequence['outputs.GetJobJobSettingsSettingsTaskForEachTaskTaskNewClusterClusterMountInfoResult']]:
        return pulumi.get(self, "cluster_mount_infos")

    @property
    @pulumi.getter(name="clusterName")
    def cluster_name(self) -> Optional[str]:
        return pulumi.get(self, "cluster_name")

    @property
    @pulumi.getter(name="customTags")
    def custom_tags(self) -> Optional[Mapping[str, str]]:
        return pulumi.get(self, "custom_tags")

    @property
    @pulumi.getter(name="dataSecurityMode")
    def data_security_mode(self) -> Optional[str]:
        return pulumi.get(self, "data_security_mode")

    @property
    @pulumi.getter(name="dockerImage")
    def docker_image(self) -> Optional['outputs.GetJobJobSettingsSettingsTaskForEachTaskTaskNewClusterDockerImageResult']:
        return pulumi.get(self, "docker_image")

    @property
    @pulumi.getter(name="gcpAttributes")
    def gcp_attributes(self) -> Optional['outputs.GetJobJobSettingsSettingsTaskForEachTaskTaskNewClusterGcpAttributesResult']:
        return pulumi.get(self, "gcp_attributes")

    @property
    @pulumi.getter(name="idempotencyToken")
    def idempotency_token(self) -> Optional[str]:
        return pulumi.get(self, "idempotency_token")

    @property
    @pulumi.getter(name="initScripts")
    def init_scripts(self) -> Optional[Sequence['outputs.GetJobJobSettingsSettingsTaskForEachTaskTaskNewClusterInitScriptResult']]:
        return pulumi.get(self, "init_scripts")

    @property
    @pulumi.getter(name="instancePoolId")
    def instance_pool_id(self) -> Optional[str]:
        return pulumi.get(self, "instance_pool_id")

    @property
    @pulumi.getter(name="policyId")
    def policy_id(self) -> Optional[str]:
        return pulumi.get(self, "policy_id")

    @property
    @pulumi.getter(name="runtimeEngine")
    def runtime_engine(self) -> Optional[str]:
        return pulumi.get(self, "runtime_engine")

    @property
    @pulumi.getter(name="singleUserName")
    def single_user_name(self) -> Optional[str]:
        return pulumi.get(self, "single_user_name")

    @property
    @pulumi.getter(name="sparkConf")
    def spark_conf(self) -> Optional[Mapping[str, str]]:
        return pulumi.get(self, "spark_conf")

    @property
    @pulumi.getter(name="sparkEnvVars")
    def spark_env_vars(self) -> Optional[Mapping[str, str]]:
        return pulumi.get(self, "spark_env_vars")

    @property
    @pulumi.getter(name="sshPublicKeys")
    def ssh_public_keys(self) -> Optional[Sequence[str]]:
        return pulumi.get(self, "ssh_public_keys")

    @property
    @pulumi.getter(name="workloadType")
    def workload_type(self) -> Optional['outputs.GetJobJobSettingsSettingsTaskForEachTaskTaskNewClusterWorkloadTypeResult']:
        return pulumi.get(self, "workload_type")


@pulumi.output_type
class GetJobJobSettingsSettingsTaskForEachTaskTaskNewClusterAutoscaleResult(dict):
    def __init__(__self__, *,
                 max_workers: Optional[int] = None,
                 min_workers: Optional[int] = None):
        if max_workers is not None:
            pulumi.set(__self__, "max_workers", max_workers)
        if min_workers is not None:
            pulumi.set(__self__, "min_workers", min_workers)

    @property
    @pulumi.getter(name="maxWorkers")
    def max_workers(self) -> Optional[int]:
        return pulumi.get(self, "max_workers")

    @property
    @pulumi.getter(name="minWorkers")
    def min_workers(self) -> Optional[int]:
        return pulumi.get(self, "min_workers")


@pulumi.output_type
class GetJobJobSettingsSettingsTaskForEachTaskTaskNewClusterAwsAttributesResult(dict):
    def __init__(__self__, *,
                 availability: Optional[str] = None,
                 ebs_volume_count: Optional[int] = None,
                 ebs_volume_size: Optional[int] = None,
                 ebs_volume_type: Optional[str] = None,
                 first_on_demand: Optional[int] = None,
                 instance_profile_arn: Optional[str] = None,
                 spot_bid_price_percent: Optional[int] = None,
                 zone_id: Optional[str] = None):
        if availability is not None:
            pulumi.set(__self__, "availability", availability)
        if ebs_volume_count is not None:
            pulumi.set(__self__, "ebs_volume_count", ebs_volume_count)
        if ebs_volume_size is not None:
            pulumi.set(__self__, "ebs_volume_size", ebs_volume_size)
        if ebs_volume_type is not None:
            pulumi.set(__self__, "ebs_volume_type", ebs_volume_type)
        if first_on_demand is not None:
            pulumi.set(__self__, "first_on_demand", first_on_demand)
        if instance_profile_arn is not None:
            pulumi.set(__self__, "instance_profile_arn", instance_profile_arn)
        if spot_bid_price_percent is not None:
            pulumi.set(__self__, "spot_bid_price_percent", spot_bid_price_percent)
        if zone_id is not None:
            pulumi.set(__self__, "zone_id", zone_id)

    @property
    @pulumi.getter
    def availability(self) -> Optional[str]:
        return pulumi.get(self, "availability")

    @property
    @pulumi.getter(name="ebsVolumeCount")
    def ebs_volume_count(self) -> Optional[int]:
        return pulumi.get(self, "ebs_volume_count")

    @property
    @pulumi.getter(name="ebsVolumeSize")
    def ebs_volume_size(self) -> Optional[int]:
        return pulumi.get(self, "ebs_volume_size")

    @property
    @pulumi.getter(name="ebsVolumeType")
    def ebs_volume_type(self) -> Optional[str]:
        return pulumi.get(self, "ebs_volume_type")

    @property
    @pulumi.getter(name="firstOnDemand")
    def first_on_demand(self) -> Optional[int]:
        return pulumi.get(self, "first_on_demand")

    @property
    @pulumi.getter(name="instanceProfileArn")
    def instance_profile_arn(self) -> Optional[str]:
        return pulumi.get(self, "instance_profile_arn")

    @property
    @pulumi.getter(name="spotBidPricePercent")
    def spot_bid_price_percent(self) -> Optional[int]:
        return pulumi.get(self, "spot_bid_price_percent")

    @property
    @pulumi.getter(name="zoneId")
    def zone_id(self) -> Optional[str]:
        return pulumi.get(self, "zone_id")


@pulumi.output_type
class GetJobJobSettingsSettingsTaskForEachTaskTaskNewClusterAzureAttributesResult(dict):
    def __init__(__self__, *,
                 availability: Optional[str] = None,
                 first_on_demand: Optional[int] = None,
                 spot_bid_max_price: Optional[float] = None):
        if availability is not None:
            pulumi.set(__self__, "availability", availability)
        if first_on_demand is not None:
            pulumi.set(__self__, "first_on_demand", first_on_demand)
        if spot_bid_max_price is not None:
            pulumi.set(__self__, "spot_bid_max_price", spot_bid_max_price)

    @property
    @pulumi.getter
    def availability(self) -> Optional[str]:
        return pulumi.get(self, "availability")

    @property
    @pulumi.getter(name="firstOnDemand")
    def first_on_demand(self) -> Optional[int]:
        return pulumi.get(self, "first_on_demand")

    @property
    @pulumi.getter(name="spotBidMaxPrice")
    def spot_bid_max_price(self) -> Optional[float]:
        return pulumi.get(self, "spot_bid_max_price")


@pulumi.output_type
class GetJobJobSettingsSettingsTaskForEachTaskTaskNewClusterClusterLogConfResult(dict):
    def __init__(__self__, *,
                 dbfs: Optional['outputs.GetJobJobSettingsSettingsTaskForEachTaskTaskNewClusterClusterLogConfDbfsResult'] = None,
                 s3: Optional['outputs.GetJobJobSettingsSettingsTaskForEachTaskTaskNewClusterClusterLogConfS3Result'] = None):
        if dbfs is not None:
            pulumi.set(__self__, "dbfs", dbfs)
        if s3 is not None:
            pulumi.set(__self__, "s3", s3)

    @property
    @pulumi.getter
    def dbfs(self) -> Optional['outputs.GetJobJobSettingsSettingsTaskForEachTaskTaskNewClusterClusterLogConfDbfsResult']:
        return pulumi.get(self, "dbfs")

    @property
    @pulumi.getter
    def s3(self) -> Optional['outputs.GetJobJobSettingsSettingsTaskForEachTaskTaskNewClusterClusterLogConfS3Result']:
        return pulumi.get(self, "s3")


@pulumi.output_type
class GetJobJobSettingsSettingsTaskForEachTaskTaskNewClusterClusterLogConfDbfsResult(dict):
    def __init__(__self__, *,
                 destination: str):
        pulumi.set(__self__, "destination", destination)

    @property
    @pulumi.getter
    def destination(self) -> str:
        return pulumi.get(self, "destination")


@pulumi.output_type
class GetJobJobSettingsSettingsTaskForEachTaskTaskNewClusterClusterLogConfS3Result(dict):
    def __init__(__self__, *,
                 destination: str,
                 canned_acl: Optional[str] = None,
                 enable_encryption: Optional[bool] = None,
                 encryption_type: Optional[str] = None,
                 endpoint: Optional[str] = None,
                 kms_key: Optional[str] = None,
                 region: Optional[str] = None):
        pulumi.set(__self__, "destination", destination)
        if canned_acl is not None:
            pulumi.set(__self__, "canned_acl", canned_acl)
        if enable_encryption is not None:
            pulumi.set(__self__, "enable_encryption", enable_encryption)
        if encryption_type is not None:
            pulumi.set(__self__, "encryption_type", encryption_type)
        if endpoint is not None:
            pulumi.set(__self__, "endpoint", endpoint)
        if kms_key is not None:
            pulumi.set(__self__, "kms_key", kms_key)
        if region is not None:
            pulumi.set(__self__, "region", region)

    @property
    @pulumi.getter
    def destination(self) -> str:
        return pulumi.get(self, "destination")

    @property
    @pulumi.getter(name="cannedAcl")
    def canned_acl(self) -> Optional[str]:
        return pulumi.get(self, "canned_acl")

    @property
    @pulumi.getter(name="enableEncryption")
    def enable_encryption(self) -> Optional[bool]:
        return pulumi.get(self, "enable_encryption")

    @property
    @pulumi.getter(name="encryptionType")
    def encryption_type(self) -> Optional[str]:
        return pulumi.get(self, "encryption_type")

    @property
    @pulumi.getter
    def endpoint(self) -> Optional[str]:
        return pulumi.get(self, "endpoint")

    @property
    @pulumi.getter(name="kmsKey")
    def kms_key(self) -> Optional[str]:
        return pulumi.get(self, "kms_key")

    @property
    @pulumi.getter
    def region(self) -> Optional[str]:
        return pulumi.get(self, "region")


@pulumi.output_type
class GetJobJobSettingsSettingsTaskForEachTaskTaskNewClusterClusterMountInfoResult(dict):
    def __init__(__self__, *,
                 local_mount_dir_path: str,
                 network_filesystem_info: 'outputs.GetJobJobSettingsSettingsTaskForEachTaskTaskNewClusterClusterMountInfoNetworkFilesystemInfoResult',
                 remote_mount_dir_path: Optional[str] = None):
        pulumi.set(__self__, "local_mount_dir_path", local_mount_dir_path)
        pulumi.set(__self__, "network_filesystem_info", network_filesystem_info)
        if remote_mount_dir_path is not None:
            pulumi.set(__self__, "remote_mount_dir_path", remote_mount_dir_path)

    @property
    @pulumi.getter(name="localMountDirPath")
    def local_mount_dir_path(self) -> str:
        return pulumi.get(self, "local_mount_dir_path")

    @property
    @pulumi.getter(name="networkFilesystemInfo")
    def network_filesystem_info(self) -> 'outputs.GetJobJobSettingsSettingsTaskForEachTaskTaskNewClusterClusterMountInfoNetworkFilesystemInfoResult':
        return pulumi.get(self, "network_filesystem_info")

    @property
    @pulumi.getter(name="remoteMountDirPath")
    def remote_mount_dir_path(self) -> Optional[str]:
        return pulumi.get(self, "remote_mount_dir_path")


@pulumi.output_type
class GetJobJobSettingsSettingsTaskForEachTaskTaskNewClusterClusterMountInfoNetworkFilesystemInfoResult(dict):
    def __init__(__self__, *,
                 server_address: str,
                 mount_options: Optional[str] = None):
        pulumi.set(__self__, "server_address", server_address)
        if mount_options is not None:
            pulumi.set(__self__, "mount_options", mount_options)

    @property
    @pulumi.getter(name="serverAddress")
    def server_address(self) -> str:
        return pulumi.get(self, "server_address")

    @property
    @pulumi.getter(name="mountOptions")
    def mount_options(self) -> Optional[str]:
        return pulumi.get(self, "mount_options")


@pulumi.output_type
class GetJobJobSettingsSettingsTaskForEachTaskTaskNewClusterDockerImageResult(dict):
    def __init__(__self__, *,
                 url: str,
                 basic_auth: Optional['outputs.GetJobJobSettingsSettingsTaskForEachTaskTaskNewClusterDockerImageBasicAuthResult'] = None):
        pulumi.set(__self__, "url", url)
        if basic_auth is not None:
            pulumi.set(__self__, "basic_auth", basic_auth)

    @property
    @pulumi.getter
    def url(self) -> str:
        return pulumi.get(self, "url")

    @property
    @pulumi.getter(name="basicAuth")
    def basic_auth(self) -> Optional['outputs.GetJobJobSettingsSettingsTaskForEachTaskTaskNewClusterDockerImageBasicAuthResult']:
        return pulumi.get(self, "basic_auth")


@pulumi.output_type
class GetJobJobSettingsSettingsTaskForEachTaskTaskNewClusterDockerImageBasicAuthResult(dict):
    def __init__(__self__, *,
                 password: str,
                 username: str):
        pulumi.set(__self__, "password", password)
        pulumi.set(__self__, "username", username)

    @property
    @pulumi.getter
    def password(self) -> str:
        return pulumi.get(self, "password")

    @property
    @pulumi.getter
    def username(self) -> str:
        return pulumi.get(self, "username")


@pulumi.output_type
class GetJobJobSettingsSettingsTaskForEachTaskTaskNewClusterGcpAttributesResult(dict):
    def __init__(__self__, *,
                 availability: Optional[str] = None,
                 boot_disk_size: Optional[int] = None,
                 google_service_account: Optional[str] = None,
                 local_ssd_count: Optional[int] = None,
                 use_preemptible_executors: Optional[bool] = None,
                 zone_id: Optional[str] = None):
        if availability is not None:
            pulumi.set(__self__, "availability", availability)
        if boot_disk_size is not None:
            pulumi.set(__self__, "boot_disk_size", boot_disk_size)
        if google_service_account is not None:
            pulumi.set(__self__, "google_service_account", google_service_account)
        if local_ssd_count is not None:
            pulumi.set(__self__, "local_ssd_count", local_ssd_count)
        if use_preemptible_executors is not None:
            pulumi.set(__self__, "use_preemptible_executors", use_preemptible_executors)
        if zone_id is not None:
            pulumi.set(__self__, "zone_id", zone_id)

    @property
    @pulumi.getter
    def availability(self) -> Optional[str]:
        return pulumi.get(self, "availability")

    @property
    @pulumi.getter(name="bootDiskSize")
    def boot_disk_size(self) -> Optional[int]:
        return pulumi.get(self, "boot_disk_size")

    @property
    @pulumi.getter(name="googleServiceAccount")
    def google_service_account(self) -> Optional[str]:
        return pulumi.get(self, "google_service_account")

    @property
    @pulumi.getter(name="localSsdCount")
    def local_ssd_count(self) -> Optional[int]:
        return pulumi.get(self, "local_ssd_count")

    @property
    @pulumi.getter(name="usePreemptibleExecutors")
    def use_preemptible_executors(self) -> Optional[bool]:
        return pulumi.get(self, "use_preemptible_executors")

    @property
    @pulumi.getter(name="zoneId")
    def zone_id(self) -> Optional[str]:
        return pulumi.get(self, "zone_id")


@pulumi.output_type
class GetJobJobSettingsSettingsTaskForEachTaskTaskNewClusterInitScriptResult(dict):
    def __init__(__self__, *,
                 abfss: Optional['outputs.GetJobJobSettingsSettingsTaskForEachTaskTaskNewClusterInitScriptAbfssResult'] = None,
                 dbfs: Optional['outputs.GetJobJobSettingsSettingsTaskForEachTaskTaskNewClusterInitScriptDbfsResult'] = None,
                 file: Optional['outputs.GetJobJobSettingsSettingsTaskForEachTaskTaskNewClusterInitScriptFileResult'] = None,
                 gcs: Optional['outputs.GetJobJobSettingsSettingsTaskForEachTaskTaskNewClusterInitScriptGcsResult'] = None,
                 s3: Optional['outputs.GetJobJobSettingsSettingsTaskForEachTaskTaskNewClusterInitScriptS3Result'] = None,
                 volumes: Optional['outputs.GetJobJobSettingsSettingsTaskForEachTaskTaskNewClusterInitScriptVolumesResult'] = None,
                 workspace: Optional['outputs.GetJobJobSettingsSettingsTaskForEachTaskTaskNewClusterInitScriptWorkspaceResult'] = None):
        if abfss is not None:
            pulumi.set(__self__, "abfss", abfss)
        if dbfs is not None:
            pulumi.set(__self__, "dbfs", dbfs)
        if file is not None:
            pulumi.set(__self__, "file", file)
        if gcs is not None:
            pulumi.set(__self__, "gcs", gcs)
        if s3 is not None:
            pulumi.set(__self__, "s3", s3)
        if volumes is not None:
            pulumi.set(__self__, "volumes", volumes)
        if workspace is not None:
            pulumi.set(__self__, "workspace", workspace)

    @property
    @pulumi.getter
    def abfss(self) -> Optional['outputs.GetJobJobSettingsSettingsTaskForEachTaskTaskNewClusterInitScriptAbfssResult']:
        return pulumi.get(self, "abfss")

    @property
    @pulumi.getter
    def dbfs(self) -> Optional['outputs.GetJobJobSettingsSettingsTaskForEachTaskTaskNewClusterInitScriptDbfsResult']:
        return pulumi.get(self, "dbfs")

    @property
    @pulumi.getter
    def file(self) -> Optional['outputs.GetJobJobSettingsSettingsTaskForEachTaskTaskNewClusterInitScriptFileResult']:
        return pulumi.get(self, "file")

    @property
    @pulumi.getter
    def gcs(self) -> Optional['outputs.GetJobJobSettingsSettingsTaskForEachTaskTaskNewClusterInitScriptGcsResult']:
        return pulumi.get(self, "gcs")

    @property
    @pulumi.getter
    def s3(self) -> Optional['outputs.GetJobJobSettingsSettingsTaskForEachTaskTaskNewClusterInitScriptS3Result']:
        return pulumi.get(self, "s3")

    @property
    @pulumi.getter
    def volumes(self) -> Optional['outputs.GetJobJobSettingsSettingsTaskForEachTaskTaskNewClusterInitScriptVolumesResult']:
        return pulumi.get(self, "volumes")

    @property
    @pulumi.getter
    def workspace(self) -> Optional['outputs.GetJobJobSettingsSettingsTaskForEachTaskTaskNewClusterInitScriptWorkspaceResult']:
        return pulumi.get(self, "workspace")


@pulumi.output_type
class GetJobJobSettingsSettingsTaskForEachTaskTaskNewClusterInitScriptAbfssResult(dict):
    def __init__(__self__, *,
                 destination: str):
        pulumi.set(__self__, "destination", destination)

    @property
    @pulumi.getter
    def destination(self) -> str:
        return pulumi.get(self, "destination")


@pulumi.output_type
class GetJobJobSettingsSettingsTaskForEachTaskTaskNewClusterInitScriptDbfsResult(dict):
    def __init__(__self__, *,
                 destination: str):
        pulumi.set(__self__, "destination", destination)

    @property
    @pulumi.getter
    def destination(self) -> str:
        return pulumi.get(self, "destination")


@pulumi.output_type
class GetJobJobSettingsSettingsTaskForEachTaskTaskNewClusterInitScriptFileResult(dict):
    def __init__(__self__, *,
                 destination: str):
        pulumi.set(__self__, "destination", destination)

    @property
    @pulumi.getter
    def destination(self) -> str:
        return pulumi.get(self, "destination")


@pulumi.output_type
class GetJobJobSettingsSettingsTaskForEachTaskTaskNewClusterInitScriptGcsResult(dict):
    def __init__(__self__, *,
                 destination: str):
        pulumi.set(__self__, "destination", destination)

    @property
    @pulumi.getter
    def destination(self) -> str:
        return pulumi.get(self, "destination")


@pulumi.output_type
class GetJobJobSettingsSettingsTaskForEachTaskTaskNewClusterInitScriptS3Result(dict):
    def __init__(__self__, *,
                 destination: str,
                 canned_acl: Optional[str] = None,
                 enable_encryption: Optional[bool] = None,
                 encryption_type: Optional[str] = None,
                 endpoint: Optional[str] = None,
                 kms_key: Optional[str] = None,
                 region: Optional[str] = None):
        pulumi.set(__self__, "destination", destination)
        if canned_acl is not None:
            pulumi.set(__self__, "canned_acl", canned_acl)
        if enable_encryption is not None:
            pulumi.set(__self__, "enable_encryption", enable_encryption)
        if encryption_type is not None:
            pulumi.set(__self__, "encryption_type", encryption_type)
        if endpoint is not None:
            pulumi.set(__self__, "endpoint", endpoint)
        if kms_key is not None:
            pulumi.set(__self__, "kms_key", kms_key)
        if region is not None:
            pulumi.set(__self__, "region", region)

    @property
    @pulumi.getter
    def destination(self) -> str:
        return pulumi.get(self, "destination")

    @property
    @pulumi.getter(name="cannedAcl")
    def canned_acl(self) -> Optional[str]:
        return pulumi.get(self, "canned_acl")

    @property
    @pulumi.getter(name="enableEncryption")
    def enable_encryption(self) -> Optional[bool]:
        return pulumi.get(self, "enable_encryption")

    @property
    @pulumi.getter(name="encryptionType")
    def encryption_type(self) -> Optional[str]:
        return pulumi.get(self, "encryption_type")

    @property
    @pulumi.getter
    def endpoint(self) -> Optional[str]:
        return pulumi.get(self, "endpoint")

    @property
    @pulumi.getter(name="kmsKey")
    def kms_key(self) -> Optional[str]:
        return pulumi.get(self, "kms_key")

    @property
    @pulumi.getter
    def region(self) -> Optional[str]:
        return pulumi.get(self, "region")


@pulumi.output_type
class GetJobJobSettingsSettingsTaskForEachTaskTaskNewClusterInitScriptVolumesResult(dict):
    def __init__(__self__, *,
                 destination: str):
        pulumi.set(__self__, "destination", destination)

    @property
    @pulumi.getter
    def destination(self) -> str:
        return pulumi.get(self, "destination")


@pulumi.output_type
class GetJobJobSettingsSettingsTaskForEachTaskTaskNewClusterInitScriptWorkspaceResult(dict):
    def __init__(__self__, *,
                 destination: str):
        pulumi.set(__self__, "destination", destination)

    @property
    @pulumi.getter
    def destination(self) -> str:
        return pulumi.get(self, "destination")


@pulumi.output_type
class GetJobJobSettingsSettingsTaskForEachTaskTaskNewClusterWorkloadTypeResult(dict):
    def __init__(__self__, *,
                 clients: 'outputs.GetJobJobSettingsSettingsTaskForEachTaskTaskNewClusterWorkloadTypeClientsResult'):
        pulumi.set(__self__, "clients", clients)

    @property
    @pulumi.getter
    def clients(self) -> 'outputs.GetJobJobSettingsSettingsTaskForEachTaskTaskNewClusterWorkloadTypeClientsResult':
        return pulumi.get(self, "clients")


@pulumi.output_type
class GetJobJobSettingsSettingsTaskForEachTaskTaskNewClusterWorkloadTypeClientsResult(dict):
    def __init__(__self__, *,
                 jobs: Optional[bool] = None,
                 notebooks: Optional[bool] = None):
        if jobs is not None:
            pulumi.set(__self__, "jobs", jobs)
        if notebooks is not None:
            pulumi.set(__self__, "notebooks", notebooks)

    @property
    @pulumi.getter
    def jobs(self) -> Optional[bool]:
        return pulumi.get(self, "jobs")

    @property
    @pulumi.getter
    def notebooks(self) -> Optional[bool]:
        return pulumi.get(self, "notebooks")


@pulumi.output_type
class GetJobJobSettingsSettingsTaskForEachTaskTaskNotebookTaskResult(dict):
    def __init__(__self__, *,
                 notebook_path: str,
                 base_parameters: Optional[Mapping[str, str]] = None,
                 source: Optional[str] = None,
                 warehouse_id: Optional[str] = None):
        pulumi.set(__self__, "notebook_path", notebook_path)
        if base_parameters is not None:
            pulumi.set(__self__, "base_parameters", base_parameters)
        if source is not None:
            pulumi.set(__self__, "source", source)
        if warehouse_id is not None:
            pulumi.set(__self__, "warehouse_id", warehouse_id)

    @property
    @pulumi.getter(name="notebookPath")
    def notebook_path(self) -> str:
        return pulumi.get(self, "notebook_path")

    @property
    @pulumi.getter(name="baseParameters")
    def base_parameters(self) -> Optional[Mapping[str, str]]:
        return pulumi.get(self, "base_parameters")

    @property
    @pulumi.getter
    def source(self) -> Optional[str]:
        return pulumi.get(self, "source")

    @property
    @pulumi.getter(name="warehouseId")
    def warehouse_id(self) -> Optional[str]:
        return pulumi.get(self, "warehouse_id")


@pulumi.output_type
class GetJobJobSettingsSettingsTaskForEachTaskTaskNotificationSettingsResult(dict):
    def __init__(__self__, *,
                 alert_on_last_attempt: Optional[bool] = None,
                 no_alert_for_canceled_runs: Optional[bool] = None,
                 no_alert_for_skipped_runs: Optional[bool] = None):
        if alert_on_last_attempt is not None:
            pulumi.set(__self__, "alert_on_last_attempt", alert_on_last_attempt)
        if no_alert_for_canceled_runs is not None:
            pulumi.set(__self__, "no_alert_for_canceled_runs", no_alert_for_canceled_runs)
        if no_alert_for_skipped_runs is not None:
            pulumi.set(__self__, "no_alert_for_skipped_runs", no_alert_for_skipped_runs)

    @property
    @pulumi.getter(name="alertOnLastAttempt")
    def alert_on_last_attempt(self) -> Optional[bool]:
        return pulumi.get(self, "alert_on_last_attempt")

    @property
    @pulumi.getter(name="noAlertForCanceledRuns")
    def no_alert_for_canceled_runs(self) -> Optional[bool]:
        return pulumi.get(self, "no_alert_for_canceled_runs")

    @property
    @pulumi.getter(name="noAlertForSkippedRuns")
    def no_alert_for_skipped_runs(self) -> Optional[bool]:
        return pulumi.get(self, "no_alert_for_skipped_runs")


@pulumi.output_type
class GetJobJobSettingsSettingsTaskForEachTaskTaskPipelineTaskResult(dict):
    def __init__(__self__, *,
                 pipeline_id: str,
                 full_refresh: Optional[bool] = None):
        pulumi.set(__self__, "pipeline_id", pipeline_id)
        if full_refresh is not None:
            pulumi.set(__self__, "full_refresh", full_refresh)

    @property
    @pulumi.getter(name="pipelineId")
    def pipeline_id(self) -> str:
        return pulumi.get(self, "pipeline_id")

    @property
    @pulumi.getter(name="fullRefresh")
    def full_refresh(self) -> Optional[bool]:
        return pulumi.get(self, "full_refresh")


@pulumi.output_type
class GetJobJobSettingsSettingsTaskForEachTaskTaskPythonWheelTaskResult(dict):
    def __init__(__self__, *,
                 entry_point: Optional[str] = None,
                 named_parameters: Optional[Mapping[str, str]] = None,
                 package_name: Optional[str] = None,
                 parameters: Optional[Sequence[str]] = None):
        if entry_point is not None:
            pulumi.set(__self__, "entry_point", entry_point)
        if named_parameters is not None:
            pulumi.set(__self__, "named_parameters", named_parameters)
        if package_name is not None:
            pulumi.set(__self__, "package_name", package_name)
        if parameters is not None:
            pulumi.set(__self__, "parameters", parameters)

    @property
    @pulumi.getter(name="entryPoint")
    def entry_point(self) -> Optional[str]:
        return pulumi.get(self, "entry_point")

    @property
    @pulumi.getter(name="namedParameters")
    def named_parameters(self) -> Optional[Mapping[str, str]]:
        return pulumi.get(self, "named_parameters")

    @property
    @pulumi.getter(name="packageName")
    def package_name(self) -> Optional[str]:
        return pulumi.get(self, "package_name")

    @property
    @pulumi.getter
    def parameters(self) -> Optional[Sequence[str]]:
        return pulumi.get(self, "parameters")


@pulumi.output_type
class GetJobJobSettingsSettingsTaskForEachTaskTaskRunJobTaskResult(dict):
    def __init__(__self__, *,
                 job_id: int,
                 job_parameters: Optional[Mapping[str, str]] = None):
        pulumi.set(__self__, "job_id", job_id)
        if job_parameters is not None:
            pulumi.set(__self__, "job_parameters", job_parameters)

    @property
    @pulumi.getter(name="jobId")
    def job_id(self) -> int:
        return pulumi.get(self, "job_id")

    @property
    @pulumi.getter(name="jobParameters")
    def job_parameters(self) -> Optional[Mapping[str, str]]:
        return pulumi.get(self, "job_parameters")


@pulumi.output_type
class GetJobJobSettingsSettingsTaskForEachTaskTaskSparkJarTaskResult(dict):
    def __init__(__self__, *,
                 jar_uri: Optional[str] = None,
                 main_class_name: Optional[str] = None,
                 parameters: Optional[Sequence[str]] = None):
        if jar_uri is not None:
            pulumi.set(__self__, "jar_uri", jar_uri)
        if main_class_name is not None:
            pulumi.set(__self__, "main_class_name", main_class_name)
        if parameters is not None:
            pulumi.set(__self__, "parameters", parameters)

    @property
    @pulumi.getter(name="jarUri")
    def jar_uri(self) -> Optional[str]:
        return pulumi.get(self, "jar_uri")

    @property
    @pulumi.getter(name="mainClassName")
    def main_class_name(self) -> Optional[str]:
        return pulumi.get(self, "main_class_name")

    @property
    @pulumi.getter
    def parameters(self) -> Optional[Sequence[str]]:
        return pulumi.get(self, "parameters")


@pulumi.output_type
class GetJobJobSettingsSettingsTaskForEachTaskTaskSparkPythonTaskResult(dict):
    def __init__(__self__, *,
                 python_file: str,
                 parameters: Optional[Sequence[str]] = None,
                 source: Optional[str] = None):
        pulumi.set(__self__, "python_file", python_file)
        if parameters is not None:
            pulumi.set(__self__, "parameters", parameters)
        if source is not None:
            pulumi.set(__self__, "source", source)

    @property
    @pulumi.getter(name="pythonFile")
    def python_file(self) -> str:
        return pulumi.get(self, "python_file")

    @property
    @pulumi.getter
    def parameters(self) -> Optional[Sequence[str]]:
        return pulumi.get(self, "parameters")

    @property
    @pulumi.getter
    def source(self) -> Optional[str]:
        return pulumi.get(self, "source")


@pulumi.output_type
class GetJobJobSettingsSettingsTaskForEachTaskTaskSparkSubmitTaskResult(dict):
    def __init__(__self__, *,
                 parameters: Optional[Sequence[str]] = None):
        if parameters is not None:
            pulumi.set(__self__, "parameters", parameters)

    @property
    @pulumi.getter
    def parameters(self) -> Optional[Sequence[str]]:
        return pulumi.get(self, "parameters")


@pulumi.output_type
class GetJobJobSettingsSettingsTaskForEachTaskTaskSqlTaskResult(dict):
    def __init__(__self__, *,
                 warehouse_id: str,
                 alert: Optional['outputs.GetJobJobSettingsSettingsTaskForEachTaskTaskSqlTaskAlertResult'] = None,
                 dashboard: Optional['outputs.GetJobJobSettingsSettingsTaskForEachTaskTaskSqlTaskDashboardResult'] = None,
                 file: Optional['outputs.GetJobJobSettingsSettingsTaskForEachTaskTaskSqlTaskFileResult'] = None,
                 parameters: Optional[Mapping[str, str]] = None,
                 query: Optional['outputs.GetJobJobSettingsSettingsTaskForEachTaskTaskSqlTaskQueryResult'] = None):
        pulumi.set(__self__, "warehouse_id", warehouse_id)
        if alert is not None:
            pulumi.set(__self__, "alert", alert)
        if dashboard is not None:
            pulumi.set(__self__, "dashboard", dashboard)
        if file is not None:
            pulumi.set(__self__, "file", file)
        if parameters is not None:
            pulumi.set(__self__, "parameters", parameters)
        if query is not None:
            pulumi.set(__self__, "query", query)

    @property
    @pulumi.getter(name="warehouseId")
    def warehouse_id(self) -> str:
        return pulumi.get(self, "warehouse_id")

    @property
    @pulumi.getter
    def alert(self) -> Optional['outputs.GetJobJobSettingsSettingsTaskForEachTaskTaskSqlTaskAlertResult']:
        return pulumi.get(self, "alert")

    @property
    @pulumi.getter
    def dashboard(self) -> Optional['outputs.GetJobJobSettingsSettingsTaskForEachTaskTaskSqlTaskDashboardResult']:
        return pulumi.get(self, "dashboard")

    @property
    @pulumi.getter
    def file(self) -> Optional['outputs.GetJobJobSettingsSettingsTaskForEachTaskTaskSqlTaskFileResult']:
        return pulumi.get(self, "file")

    @property
    @pulumi.getter
    def parameters(self) -> Optional[Mapping[str, str]]:
        return pulumi.get(self, "parameters")

    @property
    @pulumi.getter
    def query(self) -> Optional['outputs.GetJobJobSettingsSettingsTaskForEachTaskTaskSqlTaskQueryResult']:
        return pulumi.get(self, "query")


@pulumi.output_type
class GetJobJobSettingsSettingsTaskForEachTaskTaskSqlTaskAlertResult(dict):
    def __init__(__self__, *,
                 alert_id: str,
                 subscriptions: Sequence['outputs.GetJobJobSettingsSettingsTaskForEachTaskTaskSqlTaskAlertSubscriptionResult'],
                 pause_subscriptions: Optional[bool] = None):
        pulumi.set(__self__, "alert_id", alert_id)
        pulumi.set(__self__, "subscriptions", subscriptions)
        if pause_subscriptions is not None:
            pulumi.set(__self__, "pause_subscriptions", pause_subscriptions)

    @property
    @pulumi.getter(name="alertId")
    def alert_id(self) -> str:
        return pulumi.get(self, "alert_id")

    @property
    @pulumi.getter
    def subscriptions(self) -> Sequence['outputs.GetJobJobSettingsSettingsTaskForEachTaskTaskSqlTaskAlertSubscriptionResult']:
        return pulumi.get(self, "subscriptions")

    @property
    @pulumi.getter(name="pauseSubscriptions")
    def pause_subscriptions(self) -> Optional[bool]:
        return pulumi.get(self, "pause_subscriptions")


@pulumi.output_type
class GetJobJobSettingsSettingsTaskForEachTaskTaskSqlTaskAlertSubscriptionResult(dict):
    def __init__(__self__, *,
                 destination_id: Optional[str] = None,
                 user_name: Optional[str] = None):
        if destination_id is not None:
            pulumi.set(__self__, "destination_id", destination_id)
        if user_name is not None:
            pulumi.set(__self__, "user_name", user_name)

    @property
    @pulumi.getter(name="destinationId")
    def destination_id(self) -> Optional[str]:
        return pulumi.get(self, "destination_id")

    @property
    @pulumi.getter(name="userName")
    def user_name(self) -> Optional[str]:
        return pulumi.get(self, "user_name")


@pulumi.output_type
class GetJobJobSettingsSettingsTaskForEachTaskTaskSqlTaskDashboardResult(dict):
    def __init__(__self__, *,
                 dashboard_id: str,
                 custom_subject: Optional[str] = None,
                 pause_subscriptions: Optional[bool] = None,
                 subscriptions: Optional[Sequence['outputs.GetJobJobSettingsSettingsTaskForEachTaskTaskSqlTaskDashboardSubscriptionResult']] = None):
        pulumi.set(__self__, "dashboard_id", dashboard_id)
        if custom_subject is not None:
            pulumi.set(__self__, "custom_subject", custom_subject)
        if pause_subscriptions is not None:
            pulumi.set(__self__, "pause_subscriptions", pause_subscriptions)
        if subscriptions is not None:
            pulumi.set(__self__, "subscriptions", subscriptions)

    @property
    @pulumi.getter(name="dashboardId")
    def dashboard_id(self) -> str:
        return pulumi.get(self, "dashboard_id")

    @property
    @pulumi.getter(name="customSubject")
    def custom_subject(self) -> Optional[str]:
        return pulumi.get(self, "custom_subject")

    @property
    @pulumi.getter(name="pauseSubscriptions")
    def pause_subscriptions(self) -> Optional[bool]:
        return pulumi.get(self, "pause_subscriptions")

    @property
    @pulumi.getter
    def subscriptions(self) -> Optional[Sequence['outputs.GetJobJobSettingsSettingsTaskForEachTaskTaskSqlTaskDashboardSubscriptionResult']]:
        return pulumi.get(self, "subscriptions")


@pulumi.output_type
class GetJobJobSettingsSettingsTaskForEachTaskTaskSqlTaskDashboardSubscriptionResult(dict):
    def __init__(__self__, *,
                 destination_id: Optional[str] = None,
                 user_name: Optional[str] = None):
        if destination_id is not None:
            pulumi.set(__self__, "destination_id", destination_id)
        if user_name is not None:
            pulumi.set(__self__, "user_name", user_name)

    @property
    @pulumi.getter(name="destinationId")
    def destination_id(self) -> Optional[str]:
        return pulumi.get(self, "destination_id")

    @property
    @pulumi.getter(name="userName")
    def user_name(self) -> Optional[str]:
        return pulumi.get(self, "user_name")


@pulumi.output_type
class GetJobJobSettingsSettingsTaskForEachTaskTaskSqlTaskFileResult(dict):
    def __init__(__self__, *,
                 path: str,
                 source: Optional[str] = None):
        pulumi.set(__self__, "path", path)
        if source is not None:
            pulumi.set(__self__, "source", source)

    @property
    @pulumi.getter
    def path(self) -> str:
        return pulumi.get(self, "path")

    @property
    @pulumi.getter
    def source(self) -> Optional[str]:
        return pulumi.get(self, "source")


@pulumi.output_type
class GetJobJobSettingsSettingsTaskForEachTaskTaskSqlTaskQueryResult(dict):
    def __init__(__self__, *,
                 query_id: str):
        pulumi.set(__self__, "query_id", query_id)

    @property
    @pulumi.getter(name="queryId")
    def query_id(self) -> str:
        return pulumi.get(self, "query_id")


@pulumi.output_type
class GetJobJobSettingsSettingsTaskForEachTaskTaskWebhookNotificationsResult(dict):
    def __init__(__self__, *,
                 on_duration_warning_threshold_exceededs: Optional[Sequence['outputs.GetJobJobSettingsSettingsTaskForEachTaskTaskWebhookNotificationsOnDurationWarningThresholdExceededResult']] = None,
                 on_failures: Optional[Sequence['outputs.GetJobJobSettingsSettingsTaskForEachTaskTaskWebhookNotificationsOnFailureResult']] = None,
                 on_starts: Optional[Sequence['outputs.GetJobJobSettingsSettingsTaskForEachTaskTaskWebhookNotificationsOnStartResult']] = None,
                 on_streaming_backlog_exceededs: Optional[Sequence['outputs.GetJobJobSettingsSettingsTaskForEachTaskTaskWebhookNotificationsOnStreamingBacklogExceededResult']] = None,
                 on_successes: Optional[Sequence['outputs.GetJobJobSettingsSettingsTaskForEachTaskTaskWebhookNotificationsOnSuccessResult']] = None):
        if on_duration_warning_threshold_exceededs is not None:
            pulumi.set(__self__, "on_duration_warning_threshold_exceededs", on_duration_warning_threshold_exceededs)
        if on_failures is not None:
            pulumi.set(__self__, "on_failures", on_failures)
        if on_starts is not None:
            pulumi.set(__self__, "on_starts", on_starts)
        if on_streaming_backlog_exceededs is not None:
            pulumi.set(__self__, "on_streaming_backlog_exceededs", on_streaming_backlog_exceededs)
        if on_successes is not None:
            pulumi.set(__self__, "on_successes", on_successes)

    @property
    @pulumi.getter(name="onDurationWarningThresholdExceededs")
    def on_duration_warning_threshold_exceededs(self) -> Optional[Sequence['outputs.GetJobJobSettingsSettingsTaskForEachTaskTaskWebhookNotificationsOnDurationWarningThresholdExceededResult']]:
        return pulumi.get(self, "on_duration_warning_threshold_exceededs")

    @property
    @pulumi.getter(name="onFailures")
    def on_failures(self) -> Optional[Sequence['outputs.GetJobJobSettingsSettingsTaskForEachTaskTaskWebhookNotificationsOnFailureResult']]:
        return pulumi.get(self, "on_failures")

    @property
    @pulumi.getter(name="onStarts")
    def on_starts(self) -> Optional[Sequence['outputs.GetJobJobSettingsSettingsTaskForEachTaskTaskWebhookNotificationsOnStartResult']]:
        return pulumi.get(self, "on_starts")

    @property
    @pulumi.getter(name="onStreamingBacklogExceededs")
    def on_streaming_backlog_exceededs(self) -> Optional[Sequence['outputs.GetJobJobSettingsSettingsTaskForEachTaskTaskWebhookNotificationsOnStreamingBacklogExceededResult']]:
        return pulumi.get(self, "on_streaming_backlog_exceededs")

    @property
    @pulumi.getter(name="onSuccesses")
    def on_successes(self) -> Optional[Sequence['outputs.GetJobJobSettingsSettingsTaskForEachTaskTaskWebhookNotificationsOnSuccessResult']]:
        return pulumi.get(self, "on_successes")


@pulumi.output_type
class GetJobJobSettingsSettingsTaskForEachTaskTaskWebhookNotificationsOnDurationWarningThresholdExceededResult(dict):
    def __init__(__self__, *,
                 id: str):
        """
        :param str id: the id of Job if the resource was matched by name.
        """
        pulumi.set(__self__, "id", id)

    @property
    @pulumi.getter
    def id(self) -> str:
        """
        the id of Job if the resource was matched by name.
        """
        return pulumi.get(self, "id")


@pulumi.output_type
class GetJobJobSettingsSettingsTaskForEachTaskTaskWebhookNotificationsOnFailureResult(dict):
    def __init__(__self__, *,
                 id: str):
        """
        :param str id: the id of Job if the resource was matched by name.
        """
        pulumi.set(__self__, "id", id)

    @property
    @pulumi.getter
    def id(self) -> str:
        """
        the id of Job if the resource was matched by name.
        """
        return pulumi.get(self, "id")


@pulumi.output_type
class GetJobJobSettingsSettingsTaskForEachTaskTaskWebhookNotificationsOnStartResult(dict):
    def __init__(__self__, *,
                 id: str):
        """
        :param str id: the id of Job if the resource was matched by name.
        """
        pulumi.set(__self__, "id", id)

    @property
    @pulumi.getter
    def id(self) -> str:
        """
        the id of Job if the resource was matched by name.
        """
        return pulumi.get(self, "id")


@pulumi.output_type
class GetJobJobSettingsSettingsTaskForEachTaskTaskWebhookNotificationsOnStreamingBacklogExceededResult(dict):
    def __init__(__self__, *,
                 id: str):
        """
        :param str id: the id of Job if the resource was matched by name.
        """
        pulumi.set(__self__, "id", id)

    @property
    @pulumi.getter
    def id(self) -> str:
        """
        the id of Job if the resource was matched by name.
        """
        return pulumi.get(self, "id")


@pulumi.output_type
class GetJobJobSettingsSettingsTaskForEachTaskTaskWebhookNotificationsOnSuccessResult(dict):
    def __init__(__self__, *,
                 id: str):
        """
        :param str id: the id of Job if the resource was matched by name.
        """
        pulumi.set(__self__, "id", id)

    @property
    @pulumi.getter
    def id(self) -> str:
        """
        the id of Job if the resource was matched by name.
        """
        return pulumi.get(self, "id")


@pulumi.output_type
class GetJobJobSettingsSettingsTaskHealthResult(dict):
    def __init__(__self__, *,
                 rules: Sequence['outputs.GetJobJobSettingsSettingsTaskHealthRuleResult']):
        pulumi.set(__self__, "rules", rules)

    @property
    @pulumi.getter
    def rules(self) -> Sequence['outputs.GetJobJobSettingsSettingsTaskHealthRuleResult']:
        return pulumi.get(self, "rules")


@pulumi.output_type
class GetJobJobSettingsSettingsTaskHealthRuleResult(dict):
    def __init__(__self__, *,
                 metric: str,
                 op: str,
                 value: int):
        pulumi.set(__self__, "metric", metric)
        pulumi.set(__self__, "op", op)
        pulumi.set(__self__, "value", value)

    @property
    @pulumi.getter
    def metric(self) -> str:
        return pulumi.get(self, "metric")

    @property
    @pulumi.getter
    def op(self) -> str:
        return pulumi.get(self, "op")

    @property
    @pulumi.getter
    def value(self) -> int:
        return pulumi.get(self, "value")


@pulumi.output_type
class GetJobJobSettingsSettingsTaskLibraryResult(dict):
    def __init__(__self__, *,
                 cran: Optional['outputs.GetJobJobSettingsSettingsTaskLibraryCranResult'] = None,
                 egg: Optional[str] = None,
                 jar: Optional[str] = None,
                 maven: Optional['outputs.GetJobJobSettingsSettingsTaskLibraryMavenResult'] = None,
                 pypi: Optional['outputs.GetJobJobSettingsSettingsTaskLibraryPypiResult'] = None,
                 requirements: Optional[str] = None,
                 whl: Optional[str] = None):
        if cran is not None:
            pulumi.set(__self__, "cran", cran)
        if egg is not None:
            pulumi.set(__self__, "egg", egg)
        if jar is not None:
            pulumi.set(__self__, "jar", jar)
        if maven is not None:
            pulumi.set(__self__, "maven", maven)
        if pypi is not None:
            pulumi.set(__self__, "pypi", pypi)
        if requirements is not None:
            pulumi.set(__self__, "requirements", requirements)
        if whl is not None:
            pulumi.set(__self__, "whl", whl)

    @property
    @pulumi.getter
    def cran(self) -> Optional['outputs.GetJobJobSettingsSettingsTaskLibraryCranResult']:
        return pulumi.get(self, "cran")

    @property
    @pulumi.getter
    def egg(self) -> Optional[str]:
        return pulumi.get(self, "egg")

    @property
    @pulumi.getter
    def jar(self) -> Optional[str]:
        return pulumi.get(self, "jar")

    @property
    @pulumi.getter
    def maven(self) -> Optional['outputs.GetJobJobSettingsSettingsTaskLibraryMavenResult']:
        return pulumi.get(self, "maven")

    @property
    @pulumi.getter
    def pypi(self) -> Optional['outputs.GetJobJobSettingsSettingsTaskLibraryPypiResult']:
        return pulumi.get(self, "pypi")

    @property
    @pulumi.getter
    def requirements(self) -> Optional[str]:
        return pulumi.get(self, "requirements")

    @property
    @pulumi.getter
    def whl(self) -> Optional[str]:
        return pulumi.get(self, "whl")


@pulumi.output_type
class GetJobJobSettingsSettingsTaskLibraryCranResult(dict):
    def __init__(__self__, *,
                 package: str,
                 repo: Optional[str] = None):
        pulumi.set(__self__, "package", package)
        if repo is not None:
            pulumi.set(__self__, "repo", repo)

    @property
    @pulumi.getter
    def package(self) -> str:
        return pulumi.get(self, "package")

    @property
    @pulumi.getter
    def repo(self) -> Optional[str]:
        return pulumi.get(self, "repo")


@pulumi.output_type
class GetJobJobSettingsSettingsTaskLibraryMavenResult(dict):
    def __init__(__self__, *,
                 coordinates: str,
                 exclusions: Optional[Sequence[str]] = None,
                 repo: Optional[str] = None):
        pulumi.set(__self__, "coordinates", coordinates)
        if exclusions is not None:
            pulumi.set(__self__, "exclusions", exclusions)
        if repo is not None:
            pulumi.set(__self__, "repo", repo)

    @property
    @pulumi.getter
    def coordinates(self) -> str:
        return pulumi.get(self, "coordinates")

    @property
    @pulumi.getter
    def exclusions(self) -> Optional[Sequence[str]]:
        return pulumi.get(self, "exclusions")

    @property
    @pulumi.getter
    def repo(self) -> Optional[str]:
        return pulumi.get(self, "repo")


@pulumi.output_type
class GetJobJobSettingsSettingsTaskLibraryPypiResult(dict):
    def __init__(__self__, *,
                 package: str,
                 repo: Optional[str] = None):
        pulumi.set(__self__, "package", package)
        if repo is not None:
            pulumi.set(__self__, "repo", repo)

    @property
    @pulumi.getter
    def package(self) -> str:
        return pulumi.get(self, "package")

    @property
    @pulumi.getter
    def repo(self) -> Optional[str]:
        return pulumi.get(self, "repo")


@pulumi.output_type
class GetJobJobSettingsSettingsTaskNewClusterResult(dict):
    def __init__(__self__, *,
                 driver_instance_pool_id: str,
                 driver_node_type_id: str,
                 enable_elastic_disk: bool,
                 enable_local_disk_encryption: bool,
                 node_type_id: str,
                 num_workers: int,
                 spark_version: str,
                 apply_policy_default_values: Optional[bool] = None,
                 autoscale: Optional['outputs.GetJobJobSettingsSettingsTaskNewClusterAutoscaleResult'] = None,
                 autotermination_minutes: Optional[int] = None,
                 aws_attributes: Optional['outputs.GetJobJobSettingsSettingsTaskNewClusterAwsAttributesResult'] = None,
                 azure_attributes: Optional['outputs.GetJobJobSettingsSettingsTaskNewClusterAzureAttributesResult'] = None,
                 cluster_id: Optional[str] = None,
                 cluster_log_conf: Optional['outputs.GetJobJobSettingsSettingsTaskNewClusterClusterLogConfResult'] = None,
                 cluster_mount_infos: Optional[Sequence['outputs.GetJobJobSettingsSettingsTaskNewClusterClusterMountInfoResult']] = None,
                 cluster_name: Optional[str] = None,
                 custom_tags: Optional[Mapping[str, str]] = None,
                 data_security_mode: Optional[str] = None,
                 docker_image: Optional['outputs.GetJobJobSettingsSettingsTaskNewClusterDockerImageResult'] = None,
                 gcp_attributes: Optional['outputs.GetJobJobSettingsSettingsTaskNewClusterGcpAttributesResult'] = None,
                 idempotency_token: Optional[str] = None,
                 init_scripts: Optional[Sequence['outputs.GetJobJobSettingsSettingsTaskNewClusterInitScriptResult']] = None,
                 instance_pool_id: Optional[str] = None,
                 policy_id: Optional[str] = None,
                 runtime_engine: Optional[str] = None,
                 single_user_name: Optional[str] = None,
                 spark_conf: Optional[Mapping[str, str]] = None,
                 spark_env_vars: Optional[Mapping[str, str]] = None,
                 ssh_public_keys: Optional[Sequence[str]] = None,
                 workload_type: Optional['outputs.GetJobJobSettingsSettingsTaskNewClusterWorkloadTypeResult'] = None):
        pulumi.set(__self__, "driver_instance_pool_id", driver_instance_pool_id)
        pulumi.set(__self__, "driver_node_type_id", driver_node_type_id)
        pulumi.set(__self__, "enable_elastic_disk", enable_elastic_disk)
        pulumi.set(__self__, "enable_local_disk_encryption", enable_local_disk_encryption)
        pulumi.set(__self__, "node_type_id", node_type_id)
        pulumi.set(__self__, "num_workers", num_workers)
        pulumi.set(__self__, "spark_version", spark_version)
        if apply_policy_default_values is not None:
            pulumi.set(__self__, "apply_policy_default_values", apply_policy_default_values)
        if autoscale is not None:
            pulumi.set(__self__, "autoscale", autoscale)
        if autotermination_minutes is not None:
            pulumi.set(__self__, "autotermination_minutes", autotermination_minutes)
        if aws_attributes is not None:
            pulumi.set(__self__, "aws_attributes", aws_attributes)
        if azure_attributes is not None:
            pulumi.set(__self__, "azure_attributes", azure_attributes)
        if cluster_id is not None:
            pulumi.set(__self__, "cluster_id", cluster_id)
        if cluster_log_conf is not None:
            pulumi.set(__self__, "cluster_log_conf", cluster_log_conf)
        if cluster_mount_infos is not None:
            pulumi.set(__self__, "cluster_mount_infos", cluster_mount_infos)
        if cluster_name is not None:
            pulumi.set(__self__, "cluster_name", cluster_name)
        if custom_tags is not None:
            pulumi.set(__self__, "custom_tags", custom_tags)
        if data_security_mode is not None:
            pulumi.set(__self__, "data_security_mode", data_security_mode)
        if docker_image is not None:
            pulumi.set(__self__, "docker_image", docker_image)
        if gcp_attributes is not None:
            pulumi.set(__self__, "gcp_attributes", gcp_attributes)
        if idempotency_token is not None:
            pulumi.set(__self__, "idempotency_token", idempotency_token)
        if init_scripts is not None:
            pulumi.set(__self__, "init_scripts", init_scripts)
        if instance_pool_id is not None:
            pulumi.set(__self__, "instance_pool_id", instance_pool_id)
        if policy_id is not None:
            pulumi.set(__self__, "policy_id", policy_id)
        if runtime_engine is not None:
            pulumi.set(__self__, "runtime_engine", runtime_engine)
        if single_user_name is not None:
            pulumi.set(__self__, "single_user_name", single_user_name)
        if spark_conf is not None:
            pulumi.set(__self__, "spark_conf", spark_conf)
        if spark_env_vars is not None:
            pulumi.set(__self__, "spark_env_vars", spark_env_vars)
        if ssh_public_keys is not None:
            pulumi.set(__self__, "ssh_public_keys", ssh_public_keys)
        if workload_type is not None:
            pulumi.set(__self__, "workload_type", workload_type)

    @property
    @pulumi.getter(name="driverInstancePoolId")
    def driver_instance_pool_id(self) -> str:
        return pulumi.get(self, "driver_instance_pool_id")

    @property
    @pulumi.getter(name="driverNodeTypeId")
    def driver_node_type_id(self) -> str:
        return pulumi.get(self, "driver_node_type_id")

    @property
    @pulumi.getter(name="enableElasticDisk")
    def enable_elastic_disk(self) -> bool:
        return pulumi.get(self, "enable_elastic_disk")

    @property
    @pulumi.getter(name="enableLocalDiskEncryption")
    def enable_local_disk_encryption(self) -> bool:
        return pulumi.get(self, "enable_local_disk_encryption")

    @property
    @pulumi.getter(name="nodeTypeId")
    def node_type_id(self) -> str:
        return pulumi.get(self, "node_type_id")

    @property
    @pulumi.getter(name="numWorkers")
    def num_workers(self) -> int:
        return pulumi.get(self, "num_workers")

    @property
    @pulumi.getter(name="sparkVersion")
    def spark_version(self) -> str:
        return pulumi.get(self, "spark_version")

    @property
    @pulumi.getter(name="applyPolicyDefaultValues")
    def apply_policy_default_values(self) -> Optional[bool]:
        return pulumi.get(self, "apply_policy_default_values")

    @property
    @pulumi.getter
    def autoscale(self) -> Optional['outputs.GetJobJobSettingsSettingsTaskNewClusterAutoscaleResult']:
        return pulumi.get(self, "autoscale")

    @property
    @pulumi.getter(name="autoterminationMinutes")
    def autotermination_minutes(self) -> Optional[int]:
        return pulumi.get(self, "autotermination_minutes")

    @property
    @pulumi.getter(name="awsAttributes")
    def aws_attributes(self) -> Optional['outputs.GetJobJobSettingsSettingsTaskNewClusterAwsAttributesResult']:
        return pulumi.get(self, "aws_attributes")

    @property
    @pulumi.getter(name="azureAttributes")
    def azure_attributes(self) -> Optional['outputs.GetJobJobSettingsSettingsTaskNewClusterAzureAttributesResult']:
        return pulumi.get(self, "azure_attributes")

    @property
    @pulumi.getter(name="clusterId")
    def cluster_id(self) -> Optional[str]:
        return pulumi.get(self, "cluster_id")

    @property
    @pulumi.getter(name="clusterLogConf")
    def cluster_log_conf(self) -> Optional['outputs.GetJobJobSettingsSettingsTaskNewClusterClusterLogConfResult']:
        return pulumi.get(self, "cluster_log_conf")

    @property
    @pulumi.getter(name="clusterMountInfos")
    def cluster_mount_infos(self) -> Optional[Sequence['outputs.GetJobJobSettingsSettingsTaskNewClusterClusterMountInfoResult']]:
        return pulumi.get(self, "cluster_mount_infos")

    @property
    @pulumi.getter(name="clusterName")
    def cluster_name(self) -> Optional[str]:
        return pulumi.get(self, "cluster_name")

    @property
    @pulumi.getter(name="customTags")
    def custom_tags(self) -> Optional[Mapping[str, str]]:
        return pulumi.get(self, "custom_tags")

    @property
    @pulumi.getter(name="dataSecurityMode")
    def data_security_mode(self) -> Optional[str]:
        return pulumi.get(self, "data_security_mode")

    @property
    @pulumi.getter(name="dockerImage")
    def docker_image(self) -> Optional['outputs.GetJobJobSettingsSettingsTaskNewClusterDockerImageResult']:
        return pulumi.get(self, "docker_image")

    @property
    @pulumi.getter(name="gcpAttributes")
    def gcp_attributes(self) -> Optional['outputs.GetJobJobSettingsSettingsTaskNewClusterGcpAttributesResult']:
        return pulumi.get(self, "gcp_attributes")

    @property
    @pulumi.getter(name="idempotencyToken")
    def idempotency_token(self) -> Optional[str]:
        return pulumi.get(self, "idempotency_token")

    @property
    @pulumi.getter(name="initScripts")
    def init_scripts(self) -> Optional[Sequence['outputs.GetJobJobSettingsSettingsTaskNewClusterInitScriptResult']]:
        return pulumi.get(self, "init_scripts")

    @property
    @pulumi.getter(name="instancePoolId")
    def instance_pool_id(self) -> Optional[str]:
        return pulumi.get(self, "instance_pool_id")

    @property
    @pulumi.getter(name="policyId")
    def policy_id(self) -> Optional[str]:
        return pulumi.get(self, "policy_id")

    @property
    @pulumi.getter(name="runtimeEngine")
    def runtime_engine(self) -> Optional[str]:
        return pulumi.get(self, "runtime_engine")

    @property
    @pulumi.getter(name="singleUserName")
    def single_user_name(self) -> Optional[str]:
        return pulumi.get(self, "single_user_name")

    @property
    @pulumi.getter(name="sparkConf")
    def spark_conf(self) -> Optional[Mapping[str, str]]:
        return pulumi.get(self, "spark_conf")

    @property
    @pulumi.getter(name="sparkEnvVars")
    def spark_env_vars(self) -> Optional[Mapping[str, str]]:
        return pulumi.get(self, "spark_env_vars")

    @property
    @pulumi.getter(name="sshPublicKeys")
    def ssh_public_keys(self) -> Optional[Sequence[str]]:
        return pulumi.get(self, "ssh_public_keys")

    @property
    @pulumi.getter(name="workloadType")
    def workload_type(self) -> Optional['outputs.GetJobJobSettingsSettingsTaskNewClusterWorkloadTypeResult']:
        return pulumi.get(self, "workload_type")


@pulumi.output_type
class GetJobJobSettingsSettingsTaskNewClusterAutoscaleResult(dict):
    def __init__(__self__, *,
                 max_workers: Optional[int] = None,
                 min_workers: Optional[int] = None):
        if max_workers is not None:
            pulumi.set(__self__, "max_workers", max_workers)
        if min_workers is not None:
            pulumi.set(__self__, "min_workers", min_workers)

    @property
    @pulumi.getter(name="maxWorkers")
    def max_workers(self) -> Optional[int]:
        return pulumi.get(self, "max_workers")

    @property
    @pulumi.getter(name="minWorkers")
    def min_workers(self) -> Optional[int]:
        return pulumi.get(self, "min_workers")


@pulumi.output_type
class GetJobJobSettingsSettingsTaskNewClusterAwsAttributesResult(dict):
    def __init__(__self__, *,
                 availability: Optional[str] = None,
                 ebs_volume_count: Optional[int] = None,
                 ebs_volume_size: Optional[int] = None,
                 ebs_volume_type: Optional[str] = None,
                 first_on_demand: Optional[int] = None,
                 instance_profile_arn: Optional[str] = None,
                 spot_bid_price_percent: Optional[int] = None,
                 zone_id: Optional[str] = None):
        if availability is not None:
            pulumi.set(__self__, "availability", availability)
        if ebs_volume_count is not None:
            pulumi.set(__self__, "ebs_volume_count", ebs_volume_count)
        if ebs_volume_size is not None:
            pulumi.set(__self__, "ebs_volume_size", ebs_volume_size)
        if ebs_volume_type is not None:
            pulumi.set(__self__, "ebs_volume_type", ebs_volume_type)
        if first_on_demand is not None:
            pulumi.set(__self__, "first_on_demand", first_on_demand)
        if instance_profile_arn is not None:
            pulumi.set(__self__, "instance_profile_arn", instance_profile_arn)
        if spot_bid_price_percent is not None:
            pulumi.set(__self__, "spot_bid_price_percent", spot_bid_price_percent)
        if zone_id is not None:
            pulumi.set(__self__, "zone_id", zone_id)

    @property
    @pulumi.getter
    def availability(self) -> Optional[str]:
        return pulumi.get(self, "availability")

    @property
    @pulumi.getter(name="ebsVolumeCount")
    def ebs_volume_count(self) -> Optional[int]:
        return pulumi.get(self, "ebs_volume_count")

    @property
    @pulumi.getter(name="ebsVolumeSize")
    def ebs_volume_size(self) -> Optional[int]:
        return pulumi.get(self, "ebs_volume_size")

    @property
    @pulumi.getter(name="ebsVolumeType")
    def ebs_volume_type(self) -> Optional[str]:
        return pulumi.get(self, "ebs_volume_type")

    @property
    @pulumi.getter(name="firstOnDemand")
    def first_on_demand(self) -> Optional[int]:
        return pulumi.get(self, "first_on_demand")

    @property
    @pulumi.getter(name="instanceProfileArn")
    def instance_profile_arn(self) -> Optional[str]:
        return pulumi.get(self, "instance_profile_arn")

    @property
    @pulumi.getter(name="spotBidPricePercent")
    def spot_bid_price_percent(self) -> Optional[int]:
        return pulumi.get(self, "spot_bid_price_percent")

    @property
    @pulumi.getter(name="zoneId")
    def zone_id(self) -> Optional[str]:
        return pulumi.get(self, "zone_id")


@pulumi.output_type
class GetJobJobSettingsSettingsTaskNewClusterAzureAttributesResult(dict):
    def __init__(__self__, *,
                 availability: Optional[str] = None,
                 first_on_demand: Optional[int] = None,
                 spot_bid_max_price: Optional[float] = None):
        if availability is not None:
            pulumi.set(__self__, "availability", availability)
        if first_on_demand is not None:
            pulumi.set(__self__, "first_on_demand", first_on_demand)
        if spot_bid_max_price is not None:
            pulumi.set(__self__, "spot_bid_max_price", spot_bid_max_price)

    @property
    @pulumi.getter
    def availability(self) -> Optional[str]:
        return pulumi.get(self, "availability")

    @property
    @pulumi.getter(name="firstOnDemand")
    def first_on_demand(self) -> Optional[int]:
        return pulumi.get(self, "first_on_demand")

    @property
    @pulumi.getter(name="spotBidMaxPrice")
    def spot_bid_max_price(self) -> Optional[float]:
        return pulumi.get(self, "spot_bid_max_price")


@pulumi.output_type
class GetJobJobSettingsSettingsTaskNewClusterClusterLogConfResult(dict):
    def __init__(__self__, *,
                 dbfs: Optional['outputs.GetJobJobSettingsSettingsTaskNewClusterClusterLogConfDbfsResult'] = None,
                 s3: Optional['outputs.GetJobJobSettingsSettingsTaskNewClusterClusterLogConfS3Result'] = None):
        if dbfs is not None:
            pulumi.set(__self__, "dbfs", dbfs)
        if s3 is not None:
            pulumi.set(__self__, "s3", s3)

    @property
    @pulumi.getter
    def dbfs(self) -> Optional['outputs.GetJobJobSettingsSettingsTaskNewClusterClusterLogConfDbfsResult']:
        return pulumi.get(self, "dbfs")

    @property
    @pulumi.getter
    def s3(self) -> Optional['outputs.GetJobJobSettingsSettingsTaskNewClusterClusterLogConfS3Result']:
        return pulumi.get(self, "s3")


@pulumi.output_type
class GetJobJobSettingsSettingsTaskNewClusterClusterLogConfDbfsResult(dict):
    def __init__(__self__, *,
                 destination: str):
        pulumi.set(__self__, "destination", destination)

    @property
    @pulumi.getter
    def destination(self) -> str:
        return pulumi.get(self, "destination")


@pulumi.output_type
class GetJobJobSettingsSettingsTaskNewClusterClusterLogConfS3Result(dict):
    def __init__(__self__, *,
                 destination: str,
                 canned_acl: Optional[str] = None,
                 enable_encryption: Optional[bool] = None,
                 encryption_type: Optional[str] = None,
                 endpoint: Optional[str] = None,
                 kms_key: Optional[str] = None,
                 region: Optional[str] = None):
        pulumi.set(__self__, "destination", destination)
        if canned_acl is not None:
            pulumi.set(__self__, "canned_acl", canned_acl)
        if enable_encryption is not None:
            pulumi.set(__self__, "enable_encryption", enable_encryption)
        if encryption_type is not None:
            pulumi.set(__self__, "encryption_type", encryption_type)
        if endpoint is not None:
            pulumi.set(__self__, "endpoint", endpoint)
        if kms_key is not None:
            pulumi.set(__self__, "kms_key", kms_key)
        if region is not None:
            pulumi.set(__self__, "region", region)

    @property
    @pulumi.getter
    def destination(self) -> str:
        return pulumi.get(self, "destination")

    @property
    @pulumi.getter(name="cannedAcl")
    def canned_acl(self) -> Optional[str]:
        return pulumi.get(self, "canned_acl")

    @property
    @pulumi.getter(name="enableEncryption")
    def enable_encryption(self) -> Optional[bool]:
        return pulumi.get(self, "enable_encryption")

    @property
    @pulumi.getter(name="encryptionType")
    def encryption_type(self) -> Optional[str]:
        return pulumi.get(self, "encryption_type")

    @property
    @pulumi.getter
    def endpoint(self) -> Optional[str]:
        return pulumi.get(self, "endpoint")

    @property
    @pulumi.getter(name="kmsKey")
    def kms_key(self) -> Optional[str]:
        return pulumi.get(self, "kms_key")

    @property
    @pulumi.getter
    def region(self) -> Optional[str]:
        return pulumi.get(self, "region")


@pulumi.output_type
class GetJobJobSettingsSettingsTaskNewClusterClusterMountInfoResult(dict):
    def __init__(__self__, *,
                 local_mount_dir_path: str,
                 network_filesystem_info: 'outputs.GetJobJobSettingsSettingsTaskNewClusterClusterMountInfoNetworkFilesystemInfoResult',
                 remote_mount_dir_path: Optional[str] = None):
        pulumi.set(__self__, "local_mount_dir_path", local_mount_dir_path)
        pulumi.set(__self__, "network_filesystem_info", network_filesystem_info)
        if remote_mount_dir_path is not None:
            pulumi.set(__self__, "remote_mount_dir_path", remote_mount_dir_path)

    @property
    @pulumi.getter(name="localMountDirPath")
    def local_mount_dir_path(self) -> str:
        return pulumi.get(self, "local_mount_dir_path")

    @property
    @pulumi.getter(name="networkFilesystemInfo")
    def network_filesystem_info(self) -> 'outputs.GetJobJobSettingsSettingsTaskNewClusterClusterMountInfoNetworkFilesystemInfoResult':
        return pulumi.get(self, "network_filesystem_info")

    @property
    @pulumi.getter(name="remoteMountDirPath")
    def remote_mount_dir_path(self) -> Optional[str]:
        return pulumi.get(self, "remote_mount_dir_path")


@pulumi.output_type
class GetJobJobSettingsSettingsTaskNewClusterClusterMountInfoNetworkFilesystemInfoResult(dict):
    def __init__(__self__, *,
                 server_address: str,
                 mount_options: Optional[str] = None):
        pulumi.set(__self__, "server_address", server_address)
        if mount_options is not None:
            pulumi.set(__self__, "mount_options", mount_options)

    @property
    @pulumi.getter(name="serverAddress")
    def server_address(self) -> str:
        return pulumi.get(self, "server_address")

    @property
    @pulumi.getter(name="mountOptions")
    def mount_options(self) -> Optional[str]:
        return pulumi.get(self, "mount_options")


@pulumi.output_type
class GetJobJobSettingsSettingsTaskNewClusterDockerImageResult(dict):
    def __init__(__self__, *,
                 url: str,
                 basic_auth: Optional['outputs.GetJobJobSettingsSettingsTaskNewClusterDockerImageBasicAuthResult'] = None):
        pulumi.set(__self__, "url", url)
        if basic_auth is not None:
            pulumi.set(__self__, "basic_auth", basic_auth)

    @property
    @pulumi.getter
    def url(self) -> str:
        return pulumi.get(self, "url")

    @property
    @pulumi.getter(name="basicAuth")
    def basic_auth(self) -> Optional['outputs.GetJobJobSettingsSettingsTaskNewClusterDockerImageBasicAuthResult']:
        return pulumi.get(self, "basic_auth")


@pulumi.output_type
class GetJobJobSettingsSettingsTaskNewClusterDockerImageBasicAuthResult(dict):
    def __init__(__self__, *,
                 password: str,
                 username: str):
        pulumi.set(__self__, "password", password)
        pulumi.set(__self__, "username", username)

    @property
    @pulumi.getter
    def password(self) -> str:
        return pulumi.get(self, "password")

    @property
    @pulumi.getter
    def username(self) -> str:
        return pulumi.get(self, "username")


@pulumi.output_type
class GetJobJobSettingsSettingsTaskNewClusterGcpAttributesResult(dict):
    def __init__(__self__, *,
                 availability: Optional[str] = None,
                 boot_disk_size: Optional[int] = None,
                 google_service_account: Optional[str] = None,
                 local_ssd_count: Optional[int] = None,
                 use_preemptible_executors: Optional[bool] = None,
                 zone_id: Optional[str] = None):
        if availability is not None:
            pulumi.set(__self__, "availability", availability)
        if boot_disk_size is not None:
            pulumi.set(__self__, "boot_disk_size", boot_disk_size)
        if google_service_account is not None:
            pulumi.set(__self__, "google_service_account", google_service_account)
        if local_ssd_count is not None:
            pulumi.set(__self__, "local_ssd_count", local_ssd_count)
        if use_preemptible_executors is not None:
            pulumi.set(__self__, "use_preemptible_executors", use_preemptible_executors)
        if zone_id is not None:
            pulumi.set(__self__, "zone_id", zone_id)

    @property
    @pulumi.getter
    def availability(self) -> Optional[str]:
        return pulumi.get(self, "availability")

    @property
    @pulumi.getter(name="bootDiskSize")
    def boot_disk_size(self) -> Optional[int]:
        return pulumi.get(self, "boot_disk_size")

    @property
    @pulumi.getter(name="googleServiceAccount")
    def google_service_account(self) -> Optional[str]:
        return pulumi.get(self, "google_service_account")

    @property
    @pulumi.getter(name="localSsdCount")
    def local_ssd_count(self) -> Optional[int]:
        return pulumi.get(self, "local_ssd_count")

    @property
    @pulumi.getter(name="usePreemptibleExecutors")
    def use_preemptible_executors(self) -> Optional[bool]:
        return pulumi.get(self, "use_preemptible_executors")

    @property
    @pulumi.getter(name="zoneId")
    def zone_id(self) -> Optional[str]:
        return pulumi.get(self, "zone_id")


@pulumi.output_type
class GetJobJobSettingsSettingsTaskNewClusterInitScriptResult(dict):
    def __init__(__self__, *,
                 abfss: Optional['outputs.GetJobJobSettingsSettingsTaskNewClusterInitScriptAbfssResult'] = None,
                 dbfs: Optional['outputs.GetJobJobSettingsSettingsTaskNewClusterInitScriptDbfsResult'] = None,
                 file: Optional['outputs.GetJobJobSettingsSettingsTaskNewClusterInitScriptFileResult'] = None,
                 gcs: Optional['outputs.GetJobJobSettingsSettingsTaskNewClusterInitScriptGcsResult'] = None,
                 s3: Optional['outputs.GetJobJobSettingsSettingsTaskNewClusterInitScriptS3Result'] = None,
                 volumes: Optional['outputs.GetJobJobSettingsSettingsTaskNewClusterInitScriptVolumesResult'] = None,
                 workspace: Optional['outputs.GetJobJobSettingsSettingsTaskNewClusterInitScriptWorkspaceResult'] = None):
        if abfss is not None:
            pulumi.set(__self__, "abfss", abfss)
        if dbfs is not None:
            pulumi.set(__self__, "dbfs", dbfs)
        if file is not None:
            pulumi.set(__self__, "file", file)
        if gcs is not None:
            pulumi.set(__self__, "gcs", gcs)
        if s3 is not None:
            pulumi.set(__self__, "s3", s3)
        if volumes is not None:
            pulumi.set(__self__, "volumes", volumes)
        if workspace is not None:
            pulumi.set(__self__, "workspace", workspace)

    @property
    @pulumi.getter
    def abfss(self) -> Optional['outputs.GetJobJobSettingsSettingsTaskNewClusterInitScriptAbfssResult']:
        return pulumi.get(self, "abfss")

    @property
    @pulumi.getter
    def dbfs(self) -> Optional['outputs.GetJobJobSettingsSettingsTaskNewClusterInitScriptDbfsResult']:
        return pulumi.get(self, "dbfs")

    @property
    @pulumi.getter
    def file(self) -> Optional['outputs.GetJobJobSettingsSettingsTaskNewClusterInitScriptFileResult']:
        return pulumi.get(self, "file")

    @property
    @pulumi.getter
    def gcs(self) -> Optional['outputs.GetJobJobSettingsSettingsTaskNewClusterInitScriptGcsResult']:
        return pulumi.get(self, "gcs")

    @property
    @pulumi.getter
    def s3(self) -> Optional['outputs.GetJobJobSettingsSettingsTaskNewClusterInitScriptS3Result']:
        return pulumi.get(self, "s3")

    @property
    @pulumi.getter
    def volumes(self) -> Optional['outputs.GetJobJobSettingsSettingsTaskNewClusterInitScriptVolumesResult']:
        return pulumi.get(self, "volumes")

    @property
    @pulumi.getter
    def workspace(self) -> Optional['outputs.GetJobJobSettingsSettingsTaskNewClusterInitScriptWorkspaceResult']:
        return pulumi.get(self, "workspace")


@pulumi.output_type
class GetJobJobSettingsSettingsTaskNewClusterInitScriptAbfssResult(dict):
    def __init__(__self__, *,
                 destination: str):
        pulumi.set(__self__, "destination", destination)

    @property
    @pulumi.getter
    def destination(self) -> str:
        return pulumi.get(self, "destination")


@pulumi.output_type
class GetJobJobSettingsSettingsTaskNewClusterInitScriptDbfsResult(dict):
    def __init__(__self__, *,
                 destination: str):
        pulumi.set(__self__, "destination", destination)

    @property
    @pulumi.getter
    def destination(self) -> str:
        return pulumi.get(self, "destination")


@pulumi.output_type
class GetJobJobSettingsSettingsTaskNewClusterInitScriptFileResult(dict):
    def __init__(__self__, *,
                 destination: str):
        pulumi.set(__self__, "destination", destination)

    @property
    @pulumi.getter
    def destination(self) -> str:
        return pulumi.get(self, "destination")


@pulumi.output_type
class GetJobJobSettingsSettingsTaskNewClusterInitScriptGcsResult(dict):
    def __init__(__self__, *,
                 destination: str):
        pulumi.set(__self__, "destination", destination)

    @property
    @pulumi.getter
    def destination(self) -> str:
        return pulumi.get(self, "destination")


@pulumi.output_type
class GetJobJobSettingsSettingsTaskNewClusterInitScriptS3Result(dict):
    def __init__(__self__, *,
                 destination: str,
                 canned_acl: Optional[str] = None,
                 enable_encryption: Optional[bool] = None,
                 encryption_type: Optional[str] = None,
                 endpoint: Optional[str] = None,
                 kms_key: Optional[str] = None,
                 region: Optional[str] = None):
        pulumi.set(__self__, "destination", destination)
        if canned_acl is not None:
            pulumi.set(__self__, "canned_acl", canned_acl)
        if enable_encryption is not None:
            pulumi.set(__self__, "enable_encryption", enable_encryption)
        if encryption_type is not None:
            pulumi.set(__self__, "encryption_type", encryption_type)
        if endpoint is not None:
            pulumi.set(__self__, "endpoint", endpoint)
        if kms_key is not None:
            pulumi.set(__self__, "kms_key", kms_key)
        if region is not None:
            pulumi.set(__self__, "region", region)

    @property
    @pulumi.getter
    def destination(self) -> str:
        return pulumi.get(self, "destination")

    @property
    @pulumi.getter(name="cannedAcl")
    def canned_acl(self) -> Optional[str]:
        return pulumi.get(self, "canned_acl")

    @property
    @pulumi.getter(name="enableEncryption")
    def enable_encryption(self) -> Optional[bool]:
        return pulumi.get(self, "enable_encryption")

    @property
    @pulumi.getter(name="encryptionType")
    def encryption_type(self) -> Optional[str]:
        return pulumi.get(self, "encryption_type")

    @property
    @pulumi.getter
    def endpoint(self) -> Optional[str]:
        return pulumi.get(self, "endpoint")

    @property
    @pulumi.getter(name="kmsKey")
    def kms_key(self) -> Optional[str]:
        return pulumi.get(self, "kms_key")

    @property
    @pulumi.getter
    def region(self) -> Optional[str]:
        return pulumi.get(self, "region")


@pulumi.output_type
class GetJobJobSettingsSettingsTaskNewClusterInitScriptVolumesResult(dict):
    def __init__(__self__, *,
                 destination: str):
        pulumi.set(__self__, "destination", destination)

    @property
    @pulumi.getter
    def destination(self) -> str:
        return pulumi.get(self, "destination")


@pulumi.output_type
class GetJobJobSettingsSettingsTaskNewClusterInitScriptWorkspaceResult(dict):
    def __init__(__self__, *,
                 destination: str):
        pulumi.set(__self__, "destination", destination)

    @property
    @pulumi.getter
    def destination(self) -> str:
        return pulumi.get(self, "destination")


@pulumi.output_type
class GetJobJobSettingsSettingsTaskNewClusterWorkloadTypeResult(dict):
    def __init__(__self__, *,
                 clients: 'outputs.GetJobJobSettingsSettingsTaskNewClusterWorkloadTypeClientsResult'):
        pulumi.set(__self__, "clients", clients)

    @property
    @pulumi.getter
    def clients(self) -> 'outputs.GetJobJobSettingsSettingsTaskNewClusterWorkloadTypeClientsResult':
        return pulumi.get(self, "clients")


@pulumi.output_type
class GetJobJobSettingsSettingsTaskNewClusterWorkloadTypeClientsResult(dict):
    def __init__(__self__, *,
                 jobs: Optional[bool] = None,
                 notebooks: Optional[bool] = None):
        if jobs is not None:
            pulumi.set(__self__, "jobs", jobs)
        if notebooks is not None:
            pulumi.set(__self__, "notebooks", notebooks)

    @property
    @pulumi.getter
    def jobs(self) -> Optional[bool]:
        return pulumi.get(self, "jobs")

    @property
    @pulumi.getter
    def notebooks(self) -> Optional[bool]:
        return pulumi.get(self, "notebooks")


@pulumi.output_type
class GetJobJobSettingsSettingsTaskNotebookTaskResult(dict):
    def __init__(__self__, *,
                 notebook_path: str,
                 base_parameters: Optional[Mapping[str, str]] = None,
                 source: Optional[str] = None,
                 warehouse_id: Optional[str] = None):
        pulumi.set(__self__, "notebook_path", notebook_path)
        if base_parameters is not None:
            pulumi.set(__self__, "base_parameters", base_parameters)
        if source is not None:
            pulumi.set(__self__, "source", source)
        if warehouse_id is not None:
            pulumi.set(__self__, "warehouse_id", warehouse_id)

    @property
    @pulumi.getter(name="notebookPath")
    def notebook_path(self) -> str:
        return pulumi.get(self, "notebook_path")

    @property
    @pulumi.getter(name="baseParameters")
    def base_parameters(self) -> Optional[Mapping[str, str]]:
        return pulumi.get(self, "base_parameters")

    @property
    @pulumi.getter
    def source(self) -> Optional[str]:
        return pulumi.get(self, "source")

    @property
    @pulumi.getter(name="warehouseId")
    def warehouse_id(self) -> Optional[str]:
        return pulumi.get(self, "warehouse_id")


@pulumi.output_type
class GetJobJobSettingsSettingsTaskNotificationSettingsResult(dict):
    def __init__(__self__, *,
                 alert_on_last_attempt: Optional[bool] = None,
                 no_alert_for_canceled_runs: Optional[bool] = None,
                 no_alert_for_skipped_runs: Optional[bool] = None):
        if alert_on_last_attempt is not None:
            pulumi.set(__self__, "alert_on_last_attempt", alert_on_last_attempt)
        if no_alert_for_canceled_runs is not None:
            pulumi.set(__self__, "no_alert_for_canceled_runs", no_alert_for_canceled_runs)
        if no_alert_for_skipped_runs is not None:
            pulumi.set(__self__, "no_alert_for_skipped_runs", no_alert_for_skipped_runs)

    @property
    @pulumi.getter(name="alertOnLastAttempt")
    def alert_on_last_attempt(self) -> Optional[bool]:
        return pulumi.get(self, "alert_on_last_attempt")

    @property
    @pulumi.getter(name="noAlertForCanceledRuns")
    def no_alert_for_canceled_runs(self) -> Optional[bool]:
        return pulumi.get(self, "no_alert_for_canceled_runs")

    @property
    @pulumi.getter(name="noAlertForSkippedRuns")
    def no_alert_for_skipped_runs(self) -> Optional[bool]:
        return pulumi.get(self, "no_alert_for_skipped_runs")


@pulumi.output_type
class GetJobJobSettingsSettingsTaskPipelineTaskResult(dict):
    def __init__(__self__, *,
                 pipeline_id: str,
                 full_refresh: Optional[bool] = None):
        pulumi.set(__self__, "pipeline_id", pipeline_id)
        if full_refresh is not None:
            pulumi.set(__self__, "full_refresh", full_refresh)

    @property
    @pulumi.getter(name="pipelineId")
    def pipeline_id(self) -> str:
        return pulumi.get(self, "pipeline_id")

    @property
    @pulumi.getter(name="fullRefresh")
    def full_refresh(self) -> Optional[bool]:
        return pulumi.get(self, "full_refresh")


@pulumi.output_type
class GetJobJobSettingsSettingsTaskPythonWheelTaskResult(dict):
    def __init__(__self__, *,
                 entry_point: Optional[str] = None,
                 named_parameters: Optional[Mapping[str, str]] = None,
                 package_name: Optional[str] = None,
                 parameters: Optional[Sequence[str]] = None):
        if entry_point is not None:
            pulumi.set(__self__, "entry_point", entry_point)
        if named_parameters is not None:
            pulumi.set(__self__, "named_parameters", named_parameters)
        if package_name is not None:
            pulumi.set(__self__, "package_name", package_name)
        if parameters is not None:
            pulumi.set(__self__, "parameters", parameters)

    @property
    @pulumi.getter(name="entryPoint")
    def entry_point(self) -> Optional[str]:
        return pulumi.get(self, "entry_point")

    @property
    @pulumi.getter(name="namedParameters")
    def named_parameters(self) -> Optional[Mapping[str, str]]:
        return pulumi.get(self, "named_parameters")

    @property
    @pulumi.getter(name="packageName")
    def package_name(self) -> Optional[str]:
        return pulumi.get(self, "package_name")

    @property
    @pulumi.getter
    def parameters(self) -> Optional[Sequence[str]]:
        return pulumi.get(self, "parameters")


@pulumi.output_type
class GetJobJobSettingsSettingsTaskRunJobTaskResult(dict):
    def __init__(__self__, *,
                 job_id: int,
                 job_parameters: Optional[Mapping[str, str]] = None):
        pulumi.set(__self__, "job_id", job_id)
        if job_parameters is not None:
            pulumi.set(__self__, "job_parameters", job_parameters)

    @property
    @pulumi.getter(name="jobId")
    def job_id(self) -> int:
        return pulumi.get(self, "job_id")

    @property
    @pulumi.getter(name="jobParameters")
    def job_parameters(self) -> Optional[Mapping[str, str]]:
        return pulumi.get(self, "job_parameters")


@pulumi.output_type
class GetJobJobSettingsSettingsTaskSparkJarTaskResult(dict):
    def __init__(__self__, *,
                 jar_uri: Optional[str] = None,
                 main_class_name: Optional[str] = None,
                 parameters: Optional[Sequence[str]] = None):
        if jar_uri is not None:
            pulumi.set(__self__, "jar_uri", jar_uri)
        if main_class_name is not None:
            pulumi.set(__self__, "main_class_name", main_class_name)
        if parameters is not None:
            pulumi.set(__self__, "parameters", parameters)

    @property
    @pulumi.getter(name="jarUri")
    def jar_uri(self) -> Optional[str]:
        return pulumi.get(self, "jar_uri")

    @property
    @pulumi.getter(name="mainClassName")
    def main_class_name(self) -> Optional[str]:
        return pulumi.get(self, "main_class_name")

    @property
    @pulumi.getter
    def parameters(self) -> Optional[Sequence[str]]:
        return pulumi.get(self, "parameters")


@pulumi.output_type
class GetJobJobSettingsSettingsTaskSparkPythonTaskResult(dict):
    def __init__(__self__, *,
                 python_file: str,
                 parameters: Optional[Sequence[str]] = None,
                 source: Optional[str] = None):
        pulumi.set(__self__, "python_file", python_file)
        if parameters is not None:
            pulumi.set(__self__, "parameters", parameters)
        if source is not None:
            pulumi.set(__self__, "source", source)

    @property
    @pulumi.getter(name="pythonFile")
    def python_file(self) -> str:
        return pulumi.get(self, "python_file")

    @property
    @pulumi.getter
    def parameters(self) -> Optional[Sequence[str]]:
        return pulumi.get(self, "parameters")

    @property
    @pulumi.getter
    def source(self) -> Optional[str]:
        return pulumi.get(self, "source")


@pulumi.output_type
class GetJobJobSettingsSettingsTaskSparkSubmitTaskResult(dict):
    def __init__(__self__, *,
                 parameters: Optional[Sequence[str]] = None):
        if parameters is not None:
            pulumi.set(__self__, "parameters", parameters)

    @property
    @pulumi.getter
    def parameters(self) -> Optional[Sequence[str]]:
        return pulumi.get(self, "parameters")


@pulumi.output_type
class GetJobJobSettingsSettingsTaskSqlTaskResult(dict):
    def __init__(__self__, *,
                 warehouse_id: str,
                 alert: Optional['outputs.GetJobJobSettingsSettingsTaskSqlTaskAlertResult'] = None,
                 dashboard: Optional['outputs.GetJobJobSettingsSettingsTaskSqlTaskDashboardResult'] = None,
                 file: Optional['outputs.GetJobJobSettingsSettingsTaskSqlTaskFileResult'] = None,
                 parameters: Optional[Mapping[str, str]] = None,
                 query: Optional['outputs.GetJobJobSettingsSettingsTaskSqlTaskQueryResult'] = None):
        pulumi.set(__self__, "warehouse_id", warehouse_id)
        if alert is not None:
            pulumi.set(__self__, "alert", alert)
        if dashboard is not None:
            pulumi.set(__self__, "dashboard", dashboard)
        if file is not None:
            pulumi.set(__self__, "file", file)
        if parameters is not None:
            pulumi.set(__self__, "parameters", parameters)
        if query is not None:
            pulumi.set(__self__, "query", query)

    @property
    @pulumi.getter(name="warehouseId")
    def warehouse_id(self) -> str:
        return pulumi.get(self, "warehouse_id")

    @property
    @pulumi.getter
    def alert(self) -> Optional['outputs.GetJobJobSettingsSettingsTaskSqlTaskAlertResult']:
        return pulumi.get(self, "alert")

    @property
    @pulumi.getter
    def dashboard(self) -> Optional['outputs.GetJobJobSettingsSettingsTaskSqlTaskDashboardResult']:
        return pulumi.get(self, "dashboard")

    @property
    @pulumi.getter
    def file(self) -> Optional['outputs.GetJobJobSettingsSettingsTaskSqlTaskFileResult']:
        return pulumi.get(self, "file")

    @property
    @pulumi.getter
    def parameters(self) -> Optional[Mapping[str, str]]:
        return pulumi.get(self, "parameters")

    @property
    @pulumi.getter
    def query(self) -> Optional['outputs.GetJobJobSettingsSettingsTaskSqlTaskQueryResult']:
        return pulumi.get(self, "query")


@pulumi.output_type
class GetJobJobSettingsSettingsTaskSqlTaskAlertResult(dict):
    def __init__(__self__, *,
                 alert_id: str,
                 subscriptions: Sequence['outputs.GetJobJobSettingsSettingsTaskSqlTaskAlertSubscriptionResult'],
                 pause_subscriptions: Optional[bool] = None):
        pulumi.set(__self__, "alert_id", alert_id)
        pulumi.set(__self__, "subscriptions", subscriptions)
        if pause_subscriptions is not None:
            pulumi.set(__self__, "pause_subscriptions", pause_subscriptions)

    @property
    @pulumi.getter(name="alertId")
    def alert_id(self) -> str:
        return pulumi.get(self, "alert_id")

    @property
    @pulumi.getter
    def subscriptions(self) -> Sequence['outputs.GetJobJobSettingsSettingsTaskSqlTaskAlertSubscriptionResult']:
        return pulumi.get(self, "subscriptions")

    @property
    @pulumi.getter(name="pauseSubscriptions")
    def pause_subscriptions(self) -> Optional[bool]:
        return pulumi.get(self, "pause_subscriptions")


@pulumi.output_type
class GetJobJobSettingsSettingsTaskSqlTaskAlertSubscriptionResult(dict):
    def __init__(__self__, *,
                 destination_id: Optional[str] = None,
                 user_name: Optional[str] = None):
        if destination_id is not None:
            pulumi.set(__self__, "destination_id", destination_id)
        if user_name is not None:
            pulumi.set(__self__, "user_name", user_name)

    @property
    @pulumi.getter(name="destinationId")
    def destination_id(self) -> Optional[str]:
        return pulumi.get(self, "destination_id")

    @property
    @pulumi.getter(name="userName")
    def user_name(self) -> Optional[str]:
        return pulumi.get(self, "user_name")


@pulumi.output_type
class GetJobJobSettingsSettingsTaskSqlTaskDashboardResult(dict):
    def __init__(__self__, *,
                 dashboard_id: str,
                 custom_subject: Optional[str] = None,
                 pause_subscriptions: Optional[bool] = None,
                 subscriptions: Optional[Sequence['outputs.GetJobJobSettingsSettingsTaskSqlTaskDashboardSubscriptionResult']] = None):
        pulumi.set(__self__, "dashboard_id", dashboard_id)
        if custom_subject is not None:
            pulumi.set(__self__, "custom_subject", custom_subject)
        if pause_subscriptions is not None:
            pulumi.set(__self__, "pause_subscriptions", pause_subscriptions)
        if subscriptions is not None:
            pulumi.set(__self__, "subscriptions", subscriptions)

    @property
    @pulumi.getter(name="dashboardId")
    def dashboard_id(self) -> str:
        return pulumi.get(self, "dashboard_id")

    @property
    @pulumi.getter(name="customSubject")
    def custom_subject(self) -> Optional[str]:
        return pulumi.get(self, "custom_subject")

    @property
    @pulumi.getter(name="pauseSubscriptions")
    def pause_subscriptions(self) -> Optional[bool]:
        return pulumi.get(self, "pause_subscriptions")

    @property
    @pulumi.getter
    def subscriptions(self) -> Optional[Sequence['outputs.GetJobJobSettingsSettingsTaskSqlTaskDashboardSubscriptionResult']]:
        return pulumi.get(self, "subscriptions")


@pulumi.output_type
class GetJobJobSettingsSettingsTaskSqlTaskDashboardSubscriptionResult(dict):
    def __init__(__self__, *,
                 destination_id: Optional[str] = None,
                 user_name: Optional[str] = None):
        if destination_id is not None:
            pulumi.set(__self__, "destination_id", destination_id)
        if user_name is not None:
            pulumi.set(__self__, "user_name", user_name)

    @property
    @pulumi.getter(name="destinationId")
    def destination_id(self) -> Optional[str]:
        return pulumi.get(self, "destination_id")

    @property
    @pulumi.getter(name="userName")
    def user_name(self) -> Optional[str]:
        return pulumi.get(self, "user_name")


@pulumi.output_type
class GetJobJobSettingsSettingsTaskSqlTaskFileResult(dict):
    def __init__(__self__, *,
                 path: str,
                 source: Optional[str] = None):
        pulumi.set(__self__, "path", path)
        if source is not None:
            pulumi.set(__self__, "source", source)

    @property
    @pulumi.getter
    def path(self) -> str:
        return pulumi.get(self, "path")

    @property
    @pulumi.getter
    def source(self) -> Optional[str]:
        return pulumi.get(self, "source")


@pulumi.output_type
class GetJobJobSettingsSettingsTaskSqlTaskQueryResult(dict):
    def __init__(__self__, *,
                 query_id: str):
        pulumi.set(__self__, "query_id", query_id)

    @property
    @pulumi.getter(name="queryId")
    def query_id(self) -> str:
        return pulumi.get(self, "query_id")


@pulumi.output_type
class GetJobJobSettingsSettingsTaskWebhookNotificationsResult(dict):
    def __init__(__self__, *,
                 on_duration_warning_threshold_exceededs: Optional[Sequence['outputs.GetJobJobSettingsSettingsTaskWebhookNotificationsOnDurationWarningThresholdExceededResult']] = None,
                 on_failures: Optional[Sequence['outputs.GetJobJobSettingsSettingsTaskWebhookNotificationsOnFailureResult']] = None,
                 on_starts: Optional[Sequence['outputs.GetJobJobSettingsSettingsTaskWebhookNotificationsOnStartResult']] = None,
                 on_streaming_backlog_exceededs: Optional[Sequence['outputs.GetJobJobSettingsSettingsTaskWebhookNotificationsOnStreamingBacklogExceededResult']] = None,
                 on_successes: Optional[Sequence['outputs.GetJobJobSettingsSettingsTaskWebhookNotificationsOnSuccessResult']] = None):
        if on_duration_warning_threshold_exceededs is not None:
            pulumi.set(__self__, "on_duration_warning_threshold_exceededs", on_duration_warning_threshold_exceededs)
        if on_failures is not None:
            pulumi.set(__self__, "on_failures", on_failures)
        if on_starts is not None:
            pulumi.set(__self__, "on_starts", on_starts)
        if on_streaming_backlog_exceededs is not None:
            pulumi.set(__self__, "on_streaming_backlog_exceededs", on_streaming_backlog_exceededs)
        if on_successes is not None:
            pulumi.set(__self__, "on_successes", on_successes)

    @property
    @pulumi.getter(name="onDurationWarningThresholdExceededs")
    def on_duration_warning_threshold_exceededs(self) -> Optional[Sequence['outputs.GetJobJobSettingsSettingsTaskWebhookNotificationsOnDurationWarningThresholdExceededResult']]:
        return pulumi.get(self, "on_duration_warning_threshold_exceededs")

    @property
    @pulumi.getter(name="onFailures")
    def on_failures(self) -> Optional[Sequence['outputs.GetJobJobSettingsSettingsTaskWebhookNotificationsOnFailureResult']]:
        return pulumi.get(self, "on_failures")

    @property
    @pulumi.getter(name="onStarts")
    def on_starts(self) -> Optional[Sequence['outputs.GetJobJobSettingsSettingsTaskWebhookNotificationsOnStartResult']]:
        return pulumi.get(self, "on_starts")

    @property
    @pulumi.getter(name="onStreamingBacklogExceededs")
    def on_streaming_backlog_exceededs(self) -> Optional[Sequence['outputs.GetJobJobSettingsSettingsTaskWebhookNotificationsOnStreamingBacklogExceededResult']]:
        return pulumi.get(self, "on_streaming_backlog_exceededs")

    @property
    @pulumi.getter(name="onSuccesses")
    def on_successes(self) -> Optional[Sequence['outputs.GetJobJobSettingsSettingsTaskWebhookNotificationsOnSuccessResult']]:
        return pulumi.get(self, "on_successes")


@pulumi.output_type
class GetJobJobSettingsSettingsTaskWebhookNotificationsOnDurationWarningThresholdExceededResult(dict):
    def __init__(__self__, *,
                 id: str):
        """
        :param str id: the id of Job if the resource was matched by name.
        """
        pulumi.set(__self__, "id", id)

    @property
    @pulumi.getter
    def id(self) -> str:
        """
        the id of Job if the resource was matched by name.
        """
        return pulumi.get(self, "id")


@pulumi.output_type
class GetJobJobSettingsSettingsTaskWebhookNotificationsOnFailureResult(dict):
    def __init__(__self__, *,
                 id: str):
        """
        :param str id: the id of Job if the resource was matched by name.
        """
        pulumi.set(__self__, "id", id)

    @property
    @pulumi.getter
    def id(self) -> str:
        """
        the id of Job if the resource was matched by name.
        """
        return pulumi.get(self, "id")


@pulumi.output_type
class GetJobJobSettingsSettingsTaskWebhookNotificationsOnStartResult(dict):
    def __init__(__self__, *,
                 id: str):
        """
        :param str id: the id of Job if the resource was matched by name.
        """
        pulumi.set(__self__, "id", id)

    @property
    @pulumi.getter
    def id(self) -> str:
        """
        the id of Job if the resource was matched by name.
        """
        return pulumi.get(self, "id")


@pulumi.output_type
class GetJobJobSettingsSettingsTaskWebhookNotificationsOnStreamingBacklogExceededResult(dict):
    def __init__(__self__, *,
                 id: str):
        """
        :param str id: the id of Job if the resource was matched by name.
        """
        pulumi.set(__self__, "id", id)

    @property
    @pulumi.getter
    def id(self) -> str:
        """
        the id of Job if the resource was matched by name.
        """
        return pulumi.get(self, "id")


@pulumi.output_type
class GetJobJobSettingsSettingsTaskWebhookNotificationsOnSuccessResult(dict):
    def __init__(__self__, *,
                 id: str):
        """
        :param str id: the id of Job if the resource was matched by name.
        """
        pulumi.set(__self__, "id", id)

    @property
    @pulumi.getter
    def id(self) -> str:
        """
        the id of Job if the resource was matched by name.
        """
        return pulumi.get(self, "id")


@pulumi.output_type
class GetJobJobSettingsSettingsTriggerResult(dict):
    def __init__(__self__, *,
                 file_arrival: Optional['outputs.GetJobJobSettingsSettingsTriggerFileArrivalResult'] = None,
                 pause_status: Optional[str] = None,
                 periodic: Optional['outputs.GetJobJobSettingsSettingsTriggerPeriodicResult'] = None,
                 table_update: Optional['outputs.GetJobJobSettingsSettingsTriggerTableUpdateResult'] = None):
        if file_arrival is not None:
            pulumi.set(__self__, "file_arrival", file_arrival)
        if pause_status is not None:
            pulumi.set(__self__, "pause_status", pause_status)
        if periodic is not None:
            pulumi.set(__self__, "periodic", periodic)
        if table_update is not None:
            pulumi.set(__self__, "table_update", table_update)

    @property
    @pulumi.getter(name="fileArrival")
    def file_arrival(self) -> Optional['outputs.GetJobJobSettingsSettingsTriggerFileArrivalResult']:
        return pulumi.get(self, "file_arrival")

    @property
    @pulumi.getter(name="pauseStatus")
    def pause_status(self) -> Optional[str]:
        return pulumi.get(self, "pause_status")

    @property
    @pulumi.getter
    def periodic(self) -> Optional['outputs.GetJobJobSettingsSettingsTriggerPeriodicResult']:
        return pulumi.get(self, "periodic")

    @property
    @pulumi.getter(name="tableUpdate")
    def table_update(self) -> Optional['outputs.GetJobJobSettingsSettingsTriggerTableUpdateResult']:
        return pulumi.get(self, "table_update")


@pulumi.output_type
class GetJobJobSettingsSettingsTriggerFileArrivalResult(dict):
    def __init__(__self__, *,
                 url: str,
                 min_time_between_triggers_seconds: Optional[int] = None,
                 wait_after_last_change_seconds: Optional[int] = None):
        pulumi.set(__self__, "url", url)
        if min_time_between_triggers_seconds is not None:
            pulumi.set(__self__, "min_time_between_triggers_seconds", min_time_between_triggers_seconds)
        if wait_after_last_change_seconds is not None:
            pulumi.set(__self__, "wait_after_last_change_seconds", wait_after_last_change_seconds)

    @property
    @pulumi.getter
    def url(self) -> str:
        return pulumi.get(self, "url")

    @property
    @pulumi.getter(name="minTimeBetweenTriggersSeconds")
    def min_time_between_triggers_seconds(self) -> Optional[int]:
        return pulumi.get(self, "min_time_between_triggers_seconds")

    @property
    @pulumi.getter(name="waitAfterLastChangeSeconds")
    def wait_after_last_change_seconds(self) -> Optional[int]:
        return pulumi.get(self, "wait_after_last_change_seconds")


@pulumi.output_type
class GetJobJobSettingsSettingsTriggerPeriodicResult(dict):
    def __init__(__self__, *,
                 interval: int,
                 unit: str):
        pulumi.set(__self__, "interval", interval)
        pulumi.set(__self__, "unit", unit)

    @property
    @pulumi.getter
    def interval(self) -> int:
        return pulumi.get(self, "interval")

    @property
    @pulumi.getter
    def unit(self) -> str:
        return pulumi.get(self, "unit")


@pulumi.output_type
class GetJobJobSettingsSettingsTriggerTableUpdateResult(dict):
    def __init__(__self__, *,
                 table_names: Sequence[str],
                 condition: Optional[str] = None,
                 min_time_between_triggers_seconds: Optional[int] = None,
                 wait_after_last_change_seconds: Optional[int] = None):
        pulumi.set(__self__, "table_names", table_names)
        if condition is not None:
            pulumi.set(__self__, "condition", condition)
        if min_time_between_triggers_seconds is not None:
            pulumi.set(__self__, "min_time_between_triggers_seconds", min_time_between_triggers_seconds)
        if wait_after_last_change_seconds is not None:
            pulumi.set(__self__, "wait_after_last_change_seconds", wait_after_last_change_seconds)

    @property
    @pulumi.getter(name="tableNames")
    def table_names(self) -> Sequence[str]:
        return pulumi.get(self, "table_names")

    @property
    @pulumi.getter
    def condition(self) -> Optional[str]:
        return pulumi.get(self, "condition")

    @property
    @pulumi.getter(name="minTimeBetweenTriggersSeconds")
    def min_time_between_triggers_seconds(self) -> Optional[int]:
        return pulumi.get(self, "min_time_between_triggers_seconds")

    @property
    @pulumi.getter(name="waitAfterLastChangeSeconds")
    def wait_after_last_change_seconds(self) -> Optional[int]:
        return pulumi.get(self, "wait_after_last_change_seconds")


@pulumi.output_type
class GetJobJobSettingsSettingsWebhookNotificationsResult(dict):
    def __init__(__self__, *,
                 on_duration_warning_threshold_exceededs: Optional[Sequence['outputs.GetJobJobSettingsSettingsWebhookNotificationsOnDurationWarningThresholdExceededResult']] = None,
                 on_failures: Optional[Sequence['outputs.GetJobJobSettingsSettingsWebhookNotificationsOnFailureResult']] = None,
                 on_starts: Optional[Sequence['outputs.GetJobJobSettingsSettingsWebhookNotificationsOnStartResult']] = None,
                 on_streaming_backlog_exceededs: Optional[Sequence['outputs.GetJobJobSettingsSettingsWebhookNotificationsOnStreamingBacklogExceededResult']] = None,
                 on_successes: Optional[Sequence['outputs.GetJobJobSettingsSettingsWebhookNotificationsOnSuccessResult']] = None):
        if on_duration_warning_threshold_exceededs is not None:
            pulumi.set(__self__, "on_duration_warning_threshold_exceededs", on_duration_warning_threshold_exceededs)
        if on_failures is not None:
            pulumi.set(__self__, "on_failures", on_failures)
        if on_starts is not None:
            pulumi.set(__self__, "on_starts", on_starts)
        if on_streaming_backlog_exceededs is not None:
            pulumi.set(__self__, "on_streaming_backlog_exceededs", on_streaming_backlog_exceededs)
        if on_successes is not None:
            pulumi.set(__self__, "on_successes", on_successes)

    @property
    @pulumi.getter(name="onDurationWarningThresholdExceededs")
    def on_duration_warning_threshold_exceededs(self) -> Optional[Sequence['outputs.GetJobJobSettingsSettingsWebhookNotificationsOnDurationWarningThresholdExceededResult']]:
        return pulumi.get(self, "on_duration_warning_threshold_exceededs")

    @property
    @pulumi.getter(name="onFailures")
    def on_failures(self) -> Optional[Sequence['outputs.GetJobJobSettingsSettingsWebhookNotificationsOnFailureResult']]:
        return pulumi.get(self, "on_failures")

    @property
    @pulumi.getter(name="onStarts")
    def on_starts(self) -> Optional[Sequence['outputs.GetJobJobSettingsSettingsWebhookNotificationsOnStartResult']]:
        return pulumi.get(self, "on_starts")

    @property
    @pulumi.getter(name="onStreamingBacklogExceededs")
    def on_streaming_backlog_exceededs(self) -> Optional[Sequence['outputs.GetJobJobSettingsSettingsWebhookNotificationsOnStreamingBacklogExceededResult']]:
        return pulumi.get(self, "on_streaming_backlog_exceededs")

    @property
    @pulumi.getter(name="onSuccesses")
    def on_successes(self) -> Optional[Sequence['outputs.GetJobJobSettingsSettingsWebhookNotificationsOnSuccessResult']]:
        return pulumi.get(self, "on_successes")


@pulumi.output_type
class GetJobJobSettingsSettingsWebhookNotificationsOnDurationWarningThresholdExceededResult(dict):
    def __init__(__self__, *,
                 id: str):
        """
        :param str id: the id of Job if the resource was matched by name.
        """
        pulumi.set(__self__, "id", id)

    @property
    @pulumi.getter
    def id(self) -> str:
        """
        the id of Job if the resource was matched by name.
        """
        return pulumi.get(self, "id")


@pulumi.output_type
class GetJobJobSettingsSettingsWebhookNotificationsOnFailureResult(dict):
    def __init__(__self__, *,
                 id: str):
        """
        :param str id: the id of Job if the resource was matched by name.
        """
        pulumi.set(__self__, "id", id)

    @property
    @pulumi.getter
    def id(self) -> str:
        """
        the id of Job if the resource was matched by name.
        """
        return pulumi.get(self, "id")


@pulumi.output_type
class GetJobJobSettingsSettingsWebhookNotificationsOnStartResult(dict):
    def __init__(__self__, *,
                 id: str):
        """
        :param str id: the id of Job if the resource was matched by name.
        """
        pulumi.set(__self__, "id", id)

    @property
    @pulumi.getter
    def id(self) -> str:
        """
        the id of Job if the resource was matched by name.
        """
        return pulumi.get(self, "id")


@pulumi.output_type
class GetJobJobSettingsSettingsWebhookNotificationsOnStreamingBacklogExceededResult(dict):
    def __init__(__self__, *,
                 id: str):
        """
        :param str id: the id of Job if the resource was matched by name.
        """
        pulumi.set(__self__, "id", id)

    @property
    @pulumi.getter
    def id(self) -> str:
        """
        the id of Job if the resource was matched by name.
        """
        return pulumi.get(self, "id")


@pulumi.output_type
class GetJobJobSettingsSettingsWebhookNotificationsOnSuccessResult(dict):
    def __init__(__self__, *,
                 id: str):
        """
        :param str id: the id of Job if the resource was matched by name.
        """
        pulumi.set(__self__, "id", id)

    @property
    @pulumi.getter
    def id(self) -> str:
        """
        the id of Job if the resource was matched by name.
        """
        return pulumi.get(self, "id")


@pulumi.output_type
class GetMetastoreMetastoreInfoResult(dict):
    def __init__(__self__, *,
                 cloud: Optional[str] = None,
                 created_at: Optional[int] = None,
                 created_by: Optional[str] = None,
                 default_data_access_config_id: Optional[str] = None,
                 delta_sharing_organization_name: Optional[str] = None,
                 delta_sharing_recipient_token_lifetime_in_seconds: Optional[int] = None,
                 delta_sharing_scope: Optional[str] = None,
                 global_metastore_id: Optional[str] = None,
                 metastore_id: Optional[str] = None,
                 name: Optional[str] = None,
                 owner: Optional[str] = None,
                 privilege_model_version: Optional[str] = None,
                 region: Optional[str] = None,
                 storage_root: Optional[str] = None,
                 storage_root_credential_id: Optional[str] = None,
                 storage_root_credential_name: Optional[str] = None,
                 updated_at: Optional[int] = None,
                 updated_by: Optional[str] = None):
        """
        :param str delta_sharing_organization_name: The organization name of a Delta Sharing entity. This field is used for Databricks to Databricks sharing.
        :param int delta_sharing_recipient_token_lifetime_in_seconds: Used to set expiration duration in seconds on recipient data access tokens.
        :param str delta_sharing_scope: Used to enable delta sharing on the metastore. Valid values: INTERNAL, INTERNAL_AND_EXTERNAL. INTERNAL only allows sharing within the same account, and INTERNAL_AND_EXTERNAL allows cross account sharing and token based sharing.
        :param str metastore_id: ID of the metastore
        :param str name: Name of the metastore
        :param str owner: Username/groupname/sp application_id of the metastore owner.
        :param str region: Region of the metastore
        :param str storage_root: Path on cloud storage account, where managed `Table` are stored.
        """
        if cloud is not None:
            pulumi.set(__self__, "cloud", cloud)
        if created_at is not None:
            pulumi.set(__self__, "created_at", created_at)
        if created_by is not None:
            pulumi.set(__self__, "created_by", created_by)
        if default_data_access_config_id is not None:
            pulumi.set(__self__, "default_data_access_config_id", default_data_access_config_id)
        if delta_sharing_organization_name is not None:
            pulumi.set(__self__, "delta_sharing_organization_name", delta_sharing_organization_name)
        if delta_sharing_recipient_token_lifetime_in_seconds is not None:
            pulumi.set(__self__, "delta_sharing_recipient_token_lifetime_in_seconds", delta_sharing_recipient_token_lifetime_in_seconds)
        if delta_sharing_scope is not None:
            pulumi.set(__self__, "delta_sharing_scope", delta_sharing_scope)
        if global_metastore_id is not None:
            pulumi.set(__self__, "global_metastore_id", global_metastore_id)
        if metastore_id is not None:
            pulumi.set(__self__, "metastore_id", metastore_id)
        if name is not None:
            pulumi.set(__self__, "name", name)
        if owner is not None:
            pulumi.set(__self__, "owner", owner)
        if privilege_model_version is not None:
            pulumi.set(__self__, "privilege_model_version", privilege_model_version)
        if region is not None:
            pulumi.set(__self__, "region", region)
        if storage_root is not None:
            pulumi.set(__self__, "storage_root", storage_root)
        if storage_root_credential_id is not None:
            pulumi.set(__self__, "storage_root_credential_id", storage_root_credential_id)
        if storage_root_credential_name is not None:
            pulumi.set(__self__, "storage_root_credential_name", storage_root_credential_name)
        if updated_at is not None:
            pulumi.set(__self__, "updated_at", updated_at)
        if updated_by is not None:
            pulumi.set(__self__, "updated_by", updated_by)

    @property
    @pulumi.getter
    def cloud(self) -> Optional[str]:
        return pulumi.get(self, "cloud")

    @property
    @pulumi.getter(name="createdAt")
    def created_at(self) -> Optional[int]:
        return pulumi.get(self, "created_at")

    @property
    @pulumi.getter(name="createdBy")
    def created_by(self) -> Optional[str]:
        return pulumi.get(self, "created_by")

    @property
    @pulumi.getter(name="defaultDataAccessConfigId")
    def default_data_access_config_id(self) -> Optional[str]:
        return pulumi.get(self, "default_data_access_config_id")

    @property
    @pulumi.getter(name="deltaSharingOrganizationName")
    def delta_sharing_organization_name(self) -> Optional[str]:
        """
        The organization name of a Delta Sharing entity. This field is used for Databricks to Databricks sharing.
        """
        return pulumi.get(self, "delta_sharing_organization_name")

    @property
    @pulumi.getter(name="deltaSharingRecipientTokenLifetimeInSeconds")
    def delta_sharing_recipient_token_lifetime_in_seconds(self) -> Optional[int]:
        """
        Used to set expiration duration in seconds on recipient data access tokens.
        """
        return pulumi.get(self, "delta_sharing_recipient_token_lifetime_in_seconds")

    @property
    @pulumi.getter(name="deltaSharingScope")
    def delta_sharing_scope(self) -> Optional[str]:
        """
        Used to enable delta sharing on the metastore. Valid values: INTERNAL, INTERNAL_AND_EXTERNAL. INTERNAL only allows sharing within the same account, and INTERNAL_AND_EXTERNAL allows cross account sharing and token based sharing.
        """
        return pulumi.get(self, "delta_sharing_scope")

    @property
    @pulumi.getter(name="globalMetastoreId")
    def global_metastore_id(self) -> Optional[str]:
        return pulumi.get(self, "global_metastore_id")

    @property
    @pulumi.getter(name="metastoreId")
    def metastore_id(self) -> Optional[str]:
        """
        ID of the metastore
        """
        return pulumi.get(self, "metastore_id")

    @property
    @pulumi.getter
    def name(self) -> Optional[str]:
        """
        Name of the metastore
        """
        return pulumi.get(self, "name")

    @property
    @pulumi.getter
    def owner(self) -> Optional[str]:
        """
        Username/groupname/sp application_id of the metastore owner.
        """
        return pulumi.get(self, "owner")

    @property
    @pulumi.getter(name="privilegeModelVersion")
    def privilege_model_version(self) -> Optional[str]:
        return pulumi.get(self, "privilege_model_version")

    @property
    @pulumi.getter
    def region(self) -> Optional[str]:
        """
        Region of the metastore
        """
        return pulumi.get(self, "region")

    @property
    @pulumi.getter(name="storageRoot")
    def storage_root(self) -> Optional[str]:
        """
        Path on cloud storage account, where managed `Table` are stored.
        """
        return pulumi.get(self, "storage_root")

    @property
    @pulumi.getter(name="storageRootCredentialId")
    def storage_root_credential_id(self) -> Optional[str]:
        return pulumi.get(self, "storage_root_credential_id")

    @property
    @pulumi.getter(name="storageRootCredentialName")
    def storage_root_credential_name(self) -> Optional[str]:
        return pulumi.get(self, "storage_root_credential_name")

    @property
    @pulumi.getter(name="updatedAt")
    def updated_at(self) -> Optional[int]:
        return pulumi.get(self, "updated_at")

    @property
    @pulumi.getter(name="updatedBy")
    def updated_by(self) -> Optional[str]:
        return pulumi.get(self, "updated_by")


@pulumi.output_type
class GetMlflowExperimentTagResult(dict):
    def __init__(__self__, *,
                 key: Optional[str] = None,
                 value: Optional[str] = None):
        if key is not None:
            pulumi.set(__self__, "key", key)
        if value is not None:
            pulumi.set(__self__, "value", value)

    @property
    @pulumi.getter
    def key(self) -> Optional[str]:
        return pulumi.get(self, "key")

    @property
    @pulumi.getter
    def value(self) -> Optional[str]:
        return pulumi.get(self, "value")


@pulumi.output_type
class GetMlflowModelLatestVersionResult(dict):
    def __init__(__self__, *,
                 creation_timestamp: Optional[int] = None,
                 current_stage: Optional[str] = None,
                 description: Optional[str] = None,
                 last_updated_timestamp: Optional[int] = None,
                 name: Optional[str] = None,
                 run_id: Optional[str] = None,
                 run_link: Optional[str] = None,
                 source: Optional[str] = None,
                 status: Optional[str] = None,
                 status_message: Optional[str] = None,
                 tags: Optional[Sequence['outputs.GetMlflowModelLatestVersionTagResult']] = None,
                 user_id: Optional[str] = None,
                 version: Optional[str] = None):
        """
        :param str description: User-specified description for the object.
        :param str name: Name of the registered model.
        :param Sequence['GetMlflowModelLatestVersionTagArgs'] tags: Array of tags associated with the model.
        :param str user_id: The username of the user that created the object.
        """
        if creation_timestamp is not None:
            pulumi.set(__self__, "creation_timestamp", creation_timestamp)
        if current_stage is not None:
            pulumi.set(__self__, "current_stage", current_stage)
        if description is not None:
            pulumi.set(__self__, "description", description)
        if last_updated_timestamp is not None:
            pulumi.set(__self__, "last_updated_timestamp", last_updated_timestamp)
        if name is not None:
            pulumi.set(__self__, "name", name)
        if run_id is not None:
            pulumi.set(__self__, "run_id", run_id)
        if run_link is not None:
            pulumi.set(__self__, "run_link", run_link)
        if source is not None:
            pulumi.set(__self__, "source", source)
        if status is not None:
            pulumi.set(__self__, "status", status)
        if status_message is not None:
            pulumi.set(__self__, "status_message", status_message)
        if tags is not None:
            pulumi.set(__self__, "tags", tags)
        if user_id is not None:
            pulumi.set(__self__, "user_id", user_id)
        if version is not None:
            pulumi.set(__self__, "version", version)

    @property
    @pulumi.getter(name="creationTimestamp")
    def creation_timestamp(self) -> Optional[int]:
        return pulumi.get(self, "creation_timestamp")

    @property
    @pulumi.getter(name="currentStage")
    def current_stage(self) -> Optional[str]:
        return pulumi.get(self, "current_stage")

    @property
    @pulumi.getter
    def description(self) -> Optional[str]:
        """
        User-specified description for the object.
        """
        return pulumi.get(self, "description")

    @property
    @pulumi.getter(name="lastUpdatedTimestamp")
    def last_updated_timestamp(self) -> Optional[int]:
        return pulumi.get(self, "last_updated_timestamp")

    @property
    @pulumi.getter
    def name(self) -> Optional[str]:
        """
        Name of the registered model.
        """
        return pulumi.get(self, "name")

    @property
    @pulumi.getter(name="runId")
    def run_id(self) -> Optional[str]:
        return pulumi.get(self, "run_id")

    @property
    @pulumi.getter(name="runLink")
    def run_link(self) -> Optional[str]:
        return pulumi.get(self, "run_link")

    @property
    @pulumi.getter
    def source(self) -> Optional[str]:
        return pulumi.get(self, "source")

    @property
    @pulumi.getter
    def status(self) -> Optional[str]:
        return pulumi.get(self, "status")

    @property
    @pulumi.getter(name="statusMessage")
    def status_message(self) -> Optional[str]:
        return pulumi.get(self, "status_message")

    @property
    @pulumi.getter
    def tags(self) -> Optional[Sequence['outputs.GetMlflowModelLatestVersionTagResult']]:
        """
        Array of tags associated with the model.
        """
        return pulumi.get(self, "tags")

    @property
    @pulumi.getter(name="userId")
    def user_id(self) -> Optional[str]:
        """
        The username of the user that created the object.
        """
        return pulumi.get(self, "user_id")

    @property
    @pulumi.getter
    def version(self) -> Optional[str]:
        return pulumi.get(self, "version")


@pulumi.output_type
class GetMlflowModelLatestVersionTagResult(dict):
    def __init__(__self__, *,
                 key: Optional[str] = None,
                 value: Optional[str] = None):
        if key is not None:
            pulumi.set(__self__, "key", key)
        if value is not None:
            pulumi.set(__self__, "value", value)

    @property
    @pulumi.getter
    def key(self) -> Optional[str]:
        return pulumi.get(self, "key")

    @property
    @pulumi.getter
    def value(self) -> Optional[str]:
        return pulumi.get(self, "value")


@pulumi.output_type
class GetMlflowModelTagResult(dict):
    def __init__(__self__, *,
                 key: Optional[str] = None,
                 value: Optional[str] = None):
        if key is not None:
            pulumi.set(__self__, "key", key)
        if value is not None:
            pulumi.set(__self__, "value", value)

    @property
    @pulumi.getter
    def key(self) -> Optional[str]:
        return pulumi.get(self, "key")

    @property
    @pulumi.getter
    def value(self) -> Optional[str]:
        return pulumi.get(self, "value")


@pulumi.output_type
class GetNotebookPathsNotebookPathListResult(dict):
    def __init__(__self__, *,
                 language: Optional[str] = None,
                 path: Optional[str] = None):
        """
        :param str path: Path to workspace directory
        """
        if language is not None:
            pulumi.set(__self__, "language", language)
        if path is not None:
            pulumi.set(__self__, "path", path)

    @property
    @pulumi.getter
    def language(self) -> Optional[str]:
        return pulumi.get(self, "language")

    @property
    @pulumi.getter
    def path(self) -> Optional[str]:
        """
        Path to workspace directory
        """
        return pulumi.get(self, "path")


@pulumi.output_type
class GetSchemaSchemaInfoResult(dict):
    def __init__(__self__, *,
                 browse_only: Optional[bool] = None,
                 catalog_name: Optional[str] = None,
                 catalog_type: Optional[str] = None,
                 comment: Optional[str] = None,
                 created_at: Optional[int] = None,
                 created_by: Optional[str] = None,
                 effective_predictive_optimization_flag: Optional['outputs.GetSchemaSchemaInfoEffectivePredictiveOptimizationFlagResult'] = None,
                 enable_predictive_optimization: Optional[str] = None,
                 full_name: Optional[str] = None,
                 metastore_id: Optional[str] = None,
                 name: Optional[str] = None,
                 owner: Optional[str] = None,
                 properties: Optional[Mapping[str, str]] = None,
                 schema_id: Optional[str] = None,
                 storage_location: Optional[str] = None,
                 storage_root: Optional[str] = None,
                 updated_at: Optional[int] = None,
                 updated_by: Optional[str] = None):
        """
        :param bool browse_only: indicates whether the principal is limited to retrieving metadata for the schema through the BROWSE privilege.
        :param str catalog_name: the name of the catalog where the schema is.
        :param str catalog_type: the type of the parent catalog.
        :param str comment: the comment attached to the volume
        :param int created_at: time at which this schema was created, in epoch milliseconds.
        :param str created_by: username of schema creator.
        :param 'GetSchemaSchemaInfoEffectivePredictiveOptimizationFlagArgs' effective_predictive_optimization_flag: information about actual state of predictive optimization.
        :param str enable_predictive_optimization: whether predictive optimization should be enabled for this object and objects under it.
        :param str full_name: the two-level (fully qualified) name of the schema
        :param str metastore_id: the unique identifier of the metastore
        :param str name: a fully qualified name of databricks_schema: *`catalog`.`schema`*
        :param str owner: the identifier of the user who owns the schema
        :param Mapping[str, str] properties: map of properties set on the schema
        :param str schema_id: the unique identifier of the volume
        :param str storage_location: the storage location on the cloud.
        :param str storage_root: storage root URL for managed tables within schema.
        :param int updated_at: the timestamp of the last time changes were made to the schema
        :param str updated_by: the identifier of the user who updated the schema last time
        """
        if browse_only is not None:
            pulumi.set(__self__, "browse_only", browse_only)
        if catalog_name is not None:
            pulumi.set(__self__, "catalog_name", catalog_name)
        if catalog_type is not None:
            pulumi.set(__self__, "catalog_type", catalog_type)
        if comment is not None:
            pulumi.set(__self__, "comment", comment)
        if created_at is not None:
            pulumi.set(__self__, "created_at", created_at)
        if created_by is not None:
            pulumi.set(__self__, "created_by", created_by)
        if effective_predictive_optimization_flag is not None:
            pulumi.set(__self__, "effective_predictive_optimization_flag", effective_predictive_optimization_flag)
        if enable_predictive_optimization is not None:
            pulumi.set(__self__, "enable_predictive_optimization", enable_predictive_optimization)
        if full_name is not None:
            pulumi.set(__self__, "full_name", full_name)
        if metastore_id is not None:
            pulumi.set(__self__, "metastore_id", metastore_id)
        if name is not None:
            pulumi.set(__self__, "name", name)
        if owner is not None:
            pulumi.set(__self__, "owner", owner)
        if properties is not None:
            pulumi.set(__self__, "properties", properties)
        if schema_id is not None:
            pulumi.set(__self__, "schema_id", schema_id)
        if storage_location is not None:
            pulumi.set(__self__, "storage_location", storage_location)
        if storage_root is not None:
            pulumi.set(__self__, "storage_root", storage_root)
        if updated_at is not None:
            pulumi.set(__self__, "updated_at", updated_at)
        if updated_by is not None:
            pulumi.set(__self__, "updated_by", updated_by)

    @property
    @pulumi.getter(name="browseOnly")
    def browse_only(self) -> Optional[bool]:
        """
        indicates whether the principal is limited to retrieving metadata for the schema through the BROWSE privilege.
        """
        return pulumi.get(self, "browse_only")

    @property
    @pulumi.getter(name="catalogName")
    def catalog_name(self) -> Optional[str]:
        """
        the name of the catalog where the schema is.
        """
        return pulumi.get(self, "catalog_name")

    @property
    @pulumi.getter(name="catalogType")
    def catalog_type(self) -> Optional[str]:
        """
        the type of the parent catalog.
        """
        return pulumi.get(self, "catalog_type")

    @property
    @pulumi.getter
    def comment(self) -> Optional[str]:
        """
        the comment attached to the volume
        """
        return pulumi.get(self, "comment")

    @property
    @pulumi.getter(name="createdAt")
    def created_at(self) -> Optional[int]:
        """
        time at which this schema was created, in epoch milliseconds.
        """
        return pulumi.get(self, "created_at")

    @property
    @pulumi.getter(name="createdBy")
    def created_by(self) -> Optional[str]:
        """
        username of schema creator.
        """
        return pulumi.get(self, "created_by")

    @property
    @pulumi.getter(name="effectivePredictiveOptimizationFlag")
    def effective_predictive_optimization_flag(self) -> Optional['outputs.GetSchemaSchemaInfoEffectivePredictiveOptimizationFlagResult']:
        """
        information about actual state of predictive optimization.
        """
        return pulumi.get(self, "effective_predictive_optimization_flag")

    @property
    @pulumi.getter(name="enablePredictiveOptimization")
    def enable_predictive_optimization(self) -> Optional[str]:
        """
        whether predictive optimization should be enabled for this object and objects under it.
        """
        return pulumi.get(self, "enable_predictive_optimization")

    @property
    @pulumi.getter(name="fullName")
    def full_name(self) -> Optional[str]:
        """
        the two-level (fully qualified) name of the schema
        """
        return pulumi.get(self, "full_name")

    @property
    @pulumi.getter(name="metastoreId")
    def metastore_id(self) -> Optional[str]:
        """
        the unique identifier of the metastore
        """
        return pulumi.get(self, "metastore_id")

    @property
    @pulumi.getter
    def name(self) -> Optional[str]:
        """
        a fully qualified name of databricks_schema: *`catalog`.`schema`*
        """
        return pulumi.get(self, "name")

    @property
    @pulumi.getter
    def owner(self) -> Optional[str]:
        """
        the identifier of the user who owns the schema
        """
        return pulumi.get(self, "owner")

    @property
    @pulumi.getter
    def properties(self) -> Optional[Mapping[str, str]]:
        """
        map of properties set on the schema
        """
        return pulumi.get(self, "properties")

    @property
    @pulumi.getter(name="schemaId")
    def schema_id(self) -> Optional[str]:
        """
        the unique identifier of the volume
        """
        return pulumi.get(self, "schema_id")

    @property
    @pulumi.getter(name="storageLocation")
    def storage_location(self) -> Optional[str]:
        """
        the storage location on the cloud.
        """
        return pulumi.get(self, "storage_location")

    @property
    @pulumi.getter(name="storageRoot")
    def storage_root(self) -> Optional[str]:
        """
        storage root URL for managed tables within schema.
        """
        return pulumi.get(self, "storage_root")

    @property
    @pulumi.getter(name="updatedAt")
    def updated_at(self) -> Optional[int]:
        """
        the timestamp of the last time changes were made to the schema
        """
        return pulumi.get(self, "updated_at")

    @property
    @pulumi.getter(name="updatedBy")
    def updated_by(self) -> Optional[str]:
        """
        the identifier of the user who updated the schema last time
        """
        return pulumi.get(self, "updated_by")


@pulumi.output_type
class GetSchemaSchemaInfoEffectivePredictiveOptimizationFlagResult(dict):
    def __init__(__self__, *,
                 value: str,
                 inherited_from_name: Optional[str] = None,
                 inherited_from_type: Optional[str] = None):
        pulumi.set(__self__, "value", value)
        if inherited_from_name is not None:
            pulumi.set(__self__, "inherited_from_name", inherited_from_name)
        if inherited_from_type is not None:
            pulumi.set(__self__, "inherited_from_type", inherited_from_type)

    @property
    @pulumi.getter
    def value(self) -> str:
        return pulumi.get(self, "value")

    @property
    @pulumi.getter(name="inheritedFromName")
    def inherited_from_name(self) -> Optional[str]:
        return pulumi.get(self, "inherited_from_name")

    @property
    @pulumi.getter(name="inheritedFromType")
    def inherited_from_type(self) -> Optional[str]:
        return pulumi.get(self, "inherited_from_type")


@pulumi.output_type
class GetShareObjectResult(dict):
    def __init__(__self__, *,
                 added_at: int,
                 added_by: str,
                 data_object_type: str,
                 name: str,
                 status: str,
                 cdf_enabled: Optional[bool] = None,
                 comment: Optional[str] = None,
                 history_data_sharing_status: Optional[str] = None,
                 partitions: Optional[Sequence['outputs.GetShareObjectPartitionResult']] = None,
                 shared_as: Optional[str] = None,
                 start_version: Optional[int] = None):
        """
        :param str data_object_type: Type of the object.
        :param str name: The name of the share
        :param str comment: Description about the object.
        """
        pulumi.set(__self__, "added_at", added_at)
        pulumi.set(__self__, "added_by", added_by)
        pulumi.set(__self__, "data_object_type", data_object_type)
        pulumi.set(__self__, "name", name)
        pulumi.set(__self__, "status", status)
        if cdf_enabled is not None:
            pulumi.set(__self__, "cdf_enabled", cdf_enabled)
        if comment is not None:
            pulumi.set(__self__, "comment", comment)
        if history_data_sharing_status is not None:
            pulumi.set(__self__, "history_data_sharing_status", history_data_sharing_status)
        if partitions is not None:
            pulumi.set(__self__, "partitions", partitions)
        if shared_as is not None:
            pulumi.set(__self__, "shared_as", shared_as)
        if start_version is not None:
            pulumi.set(__self__, "start_version", start_version)

    @property
    @pulumi.getter(name="addedAt")
    def added_at(self) -> int:
        return pulumi.get(self, "added_at")

    @property
    @pulumi.getter(name="addedBy")
    def added_by(self) -> str:
        return pulumi.get(self, "added_by")

    @property
    @pulumi.getter(name="dataObjectType")
    def data_object_type(self) -> str:
        """
        Type of the object.
        """
        return pulumi.get(self, "data_object_type")

    @property
    @pulumi.getter
    def name(self) -> str:
        """
        The name of the share
        """
        return pulumi.get(self, "name")

    @property
    @pulumi.getter
    def status(self) -> str:
        return pulumi.get(self, "status")

    @property
    @pulumi.getter(name="cdfEnabled")
    def cdf_enabled(self) -> Optional[bool]:
        return pulumi.get(self, "cdf_enabled")

    @property
    @pulumi.getter
    def comment(self) -> Optional[str]:
        """
        Description about the object.
        """
        return pulumi.get(self, "comment")

    @property
    @pulumi.getter(name="historyDataSharingStatus")
    def history_data_sharing_status(self) -> Optional[str]:
        return pulumi.get(self, "history_data_sharing_status")

    @property
    @pulumi.getter
    def partitions(self) -> Optional[Sequence['outputs.GetShareObjectPartitionResult']]:
        return pulumi.get(self, "partitions")

    @property
    @pulumi.getter(name="sharedAs")
    def shared_as(self) -> Optional[str]:
        return pulumi.get(self, "shared_as")

    @property
    @pulumi.getter(name="startVersion")
    def start_version(self) -> Optional[int]:
        return pulumi.get(self, "start_version")


@pulumi.output_type
class GetShareObjectPartitionResult(dict):
    def __init__(__self__, *,
                 values: Sequence['outputs.GetShareObjectPartitionValueResult']):
        pulumi.set(__self__, "values", values)

    @property
    @pulumi.getter
    def values(self) -> Sequence['outputs.GetShareObjectPartitionValueResult']:
        return pulumi.get(self, "values")


@pulumi.output_type
class GetShareObjectPartitionValueResult(dict):
    def __init__(__self__, *,
                 name: str,
                 op: str,
                 recipient_property_key: Optional[str] = None,
                 value: Optional[str] = None):
        """
        :param str name: The name of the share
        """
        pulumi.set(__self__, "name", name)
        pulumi.set(__self__, "op", op)
        if recipient_property_key is not None:
            pulumi.set(__self__, "recipient_property_key", recipient_property_key)
        if value is not None:
            pulumi.set(__self__, "value", value)

    @property
    @pulumi.getter
    def name(self) -> str:
        """
        The name of the share
        """
        return pulumi.get(self, "name")

    @property
    @pulumi.getter
    def op(self) -> str:
        return pulumi.get(self, "op")

    @property
    @pulumi.getter(name="recipientPropertyKey")
    def recipient_property_key(self) -> Optional[str]:
        return pulumi.get(self, "recipient_property_key")

    @property
    @pulumi.getter
    def value(self) -> Optional[str]:
        return pulumi.get(self, "value")


@pulumi.output_type
class GetSqlWarehouseChannelResult(dict):
    def __init__(__self__, *,
                 dbsql_version: Optional[str] = None,
                 name: Optional[str] = None):
        """
        :param str name: Name of the SQL warehouse to search (case-sensitive).
        """
        if dbsql_version is not None:
            pulumi.set(__self__, "dbsql_version", dbsql_version)
        if name is not None:
            pulumi.set(__self__, "name", name)

    @property
    @pulumi.getter(name="dbsqlVersion")
    def dbsql_version(self) -> Optional[str]:
        return pulumi.get(self, "dbsql_version")

    @property
    @pulumi.getter
    def name(self) -> Optional[str]:
        """
        Name of the SQL warehouse to search (case-sensitive).
        """
        return pulumi.get(self, "name")


@pulumi.output_type
class GetSqlWarehouseHealthResult(dict):
    def __init__(__self__, *,
                 details: Optional[str] = None,
                 failure_reason: Optional['outputs.GetSqlWarehouseHealthFailureReasonResult'] = None,
                 message: Optional[str] = None,
                 status: Optional[str] = None,
                 summary: Optional[str] = None):
        if details is not None:
            pulumi.set(__self__, "details", details)
        if failure_reason is not None:
            pulumi.set(__self__, "failure_reason", failure_reason)
        if message is not None:
            pulumi.set(__self__, "message", message)
        if status is not None:
            pulumi.set(__self__, "status", status)
        if summary is not None:
            pulumi.set(__self__, "summary", summary)

    @property
    @pulumi.getter
    def details(self) -> Optional[str]:
        return pulumi.get(self, "details")

    @property
    @pulumi.getter(name="failureReason")
    def failure_reason(self) -> Optional['outputs.GetSqlWarehouseHealthFailureReasonResult']:
        return pulumi.get(self, "failure_reason")

    @property
    @pulumi.getter
    def message(self) -> Optional[str]:
        return pulumi.get(self, "message")

    @property
    @pulumi.getter
    def status(self) -> Optional[str]:
        return pulumi.get(self, "status")

    @property
    @pulumi.getter
    def summary(self) -> Optional[str]:
        return pulumi.get(self, "summary")


@pulumi.output_type
class GetSqlWarehouseHealthFailureReasonResult(dict):
    def __init__(__self__, *,
                 code: Optional[str] = None,
                 parameters: Optional[Mapping[str, str]] = None,
                 type: Optional[str] = None):
        if code is not None:
            pulumi.set(__self__, "code", code)
        if parameters is not None:
            pulumi.set(__self__, "parameters", parameters)
        if type is not None:
            pulumi.set(__self__, "type", type)

    @property
    @pulumi.getter
    def code(self) -> Optional[str]:
        return pulumi.get(self, "code")

    @property
    @pulumi.getter
    def parameters(self) -> Optional[Mapping[str, str]]:
        return pulumi.get(self, "parameters")

    @property
    @pulumi.getter
    def type(self) -> Optional[str]:
        return pulumi.get(self, "type")


@pulumi.output_type
class GetSqlWarehouseOdbcParamsResult(dict):
    def __init__(__self__, *,
                 hostname: Optional[str] = None,
                 path: Optional[str] = None,
                 port: Optional[int] = None,
                 protocol: Optional[str] = None):
        if hostname is not None:
            pulumi.set(__self__, "hostname", hostname)
        if path is not None:
            pulumi.set(__self__, "path", path)
        if port is not None:
            pulumi.set(__self__, "port", port)
        if protocol is not None:
            pulumi.set(__self__, "protocol", protocol)

    @property
    @pulumi.getter
    def hostname(self) -> Optional[str]:
        return pulumi.get(self, "hostname")

    @property
    @pulumi.getter
    def path(self) -> Optional[str]:
        return pulumi.get(self, "path")

    @property
    @pulumi.getter
    def port(self) -> Optional[int]:
        return pulumi.get(self, "port")

    @property
    @pulumi.getter
    def protocol(self) -> Optional[str]:
        return pulumi.get(self, "protocol")


@pulumi.output_type
class GetSqlWarehouseTagsResult(dict):
    def __init__(__self__, *,
                 custom_tags: Optional[Sequence['outputs.GetSqlWarehouseTagsCustomTagResult']] = None):
        if custom_tags is not None:
            pulumi.set(__self__, "custom_tags", custom_tags)

    @property
    @pulumi.getter(name="customTags")
    def custom_tags(self) -> Optional[Sequence['outputs.GetSqlWarehouseTagsCustomTagResult']]:
        return pulumi.get(self, "custom_tags")


@pulumi.output_type
class GetSqlWarehouseTagsCustomTagResult(dict):
    def __init__(__self__, *,
                 key: Optional[str] = None,
                 value: Optional[str] = None):
        if key is not None:
            pulumi.set(__self__, "key", key)
        if value is not None:
            pulumi.set(__self__, "value", value)

    @property
    @pulumi.getter
    def key(self) -> Optional[str]:
        return pulumi.get(self, "key")

    @property
    @pulumi.getter
    def value(self) -> Optional[str]:
        return pulumi.get(self, "value")


@pulumi.output_type
class GetStorageCredentialStorageCredentialInfoResult(dict):
    def __init__(__self__, *,
                 aws_iam_role: Optional['outputs.GetStorageCredentialStorageCredentialInfoAwsIamRoleResult'] = None,
                 azure_managed_identity: Optional['outputs.GetStorageCredentialStorageCredentialInfoAzureManagedIdentityResult'] = None,
                 azure_service_principal: Optional['outputs.GetStorageCredentialStorageCredentialInfoAzureServicePrincipalResult'] = None,
                 cloudflare_api_token: Optional['outputs.GetStorageCredentialStorageCredentialInfoCloudflareApiTokenResult'] = None,
                 comment: Optional[str] = None,
                 created_at: Optional[int] = None,
                 created_by: Optional[str] = None,
                 databricks_gcp_service_account: Optional['outputs.GetStorageCredentialStorageCredentialInfoDatabricksGcpServiceAccountResult'] = None,
                 id: Optional[str] = None,
                 isolation_mode: Optional[str] = None,
                 metastore_id: Optional[str] = None,
                 name: Optional[str] = None,
                 owner: Optional[str] = None,
                 read_only: Optional[bool] = None,
                 updated_at: Optional[int] = None,
                 updated_by: Optional[str] = None,
                 used_for_managed_storage: Optional[bool] = None):
        """
        :param 'GetStorageCredentialStorageCredentialInfoAwsIamRoleArgs' aws_iam_role: credential details for AWS:
        :param 'GetStorageCredentialStorageCredentialInfoAzureManagedIdentityArgs' azure_managed_identity: managed identity credential details for Azure
        :param 'GetStorageCredentialStorageCredentialInfoAzureServicePrincipalArgs' azure_service_principal: service principal credential details for Azure:
        :param int created_at: Time at which this catalog was created, in epoch milliseconds.
        :param str created_by: Username of catalog creator.
        :param 'GetStorageCredentialStorageCredentialInfoDatabricksGcpServiceAccountArgs' databricks_gcp_service_account: credential details for GCP:
        :param str id: Unique ID of storage credential.
        :param str metastore_id: Unique identifier of the parent Metastore.
        :param str name: The name of the storage credential
        :param str owner: Username/groupname/sp application_id of the storage credential owner.
        :param bool read_only: Indicates whether the storage credential is only usable for read operations.
        :param int updated_at: Time at which this catalog was last modified, in epoch milliseconds.
        :param str updated_by: Username of user who last modified catalog.
        """
        if aws_iam_role is not None:
            pulumi.set(__self__, "aws_iam_role", aws_iam_role)
        if azure_managed_identity is not None:
            pulumi.set(__self__, "azure_managed_identity", azure_managed_identity)
        if azure_service_principal is not None:
            pulumi.set(__self__, "azure_service_principal", azure_service_principal)
        if cloudflare_api_token is not None:
            pulumi.set(__self__, "cloudflare_api_token", cloudflare_api_token)
        if comment is not None:
            pulumi.set(__self__, "comment", comment)
        if created_at is not None:
            pulumi.set(__self__, "created_at", created_at)
        if created_by is not None:
            pulumi.set(__self__, "created_by", created_by)
        if databricks_gcp_service_account is not None:
            pulumi.set(__self__, "databricks_gcp_service_account", databricks_gcp_service_account)
        if id is not None:
            pulumi.set(__self__, "id", id)
        if isolation_mode is not None:
            pulumi.set(__self__, "isolation_mode", isolation_mode)
        if metastore_id is not None:
            pulumi.set(__self__, "metastore_id", metastore_id)
        if name is not None:
            pulumi.set(__self__, "name", name)
        if owner is not None:
            pulumi.set(__self__, "owner", owner)
        if read_only is not None:
            pulumi.set(__self__, "read_only", read_only)
        if updated_at is not None:
            pulumi.set(__self__, "updated_at", updated_at)
        if updated_by is not None:
            pulumi.set(__self__, "updated_by", updated_by)
        if used_for_managed_storage is not None:
            pulumi.set(__self__, "used_for_managed_storage", used_for_managed_storage)

    @property
    @pulumi.getter(name="awsIamRole")
    def aws_iam_role(self) -> Optional['outputs.GetStorageCredentialStorageCredentialInfoAwsIamRoleResult']:
        """
        credential details for AWS:
        """
        return pulumi.get(self, "aws_iam_role")

    @property
    @pulumi.getter(name="azureManagedIdentity")
    def azure_managed_identity(self) -> Optional['outputs.GetStorageCredentialStorageCredentialInfoAzureManagedIdentityResult']:
        """
        managed identity credential details for Azure
        """
        return pulumi.get(self, "azure_managed_identity")

    @property
    @pulumi.getter(name="azureServicePrincipal")
    def azure_service_principal(self) -> Optional['outputs.GetStorageCredentialStorageCredentialInfoAzureServicePrincipalResult']:
        """
        service principal credential details for Azure:
        """
        return pulumi.get(self, "azure_service_principal")

    @property
    @pulumi.getter(name="cloudflareApiToken")
    def cloudflare_api_token(self) -> Optional['outputs.GetStorageCredentialStorageCredentialInfoCloudflareApiTokenResult']:
        return pulumi.get(self, "cloudflare_api_token")

    @property
    @pulumi.getter
    def comment(self) -> Optional[str]:
        return pulumi.get(self, "comment")

    @property
    @pulumi.getter(name="createdAt")
    def created_at(self) -> Optional[int]:
        """
        Time at which this catalog was created, in epoch milliseconds.
        """
        return pulumi.get(self, "created_at")

    @property
    @pulumi.getter(name="createdBy")
    def created_by(self) -> Optional[str]:
        """
        Username of catalog creator.
        """
        return pulumi.get(self, "created_by")

    @property
    @pulumi.getter(name="databricksGcpServiceAccount")
    def databricks_gcp_service_account(self) -> Optional['outputs.GetStorageCredentialStorageCredentialInfoDatabricksGcpServiceAccountResult']:
        """
        credential details for GCP:
        """
        return pulumi.get(self, "databricks_gcp_service_account")

    @property
    @pulumi.getter
    def id(self) -> Optional[str]:
        """
        Unique ID of storage credential.
        """
        return pulumi.get(self, "id")

    @property
    @pulumi.getter(name="isolationMode")
    def isolation_mode(self) -> Optional[str]:
        return pulumi.get(self, "isolation_mode")

    @property
    @pulumi.getter(name="metastoreId")
    def metastore_id(self) -> Optional[str]:
        """
        Unique identifier of the parent Metastore.
        """
        return pulumi.get(self, "metastore_id")

    @property
    @pulumi.getter
    def name(self) -> Optional[str]:
        """
        The name of the storage credential
        """
        return pulumi.get(self, "name")

    @property
    @pulumi.getter
    def owner(self) -> Optional[str]:
        """
        Username/groupname/sp application_id of the storage credential owner.
        """
        return pulumi.get(self, "owner")

    @property
    @pulumi.getter(name="readOnly")
    def read_only(self) -> Optional[bool]:
        """
        Indicates whether the storage credential is only usable for read operations.
        """
        return pulumi.get(self, "read_only")

    @property
    @pulumi.getter(name="updatedAt")
    def updated_at(self) -> Optional[int]:
        """
        Time at which this catalog was last modified, in epoch milliseconds.
        """
        return pulumi.get(self, "updated_at")

    @property
    @pulumi.getter(name="updatedBy")
    def updated_by(self) -> Optional[str]:
        """
        Username of user who last modified catalog.
        """
        return pulumi.get(self, "updated_by")

    @property
    @pulumi.getter(name="usedForManagedStorage")
    def used_for_managed_storage(self) -> Optional[bool]:
        return pulumi.get(self, "used_for_managed_storage")


@pulumi.output_type
class GetStorageCredentialStorageCredentialInfoAwsIamRoleResult(dict):
    def __init__(__self__, *,
                 role_arn: str,
                 external_id: Optional[str] = None,
                 unity_catalog_iam_arn: Optional[str] = None):
        """
        :param str role_arn: The Amazon Resource Name (ARN) of the AWS IAM role for S3 data access, of the form `arn:aws:iam::1234567890:role/MyRole-AJJHDSKSDF`
        :param str external_id: (output only) - The external ID used in role assumption to prevent confused deputy problem.
        :param str unity_catalog_iam_arn: (output only) - The Amazon Resource Name (ARN) of the AWS IAM user managed by Databricks. This is the identity that is going to assume the AWS IAM role.
        """
        pulumi.set(__self__, "role_arn", role_arn)
        if external_id is not None:
            pulumi.set(__self__, "external_id", external_id)
        if unity_catalog_iam_arn is not None:
            pulumi.set(__self__, "unity_catalog_iam_arn", unity_catalog_iam_arn)

    @property
    @pulumi.getter(name="roleArn")
    def role_arn(self) -> str:
        """
        The Amazon Resource Name (ARN) of the AWS IAM role for S3 data access, of the form `arn:aws:iam::1234567890:role/MyRole-AJJHDSKSDF`
        """
        return pulumi.get(self, "role_arn")

    @property
    @pulumi.getter(name="externalId")
    def external_id(self) -> Optional[str]:
        """
        (output only) - The external ID used in role assumption to prevent confused deputy problem.
        """
        return pulumi.get(self, "external_id")

    @property
    @pulumi.getter(name="unityCatalogIamArn")
    def unity_catalog_iam_arn(self) -> Optional[str]:
        """
        (output only) - The Amazon Resource Name (ARN) of the AWS IAM user managed by Databricks. This is the identity that is going to assume the AWS IAM role.
        """
        return pulumi.get(self, "unity_catalog_iam_arn")


@pulumi.output_type
class GetStorageCredentialStorageCredentialInfoAzureManagedIdentityResult(dict):
    def __init__(__self__, *,
                 access_connector_id: str,
                 credential_id: Optional[str] = None,
                 managed_identity_id: Optional[str] = None):
        """
        :param str access_connector_id: The Resource ID of the Azure Databricks Access Connector resource, of the form `/subscriptions/00000000-0000-0000-0000-000000000000/resourceGroups/rg-name/providers/Microsoft.Databricks/accessConnectors/connector-name`.
        :param str managed_identity_id: The Resource ID of the Azure User Assigned Managed Identity associated with Azure Databricks Access Connector, of the form `/subscriptions/00000000-0000-0000-0000-000000000000/resourceGroups/rg-name/providers/Microsoft.ManagedIdentity/userAssignedIdentities/user-managed-identity-name`.
        """
        pulumi.set(__self__, "access_connector_id", access_connector_id)
        if credential_id is not None:
            pulumi.set(__self__, "credential_id", credential_id)
        if managed_identity_id is not None:
            pulumi.set(__self__, "managed_identity_id", managed_identity_id)

    @property
    @pulumi.getter(name="accessConnectorId")
    def access_connector_id(self) -> str:
        """
        The Resource ID of the Azure Databricks Access Connector resource, of the form `/subscriptions/00000000-0000-0000-0000-000000000000/resourceGroups/rg-name/providers/Microsoft.Databricks/accessConnectors/connector-name`.
        """
        return pulumi.get(self, "access_connector_id")

    @property
    @pulumi.getter(name="credentialId")
    def credential_id(self) -> Optional[str]:
        return pulumi.get(self, "credential_id")

    @property
    @pulumi.getter(name="managedIdentityId")
    def managed_identity_id(self) -> Optional[str]:
        """
        The Resource ID of the Azure User Assigned Managed Identity associated with Azure Databricks Access Connector, of the form `/subscriptions/00000000-0000-0000-0000-000000000000/resourceGroups/rg-name/providers/Microsoft.ManagedIdentity/userAssignedIdentities/user-managed-identity-name`.
        """
        return pulumi.get(self, "managed_identity_id")


@pulumi.output_type
class GetStorageCredentialStorageCredentialInfoAzureServicePrincipalResult(dict):
    def __init__(__self__, *,
                 application_id: str,
                 client_secret: str,
                 directory_id: str):
        """
        :param str application_id: The application ID of the application registration within the referenced AAD tenant
        :param str directory_id: The directory ID corresponding to the Azure Active Directory (AAD) tenant of the application
        """
        pulumi.set(__self__, "application_id", application_id)
        pulumi.set(__self__, "client_secret", client_secret)
        pulumi.set(__self__, "directory_id", directory_id)

    @property
    @pulumi.getter(name="applicationId")
    def application_id(self) -> str:
        """
        The application ID of the application registration within the referenced AAD tenant
        """
        return pulumi.get(self, "application_id")

    @property
    @pulumi.getter(name="clientSecret")
    def client_secret(self) -> str:
        return pulumi.get(self, "client_secret")

    @property
    @pulumi.getter(name="directoryId")
    def directory_id(self) -> str:
        """
        The directory ID corresponding to the Azure Active Directory (AAD) tenant of the application
        """
        return pulumi.get(self, "directory_id")


@pulumi.output_type
class GetStorageCredentialStorageCredentialInfoCloudflareApiTokenResult(dict):
    def __init__(__self__, *,
                 access_key_id: str,
                 account_id: str,
                 secret_access_key: str):
        pulumi.set(__self__, "access_key_id", access_key_id)
        pulumi.set(__self__, "account_id", account_id)
        pulumi.set(__self__, "secret_access_key", secret_access_key)

    @property
    @pulumi.getter(name="accessKeyId")
    def access_key_id(self) -> str:
        return pulumi.get(self, "access_key_id")

    @property
    @pulumi.getter(name="accountId")
    def account_id(self) -> str:
        return pulumi.get(self, "account_id")

    @property
    @pulumi.getter(name="secretAccessKey")
    def secret_access_key(self) -> str:
        return pulumi.get(self, "secret_access_key")


@pulumi.output_type
class GetStorageCredentialStorageCredentialInfoDatabricksGcpServiceAccountResult(dict):
    def __init__(__self__, *,
                 credential_id: Optional[str] = None,
                 email: Optional[str] = None):
        """
        :param str email: The email of the GCP service account created, to be granted access to relevant buckets.
        """
        if credential_id is not None:
            pulumi.set(__self__, "credential_id", credential_id)
        if email is not None:
            pulumi.set(__self__, "email", email)

    @property
    @pulumi.getter(name="credentialId")
    def credential_id(self) -> Optional[str]:
        return pulumi.get(self, "credential_id")

    @property
    @pulumi.getter
    def email(self) -> Optional[str]:
        """
        The email of the GCP service account created, to be granted access to relevant buckets.
        """
        return pulumi.get(self, "email")


@pulumi.output_type
class GetTableTableInfoResult(dict):
    def __init__(__self__, *,
                 access_point: Optional[str] = None,
                 browse_only: Optional[bool] = None,
                 catalog_name: Optional[str] = None,
                 columns: Optional[Sequence['outputs.GetTableTableInfoColumnResult']] = None,
                 comment: Optional[str] = None,
                 created_at: Optional[int] = None,
                 created_by: Optional[str] = None,
                 data_access_configuration_id: Optional[str] = None,
                 data_source_format: Optional[str] = None,
                 deleted_at: Optional[int] = None,
                 delta_runtime_properties_kvpairs: Optional['outputs.GetTableTableInfoDeltaRuntimePropertiesKvpairsResult'] = None,
                 effective_predictive_optimization_flag: Optional['outputs.GetTableTableInfoEffectivePredictiveOptimizationFlagResult'] = None,
                 enable_predictive_optimization: Optional[str] = None,
                 encryption_details: Optional['outputs.GetTableTableInfoEncryptionDetailsResult'] = None,
                 full_name: Optional[str] = None,
                 metastore_id: Optional[str] = None,
                 name: Optional[str] = None,
                 owner: Optional[str] = None,
                 pipeline_id: Optional[str] = None,
                 properties: Optional[Mapping[str, str]] = None,
                 row_filter: Optional['outputs.GetTableTableInfoRowFilterResult'] = None,
                 schema_name: Optional[str] = None,
                 sql_path: Optional[str] = None,
                 storage_credential_name: Optional[str] = None,
                 storage_location: Optional[str] = None,
                 table_constraints: Optional[Sequence['outputs.GetTableTableInfoTableConstraintResult']] = None,
                 table_id: Optional[str] = None,
                 table_type: Optional[str] = None,
                 updated_at: Optional[int] = None,
                 updated_by: Optional[str] = None,
                 view_definition: Optional[str] = None,
                 view_dependencies: Optional['outputs.GetTableTableInfoViewDependenciesResult'] = None):
        """
        :param str catalog_name: Name of parent catalog.
        :param Sequence['GetTableTableInfoColumnArgs'] columns: Array of ColumnInfo objects of the table's columns
        :param str comment: Free-form text description
        :param str data_source_format: Table format, e.g. DELTA, CSV, JSON
        :param str name: Full name of the databricks_table: _`catalog`.`schema`.`table`_
        :param str owner: Current owner of the table
        :param str schema_name: Name of parent schema relative to its parent catalog.
        :param str table_type: Table type, e.g. MANAGED, EXTERNAL, VIEW
        :param str view_definition: View definition SQL (when `table_type` is VIEW, MATERIALIZED_VIEW, or STREAMING_TABLE)
        :param 'GetTableTableInfoViewDependenciesArgs' view_dependencies: View dependencies (when `table_type` is VIEW or MATERIALIZED_VIEW, STREAMING_TABLE)
        """
        if access_point is not None:
            pulumi.set(__self__, "access_point", access_point)
        if browse_only is not None:
            pulumi.set(__self__, "browse_only", browse_only)
        if catalog_name is not None:
            pulumi.set(__self__, "catalog_name", catalog_name)
        if columns is not None:
            pulumi.set(__self__, "columns", columns)
        if comment is not None:
            pulumi.set(__self__, "comment", comment)
        if created_at is not None:
            pulumi.set(__self__, "created_at", created_at)
        if created_by is not None:
            pulumi.set(__self__, "created_by", created_by)
        if data_access_configuration_id is not None:
            pulumi.set(__self__, "data_access_configuration_id", data_access_configuration_id)
        if data_source_format is not None:
            pulumi.set(__self__, "data_source_format", data_source_format)
        if deleted_at is not None:
            pulumi.set(__self__, "deleted_at", deleted_at)
        if delta_runtime_properties_kvpairs is not None:
            pulumi.set(__self__, "delta_runtime_properties_kvpairs", delta_runtime_properties_kvpairs)
        if effective_predictive_optimization_flag is not None:
            pulumi.set(__self__, "effective_predictive_optimization_flag", effective_predictive_optimization_flag)
        if enable_predictive_optimization is not None:
            pulumi.set(__self__, "enable_predictive_optimization", enable_predictive_optimization)
        if encryption_details is not None:
            pulumi.set(__self__, "encryption_details", encryption_details)
        if full_name is not None:
            pulumi.set(__self__, "full_name", full_name)
        if metastore_id is not None:
            pulumi.set(__self__, "metastore_id", metastore_id)
        if name is not None:
            pulumi.set(__self__, "name", name)
        if owner is not None:
            pulumi.set(__self__, "owner", owner)
        if pipeline_id is not None:
            pulumi.set(__self__, "pipeline_id", pipeline_id)
        if properties is not None:
            pulumi.set(__self__, "properties", properties)
        if row_filter is not None:
            pulumi.set(__self__, "row_filter", row_filter)
        if schema_name is not None:
            pulumi.set(__self__, "schema_name", schema_name)
        if sql_path is not None:
            pulumi.set(__self__, "sql_path", sql_path)
        if storage_credential_name is not None:
            pulumi.set(__self__, "storage_credential_name", storage_credential_name)
        if storage_location is not None:
            pulumi.set(__self__, "storage_location", storage_location)
        if table_constraints is not None:
            pulumi.set(__self__, "table_constraints", table_constraints)
        if table_id is not None:
            pulumi.set(__self__, "table_id", table_id)
        if table_type is not None:
            pulumi.set(__self__, "table_type", table_type)
        if updated_at is not None:
            pulumi.set(__self__, "updated_at", updated_at)
        if updated_by is not None:
            pulumi.set(__self__, "updated_by", updated_by)
        if view_definition is not None:
            pulumi.set(__self__, "view_definition", view_definition)
        if view_dependencies is not None:
            pulumi.set(__self__, "view_dependencies", view_dependencies)

    @property
    @pulumi.getter(name="accessPoint")
    def access_point(self) -> Optional[str]:
        return pulumi.get(self, "access_point")

    @property
    @pulumi.getter(name="browseOnly")
    def browse_only(self) -> Optional[bool]:
        return pulumi.get(self, "browse_only")

    @property
    @pulumi.getter(name="catalogName")
    def catalog_name(self) -> Optional[str]:
        """
        Name of parent catalog.
        """
        return pulumi.get(self, "catalog_name")

    @property
    @pulumi.getter
    def columns(self) -> Optional[Sequence['outputs.GetTableTableInfoColumnResult']]:
        """
        Array of ColumnInfo objects of the table's columns
        """
        return pulumi.get(self, "columns")

    @property
    @pulumi.getter
    def comment(self) -> Optional[str]:
        """
        Free-form text description
        """
        return pulumi.get(self, "comment")

    @property
    @pulumi.getter(name="createdAt")
    def created_at(self) -> Optional[int]:
        return pulumi.get(self, "created_at")

    @property
    @pulumi.getter(name="createdBy")
    def created_by(self) -> Optional[str]:
        return pulumi.get(self, "created_by")

    @property
    @pulumi.getter(name="dataAccessConfigurationId")
    def data_access_configuration_id(self) -> Optional[str]:
        return pulumi.get(self, "data_access_configuration_id")

    @property
    @pulumi.getter(name="dataSourceFormat")
    def data_source_format(self) -> Optional[str]:
        """
        Table format, e.g. DELTA, CSV, JSON
        """
        return pulumi.get(self, "data_source_format")

    @property
    @pulumi.getter(name="deletedAt")
    def deleted_at(self) -> Optional[int]:
        return pulumi.get(self, "deleted_at")

    @property
    @pulumi.getter(name="deltaRuntimePropertiesKvpairs")
    def delta_runtime_properties_kvpairs(self) -> Optional['outputs.GetTableTableInfoDeltaRuntimePropertiesKvpairsResult']:
        return pulumi.get(self, "delta_runtime_properties_kvpairs")

    @property
    @pulumi.getter(name="effectivePredictiveOptimizationFlag")
    def effective_predictive_optimization_flag(self) -> Optional['outputs.GetTableTableInfoEffectivePredictiveOptimizationFlagResult']:
        return pulumi.get(self, "effective_predictive_optimization_flag")

    @property
    @pulumi.getter(name="enablePredictiveOptimization")
    def enable_predictive_optimization(self) -> Optional[str]:
        return pulumi.get(self, "enable_predictive_optimization")

    @property
    @pulumi.getter(name="encryptionDetails")
    def encryption_details(self) -> Optional['outputs.GetTableTableInfoEncryptionDetailsResult']:
        return pulumi.get(self, "encryption_details")

    @property
    @pulumi.getter(name="fullName")
    def full_name(self) -> Optional[str]:
        return pulumi.get(self, "full_name")

    @property
    @pulumi.getter(name="metastoreId")
    def metastore_id(self) -> Optional[str]:
        return pulumi.get(self, "metastore_id")

    @property
    @pulumi.getter
    def name(self) -> Optional[str]:
        """
        Full name of the databricks_table: _`catalog`.`schema`.`table`_
        """
        return pulumi.get(self, "name")

    @property
    @pulumi.getter
    def owner(self) -> Optional[str]:
        """
        Current owner of the table
        """
        return pulumi.get(self, "owner")

    @property
    @pulumi.getter(name="pipelineId")
    def pipeline_id(self) -> Optional[str]:
        return pulumi.get(self, "pipeline_id")

    @property
    @pulumi.getter
    def properties(self) -> Optional[Mapping[str, str]]:
        return pulumi.get(self, "properties")

    @property
    @pulumi.getter(name="rowFilter")
    def row_filter(self) -> Optional['outputs.GetTableTableInfoRowFilterResult']:
        return pulumi.get(self, "row_filter")

    @property
    @pulumi.getter(name="schemaName")
    def schema_name(self) -> Optional[str]:
        """
        Name of parent schema relative to its parent catalog.
        """
        return pulumi.get(self, "schema_name")

    @property
    @pulumi.getter(name="sqlPath")
    def sql_path(self) -> Optional[str]:
        return pulumi.get(self, "sql_path")

    @property
    @pulumi.getter(name="storageCredentialName")
    def storage_credential_name(self) -> Optional[str]:
        return pulumi.get(self, "storage_credential_name")

    @property
    @pulumi.getter(name="storageLocation")
    def storage_location(self) -> Optional[str]:
        return pulumi.get(self, "storage_location")

    @property
    @pulumi.getter(name="tableConstraints")
    def table_constraints(self) -> Optional[Sequence['outputs.GetTableTableInfoTableConstraintResult']]:
        return pulumi.get(self, "table_constraints")

    @property
    @pulumi.getter(name="tableId")
    def table_id(self) -> Optional[str]:
        return pulumi.get(self, "table_id")

    @property
    @pulumi.getter(name="tableType")
    def table_type(self) -> Optional[str]:
        """
        Table type, e.g. MANAGED, EXTERNAL, VIEW
        """
        return pulumi.get(self, "table_type")

    @property
    @pulumi.getter(name="updatedAt")
    def updated_at(self) -> Optional[int]:
        return pulumi.get(self, "updated_at")

    @property
    @pulumi.getter(name="updatedBy")
    def updated_by(self) -> Optional[str]:
        return pulumi.get(self, "updated_by")

    @property
    @pulumi.getter(name="viewDefinition")
    def view_definition(self) -> Optional[str]:
        """
        View definition SQL (when `table_type` is VIEW, MATERIALIZED_VIEW, or STREAMING_TABLE)
        """
        return pulumi.get(self, "view_definition")

    @property
    @pulumi.getter(name="viewDependencies")
    def view_dependencies(self) -> Optional['outputs.GetTableTableInfoViewDependenciesResult']:
        """
        View dependencies (when `table_type` is VIEW or MATERIALIZED_VIEW, STREAMING_TABLE)
        """
        return pulumi.get(self, "view_dependencies")


@pulumi.output_type
class GetTableTableInfoColumnResult(dict):
    def __init__(__self__, *,
                 comment: Optional[str] = None,
                 mask: Optional['outputs.GetTableTableInfoColumnMaskResult'] = None,
                 name: Optional[str] = None,
                 nullable: Optional[bool] = None,
                 partition_index: Optional[int] = None,
                 position: Optional[int] = None,
                 type_interval_type: Optional[str] = None,
                 type_json: Optional[str] = None,
                 type_name: Optional[str] = None,
                 type_precision: Optional[int] = None,
                 type_scale: Optional[int] = None,
                 type_text: Optional[str] = None):
        """
        :param str comment: Free-form text description
        :param str name: Full name of the databricks_table: _`catalog`.`schema`.`table`_
        """
        if comment is not None:
            pulumi.set(__self__, "comment", comment)
        if mask is not None:
            pulumi.set(__self__, "mask", mask)
        if name is not None:
            pulumi.set(__self__, "name", name)
        if nullable is not None:
            pulumi.set(__self__, "nullable", nullable)
        if partition_index is not None:
            pulumi.set(__self__, "partition_index", partition_index)
        if position is not None:
            pulumi.set(__self__, "position", position)
        if type_interval_type is not None:
            pulumi.set(__self__, "type_interval_type", type_interval_type)
        if type_json is not None:
            pulumi.set(__self__, "type_json", type_json)
        if type_name is not None:
            pulumi.set(__self__, "type_name", type_name)
        if type_precision is not None:
            pulumi.set(__self__, "type_precision", type_precision)
        if type_scale is not None:
            pulumi.set(__self__, "type_scale", type_scale)
        if type_text is not None:
            pulumi.set(__self__, "type_text", type_text)

    @property
    @pulumi.getter
    def comment(self) -> Optional[str]:
        """
        Free-form text description
        """
        return pulumi.get(self, "comment")

    @property
    @pulumi.getter
    def mask(self) -> Optional['outputs.GetTableTableInfoColumnMaskResult']:
        return pulumi.get(self, "mask")

    @property
    @pulumi.getter
    def name(self) -> Optional[str]:
        """
        Full name of the databricks_table: _`catalog`.`schema`.`table`_
        """
        return pulumi.get(self, "name")

    @property
    @pulumi.getter
    def nullable(self) -> Optional[bool]:
        return pulumi.get(self, "nullable")

    @property
    @pulumi.getter(name="partitionIndex")
    def partition_index(self) -> Optional[int]:
        return pulumi.get(self, "partition_index")

    @property
    @pulumi.getter
    def position(self) -> Optional[int]:
        return pulumi.get(self, "position")

    @property
    @pulumi.getter(name="typeIntervalType")
    def type_interval_type(self) -> Optional[str]:
        return pulumi.get(self, "type_interval_type")

    @property
    @pulumi.getter(name="typeJson")
    def type_json(self) -> Optional[str]:
        return pulumi.get(self, "type_json")

    @property
    @pulumi.getter(name="typeName")
    def type_name(self) -> Optional[str]:
        return pulumi.get(self, "type_name")

    @property
    @pulumi.getter(name="typePrecision")
    def type_precision(self) -> Optional[int]:
        return pulumi.get(self, "type_precision")

    @property
    @pulumi.getter(name="typeScale")
    def type_scale(self) -> Optional[int]:
        return pulumi.get(self, "type_scale")

    @property
    @pulumi.getter(name="typeText")
    def type_text(self) -> Optional[str]:
        return pulumi.get(self, "type_text")


@pulumi.output_type
class GetTableTableInfoColumnMaskResult(dict):
    def __init__(__self__, *,
                 function_name: Optional[str] = None,
                 using_column_names: Optional[Sequence[str]] = None):
        if function_name is not None:
            pulumi.set(__self__, "function_name", function_name)
        if using_column_names is not None:
            pulumi.set(__self__, "using_column_names", using_column_names)

    @property
    @pulumi.getter(name="functionName")
    def function_name(self) -> Optional[str]:
        return pulumi.get(self, "function_name")

    @property
    @pulumi.getter(name="usingColumnNames")
    def using_column_names(self) -> Optional[Sequence[str]]:
        return pulumi.get(self, "using_column_names")


@pulumi.output_type
class GetTableTableInfoDeltaRuntimePropertiesKvpairsResult(dict):
    def __init__(__self__, *,
                 delta_runtime_properties: Mapping[str, str]):
        pulumi.set(__self__, "delta_runtime_properties", delta_runtime_properties)

    @property
    @pulumi.getter(name="deltaRuntimeProperties")
    def delta_runtime_properties(self) -> Mapping[str, str]:
        return pulumi.get(self, "delta_runtime_properties")


@pulumi.output_type
class GetTableTableInfoEffectivePredictiveOptimizationFlagResult(dict):
    def __init__(__self__, *,
                 value: str,
                 inherited_from_name: Optional[str] = None,
                 inherited_from_type: Optional[str] = None):
        pulumi.set(__self__, "value", value)
        if inherited_from_name is not None:
            pulumi.set(__self__, "inherited_from_name", inherited_from_name)
        if inherited_from_type is not None:
            pulumi.set(__self__, "inherited_from_type", inherited_from_type)

    @property
    @pulumi.getter
    def value(self) -> str:
        return pulumi.get(self, "value")

    @property
    @pulumi.getter(name="inheritedFromName")
    def inherited_from_name(self) -> Optional[str]:
        return pulumi.get(self, "inherited_from_name")

    @property
    @pulumi.getter(name="inheritedFromType")
    def inherited_from_type(self) -> Optional[str]:
        return pulumi.get(self, "inherited_from_type")


@pulumi.output_type
class GetTableTableInfoEncryptionDetailsResult(dict):
    def __init__(__self__, *,
                 sse_encryption_details: Optional['outputs.GetTableTableInfoEncryptionDetailsSseEncryptionDetailsResult'] = None):
        if sse_encryption_details is not None:
            pulumi.set(__self__, "sse_encryption_details", sse_encryption_details)

    @property
    @pulumi.getter(name="sseEncryptionDetails")
    def sse_encryption_details(self) -> Optional['outputs.GetTableTableInfoEncryptionDetailsSseEncryptionDetailsResult']:
        return pulumi.get(self, "sse_encryption_details")


@pulumi.output_type
class GetTableTableInfoEncryptionDetailsSseEncryptionDetailsResult(dict):
    def __init__(__self__, *,
                 algorithm: Optional[str] = None,
                 aws_kms_key_arn: Optional[str] = None):
        if algorithm is not None:
            pulumi.set(__self__, "algorithm", algorithm)
        if aws_kms_key_arn is not None:
            pulumi.set(__self__, "aws_kms_key_arn", aws_kms_key_arn)

    @property
    @pulumi.getter
    def algorithm(self) -> Optional[str]:
        return pulumi.get(self, "algorithm")

    @property
    @pulumi.getter(name="awsKmsKeyArn")
    def aws_kms_key_arn(self) -> Optional[str]:
        return pulumi.get(self, "aws_kms_key_arn")


@pulumi.output_type
class GetTableTableInfoRowFilterResult(dict):
    def __init__(__self__, *,
                 function_name: str,
                 input_column_names: Sequence[str]):
        pulumi.set(__self__, "function_name", function_name)
        pulumi.set(__self__, "input_column_names", input_column_names)

    @property
    @pulumi.getter(name="functionName")
    def function_name(self) -> str:
        return pulumi.get(self, "function_name")

    @property
    @pulumi.getter(name="inputColumnNames")
    def input_column_names(self) -> Sequence[str]:
        return pulumi.get(self, "input_column_names")


@pulumi.output_type
class GetTableTableInfoTableConstraintResult(dict):
    def __init__(__self__, *,
                 foreign_key_constraint: Optional['outputs.GetTableTableInfoTableConstraintForeignKeyConstraintResult'] = None,
                 named_table_constraint: Optional['outputs.GetTableTableInfoTableConstraintNamedTableConstraintResult'] = None,
                 primary_key_constraint: Optional['outputs.GetTableTableInfoTableConstraintPrimaryKeyConstraintResult'] = None):
        if foreign_key_constraint is not None:
            pulumi.set(__self__, "foreign_key_constraint", foreign_key_constraint)
        if named_table_constraint is not None:
            pulumi.set(__self__, "named_table_constraint", named_table_constraint)
        if primary_key_constraint is not None:
            pulumi.set(__self__, "primary_key_constraint", primary_key_constraint)

    @property
    @pulumi.getter(name="foreignKeyConstraint")
    def foreign_key_constraint(self) -> Optional['outputs.GetTableTableInfoTableConstraintForeignKeyConstraintResult']:
        return pulumi.get(self, "foreign_key_constraint")

    @property
    @pulumi.getter(name="namedTableConstraint")
    def named_table_constraint(self) -> Optional['outputs.GetTableTableInfoTableConstraintNamedTableConstraintResult']:
        return pulumi.get(self, "named_table_constraint")

    @property
    @pulumi.getter(name="primaryKeyConstraint")
    def primary_key_constraint(self) -> Optional['outputs.GetTableTableInfoTableConstraintPrimaryKeyConstraintResult']:
        return pulumi.get(self, "primary_key_constraint")


@pulumi.output_type
class GetTableTableInfoTableConstraintForeignKeyConstraintResult(dict):
    def __init__(__self__, *,
                 child_columns: Sequence[str],
                 name: str,
                 parent_columns: Sequence[str],
                 parent_table: str):
        """
        :param str name: Full name of the databricks_table: _`catalog`.`schema`.`table`_
        """
        pulumi.set(__self__, "child_columns", child_columns)
        pulumi.set(__self__, "name", name)
        pulumi.set(__self__, "parent_columns", parent_columns)
        pulumi.set(__self__, "parent_table", parent_table)

    @property
    @pulumi.getter(name="childColumns")
    def child_columns(self) -> Sequence[str]:
        return pulumi.get(self, "child_columns")

    @property
    @pulumi.getter
    def name(self) -> str:
        """
        Full name of the databricks_table: _`catalog`.`schema`.`table`_
        """
        return pulumi.get(self, "name")

    @property
    @pulumi.getter(name="parentColumns")
    def parent_columns(self) -> Sequence[str]:
        return pulumi.get(self, "parent_columns")

    @property
    @pulumi.getter(name="parentTable")
    def parent_table(self) -> str:
        return pulumi.get(self, "parent_table")


@pulumi.output_type
class GetTableTableInfoTableConstraintNamedTableConstraintResult(dict):
    def __init__(__self__, *,
                 name: str):
        """
        :param str name: Full name of the databricks_table: _`catalog`.`schema`.`table`_
        """
        pulumi.set(__self__, "name", name)

    @property
    @pulumi.getter
    def name(self) -> str:
        """
        Full name of the databricks_table: _`catalog`.`schema`.`table`_
        """
        return pulumi.get(self, "name")


@pulumi.output_type
class GetTableTableInfoTableConstraintPrimaryKeyConstraintResult(dict):
    def __init__(__self__, *,
                 child_columns: Sequence[str],
                 name: str):
        """
        :param str name: Full name of the databricks_table: _`catalog`.`schema`.`table`_
        """
        pulumi.set(__self__, "child_columns", child_columns)
        pulumi.set(__self__, "name", name)

    @property
    @pulumi.getter(name="childColumns")
    def child_columns(self) -> Sequence[str]:
        return pulumi.get(self, "child_columns")

    @property
    @pulumi.getter
    def name(self) -> str:
        """
        Full name of the databricks_table: _`catalog`.`schema`.`table`_
        """
        return pulumi.get(self, "name")


@pulumi.output_type
class GetTableTableInfoViewDependenciesResult(dict):
    def __init__(__self__, *,
                 dependencies: Optional[Sequence['outputs.GetTableTableInfoViewDependenciesDependencyResult']] = None):
        if dependencies is not None:
            pulumi.set(__self__, "dependencies", dependencies)

    @property
    @pulumi.getter
    def dependencies(self) -> Optional[Sequence['outputs.GetTableTableInfoViewDependenciesDependencyResult']]:
        return pulumi.get(self, "dependencies")


@pulumi.output_type
class GetTableTableInfoViewDependenciesDependencyResult(dict):
    def __init__(__self__, *,
                 function: Optional['outputs.GetTableTableInfoViewDependenciesDependencyFunctionResult'] = None,
                 table: Optional['outputs.GetTableTableInfoViewDependenciesDependencyTableResult'] = None):
        if function is not None:
            pulumi.set(__self__, "function", function)
        if table is not None:
            pulumi.set(__self__, "table", table)

    @property
    @pulumi.getter
    def function(self) -> Optional['outputs.GetTableTableInfoViewDependenciesDependencyFunctionResult']:
        return pulumi.get(self, "function")

    @property
    @pulumi.getter
    def table(self) -> Optional['outputs.GetTableTableInfoViewDependenciesDependencyTableResult']:
        return pulumi.get(self, "table")


@pulumi.output_type
class GetTableTableInfoViewDependenciesDependencyFunctionResult(dict):
    def __init__(__self__, *,
                 function_full_name: str):
        pulumi.set(__self__, "function_full_name", function_full_name)

    @property
    @pulumi.getter(name="functionFullName")
    def function_full_name(self) -> str:
        return pulumi.get(self, "function_full_name")


@pulumi.output_type
class GetTableTableInfoViewDependenciesDependencyTableResult(dict):
    def __init__(__self__, *,
                 table_full_name: str):
        pulumi.set(__self__, "table_full_name", table_full_name)

    @property
    @pulumi.getter(name="tableFullName")
    def table_full_name(self) -> str:
        return pulumi.get(self, "table_full_name")


@pulumi.output_type
class GetVolumeVolumeInfoResult(dict):
    def __init__(__self__, *,
                 access_point: Optional[str] = None,
                 browse_only: Optional[bool] = None,
                 catalog_name: Optional[str] = None,
                 comment: Optional[str] = None,
                 created_at: Optional[int] = None,
                 created_by: Optional[str] = None,
                 encryption_details: Optional['outputs.GetVolumeVolumeInfoEncryptionDetailsResult'] = None,
                 full_name: Optional[str] = None,
                 metastore_id: Optional[str] = None,
                 name: Optional[str] = None,
                 owner: Optional[str] = None,
                 schema_name: Optional[str] = None,
                 storage_location: Optional[str] = None,
                 updated_at: Optional[int] = None,
                 updated_by: Optional[str] = None,
                 volume_id: Optional[str] = None,
                 volume_type: Optional[str] = None):
        """
        :param str access_point: the AWS access point to use when accessing s3 bucket for this volume's external location
        :param bool browse_only: indicates whether the principal is limited to retrieving metadata for the volume through the BROWSE privilege when include_browse is enabled in the request.
        :param str catalog_name: the name of the catalog where the schema and the volume are
        :param str comment: the comment attached to the volume
        :param int created_at: the Unix timestamp at the volume's creation
        :param str created_by: the identifier of the user who created the volume
        :param 'GetVolumeVolumeInfoEncryptionDetailsArgs' encryption_details: encryption options that apply to clients connecting to cloud storage
        :param str full_name: the three-level (fully qualified) name of the volume
        :param str metastore_id: the unique identifier of the metastore
        :param str name: a fully qualified name of databricks_volume: *`catalog`.`schema`.`volume`*
        :param str owner: the identifier of the user who owns the volume
        :param str schema_name: the name of the schema where the volume is
        :param str storage_location: the storage location on the cloud
        :param int updated_at: the timestamp of the last time changes were made to the volume
        :param str updated_by: the identifier of the user who updated the volume last time
        :param str volume_id: the unique identifier of the volume
        :param str volume_type: whether the volume is `MANAGED` or `EXTERNAL`
        """
        if access_point is not None:
            pulumi.set(__self__, "access_point", access_point)
        if browse_only is not None:
            pulumi.set(__self__, "browse_only", browse_only)
        if catalog_name is not None:
            pulumi.set(__self__, "catalog_name", catalog_name)
        if comment is not None:
            pulumi.set(__self__, "comment", comment)
        if created_at is not None:
            pulumi.set(__self__, "created_at", created_at)
        if created_by is not None:
            pulumi.set(__self__, "created_by", created_by)
        if encryption_details is not None:
            pulumi.set(__self__, "encryption_details", encryption_details)
        if full_name is not None:
            pulumi.set(__self__, "full_name", full_name)
        if metastore_id is not None:
            pulumi.set(__self__, "metastore_id", metastore_id)
        if name is not None:
            pulumi.set(__self__, "name", name)
        if owner is not None:
            pulumi.set(__self__, "owner", owner)
        if schema_name is not None:
            pulumi.set(__self__, "schema_name", schema_name)
        if storage_location is not None:
            pulumi.set(__self__, "storage_location", storage_location)
        if updated_at is not None:
            pulumi.set(__self__, "updated_at", updated_at)
        if updated_by is not None:
            pulumi.set(__self__, "updated_by", updated_by)
        if volume_id is not None:
            pulumi.set(__self__, "volume_id", volume_id)
        if volume_type is not None:
            pulumi.set(__self__, "volume_type", volume_type)

    @property
    @pulumi.getter(name="accessPoint")
    def access_point(self) -> Optional[str]:
        """
        the AWS access point to use when accessing s3 bucket for this volume's external location
        """
        return pulumi.get(self, "access_point")

    @property
    @pulumi.getter(name="browseOnly")
    def browse_only(self) -> Optional[bool]:
        """
        indicates whether the principal is limited to retrieving metadata for the volume through the BROWSE privilege when include_browse is enabled in the request.
        """
        return pulumi.get(self, "browse_only")

    @property
    @pulumi.getter(name="catalogName")
    def catalog_name(self) -> Optional[str]:
        """
        the name of the catalog where the schema and the volume are
        """
        return pulumi.get(self, "catalog_name")

    @property
    @pulumi.getter
    def comment(self) -> Optional[str]:
        """
        the comment attached to the volume
        """
        return pulumi.get(self, "comment")

    @property
    @pulumi.getter(name="createdAt")
    def created_at(self) -> Optional[int]:
        """
        the Unix timestamp at the volume's creation
        """
        return pulumi.get(self, "created_at")

    @property
    @pulumi.getter(name="createdBy")
    def created_by(self) -> Optional[str]:
        """
        the identifier of the user who created the volume
        """
        return pulumi.get(self, "created_by")

    @property
    @pulumi.getter(name="encryptionDetails")
    def encryption_details(self) -> Optional['outputs.GetVolumeVolumeInfoEncryptionDetailsResult']:
        """
        encryption options that apply to clients connecting to cloud storage
        """
        return pulumi.get(self, "encryption_details")

    @property
    @pulumi.getter(name="fullName")
    def full_name(self) -> Optional[str]:
        """
        the three-level (fully qualified) name of the volume
        """
        return pulumi.get(self, "full_name")

    @property
    @pulumi.getter(name="metastoreId")
    def metastore_id(self) -> Optional[str]:
        """
        the unique identifier of the metastore
        """
        return pulumi.get(self, "metastore_id")

    @property
    @pulumi.getter
    def name(self) -> Optional[str]:
        """
        a fully qualified name of databricks_volume: *`catalog`.`schema`.`volume`*
        """
        return pulumi.get(self, "name")

    @property
    @pulumi.getter
    def owner(self) -> Optional[str]:
        """
        the identifier of the user who owns the volume
        """
        return pulumi.get(self, "owner")

    @property
    @pulumi.getter(name="schemaName")
    def schema_name(self) -> Optional[str]:
        """
        the name of the schema where the volume is
        """
        return pulumi.get(self, "schema_name")

    @property
    @pulumi.getter(name="storageLocation")
    def storage_location(self) -> Optional[str]:
        """
        the storage location on the cloud
        """
        return pulumi.get(self, "storage_location")

    @property
    @pulumi.getter(name="updatedAt")
    def updated_at(self) -> Optional[int]:
        """
        the timestamp of the last time changes were made to the volume
        """
        return pulumi.get(self, "updated_at")

    @property
    @pulumi.getter(name="updatedBy")
    def updated_by(self) -> Optional[str]:
        """
        the identifier of the user who updated the volume last time
        """
        return pulumi.get(self, "updated_by")

    @property
    @pulumi.getter(name="volumeId")
    def volume_id(self) -> Optional[str]:
        """
        the unique identifier of the volume
        """
        return pulumi.get(self, "volume_id")

    @property
    @pulumi.getter(name="volumeType")
    def volume_type(self) -> Optional[str]:
        """
        whether the volume is `MANAGED` or `EXTERNAL`
        """
        return pulumi.get(self, "volume_type")


@pulumi.output_type
class GetVolumeVolumeInfoEncryptionDetailsResult(dict):
    def __init__(__self__, *,
                 sse_encryption_details: Optional['outputs.GetVolumeVolumeInfoEncryptionDetailsSseEncryptionDetailsResult'] = None):
        if sse_encryption_details is not None:
            pulumi.set(__self__, "sse_encryption_details", sse_encryption_details)

    @property
    @pulumi.getter(name="sseEncryptionDetails")
    def sse_encryption_details(self) -> Optional['outputs.GetVolumeVolumeInfoEncryptionDetailsSseEncryptionDetailsResult']:
        return pulumi.get(self, "sse_encryption_details")


@pulumi.output_type
class GetVolumeVolumeInfoEncryptionDetailsSseEncryptionDetailsResult(dict):
    def __init__(__self__, *,
                 algorithm: Optional[str] = None,
                 aws_kms_key_arn: Optional[str] = None):
        if algorithm is not None:
            pulumi.set(__self__, "algorithm", algorithm)
        if aws_kms_key_arn is not None:
            pulumi.set(__self__, "aws_kms_key_arn", aws_kms_key_arn)

    @property
    @pulumi.getter
    def algorithm(self) -> Optional[str]:
        return pulumi.get(self, "algorithm")

    @property
    @pulumi.getter(name="awsKmsKeyArn")
    def aws_kms_key_arn(self) -> Optional[str]:
        return pulumi.get(self, "aws_kms_key_arn")


