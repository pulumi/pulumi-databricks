# coding=utf-8
# *** WARNING: this file was generated by pulumi-language-python. ***
# *** Do not edit by hand unless you're certain you know what you are doing! ***

import builtins as _builtins
import warnings
import sys
import pulumi
import pulumi.runtime
from typing import Any, Mapping, Optional, Sequence, Union, overload
if sys.version_info >= (3, 11):
    from typing import NotRequired, TypedDict, TypeAlias
else:
    from typing_extensions import NotRequired, TypedDict, TypeAlias
from . import _utilities

__all__ = [
    'GetPipelinesResult',
    'AwaitableGetPipelinesResult',
    'get_pipelines',
    'get_pipelines_output',
]

@pulumi.output_type
class GetPipelinesResult:
    """
    A collection of values returned by getPipelines.
    """
    def __init__(__self__, id=None, ids=None, pipeline_name=None):
        if id and not isinstance(id, str):
            raise TypeError("Expected argument 'id' to be a str")
        pulumi.set(__self__, "id", id)
        if ids and not isinstance(ids, list):
            raise TypeError("Expected argument 'ids' to be a list")
        pulumi.set(__self__, "ids", ids)
        if pipeline_name and not isinstance(pipeline_name, str):
            raise TypeError("Expected argument 'pipeline_name' to be a str")
        pulumi.set(__self__, "pipeline_name", pipeline_name)

    @_builtins.property
    @pulumi.getter
    def id(self) -> _builtins.str:
        """
        The provider-assigned unique ID for this managed resource.
        """
        return pulumi.get(self, "id")

    @_builtins.property
    @pulumi.getter
    def ids(self) -> Sequence[_builtins.str]:
        """
        List of ids for [Lakeflow Declarative Pipelines](https://docs.databricks.com/aws/en/dlt) pipelines matching the provided search criteria.
        """
        return pulumi.get(self, "ids")

    @_builtins.property
    @pulumi.getter(name="pipelineName")
    def pipeline_name(self) -> Optional[_builtins.str]:
        return pulumi.get(self, "pipeline_name")


class AwaitableGetPipelinesResult(GetPipelinesResult):
    # pylint: disable=using-constant-test
    def __await__(self):
        if False:
            yield self
        return GetPipelinesResult(
            id=self.id,
            ids=self.ids,
            pipeline_name=self.pipeline_name)


def get_pipelines(ids: Optional[Sequence[_builtins.str]] = None,
                  pipeline_name: Optional[_builtins.str] = None,
                  opts: Optional[pulumi.InvokeOptions] = None) -> AwaitableGetPipelinesResult:
    """
    Retrieves a list of all Pipeline ([Lakeflow Declarative Pipelines](https://docs.databricks.com/aws/en/dlt)) ids deployed in a workspace, or those matching the provided search term. Maximum 100 results.

    > This data source can only be used with a workspace-level provider!

    ## Example Usage

    Get all Lakeflow Declarative Pipelines:

    ```python
    import pulumi
    import pulumi_databricks as databricks

    all = databricks.get_pipelines()
    pulumi.export("allPipelines", all.ids)
    ```

    Filter Lakeflow Declarative Pipelines by name (exact match):

    ```python
    import pulumi
    import pulumi_databricks as databricks

    this = databricks.get_pipelines(pipeline_name="my_pipeline")
    pulumi.export("myPipeline", this.ids)
    ```

    Filter Lakeflow Declarative Pipelines by name (wildcard search):

    ```python
    import pulumi
    import pulumi_databricks as databricks

    this = databricks.get_pipelines(pipeline_name="%pipeline%")
    pulumi.export("wildcardPipelines", this.ids)
    ```

    ## Related Resources

    The following resources are used in the same context:

    * End to end workspace management guide.
    * Pipeline to deploy [Lakeflow Declarative Pipelines](https://docs.databricks.com/aws/en/dlt).
    * Cluster to create [Databricks Clusters](https://docs.databricks.com/clusters/index.html).
    * Job to manage [Databricks Jobs](https://docs.databricks.com/jobs.html) to run non-interactive code in a databricks_cluster.
    * Notebook to manage [Databricks Notebooks](https://docs.databricks.com/notebooks/index.html).


    :param Sequence[_builtins.str] ids: List of ids for [Lakeflow Declarative Pipelines](https://docs.databricks.com/aws/en/dlt) pipelines matching the provided search criteria.
    :param _builtins.str pipeline_name: Filter Lakeflow Declarative Pipelines by name for a given search term. `%` is the supported wildcard operator.
    """
    __args__ = dict()
    __args__['ids'] = ids
    __args__['pipelineName'] = pipeline_name
    opts = pulumi.InvokeOptions.merge(_utilities.get_invoke_opts_defaults(), opts)
    __ret__ = pulumi.runtime.invoke('databricks:index/getPipelines:getPipelines', __args__, opts=opts, typ=GetPipelinesResult).value

    return AwaitableGetPipelinesResult(
        id=pulumi.get(__ret__, 'id'),
        ids=pulumi.get(__ret__, 'ids'),
        pipeline_name=pulumi.get(__ret__, 'pipeline_name'))
def get_pipelines_output(ids: Optional[pulumi.Input[Optional[Sequence[_builtins.str]]]] = None,
                         pipeline_name: Optional[pulumi.Input[Optional[_builtins.str]]] = None,
                         opts: Optional[Union[pulumi.InvokeOptions, pulumi.InvokeOutputOptions]] = None) -> pulumi.Output[GetPipelinesResult]:
    """
    Retrieves a list of all Pipeline ([Lakeflow Declarative Pipelines](https://docs.databricks.com/aws/en/dlt)) ids deployed in a workspace, or those matching the provided search term. Maximum 100 results.

    > This data source can only be used with a workspace-level provider!

    ## Example Usage

    Get all Lakeflow Declarative Pipelines:

    ```python
    import pulumi
    import pulumi_databricks as databricks

    all = databricks.get_pipelines()
    pulumi.export("allPipelines", all.ids)
    ```

    Filter Lakeflow Declarative Pipelines by name (exact match):

    ```python
    import pulumi
    import pulumi_databricks as databricks

    this = databricks.get_pipelines(pipeline_name="my_pipeline")
    pulumi.export("myPipeline", this.ids)
    ```

    Filter Lakeflow Declarative Pipelines by name (wildcard search):

    ```python
    import pulumi
    import pulumi_databricks as databricks

    this = databricks.get_pipelines(pipeline_name="%pipeline%")
    pulumi.export("wildcardPipelines", this.ids)
    ```

    ## Related Resources

    The following resources are used in the same context:

    * End to end workspace management guide.
    * Pipeline to deploy [Lakeflow Declarative Pipelines](https://docs.databricks.com/aws/en/dlt).
    * Cluster to create [Databricks Clusters](https://docs.databricks.com/clusters/index.html).
    * Job to manage [Databricks Jobs](https://docs.databricks.com/jobs.html) to run non-interactive code in a databricks_cluster.
    * Notebook to manage [Databricks Notebooks](https://docs.databricks.com/notebooks/index.html).


    :param Sequence[_builtins.str] ids: List of ids for [Lakeflow Declarative Pipelines](https://docs.databricks.com/aws/en/dlt) pipelines matching the provided search criteria.
    :param _builtins.str pipeline_name: Filter Lakeflow Declarative Pipelines by name for a given search term. `%` is the supported wildcard operator.
    """
    __args__ = dict()
    __args__['ids'] = ids
    __args__['pipelineName'] = pipeline_name
    opts = pulumi.InvokeOutputOptions.merge(_utilities.get_invoke_opts_defaults(), opts)
    __ret__ = pulumi.runtime.invoke_output('databricks:index/getPipelines:getPipelines', __args__, opts=opts, typ=GetPipelinesResult)
    return __ret__.apply(lambda __response__: GetPipelinesResult(
        id=pulumi.get(__response__, 'id'),
        ids=pulumi.get(__response__, 'ids'),
        pipeline_name=pulumi.get(__response__, 'pipeline_name')))
