// *** WARNING: this file was generated by pulumi-language-nodejs. ***
// *** Do not edit by hand unless you're certain you know what you are doing! ***

import * as pulumi from "@pulumi/pulumi";
import * as inputs from "./types/input";
import * as outputs from "./types/output";
import * as utilities from "./utilities";

/**
 * This resource allows you to manage [instance pools](https://docs.databricks.com/clusters/instance-pools/index.html) to reduce cluster start and auto-scaling times by maintaining a set of idle, ready-to-use instances. An instance pool reduces cluster start and auto-scaling times by maintaining a set of idle, ready-to-use cloud instances. When a cluster attached to a pool needs an instance, it first attempts to allocate one of the pool's idle instances. If the pool has no idle instances, it expands by allocating a new instance from the instance provider in order to accommodate the cluster's request. When a cluster releases an instance, it returns to the pool and is free for another cluster to use. Only clusters attached to a pool can use that pool's idle instances.
 *
 * > This resource can only be used with a workspace-level provider!
 *
 * > It is important to know that different cloud service providers have different `nodeTypeId`, `diskSpecs` and potentially other configurations.
 *
 * > "auto" `zoneId` is only supported for fleet node types.
 *
 * ## Example Usage
 *
 * ```typescript
 * import * as pulumi from "@pulumi/pulumi";
 * import * as databricks from "@pulumi/databricks";
 *
 * const smallest = databricks.getNodeType({});
 * const smallestNodes = new databricks.InstancePool("smallest_nodes", {
 *     instancePoolName: "Smallest Nodes",
 *     minIdleInstances: 0,
 *     maxCapacity: 300,
 *     nodeTypeId: smallest.then(smallest => smallest.id),
 *     awsAttributes: {
 *         availability: "ON_DEMAND",
 *         zoneId: "us-east-1a",
 *         spotBidPricePercent: 100,
 *     },
 *     idleInstanceAutoterminationMinutes: 10,
 *     diskSpec: {
 *         diskType: {
 *             ebsVolumeType: "GENERAL_PURPOSE_SSD",
 *         },
 *         diskSize: 80,
 *         diskCount: 1,
 *     },
 * });
 * ```
 *
 * ## Access Control
 *
 * * databricks.Group and databricks.User can control which groups or individual users can create instance pools.
 * * databricks.Permissions can control which groups or individual users can *Manage* or *Attach to* individual instance pools.
 *
 * ## Import
 *
 * The resource instance pool can be imported using its id:
 *
 * hcl
 *
 * import {
 *
 *   to = databricks_instance_pool.this
 *
 *   id = "<instance-pool-id>"
 *
 * }
 *
 * Alternatively, when using `terraform` version 1.4 or earlier, import using the `pulumi import` command:
 *
 * bash
 *
 * ```sh
 * $ pulumi import databricks:index/instancePool:InstancePool this <instance-pool-id>
 * ```
 */
export class InstancePool extends pulumi.CustomResource {
    /**
     * Get an existing InstancePool resource's state with the given name, ID, and optional extra
     * properties used to qualify the lookup.
     *
     * @param name The _unique_ name of the resulting resource.
     * @param id The _unique_ provider ID of the resource to lookup.
     * @param state Any extra arguments used during the lookup.
     * @param opts Optional settings to control the behavior of the CustomResource.
     */
    public static get(name: string, id: pulumi.Input<pulumi.ID>, state?: InstancePoolState, opts?: pulumi.CustomResourceOptions): InstancePool {
        return new InstancePool(name, <any>state, { ...opts, id: id });
    }

    /** @internal */
    public static readonly __pulumiType = 'databricks:index/instancePool:InstancePool';

    /**
     * Returns true if the given object is an instance of InstancePool.  This is designed to work even
     * when multiple copies of the Pulumi SDK have been loaded into the same process.
     */
    public static isInstance(obj: any): obj is InstancePool {
        if (obj === undefined || obj === null) {
            return false;
        }
        return obj['__pulumiType'] === InstancePool.__pulumiType;
    }

    declare public readonly awsAttributes: pulumi.Output<outputs.InstancePoolAwsAttributes | undefined>;
    declare public readonly azureAttributes: pulumi.Output<outputs.InstancePoolAzureAttributes | undefined>;
    /**
     * (Map) Additional tags for instance pool resources. Databricks tags all pool resources (e.g. AWS & Azure instances and Disk volumes). The tags of the instance pool will propagate to the clusters using the pool (see the [official documentation](https://docs.databricks.com/administration-guide/account-settings/usage-detail-tags-aws.html#tag-propagation)). Attempting to set the same tags in both cluster and instance pool will raise an error. *Databricks allows at most 43 custom tags.*
     */
    declare public readonly customTags: pulumi.Output<{[key: string]: string} | undefined>;
    declare public readonly diskSpec: pulumi.Output<outputs.InstancePoolDiskSpec | undefined>;
    /**
     * (Bool) Autoscaling Local Storage: when enabled, the instances in the pool dynamically acquire additional disk space when they are running low on disk space.
     */
    declare public readonly enableElasticDisk: pulumi.Output<boolean | undefined>;
    declare public readonly gcpAttributes: pulumi.Output<outputs.InstancePoolGcpAttributes | undefined>;
    /**
     * (Integer) The number of minutes that idle instances in excess of the minIdleInstances are maintained by the pool before being terminated. If not specified, excess idle instances are terminated automatically after a default timeout period. If specified, the time must be between 0 and 10000 minutes. If you specify 0, excess idle instances are removed as soon as possible.
     */
    declare public readonly idleInstanceAutoterminationMinutes: pulumi.Output<number>;
    declare public readonly instancePoolFleetAttributes: pulumi.Output<outputs.InstancePoolInstancePoolFleetAttributes | undefined>;
    declare public readonly instancePoolId: pulumi.Output<string>;
    /**
     * (String) The name of the instance pool. This is required for create and edit operations. It must be unique, non-empty, and less than 100 characters.
     */
    declare public readonly instancePoolName: pulumi.Output<string>;
    /**
     * (Integer) The maximum number of instances the pool can contain, including both idle instances and ones in use by clusters. Once the maximum capacity is reached, you cannot create new clusters from the pool and existing clusters cannot autoscale up until some instances are made idle in the pool via cluster termination or down-scaling. There is no default limit, but as a [best practice](https://docs.databricks.com/clusters/instance-pools/pool-best-practices.html#configure-pools-to-control-cost), this should be set based on anticipated usage.
     */
    declare public readonly maxCapacity: pulumi.Output<number | undefined>;
    /**
     * (Integer) The minimum number of idle instances maintained by the pool. This is in addition to any instances in use by active clusters.
     */
    declare public readonly minIdleInstances: pulumi.Output<number | undefined>;
    /**
     * (String) The node type for the instances in the pool. All clusters attached to the pool inherit this node type and the pool's idle instances are allocated based on this type. You can retrieve a list of available node types by using the [List Node Types API](https://docs.databricks.com/dev-tools/api/latest/clusters.html#clusterclusterservicelistnodetypes) call.
     */
    declare public readonly nodeTypeId: pulumi.Output<string | undefined>;
    declare public readonly preloadedDockerImages: pulumi.Output<outputs.InstancePoolPreloadedDockerImage[] | undefined>;
    /**
     * (List) A list with at most one runtime version the pool installs on each instance. Pool clusters that use a preloaded runtime version start faster as they do not have to wait for the image to download. You can retrieve them via databricks.getSparkVersion data source or via  [Runtime Versions API](https://docs.databricks.com/dev-tools/api/latest/clusters.html#clusterclusterservicelistsparkversions) call.
     */
    declare public readonly preloadedSparkVersions: pulumi.Output<string[] | undefined>;

    /**
     * Create a InstancePool resource with the given unique name, arguments, and options.
     *
     * @param name The _unique_ name of the resource.
     * @param args The arguments to use to populate this resource's properties.
     * @param opts A bag of options that control this resource's behavior.
     */
    constructor(name: string, args: InstancePoolArgs, opts?: pulumi.CustomResourceOptions)
    constructor(name: string, argsOrState?: InstancePoolArgs | InstancePoolState, opts?: pulumi.CustomResourceOptions) {
        let resourceInputs: pulumi.Inputs = {};
        opts = opts || {};
        if (opts.id) {
            const state = argsOrState as InstancePoolState | undefined;
            resourceInputs["awsAttributes"] = state?.awsAttributes;
            resourceInputs["azureAttributes"] = state?.azureAttributes;
            resourceInputs["customTags"] = state?.customTags;
            resourceInputs["diskSpec"] = state?.diskSpec;
            resourceInputs["enableElasticDisk"] = state?.enableElasticDisk;
            resourceInputs["gcpAttributes"] = state?.gcpAttributes;
            resourceInputs["idleInstanceAutoterminationMinutes"] = state?.idleInstanceAutoterminationMinutes;
            resourceInputs["instancePoolFleetAttributes"] = state?.instancePoolFleetAttributes;
            resourceInputs["instancePoolId"] = state?.instancePoolId;
            resourceInputs["instancePoolName"] = state?.instancePoolName;
            resourceInputs["maxCapacity"] = state?.maxCapacity;
            resourceInputs["minIdleInstances"] = state?.minIdleInstances;
            resourceInputs["nodeTypeId"] = state?.nodeTypeId;
            resourceInputs["preloadedDockerImages"] = state?.preloadedDockerImages;
            resourceInputs["preloadedSparkVersions"] = state?.preloadedSparkVersions;
        } else {
            const args = argsOrState as InstancePoolArgs | undefined;
            if (args?.idleInstanceAutoterminationMinutes === undefined && !opts.urn) {
                throw new Error("Missing required property 'idleInstanceAutoterminationMinutes'");
            }
            if (args?.instancePoolName === undefined && !opts.urn) {
                throw new Error("Missing required property 'instancePoolName'");
            }
            resourceInputs["awsAttributes"] = args?.awsAttributes;
            resourceInputs["azureAttributes"] = args?.azureAttributes;
            resourceInputs["customTags"] = args?.customTags;
            resourceInputs["diskSpec"] = args?.diskSpec;
            resourceInputs["enableElasticDisk"] = args?.enableElasticDisk;
            resourceInputs["gcpAttributes"] = args?.gcpAttributes;
            resourceInputs["idleInstanceAutoterminationMinutes"] = args?.idleInstanceAutoterminationMinutes;
            resourceInputs["instancePoolFleetAttributes"] = args?.instancePoolFleetAttributes;
            resourceInputs["instancePoolId"] = args?.instancePoolId;
            resourceInputs["instancePoolName"] = args?.instancePoolName;
            resourceInputs["maxCapacity"] = args?.maxCapacity;
            resourceInputs["minIdleInstances"] = args?.minIdleInstances;
            resourceInputs["nodeTypeId"] = args?.nodeTypeId;
            resourceInputs["preloadedDockerImages"] = args?.preloadedDockerImages;
            resourceInputs["preloadedSparkVersions"] = args?.preloadedSparkVersions;
        }
        opts = pulumi.mergeOptions(utilities.resourceOptsDefaults(), opts);
        super(InstancePool.__pulumiType, name, resourceInputs, opts);
    }
}

/**
 * Input properties used for looking up and filtering InstancePool resources.
 */
export interface InstancePoolState {
    awsAttributes?: pulumi.Input<inputs.InstancePoolAwsAttributes>;
    azureAttributes?: pulumi.Input<inputs.InstancePoolAzureAttributes>;
    /**
     * (Map) Additional tags for instance pool resources. Databricks tags all pool resources (e.g. AWS & Azure instances and Disk volumes). The tags of the instance pool will propagate to the clusters using the pool (see the [official documentation](https://docs.databricks.com/administration-guide/account-settings/usage-detail-tags-aws.html#tag-propagation)). Attempting to set the same tags in both cluster and instance pool will raise an error. *Databricks allows at most 43 custom tags.*
     */
    customTags?: pulumi.Input<{[key: string]: pulumi.Input<string>}>;
    diskSpec?: pulumi.Input<inputs.InstancePoolDiskSpec>;
    /**
     * (Bool) Autoscaling Local Storage: when enabled, the instances in the pool dynamically acquire additional disk space when they are running low on disk space.
     */
    enableElasticDisk?: pulumi.Input<boolean>;
    gcpAttributes?: pulumi.Input<inputs.InstancePoolGcpAttributes>;
    /**
     * (Integer) The number of minutes that idle instances in excess of the minIdleInstances are maintained by the pool before being terminated. If not specified, excess idle instances are terminated automatically after a default timeout period. If specified, the time must be between 0 and 10000 minutes. If you specify 0, excess idle instances are removed as soon as possible.
     */
    idleInstanceAutoterminationMinutes?: pulumi.Input<number>;
    instancePoolFleetAttributes?: pulumi.Input<inputs.InstancePoolInstancePoolFleetAttributes>;
    instancePoolId?: pulumi.Input<string>;
    /**
     * (String) The name of the instance pool. This is required for create and edit operations. It must be unique, non-empty, and less than 100 characters.
     */
    instancePoolName?: pulumi.Input<string>;
    /**
     * (Integer) The maximum number of instances the pool can contain, including both idle instances and ones in use by clusters. Once the maximum capacity is reached, you cannot create new clusters from the pool and existing clusters cannot autoscale up until some instances are made idle in the pool via cluster termination or down-scaling. There is no default limit, but as a [best practice](https://docs.databricks.com/clusters/instance-pools/pool-best-practices.html#configure-pools-to-control-cost), this should be set based on anticipated usage.
     */
    maxCapacity?: pulumi.Input<number>;
    /**
     * (Integer) The minimum number of idle instances maintained by the pool. This is in addition to any instances in use by active clusters.
     */
    minIdleInstances?: pulumi.Input<number>;
    /**
     * (String) The node type for the instances in the pool. All clusters attached to the pool inherit this node type and the pool's idle instances are allocated based on this type. You can retrieve a list of available node types by using the [List Node Types API](https://docs.databricks.com/dev-tools/api/latest/clusters.html#clusterclusterservicelistnodetypes) call.
     */
    nodeTypeId?: pulumi.Input<string>;
    preloadedDockerImages?: pulumi.Input<pulumi.Input<inputs.InstancePoolPreloadedDockerImage>[]>;
    /**
     * (List) A list with at most one runtime version the pool installs on each instance. Pool clusters that use a preloaded runtime version start faster as they do not have to wait for the image to download. You can retrieve them via databricks.getSparkVersion data source or via  [Runtime Versions API](https://docs.databricks.com/dev-tools/api/latest/clusters.html#clusterclusterservicelistsparkversions) call.
     */
    preloadedSparkVersions?: pulumi.Input<pulumi.Input<string>[]>;
}

/**
 * The set of arguments for constructing a InstancePool resource.
 */
export interface InstancePoolArgs {
    awsAttributes?: pulumi.Input<inputs.InstancePoolAwsAttributes>;
    azureAttributes?: pulumi.Input<inputs.InstancePoolAzureAttributes>;
    /**
     * (Map) Additional tags for instance pool resources. Databricks tags all pool resources (e.g. AWS & Azure instances and Disk volumes). The tags of the instance pool will propagate to the clusters using the pool (see the [official documentation](https://docs.databricks.com/administration-guide/account-settings/usage-detail-tags-aws.html#tag-propagation)). Attempting to set the same tags in both cluster and instance pool will raise an error. *Databricks allows at most 43 custom tags.*
     */
    customTags?: pulumi.Input<{[key: string]: pulumi.Input<string>}>;
    diskSpec?: pulumi.Input<inputs.InstancePoolDiskSpec>;
    /**
     * (Bool) Autoscaling Local Storage: when enabled, the instances in the pool dynamically acquire additional disk space when they are running low on disk space.
     */
    enableElasticDisk?: pulumi.Input<boolean>;
    gcpAttributes?: pulumi.Input<inputs.InstancePoolGcpAttributes>;
    /**
     * (Integer) The number of minutes that idle instances in excess of the minIdleInstances are maintained by the pool before being terminated. If not specified, excess idle instances are terminated automatically after a default timeout period. If specified, the time must be between 0 and 10000 minutes. If you specify 0, excess idle instances are removed as soon as possible.
     */
    idleInstanceAutoterminationMinutes: pulumi.Input<number>;
    instancePoolFleetAttributes?: pulumi.Input<inputs.InstancePoolInstancePoolFleetAttributes>;
    instancePoolId?: pulumi.Input<string>;
    /**
     * (String) The name of the instance pool. This is required for create and edit operations. It must be unique, non-empty, and less than 100 characters.
     */
    instancePoolName: pulumi.Input<string>;
    /**
     * (Integer) The maximum number of instances the pool can contain, including both idle instances and ones in use by clusters. Once the maximum capacity is reached, you cannot create new clusters from the pool and existing clusters cannot autoscale up until some instances are made idle in the pool via cluster termination or down-scaling. There is no default limit, but as a [best practice](https://docs.databricks.com/clusters/instance-pools/pool-best-practices.html#configure-pools-to-control-cost), this should be set based on anticipated usage.
     */
    maxCapacity?: pulumi.Input<number>;
    /**
     * (Integer) The minimum number of idle instances maintained by the pool. This is in addition to any instances in use by active clusters.
     */
    minIdleInstances?: pulumi.Input<number>;
    /**
     * (String) The node type for the instances in the pool. All clusters attached to the pool inherit this node type and the pool's idle instances are allocated based on this type. You can retrieve a list of available node types by using the [List Node Types API](https://docs.databricks.com/dev-tools/api/latest/clusters.html#clusterclusterservicelistnodetypes) call.
     */
    nodeTypeId?: pulumi.Input<string>;
    preloadedDockerImages?: pulumi.Input<pulumi.Input<inputs.InstancePoolPreloadedDockerImage>[]>;
    /**
     * (List) A list with at most one runtime version the pool installs on each instance. Pool clusters that use a preloaded runtime version start faster as they do not have to wait for the image to download. You can retrieve them via databricks.getSparkVersion data source or via  [Runtime Versions API](https://docs.databricks.com/dev-tools/api/latest/clusters.html#clusterclusterservicelistsparkversions) call.
     */
    preloadedSparkVersions?: pulumi.Input<pulumi.Input<string>[]>;
}
