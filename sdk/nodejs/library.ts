// *** WARNING: this file was generated by pulumi-language-nodejs. ***
// *** Do not edit by hand unless you're certain you know what you are doing! ***

import * as pulumi from "@pulumi/pulumi";
import * as inputs from "./types/input";
import * as outputs from "./types/output";
import * as utilities from "./utilities";

/**
 * Installs a [library](https://docs.databricks.com/libraries/index.html) on databricks_cluster. Each different type of library has a slightly different syntax. It's possible to set only one type of library within one resource. Otherwise, the plan will fail with an error.
 *
 * > This resource can only be used with a workspace-level provider!
 *
 * > `databricks.Library` resource would always start the associated cluster if it's not running, so make sure to have auto-termination configured. It's not possible to atomically change the version of the same library without cluster restart. Libraries are fully removed from the cluster only after restart.
 *
 * ## Plugin Framework Migration
 *
 * The library resource has been migrated from sdkv2 to plugin frameworkã€‚ If you encounter any problem with this resource and suspect it is due to the migration, you can fallback to sdkv2 by setting the environment variable in the following way `export USE_SDK_V2_RESOURCES="databricks.Library"`.
 *
 * ## Installing library on all clusters
 *
 * You can install libraries on all clusters with the help of databricks.getClusters data resource:
 *
 * ```typescript
 * import * as pulumi from "@pulumi/pulumi";
 * import * as databricks from "@pulumi/databricks";
 *
 * export = async () => {
 *     const all = await databricks.getClusters({});
 *     const cli: databricks.Library[] = [];
 *     for (const range of all.ids.map((v, k) => ({key: k, value: v}))) {
 *         cli.push(new databricks.Library(`cli-${range.key}`, {
 *             clusterId: range.key,
 *             pypi: {
 *                 "package": "databricks-cli",
 *             },
 *         }));
 *     }
 * }
 * ```
 *
 * ## Java/Scala Maven
 *
 * Installing artifacts from Maven repository. You can also optionally specify a `repo` parameter for a custom Maven-style repository, that should be accessible without any authentication. Maven libraries are resolved in Databricks Control Plane, so repo should be accessible from it. It can even be properly configured [maven s3 wagon](https://github.com/seahen/maven-s3-wagon), [AWS CodeArtifact](https://aws.amazon.com/codeartifact/) or [Azure Artifacts](https://azure.microsoft.com/en-us/services/devops/artifacts/).
 *
 * ```typescript
 * import * as pulumi from "@pulumi/pulumi";
 * import * as databricks from "@pulumi/databricks";
 *
 * const deequ = new databricks.Library("deequ", {
 *     clusterId: _this.id,
 *     maven: {
 *         coordinates: "com.amazon.deequ:deequ:1.0.4",
 *         exclusions: ["org.apache.avro:avro"],
 *     },
 * });
 * ```
 *
 * ## Python PyPI
 *
 * Installing Python PyPI artifacts. You can optionally also specify the `repo` parameter for a custom PyPI mirror, which should be accessible without any authentication for the network that cluster runs in.
 *
 * > `repo` host should be accessible from the Internet by Databricks control plane. If connectivity to custom PyPI repositories is required, please modify cluster-node `/etc/pip.conf` through databricks_global_init_script.
 *
 * ```typescript
 * import * as pulumi from "@pulumi/pulumi";
 * import * as databricks from "@pulumi/databricks";
 *
 * const fbprophet = new databricks.Library("fbprophet", {
 *     clusterId: _this.id,
 *     pypi: {
 *         "package": "fbprophet==0.6",
 *     },
 * });
 * ```
 *
 * ## Python requirements files
 *
 * Installing Python libraries listed in the `requirements.txt` file.  Only Workspace paths and Unity Catalog Volumes paths are supported.  Requires a cluster with DBR 15.0+.
 *
 * ```typescript
 * import * as pulumi from "@pulumi/pulumi";
 * import * as databricks from "@pulumi/databricks";
 *
 * const libraries = new databricks.Library("libraries", {
 *     clusterId: _this.id,
 *     requirements: "/Workspace/path/to/requirements.txt",
 * });
 * ```
 *
 * ## R CRan
 *
 * Installing artifacts from CRan. You can also optionally specify a `repo` parameter for a custom cran mirror.
 *
 * ```typescript
 * import * as pulumi from "@pulumi/pulumi";
 * import * as databricks from "@pulumi/databricks";
 *
 * const rkeops = new databricks.Library("rkeops", {
 *     clusterId: _this.id,
 *     cran: {
 *         "package": "rkeops",
 *     },
 * });
 * ```
 *
 * ## Related Resources
 *
 * The following resources are often used in the same context:
 *
 * * End to end workspace management guide.
 * * databricks.getClusters data to retrieve a list of databricks.Cluster ids.
 * * databricks.Cluster to create [Databricks Clusters](https://docs.databricks.com/clusters/index.html).
 * * databricks.ClusterPolicy to create a databricks.Cluster policy, which limits the ability to create clusters based on a set of rules.
 * * databricks.GlobalInitScript to manage [global init scripts](https://docs.databricks.com/clusters/init-scripts.html#global-init-scripts), which are run on all databricks.Cluster and databricks_job.
 * * databricks.Job to manage [Databricks Jobs](https://docs.databricks.com/jobs.html) to run non-interactive code in a databricks_cluster.
 * * databricks.Pipeline to deploy [Lakeflow Declarative Pipelines](https://docs.databricks.com/aws/en/dlt).
 * * databricks.Repo to manage [Databricks Repos](https://docs.databricks.com/repos.html).
 *
 * ## Import
 *
 * !> Importing this resource is not currently supported.
 */
export class Library extends pulumi.CustomResource {
    /**
     * Get an existing Library resource's state with the given name, ID, and optional extra
     * properties used to qualify the lookup.
     *
     * @param name The _unique_ name of the resulting resource.
     * @param id The _unique_ provider ID of the resource to lookup.
     * @param state Any extra arguments used during the lookup.
     * @param opts Optional settings to control the behavior of the CustomResource.
     */
    public static get(name: string, id: pulumi.Input<pulumi.ID>, state?: LibraryState, opts?: pulumi.CustomResourceOptions): Library {
        return new Library(name, <any>state, { ...opts, id: id });
    }

    /** @internal */
    public static readonly __pulumiType = 'databricks:index/library:Library';

    /**
     * Returns true if the given object is an instance of Library.  This is designed to work even
     * when multiple copies of the Pulumi SDK have been loaded into the same process.
     */
    public static isInstance(obj: any): obj is Library {
        if (obj === undefined || obj === null) {
            return false;
        }
        return obj['__pulumiType'] === Library.__pulumiType;
    }

    /**
     * ID of the databricks.Cluster to install the library on.
     *
     * You must specify exactly **one** of the following library types:
     */
    declare public readonly clusterId: pulumi.Output<string>;
    /**
     * Configuration block for a CRAN library. The block consists of the following fields:
     */
    declare public readonly cran: pulumi.Output<outputs.LibraryCran | undefined>;
    /**
     * Path to the EGG library. Installing Python egg files is deprecated and is not supported in Databricks Runtime 14.0 and above. Use `whl` or `pypi` instead.
     *
     * @deprecated The `egg` library type is deprecated. Please use `whl` or `pypi` instead.
     */
    declare public readonly egg: pulumi.Output<string | undefined>;
    /**
     * Path to the JAR library. Supported URIs include Workspace paths, Unity Catalog Volumes paths, and S3 URIs. For example: `/Workspace/path/to/library.jar`, `/Volumes/path/to/library.jar` or `s3://my-bucket/library.jar`. If S3 is used, make sure the cluster has read access to the library. You may need to launch the cluster with an IAM role to access the S3 URI.
     */
    declare public readonly jar: pulumi.Output<string | undefined>;
    declare public readonly libraryId: pulumi.Output<string>;
    /**
     * Configuration block for a Maven library. The block consists of the following fields:
     */
    declare public readonly maven: pulumi.Output<outputs.LibraryMaven | undefined>;
    /**
     * Configuration block for management through the account provider. This block consists of the following fields:
     */
    declare public readonly providerConfig: pulumi.Output<outputs.LibraryProviderConfig | undefined>;
    /**
     * Configuration block for a PyPI library. The block consists of the following fields:
     */
    declare public readonly pypi: pulumi.Output<outputs.LibraryPypi | undefined>;
    /**
     * Path to the requirements.txt file. Only Workspace paths and Unity Catalog Volumes paths are supported. For example: `/Workspace/path/to/requirements.txt` or `/Volumes/path/to/requirements.txt`. Requires a cluster with DBR 15.0+.
     */
    declare public readonly requirements: pulumi.Output<string | undefined>;
    /**
     * Path to the wheel library. Supported URIs include Workspace paths, Unity Catalog Volumes paths, and S3 URIs. For example: `/Workspace/path/to/library.whl`, `/Volumes/path/to/library.whl` or `s3://my-bucket/library.whl`. If S3 is used, make sure the cluster has read access to the library. You may need to launch the cluster with an IAM role to access the S3 URI.
     */
    declare public readonly whl: pulumi.Output<string | undefined>;

    /**
     * Create a Library resource with the given unique name, arguments, and options.
     *
     * @param name The _unique_ name of the resource.
     * @param args The arguments to use to populate this resource's properties.
     * @param opts A bag of options that control this resource's behavior.
     */
    constructor(name: string, args: LibraryArgs, opts?: pulumi.CustomResourceOptions)
    constructor(name: string, argsOrState?: LibraryArgs | LibraryState, opts?: pulumi.CustomResourceOptions) {
        let resourceInputs: pulumi.Inputs = {};
        opts = opts || {};
        if (opts.id) {
            const state = argsOrState as LibraryState | undefined;
            resourceInputs["clusterId"] = state?.clusterId;
            resourceInputs["cran"] = state?.cran;
            resourceInputs["egg"] = state?.egg;
            resourceInputs["jar"] = state?.jar;
            resourceInputs["libraryId"] = state?.libraryId;
            resourceInputs["maven"] = state?.maven;
            resourceInputs["providerConfig"] = state?.providerConfig;
            resourceInputs["pypi"] = state?.pypi;
            resourceInputs["requirements"] = state?.requirements;
            resourceInputs["whl"] = state?.whl;
        } else {
            const args = argsOrState as LibraryArgs | undefined;
            if (args?.clusterId === undefined && !opts.urn) {
                throw new Error("Missing required property 'clusterId'");
            }
            resourceInputs["clusterId"] = args?.clusterId;
            resourceInputs["cran"] = args?.cran;
            resourceInputs["egg"] = args?.egg;
            resourceInputs["jar"] = args?.jar;
            resourceInputs["libraryId"] = args?.libraryId;
            resourceInputs["maven"] = args?.maven;
            resourceInputs["providerConfig"] = args?.providerConfig;
            resourceInputs["pypi"] = args?.pypi;
            resourceInputs["requirements"] = args?.requirements;
            resourceInputs["whl"] = args?.whl;
        }
        opts = pulumi.mergeOptions(utilities.resourceOptsDefaults(), opts);
        super(Library.__pulumiType, name, resourceInputs, opts);
    }
}

/**
 * Input properties used for looking up and filtering Library resources.
 */
export interface LibraryState {
    /**
     * ID of the databricks.Cluster to install the library on.
     *
     * You must specify exactly **one** of the following library types:
     */
    clusterId?: pulumi.Input<string>;
    /**
     * Configuration block for a CRAN library. The block consists of the following fields:
     */
    cran?: pulumi.Input<inputs.LibraryCran>;
    /**
     * Path to the EGG library. Installing Python egg files is deprecated and is not supported in Databricks Runtime 14.0 and above. Use `whl` or `pypi` instead.
     *
     * @deprecated The `egg` library type is deprecated. Please use `whl` or `pypi` instead.
     */
    egg?: pulumi.Input<string>;
    /**
     * Path to the JAR library. Supported URIs include Workspace paths, Unity Catalog Volumes paths, and S3 URIs. For example: `/Workspace/path/to/library.jar`, `/Volumes/path/to/library.jar` or `s3://my-bucket/library.jar`. If S3 is used, make sure the cluster has read access to the library. You may need to launch the cluster with an IAM role to access the S3 URI.
     */
    jar?: pulumi.Input<string>;
    libraryId?: pulumi.Input<string>;
    /**
     * Configuration block for a Maven library. The block consists of the following fields:
     */
    maven?: pulumi.Input<inputs.LibraryMaven>;
    /**
     * Configuration block for management through the account provider. This block consists of the following fields:
     */
    providerConfig?: pulumi.Input<inputs.LibraryProviderConfig>;
    /**
     * Configuration block for a PyPI library. The block consists of the following fields:
     */
    pypi?: pulumi.Input<inputs.LibraryPypi>;
    /**
     * Path to the requirements.txt file. Only Workspace paths and Unity Catalog Volumes paths are supported. For example: `/Workspace/path/to/requirements.txt` or `/Volumes/path/to/requirements.txt`. Requires a cluster with DBR 15.0+.
     */
    requirements?: pulumi.Input<string>;
    /**
     * Path to the wheel library. Supported URIs include Workspace paths, Unity Catalog Volumes paths, and S3 URIs. For example: `/Workspace/path/to/library.whl`, `/Volumes/path/to/library.whl` or `s3://my-bucket/library.whl`. If S3 is used, make sure the cluster has read access to the library. You may need to launch the cluster with an IAM role to access the S3 URI.
     */
    whl?: pulumi.Input<string>;
}

/**
 * The set of arguments for constructing a Library resource.
 */
export interface LibraryArgs {
    /**
     * ID of the databricks.Cluster to install the library on.
     *
     * You must specify exactly **one** of the following library types:
     */
    clusterId: pulumi.Input<string>;
    /**
     * Configuration block for a CRAN library. The block consists of the following fields:
     */
    cran?: pulumi.Input<inputs.LibraryCran>;
    /**
     * Path to the EGG library. Installing Python egg files is deprecated and is not supported in Databricks Runtime 14.0 and above. Use `whl` or `pypi` instead.
     *
     * @deprecated The `egg` library type is deprecated. Please use `whl` or `pypi` instead.
     */
    egg?: pulumi.Input<string>;
    /**
     * Path to the JAR library. Supported URIs include Workspace paths, Unity Catalog Volumes paths, and S3 URIs. For example: `/Workspace/path/to/library.jar`, `/Volumes/path/to/library.jar` or `s3://my-bucket/library.jar`. If S3 is used, make sure the cluster has read access to the library. You may need to launch the cluster with an IAM role to access the S3 URI.
     */
    jar?: pulumi.Input<string>;
    libraryId?: pulumi.Input<string>;
    /**
     * Configuration block for a Maven library. The block consists of the following fields:
     */
    maven?: pulumi.Input<inputs.LibraryMaven>;
    /**
     * Configuration block for management through the account provider. This block consists of the following fields:
     */
    providerConfig?: pulumi.Input<inputs.LibraryProviderConfig>;
    /**
     * Configuration block for a PyPI library. The block consists of the following fields:
     */
    pypi?: pulumi.Input<inputs.LibraryPypi>;
    /**
     * Path to the requirements.txt file. Only Workspace paths and Unity Catalog Volumes paths are supported. For example: `/Workspace/path/to/requirements.txt` or `/Volumes/path/to/requirements.txt`. Requires a cluster with DBR 15.0+.
     */
    requirements?: pulumi.Input<string>;
    /**
     * Path to the wheel library. Supported URIs include Workspace paths, Unity Catalog Volumes paths, and S3 URIs. For example: `/Workspace/path/to/library.whl`, `/Volumes/path/to/library.whl` or `s3://my-bucket/library.whl`. If S3 is used, make sure the cluster has read access to the library. You may need to launch the cluster with an IAM role to access the S3 URI.
     */
    whl?: pulumi.Input<string>;
}
