// *** WARNING: this file was generated by pulumi-language-nodejs. ***
// *** Do not edit by hand unless you're certain you know what you are doing! ***

import * as pulumi from "@pulumi/pulumi";
import * as inputs from "./types/input";
import * as outputs from "./types/output";
import * as utilities from "./utilities";

/**
 * [![Private Preview](https://img.shields.io/badge/Release_Stage-Private_Preview-blueviolet)](https://docs.databricks.com/aws/en/release-notes/release-types)
 *
 * ## Import
 *
 * As of Pulumi v1.5, resources can be imported through configuration.
 *
 * hcl
 *
 * import {
 *
 *   id = "name"
 *
 *   to = databricks_feature_engineering_kafka_config.this
 *
 * }
 *
 * If you are using an older version of Pulumi, import the resource using the `pulumi import` command as follows:
 *
 * ```sh
 * $ pulumi import databricks:index/featureEngineeringKafkaConfig:FeatureEngineeringKafkaConfig this "name"
 * ```
 */
export class FeatureEngineeringKafkaConfig extends pulumi.CustomResource {
    /**
     * Get an existing FeatureEngineeringKafkaConfig resource's state with the given name, ID, and optional extra
     * properties used to qualify the lookup.
     *
     * @param name The _unique_ name of the resulting resource.
     * @param id The _unique_ provider ID of the resource to lookup.
     * @param state Any extra arguments used during the lookup.
     * @param opts Optional settings to control the behavior of the CustomResource.
     */
    public static get(name: string, id: pulumi.Input<pulumi.ID>, state?: FeatureEngineeringKafkaConfigState, opts?: pulumi.CustomResourceOptions): FeatureEngineeringKafkaConfig {
        return new FeatureEngineeringKafkaConfig(name, <any>state, { ...opts, id: id });
    }

    /** @internal */
    public static readonly __pulumiType = 'databricks:index/featureEngineeringKafkaConfig:FeatureEngineeringKafkaConfig';

    /**
     * Returns true if the given object is an instance of FeatureEngineeringKafkaConfig.  This is designed to work even
     * when multiple copies of the Pulumi SDK have been loaded into the same process.
     */
    public static isInstance(obj: any): obj is FeatureEngineeringKafkaConfig {
        if (obj === undefined || obj === null) {
            return false;
        }
        return obj['__pulumiType'] === FeatureEngineeringKafkaConfig.__pulumiType;
    }

    /**
     * Authentication configuration for connection to topics
     */
    declare public readonly authConfig: pulumi.Output<outputs.FeatureEngineeringKafkaConfigAuthConfig>;
    /**
     * A user-provided and managed source for backfilling data. Historical data is used when creating a training set from streaming features linked to this Kafka config.
     * In the future, a separate table will be maintained by Databricks for forward filling data.
     * The schema for this source must match exactly that of the key and value schemas specified for this Kafka config
     */
    declare public readonly backfillSource: pulumi.Output<outputs.FeatureEngineeringKafkaConfigBackfillSource | undefined>;
    /**
     * A comma-separated list of host/port pairs pointing to Kafka cluster
     */
    declare public readonly bootstrapServers: pulumi.Output<string>;
    /**
     * Catch-all for miscellaneous options. Keys should be source options or Kafka consumer options (kafka.*)
     */
    declare public readonly extraOptions: pulumi.Output<{[key: string]: string} | undefined>;
    /**
     * Schema configuration for extracting message keys from topics. At least one of keySchema and valueSchema must be provided
     */
    declare public readonly keySchema: pulumi.Output<outputs.FeatureEngineeringKafkaConfigKeySchema | undefined>;
    /**
     * (string) - Name that uniquely identifies this Kafka config within the metastore. This will be the identifier used from the Feature object to reference these configs for a feature.
     * Can be distinct from topic name
     */
    declare public /*out*/ readonly name: pulumi.Output<string>;
    /**
     * Options to configure which Kafka topics to pull data from
     */
    declare public readonly subscriptionMode: pulumi.Output<outputs.FeatureEngineeringKafkaConfigSubscriptionMode>;
    /**
     * Schema configuration for extracting message values from topics. At least one of keySchema and valueSchema must be provided
     */
    declare public readonly valueSchema: pulumi.Output<outputs.FeatureEngineeringKafkaConfigValueSchema | undefined>;

    /**
     * Create a FeatureEngineeringKafkaConfig resource with the given unique name, arguments, and options.
     *
     * @param name The _unique_ name of the resource.
     * @param args The arguments to use to populate this resource's properties.
     * @param opts A bag of options that control this resource's behavior.
     */
    constructor(name: string, args: FeatureEngineeringKafkaConfigArgs, opts?: pulumi.CustomResourceOptions)
    constructor(name: string, argsOrState?: FeatureEngineeringKafkaConfigArgs | FeatureEngineeringKafkaConfigState, opts?: pulumi.CustomResourceOptions) {
        let resourceInputs: pulumi.Inputs = {};
        opts = opts || {};
        if (opts.id) {
            const state = argsOrState as FeatureEngineeringKafkaConfigState | undefined;
            resourceInputs["authConfig"] = state?.authConfig;
            resourceInputs["backfillSource"] = state?.backfillSource;
            resourceInputs["bootstrapServers"] = state?.bootstrapServers;
            resourceInputs["extraOptions"] = state?.extraOptions;
            resourceInputs["keySchema"] = state?.keySchema;
            resourceInputs["name"] = state?.name;
            resourceInputs["subscriptionMode"] = state?.subscriptionMode;
            resourceInputs["valueSchema"] = state?.valueSchema;
        } else {
            const args = argsOrState as FeatureEngineeringKafkaConfigArgs | undefined;
            if (args?.authConfig === undefined && !opts.urn) {
                throw new Error("Missing required property 'authConfig'");
            }
            if (args?.bootstrapServers === undefined && !opts.urn) {
                throw new Error("Missing required property 'bootstrapServers'");
            }
            if (args?.subscriptionMode === undefined && !opts.urn) {
                throw new Error("Missing required property 'subscriptionMode'");
            }
            resourceInputs["authConfig"] = args?.authConfig;
            resourceInputs["backfillSource"] = args?.backfillSource;
            resourceInputs["bootstrapServers"] = args?.bootstrapServers;
            resourceInputs["extraOptions"] = args?.extraOptions;
            resourceInputs["keySchema"] = args?.keySchema;
            resourceInputs["subscriptionMode"] = args?.subscriptionMode;
            resourceInputs["valueSchema"] = args?.valueSchema;
            resourceInputs["name"] = undefined /*out*/;
        }
        opts = pulumi.mergeOptions(utilities.resourceOptsDefaults(), opts);
        super(FeatureEngineeringKafkaConfig.__pulumiType, name, resourceInputs, opts);
    }
}

/**
 * Input properties used for looking up and filtering FeatureEngineeringKafkaConfig resources.
 */
export interface FeatureEngineeringKafkaConfigState {
    /**
     * Authentication configuration for connection to topics
     */
    authConfig?: pulumi.Input<inputs.FeatureEngineeringKafkaConfigAuthConfig>;
    /**
     * A user-provided and managed source for backfilling data. Historical data is used when creating a training set from streaming features linked to this Kafka config.
     * In the future, a separate table will be maintained by Databricks for forward filling data.
     * The schema for this source must match exactly that of the key and value schemas specified for this Kafka config
     */
    backfillSource?: pulumi.Input<inputs.FeatureEngineeringKafkaConfigBackfillSource>;
    /**
     * A comma-separated list of host/port pairs pointing to Kafka cluster
     */
    bootstrapServers?: pulumi.Input<string>;
    /**
     * Catch-all for miscellaneous options. Keys should be source options or Kafka consumer options (kafka.*)
     */
    extraOptions?: pulumi.Input<{[key: string]: pulumi.Input<string>}>;
    /**
     * Schema configuration for extracting message keys from topics. At least one of keySchema and valueSchema must be provided
     */
    keySchema?: pulumi.Input<inputs.FeatureEngineeringKafkaConfigKeySchema>;
    /**
     * (string) - Name that uniquely identifies this Kafka config within the metastore. This will be the identifier used from the Feature object to reference these configs for a feature.
     * Can be distinct from topic name
     */
    name?: pulumi.Input<string>;
    /**
     * Options to configure which Kafka topics to pull data from
     */
    subscriptionMode?: pulumi.Input<inputs.FeatureEngineeringKafkaConfigSubscriptionMode>;
    /**
     * Schema configuration for extracting message values from topics. At least one of keySchema and valueSchema must be provided
     */
    valueSchema?: pulumi.Input<inputs.FeatureEngineeringKafkaConfigValueSchema>;
}

/**
 * The set of arguments for constructing a FeatureEngineeringKafkaConfig resource.
 */
export interface FeatureEngineeringKafkaConfigArgs {
    /**
     * Authentication configuration for connection to topics
     */
    authConfig: pulumi.Input<inputs.FeatureEngineeringKafkaConfigAuthConfig>;
    /**
     * A user-provided and managed source for backfilling data. Historical data is used when creating a training set from streaming features linked to this Kafka config.
     * In the future, a separate table will be maintained by Databricks for forward filling data.
     * The schema for this source must match exactly that of the key and value schemas specified for this Kafka config
     */
    backfillSource?: pulumi.Input<inputs.FeatureEngineeringKafkaConfigBackfillSource>;
    /**
     * A comma-separated list of host/port pairs pointing to Kafka cluster
     */
    bootstrapServers: pulumi.Input<string>;
    /**
     * Catch-all for miscellaneous options. Keys should be source options or Kafka consumer options (kafka.*)
     */
    extraOptions?: pulumi.Input<{[key: string]: pulumi.Input<string>}>;
    /**
     * Schema configuration for extracting message keys from topics. At least one of keySchema and valueSchema must be provided
     */
    keySchema?: pulumi.Input<inputs.FeatureEngineeringKafkaConfigKeySchema>;
    /**
     * Options to configure which Kafka topics to pull data from
     */
    subscriptionMode: pulumi.Input<inputs.FeatureEngineeringKafkaConfigSubscriptionMode>;
    /**
     * Schema configuration for extracting message values from topics. At least one of keySchema and valueSchema must be provided
     */
    valueSchema?: pulumi.Input<inputs.FeatureEngineeringKafkaConfigValueSchema>;
}
