// *** WARNING: this file was generated by pulumi-language-nodejs. ***
// *** Do not edit by hand unless you're certain you know what you are doing! ***

import * as pulumi from "@pulumi/pulumi";
import * as inputs from "./types/input";
import * as outputs from "./types/output";
import * as utilities from "./utilities";

/**
 * !> This resource has been deprecated and will be removed soon. Please use the databricks.QualityMonitor resource instead.
 *
 * This resource allows you to manage [Lakehouse Monitors](https://docs.databricks.com/en/lakehouse-monitoring/index.html) in Databricks.
 *
 * A `databricks.LakehouseMonitor` is attached to a databricks.SqlTable and can be of type timeseries, snapshot or inference.
 *
 * ## Example Usage
 *
 * ```typescript
 * import * as pulumi from "@pulumi/pulumi";
 * import * as databricks from "@pulumi/databricks";
 *
 * const sandbox = new databricks.Catalog("sandbox", {
 *     name: "sandbox",
 *     comment: "this catalog is managed by terraform",
 *     properties: {
 *         purpose: "testing",
 *     },
 * });
 * const things = new databricks.Schema("things", {
 *     catalogName: sandbox.id,
 *     name: "things",
 *     comment: "this database is managed by terraform",
 *     properties: {
 *         kind: "various",
 *     },
 * });
 * const myTestTable = new databricks.SqlTable("myTestTable", {
 *     catalogName: "main",
 *     schemaName: things.name,
 *     name: "bar",
 *     tableType: "MANAGED",
 *     dataSourceFormat: "DELTA",
 *     columns: [{
 *         name: "timestamp",
 *         type: "int",
 *     }],
 * });
 * const testTimeseriesMonitor = new databricks.LakehouseMonitor("testTimeseriesMonitor", {
 *     tableName: pulumi.interpolate`${sandbox.name}.${things.name}.${myTestTable.name}`,
 *     assetsDir: pulumi.interpolate`/Shared/provider-test/databricks_lakehouse_monitoring/${myTestTable.name}`,
 *     outputSchemaName: pulumi.interpolate`${sandbox.name}.${things.name}`,
 *     timeSeries: {
 *         granularities: ["1 hour"],
 *         timestampCol: "timestamp",
 *     },
 * });
 * ```
 *
 * ### Inference Monitor
 *
 * ```typescript
 * import * as pulumi from "@pulumi/pulumi";
 * import * as databricks from "@pulumi/databricks";
 *
 * const testMonitorInference = new databricks.LakehouseMonitor("testMonitorInference", {
 *     tableName: `${sandbox.name}.${things.name}.${myTestTable.name}`,
 *     assetsDir: `/Shared/provider-test/databricks_lakehouse_monitoring/${myTestTable.name}`,
 *     outputSchemaName: `${sandbox.name}.${things.name}`,
 *     inferenceLog: {
 *         granularities: ["1 hour"],
 *         timestampCol: "timestamp",
 *         predictionCol: "prediction",
 *         modelIdCol: "model_id",
 *         problemType: "PROBLEM_TYPE_REGRESSION",
 *     },
 * });
 * ```
 * ### Snapshot Monitor
 * ```typescript
 * import * as pulumi from "@pulumi/pulumi";
 * import * as databricks from "@pulumi/databricks";
 *
 * const testMonitorInference = new databricks.LakehouseMonitor("testMonitorInference", {
 *     tableName: `${sandbox.name}.${things.name}.${myTestTable.name}`,
 *     assetsDir: `/Shared/provider-test/databricks_lakehouse_monitoring/${myTestTable.name}`,
 *     outputSchemaName: `${sandbox.name}.${things.name}`,
 *     snapshot: {},
 * });
 * ```
 *
 * ## Related Resources
 *
 * The following resources are often used in the same context:
 *
 * * databricks.Catalog
 * * databricks.Schema
 * * databricks.SqlTable
 */
export class LakehouseMonitor extends pulumi.CustomResource {
    /**
     * Get an existing LakehouseMonitor resource's state with the given name, ID, and optional extra
     * properties used to qualify the lookup.
     *
     * @param name The _unique_ name of the resulting resource.
     * @param id The _unique_ provider ID of the resource to lookup.
     * @param state Any extra arguments used during the lookup.
     * @param opts Optional settings to control the behavior of the CustomResource.
     */
    public static get(name: string, id: pulumi.Input<pulumi.ID>, state?: LakehouseMonitorState, opts?: pulumi.CustomResourceOptions): LakehouseMonitor {
        return new LakehouseMonitor(name, <any>state, { ...opts, id: id });
    }

    /** @internal */
    public static readonly __pulumiType = 'databricks:index/lakehouseMonitor:LakehouseMonitor';

    /**
     * Returns true if the given object is an instance of LakehouseMonitor.  This is designed to work even
     * when multiple copies of the Pulumi SDK have been loaded into the same process.
     */
    public static isInstance(obj: any): obj is LakehouseMonitor {
        if (obj === undefined || obj === null) {
            return false;
        }
        return obj['__pulumiType'] === LakehouseMonitor.__pulumiType;
    }

    /**
     * The directory to store the monitoring assets (Eg. Dashboard and Metric Tables)
     */
    declare public readonly assetsDir: pulumi.Output<string>;
    /**
     * Name of the baseline table from which drift metrics are computed from.Columns in the monitored table should also be present in the baseline
     * table.
     */
    declare public readonly baselineTableName: pulumi.Output<string | undefined>;
    /**
     * Custom metrics to compute on the monitored table. These can be aggregate metrics, derived metrics (from already computed aggregate metrics), or drift metrics (comparing metrics across time windows).
     */
    declare public readonly customMetrics: pulumi.Output<outputs.LakehouseMonitorCustomMetric[] | undefined>;
    /**
     * The ID of the generated dashboard.
     */
    declare public /*out*/ readonly dashboardId: pulumi.Output<string>;
    /**
     * The data classification config for the monitor
     */
    declare public readonly dataClassificationConfig: pulumi.Output<outputs.LakehouseMonitorDataClassificationConfig | undefined>;
    /**
     * The full name of the drift metrics table. Format: __catalog_name__.__schema_name__.__table_name__.
     */
    declare public /*out*/ readonly driftMetricsTableName: pulumi.Output<string>;
    /**
     * Configuration for the inference log monitor
     */
    declare public readonly inferenceLog: pulumi.Output<outputs.LakehouseMonitorInferenceLog | undefined>;
    declare public readonly latestMonitorFailureMsg: pulumi.Output<string | undefined>;
    /**
     * The version of the monitor config (e.g. 1,2,3). If negative, the monitor may be corrupted
     */
    declare public /*out*/ readonly monitorVersion: pulumi.Output<number>;
    /**
     * The notification settings for the monitor.  The following optional blocks are supported, each consisting of the single string array field with name `emailAddresses` containing a list of emails to notify:
     */
    declare public readonly notifications: pulumi.Output<outputs.LakehouseMonitorNotifications | undefined>;
    /**
     * Schema where output metric tables are created
     */
    declare public readonly outputSchemaName: pulumi.Output<string>;
    /**
     * The full name of the profile metrics table. Format: __catalog_name__.__schema_name__.__table_name__.
     */
    declare public /*out*/ readonly profileMetricsTableName: pulumi.Output<string>;
    /**
     * The schedule for automatically updating and refreshing metric tables.  This block consists of following fields:
     */
    declare public readonly schedule: pulumi.Output<outputs.LakehouseMonitorSchedule | undefined>;
    /**
     * Whether to skip creating a default dashboard summarizing data quality metrics.
     */
    declare public readonly skipBuiltinDashboard: pulumi.Output<boolean | undefined>;
    /**
     * List of column expressions to slice data with for targeted analysis. The data is grouped by each expression independently, resulting in a separate slice for each predicate and its complements. For high-cardinality columns, only the top 100 unique values by frequency will generate slices.
     */
    declare public readonly slicingExprs: pulumi.Output<string[] | undefined>;
    /**
     * Configuration for monitoring snapshot tables.
     */
    declare public readonly snapshot: pulumi.Output<outputs.LakehouseMonitorSnapshot | undefined>;
    /**
     * Status of the Monitor
     */
    declare public /*out*/ readonly status: pulumi.Output<string>;
    /**
     * The full name of the table to attach the monitor too. Its of the format {catalog}.{schema}.{tableName}
     */
    declare public readonly tableName: pulumi.Output<string>;
    /**
     * Configuration for monitoring timeseries tables.
     */
    declare public readonly timeSeries: pulumi.Output<outputs.LakehouseMonitorTimeSeries | undefined>;
    /**
     * Optional argument to specify the warehouse for dashboard creation. If not specified, the first running warehouse will be used.
     */
    declare public readonly warehouseId: pulumi.Output<string | undefined>;

    /**
     * Create a LakehouseMonitor resource with the given unique name, arguments, and options.
     *
     * @param name The _unique_ name of the resource.
     * @param args The arguments to use to populate this resource's properties.
     * @param opts A bag of options that control this resource's behavior.
     */
    constructor(name: string, args: LakehouseMonitorArgs, opts?: pulumi.CustomResourceOptions)
    constructor(name: string, argsOrState?: LakehouseMonitorArgs | LakehouseMonitorState, opts?: pulumi.CustomResourceOptions) {
        let resourceInputs: pulumi.Inputs = {};
        opts = opts || {};
        if (opts.id) {
            const state = argsOrState as LakehouseMonitorState | undefined;
            resourceInputs["assetsDir"] = state?.assetsDir;
            resourceInputs["baselineTableName"] = state?.baselineTableName;
            resourceInputs["customMetrics"] = state?.customMetrics;
            resourceInputs["dashboardId"] = state?.dashboardId;
            resourceInputs["dataClassificationConfig"] = state?.dataClassificationConfig;
            resourceInputs["driftMetricsTableName"] = state?.driftMetricsTableName;
            resourceInputs["inferenceLog"] = state?.inferenceLog;
            resourceInputs["latestMonitorFailureMsg"] = state?.latestMonitorFailureMsg;
            resourceInputs["monitorVersion"] = state?.monitorVersion;
            resourceInputs["notifications"] = state?.notifications;
            resourceInputs["outputSchemaName"] = state?.outputSchemaName;
            resourceInputs["profileMetricsTableName"] = state?.profileMetricsTableName;
            resourceInputs["schedule"] = state?.schedule;
            resourceInputs["skipBuiltinDashboard"] = state?.skipBuiltinDashboard;
            resourceInputs["slicingExprs"] = state?.slicingExprs;
            resourceInputs["snapshot"] = state?.snapshot;
            resourceInputs["status"] = state?.status;
            resourceInputs["tableName"] = state?.tableName;
            resourceInputs["timeSeries"] = state?.timeSeries;
            resourceInputs["warehouseId"] = state?.warehouseId;
        } else {
            const args = argsOrState as LakehouseMonitorArgs | undefined;
            if (args?.assetsDir === undefined && !opts.urn) {
                throw new Error("Missing required property 'assetsDir'");
            }
            if (args?.outputSchemaName === undefined && !opts.urn) {
                throw new Error("Missing required property 'outputSchemaName'");
            }
            if (args?.tableName === undefined && !opts.urn) {
                throw new Error("Missing required property 'tableName'");
            }
            resourceInputs["assetsDir"] = args?.assetsDir;
            resourceInputs["baselineTableName"] = args?.baselineTableName;
            resourceInputs["customMetrics"] = args?.customMetrics;
            resourceInputs["dataClassificationConfig"] = args?.dataClassificationConfig;
            resourceInputs["inferenceLog"] = args?.inferenceLog;
            resourceInputs["latestMonitorFailureMsg"] = args?.latestMonitorFailureMsg;
            resourceInputs["notifications"] = args?.notifications;
            resourceInputs["outputSchemaName"] = args?.outputSchemaName;
            resourceInputs["schedule"] = args?.schedule;
            resourceInputs["skipBuiltinDashboard"] = args?.skipBuiltinDashboard;
            resourceInputs["slicingExprs"] = args?.slicingExprs;
            resourceInputs["snapshot"] = args?.snapshot;
            resourceInputs["tableName"] = args?.tableName;
            resourceInputs["timeSeries"] = args?.timeSeries;
            resourceInputs["warehouseId"] = args?.warehouseId;
            resourceInputs["dashboardId"] = undefined /*out*/;
            resourceInputs["driftMetricsTableName"] = undefined /*out*/;
            resourceInputs["monitorVersion"] = undefined /*out*/;
            resourceInputs["profileMetricsTableName"] = undefined /*out*/;
            resourceInputs["status"] = undefined /*out*/;
        }
        opts = pulumi.mergeOptions(utilities.resourceOptsDefaults(), opts);
        super(LakehouseMonitor.__pulumiType, name, resourceInputs, opts);
    }
}

/**
 * Input properties used for looking up and filtering LakehouseMonitor resources.
 */
export interface LakehouseMonitorState {
    /**
     * The directory to store the monitoring assets (Eg. Dashboard and Metric Tables)
     */
    assetsDir?: pulumi.Input<string>;
    /**
     * Name of the baseline table from which drift metrics are computed from.Columns in the monitored table should also be present in the baseline
     * table.
     */
    baselineTableName?: pulumi.Input<string>;
    /**
     * Custom metrics to compute on the monitored table. These can be aggregate metrics, derived metrics (from already computed aggregate metrics), or drift metrics (comparing metrics across time windows).
     */
    customMetrics?: pulumi.Input<pulumi.Input<inputs.LakehouseMonitorCustomMetric>[]>;
    /**
     * The ID of the generated dashboard.
     */
    dashboardId?: pulumi.Input<string>;
    /**
     * The data classification config for the monitor
     */
    dataClassificationConfig?: pulumi.Input<inputs.LakehouseMonitorDataClassificationConfig>;
    /**
     * The full name of the drift metrics table. Format: __catalog_name__.__schema_name__.__table_name__.
     */
    driftMetricsTableName?: pulumi.Input<string>;
    /**
     * Configuration for the inference log monitor
     */
    inferenceLog?: pulumi.Input<inputs.LakehouseMonitorInferenceLog>;
    latestMonitorFailureMsg?: pulumi.Input<string>;
    /**
     * The version of the monitor config (e.g. 1,2,3). If negative, the monitor may be corrupted
     */
    monitorVersion?: pulumi.Input<number>;
    /**
     * The notification settings for the monitor.  The following optional blocks are supported, each consisting of the single string array field with name `emailAddresses` containing a list of emails to notify:
     */
    notifications?: pulumi.Input<inputs.LakehouseMonitorNotifications>;
    /**
     * Schema where output metric tables are created
     */
    outputSchemaName?: pulumi.Input<string>;
    /**
     * The full name of the profile metrics table. Format: __catalog_name__.__schema_name__.__table_name__.
     */
    profileMetricsTableName?: pulumi.Input<string>;
    /**
     * The schedule for automatically updating and refreshing metric tables.  This block consists of following fields:
     */
    schedule?: pulumi.Input<inputs.LakehouseMonitorSchedule>;
    /**
     * Whether to skip creating a default dashboard summarizing data quality metrics.
     */
    skipBuiltinDashboard?: pulumi.Input<boolean>;
    /**
     * List of column expressions to slice data with for targeted analysis. The data is grouped by each expression independently, resulting in a separate slice for each predicate and its complements. For high-cardinality columns, only the top 100 unique values by frequency will generate slices.
     */
    slicingExprs?: pulumi.Input<pulumi.Input<string>[]>;
    /**
     * Configuration for monitoring snapshot tables.
     */
    snapshot?: pulumi.Input<inputs.LakehouseMonitorSnapshot>;
    /**
     * Status of the Monitor
     */
    status?: pulumi.Input<string>;
    /**
     * The full name of the table to attach the monitor too. Its of the format {catalog}.{schema}.{tableName}
     */
    tableName?: pulumi.Input<string>;
    /**
     * Configuration for monitoring timeseries tables.
     */
    timeSeries?: pulumi.Input<inputs.LakehouseMonitorTimeSeries>;
    /**
     * Optional argument to specify the warehouse for dashboard creation. If not specified, the first running warehouse will be used.
     */
    warehouseId?: pulumi.Input<string>;
}

/**
 * The set of arguments for constructing a LakehouseMonitor resource.
 */
export interface LakehouseMonitorArgs {
    /**
     * The directory to store the monitoring assets (Eg. Dashboard and Metric Tables)
     */
    assetsDir: pulumi.Input<string>;
    /**
     * Name of the baseline table from which drift metrics are computed from.Columns in the monitored table should also be present in the baseline
     * table.
     */
    baselineTableName?: pulumi.Input<string>;
    /**
     * Custom metrics to compute on the monitored table. These can be aggregate metrics, derived metrics (from already computed aggregate metrics), or drift metrics (comparing metrics across time windows).
     */
    customMetrics?: pulumi.Input<pulumi.Input<inputs.LakehouseMonitorCustomMetric>[]>;
    /**
     * The data classification config for the monitor
     */
    dataClassificationConfig?: pulumi.Input<inputs.LakehouseMonitorDataClassificationConfig>;
    /**
     * Configuration for the inference log monitor
     */
    inferenceLog?: pulumi.Input<inputs.LakehouseMonitorInferenceLog>;
    latestMonitorFailureMsg?: pulumi.Input<string>;
    /**
     * The notification settings for the monitor.  The following optional blocks are supported, each consisting of the single string array field with name `emailAddresses` containing a list of emails to notify:
     */
    notifications?: pulumi.Input<inputs.LakehouseMonitorNotifications>;
    /**
     * Schema where output metric tables are created
     */
    outputSchemaName: pulumi.Input<string>;
    /**
     * The schedule for automatically updating and refreshing metric tables.  This block consists of following fields:
     */
    schedule?: pulumi.Input<inputs.LakehouseMonitorSchedule>;
    /**
     * Whether to skip creating a default dashboard summarizing data quality metrics.
     */
    skipBuiltinDashboard?: pulumi.Input<boolean>;
    /**
     * List of column expressions to slice data with for targeted analysis. The data is grouped by each expression independently, resulting in a separate slice for each predicate and its complements. For high-cardinality columns, only the top 100 unique values by frequency will generate slices.
     */
    slicingExprs?: pulumi.Input<pulumi.Input<string>[]>;
    /**
     * Configuration for monitoring snapshot tables.
     */
    snapshot?: pulumi.Input<inputs.LakehouseMonitorSnapshot>;
    /**
     * The full name of the table to attach the monitor too. Its of the format {catalog}.{schema}.{tableName}
     */
    tableName: pulumi.Input<string>;
    /**
     * Configuration for monitoring timeseries tables.
     */
    timeSeries?: pulumi.Input<inputs.LakehouseMonitorTimeSeries>;
    /**
     * Optional argument to specify the warehouse for dashboard creation. If not specified, the first running warehouse will be used.
     */
    warehouseId?: pulumi.Input<string>;
}
