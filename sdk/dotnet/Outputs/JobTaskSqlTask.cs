// *** WARNING: this file was generated by the Pulumi Terraform Bridge (tfgen) Tool. ***
// *** Do not edit by hand unless you're certain you know what you are doing! ***

using System;
using System.Collections.Generic;
using System.Collections.Immutable;
using System.Threading.Tasks;
using Pulumi.Serialization;

namespace Pulumi.Databricks.Outputs
{

    [OutputType]
    public sealed class JobTaskSqlTask
    {
        /// <summary>
        /// block consisting of single string field: `alert_id` - identifier of the Databricks SQL Alert.
        /// </summary>
        public readonly Outputs.JobTaskSqlTaskAlert? Alert;
        /// <summary>
        /// block consisting of single string field: `dashboard_id` - identifier of the Databricks SQL Dashboard databricks_sql_dashboard.
        /// </summary>
        public readonly Outputs.JobTaskSqlTaskDashboard? Dashboard;
        /// <summary>
        /// block consisting of single string field: `path` - a relative path to the file (inside the Git repository) with SQL commands to execute.  *Requires `git_source` configuration block*.
        /// 
        /// Example
        /// 
        /// ```csharp
        /// using System.Collections.Generic;
        /// using System.Linq;
        /// using Pulumi;
        /// using Databricks = Pulumi.Databricks;
        /// 
        /// return await Deployment.RunAsync(() =&gt; 
        /// {
        ///     var sqlAggregationJob = new Databricks.Job("sqlAggregationJob", new()
        ///     {
        ///         Tasks = new[]
        ///         {
        ///             new Databricks.Inputs.JobTaskArgs
        ///             {
        ///                 TaskKey = "run_agg_query",
        ///                 SqlTask = new Databricks.Inputs.JobTaskSqlTaskArgs
        ///                 {
        ///                     WarehouseId = databricks_sql_endpoint.Sql_job_warehouse.Id,
        ///                     Query = new Databricks.Inputs.JobTaskSqlTaskQueryArgs
        ///                     {
        ///                         QueryId = databricks_sql_query.Agg_query.Id,
        ///                     },
        ///                 },
        ///             },
        ///         },
        ///     });
        /// 
        /// });
        /// ```
        /// </summary>
        public readonly Outputs.JobTaskSqlTaskFile? File;
        /// <summary>
        /// (Map) parameters to be used for each run of this task. The SQL alert task does not support custom parameters.
        /// </summary>
        public readonly ImmutableDictionary<string, object>? Parameters;
        /// <summary>
        /// block consisting of single string field: `query_id` - identifier of the Databricks SQL Query (databricks_sql_query).
        /// </summary>
        public readonly Outputs.JobTaskSqlTaskQuery? Query;
        /// <summary>
        /// ID of the (the databricks_sql_endpoint) that will be used to execute the task.  Only Serverless &amp; Pro warehouses are supported right now.
        /// </summary>
        public readonly string? WarehouseId;

        [OutputConstructor]
        private JobTaskSqlTask(
            Outputs.JobTaskSqlTaskAlert? alert,

            Outputs.JobTaskSqlTaskDashboard? dashboard,

            Outputs.JobTaskSqlTaskFile? file,

            ImmutableDictionary<string, object>? parameters,

            Outputs.JobTaskSqlTaskQuery? query,

            string? warehouseId)
        {
            Alert = alert;
            Dashboard = dashboard;
            File = file;
            Parameters = parameters;
            Query = query;
            WarehouseId = warehouseId;
        }
    }
}
