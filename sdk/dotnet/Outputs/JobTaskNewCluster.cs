// *** WARNING: this file was generated by pulumi-language-dotnet. ***
// *** Do not edit by hand unless you're certain you know what you are doing! ***

using System;
using System.Collections.Generic;
using System.Collections.Immutable;
using System.Threading.Tasks;
using Pulumi.Serialization;

namespace Pulumi.Databricks.Outputs
{

    [OutputType]
    public sealed class JobTaskNewCluster
    {
        public readonly ImmutableArray<string> __applyPolicyDefaultValuesAllowLists;
        public readonly bool? ApplyPolicyDefaultValues;
        public readonly Outputs.JobTaskNewClusterAutoscale? Autoscale;
        public readonly Outputs.JobTaskNewClusterAwsAttributes? AwsAttributes;
        public readonly Outputs.JobTaskNewClusterAzureAttributes? AzureAttributes;
        public readonly string? ClusterId;
        public readonly Outputs.JobTaskNewClusterClusterLogConf? ClusterLogConf;
        public readonly ImmutableArray<Outputs.JobTaskNewClusterClusterMountInfo> ClusterMountInfos;
        public readonly string? ClusterName;
        public readonly ImmutableDictionary<string, string>? CustomTags;
        public readonly string? DataSecurityMode;
        public readonly Outputs.JobTaskNewClusterDockerImage? DockerImage;
        public readonly string? DriverInstancePoolId;
        public readonly string? DriverNodeTypeId;
        public readonly bool? EnableElasticDisk;
        public readonly bool? EnableLocalDiskEncryption;
        public readonly Outputs.JobTaskNewClusterGcpAttributes? GcpAttributes;
        public readonly string? IdempotencyToken;
        public readonly ImmutableArray<Outputs.JobTaskNewClusterInitScript> InitScripts;
        public readonly string? InstancePoolId;
        public readonly bool? IsSingleNode;
        public readonly string? Kind;
        /// <summary>
        /// (List) An optional list of libraries to be installed on the cluster that will execute the job. See library Configuration Block below.
        /// </summary>
        public readonly ImmutableArray<Outputs.JobTaskNewClusterLibrary> Libraries;
        public readonly string? NodeTypeId;
        public readonly int? NumWorkers;
        public readonly string? PolicyId;
        /// <summary>
        /// Configure the provider for management through account provider. This block consists of the following fields:
        /// </summary>
        public readonly Outputs.JobTaskNewClusterProviderConfig? ProviderConfig;
        public readonly int? RemoteDiskThroughput;
        public readonly string? RuntimeEngine;
        public readonly string? SingleUserName;
        public readonly ImmutableDictionary<string, string>? SparkConf;
        public readonly ImmutableDictionary<string, string>? SparkEnvVars;
        public readonly string? SparkVersion;
        public readonly ImmutableArray<string> SshPublicKeys;
        public readonly int? TotalInitialRemoteDiskSize;
        public readonly bool? UseMlRuntime;
        /// <summary>
        /// isn't supported
        /// </summary>
        public readonly Outputs.JobTaskNewClusterWorkloadType? WorkloadType;

        [OutputConstructor]
        private JobTaskNewCluster(
            ImmutableArray<string> __applyPolicyDefaultValuesAllowLists,

            bool? applyPolicyDefaultValues,

            Outputs.JobTaskNewClusterAutoscale? autoscale,

            Outputs.JobTaskNewClusterAwsAttributes? awsAttributes,

            Outputs.JobTaskNewClusterAzureAttributes? azureAttributes,

            string? clusterId,

            Outputs.JobTaskNewClusterClusterLogConf? clusterLogConf,

            ImmutableArray<Outputs.JobTaskNewClusterClusterMountInfo> clusterMountInfos,

            string? clusterName,

            ImmutableDictionary<string, string>? customTags,

            string? dataSecurityMode,

            Outputs.JobTaskNewClusterDockerImage? dockerImage,

            string? driverInstancePoolId,

            string? driverNodeTypeId,

            bool? enableElasticDisk,

            bool? enableLocalDiskEncryption,

            Outputs.JobTaskNewClusterGcpAttributes? gcpAttributes,

            string? idempotencyToken,

            ImmutableArray<Outputs.JobTaskNewClusterInitScript> initScripts,

            string? instancePoolId,

            bool? isSingleNode,

            string? kind,

            ImmutableArray<Outputs.JobTaskNewClusterLibrary> libraries,

            string? nodeTypeId,

            int? numWorkers,

            string? policyId,

            Outputs.JobTaskNewClusterProviderConfig? providerConfig,

            int? remoteDiskThroughput,

            string? runtimeEngine,

            string? singleUserName,

            ImmutableDictionary<string, string>? sparkConf,

            ImmutableDictionary<string, string>? sparkEnvVars,

            string? sparkVersion,

            ImmutableArray<string> sshPublicKeys,

            int? totalInitialRemoteDiskSize,

            bool? useMlRuntime,

            Outputs.JobTaskNewClusterWorkloadType? workloadType)
        {
            this.__applyPolicyDefaultValuesAllowLists = __applyPolicyDefaultValuesAllowLists;
            ApplyPolicyDefaultValues = applyPolicyDefaultValues;
            Autoscale = autoscale;
            AwsAttributes = awsAttributes;
            AzureAttributes = azureAttributes;
            ClusterId = clusterId;
            ClusterLogConf = clusterLogConf;
            ClusterMountInfos = clusterMountInfos;
            ClusterName = clusterName;
            CustomTags = customTags;
            DataSecurityMode = dataSecurityMode;
            DockerImage = dockerImage;
            DriverInstancePoolId = driverInstancePoolId;
            DriverNodeTypeId = driverNodeTypeId;
            EnableElasticDisk = enableElasticDisk;
            EnableLocalDiskEncryption = enableLocalDiskEncryption;
            GcpAttributes = gcpAttributes;
            IdempotencyToken = idempotencyToken;
            InitScripts = initScripts;
            InstancePoolId = instancePoolId;
            IsSingleNode = isSingleNode;
            Kind = kind;
            Libraries = libraries;
            NodeTypeId = nodeTypeId;
            NumWorkers = numWorkers;
            PolicyId = policyId;
            ProviderConfig = providerConfig;
            RemoteDiskThroughput = remoteDiskThroughput;
            RuntimeEngine = runtimeEngine;
            SingleUserName = singleUserName;
            SparkConf = sparkConf;
            SparkEnvVars = sparkEnvVars;
            SparkVersion = sparkVersion;
            SshPublicKeys = sshPublicKeys;
            TotalInitialRemoteDiskSize = totalInitialRemoteDiskSize;
            UseMlRuntime = useMlRuntime;
            WorkloadType = workloadType;
        }
    }
}
