// *** WARNING: this file was generated by the Pulumi Terraform Bridge (tfgen) Tool. ***
// *** Do not edit by hand unless you're certain you know what you are doing! ***

using System;
using System.Collections.Generic;
using System.Collections.Immutable;
using System.Threading.Tasks;
using Pulumi.Serialization;

namespace Pulumi.Databricks.Outputs
{

    [OutputType]
    public sealed class ModelServingConfigServedEntity
    {
        /// <summary>
        /// The name of the entity to be served. The entity may be a model in the Databricks Model Registry, a model in the Unity Catalog (UC), or a function of type `FEATURE_SPEC` in the UC. If it is a UC object, the full name of the object should be given in the form of `catalog_name.schema_name.model_name`.
        /// </summary>
        public readonly string? EntityName;
        /// <summary>
        /// The version of the model in Databricks Model Registry to be served or empty if the entity is a `FEATURE_SPEC`.
        /// </summary>
        public readonly string? EntityVersion;
        /// <summary>
        /// An object containing a set of optional, user-specified environment variable key-value pairs used for serving this entity. Note: this is an experimental feature and subject to change. Example entity environment variables that refer to Databricks secrets: ```{"OPENAI_API_KEY": "{{secrets/my_scope/my_key}}", "DATABRICKS_TOKEN": "{{secrets/my_scope2/my_key2}}"}```
        /// </summary>
        public readonly ImmutableDictionary<string, object>? EnvironmentVars;
        /// <summary>
        /// The external model to be served. NOTE: Only one of `external_model` and (`entity_name`, `entity_version`, `workload_size`, `workload_type`, and `scale_to_zero_enabled`) can be specified with the latter set being used for custom model serving for a Databricks registered model. When an `external_model` is present, the served entities list can only have one `served_entity` object. For an existing endpoint with `external_model`, it can not be updated to an endpoint without `external_model`. If the endpoint is created without `external_model`, users cannot update it to add `external_model` later.
        /// </summary>
        public readonly Outputs.ModelServingConfigServedEntityExternalModel? ExternalModel;
        /// <summary>
        /// ARN of the instance profile that the served entity uses to access AWS resources.
        /// </summary>
        public readonly string? InstanceProfileArn;
        /// <summary>
        /// The maximum tokens per second that the endpoint can scale up to.
        /// </summary>
        public readonly int? MaxProvisionedThroughput;
        /// <summary>
        /// The minimum tokens per second that the endpoint can scale down to.
        /// </summary>
        public readonly int? MinProvisionedThroughput;
        /// <summary>
        /// The name of the external model.
        /// </summary>
        public readonly string? Name;
        /// <summary>
        /// Whether the compute resources for the served entity should scale down to zero.
        /// </summary>
        public readonly bool? ScaleToZeroEnabled;
        /// <summary>
        /// The workload size of the served entity. The workload size corresponds to a range of provisioned concurrency that the compute autoscales between. A single unit of provisioned concurrency can process one request at a time. Valid workload sizes are `Small` (4 - 4 provisioned concurrency), `Medium` (8 - 16 provisioned concurrency), and `Large` (16 - 64 provisioned concurrency). If `scale-to-zero` is enabled, the lower bound of the provisioned concurrency for each workload size is 0.
        /// </summary>
        public readonly string? WorkloadSize;
        /// <summary>
        /// The workload type of the served entity. The workload type selects which type of compute to use in the endpoint. The default value for this parameter is `CPU`. For deep learning workloads, GPU acceleration is available by selecting workload types like `GPU_SMALL` and others. See the available [GPU types](https://docs.databricks.com/machine-learning/model-serving/create-manage-serving-endpoints.html#gpu-workload-types).
        /// </summary>
        public readonly string? WorkloadType;

        [OutputConstructor]
        private ModelServingConfigServedEntity(
            string? entityName,

            string? entityVersion,

            ImmutableDictionary<string, object>? environmentVars,

            Outputs.ModelServingConfigServedEntityExternalModel? externalModel,

            string? instanceProfileArn,

            int? maxProvisionedThroughput,

            int? minProvisionedThroughput,

            string? name,

            bool? scaleToZeroEnabled,

            string? workloadSize,

            string? workloadType)
        {
            EntityName = entityName;
            EntityVersion = entityVersion;
            EnvironmentVars = environmentVars;
            ExternalModel = externalModel;
            InstanceProfileArn = instanceProfileArn;
            MaxProvisionedThroughput = maxProvisionedThroughput;
            MinProvisionedThroughput = minProvisionedThroughput;
            Name = name;
            ScaleToZeroEnabled = scaleToZeroEnabled;
            WorkloadSize = workloadSize;
            WorkloadType = workloadType;
        }
    }
}
