// *** WARNING: this file was generated by pulumi-language-dotnet. ***
// *** Do not edit by hand unless you're certain you know what you are doing! ***

using System;
using System.Collections.Generic;
using System.Collections.Immutable;
using System.Threading.Tasks;
using Pulumi.Serialization;

namespace Pulumi.Databricks.Outputs
{

    [OutputType]
    public sealed class GetFeatureEngineeringKafkaConfigsKafkaConfigResult
    {
        /// <summary>
        /// (AuthConfig) - Authentication configuration for connection to topics
        /// </summary>
        public readonly Outputs.GetFeatureEngineeringKafkaConfigsKafkaConfigAuthConfigResult AuthConfig;
        /// <summary>
        /// (BackfillSource) - A user-provided and managed source for backfilling data. Historical data is used when creating a training set from streaming features linked to this Kafka config.
        /// In the future, a separate table will be maintained by Databricks for forward filling data.
        /// The schema for this source must match exactly that of the key and value schemas specified for this Kafka config
        /// </summary>
        public readonly Outputs.GetFeatureEngineeringKafkaConfigsKafkaConfigBackfillSourceResult BackfillSource;
        /// <summary>
        /// (string) - A comma-separated list of host/port pairs pointing to Kafka cluster
        /// </summary>
        public readonly string BootstrapServers;
        /// <summary>
        /// (object) - Catch-all for miscellaneous options. Keys should be source options or Kafka consumer options (kafka.*)
        /// </summary>
        public readonly ImmutableDictionary<string, string> ExtraOptions;
        /// <summary>
        /// (SchemaConfig) - Schema configuration for extracting message keys from topics. At least one of KeySchema and ValueSchema must be provided
        /// </summary>
        public readonly Outputs.GetFeatureEngineeringKafkaConfigsKafkaConfigKeySchemaResult KeySchema;
        /// <summary>
        /// (string) - Name that uniquely identifies this Kafka config within the metastore. This will be the identifier used from the Feature object to reference these configs for a feature.
        /// Can be distinct from topic name
        /// </summary>
        public readonly string Name;
        /// <summary>
        /// (SubscriptionMode) - Options to configure which Kafka topics to pull data from
        /// </summary>
        public readonly Outputs.GetFeatureEngineeringKafkaConfigsKafkaConfigSubscriptionModeResult SubscriptionMode;
        /// <summary>
        /// (SchemaConfig) - Schema configuration for extracting message values from topics. At least one of KeySchema and ValueSchema must be provided
        /// </summary>
        public readonly Outputs.GetFeatureEngineeringKafkaConfigsKafkaConfigValueSchemaResult ValueSchema;

        [OutputConstructor]
        private GetFeatureEngineeringKafkaConfigsKafkaConfigResult(
            Outputs.GetFeatureEngineeringKafkaConfigsKafkaConfigAuthConfigResult authConfig,

            Outputs.GetFeatureEngineeringKafkaConfigsKafkaConfigBackfillSourceResult backfillSource,

            string bootstrapServers,

            ImmutableDictionary<string, string> extraOptions,

            Outputs.GetFeatureEngineeringKafkaConfigsKafkaConfigKeySchemaResult keySchema,

            string name,

            Outputs.GetFeatureEngineeringKafkaConfigsKafkaConfigSubscriptionModeResult subscriptionMode,

            Outputs.GetFeatureEngineeringKafkaConfigsKafkaConfigValueSchemaResult valueSchema)
        {
            AuthConfig = authConfig;
            BackfillSource = backfillSource;
            BootstrapServers = bootstrapServers;
            ExtraOptions = extraOptions;
            KeySchema = keySchema;
            Name = name;
            SubscriptionMode = subscriptionMode;
            ValueSchema = valueSchema;
        }
    }
}
