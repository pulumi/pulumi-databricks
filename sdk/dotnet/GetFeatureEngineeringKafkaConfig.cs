// *** WARNING: this file was generated by pulumi-language-dotnet. ***
// *** Do not edit by hand unless you're certain you know what you are doing! ***

using System;
using System.Collections.Generic;
using System.Collections.Immutable;
using System.Threading.Tasks;
using Pulumi.Serialization;

namespace Pulumi.Databricks
{
    public static class GetFeatureEngineeringKafkaConfig
    {
        /// <summary>
        /// [![Private Preview](https://img.shields.io/badge/Release_Stage-Private_Preview-blueviolet)](https://docs.databricks.com/aws/en/release-notes/release-types)
        /// </summary>
        public static Task<GetFeatureEngineeringKafkaConfigResult> InvokeAsync(GetFeatureEngineeringKafkaConfigArgs args, InvokeOptions? options = null)
            => global::Pulumi.Deployment.Instance.InvokeAsync<GetFeatureEngineeringKafkaConfigResult>("databricks:index/getFeatureEngineeringKafkaConfig:getFeatureEngineeringKafkaConfig", args ?? new GetFeatureEngineeringKafkaConfigArgs(), options.WithDefaults());

        /// <summary>
        /// [![Private Preview](https://img.shields.io/badge/Release_Stage-Private_Preview-blueviolet)](https://docs.databricks.com/aws/en/release-notes/release-types)
        /// </summary>
        public static Output<GetFeatureEngineeringKafkaConfigResult> Invoke(GetFeatureEngineeringKafkaConfigInvokeArgs args, InvokeOptions? options = null)
            => global::Pulumi.Deployment.Instance.Invoke<GetFeatureEngineeringKafkaConfigResult>("databricks:index/getFeatureEngineeringKafkaConfig:getFeatureEngineeringKafkaConfig", args ?? new GetFeatureEngineeringKafkaConfigInvokeArgs(), options.WithDefaults());

        /// <summary>
        /// [![Private Preview](https://img.shields.io/badge/Release_Stage-Private_Preview-blueviolet)](https://docs.databricks.com/aws/en/release-notes/release-types)
        /// </summary>
        public static Output<GetFeatureEngineeringKafkaConfigResult> Invoke(GetFeatureEngineeringKafkaConfigInvokeArgs args, InvokeOutputOptions options)
            => global::Pulumi.Deployment.Instance.Invoke<GetFeatureEngineeringKafkaConfigResult>("databricks:index/getFeatureEngineeringKafkaConfig:getFeatureEngineeringKafkaConfig", args ?? new GetFeatureEngineeringKafkaConfigInvokeArgs(), options.WithDefaults());
    }


    public sealed class GetFeatureEngineeringKafkaConfigArgs : global::Pulumi.InvokeArgs
    {
        /// <summary>
        /// Name that uniquely identifies this Kafka config within the metastore. This will be the identifier used from the Feature object to reference these configs for a feature.
        /// Can be distinct from topic name
        /// </summary>
        [Input("name", required: true)]
        public string Name { get; set; } = null!;

        /// <summary>
        /// Configure the provider for management through account provider.
        /// </summary>
        [Input("providerConfig")]
        public Inputs.GetFeatureEngineeringKafkaConfigProviderConfigArgs? ProviderConfig { get; set; }

        public GetFeatureEngineeringKafkaConfigArgs()
        {
        }
        public static new GetFeatureEngineeringKafkaConfigArgs Empty => new GetFeatureEngineeringKafkaConfigArgs();
    }

    public sealed class GetFeatureEngineeringKafkaConfigInvokeArgs : global::Pulumi.InvokeArgs
    {
        /// <summary>
        /// Name that uniquely identifies this Kafka config within the metastore. This will be the identifier used from the Feature object to reference these configs for a feature.
        /// Can be distinct from topic name
        /// </summary>
        [Input("name", required: true)]
        public Input<string> Name { get; set; } = null!;

        /// <summary>
        /// Configure the provider for management through account provider.
        /// </summary>
        [Input("providerConfig")]
        public Input<Inputs.GetFeatureEngineeringKafkaConfigProviderConfigInputArgs>? ProviderConfig { get; set; }

        public GetFeatureEngineeringKafkaConfigInvokeArgs()
        {
        }
        public static new GetFeatureEngineeringKafkaConfigInvokeArgs Empty => new GetFeatureEngineeringKafkaConfigInvokeArgs();
    }


    [OutputType]
    public sealed class GetFeatureEngineeringKafkaConfigResult
    {
        /// <summary>
        /// (AuthConfig) - Authentication configuration for connection to topics
        /// </summary>
        public readonly Outputs.GetFeatureEngineeringKafkaConfigAuthConfigResult AuthConfig;
        /// <summary>
        /// (BackfillSource) - A user-provided and managed source for backfilling data. Historical data is used when creating a training set from streaming features linked to this Kafka config.
        /// In the future, a separate table will be maintained by Databricks for forward filling data.
        /// The schema for this source must match exactly that of the key and value schemas specified for this Kafka config
        /// </summary>
        public readonly Outputs.GetFeatureEngineeringKafkaConfigBackfillSourceResult BackfillSource;
        /// <summary>
        /// (string) - A comma-separated list of host/port pairs pointing to Kafka cluster
        /// </summary>
        public readonly string BootstrapServers;
        /// <summary>
        /// (object) - Catch-all for miscellaneous options. Keys should be source options or Kafka consumer options (kafka.*)
        /// </summary>
        public readonly ImmutableDictionary<string, string> ExtraOptions;
        /// <summary>
        /// The provider-assigned unique ID for this managed resource.
        /// </summary>
        public readonly string Id;
        /// <summary>
        /// (SchemaConfig) - Schema configuration for extracting message keys from topics. At least one of KeySchema and ValueSchema must be provided
        /// </summary>
        public readonly Outputs.GetFeatureEngineeringKafkaConfigKeySchemaResult KeySchema;
        /// <summary>
        /// (string) - Name that uniquely identifies this Kafka config within the metastore. This will be the identifier used from the Feature object to reference these configs for a feature.
        /// Can be distinct from topic name
        /// </summary>
        public readonly string Name;
        public readonly Outputs.GetFeatureEngineeringKafkaConfigProviderConfigResult? ProviderConfig;
        /// <summary>
        /// (SubscriptionMode) - Options to configure which Kafka topics to pull data from
        /// </summary>
        public readonly Outputs.GetFeatureEngineeringKafkaConfigSubscriptionModeResult SubscriptionMode;
        /// <summary>
        /// (SchemaConfig) - Schema configuration for extracting message values from topics. At least one of KeySchema and ValueSchema must be provided
        /// </summary>
        public readonly Outputs.GetFeatureEngineeringKafkaConfigValueSchemaResult ValueSchema;

        [OutputConstructor]
        private GetFeatureEngineeringKafkaConfigResult(
            Outputs.GetFeatureEngineeringKafkaConfigAuthConfigResult authConfig,

            Outputs.GetFeatureEngineeringKafkaConfigBackfillSourceResult backfillSource,

            string bootstrapServers,

            ImmutableDictionary<string, string> extraOptions,

            string id,

            Outputs.GetFeatureEngineeringKafkaConfigKeySchemaResult keySchema,

            string name,

            Outputs.GetFeatureEngineeringKafkaConfigProviderConfigResult? providerConfig,

            Outputs.GetFeatureEngineeringKafkaConfigSubscriptionModeResult subscriptionMode,

            Outputs.GetFeatureEngineeringKafkaConfigValueSchemaResult valueSchema)
        {
            AuthConfig = authConfig;
            BackfillSource = backfillSource;
            BootstrapServers = bootstrapServers;
            ExtraOptions = extraOptions;
            Id = id;
            KeySchema = keySchema;
            Name = name;
            ProviderConfig = providerConfig;
            SubscriptionMode = subscriptionMode;
            ValueSchema = valueSchema;
        }
    }
}
