// *** WARNING: this file was generated by pulumi-language-dotnet. ***
// *** Do not edit by hand unless you're certain you know what you are doing! ***

using System;
using System.Collections.Generic;
using System.Collections.Immutable;
using System.Threading.Tasks;
using Pulumi.Serialization;

namespace Pulumi.Databricks
{
    /// <summary>
    /// This resource allows you to manage [Model Serving](https://docs.databricks.com/machine-learning/model-serving/index.html) endpoints in Databricks, including custom models, external models, and foundation models. For newer foundation models, including Llama 4, please use the databricks.ModelServingProvisionedThroughput resource.
    /// 
    /// &gt; This resource can only be used with a workspace-level provider!
    /// 
    /// &gt; If you replace `ServedModels` with `ServedEntities` in an existing serving endpoint, the serving endpoint will briefly go into an update state (~30 seconds) and increment the config version.
    /// 
    /// ## Example Usage
    /// 
    /// Creating a CPU serving endpoint
    /// 
    /// ```csharp
    /// using System.Collections.Generic;
    /// using System.Linq;
    /// using Pulumi;
    /// using Databricks = Pulumi.Databricks;
    /// 
    /// return await Deployment.RunAsync(() =&gt; 
    /// {
    ///     var @this = new Databricks.ModelServing("this", new()
    ///     {
    ///         Name = "ads-serving-endpoint",
    ///         Config = new Databricks.Inputs.ModelServingConfigArgs
    ///         {
    ///             ServedEntities = new[]
    ///             {
    ///                 new Databricks.Inputs.ModelServingConfigServedEntityArgs
    ///                 {
    ///                     Name = "prod_model",
    ///                     EntityName = "ads-model",
    ///                     EntityVersion = "2",
    ///                     WorkloadSize = "Small",
    ///                     ScaleToZeroEnabled = true,
    ///                 },
    ///                 new Databricks.Inputs.ModelServingConfigServedEntityArgs
    ///                 {
    ///                     Name = "candidate_model",
    ///                     EntityName = "ads-model",
    ///                     EntityVersion = "4",
    ///                     WorkloadSize = "Small",
    ///                     ScaleToZeroEnabled = false,
    ///                 },
    ///             },
    ///             TrafficConfig = new Databricks.Inputs.ModelServingConfigTrafficConfigArgs
    ///             {
    ///                 Routes = new[]
    ///                 {
    ///                     new Databricks.Inputs.ModelServingConfigTrafficConfigRouteArgs
    ///                     {
    ///                         ServedModelName = "prod_model",
    ///                         TrafficPercentage = 90,
    ///                     },
    ///                     new Databricks.Inputs.ModelServingConfigTrafficConfigRouteArgs
    ///                     {
    ///                         ServedModelName = "candidate_model",
    ///                         TrafficPercentage = 10,
    ///                     },
    ///                 },
    ///             },
    ///         },
    ///     });
    /// 
    /// });
    /// ```
    /// 
    /// Creating a Foundation Model endpoint
    /// 
    /// ```csharp
    /// using System.Collections.Generic;
    /// using System.Linq;
    /// using Pulumi;
    /// using Databricks = Pulumi.Databricks;
    /// 
    /// return await Deployment.RunAsync(() =&gt; 
    /// {
    ///     var llama = new Databricks.ModelServing("llama", new()
    ///     {
    ///         Name = "llama_3_2_3b_instruct",
    ///         AiGateway = new Databricks.Inputs.ModelServingAiGatewayArgs
    ///         {
    ///             UsageTrackingConfig = new Databricks.Inputs.ModelServingAiGatewayUsageTrackingConfigArgs
    ///             {
    ///                 Enabled = true,
    ///             },
    ///         },
    ///         Config = new Databricks.Inputs.ModelServingConfigArgs
    ///         {
    ///             ServedEntities = new[]
    ///             {
    ///                 new Databricks.Inputs.ModelServingConfigServedEntityArgs
    ///                 {
    ///                     Name = "meta_llama_v3_2_3b_instruct-3",
    ///                     EntityName = "system.ai.llama_v3_2_3b_instruct",
    ///                     EntityVersion = "2",
    ///                     ScaleToZeroEnabled = true,
    ///                     MaxProvisionedThroughput = 44000,
    ///                 },
    ///             },
    ///         },
    ///     });
    /// 
    /// });
    /// ```
    /// 
    /// Creating an External Model endpoint
    /// 
    /// ```csharp
    /// using System.Collections.Generic;
    /// using System.Linq;
    /// using Pulumi;
    /// using Databricks = Pulumi.Databricks;
    /// 
    /// return await Deployment.RunAsync(() =&gt; 
    /// {
    ///     var gpt4o = new Databricks.ModelServing("gpt_4o", new()
    ///     {
    ///         Name = "gpt-4o-mini",
    ///         AiGateway = new Databricks.Inputs.ModelServingAiGatewayArgs
    ///         {
    ///             UsageTrackingConfig = new Databricks.Inputs.ModelServingAiGatewayUsageTrackingConfigArgs
    ///             {
    ///                 Enabled = true,
    ///             },
    ///             RateLimits = new[]
    ///             {
    ///                 new Databricks.Inputs.ModelServingAiGatewayRateLimitArgs
    ///                 {
    ///                     Calls = 10,
    ///                     Key = "endpoint",
    ///                     RenewalPeriod = "minute",
    ///                 },
    ///             },
    ///             InferenceTableConfig = new Databricks.Inputs.ModelServingAiGatewayInferenceTableConfigArgs
    ///             {
    ///                 Enabled = true,
    ///                 TableNamePrefix = "gpt-4o-mini",
    ///                 CatalogName = "ml",
    ///                 SchemaName = "ai_gateway",
    ///             },
    ///             Guardrails = new Databricks.Inputs.ModelServingAiGatewayGuardrailsArgs
    ///             {
    ///                 Input = new Databricks.Inputs.ModelServingAiGatewayGuardrailsInputArgs
    ///                 {
    ///                     InvalidKeywords = new[]
    ///                     {
    ///                         "SuperSecretProject",
    ///                     },
    ///                     Pii = new Databricks.Inputs.ModelServingAiGatewayGuardrailsInputPiiArgs
    ///                     {
    ///                         Behavior = "BLOCK",
    ///                     },
    ///                 },
    ///                 Output = new Databricks.Inputs.ModelServingAiGatewayGuardrailsOutputArgs
    ///                 {
    ///                     Pii = new Databricks.Inputs.ModelServingAiGatewayGuardrailsOutputPiiArgs
    ///                     {
    ///                         Behavior = "BLOCK",
    ///                     },
    ///                 },
    ///             },
    ///         },
    ///         Config = new Databricks.Inputs.ModelServingConfigArgs
    ///         {
    ///             ServedEntities = new[]
    ///             {
    ///                 new Databricks.Inputs.ModelServingConfigServedEntityArgs
    ///                 {
    ///                     Name = "gpt-4o-mini",
    ///                     ExternalModel = new Databricks.Inputs.ModelServingConfigServedEntityExternalModelArgs
    ///                     {
    ///                         Name = "gpt-4o-mini",
    ///                         Provider = "openai",
    ///                         Task = "llm/v1/chat",
    ///                         OpenaiConfig = new Databricks.Inputs.ModelServingConfigServedEntityExternalModelOpenaiConfigArgs
    ///                         {
    ///                             OpenaiApiKey = "{{secrets/llm_scope/openai_api_key}}",
    ///                         },
    ///                     },
    ///                 },
    ///             },
    ///         },
    ///     });
    /// 
    /// });
    /// ```
    /// 
    /// ## Access Control
    /// 
    /// * databricks.Permissions can control which groups or individual users can *Manage*, *Query* or *View* individual serving endpoints.
    /// 
    /// ## Related Resources
    /// 
    /// The following resources are often used in the same context:
    /// 
    /// * databricks.ModelServingProvisionedThroughput to create [Foundation Model provisioned throughput](https://docs.databricks.com/aws/en/machine-learning/foundation-model-apis/deploy-prov-throughput-foundation-model-apis) endpoints in Databricks.
    /// * databricks.RegisteredModel to create [Models in Unity Catalog](https://docs.databricks.com/en/mlflow/models-in-uc.html) in Databricks.
    /// * End to end workspace management guide.
    /// * databricks.Directory to manage directories in [Databricks Workspace](https://docs.databricks.com/workspace/workspace-objects.html).
    /// * databricks.MlflowModel to create models in the [workspace model registry](https://docs.databricks.com/en/mlflow/model-registry.html) in Databricks.
    /// * databricks.Notebook to manage [Databricks Notebooks](https://docs.databricks.com/notebooks/index.html).
    /// * databricks.Notebook data to export a notebook from Databricks Workspace.
    /// * databricks.Repo to manage [Databricks Repos](https://docs.databricks.com/repos.html).
    /// </summary>
    [DatabricksResourceType("databricks:index/modelServing:ModelServing")]
    public partial class ModelServing : global::Pulumi.CustomResource
    {
        /// <summary>
        /// A block with AI Gateway configuration for the serving endpoint. *Note: only external model endpoints are supported as of now.*
        /// </summary>
        [Output("aiGateway")]
        public Output<Outputs.ModelServingAiGateway?> AiGateway { get; private set; } = null!;

        /// <summary>
        /// The Budget Policy ID set for this serving endpoint.
        /// </summary>
        [Output("budgetPolicyId")]
        public Output<string?> BudgetPolicyId { get; private set; } = null!;

        /// <summary>
        /// The model serving endpoint configuration. This is optional and can be added and modified after creation. If `Config` was provided in a previous apply but is not provided in the current apply, no change to the model serving endpoint will occur. To recreate the model serving endpoint without the `Config` block, the model serving endpoint must be destroyed and recreated.
        /// </summary>
        [Output("config")]
        public Output<Outputs.ModelServingConfig> Config { get; private set; } = null!;

        /// <summary>
        /// The description of the model serving endpoint.
        /// </summary>
        [Output("description")]
        public Output<string?> Description { get; private set; } = null!;

        /// <summary>
        /// A block with Email notification setting.
        /// </summary>
        [Output("emailNotifications")]
        public Output<Outputs.ModelServingEmailNotifications?> EmailNotifications { get; private set; } = null!;

        /// <summary>
        /// Invocation url of the endpoint.
        /// </summary>
        [Output("endpointUrl")]
        public Output<string> EndpointUrl { get; private set; } = null!;

        /// <summary>
        /// The name of the model serving endpoint. This field is required and must be unique across a workspace. An endpoint name can consist of alphanumeric characters, dashes, and underscores. NOTE: Changing this name will delete the existing endpoint and create a new endpoint with the updated name.
        /// </summary>
        [Output("name")]
        public Output<string> Name { get; private set; } = null!;

        /// <summary>
        /// Configure the provider for management through account provider. This block consists of the following fields:
        /// </summary>
        [Output("providerConfig")]
        public Output<Outputs.ModelServingProviderConfig?> ProviderConfig { get; private set; } = null!;

        /// <summary>
        /// A list of rate limit blocks to be applied to the serving endpoint. *Note: only external and foundation model endpoints are supported as of now.*
        /// </summary>
        [Output("rateLimits")]
        public Output<ImmutableArray<Outputs.ModelServingRateLimit>> RateLimits { get; private set; } = null!;

        /// <summary>
        /// A boolean enabling route optimization for the endpoint. *Note: only available for custom models.*
        /// </summary>
        [Output("routeOptimized")]
        public Output<bool?> RouteOptimized { get; private set; } = null!;

        /// <summary>
        /// Unique identifier of the serving endpoint primarily used to set permissions and refer to this instance for other operations.
        /// </summary>
        [Output("servingEndpointId")]
        public Output<string> ServingEndpointId { get; private set; } = null!;

        /// <summary>
        /// Tags to be attached to the serving endpoint and automatically propagated to billing logs.
        /// </summary>
        [Output("tags")]
        public Output<ImmutableArray<Outputs.ModelServingTag>> Tags { get; private set; } = null!;


        /// <summary>
        /// Create a ModelServing resource with the given unique name, arguments, and options.
        /// </summary>
        ///
        /// <param name="name">The unique name of the resource</param>
        /// <param name="args">The arguments used to populate this resource's properties</param>
        /// <param name="options">A bag of options that control this resource's behavior</param>
        public ModelServing(string name, ModelServingArgs? args = null, CustomResourceOptions? options = null)
            : base("databricks:index/modelServing:ModelServing", name, args ?? new ModelServingArgs(), MakeResourceOptions(options, ""))
        {
        }

        private ModelServing(string name, Input<string> id, ModelServingState? state = null, CustomResourceOptions? options = null)
            : base("databricks:index/modelServing:ModelServing", name, state, MakeResourceOptions(options, id))
        {
        }

        private static CustomResourceOptions MakeResourceOptions(CustomResourceOptions? options, Input<string>? id)
        {
            var defaultOptions = new CustomResourceOptions
            {
                Version = Utilities.Version,
            };
            var merged = CustomResourceOptions.Merge(defaultOptions, options);
            // Override the ID if one was specified for consistency with other language SDKs.
            merged.Id = id ?? merged.Id;
            return merged;
        }
        /// <summary>
        /// Get an existing ModelServing resource's state with the given name, ID, and optional extra
        /// properties used to qualify the lookup.
        /// </summary>
        ///
        /// <param name="name">The unique name of the resulting resource.</param>
        /// <param name="id">The unique provider ID of the resource to lookup.</param>
        /// <param name="state">Any extra arguments used during the lookup.</param>
        /// <param name="options">A bag of options that control this resource's behavior</param>
        public static ModelServing Get(string name, Input<string> id, ModelServingState? state = null, CustomResourceOptions? options = null)
        {
            return new ModelServing(name, id, state, options);
        }
    }

    public sealed class ModelServingArgs : global::Pulumi.ResourceArgs
    {
        /// <summary>
        /// A block with AI Gateway configuration for the serving endpoint. *Note: only external model endpoints are supported as of now.*
        /// </summary>
        [Input("aiGateway")]
        public Input<Inputs.ModelServingAiGatewayArgs>? AiGateway { get; set; }

        /// <summary>
        /// The Budget Policy ID set for this serving endpoint.
        /// </summary>
        [Input("budgetPolicyId")]
        public Input<string>? BudgetPolicyId { get; set; }

        /// <summary>
        /// The model serving endpoint configuration. This is optional and can be added and modified after creation. If `Config` was provided in a previous apply but is not provided in the current apply, no change to the model serving endpoint will occur. To recreate the model serving endpoint without the `Config` block, the model serving endpoint must be destroyed and recreated.
        /// </summary>
        [Input("config")]
        public Input<Inputs.ModelServingConfigArgs>? Config { get; set; }

        /// <summary>
        /// The description of the model serving endpoint.
        /// </summary>
        [Input("description")]
        public Input<string>? Description { get; set; }

        /// <summary>
        /// A block with Email notification setting.
        /// </summary>
        [Input("emailNotifications")]
        public Input<Inputs.ModelServingEmailNotificationsArgs>? EmailNotifications { get; set; }

        /// <summary>
        /// The name of the model serving endpoint. This field is required and must be unique across a workspace. An endpoint name can consist of alphanumeric characters, dashes, and underscores. NOTE: Changing this name will delete the existing endpoint and create a new endpoint with the updated name.
        /// </summary>
        [Input("name")]
        public Input<string>? Name { get; set; }

        /// <summary>
        /// Configure the provider for management through account provider. This block consists of the following fields:
        /// </summary>
        [Input("providerConfig")]
        public Input<Inputs.ModelServingProviderConfigArgs>? ProviderConfig { get; set; }

        [Input("rateLimits")]
        private InputList<Inputs.ModelServingRateLimitArgs>? _rateLimits;

        /// <summary>
        /// A list of rate limit blocks to be applied to the serving endpoint. *Note: only external and foundation model endpoints are supported as of now.*
        /// </summary>
        [Obsolete(@"Please use AI Gateway to manage rate limits.")]
        public InputList<Inputs.ModelServingRateLimitArgs> RateLimits
        {
            get => _rateLimits ?? (_rateLimits = new InputList<Inputs.ModelServingRateLimitArgs>());
            set => _rateLimits = value;
        }

        /// <summary>
        /// A boolean enabling route optimization for the endpoint. *Note: only available for custom models.*
        /// </summary>
        [Input("routeOptimized")]
        public Input<bool>? RouteOptimized { get; set; }

        [Input("tags")]
        private InputList<Inputs.ModelServingTagArgs>? _tags;

        /// <summary>
        /// Tags to be attached to the serving endpoint and automatically propagated to billing logs.
        /// </summary>
        public InputList<Inputs.ModelServingTagArgs> Tags
        {
            get => _tags ?? (_tags = new InputList<Inputs.ModelServingTagArgs>());
            set => _tags = value;
        }

        public ModelServingArgs()
        {
        }
        public static new ModelServingArgs Empty => new ModelServingArgs();
    }

    public sealed class ModelServingState : global::Pulumi.ResourceArgs
    {
        /// <summary>
        /// A block with AI Gateway configuration for the serving endpoint. *Note: only external model endpoints are supported as of now.*
        /// </summary>
        [Input("aiGateway")]
        public Input<Inputs.ModelServingAiGatewayGetArgs>? AiGateway { get; set; }

        /// <summary>
        /// The Budget Policy ID set for this serving endpoint.
        /// </summary>
        [Input("budgetPolicyId")]
        public Input<string>? BudgetPolicyId { get; set; }

        /// <summary>
        /// The model serving endpoint configuration. This is optional and can be added and modified after creation. If `Config` was provided in a previous apply but is not provided in the current apply, no change to the model serving endpoint will occur. To recreate the model serving endpoint without the `Config` block, the model serving endpoint must be destroyed and recreated.
        /// </summary>
        [Input("config")]
        public Input<Inputs.ModelServingConfigGetArgs>? Config { get; set; }

        /// <summary>
        /// The description of the model serving endpoint.
        /// </summary>
        [Input("description")]
        public Input<string>? Description { get; set; }

        /// <summary>
        /// A block with Email notification setting.
        /// </summary>
        [Input("emailNotifications")]
        public Input<Inputs.ModelServingEmailNotificationsGetArgs>? EmailNotifications { get; set; }

        /// <summary>
        /// Invocation url of the endpoint.
        /// </summary>
        [Input("endpointUrl")]
        public Input<string>? EndpointUrl { get; set; }

        /// <summary>
        /// The name of the model serving endpoint. This field is required and must be unique across a workspace. An endpoint name can consist of alphanumeric characters, dashes, and underscores. NOTE: Changing this name will delete the existing endpoint and create a new endpoint with the updated name.
        /// </summary>
        [Input("name")]
        public Input<string>? Name { get; set; }

        /// <summary>
        /// Configure the provider for management through account provider. This block consists of the following fields:
        /// </summary>
        [Input("providerConfig")]
        public Input<Inputs.ModelServingProviderConfigGetArgs>? ProviderConfig { get; set; }

        [Input("rateLimits")]
        private InputList<Inputs.ModelServingRateLimitGetArgs>? _rateLimits;

        /// <summary>
        /// A list of rate limit blocks to be applied to the serving endpoint. *Note: only external and foundation model endpoints are supported as of now.*
        /// </summary>
        [Obsolete(@"Please use AI Gateway to manage rate limits.")]
        public InputList<Inputs.ModelServingRateLimitGetArgs> RateLimits
        {
            get => _rateLimits ?? (_rateLimits = new InputList<Inputs.ModelServingRateLimitGetArgs>());
            set => _rateLimits = value;
        }

        /// <summary>
        /// A boolean enabling route optimization for the endpoint. *Note: only available for custom models.*
        /// </summary>
        [Input("routeOptimized")]
        public Input<bool>? RouteOptimized { get; set; }

        /// <summary>
        /// Unique identifier of the serving endpoint primarily used to set permissions and refer to this instance for other operations.
        /// </summary>
        [Input("servingEndpointId")]
        public Input<string>? ServingEndpointId { get; set; }

        [Input("tags")]
        private InputList<Inputs.ModelServingTagGetArgs>? _tags;

        /// <summary>
        /// Tags to be attached to the serving endpoint and automatically propagated to billing logs.
        /// </summary>
        public InputList<Inputs.ModelServingTagGetArgs> Tags
        {
            get => _tags ?? (_tags = new InputList<Inputs.ModelServingTagGetArgs>());
            set => _tags = value;
        }

        public ModelServingState()
        {
        }
        public static new ModelServingState Empty => new ModelServingState();
    }
}
