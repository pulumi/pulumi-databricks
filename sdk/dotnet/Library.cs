// *** WARNING: this file was generated by pulumi-language-dotnet. ***
// *** Do not edit by hand unless you're certain you know what you are doing! ***

using System;
using System.Collections.Generic;
using System.Collections.Immutable;
using System.Threading.Tasks;
using Pulumi.Serialization;

namespace Pulumi.Databricks
{
    /// <summary>
    /// Installs a [library](https://docs.databricks.com/libraries/index.html) on databricks_cluster. Each different type of library has a slightly different syntax. It's possible to set only one type of library within one resource. Otherwise, the plan will fail with an error.
    /// 
    /// &gt; This resource can only be used with a workspace-level provider!
    /// 
    /// &gt; `databricks.Library` resource would always start the associated cluster if it's not running, so make sure to have auto-termination configured. It's not possible to atomically change the version of the same library without cluster restart. Libraries are fully removed from the cluster only after restart.
    /// 
    /// ## Plugin Framework Migration
    /// 
    /// The library resource has been migrated from sdkv2 to plugin frameworkã€‚ If you encounter any problem with this resource and suspect it is due to the migration, you can fallback to sdkv2 by setting the environment variable in the following way `export USE_SDK_V2_RESOURCES="databricks.Library"`.
    /// 
    /// ## Installing library on all clusters
    /// 
    /// You can install libraries on all clusters with the help of databricks.getClusters data resource:
    /// 
    /// ```csharp
    /// using System.Collections.Generic;
    /// using System.Linq;
    /// using System.Threading.Tasks;
    /// using Pulumi;
    /// using Databricks = Pulumi.Databricks;
    /// 
    /// return await Deployment.RunAsync(async() =&gt; 
    /// {
    ///     var all = await Databricks.GetClusters.InvokeAsync();
    /// 
    ///     var cli = new List&lt;Databricks.Library&gt;();
    ///     foreach (var range in )
    ///     {
    ///         cli.Add(new Databricks.Library($"cli-{range.Key}", new()
    ///         {
    ///             ClusterId = range.Key,
    ///             Pypi = new Databricks.Inputs.LibraryPypiArgs
    ///             {
    ///                 Package = "databricks-cli",
    ///             },
    ///         }));
    ///     }
    /// });
    /// ```
    /// 
    /// ## Java/Scala Maven
    /// 
    /// Installing artifacts from Maven repository. You can also optionally specify a `Repo` parameter for a custom Maven-style repository, that should be accessible without any authentication. Maven libraries are resolved in Databricks Control Plane, so repo should be accessible from it. It can even be properly configured [maven s3 wagon](https://github.com/seahen/maven-s3-wagon), [AWS CodeArtifact](https://aws.amazon.com/codeartifact/) or [Azure Artifacts](https://azure.microsoft.com/en-us/services/devops/artifacts/).
    /// 
    /// ```csharp
    /// using System.Collections.Generic;
    /// using System.Linq;
    /// using Pulumi;
    /// using Databricks = Pulumi.Databricks;
    /// 
    /// return await Deployment.RunAsync(() =&gt; 
    /// {
    ///     var deequ = new Databricks.Library("deequ", new()
    ///     {
    ///         ClusterId = @this.Id,
    ///         Maven = new Databricks.Inputs.LibraryMavenArgs
    ///         {
    ///             Coordinates = "com.amazon.deequ:deequ:1.0.4",
    ///             Exclusions = new[]
    ///             {
    ///                 "org.apache.avro:avro",
    ///             },
    ///         },
    ///     });
    /// 
    /// });
    /// ```
    /// 
    /// ## Python PyPI
    /// 
    /// Installing Python PyPI artifacts. You can optionally also specify the `Repo` parameter for a custom PyPI mirror, which should be accessible without any authentication for the network that cluster runs in.
    /// 
    /// &gt; `Repo` host should be accessible from the Internet by Databricks control plane. If connectivity to custom PyPI repositories is required, please modify cluster-node `/etc/pip.conf` through databricks_global_init_script.
    /// 
    /// ```csharp
    /// using System.Collections.Generic;
    /// using System.Linq;
    /// using Pulumi;
    /// using Databricks = Pulumi.Databricks;
    /// 
    /// return await Deployment.RunAsync(() =&gt; 
    /// {
    ///     var fbprophet = new Databricks.Library("fbprophet", new()
    ///     {
    ///         ClusterId = @this.Id,
    ///         Pypi = new Databricks.Inputs.LibraryPypiArgs
    ///         {
    ///             Package = "fbprophet==0.6",
    ///         },
    ///     });
    /// 
    /// });
    /// ```
    /// 
    /// ## Python requirements files
    /// 
    /// Installing Python libraries listed in the `requirements.txt` file.  Only Workspace paths and Unity Catalog Volumes paths are supported.  Requires a cluster with DBR 15.0+.
    /// 
    /// ```csharp
    /// using System.Collections.Generic;
    /// using System.Linq;
    /// using Pulumi;
    /// using Databricks = Pulumi.Databricks;
    /// 
    /// return await Deployment.RunAsync(() =&gt; 
    /// {
    ///     var libraries = new Databricks.Library("libraries", new()
    ///     {
    ///         ClusterId = @this.Id,
    ///         Requirements = "/Workspace/path/to/requirements.txt",
    ///     });
    /// 
    /// });
    /// ```
    /// 
    /// ## R CRan
    /// 
    /// Installing artifacts from CRan. You can also optionally specify a `Repo` parameter for a custom cran mirror.
    /// 
    /// ```csharp
    /// using System.Collections.Generic;
    /// using System.Linq;
    /// using Pulumi;
    /// using Databricks = Pulumi.Databricks;
    /// 
    /// return await Deployment.RunAsync(() =&gt; 
    /// {
    ///     var rkeops = new Databricks.Library("rkeops", new()
    ///     {
    ///         ClusterId = @this.Id,
    ///         Cran = new Databricks.Inputs.LibraryCranArgs
    ///         {
    ///             Package = "rkeops",
    ///         },
    ///     });
    /// 
    /// });
    /// ```
    /// 
    /// ## Related Resources
    /// 
    /// The following resources are often used in the same context:
    /// 
    /// * End to end workspace management guide.
    /// * databricks.getClusters data to retrieve a list of databricks.Cluster ids.
    /// * databricks.Cluster to create [Databricks Clusters](https://docs.databricks.com/clusters/index.html).
    /// * databricks.ClusterPolicy to create a databricks.Cluster policy, which limits the ability to create clusters based on a set of rules.
    /// * databricks.GlobalInitScript to manage [global init scripts](https://docs.databricks.com/clusters/init-scripts.html#global-init-scripts), which are run on all databricks.Cluster and databricks_job.
    /// * databricks.Job to manage [Databricks Jobs](https://docs.databricks.com/jobs.html) to run non-interactive code in a databricks_cluster.
    /// * databricks.Pipeline to deploy [Lakeflow Declarative Pipelines](https://docs.databricks.com/aws/en/dlt).
    /// * databricks.Repo to manage [Databricks Repos](https://docs.databricks.com/repos.html).
    /// 
    /// ## Import
    /// 
    /// !&gt; Importing this resource is not currently supported.
    /// </summary>
    [DatabricksResourceType("databricks:index/library:Library")]
    public partial class Library : global::Pulumi.CustomResource
    {
        /// <summary>
        /// ID of the databricks.Cluster to install the library on.
        /// 
        /// You must specify exactly **one** of the following library types:
        /// </summary>
        [Output("clusterId")]
        public Output<string> ClusterId { get; private set; } = null!;

        /// <summary>
        /// Configuration block for a CRAN library. The block consists of the following fields:
        /// </summary>
        [Output("cran")]
        public Output<Outputs.LibraryCran?> Cran { get; private set; } = null!;

        /// <summary>
        /// Path to the EGG library. Installing Python egg files is deprecated and is not supported in Databricks Runtime 14.0 and above. Use `Whl` or `Pypi` instead.
        /// </summary>
        [Output("egg")]
        public Output<string?> Egg { get; private set; } = null!;

        /// <summary>
        /// Path to the JAR library. Supported URIs include Workspace paths, Unity Catalog Volumes paths, and S3 URIs. For example: `/Workspace/path/to/library.jar`, `/Volumes/path/to/library.jar` or `s3://my-bucket/library.jar`. If S3 is used, make sure the cluster has read access to the library. You may need to launch the cluster with an IAM role to access the S3 URI.
        /// </summary>
        [Output("jar")]
        public Output<string?> Jar { get; private set; } = null!;

        [Output("libraryId")]
        public Output<string> LibraryId { get; private set; } = null!;

        /// <summary>
        /// Configuration block for a Maven library. The block consists of the following fields:
        /// </summary>
        [Output("maven")]
        public Output<Outputs.LibraryMaven?> Maven { get; private set; } = null!;

        /// <summary>
        /// Configuration block for management through the account provider. This block consists of the following fields:
        /// </summary>
        [Output("providerConfig")]
        public Output<Outputs.LibraryProviderConfig?> ProviderConfig { get; private set; } = null!;

        /// <summary>
        /// Configuration block for a PyPI library. The block consists of the following fields:
        /// </summary>
        [Output("pypi")]
        public Output<Outputs.LibraryPypi?> Pypi { get; private set; } = null!;

        /// <summary>
        /// Path to the requirements.txt file. Only Workspace paths and Unity Catalog Volumes paths are supported. For example: `/Workspace/path/to/requirements.txt` or `/Volumes/path/to/requirements.txt`. Requires a cluster with DBR 15.0+.
        /// </summary>
        [Output("requirements")]
        public Output<string?> Requirements { get; private set; } = null!;

        /// <summary>
        /// Path to the wheel library. Supported URIs include Workspace paths, Unity Catalog Volumes paths, and S3 URIs. For example: `/Workspace/path/to/library.whl`, `/Volumes/path/to/library.whl` or `s3://my-bucket/library.whl`. If S3 is used, make sure the cluster has read access to the library. You may need to launch the cluster with an IAM role to access the S3 URI.
        /// </summary>
        [Output("whl")]
        public Output<string?> Whl { get; private set; } = null!;


        /// <summary>
        /// Create a Library resource with the given unique name, arguments, and options.
        /// </summary>
        ///
        /// <param name="name">The unique name of the resource</param>
        /// <param name="args">The arguments used to populate this resource's properties</param>
        /// <param name="options">A bag of options that control this resource's behavior</param>
        public Library(string name, LibraryArgs args, CustomResourceOptions? options = null)
            : base("databricks:index/library:Library", name, args ?? new LibraryArgs(), MakeResourceOptions(options, ""))
        {
        }

        private Library(string name, Input<string> id, LibraryState? state = null, CustomResourceOptions? options = null)
            : base("databricks:index/library:Library", name, state, MakeResourceOptions(options, id))
        {
        }

        private static CustomResourceOptions MakeResourceOptions(CustomResourceOptions? options, Input<string>? id)
        {
            var defaultOptions = new CustomResourceOptions
            {
                Version = Utilities.Version,
            };
            var merged = CustomResourceOptions.Merge(defaultOptions, options);
            // Override the ID if one was specified for consistency with other language SDKs.
            merged.Id = id ?? merged.Id;
            return merged;
        }
        /// <summary>
        /// Get an existing Library resource's state with the given name, ID, and optional extra
        /// properties used to qualify the lookup.
        /// </summary>
        ///
        /// <param name="name">The unique name of the resulting resource.</param>
        /// <param name="id">The unique provider ID of the resource to lookup.</param>
        /// <param name="state">Any extra arguments used during the lookup.</param>
        /// <param name="options">A bag of options that control this resource's behavior</param>
        public static Library Get(string name, Input<string> id, LibraryState? state = null, CustomResourceOptions? options = null)
        {
            return new Library(name, id, state, options);
        }
    }

    public sealed class LibraryArgs : global::Pulumi.ResourceArgs
    {
        /// <summary>
        /// ID of the databricks.Cluster to install the library on.
        /// 
        /// You must specify exactly **one** of the following library types:
        /// </summary>
        [Input("clusterId", required: true)]
        public Input<string> ClusterId { get; set; } = null!;

        /// <summary>
        /// Configuration block for a CRAN library. The block consists of the following fields:
        /// </summary>
        [Input("cran")]
        public Input<Inputs.LibraryCranArgs>? Cran { get; set; }

        /// <summary>
        /// Path to the EGG library. Installing Python egg files is deprecated and is not supported in Databricks Runtime 14.0 and above. Use `Whl` or `Pypi` instead.
        /// </summary>
        [Input("egg")]
        public Input<string>? Egg { get; set; }

        /// <summary>
        /// Path to the JAR library. Supported URIs include Workspace paths, Unity Catalog Volumes paths, and S3 URIs. For example: `/Workspace/path/to/library.jar`, `/Volumes/path/to/library.jar` or `s3://my-bucket/library.jar`. If S3 is used, make sure the cluster has read access to the library. You may need to launch the cluster with an IAM role to access the S3 URI.
        /// </summary>
        [Input("jar")]
        public Input<string>? Jar { get; set; }

        [Input("libraryId")]
        public Input<string>? LibraryId { get; set; }

        /// <summary>
        /// Configuration block for a Maven library. The block consists of the following fields:
        /// </summary>
        [Input("maven")]
        public Input<Inputs.LibraryMavenArgs>? Maven { get; set; }

        /// <summary>
        /// Configuration block for management through the account provider. This block consists of the following fields:
        /// </summary>
        [Input("providerConfig")]
        public Input<Inputs.LibraryProviderConfigArgs>? ProviderConfig { get; set; }

        /// <summary>
        /// Configuration block for a PyPI library. The block consists of the following fields:
        /// </summary>
        [Input("pypi")]
        public Input<Inputs.LibraryPypiArgs>? Pypi { get; set; }

        /// <summary>
        /// Path to the requirements.txt file. Only Workspace paths and Unity Catalog Volumes paths are supported. For example: `/Workspace/path/to/requirements.txt` or `/Volumes/path/to/requirements.txt`. Requires a cluster with DBR 15.0+.
        /// </summary>
        [Input("requirements")]
        public Input<string>? Requirements { get; set; }

        /// <summary>
        /// Path to the wheel library. Supported URIs include Workspace paths, Unity Catalog Volumes paths, and S3 URIs. For example: `/Workspace/path/to/library.whl`, `/Volumes/path/to/library.whl` or `s3://my-bucket/library.whl`. If S3 is used, make sure the cluster has read access to the library. You may need to launch the cluster with an IAM role to access the S3 URI.
        /// </summary>
        [Input("whl")]
        public Input<string>? Whl { get; set; }

        public LibraryArgs()
        {
        }
        public static new LibraryArgs Empty => new LibraryArgs();
    }

    public sealed class LibraryState : global::Pulumi.ResourceArgs
    {
        /// <summary>
        /// ID of the databricks.Cluster to install the library on.
        /// 
        /// You must specify exactly **one** of the following library types:
        /// </summary>
        [Input("clusterId")]
        public Input<string>? ClusterId { get; set; }

        /// <summary>
        /// Configuration block for a CRAN library. The block consists of the following fields:
        /// </summary>
        [Input("cran")]
        public Input<Inputs.LibraryCranGetArgs>? Cran { get; set; }

        /// <summary>
        /// Path to the EGG library. Installing Python egg files is deprecated and is not supported in Databricks Runtime 14.0 and above. Use `Whl` or `Pypi` instead.
        /// </summary>
        [Input("egg")]
        public Input<string>? Egg { get; set; }

        /// <summary>
        /// Path to the JAR library. Supported URIs include Workspace paths, Unity Catalog Volumes paths, and S3 URIs. For example: `/Workspace/path/to/library.jar`, `/Volumes/path/to/library.jar` or `s3://my-bucket/library.jar`. If S3 is used, make sure the cluster has read access to the library. You may need to launch the cluster with an IAM role to access the S3 URI.
        /// </summary>
        [Input("jar")]
        public Input<string>? Jar { get; set; }

        [Input("libraryId")]
        public Input<string>? LibraryId { get; set; }

        /// <summary>
        /// Configuration block for a Maven library. The block consists of the following fields:
        /// </summary>
        [Input("maven")]
        public Input<Inputs.LibraryMavenGetArgs>? Maven { get; set; }

        /// <summary>
        /// Configuration block for management through the account provider. This block consists of the following fields:
        /// </summary>
        [Input("providerConfig")]
        public Input<Inputs.LibraryProviderConfigGetArgs>? ProviderConfig { get; set; }

        /// <summary>
        /// Configuration block for a PyPI library. The block consists of the following fields:
        /// </summary>
        [Input("pypi")]
        public Input<Inputs.LibraryPypiGetArgs>? Pypi { get; set; }

        /// <summary>
        /// Path to the requirements.txt file. Only Workspace paths and Unity Catalog Volumes paths are supported. For example: `/Workspace/path/to/requirements.txt` or `/Volumes/path/to/requirements.txt`. Requires a cluster with DBR 15.0+.
        /// </summary>
        [Input("requirements")]
        public Input<string>? Requirements { get; set; }

        /// <summary>
        /// Path to the wheel library. Supported URIs include Workspace paths, Unity Catalog Volumes paths, and S3 URIs. For example: `/Workspace/path/to/library.whl`, `/Volumes/path/to/library.whl` or `s3://my-bucket/library.whl`. If S3 is used, make sure the cluster has read access to the library. You may need to launch the cluster with an IAM role to access the S3 URI.
        /// </summary>
        [Input("whl")]
        public Input<string>? Whl { get; set; }

        public LibraryState()
        {
        }
        public static new LibraryState Empty => new LibraryState();
    }
}
