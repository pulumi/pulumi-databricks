// *** WARNING: this file was generated by pulumi-language-dotnet. ***
// *** Do not edit by hand unless you're certain you know what you are doing! ***

using System;
using System.Collections.Generic;
using System.Collections.Immutable;
using System.Threading.Tasks;
using Pulumi.Serialization;

namespace Pulumi.Databricks.Inputs
{

    public sealed class DatabaseSyncedDatabaseTableSpecGetArgs : global::Pulumi.ResourceArgs
    {
        /// <summary>
        /// If true, the synced table's logical database and schema resources in PG
        /// will be created if they do not already exist
        /// </summary>
        [Input("createDatabaseObjectsIfMissing")]
        public Input<bool>? CreateDatabaseObjectsIfMissing { get; set; }

        /// <summary>
        /// At most one of existing_pipeline_id and new_pipeline_spec should be defined.
        /// 
        /// If existing_pipeline_id is defined, the synced table will be bin packed into the existing pipeline
        /// referenced. This avoids creating a new pipeline and allows sharing existing compute.
        /// In this case, the scheduling_policy of this synced table must match the scheduling policy of the existing pipeline
        /// </summary>
        [Input("existingPipelineId")]
        public Input<string>? ExistingPipelineId { get; set; }

        /// <summary>
        /// At most one of existing_pipeline_id and new_pipeline_spec should be defined.
        /// 
        /// If new_pipeline_spec is defined, a new pipeline is created for this synced table. The location pointed to is used
        /// to store intermediate files (checkpoints, event logs etc). The caller must have write permissions to create Delta
        /// tables in the specified catalog and schema. Again, note this requires write permissions, whereas the source table
        /// only requires read permissions
        /// </summary>
        [Input("newPipelineSpec")]
        public Input<Inputs.DatabaseSyncedDatabaseTableSpecNewPipelineSpecGetArgs>? NewPipelineSpec { get; set; }

        [Input("primaryKeyColumns")]
        private InputList<string>? _primaryKeyColumns;

        /// <summary>
        /// Primary Key columns to be used for data insert/update in the destination
        /// </summary>
        public InputList<string> PrimaryKeyColumns
        {
            get => _primaryKeyColumns ?? (_primaryKeyColumns = new InputList<string>());
            set => _primaryKeyColumns = value;
        }

        /// <summary>
        /// Scheduling policy of the underlying pipeline. Possible values are: `CONTINUOUS`, `SNAPSHOT`, `TRIGGERED`
        /// </summary>
        [Input("schedulingPolicy")]
        public Input<string>? SchedulingPolicy { get; set; }

        /// <summary>
        /// Three-part (catalog, schema, table) name of the source Delta table
        /// </summary>
        [Input("sourceTableFullName")]
        public Input<string>? SourceTableFullName { get; set; }

        /// <summary>
        /// Time series key to deduplicate (tie-break) rows with the same primary key
        /// </summary>
        [Input("timeseriesKey")]
        public Input<string>? TimeseriesKey { get; set; }

        public DatabaseSyncedDatabaseTableSpecGetArgs()
        {
        }
        public static new DatabaseSyncedDatabaseTableSpecGetArgs Empty => new DatabaseSyncedDatabaseTableSpecGetArgs();
    }
}
