// *** WARNING: this file was generated by the Pulumi Terraform Bridge (tfgen) Tool. ***
// *** Do not edit by hand unless you're certain you know what you are doing! ***

using System;
using System.Collections.Generic;
using System.Collections.Immutable;
using System.Threading.Tasks;
using Pulumi.Serialization;

namespace Pulumi.Databricks.Inputs
{

    public sealed class GetClusterClusterInfoArgs : global::Pulumi.InvokeArgs
    {
        [Input("autoscale")]
        public Inputs.GetClusterClusterInfoAutoscaleArgs? Autoscale { get; set; }

        /// <summary>
        /// Automatically terminate the cluster after being inactive for this time in minutes. If specified, the threshold must be between 10 and 10000 minutes. You can also set this value to 0 to explicitly disable automatic termination.
        /// </summary>
        [Input("autoterminationMinutes")]
        public int? AutoterminationMinutes { get; set; }

        [Input("awsAttributes")]
        public Inputs.GetClusterClusterInfoAwsAttributesArgs? AwsAttributes { get; set; }

        [Input("azureAttributes")]
        public Inputs.GetClusterClusterInfoAzureAttributesArgs? AzureAttributes { get; set; }

        [Input("clusterCores")]
        public double? ClusterCores { get; set; }

        /// <summary>
        /// The id of the cluster
        /// </summary>
        [Input("clusterId")]
        public string? ClusterId { get; set; }

        [Input("clusterLogConf")]
        public Inputs.GetClusterClusterInfoClusterLogConfArgs? ClusterLogConf { get; set; }

        [Input("clusterLogStatus")]
        public Inputs.GetClusterClusterInfoClusterLogStatusArgs? ClusterLogStatus { get; set; }

        [Input("clusterMemoryMb")]
        public int? ClusterMemoryMb { get; set; }

        /// <summary>
        /// The exact name of the cluster to search
        /// </summary>
        [Input("clusterName")]
        public string? ClusterName { get; set; }

        [Input("clusterSource")]
        public string? ClusterSource { get; set; }

        [Input("creatorUserName")]
        public string? CreatorUserName { get; set; }

        [Input("customTags")]
        private Dictionary<string, string>? _customTags;

        /// <summary>
        /// Additional tags for cluster resources.
        /// </summary>
        public Dictionary<string, string> CustomTags
        {
            get => _customTags ?? (_customTags = new Dictionary<string, string>());
            set => _customTags = value;
        }

        /// <summary>
        /// Security features of the cluster. Unity Catalog requires `SINGLE_USER` or `USER_ISOLATION` mode. `LEGACY_PASSTHROUGH` for passthrough cluster and `LEGACY_TABLE_ACL` for Table ACL cluster. Default to `NONE`, i.e. no security feature enabled.
        /// </summary>
        [Input("dataSecurityMode")]
        public string? DataSecurityMode { get; set; }

        [Input("defaultTags")]
        private Dictionary<string, string>? _defaultTags;
        public Dictionary<string, string> DefaultTags
        {
            get => _defaultTags ?? (_defaultTags = new Dictionary<string, string>());
            set => _defaultTags = value;
        }

        [Input("dockerImage")]
        public Inputs.GetClusterClusterInfoDockerImageArgs? DockerImage { get; set; }

        [Input("driver")]
        public Inputs.GetClusterClusterInfoDriverArgs? Driver { get; set; }

        /// <summary>
        /// similar to `instance_pool_id`, but for driver node.
        /// </summary>
        [Input("driverInstancePoolId")]
        public string? DriverInstancePoolId { get; set; }

        /// <summary>
        /// The node type of the Spark driver.
        /// </summary>
        [Input("driverNodeTypeId")]
        public string? DriverNodeTypeId { get; set; }

        /// <summary>
        /// Use autoscaling local storage.
        /// </summary>
        [Input("enableElasticDisk")]
        public bool? EnableElasticDisk { get; set; }

        /// <summary>
        /// Enable local disk encryption.
        /// </summary>
        [Input("enableLocalDiskEncryption")]
        public bool? EnableLocalDiskEncryption { get; set; }

        [Input("executors")]
        private List<Inputs.GetClusterClusterInfoExecutorArgs>? _executors;
        public List<Inputs.GetClusterClusterInfoExecutorArgs> Executors
        {
            get => _executors ?? (_executors = new List<Inputs.GetClusterClusterInfoExecutorArgs>());
            set => _executors = value;
        }

        [Input("gcpAttributes")]
        public Inputs.GetClusterClusterInfoGcpAttributesArgs? GcpAttributes { get; set; }

        [Input("initScripts")]
        private List<Inputs.GetClusterClusterInfoInitScriptArgs>? _initScripts;
        public List<Inputs.GetClusterClusterInfoInitScriptArgs> InitScripts
        {
            get => _initScripts ?? (_initScripts = new List<Inputs.GetClusterClusterInfoInitScriptArgs>());
            set => _initScripts = value;
        }

        /// <summary>
        /// The pool of idle instances the cluster is attached to.
        /// </summary>
        [Input("instancePoolId")]
        public string? InstancePoolId { get; set; }

        [Input("jdbcPort")]
        public int? JdbcPort { get; set; }

        [Input("lastRestartedTime")]
        public int? LastRestartedTime { get; set; }

        [Input("lastStateLossTime")]
        public int? LastStateLossTime { get; set; }

        /// <summary>
        /// Any supported databricks.getNodeType id.
        /// </summary>
        [Input("nodeTypeId")]
        public string? NodeTypeId { get; set; }

        [Input("numWorkers")]
        public int? NumWorkers { get; set; }

        /// <summary>
        /// Identifier of Cluster Policy to validate cluster and preset certain defaults.
        /// </summary>
        [Input("policyId")]
        public string? PolicyId { get; set; }

        /// <summary>
        /// The type of runtime of the cluster
        /// </summary>
        [Input("runtimeEngine")]
        public string? RuntimeEngine { get; set; }

        /// <summary>
        /// The optional user name of the user to assign to an interactive cluster. This field is required when using standard AAD Passthrough for Azure Data Lake Storage (ADLS) with a single-user cluster (i.e., not high-concurrency clusters).
        /// </summary>
        [Input("singleUserName")]
        public string? SingleUserName { get; set; }

        [Input("sparkConf")]
        private Dictionary<string, string>? _sparkConf;

        /// <summary>
        /// Map with key-value pairs to fine-tune Spark clusters.
        /// </summary>
        public Dictionary<string, string> SparkConf
        {
            get => _sparkConf ?? (_sparkConf = new Dictionary<string, string>());
            set => _sparkConf = value;
        }

        [Input("sparkContextId")]
        public int? SparkContextId { get; set; }

        [Input("sparkEnvVars")]
        private Dictionary<string, string>? _sparkEnvVars;

        /// <summary>
        /// Map with environment variable key-value pairs to fine-tune Spark clusters. Key-value pairs of the form (X,Y) are exported (i.e., X='Y') while launching the driver and workers.
        /// </summary>
        public Dictionary<string, string> SparkEnvVars
        {
            get => _sparkEnvVars ?? (_sparkEnvVars = new Dictionary<string, string>());
            set => _sparkEnvVars = value;
        }

        /// <summary>
        /// [Runtime version](https://docs.databricks.com/runtime/index.html) of the cluster.
        /// </summary>
        [Input("sparkVersion")]
        public string? SparkVersion { get; set; }

        [Input("spec")]
        public Inputs.GetClusterClusterInfoSpecArgs? Spec { get; set; }

        [Input("sshPublicKeys")]
        private List<string>? _sshPublicKeys;

        /// <summary>
        /// SSH public key contents that will be added to each Spark node in this cluster.
        /// </summary>
        public List<string> SshPublicKeys
        {
            get => _sshPublicKeys ?? (_sshPublicKeys = new List<string>());
            set => _sshPublicKeys = value;
        }

        [Input("startTime")]
        public int? StartTime { get; set; }

        [Input("state")]
        public string? State { get; set; }

        [Input("stateMessage")]
        public string? StateMessage { get; set; }

        [Input("terminatedTime")]
        public int? TerminatedTime { get; set; }

        [Input("terminationReason")]
        public Inputs.GetClusterClusterInfoTerminationReasonArgs? TerminationReason { get; set; }

        [Input("workloadType")]
        public Inputs.GetClusterClusterInfoWorkloadTypeArgs? WorkloadType { get; set; }

        public GetClusterClusterInfoArgs()
        {
        }
        public static new GetClusterClusterInfoArgs Empty => new GetClusterClusterInfoArgs();
    }
}
