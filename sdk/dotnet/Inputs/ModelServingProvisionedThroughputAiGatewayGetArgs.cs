// *** WARNING: this file was generated by pulumi-language-dotnet. ***
// *** Do not edit by hand unless you're certain you know what you are doing! ***

using System;
using System.Collections.Generic;
using System.Collections.Immutable;
using System.Threading.Tasks;
using Pulumi.Serialization;

namespace Pulumi.Databricks.Inputs
{

    public sealed class ModelServingProvisionedThroughputAiGatewayGetArgs : global::Pulumi.ResourceArgs
    {
        [Input("fallbackConfig")]
        public Input<Inputs.ModelServingProvisionedThroughputAiGatewayFallbackConfigGetArgs>? FallbackConfig { get; set; }

        /// <summary>
        /// Block with configuration for AI Guardrails to prevent unwanted data and unsafe data in requests and responses. Consists of the following attributes:
        /// </summary>
        [Input("guardrails")]
        public Input<Inputs.ModelServingProvisionedThroughputAiGatewayGuardrailsGetArgs>? Guardrails { get; set; }

        /// <summary>
        /// Block describing the configuration of usage tracking. Consists of the following attributes:
        /// </summary>
        [Input("inferenceTableConfig")]
        public Input<Inputs.ModelServingProvisionedThroughputAiGatewayInferenceTableConfigGetArgs>? InferenceTableConfig { get; set; }

        [Input("rateLimits")]
        private InputList<Inputs.ModelServingProvisionedThroughputAiGatewayRateLimitGetArgs>? _rateLimits;

        /// <summary>
        /// Block describing rate limits for AI gateway. For details see the description of `rate_limits` block above.
        /// </summary>
        public InputList<Inputs.ModelServingProvisionedThroughputAiGatewayRateLimitGetArgs> RateLimits
        {
            get => _rateLimits ?? (_rateLimits = new InputList<Inputs.ModelServingProvisionedThroughputAiGatewayRateLimitGetArgs>());
            set => _rateLimits = value;
        }

        /// <summary>
        /// Block with configuration for payload logging using inference tables. For details see the description of `auto_capture_config` block above.
        /// </summary>
        [Input("usageTrackingConfig")]
        public Input<Inputs.ModelServingProvisionedThroughputAiGatewayUsageTrackingConfigGetArgs>? UsageTrackingConfig { get; set; }

        public ModelServingProvisionedThroughputAiGatewayGetArgs()
        {
        }
        public static new ModelServingProvisionedThroughputAiGatewayGetArgs Empty => new ModelServingProvisionedThroughputAiGatewayGetArgs();
    }
}
