// *** WARNING: this file was generated by pulumi-language-dotnet. ***
// *** Do not edit by hand unless you're certain you know what you are doing! ***

using System;
using System.Collections.Generic;
using System.Collections.Immutable;
using System.Threading.Tasks;
using Pulumi.Serialization;

namespace Pulumi.Databricks.Inputs
{

    public sealed class ModelServingProvisionedThroughputAiGatewayArgs : global::Pulumi.ResourceArgs
    {
        [Input("fallbackConfig")]
        public Input<Inputs.ModelServingProvisionedThroughputAiGatewayFallbackConfigArgs>? FallbackConfig { get; set; }

        /// <summary>
        /// Block with configuration for AI Guardrails to prevent unwanted data and unsafe data in requests and responses. Consists of the following attributes:
        /// </summary>
        [Input("guardrails")]
        public Input<Inputs.ModelServingProvisionedThroughputAiGatewayGuardrailsArgs>? Guardrails { get; set; }

        /// <summary>
        /// Block describing the configuration of usage tracking. Consists of the following attributes:
        /// </summary>
        [Input("inferenceTableConfig")]
        public Input<Inputs.ModelServingProvisionedThroughputAiGatewayInferenceTableConfigArgs>? InferenceTableConfig { get; set; }

        [Input("rateLimits")]
        private InputList<Inputs.ModelServingProvisionedThroughputAiGatewayRateLimitArgs>? _rateLimits;

        /// <summary>
        /// Block describing rate limits for AI gateway. For details see the description of `RateLimits` block above.
        /// </summary>
        public InputList<Inputs.ModelServingProvisionedThroughputAiGatewayRateLimitArgs> RateLimits
        {
            get => _rateLimits ?? (_rateLimits = new InputList<Inputs.ModelServingProvisionedThroughputAiGatewayRateLimitArgs>());
            set => _rateLimits = value;
        }

        /// <summary>
        /// Block with configuration for payload logging using inference tables. For details see the description of `AutoCaptureConfig` block above.
        /// </summary>
        [Input("usageTrackingConfig")]
        public Input<Inputs.ModelServingProvisionedThroughputAiGatewayUsageTrackingConfigArgs>? UsageTrackingConfig { get; set; }

        public ModelServingProvisionedThroughputAiGatewayArgs()
        {
        }
        public static new ModelServingProvisionedThroughputAiGatewayArgs Empty => new ModelServingProvisionedThroughputAiGatewayArgs();
    }
}
