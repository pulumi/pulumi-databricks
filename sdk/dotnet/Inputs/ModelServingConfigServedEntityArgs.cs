// *** WARNING: this file was generated by the Pulumi Terraform Bridge (tfgen) Tool. ***
// *** Do not edit by hand unless you're certain you know what you are doing! ***

using System;
using System.Collections.Generic;
using System.Collections.Immutable;
using System.Threading.Tasks;
using Pulumi.Serialization;

namespace Pulumi.Databricks.Inputs
{

    public sealed class ModelServingConfigServedEntityArgs : global::Pulumi.ResourceArgs
    {
        /// <summary>
        /// The name of the entity to be served. The entity may be a model in the Databricks Model Registry, a model in the Unity Catalog (UC), or a function of type `FEATURE_SPEC` in the UC. If it is a UC object, the full name of the object should be given in the form of `catalog_name.schema_name.model_name`.
        /// </summary>
        [Input("entityName")]
        public Input<string>? EntityName { get; set; }

        /// <summary>
        /// The version of the model in Databricks Model Registry to be served or empty if the entity is a `FEATURE_SPEC`.
        /// </summary>
        [Input("entityVersion")]
        public Input<string>? EntityVersion { get; set; }

        [Input("environmentVars")]
        private InputMap<object>? _environmentVars;

        /// <summary>
        /// An object containing a set of optional, user-specified environment variable key-value pairs used for serving this entity. Note: this is an experimental feature and subject to change. Example entity environment variables that refer to Databricks secrets: ```{"OPENAI_API_KEY": "{{secrets/my_scope/my_key}}", "DATABRICKS_TOKEN": "{{secrets/my_scope2/my_key2}}"}```
        /// </summary>
        public InputMap<object> EnvironmentVars
        {
            get => _environmentVars ?? (_environmentVars = new InputMap<object>());
            set => _environmentVars = value;
        }

        /// <summary>
        /// The external model to be served. NOTE: Only one of `external_model` and (`entity_name`, `entity_version`, `workload_size`, `workload_type`, and `scale_to_zero_enabled`) can be specified with the latter set being used for custom model serving for a Databricks registered model. When an `external_model` is present, the served entities list can only have one `served_entity` object. For an existing endpoint with `external_model`, it can not be updated to an endpoint without `external_model`. If the endpoint is created without `external_model`, users cannot update it to add `external_model` later.
        /// </summary>
        [Input("externalModel")]
        public Input<Inputs.ModelServingConfigServedEntityExternalModelArgs>? ExternalModel { get; set; }

        /// <summary>
        /// ARN of the instance profile that the served entity uses to access AWS resources.
        /// </summary>
        [Input("instanceProfileArn")]
        public Input<string>? InstanceProfileArn { get; set; }

        /// <summary>
        /// The maximum tokens per second that the endpoint can scale up to.
        /// </summary>
        [Input("maxProvisionedThroughput")]
        public Input<int>? MaxProvisionedThroughput { get; set; }

        /// <summary>
        /// The minimum tokens per second that the endpoint can scale down to.
        /// </summary>
        [Input("minProvisionedThroughput")]
        public Input<int>? MinProvisionedThroughput { get; set; }

        /// <summary>
        /// The name of the external model.
        /// </summary>
        [Input("name")]
        public Input<string>? Name { get; set; }

        /// <summary>
        /// Whether the compute resources for the served entity should scale down to zero.
        /// </summary>
        [Input("scaleToZeroEnabled")]
        public Input<bool>? ScaleToZeroEnabled { get; set; }

        /// <summary>
        /// The workload size of the served entity. The workload size corresponds to a range of provisioned concurrency that the compute autoscales between. A single unit of provisioned concurrency can process one request at a time. Valid workload sizes are `Small` (4 - 4 provisioned concurrency), `Medium` (8 - 16 provisioned concurrency), and `Large` (16 - 64 provisioned concurrency). If `scale-to-zero` is enabled, the lower bound of the provisioned concurrency for each workload size is 0.
        /// </summary>
        [Input("workloadSize")]
        public Input<string>? WorkloadSize { get; set; }

        /// <summary>
        /// The workload type of the served entity. The workload type selects which type of compute to use in the endpoint. The default value for this parameter is `CPU`. For deep learning workloads, GPU acceleration is available by selecting workload types like `GPU_SMALL` and others. See the available [GPU types](https://docs.databricks.com/machine-learning/model-serving/create-manage-serving-endpoints.html#gpu-workload-types).
        /// </summary>
        [Input("workloadType")]
        public Input<string>? WorkloadType { get; set; }

        public ModelServingConfigServedEntityArgs()
        {
        }
        public static new ModelServingConfigServedEntityArgs Empty => new ModelServingConfigServedEntityArgs();
    }
}
