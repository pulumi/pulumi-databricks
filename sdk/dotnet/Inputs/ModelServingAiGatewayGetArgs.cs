// *** WARNING: this file was generated by pulumi-language-dotnet. ***
// *** Do not edit by hand unless you're certain you know what you are doing! ***

using System;
using System.Collections.Generic;
using System.Collections.Immutable;
using System.Threading.Tasks;
using Pulumi.Serialization;

namespace Pulumi.Databricks.Inputs
{

    public sealed class ModelServingAiGatewayGetArgs : global::Pulumi.ResourceArgs
    {
        /// <summary>
        /// block with configuration for traffic fallback which auto fallbacks to other served entities if the request to a served entity fails with certain error codes, to increase availability.
        /// </summary>
        [Input("fallbackConfig")]
        public Input<Inputs.ModelServingAiGatewayFallbackConfigGetArgs>? FallbackConfig { get; set; }

        /// <summary>
        /// Block with configuration for AI Guardrails to prevent unwanted data and unsafe data in requests and responses. Consists of the following attributes:
        /// </summary>
        [Input("guardrails")]
        public Input<Inputs.ModelServingAiGatewayGuardrailsGetArgs>? Guardrails { get; set; }

        /// <summary>
        /// Block describing the configuration of usage tracking. Consists of the following attributes:
        /// </summary>
        [Input("inferenceTableConfig")]
        public Input<Inputs.ModelServingAiGatewayInferenceTableConfigGetArgs>? InferenceTableConfig { get; set; }

        [Input("rateLimits")]
        private InputList<Inputs.ModelServingAiGatewayRateLimitGetArgs>? _rateLimits;

        /// <summary>
        /// Block describing rate limits for AI gateway. For details see the description of `RateLimits` block above.
        /// </summary>
        public InputList<Inputs.ModelServingAiGatewayRateLimitGetArgs> RateLimits
        {
            get => _rateLimits ?? (_rateLimits = new InputList<Inputs.ModelServingAiGatewayRateLimitGetArgs>());
            set => _rateLimits = value;
        }

        /// <summary>
        /// Block with configuration for payload logging using inference tables. For details see the description of `AutoCaptureConfig` block above.
        /// </summary>
        [Input("usageTrackingConfig")]
        public Input<Inputs.ModelServingAiGatewayUsageTrackingConfigGetArgs>? UsageTrackingConfig { get; set; }

        public ModelServingAiGatewayGetArgs()
        {
        }
        public static new ModelServingAiGatewayGetArgs Empty => new ModelServingAiGatewayGetArgs();
    }
}
