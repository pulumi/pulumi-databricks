// *** WARNING: this file was generated by pulumi-language-java. ***
// *** Do not edit by hand unless you're certain you know what you are doing! ***

package com.pulumi.databricks.inputs;

import com.pulumi.core.annotations.Import;
import com.pulumi.databricks.inputs.GetClusterClusterInfoSpecAutoscale;
import com.pulumi.databricks.inputs.GetClusterClusterInfoSpecAwsAttributes;
import com.pulumi.databricks.inputs.GetClusterClusterInfoSpecAzureAttributes;
import com.pulumi.databricks.inputs.GetClusterClusterInfoSpecClusterLogConf;
import com.pulumi.databricks.inputs.GetClusterClusterInfoSpecClusterMountInfo;
import com.pulumi.databricks.inputs.GetClusterClusterInfoSpecDockerImage;
import com.pulumi.databricks.inputs.GetClusterClusterInfoSpecGcpAttributes;
import com.pulumi.databricks.inputs.GetClusterClusterInfoSpecInitScript;
import com.pulumi.databricks.inputs.GetClusterClusterInfoSpecLibrary;
import com.pulumi.databricks.inputs.GetClusterClusterInfoSpecWorkloadType;
import com.pulumi.exceptions.MissingRequiredPropertyException;
import java.lang.Boolean;
import java.lang.Integer;
import java.lang.String;
import java.util.List;
import java.util.Map;
import java.util.Objects;
import java.util.Optional;
import javax.annotation.Nullable;


public final class GetClusterClusterInfoSpec extends com.pulumi.resources.InvokeArgs {

    public static final GetClusterClusterInfoSpec Empty = new GetClusterClusterInfoSpec();

    @Import(name="applyPolicyDefaultValues")
    private @Nullable Boolean applyPolicyDefaultValues;

    public Optional<Boolean> applyPolicyDefaultValues() {
        return Optional.ofNullable(this.applyPolicyDefaultValues);
    }

    @Import(name="autoscale")
    private @Nullable GetClusterClusterInfoSpecAutoscale autoscale;

    public Optional<GetClusterClusterInfoSpecAutoscale> autoscale() {
        return Optional.ofNullable(this.autoscale);
    }

    @Import(name="awsAttributes")
    private @Nullable GetClusterClusterInfoSpecAwsAttributes awsAttributes;

    public Optional<GetClusterClusterInfoSpecAwsAttributes> awsAttributes() {
        return Optional.ofNullable(this.awsAttributes);
    }

    @Import(name="azureAttributes")
    private @Nullable GetClusterClusterInfoSpecAzureAttributes azureAttributes;

    public Optional<GetClusterClusterInfoSpecAzureAttributes> azureAttributes() {
        return Optional.ofNullable(this.azureAttributes);
    }

    /**
     * The id of the cluster.
     * 
     */
    @Import(name="clusterId", required=true)
    private String clusterId;

    /**
     * @return The id of the cluster.
     * 
     */
    public String clusterId() {
        return this.clusterId;
    }

    @Import(name="clusterLogConf")
    private @Nullable GetClusterClusterInfoSpecClusterLogConf clusterLogConf;

    public Optional<GetClusterClusterInfoSpecClusterLogConf> clusterLogConf() {
        return Optional.ofNullable(this.clusterLogConf);
    }

    @Import(name="clusterMountInfos")
    private @Nullable List<GetClusterClusterInfoSpecClusterMountInfo> clusterMountInfos;

    public Optional<List<GetClusterClusterInfoSpecClusterMountInfo>> clusterMountInfos() {
        return Optional.ofNullable(this.clusterMountInfos);
    }

    /**
     * The exact name of the cluster to search. Can only be specified if there is exactly one cluster with the provided name.
     * 
     */
    @Import(name="clusterName")
    private @Nullable String clusterName;

    /**
     * @return The exact name of the cluster to search. Can only be specified if there is exactly one cluster with the provided name.
     * 
     */
    public Optional<String> clusterName() {
        return Optional.ofNullable(this.clusterName);
    }

    /**
     * Additional tags for cluster resources.
     * 
     */
    @Import(name="customTags")
    private @Nullable Map<String,String> customTags;

    /**
     * @return Additional tags for cluster resources.
     * 
     */
    public Optional<Map<String,String>> customTags() {
        return Optional.ofNullable(this.customTags);
    }

    /**
     * Security features of the cluster. Unity Catalog requires `SINGLE_USER` or `USER_ISOLATION` mode. `LEGACY_PASSTHROUGH` for passthrough cluster and `LEGACY_TABLE_ACL` for Table ACL cluster. Default to `NONE`, i.e. no security feature enabled.
     * 
     */
    @Import(name="dataSecurityMode")
    private @Nullable String dataSecurityMode;

    /**
     * @return Security features of the cluster. Unity Catalog requires `SINGLE_USER` or `USER_ISOLATION` mode. `LEGACY_PASSTHROUGH` for passthrough cluster and `LEGACY_TABLE_ACL` for Table ACL cluster. Default to `NONE`, i.e. no security feature enabled.
     * 
     */
    public Optional<String> dataSecurityMode() {
        return Optional.ofNullable(this.dataSecurityMode);
    }

    @Import(name="dockerImage")
    private @Nullable GetClusterClusterInfoSpecDockerImage dockerImage;

    public Optional<GetClusterClusterInfoSpecDockerImage> dockerImage() {
        return Optional.ofNullable(this.dockerImage);
    }

    /**
     * similar to `instancePoolId`, but for driver node.
     * 
     */
    @Import(name="driverInstancePoolId", required=true)
    private String driverInstancePoolId;

    /**
     * @return similar to `instancePoolId`, but for driver node.
     * 
     */
    public String driverInstancePoolId() {
        return this.driverInstancePoolId;
    }

    /**
     * The node type of the Spark driver.
     * 
     */
    @Import(name="driverNodeTypeId", required=true)
    private String driverNodeTypeId;

    /**
     * @return The node type of the Spark driver.
     * 
     */
    public String driverNodeTypeId() {
        return this.driverNodeTypeId;
    }

    /**
     * Use autoscaling local storage.
     * 
     */
    @Import(name="enableElasticDisk", required=true)
    private Boolean enableElasticDisk;

    /**
     * @return Use autoscaling local storage.
     * 
     */
    public Boolean enableElasticDisk() {
        return this.enableElasticDisk;
    }

    /**
     * Enable local disk encryption.
     * 
     */
    @Import(name="enableLocalDiskEncryption", required=true)
    private Boolean enableLocalDiskEncryption;

    /**
     * @return Enable local disk encryption.
     * 
     */
    public Boolean enableLocalDiskEncryption() {
        return this.enableLocalDiskEncryption;
    }

    @Import(name="gcpAttributes")
    private @Nullable GetClusterClusterInfoSpecGcpAttributes gcpAttributes;

    public Optional<GetClusterClusterInfoSpecGcpAttributes> gcpAttributes() {
        return Optional.ofNullable(this.gcpAttributes);
    }

    /**
     * An optional token to guarantee the idempotency of cluster creation requests.
     * 
     */
    @Import(name="idempotencyToken")
    private @Nullable String idempotencyToken;

    /**
     * @return An optional token to guarantee the idempotency of cluster creation requests.
     * 
     */
    public Optional<String> idempotencyToken() {
        return Optional.ofNullable(this.idempotencyToken);
    }

    @Import(name="initScripts")
    private @Nullable List<GetClusterClusterInfoSpecInitScript> initScripts;

    public Optional<List<GetClusterClusterInfoSpecInitScript>> initScripts() {
        return Optional.ofNullable(this.initScripts);
    }

    /**
     * The pool of idle instances the cluster is attached to.
     * 
     */
    @Import(name="instancePoolId")
    private @Nullable String instancePoolId;

    /**
     * @return The pool of idle instances the cluster is attached to.
     * 
     */
    public Optional<String> instancePoolId() {
        return Optional.ofNullable(this.instancePoolId);
    }

    @Import(name="isSingleNode")
    private @Nullable Boolean isSingleNode;

    public Optional<Boolean> isSingleNode() {
        return Optional.ofNullable(this.isSingleNode);
    }

    @Import(name="kind")
    private @Nullable String kind;

    public Optional<String> kind() {
        return Optional.ofNullable(this.kind);
    }

    @Import(name="libraries")
    private @Nullable List<GetClusterClusterInfoSpecLibrary> libraries;

    public Optional<List<GetClusterClusterInfoSpecLibrary>> libraries() {
        return Optional.ofNullable(this.libraries);
    }

    /**
     * Any supported databricks.getNodeType id.
     * 
     */
    @Import(name="nodeTypeId", required=true)
    private String nodeTypeId;

    /**
     * @return Any supported databricks.getNodeType id.
     * 
     */
    public String nodeTypeId() {
        return this.nodeTypeId;
    }

    @Import(name="numWorkers")
    private @Nullable Integer numWorkers;

    public Optional<Integer> numWorkers() {
        return Optional.ofNullable(this.numWorkers);
    }

    /**
     * Identifier of Cluster Policy to validate cluster and preset certain defaults.
     * 
     */
    @Import(name="policyId")
    private @Nullable String policyId;

    /**
     * @return Identifier of Cluster Policy to validate cluster and preset certain defaults.
     * 
     */
    public Optional<String> policyId() {
        return Optional.ofNullable(this.policyId);
    }

    @Import(name="remoteDiskThroughput")
    private @Nullable Integer remoteDiskThroughput;

    public Optional<Integer> remoteDiskThroughput() {
        return Optional.ofNullable(this.remoteDiskThroughput);
    }

    /**
     * The type of runtime of the cluster
     * 
     */
    @Import(name="runtimeEngine")
    private @Nullable String runtimeEngine;

    /**
     * @return The type of runtime of the cluster
     * 
     */
    public Optional<String> runtimeEngine() {
        return Optional.ofNullable(this.runtimeEngine);
    }

    /**
     * The optional user name of the user to assign to an interactive cluster. This field is required when using standard AAD Passthrough for Azure Data Lake Storage (ADLS) with a single-user cluster (i.e., not high-concurrency clusters).
     * 
     */
    @Import(name="singleUserName")
    private @Nullable String singleUserName;

    /**
     * @return The optional user name of the user to assign to an interactive cluster. This field is required when using standard AAD Passthrough for Azure Data Lake Storage (ADLS) with a single-user cluster (i.e., not high-concurrency clusters).
     * 
     */
    public Optional<String> singleUserName() {
        return Optional.ofNullable(this.singleUserName);
    }

    /**
     * Map with key-value pairs to fine-tune Spark clusters.
     * 
     */
    @Import(name="sparkConf")
    private @Nullable Map<String,String> sparkConf;

    /**
     * @return Map with key-value pairs to fine-tune Spark clusters.
     * 
     */
    public Optional<Map<String,String>> sparkConf() {
        return Optional.ofNullable(this.sparkConf);
    }

    /**
     * Map with environment variable key-value pairs to fine-tune Spark clusters. Key-value pairs of the form (X,Y) are exported (i.e., X=&#39;Y&#39;) while launching the driver and workers.
     * 
     */
    @Import(name="sparkEnvVars")
    private @Nullable Map<String,String> sparkEnvVars;

    /**
     * @return Map with environment variable key-value pairs to fine-tune Spark clusters. Key-value pairs of the form (X,Y) are exported (i.e., X=&#39;Y&#39;) while launching the driver and workers.
     * 
     */
    public Optional<Map<String,String>> sparkEnvVars() {
        return Optional.ofNullable(this.sparkEnvVars);
    }

    /**
     * [Runtime version](https://docs.databricks.com/runtime/index.html) of the cluster.
     * 
     */
    @Import(name="sparkVersion")
    private @Nullable String sparkVersion;

    /**
     * @return [Runtime version](https://docs.databricks.com/runtime/index.html) of the cluster.
     * 
     */
    public Optional<String> sparkVersion() {
        return Optional.ofNullable(this.sparkVersion);
    }

    /**
     * SSH public key contents that will be added to each Spark node in this cluster.
     * 
     */
    @Import(name="sshPublicKeys")
    private @Nullable List<String> sshPublicKeys;

    /**
     * @return SSH public key contents that will be added to each Spark node in this cluster.
     * 
     */
    public Optional<List<String>> sshPublicKeys() {
        return Optional.ofNullable(this.sshPublicKeys);
    }

    @Import(name="totalInitialRemoteDiskSize")
    private @Nullable Integer totalInitialRemoteDiskSize;

    public Optional<Integer> totalInitialRemoteDiskSize() {
        return Optional.ofNullable(this.totalInitialRemoteDiskSize);
    }

    @Import(name="useMlRuntime")
    private @Nullable Boolean useMlRuntime;

    public Optional<Boolean> useMlRuntime() {
        return Optional.ofNullable(this.useMlRuntime);
    }

    @Import(name="workloadType")
    private @Nullable GetClusterClusterInfoSpecWorkloadType workloadType;

    public Optional<GetClusterClusterInfoSpecWorkloadType> workloadType() {
        return Optional.ofNullable(this.workloadType);
    }

    private GetClusterClusterInfoSpec() {}

    private GetClusterClusterInfoSpec(GetClusterClusterInfoSpec $) {
        this.applyPolicyDefaultValues = $.applyPolicyDefaultValues;
        this.autoscale = $.autoscale;
        this.awsAttributes = $.awsAttributes;
        this.azureAttributes = $.azureAttributes;
        this.clusterId = $.clusterId;
        this.clusterLogConf = $.clusterLogConf;
        this.clusterMountInfos = $.clusterMountInfos;
        this.clusterName = $.clusterName;
        this.customTags = $.customTags;
        this.dataSecurityMode = $.dataSecurityMode;
        this.dockerImage = $.dockerImage;
        this.driverInstancePoolId = $.driverInstancePoolId;
        this.driverNodeTypeId = $.driverNodeTypeId;
        this.enableElasticDisk = $.enableElasticDisk;
        this.enableLocalDiskEncryption = $.enableLocalDiskEncryption;
        this.gcpAttributes = $.gcpAttributes;
        this.idempotencyToken = $.idempotencyToken;
        this.initScripts = $.initScripts;
        this.instancePoolId = $.instancePoolId;
        this.isSingleNode = $.isSingleNode;
        this.kind = $.kind;
        this.libraries = $.libraries;
        this.nodeTypeId = $.nodeTypeId;
        this.numWorkers = $.numWorkers;
        this.policyId = $.policyId;
        this.remoteDiskThroughput = $.remoteDiskThroughput;
        this.runtimeEngine = $.runtimeEngine;
        this.singleUserName = $.singleUserName;
        this.sparkConf = $.sparkConf;
        this.sparkEnvVars = $.sparkEnvVars;
        this.sparkVersion = $.sparkVersion;
        this.sshPublicKeys = $.sshPublicKeys;
        this.totalInitialRemoteDiskSize = $.totalInitialRemoteDiskSize;
        this.useMlRuntime = $.useMlRuntime;
        this.workloadType = $.workloadType;
    }

    public static Builder builder() {
        return new Builder();
    }
    public static Builder builder(GetClusterClusterInfoSpec defaults) {
        return new Builder(defaults);
    }

    public static final class Builder {
        private GetClusterClusterInfoSpec $;

        public Builder() {
            $ = new GetClusterClusterInfoSpec();
        }

        public Builder(GetClusterClusterInfoSpec defaults) {
            $ = new GetClusterClusterInfoSpec(Objects.requireNonNull(defaults));
        }

        public Builder applyPolicyDefaultValues(@Nullable Boolean applyPolicyDefaultValues) {
            $.applyPolicyDefaultValues = applyPolicyDefaultValues;
            return this;
        }

        public Builder autoscale(@Nullable GetClusterClusterInfoSpecAutoscale autoscale) {
            $.autoscale = autoscale;
            return this;
        }

        public Builder awsAttributes(@Nullable GetClusterClusterInfoSpecAwsAttributes awsAttributes) {
            $.awsAttributes = awsAttributes;
            return this;
        }

        public Builder azureAttributes(@Nullable GetClusterClusterInfoSpecAzureAttributes azureAttributes) {
            $.azureAttributes = azureAttributes;
            return this;
        }

        /**
         * @param clusterId The id of the cluster.
         * 
         * @return builder
         * 
         */
        public Builder clusterId(String clusterId) {
            $.clusterId = clusterId;
            return this;
        }

        public Builder clusterLogConf(@Nullable GetClusterClusterInfoSpecClusterLogConf clusterLogConf) {
            $.clusterLogConf = clusterLogConf;
            return this;
        }

        public Builder clusterMountInfos(@Nullable List<GetClusterClusterInfoSpecClusterMountInfo> clusterMountInfos) {
            $.clusterMountInfos = clusterMountInfos;
            return this;
        }

        public Builder clusterMountInfos(GetClusterClusterInfoSpecClusterMountInfo... clusterMountInfos) {
            return clusterMountInfos(List.of(clusterMountInfos));
        }

        /**
         * @param clusterName The exact name of the cluster to search. Can only be specified if there is exactly one cluster with the provided name.
         * 
         * @return builder
         * 
         */
        public Builder clusterName(@Nullable String clusterName) {
            $.clusterName = clusterName;
            return this;
        }

        /**
         * @param customTags Additional tags for cluster resources.
         * 
         * @return builder
         * 
         */
        public Builder customTags(@Nullable Map<String,String> customTags) {
            $.customTags = customTags;
            return this;
        }

        /**
         * @param dataSecurityMode Security features of the cluster. Unity Catalog requires `SINGLE_USER` or `USER_ISOLATION` mode. `LEGACY_PASSTHROUGH` for passthrough cluster and `LEGACY_TABLE_ACL` for Table ACL cluster. Default to `NONE`, i.e. no security feature enabled.
         * 
         * @return builder
         * 
         */
        public Builder dataSecurityMode(@Nullable String dataSecurityMode) {
            $.dataSecurityMode = dataSecurityMode;
            return this;
        }

        public Builder dockerImage(@Nullable GetClusterClusterInfoSpecDockerImage dockerImage) {
            $.dockerImage = dockerImage;
            return this;
        }

        /**
         * @param driverInstancePoolId similar to `instancePoolId`, but for driver node.
         * 
         * @return builder
         * 
         */
        public Builder driverInstancePoolId(String driverInstancePoolId) {
            $.driverInstancePoolId = driverInstancePoolId;
            return this;
        }

        /**
         * @param driverNodeTypeId The node type of the Spark driver.
         * 
         * @return builder
         * 
         */
        public Builder driverNodeTypeId(String driverNodeTypeId) {
            $.driverNodeTypeId = driverNodeTypeId;
            return this;
        }

        /**
         * @param enableElasticDisk Use autoscaling local storage.
         * 
         * @return builder
         * 
         */
        public Builder enableElasticDisk(Boolean enableElasticDisk) {
            $.enableElasticDisk = enableElasticDisk;
            return this;
        }

        /**
         * @param enableLocalDiskEncryption Enable local disk encryption.
         * 
         * @return builder
         * 
         */
        public Builder enableLocalDiskEncryption(Boolean enableLocalDiskEncryption) {
            $.enableLocalDiskEncryption = enableLocalDiskEncryption;
            return this;
        }

        public Builder gcpAttributes(@Nullable GetClusterClusterInfoSpecGcpAttributes gcpAttributes) {
            $.gcpAttributes = gcpAttributes;
            return this;
        }

        /**
         * @param idempotencyToken An optional token to guarantee the idempotency of cluster creation requests.
         * 
         * @return builder
         * 
         */
        public Builder idempotencyToken(@Nullable String idempotencyToken) {
            $.idempotencyToken = idempotencyToken;
            return this;
        }

        public Builder initScripts(@Nullable List<GetClusterClusterInfoSpecInitScript> initScripts) {
            $.initScripts = initScripts;
            return this;
        }

        public Builder initScripts(GetClusterClusterInfoSpecInitScript... initScripts) {
            return initScripts(List.of(initScripts));
        }

        /**
         * @param instancePoolId The pool of idle instances the cluster is attached to.
         * 
         * @return builder
         * 
         */
        public Builder instancePoolId(@Nullable String instancePoolId) {
            $.instancePoolId = instancePoolId;
            return this;
        }

        public Builder isSingleNode(@Nullable Boolean isSingleNode) {
            $.isSingleNode = isSingleNode;
            return this;
        }

        public Builder kind(@Nullable String kind) {
            $.kind = kind;
            return this;
        }

        public Builder libraries(@Nullable List<GetClusterClusterInfoSpecLibrary> libraries) {
            $.libraries = libraries;
            return this;
        }

        public Builder libraries(GetClusterClusterInfoSpecLibrary... libraries) {
            return libraries(List.of(libraries));
        }

        /**
         * @param nodeTypeId Any supported databricks.getNodeType id.
         * 
         * @return builder
         * 
         */
        public Builder nodeTypeId(String nodeTypeId) {
            $.nodeTypeId = nodeTypeId;
            return this;
        }

        public Builder numWorkers(@Nullable Integer numWorkers) {
            $.numWorkers = numWorkers;
            return this;
        }

        /**
         * @param policyId Identifier of Cluster Policy to validate cluster and preset certain defaults.
         * 
         * @return builder
         * 
         */
        public Builder policyId(@Nullable String policyId) {
            $.policyId = policyId;
            return this;
        }

        public Builder remoteDiskThroughput(@Nullable Integer remoteDiskThroughput) {
            $.remoteDiskThroughput = remoteDiskThroughput;
            return this;
        }

        /**
         * @param runtimeEngine The type of runtime of the cluster
         * 
         * @return builder
         * 
         */
        public Builder runtimeEngine(@Nullable String runtimeEngine) {
            $.runtimeEngine = runtimeEngine;
            return this;
        }

        /**
         * @param singleUserName The optional user name of the user to assign to an interactive cluster. This field is required when using standard AAD Passthrough for Azure Data Lake Storage (ADLS) with a single-user cluster (i.e., not high-concurrency clusters).
         * 
         * @return builder
         * 
         */
        public Builder singleUserName(@Nullable String singleUserName) {
            $.singleUserName = singleUserName;
            return this;
        }

        /**
         * @param sparkConf Map with key-value pairs to fine-tune Spark clusters.
         * 
         * @return builder
         * 
         */
        public Builder sparkConf(@Nullable Map<String,String> sparkConf) {
            $.sparkConf = sparkConf;
            return this;
        }

        /**
         * @param sparkEnvVars Map with environment variable key-value pairs to fine-tune Spark clusters. Key-value pairs of the form (X,Y) are exported (i.e., X=&#39;Y&#39;) while launching the driver and workers.
         * 
         * @return builder
         * 
         */
        public Builder sparkEnvVars(@Nullable Map<String,String> sparkEnvVars) {
            $.sparkEnvVars = sparkEnvVars;
            return this;
        }

        /**
         * @param sparkVersion [Runtime version](https://docs.databricks.com/runtime/index.html) of the cluster.
         * 
         * @return builder
         * 
         */
        public Builder sparkVersion(@Nullable String sparkVersion) {
            $.sparkVersion = sparkVersion;
            return this;
        }

        /**
         * @param sshPublicKeys SSH public key contents that will be added to each Spark node in this cluster.
         * 
         * @return builder
         * 
         */
        public Builder sshPublicKeys(@Nullable List<String> sshPublicKeys) {
            $.sshPublicKeys = sshPublicKeys;
            return this;
        }

        /**
         * @param sshPublicKeys SSH public key contents that will be added to each Spark node in this cluster.
         * 
         * @return builder
         * 
         */
        public Builder sshPublicKeys(String... sshPublicKeys) {
            return sshPublicKeys(List.of(sshPublicKeys));
        }

        public Builder totalInitialRemoteDiskSize(@Nullable Integer totalInitialRemoteDiskSize) {
            $.totalInitialRemoteDiskSize = totalInitialRemoteDiskSize;
            return this;
        }

        public Builder useMlRuntime(@Nullable Boolean useMlRuntime) {
            $.useMlRuntime = useMlRuntime;
            return this;
        }

        public Builder workloadType(@Nullable GetClusterClusterInfoSpecWorkloadType workloadType) {
            $.workloadType = workloadType;
            return this;
        }

        public GetClusterClusterInfoSpec build() {
            if ($.clusterId == null) {
                throw new MissingRequiredPropertyException("GetClusterClusterInfoSpec", "clusterId");
            }
            if ($.driverInstancePoolId == null) {
                throw new MissingRequiredPropertyException("GetClusterClusterInfoSpec", "driverInstancePoolId");
            }
            if ($.driverNodeTypeId == null) {
                throw new MissingRequiredPropertyException("GetClusterClusterInfoSpec", "driverNodeTypeId");
            }
            if ($.enableElasticDisk == null) {
                throw new MissingRequiredPropertyException("GetClusterClusterInfoSpec", "enableElasticDisk");
            }
            if ($.enableLocalDiskEncryption == null) {
                throw new MissingRequiredPropertyException("GetClusterClusterInfoSpec", "enableLocalDiskEncryption");
            }
            if ($.nodeTypeId == null) {
                throw new MissingRequiredPropertyException("GetClusterClusterInfoSpec", "nodeTypeId");
            }
            return $;
        }
    }

}
