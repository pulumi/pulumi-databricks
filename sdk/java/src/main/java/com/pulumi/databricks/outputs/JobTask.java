// *** WARNING: this file was generated by pulumi-java-gen. ***
// *** Do not edit by hand unless you're certain you know what you are doing! ***

package com.pulumi.databricks.outputs;

import com.pulumi.core.annotations.CustomType;
import com.pulumi.databricks.outputs.JobTaskDbtTask;
import com.pulumi.databricks.outputs.JobTaskDependsOn;
import com.pulumi.databricks.outputs.JobTaskEmailNotifications;
import com.pulumi.databricks.outputs.JobTaskLibrary;
import com.pulumi.databricks.outputs.JobTaskNewCluster;
import com.pulumi.databricks.outputs.JobTaskNotebookTask;
import com.pulumi.databricks.outputs.JobTaskPipelineTask;
import com.pulumi.databricks.outputs.JobTaskPythonWheelTask;
import com.pulumi.databricks.outputs.JobTaskSparkJarTask;
import com.pulumi.databricks.outputs.JobTaskSparkPythonTask;
import com.pulumi.databricks.outputs.JobTaskSparkSubmitTask;
import com.pulumi.databricks.outputs.JobTaskSqlTask;
import java.lang.Boolean;
import java.lang.Integer;
import java.lang.String;
import java.util.List;
import java.util.Objects;
import java.util.Optional;
import javax.annotation.Nullable;

@CustomType
public final class JobTask {
    private @Nullable JobTaskDbtTask dbtTask;
    private @Nullable List<JobTaskDependsOn> dependsOns;
    private @Nullable String description;
    /**
     * @return (List) An optional set of email addresses notified when runs of this job begins, completes and fails. The default behavior is to not send any emails. This field is a block and is documented below.
     * 
     */
    private @Nullable JobTaskEmailNotifications emailNotifications;
    private @Nullable String existingClusterId;
    /**
     * @return Identifier that can be referenced in `task` block, so that cluster is shared between tasks
     * 
     */
    private @Nullable String jobClusterKey;
    /**
     * @return (Set) An optional list of libraries to be installed on the cluster that will execute the job. Please consult libraries section for databricks.Cluster resource.
     * 
     */
    private @Nullable List<JobTaskLibrary> libraries;
    /**
     * @return (Integer) An optional maximum number of times to retry an unsuccessful run. A run is considered to be unsuccessful if it completes with a FAILED or INTERNAL_ERROR lifecycle state. The value -1 means to retry indefinitely and the value 0 means to never retry. The default behavior is to never retry. A run can have the following lifecycle state: PENDING, RUNNING, TERMINATING, TERMINATED, SKIPPED or INTERNAL_ERROR
     * 
     */
    private @Nullable Integer maxRetries;
    /**
     * @return (Integer) An optional minimal interval in milliseconds between the start of the failed run and the subsequent retry run. The default behavior is that unsuccessful runs are immediately retried.
     * 
     */
    private @Nullable Integer minRetryIntervalMillis;
    /**
     * @return Same set of parameters as for databricks.Cluster resource.
     * 
     */
    private @Nullable JobTaskNewCluster newCluster;
    private @Nullable JobTaskNotebookTask notebookTask;
    private @Nullable JobTaskPipelineTask pipelineTask;
    private @Nullable JobTaskPythonWheelTask pythonWheelTask;
    /**
     * @return (Bool) An optional policy to specify whether to retry a job when it times out. The default behavior is to not retry on timeout.
     * 
     */
    private @Nullable Boolean retryOnTimeout;
    private @Nullable JobTaskSparkJarTask sparkJarTask;
    private @Nullable JobTaskSparkPythonTask sparkPythonTask;
    private @Nullable JobTaskSparkSubmitTask sparkSubmitTask;
    private @Nullable JobTaskSqlTask sqlTask;
    private @Nullable String taskKey;
    /**
     * @return (Integer) An optional timeout applied to each run of this job. The default behavior is to have no timeout.
     * 
     */
    private @Nullable Integer timeoutSeconds;

    private JobTask() {}
    public Optional<JobTaskDbtTask> dbtTask() {
        return Optional.ofNullable(this.dbtTask);
    }
    public List<JobTaskDependsOn> dependsOns() {
        return this.dependsOns == null ? List.of() : this.dependsOns;
    }
    public Optional<String> description() {
        return Optional.ofNullable(this.description);
    }
    /**
     * @return (List) An optional set of email addresses notified when runs of this job begins, completes and fails. The default behavior is to not send any emails. This field is a block and is documented below.
     * 
     */
    public Optional<JobTaskEmailNotifications> emailNotifications() {
        return Optional.ofNullable(this.emailNotifications);
    }
    public Optional<String> existingClusterId() {
        return Optional.ofNullable(this.existingClusterId);
    }
    /**
     * @return Identifier that can be referenced in `task` block, so that cluster is shared between tasks
     * 
     */
    public Optional<String> jobClusterKey() {
        return Optional.ofNullable(this.jobClusterKey);
    }
    /**
     * @return (Set) An optional list of libraries to be installed on the cluster that will execute the job. Please consult libraries section for databricks.Cluster resource.
     * 
     */
    public List<JobTaskLibrary> libraries() {
        return this.libraries == null ? List.of() : this.libraries;
    }
    /**
     * @return (Integer) An optional maximum number of times to retry an unsuccessful run. A run is considered to be unsuccessful if it completes with a FAILED or INTERNAL_ERROR lifecycle state. The value -1 means to retry indefinitely and the value 0 means to never retry. The default behavior is to never retry. A run can have the following lifecycle state: PENDING, RUNNING, TERMINATING, TERMINATED, SKIPPED or INTERNAL_ERROR
     * 
     */
    public Optional<Integer> maxRetries() {
        return Optional.ofNullable(this.maxRetries);
    }
    /**
     * @return (Integer) An optional minimal interval in milliseconds between the start of the failed run and the subsequent retry run. The default behavior is that unsuccessful runs are immediately retried.
     * 
     */
    public Optional<Integer> minRetryIntervalMillis() {
        return Optional.ofNullable(this.minRetryIntervalMillis);
    }
    /**
     * @return Same set of parameters as for databricks.Cluster resource.
     * 
     */
    public Optional<JobTaskNewCluster> newCluster() {
        return Optional.ofNullable(this.newCluster);
    }
    public Optional<JobTaskNotebookTask> notebookTask() {
        return Optional.ofNullable(this.notebookTask);
    }
    public Optional<JobTaskPipelineTask> pipelineTask() {
        return Optional.ofNullable(this.pipelineTask);
    }
    public Optional<JobTaskPythonWheelTask> pythonWheelTask() {
        return Optional.ofNullable(this.pythonWheelTask);
    }
    /**
     * @return (Bool) An optional policy to specify whether to retry a job when it times out. The default behavior is to not retry on timeout.
     * 
     */
    public Optional<Boolean> retryOnTimeout() {
        return Optional.ofNullable(this.retryOnTimeout);
    }
    public Optional<JobTaskSparkJarTask> sparkJarTask() {
        return Optional.ofNullable(this.sparkJarTask);
    }
    public Optional<JobTaskSparkPythonTask> sparkPythonTask() {
        return Optional.ofNullable(this.sparkPythonTask);
    }
    public Optional<JobTaskSparkSubmitTask> sparkSubmitTask() {
        return Optional.ofNullable(this.sparkSubmitTask);
    }
    public Optional<JobTaskSqlTask> sqlTask() {
        return Optional.ofNullable(this.sqlTask);
    }
    public Optional<String> taskKey() {
        return Optional.ofNullable(this.taskKey);
    }
    /**
     * @return (Integer) An optional timeout applied to each run of this job. The default behavior is to have no timeout.
     * 
     */
    public Optional<Integer> timeoutSeconds() {
        return Optional.ofNullable(this.timeoutSeconds);
    }

    public static Builder builder() {
        return new Builder();
    }

    public static Builder builder(JobTask defaults) {
        return new Builder(defaults);
    }
    @CustomType.Builder
    public static final class Builder {
        private @Nullable JobTaskDbtTask dbtTask;
        private @Nullable List<JobTaskDependsOn> dependsOns;
        private @Nullable String description;
        private @Nullable JobTaskEmailNotifications emailNotifications;
        private @Nullable String existingClusterId;
        private @Nullable String jobClusterKey;
        private @Nullable List<JobTaskLibrary> libraries;
        private @Nullable Integer maxRetries;
        private @Nullable Integer minRetryIntervalMillis;
        private @Nullable JobTaskNewCluster newCluster;
        private @Nullable JobTaskNotebookTask notebookTask;
        private @Nullable JobTaskPipelineTask pipelineTask;
        private @Nullable JobTaskPythonWheelTask pythonWheelTask;
        private @Nullable Boolean retryOnTimeout;
        private @Nullable JobTaskSparkJarTask sparkJarTask;
        private @Nullable JobTaskSparkPythonTask sparkPythonTask;
        private @Nullable JobTaskSparkSubmitTask sparkSubmitTask;
        private @Nullable JobTaskSqlTask sqlTask;
        private @Nullable String taskKey;
        private @Nullable Integer timeoutSeconds;
        public Builder() {}
        public Builder(JobTask defaults) {
    	      Objects.requireNonNull(defaults);
    	      this.dbtTask = defaults.dbtTask;
    	      this.dependsOns = defaults.dependsOns;
    	      this.description = defaults.description;
    	      this.emailNotifications = defaults.emailNotifications;
    	      this.existingClusterId = defaults.existingClusterId;
    	      this.jobClusterKey = defaults.jobClusterKey;
    	      this.libraries = defaults.libraries;
    	      this.maxRetries = defaults.maxRetries;
    	      this.minRetryIntervalMillis = defaults.minRetryIntervalMillis;
    	      this.newCluster = defaults.newCluster;
    	      this.notebookTask = defaults.notebookTask;
    	      this.pipelineTask = defaults.pipelineTask;
    	      this.pythonWheelTask = defaults.pythonWheelTask;
    	      this.retryOnTimeout = defaults.retryOnTimeout;
    	      this.sparkJarTask = defaults.sparkJarTask;
    	      this.sparkPythonTask = defaults.sparkPythonTask;
    	      this.sparkSubmitTask = defaults.sparkSubmitTask;
    	      this.sqlTask = defaults.sqlTask;
    	      this.taskKey = defaults.taskKey;
    	      this.timeoutSeconds = defaults.timeoutSeconds;
        }

        @CustomType.Setter
        public Builder dbtTask(@Nullable JobTaskDbtTask dbtTask) {
            this.dbtTask = dbtTask;
            return this;
        }
        @CustomType.Setter
        public Builder dependsOns(@Nullable List<JobTaskDependsOn> dependsOns) {
            this.dependsOns = dependsOns;
            return this;
        }
        public Builder dependsOns(JobTaskDependsOn... dependsOns) {
            return dependsOns(List.of(dependsOns));
        }
        @CustomType.Setter
        public Builder description(@Nullable String description) {
            this.description = description;
            return this;
        }
        @CustomType.Setter
        public Builder emailNotifications(@Nullable JobTaskEmailNotifications emailNotifications) {
            this.emailNotifications = emailNotifications;
            return this;
        }
        @CustomType.Setter
        public Builder existingClusterId(@Nullable String existingClusterId) {
            this.existingClusterId = existingClusterId;
            return this;
        }
        @CustomType.Setter
        public Builder jobClusterKey(@Nullable String jobClusterKey) {
            this.jobClusterKey = jobClusterKey;
            return this;
        }
        @CustomType.Setter
        public Builder libraries(@Nullable List<JobTaskLibrary> libraries) {
            this.libraries = libraries;
            return this;
        }
        public Builder libraries(JobTaskLibrary... libraries) {
            return libraries(List.of(libraries));
        }
        @CustomType.Setter
        public Builder maxRetries(@Nullable Integer maxRetries) {
            this.maxRetries = maxRetries;
            return this;
        }
        @CustomType.Setter
        public Builder minRetryIntervalMillis(@Nullable Integer minRetryIntervalMillis) {
            this.minRetryIntervalMillis = minRetryIntervalMillis;
            return this;
        }
        @CustomType.Setter
        public Builder newCluster(@Nullable JobTaskNewCluster newCluster) {
            this.newCluster = newCluster;
            return this;
        }
        @CustomType.Setter
        public Builder notebookTask(@Nullable JobTaskNotebookTask notebookTask) {
            this.notebookTask = notebookTask;
            return this;
        }
        @CustomType.Setter
        public Builder pipelineTask(@Nullable JobTaskPipelineTask pipelineTask) {
            this.pipelineTask = pipelineTask;
            return this;
        }
        @CustomType.Setter
        public Builder pythonWheelTask(@Nullable JobTaskPythonWheelTask pythonWheelTask) {
            this.pythonWheelTask = pythonWheelTask;
            return this;
        }
        @CustomType.Setter
        public Builder retryOnTimeout(@Nullable Boolean retryOnTimeout) {
            this.retryOnTimeout = retryOnTimeout;
            return this;
        }
        @CustomType.Setter
        public Builder sparkJarTask(@Nullable JobTaskSparkJarTask sparkJarTask) {
            this.sparkJarTask = sparkJarTask;
            return this;
        }
        @CustomType.Setter
        public Builder sparkPythonTask(@Nullable JobTaskSparkPythonTask sparkPythonTask) {
            this.sparkPythonTask = sparkPythonTask;
            return this;
        }
        @CustomType.Setter
        public Builder sparkSubmitTask(@Nullable JobTaskSparkSubmitTask sparkSubmitTask) {
            this.sparkSubmitTask = sparkSubmitTask;
            return this;
        }
        @CustomType.Setter
        public Builder sqlTask(@Nullable JobTaskSqlTask sqlTask) {
            this.sqlTask = sqlTask;
            return this;
        }
        @CustomType.Setter
        public Builder taskKey(@Nullable String taskKey) {
            this.taskKey = taskKey;
            return this;
        }
        @CustomType.Setter
        public Builder timeoutSeconds(@Nullable Integer timeoutSeconds) {
            this.timeoutSeconds = timeoutSeconds;
            return this;
        }
        public JobTask build() {
            final var o = new JobTask();
            o.dbtTask = dbtTask;
            o.dependsOns = dependsOns;
            o.description = description;
            o.emailNotifications = emailNotifications;
            o.existingClusterId = existingClusterId;
            o.jobClusterKey = jobClusterKey;
            o.libraries = libraries;
            o.maxRetries = maxRetries;
            o.minRetryIntervalMillis = minRetryIntervalMillis;
            o.newCluster = newCluster;
            o.notebookTask = notebookTask;
            o.pipelineTask = pipelineTask;
            o.pythonWheelTask = pythonWheelTask;
            o.retryOnTimeout = retryOnTimeout;
            o.sparkJarTask = sparkJarTask;
            o.sparkPythonTask = sparkPythonTask;
            o.sparkSubmitTask = sparkSubmitTask;
            o.sqlTask = sqlTask;
            o.taskKey = taskKey;
            o.timeoutSeconds = timeoutSeconds;
            return o;
        }
    }
}
