// *** WARNING: this file was generated by pulumi-java-gen. ***
// *** Do not edit by hand unless you're certain you know what you are doing! ***

package com.pulumi.databricks.outputs;

import com.pulumi.core.annotations.CustomType;
import com.pulumi.databricks.outputs.ModelServingProvisionedThroughputAiGatewayFallbackConfig;
import com.pulumi.databricks.outputs.ModelServingProvisionedThroughputAiGatewayGuardrails;
import com.pulumi.databricks.outputs.ModelServingProvisionedThroughputAiGatewayInferenceTableConfig;
import com.pulumi.databricks.outputs.ModelServingProvisionedThroughputAiGatewayRateLimit;
import com.pulumi.databricks.outputs.ModelServingProvisionedThroughputAiGatewayUsageTrackingConfig;
import java.util.List;
import java.util.Objects;
import java.util.Optional;
import javax.annotation.Nullable;

@CustomType
public final class ModelServingProvisionedThroughputAiGateway {
    private @Nullable ModelServingProvisionedThroughputAiGatewayFallbackConfig fallbackConfig;
    /**
     * @return Block with configuration for AI Guardrails to prevent unwanted data and unsafe data in requests and responses. Consists of the following attributes:
     * 
     */
    private @Nullable ModelServingProvisionedThroughputAiGatewayGuardrails guardrails;
    /**
     * @return Block describing the configuration of usage tracking. Consists of the following attributes:
     * 
     */
    private @Nullable ModelServingProvisionedThroughputAiGatewayInferenceTableConfig inferenceTableConfig;
    /**
     * @return Block describing rate limits for AI gateway. For details see the description of `rate_limits` block above.
     * 
     */
    private @Nullable List<ModelServingProvisionedThroughputAiGatewayRateLimit> rateLimits;
    /**
     * @return Block with configuration for payload logging using inference tables. For details see the description of `auto_capture_config` block above.
     * 
     */
    private @Nullable ModelServingProvisionedThroughputAiGatewayUsageTrackingConfig usageTrackingConfig;

    private ModelServingProvisionedThroughputAiGateway() {}
    public Optional<ModelServingProvisionedThroughputAiGatewayFallbackConfig> fallbackConfig() {
        return Optional.ofNullable(this.fallbackConfig);
    }
    /**
     * @return Block with configuration for AI Guardrails to prevent unwanted data and unsafe data in requests and responses. Consists of the following attributes:
     * 
     */
    public Optional<ModelServingProvisionedThroughputAiGatewayGuardrails> guardrails() {
        return Optional.ofNullable(this.guardrails);
    }
    /**
     * @return Block describing the configuration of usage tracking. Consists of the following attributes:
     * 
     */
    public Optional<ModelServingProvisionedThroughputAiGatewayInferenceTableConfig> inferenceTableConfig() {
        return Optional.ofNullable(this.inferenceTableConfig);
    }
    /**
     * @return Block describing rate limits for AI gateway. For details see the description of `rate_limits` block above.
     * 
     */
    public List<ModelServingProvisionedThroughputAiGatewayRateLimit> rateLimits() {
        return this.rateLimits == null ? List.of() : this.rateLimits;
    }
    /**
     * @return Block with configuration for payload logging using inference tables. For details see the description of `auto_capture_config` block above.
     * 
     */
    public Optional<ModelServingProvisionedThroughputAiGatewayUsageTrackingConfig> usageTrackingConfig() {
        return Optional.ofNullable(this.usageTrackingConfig);
    }

    public static Builder builder() {
        return new Builder();
    }

    public static Builder builder(ModelServingProvisionedThroughputAiGateway defaults) {
        return new Builder(defaults);
    }
    @CustomType.Builder
    public static final class Builder {
        private @Nullable ModelServingProvisionedThroughputAiGatewayFallbackConfig fallbackConfig;
        private @Nullable ModelServingProvisionedThroughputAiGatewayGuardrails guardrails;
        private @Nullable ModelServingProvisionedThroughputAiGatewayInferenceTableConfig inferenceTableConfig;
        private @Nullable List<ModelServingProvisionedThroughputAiGatewayRateLimit> rateLimits;
        private @Nullable ModelServingProvisionedThroughputAiGatewayUsageTrackingConfig usageTrackingConfig;
        public Builder() {}
        public Builder(ModelServingProvisionedThroughputAiGateway defaults) {
    	      Objects.requireNonNull(defaults);
    	      this.fallbackConfig = defaults.fallbackConfig;
    	      this.guardrails = defaults.guardrails;
    	      this.inferenceTableConfig = defaults.inferenceTableConfig;
    	      this.rateLimits = defaults.rateLimits;
    	      this.usageTrackingConfig = defaults.usageTrackingConfig;
        }

        @CustomType.Setter
        public Builder fallbackConfig(@Nullable ModelServingProvisionedThroughputAiGatewayFallbackConfig fallbackConfig) {

            this.fallbackConfig = fallbackConfig;
            return this;
        }
        @CustomType.Setter
        public Builder guardrails(@Nullable ModelServingProvisionedThroughputAiGatewayGuardrails guardrails) {

            this.guardrails = guardrails;
            return this;
        }
        @CustomType.Setter
        public Builder inferenceTableConfig(@Nullable ModelServingProvisionedThroughputAiGatewayInferenceTableConfig inferenceTableConfig) {

            this.inferenceTableConfig = inferenceTableConfig;
            return this;
        }
        @CustomType.Setter
        public Builder rateLimits(@Nullable List<ModelServingProvisionedThroughputAiGatewayRateLimit> rateLimits) {

            this.rateLimits = rateLimits;
            return this;
        }
        public Builder rateLimits(ModelServingProvisionedThroughputAiGatewayRateLimit... rateLimits) {
            return rateLimits(List.of(rateLimits));
        }
        @CustomType.Setter
        public Builder usageTrackingConfig(@Nullable ModelServingProvisionedThroughputAiGatewayUsageTrackingConfig usageTrackingConfig) {

            this.usageTrackingConfig = usageTrackingConfig;
            return this;
        }
        public ModelServingProvisionedThroughputAiGateway build() {
            final var _resultValue = new ModelServingProvisionedThroughputAiGateway();
            _resultValue.fallbackConfig = fallbackConfig;
            _resultValue.guardrails = guardrails;
            _resultValue.inferenceTableConfig = inferenceTableConfig;
            _resultValue.rateLimits = rateLimits;
            _resultValue.usageTrackingConfig = usageTrackingConfig;
            return _resultValue;
        }
    }
}
