// *** WARNING: this file was generated by pulumi-java-gen. ***
// *** Do not edit by hand unless you're certain you know what you are doing! ***

package com.pulumi.databricks.inputs;

import com.pulumi.core.Output;
import com.pulumi.core.annotations.Import;
import com.pulumi.databricks.inputs.DatabaseSyncedDatabaseTableSpecNewPipelineSpecArgs;
import java.lang.Boolean;
import java.lang.String;
import java.util.List;
import java.util.Objects;
import java.util.Optional;
import javax.annotation.Nullable;


public final class DatabaseSyncedDatabaseTableSpecArgs extends com.pulumi.resources.ResourceArgs {

    public static final DatabaseSyncedDatabaseTableSpecArgs Empty = new DatabaseSyncedDatabaseTableSpecArgs();

    /**
     * If true, the synced table&#39;s logical database and schema resources in PG
     * will be created if they do not already exist
     * 
     */
    @Import(name="createDatabaseObjectsIfMissing")
    private @Nullable Output<Boolean> createDatabaseObjectsIfMissing;

    /**
     * @return If true, the synced table&#39;s logical database and schema resources in PG
     * will be created if they do not already exist
     * 
     */
    public Optional<Output<Boolean>> createDatabaseObjectsIfMissing() {
        return Optional.ofNullable(this.createDatabaseObjectsIfMissing);
    }

    /**
     * At most one of existing_pipeline_id and new_pipeline_spec should be defined.
     * 
     * If existing_pipeline_id is defined, the synced table will be bin packed into the existing pipeline
     * referenced. This avoids creating a new pipeline and allows sharing existing compute.
     * In this case, the scheduling_policy of this synced table must match the scheduling policy of the existing pipeline
     * 
     */
    @Import(name="existingPipelineId")
    private @Nullable Output<String> existingPipelineId;

    /**
     * @return At most one of existing_pipeline_id and new_pipeline_spec should be defined.
     * 
     * If existing_pipeline_id is defined, the synced table will be bin packed into the existing pipeline
     * referenced. This avoids creating a new pipeline and allows sharing existing compute.
     * In this case, the scheduling_policy of this synced table must match the scheduling policy of the existing pipeline
     * 
     */
    public Optional<Output<String>> existingPipelineId() {
        return Optional.ofNullable(this.existingPipelineId);
    }

    /**
     * At most one of existing_pipeline_id and new_pipeline_spec should be defined.
     * 
     * If new_pipeline_spec is defined, a new pipeline is created for this synced table. The location pointed to is used
     * to store intermediate files (checkpoints, event logs etc). The caller must have write permissions to create Delta
     * tables in the specified catalog and schema. Again, note this requires write permissions, whereas the source table
     * only requires read permissions
     * 
     */
    @Import(name="newPipelineSpec")
    private @Nullable Output<DatabaseSyncedDatabaseTableSpecNewPipelineSpecArgs> newPipelineSpec;

    /**
     * @return At most one of existing_pipeline_id and new_pipeline_spec should be defined.
     * 
     * If new_pipeline_spec is defined, a new pipeline is created for this synced table. The location pointed to is used
     * to store intermediate files (checkpoints, event logs etc). The caller must have write permissions to create Delta
     * tables in the specified catalog and schema. Again, note this requires write permissions, whereas the source table
     * only requires read permissions
     * 
     */
    public Optional<Output<DatabaseSyncedDatabaseTableSpecNewPipelineSpecArgs>> newPipelineSpec() {
        return Optional.ofNullable(this.newPipelineSpec);
    }

    /**
     * Primary Key columns to be used for data insert/update in the destination
     * 
     */
    @Import(name="primaryKeyColumns")
    private @Nullable Output<List<String>> primaryKeyColumns;

    /**
     * @return Primary Key columns to be used for data insert/update in the destination
     * 
     */
    public Optional<Output<List<String>>> primaryKeyColumns() {
        return Optional.ofNullable(this.primaryKeyColumns);
    }

    /**
     * Scheduling policy of the underlying pipeline. Possible values are: `CONTINUOUS`, `SNAPSHOT`, `TRIGGERED`
     * 
     */
    @Import(name="schedulingPolicy")
    private @Nullable Output<String> schedulingPolicy;

    /**
     * @return Scheduling policy of the underlying pipeline. Possible values are: `CONTINUOUS`, `SNAPSHOT`, `TRIGGERED`
     * 
     */
    public Optional<Output<String>> schedulingPolicy() {
        return Optional.ofNullable(this.schedulingPolicy);
    }

    /**
     * Three-part (catalog, schema, table) name of the source Delta table
     * 
     */
    @Import(name="sourceTableFullName")
    private @Nullable Output<String> sourceTableFullName;

    /**
     * @return Three-part (catalog, schema, table) name of the source Delta table
     * 
     */
    public Optional<Output<String>> sourceTableFullName() {
        return Optional.ofNullable(this.sourceTableFullName);
    }

    /**
     * Time series key to deduplicate (tie-break) rows with the same primary key
     * 
     */
    @Import(name="timeseriesKey")
    private @Nullable Output<String> timeseriesKey;

    /**
     * @return Time series key to deduplicate (tie-break) rows with the same primary key
     * 
     */
    public Optional<Output<String>> timeseriesKey() {
        return Optional.ofNullable(this.timeseriesKey);
    }

    private DatabaseSyncedDatabaseTableSpecArgs() {}

    private DatabaseSyncedDatabaseTableSpecArgs(DatabaseSyncedDatabaseTableSpecArgs $) {
        this.createDatabaseObjectsIfMissing = $.createDatabaseObjectsIfMissing;
        this.existingPipelineId = $.existingPipelineId;
        this.newPipelineSpec = $.newPipelineSpec;
        this.primaryKeyColumns = $.primaryKeyColumns;
        this.schedulingPolicy = $.schedulingPolicy;
        this.sourceTableFullName = $.sourceTableFullName;
        this.timeseriesKey = $.timeseriesKey;
    }

    public static Builder builder() {
        return new Builder();
    }
    public static Builder builder(DatabaseSyncedDatabaseTableSpecArgs defaults) {
        return new Builder(defaults);
    }

    public static final class Builder {
        private DatabaseSyncedDatabaseTableSpecArgs $;

        public Builder() {
            $ = new DatabaseSyncedDatabaseTableSpecArgs();
        }

        public Builder(DatabaseSyncedDatabaseTableSpecArgs defaults) {
            $ = new DatabaseSyncedDatabaseTableSpecArgs(Objects.requireNonNull(defaults));
        }

        /**
         * @param createDatabaseObjectsIfMissing If true, the synced table&#39;s logical database and schema resources in PG
         * will be created if they do not already exist
         * 
         * @return builder
         * 
         */
        public Builder createDatabaseObjectsIfMissing(@Nullable Output<Boolean> createDatabaseObjectsIfMissing) {
            $.createDatabaseObjectsIfMissing = createDatabaseObjectsIfMissing;
            return this;
        }

        /**
         * @param createDatabaseObjectsIfMissing If true, the synced table&#39;s logical database and schema resources in PG
         * will be created if they do not already exist
         * 
         * @return builder
         * 
         */
        public Builder createDatabaseObjectsIfMissing(Boolean createDatabaseObjectsIfMissing) {
            return createDatabaseObjectsIfMissing(Output.of(createDatabaseObjectsIfMissing));
        }

        /**
         * @param existingPipelineId At most one of existing_pipeline_id and new_pipeline_spec should be defined.
         * 
         * If existing_pipeline_id is defined, the synced table will be bin packed into the existing pipeline
         * referenced. This avoids creating a new pipeline and allows sharing existing compute.
         * In this case, the scheduling_policy of this synced table must match the scheduling policy of the existing pipeline
         * 
         * @return builder
         * 
         */
        public Builder existingPipelineId(@Nullable Output<String> existingPipelineId) {
            $.existingPipelineId = existingPipelineId;
            return this;
        }

        /**
         * @param existingPipelineId At most one of existing_pipeline_id and new_pipeline_spec should be defined.
         * 
         * If existing_pipeline_id is defined, the synced table will be bin packed into the existing pipeline
         * referenced. This avoids creating a new pipeline and allows sharing existing compute.
         * In this case, the scheduling_policy of this synced table must match the scheduling policy of the existing pipeline
         * 
         * @return builder
         * 
         */
        public Builder existingPipelineId(String existingPipelineId) {
            return existingPipelineId(Output.of(existingPipelineId));
        }

        /**
         * @param newPipelineSpec At most one of existing_pipeline_id and new_pipeline_spec should be defined.
         * 
         * If new_pipeline_spec is defined, a new pipeline is created for this synced table. The location pointed to is used
         * to store intermediate files (checkpoints, event logs etc). The caller must have write permissions to create Delta
         * tables in the specified catalog and schema. Again, note this requires write permissions, whereas the source table
         * only requires read permissions
         * 
         * @return builder
         * 
         */
        public Builder newPipelineSpec(@Nullable Output<DatabaseSyncedDatabaseTableSpecNewPipelineSpecArgs> newPipelineSpec) {
            $.newPipelineSpec = newPipelineSpec;
            return this;
        }

        /**
         * @param newPipelineSpec At most one of existing_pipeline_id and new_pipeline_spec should be defined.
         * 
         * If new_pipeline_spec is defined, a new pipeline is created for this synced table. The location pointed to is used
         * to store intermediate files (checkpoints, event logs etc). The caller must have write permissions to create Delta
         * tables in the specified catalog and schema. Again, note this requires write permissions, whereas the source table
         * only requires read permissions
         * 
         * @return builder
         * 
         */
        public Builder newPipelineSpec(DatabaseSyncedDatabaseTableSpecNewPipelineSpecArgs newPipelineSpec) {
            return newPipelineSpec(Output.of(newPipelineSpec));
        }

        /**
         * @param primaryKeyColumns Primary Key columns to be used for data insert/update in the destination
         * 
         * @return builder
         * 
         */
        public Builder primaryKeyColumns(@Nullable Output<List<String>> primaryKeyColumns) {
            $.primaryKeyColumns = primaryKeyColumns;
            return this;
        }

        /**
         * @param primaryKeyColumns Primary Key columns to be used for data insert/update in the destination
         * 
         * @return builder
         * 
         */
        public Builder primaryKeyColumns(List<String> primaryKeyColumns) {
            return primaryKeyColumns(Output.of(primaryKeyColumns));
        }

        /**
         * @param primaryKeyColumns Primary Key columns to be used for data insert/update in the destination
         * 
         * @return builder
         * 
         */
        public Builder primaryKeyColumns(String... primaryKeyColumns) {
            return primaryKeyColumns(List.of(primaryKeyColumns));
        }

        /**
         * @param schedulingPolicy Scheduling policy of the underlying pipeline. Possible values are: `CONTINUOUS`, `SNAPSHOT`, `TRIGGERED`
         * 
         * @return builder
         * 
         */
        public Builder schedulingPolicy(@Nullable Output<String> schedulingPolicy) {
            $.schedulingPolicy = schedulingPolicy;
            return this;
        }

        /**
         * @param schedulingPolicy Scheduling policy of the underlying pipeline. Possible values are: `CONTINUOUS`, `SNAPSHOT`, `TRIGGERED`
         * 
         * @return builder
         * 
         */
        public Builder schedulingPolicy(String schedulingPolicy) {
            return schedulingPolicy(Output.of(schedulingPolicy));
        }

        /**
         * @param sourceTableFullName Three-part (catalog, schema, table) name of the source Delta table
         * 
         * @return builder
         * 
         */
        public Builder sourceTableFullName(@Nullable Output<String> sourceTableFullName) {
            $.sourceTableFullName = sourceTableFullName;
            return this;
        }

        /**
         * @param sourceTableFullName Three-part (catalog, schema, table) name of the source Delta table
         * 
         * @return builder
         * 
         */
        public Builder sourceTableFullName(String sourceTableFullName) {
            return sourceTableFullName(Output.of(sourceTableFullName));
        }

        /**
         * @param timeseriesKey Time series key to deduplicate (tie-break) rows with the same primary key
         * 
         * @return builder
         * 
         */
        public Builder timeseriesKey(@Nullable Output<String> timeseriesKey) {
            $.timeseriesKey = timeseriesKey;
            return this;
        }

        /**
         * @param timeseriesKey Time series key to deduplicate (tie-break) rows with the same primary key
         * 
         * @return builder
         * 
         */
        public Builder timeseriesKey(String timeseriesKey) {
            return timeseriesKey(Output.of(timeseriesKey));
        }

        public DatabaseSyncedDatabaseTableSpecArgs build() {
            return $;
        }
    }

}
