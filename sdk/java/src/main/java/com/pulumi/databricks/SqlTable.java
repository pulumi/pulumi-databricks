// *** WARNING: this file was generated by pulumi-language-java. ***
// *** Do not edit by hand unless you're certain you know what you are doing! ***

package com.pulumi.databricks;

import com.pulumi.core.Output;
import com.pulumi.core.annotations.Export;
import com.pulumi.core.annotations.ResourceType;
import com.pulumi.core.internal.Codegen;
import com.pulumi.databricks.SqlTableArgs;
import com.pulumi.databricks.Utilities;
import com.pulumi.databricks.inputs.SqlTableState;
import com.pulumi.databricks.outputs.SqlTableColumn;
import com.pulumi.databricks.outputs.SqlTableProviderConfig;
import java.lang.String;
import java.util.List;
import java.util.Map;
import java.util.Optional;
import javax.annotation.Nullable;

/**
 * Within a metastore, Unity Catalog provides a 3-level namespace for organizing data: Catalogs, databases (also called schemas), and tables/views.
 * 
 * A `databricks.SqlTable` is contained within databricks_schema, and can represent either a managed table, an external table, or a view.
 * 
 * This resource creates and updates the Unity Catalog table/view by executing the necessary SQL queries on a special auto-terminating cluster it would create for this operation. You could also specify a SQL warehouse or cluster for the queries to be executed on.
 * 
 * &gt; This resource can only be used with a workspace-level provider!
 * 
 * &gt; This resource doesn&#39;t handle complex cases of schema evolution due to the limitations of Pulumi itself.  If you need to implement schema evolution it&#39;s recommended to use specialized tools, such as, [Liquibase](https://medium.com/dbsql-sme-engineering/advanced-schema-management-on-databricks-with-liquibase-1900e9f7b9c0) and [Flyway](https://medium.com/dbsql-sme-engineering/databricks-schema-management-with-flyway-527c4a9f5d67).
 * 
 * ## Example Usage
 * 
 * <pre>
 * {@code
 * package generated_program;
 * 
 * import com.pulumi.Context;
 * import com.pulumi.Pulumi;
 * import com.pulumi.core.Output;
 * import com.pulumi.databricks.Catalog;
 * import com.pulumi.databricks.CatalogArgs;
 * import com.pulumi.databricks.Schema;
 * import com.pulumi.databricks.SchemaArgs;
 * import com.pulumi.databricks.SqlTable;
 * import com.pulumi.databricks.SqlTableArgs;
 * import com.pulumi.databricks.inputs.SqlTableColumnArgs;
 * import com.pulumi.std.StdFunctions;
 * import com.pulumi.std.inputs.FormatArgs;
 * import java.util.List;
 * import java.util.ArrayList;
 * import java.util.Map;
 * import java.io.File;
 * import java.nio.file.Files;
 * import java.nio.file.Paths;
 * 
 * public class App {
 *     public static void main(String[] args) {
 *         Pulumi.run(App::stack);
 *     }
 * 
 *     public static void stack(Context ctx) {
 *         var sandbox = new Catalog("sandbox", CatalogArgs.builder()
 *             .name("sandbox")
 *             .comment("this catalog is managed by terraform")
 *             .properties(Map.of("purpose", "testing"))
 *             .build());
 * 
 *         var things = new Schema("things", SchemaArgs.builder()
 *             .catalogName(sandbox.id())
 *             .name("things")
 *             .comment("this database is managed by terraform")
 *             .properties(Map.of("kind", "various"))
 *             .build());
 * 
 *         var thing = new SqlTable("thing", SqlTableArgs.builder()
 *             .name("quickstart_table")
 *             .catalogName(sandbox.name())
 *             .schemaName(things.name())
 *             .tableType("MANAGED")
 *             .columns(            
 *                 SqlTableColumnArgs.builder()
 *                     .name("id")
 *                     .type("int")
 *                     .build(),
 *                 SqlTableColumnArgs.builder()
 *                     .name("name")
 *                     .type("string")
 *                     .comment("name of thing")
 *                     .build())
 *             .comment("this table is managed by terraform")
 *             .build());
 * 
 *         var thingView = new SqlTable("thingView", SqlTableArgs.builder()
 *             .name("quickstart_table_view")
 *             .catalogName(sandbox.name())
 *             .schemaName(things.name())
 *             .tableType("VIEW")
 *             .clusterId("0423-201305-xsrt82qn")
 *             .viewDefinition(StdFunctions.format(FormatArgs.builder()
 *                 .input("SELECT name FROM %s WHERE id == 1")
 *                 .args(thing.id())
 *                 .build()).result())
 *             .comment("this view is managed by terraform")
 *             .build());
 * 
 *     }
 * }
 * }
 * </pre>
 * 
 * ### Use an existing warehouse to create a table
 * 
 * <pre>
 * {@code
 * package generated_program;
 * 
 * import com.pulumi.Context;
 * import com.pulumi.Pulumi;
 * import com.pulumi.core.Output;
 * import com.pulumi.databricks.SqlEndpoint;
 * import com.pulumi.databricks.SqlEndpointArgs;
 * import com.pulumi.databricks.SqlTable;
 * import com.pulumi.databricks.SqlTableArgs;
 * import com.pulumi.databricks.inputs.SqlTableColumnArgs;
 * import com.pulumi.std.StdFunctions;
 * import com.pulumi.std.inputs.FormatArgs;
 * import java.util.List;
 * import java.util.ArrayList;
 * import java.util.Map;
 * import java.io.File;
 * import java.nio.file.Files;
 * import java.nio.file.Paths;
 * 
 * public class App {
 *     public static void main(String[] args) {
 *         Pulumi.run(App::stack);
 *     }
 * 
 *     public static void stack(Context ctx) {
 *         var this_ = new SqlEndpoint("this", SqlEndpointArgs.builder()
 *             .name("endpoint")
 *             .clusterSize("2X-Small")
 *             .maxNumClusters(1)
 *             .build());
 * 
 *         var thing = new SqlTable("thing", SqlTableArgs.builder()
 *             .name("quickstart_table")
 *             .catalogName(sandbox.name())
 *             .schemaName(things.name())
 *             .tableType("MANAGED")
 *             .warehouseId(this_.id())
 *             .columns(            
 *                 SqlTableColumnArgs.builder()
 *                     .name("id")
 *                     .type("int")
 *                     .build(),
 *                 SqlTableColumnArgs.builder()
 *                     .name("name")
 *                     .type("string")
 *                     .comment("name of thing")
 *                     .build())
 *             .comment("this table is managed by terraform")
 *             .build());
 * 
 *         var thingView = new SqlTable("thingView", SqlTableArgs.builder()
 *             .name("quickstart_table_view")
 *             .catalogName(sandbox.name())
 *             .schemaName(things.name())
 *             .tableType("VIEW")
 *             .warehouseId(this_.id())
 *             .viewDefinition(StdFunctions.format(FormatArgs.builder()
 *                 .input("SELECT name FROM %s WHERE id == 1")
 *                 .args(thing.id())
 *                 .build()).result())
 *             .comment("this view is managed by terraform")
 *             .build());
 * 
 *     }
 * }
 * }
 * </pre>
 * 
 * ## Use an Identity Column
 * 
 * <pre>
 * {@code
 * package generated_program;
 * 
 * import com.pulumi.Context;
 * import com.pulumi.Pulumi;
 * import com.pulumi.core.Output;
 * import com.pulumi.databricks.Catalog;
 * import com.pulumi.databricks.CatalogArgs;
 * import com.pulumi.databricks.Schema;
 * import com.pulumi.databricks.SchemaArgs;
 * import com.pulumi.databricks.SqlTable;
 * import com.pulumi.databricks.SqlTableArgs;
 * import com.pulumi.databricks.inputs.SqlTableColumnArgs;
 * import java.util.List;
 * import java.util.ArrayList;
 * import java.util.Map;
 * import java.io.File;
 * import java.nio.file.Files;
 * import java.nio.file.Paths;
 * 
 * public class App {
 *     public static void main(String[] args) {
 *         Pulumi.run(App::stack);
 *     }
 * 
 *     public static void stack(Context ctx) {
 *         var sandbox = new Catalog("sandbox", CatalogArgs.builder()
 *             .name("sandbox")
 *             .comment("this catalog is managed by terraform")
 *             .properties(Map.of("purpose", "testing"))
 *             .build());
 * 
 *         var things = new Schema("things", SchemaArgs.builder()
 *             .catalogName(sandbox.id())
 *             .name("things")
 *             .comment("this database is managed by terraform")
 *             .properties(Map.of("kind", "various"))
 *             .build());
 * 
 *         var thing = new SqlTable("thing", SqlTableArgs.builder()
 *             .name("identity_table")
 *             .catalogName(sandbox.name())
 *             .schemaName(things.name())
 *             .tableType("MANAGED")
 *             .columns(            
 *                 SqlTableColumnArgs.builder()
 *                     .name("id")
 *                     .type("bigint")
 *                     .identity("default")
 *                     .build(),
 *                 SqlTableColumnArgs.builder()
 *                     .name("name")
 *                     .type("string")
 *                     .comment("name of thing")
 *                     .build())
 *             .comment("this table is managed by terraform")
 *             .build());
 * 
 *     }
 * }
 * }
 * </pre>
 * 
 * ## Enable automatic clustering
 * 
 * <pre>
 * {@code
 * package generated_program;
 * 
 * import com.pulumi.Context;
 * import com.pulumi.Pulumi;
 * import com.pulumi.core.Output;
 * import com.pulumi.databricks.SqlTable;
 * import com.pulumi.databricks.SqlTableArgs;
 * import com.pulumi.databricks.inputs.SqlTableColumnArgs;
 * import java.util.List;
 * import java.util.ArrayList;
 * import java.util.Map;
 * import java.io.File;
 * import java.nio.file.Files;
 * import java.nio.file.Paths;
 * 
 * public class App {
 *     public static void main(String[] args) {
 *         Pulumi.run(App::stack);
 *     }
 * 
 *     public static void stack(Context ctx) {
 *         var thing = new SqlTable("thing", SqlTableArgs.builder()
 *             .name("auto_cluster_table")
 *             .catalogName(sandbox.name())
 *             .schemaName(things.name())
 *             .tableType("MANAGED")
 *             .clusterKeys("AUTO")
 *             .columns(SqlTableColumnArgs.builder()
 *                 .name("name")
 *                 .type("string")
 *                 .comment("name of thing")
 *                 .build())
 *             .comment("this table is managed by terraform")
 *             .build());
 * 
 *     }
 * }
 * }
 * </pre>
 * 
 * ## Migration from `databricks.Table`
 * 
 * The `databricks.Table` resource has been deprecated in favor of `databricks.SqlTable`. To migrate from `databricks.Table` to `databricks.SqlTable`:
 * 
 * 1. Define a `databricks.SqlTable` resource with arguments corresponding to `databricks.Table`.
 * 2. Add a `removed` block to remove the `databricks.Table` resource without deleting the existing table by using the `lifecycle` block. If you&#39;re using Pulumi version below v1.7.0, you will need to use the `terraform state rm` command instead.
 * 3. Add an `import` block to add the `databricks.SqlTable` resource, corresponding to the existing table. If you&#39;re using Pulumi version below v1.5.0, you will need to use `pulumi import` command instead.
 * 
 * For example, suppose we have the following `databricks.Table` resource:
 * 
 * <pre>
 * {@code
 * package generated_program;
 * 
 * import com.pulumi.Context;
 * import com.pulumi.Pulumi;
 * import com.pulumi.core.Output;
 * import com.pulumi.databricks.Table;
 * import com.pulumi.databricks.TableArgs;
 * import com.pulumi.databricks.inputs.TableColumnArgs;
 * import java.util.List;
 * import java.util.ArrayList;
 * import java.util.Map;
 * import java.io.File;
 * import java.nio.file.Files;
 * import java.nio.file.Paths;
 * 
 * public class App {
 *     public static void main(String[] args) {
 *         Pulumi.run(App::stack);
 *     }
 * 
 *     public static void stack(Context ctx) {
 *         var this_ = new Table("this", TableArgs.builder()
 *             .catalogName("catalog")
 *             .schemaName("schema")
 *             .name("table")
 *             .tableType("MANAGED")
 *             .dataSourceFormat("DELTA")
 *             .columns(TableColumnArgs.builder()
 *                 .name("col1")
 *                 .typeName("STRING")
 *                 .typeJson("{\"type\":\"STRING\"}")
 *                 .comment("comment")
 *                 .nullable(true)
 *                 .build())
 *             .comment("comment")
 *             .properties(Map.of("key", "value"))
 *             .build());
 * 
 *     }
 * }
 * }
 * </pre>
 * 
 * The migration would look like this:
 * 
 */
@ResourceType(type="databricks:index/sqlTable:SqlTable")
public class SqlTable extends com.pulumi.resources.CustomResource {
    /**
     * Name of parent catalog. Change forces the creation of a new resource.
     * 
     */
    @Export(name="catalogName", refs={String.class}, tree="[0]")
    private Output<String> catalogName;

    /**
     * @return Name of parent catalog. Change forces the creation of a new resource.
     * 
     */
    public Output<String> catalogName() {
        return this.catalogName;
    }
    /**
     * All table CRUD operations must be executed on a running cluster or SQL warehouse. If a clusterId is specified, it will be used to execute SQL commands to manage this table. If empty, a cluster will be created automatically with the name `terraform-sql-table`. Conflicts with `warehouseId`.
     * 
     */
    @Export(name="clusterId", refs={String.class}, tree="[0]")
    private Output<String> clusterId;

    /**
     * @return All table CRUD operations must be executed on a running cluster or SQL warehouse. If a clusterId is specified, it will be used to execute SQL commands to manage this table. If empty, a cluster will be created automatically with the name `terraform-sql-table`. Conflicts with `warehouseId`.
     * 
     */
    public Output<String> clusterId() {
        return this.clusterId;
    }
    /**
     * a subset of columns to liquid cluster the table by. For automatic clustering, set `clusterKeys` to `[&#34;AUTO&#34;]`. To turn off clustering, set it to `[&#34;NONE&#34;]`. Conflicts with `partitions`.
     * 
     */
    @Export(name="clusterKeys", refs={List.class,String.class}, tree="[0,1]")
    private Output</* @Nullable */ List<String>> clusterKeys;

    /**
     * @return a subset of columns to liquid cluster the table by. For automatic clustering, set `clusterKeys` to `[&#34;AUTO&#34;]`. To turn off clustering, set it to `[&#34;NONE&#34;]`. Conflicts with `partitions`.
     * 
     */
    public Output<Optional<List<String>>> clusterKeys() {
        return Codegen.optional(this.clusterKeys);
    }
    @Export(name="columns", refs={List.class,SqlTableColumn.class}, tree="[0,1]")
    private Output<List<SqlTableColumn>> columns;

    public Output<List<SqlTableColumn>> columns() {
        return this.columns;
    }
    /**
     * User-supplied free-form text. Changing the comment is not currently supported on the `VIEW` table type.
     * 
     */
    @Export(name="comment", refs={String.class}, tree="[0]")
    private Output</* @Nullable */ String> comment;

    /**
     * @return User-supplied free-form text. Changing the comment is not currently supported on the `VIEW` table type.
     * 
     */
    public Output<Optional<String>> comment() {
        return Codegen.optional(this.comment);
    }
    /**
     * External tables are supported in multiple data source formats. The string constants identifying these formats are `DELTA`, `CSV`, `JSON`, `AVRO`, `PARQUET`, `ORC`, and `TEXT`. Change forces the creation of a new resource. Not supported for `MANAGED` tables or `VIEW`.
     * 
     */
    @Export(name="dataSourceFormat", refs={String.class}, tree="[0]")
    private Output</* @Nullable */ String> dataSourceFormat;

    /**
     * @return External tables are supported in multiple data source formats. The string constants identifying these formats are `DELTA`, `CSV`, `JSON`, `AVRO`, `PARQUET`, `ORC`, and `TEXT`. Change forces the creation of a new resource. Not supported for `MANAGED` tables or `VIEW`.
     * 
     */
    public Output<Optional<String>> dataSourceFormat() {
        return Codegen.optional(this.dataSourceFormat);
    }
    @Export(name="effectiveProperties", refs={Map.class,String.class}, tree="[0,1,1]")
    private Output<Map<String,String>> effectiveProperties;

    public Output<Map<String,String>> effectiveProperties() {
        return this.effectiveProperties;
    }
    /**
     * Name of table relative to parent catalog and schema. Change forces the creation of a new resource.
     * 
     */
    @Export(name="name", refs={String.class}, tree="[0]")
    private Output<String> name;

    /**
     * @return Name of table relative to parent catalog and schema. Change forces the creation of a new resource.
     * 
     */
    public Output<String> name() {
        return this.name;
    }
    /**
     * Map of user defined table options. Change forces creation of a new resource.
     * 
     */
    @Export(name="options", refs={Map.class,String.class}, tree="[0,1,1]")
    private Output</* @Nullable */ Map<String,String>> options;

    /**
     * @return Map of user defined table options. Change forces creation of a new resource.
     * 
     */
    public Output<Optional<Map<String,String>>> options() {
        return Codegen.optional(this.options);
    }
    /**
     * User name/group name/sp applicationId of the table owner.
     * 
     */
    @Export(name="owner", refs={String.class}, tree="[0]")
    private Output<String> owner;

    /**
     * @return User name/group name/sp applicationId of the table owner.
     * 
     */
    public Output<String> owner() {
        return this.owner;
    }
    /**
     * a subset of columns to partition the table by. Change forces the creation of a new resource. Conflicts with `clusterKeys`.
     * 
     */
    @Export(name="partitions", refs={List.class,String.class}, tree="[0,1]")
    private Output<List<String>> partitions;

    /**
     * @return a subset of columns to partition the table by. Change forces the creation of a new resource. Conflicts with `clusterKeys`.
     * 
     */
    public Output<List<String>> partitions() {
        return this.partitions;
    }
    /**
     * A map of table properties.
     * 
     */
    @Export(name="properties", refs={Map.class,String.class}, tree="[0,1,1]")
    private Output</* @Nullable */ Map<String,String>> properties;

    /**
     * @return A map of table properties.
     * 
     */
    public Output<Optional<Map<String,String>>> properties() {
        return Codegen.optional(this.properties);
    }
    /**
     * Configure the provider for management through account provider. This block consists of the following fields:
     * 
     */
    @Export(name="providerConfig", refs={SqlTableProviderConfig.class}, tree="[0]")
    private Output</* @Nullable */ SqlTableProviderConfig> providerConfig;

    /**
     * @return Configure the provider for management through account provider. This block consists of the following fields:
     * 
     */
    public Output<Optional<SqlTableProviderConfig>> providerConfig() {
        return Codegen.optional(this.providerConfig);
    }
    /**
     * Name of parent Schema relative to parent Catalog. Change forces the creation of a new resource.
     * 
     */
    @Export(name="schemaName", refs={String.class}, tree="[0]")
    private Output<String> schemaName;

    /**
     * @return Name of parent Schema relative to parent Catalog. Change forces the creation of a new resource.
     * 
     */
    public Output<String> schemaName() {
        return this.schemaName;
    }
    /**
     * For EXTERNAL Tables only: the name of storage credential to use. Change forces the creation of a new resource.
     * 
     */
    @Export(name="storageCredentialName", refs={String.class}, tree="[0]")
    private Output</* @Nullable */ String> storageCredentialName;

    /**
     * @return For EXTERNAL Tables only: the name of storage credential to use. Change forces the creation of a new resource.
     * 
     */
    public Output<Optional<String>> storageCredentialName() {
        return Codegen.optional(this.storageCredentialName);
    }
    /**
     * URL of storage location for Table data (required for EXTERNAL Tables).  If the URL contains special characters, such as space, `&amp;`, etc., they should be percent-encoded (space &gt; `%20`, etc.).  Not supported for `VIEW` or `MANAGED` table_type.
     * 
     */
    @Export(name="storageLocation", refs={String.class}, tree="[0]")
    private Output</* @Nullable */ String> storageLocation;

    /**
     * @return URL of storage location for Table data (required for EXTERNAL Tables).  If the URL contains special characters, such as space, `&amp;`, etc., they should be percent-encoded (space &gt; `%20`, etc.).  Not supported for `VIEW` or `MANAGED` table_type.
     * 
     */
    public Output<Optional<String>> storageLocation() {
        return Codegen.optional(this.storageLocation);
    }
    /**
     * The unique identifier of the table.
     * 
     */
    @Export(name="tableId", refs={String.class}, tree="[0]")
    private Output<String> tableId;

    /**
     * @return The unique identifier of the table.
     * 
     */
    public Output<String> tableId() {
        return this.tableId;
    }
    /**
     * Distinguishes a view vs. managed/external Table. `MANAGED`, `EXTERNAL` or `VIEW`. Change forces the creation of a new resource.
     * 
     */
    @Export(name="tableType", refs={String.class}, tree="[0]")
    private Output<String> tableType;

    /**
     * @return Distinguishes a view vs. managed/external Table. `MANAGED`, `EXTERNAL` or `VIEW`. Change forces the creation of a new resource.
     * 
     */
    public Output<String> tableType() {
        return this.tableType;
    }
    /**
     * SQL text defining the view (for `tableType == &#34;VIEW&#34;`). Not supported for `MANAGED` or `EXTERNAL` table_type.
     * 
     */
    @Export(name="viewDefinition", refs={String.class}, tree="[0]")
    private Output</* @Nullable */ String> viewDefinition;

    /**
     * @return SQL text defining the view (for `tableType == &#34;VIEW&#34;`). Not supported for `MANAGED` or `EXTERNAL` table_type.
     * 
     */
    public Output<Optional<String>> viewDefinition() {
        return Codegen.optional(this.viewDefinition);
    }
    /**
     * All table CRUD operations must be executed on a running cluster or SQL warehouse. If a `warehouseId` is specified, that SQL warehouse will be used to execute SQL commands to manage this table. Conflicts with `clusterId`.
     * 
     */
    @Export(name="warehouseId", refs={String.class}, tree="[0]")
    private Output</* @Nullable */ String> warehouseId;

    /**
     * @return All table CRUD operations must be executed on a running cluster or SQL warehouse. If a `warehouseId` is specified, that SQL warehouse will be used to execute SQL commands to manage this table. Conflicts with `clusterId`.
     * 
     */
    public Output<Optional<String>> warehouseId() {
        return Codegen.optional(this.warehouseId);
    }

    /**
     *
     * @param name The _unique_ name of the resulting resource.
     */
    public SqlTable(java.lang.String name) {
        this(name, SqlTableArgs.Empty);
    }
    /**
     *
     * @param name The _unique_ name of the resulting resource.
     * @param args The arguments to use to populate this resource's properties.
     */
    public SqlTable(java.lang.String name, SqlTableArgs args) {
        this(name, args, null);
    }
    /**
     *
     * @param name The _unique_ name of the resulting resource.
     * @param args The arguments to use to populate this resource's properties.
     * @param options A bag of options that control this resource's behavior.
     */
    public SqlTable(java.lang.String name, SqlTableArgs args, @Nullable com.pulumi.resources.CustomResourceOptions options) {
        super("databricks:index/sqlTable:SqlTable", name, makeArgs(args, options), makeResourceOptions(options, Codegen.empty()), false);
    }

    private SqlTable(java.lang.String name, Output<java.lang.String> id, @Nullable SqlTableState state, @Nullable com.pulumi.resources.CustomResourceOptions options) {
        super("databricks:index/sqlTable:SqlTable", name, state, makeResourceOptions(options, id), false);
    }

    private static SqlTableArgs makeArgs(SqlTableArgs args, @Nullable com.pulumi.resources.CustomResourceOptions options) {
        if (options != null && options.getUrn().isPresent()) {
            return null;
        }
        return args == null ? SqlTableArgs.Empty : args;
    }

    private static com.pulumi.resources.CustomResourceOptions makeResourceOptions(@Nullable com.pulumi.resources.CustomResourceOptions options, @Nullable Output<java.lang.String> id) {
        var defaultOptions = com.pulumi.resources.CustomResourceOptions.builder()
            .version(Utilities.getVersion())
            .build();
        return com.pulumi.resources.CustomResourceOptions.merge(defaultOptions, options, id);
    }

    /**
     * Get an existing Host resource's state with the given name, ID, and optional extra
     * properties used to qualify the lookup.
     *
     * @param name The _unique_ name of the resulting resource.
     * @param id The _unique_ provider ID of the resource to lookup.
     * @param state
     * @param options Optional settings to control the behavior of the CustomResource.
     */
    public static SqlTable get(java.lang.String name, Output<java.lang.String> id, @Nullable SqlTableState state, @Nullable com.pulumi.resources.CustomResourceOptions options) {
        return new SqlTable(name, id, state, options);
    }
}
