// *** WARNING: this file was generated by pulumi-java-gen. ***
// *** Do not edit by hand unless you're certain you know what you are doing! ***

package com.pulumi.databricks.inputs;

import com.pulumi.core.Output;
import com.pulumi.core.annotations.Import;
import com.pulumi.databricks.inputs.GetClusterClusterInfoSpecAutoscaleArgs;
import com.pulumi.databricks.inputs.GetClusterClusterInfoSpecAwsAttributesArgs;
import com.pulumi.databricks.inputs.GetClusterClusterInfoSpecAzureAttributesArgs;
import com.pulumi.databricks.inputs.GetClusterClusterInfoSpecClusterLogConfArgs;
import com.pulumi.databricks.inputs.GetClusterClusterInfoSpecClusterMountInfoArgs;
import com.pulumi.databricks.inputs.GetClusterClusterInfoSpecDockerImageArgs;
import com.pulumi.databricks.inputs.GetClusterClusterInfoSpecGcpAttributesArgs;
import com.pulumi.databricks.inputs.GetClusterClusterInfoSpecInitScriptArgs;
import com.pulumi.databricks.inputs.GetClusterClusterInfoSpecLibraryArgs;
import com.pulumi.databricks.inputs.GetClusterClusterInfoSpecWorkloadTypeArgs;
import com.pulumi.exceptions.MissingRequiredPropertyException;
import java.lang.Boolean;
import java.lang.Integer;
import java.lang.String;
import java.util.List;
import java.util.Map;
import java.util.Objects;
import java.util.Optional;
import javax.annotation.Nullable;


public final class GetClusterClusterInfoSpecArgs extends com.pulumi.resources.ResourceArgs {

    public static final GetClusterClusterInfoSpecArgs Empty = new GetClusterClusterInfoSpecArgs();

    @Import(name="applyPolicyDefaultValues")
    private @Nullable Output<Boolean> applyPolicyDefaultValues;

    public Optional<Output<Boolean>> applyPolicyDefaultValues() {
        return Optional.ofNullable(this.applyPolicyDefaultValues);
    }

    @Import(name="autoscale")
    private @Nullable Output<GetClusterClusterInfoSpecAutoscaleArgs> autoscale;

    public Optional<Output<GetClusterClusterInfoSpecAutoscaleArgs>> autoscale() {
        return Optional.ofNullable(this.autoscale);
    }

    @Import(name="awsAttributes")
    private @Nullable Output<GetClusterClusterInfoSpecAwsAttributesArgs> awsAttributes;

    public Optional<Output<GetClusterClusterInfoSpecAwsAttributesArgs>> awsAttributes() {
        return Optional.ofNullable(this.awsAttributes);
    }

    @Import(name="azureAttributes")
    private @Nullable Output<GetClusterClusterInfoSpecAzureAttributesArgs> azureAttributes;

    public Optional<Output<GetClusterClusterInfoSpecAzureAttributesArgs>> azureAttributes() {
        return Optional.ofNullable(this.azureAttributes);
    }

    /**
     * The id of the cluster
     * 
     */
    @Import(name="clusterId", required=true)
    private Output<String> clusterId;

    /**
     * @return The id of the cluster
     * 
     */
    public Output<String> clusterId() {
        return this.clusterId;
    }

    @Import(name="clusterLogConf")
    private @Nullable Output<GetClusterClusterInfoSpecClusterLogConfArgs> clusterLogConf;

    public Optional<Output<GetClusterClusterInfoSpecClusterLogConfArgs>> clusterLogConf() {
        return Optional.ofNullable(this.clusterLogConf);
    }

    @Import(name="clusterMountInfos")
    private @Nullable Output<List<GetClusterClusterInfoSpecClusterMountInfoArgs>> clusterMountInfos;

    public Optional<Output<List<GetClusterClusterInfoSpecClusterMountInfoArgs>>> clusterMountInfos() {
        return Optional.ofNullable(this.clusterMountInfos);
    }

    /**
     * The exact name of the cluster to search
     * 
     */
    @Import(name="clusterName")
    private @Nullable Output<String> clusterName;

    /**
     * @return The exact name of the cluster to search
     * 
     */
    public Optional<Output<String>> clusterName() {
        return Optional.ofNullable(this.clusterName);
    }

    /**
     * Additional tags for cluster resources.
     * 
     */
    @Import(name="customTags")
    private @Nullable Output<Map<String,String>> customTags;

    /**
     * @return Additional tags for cluster resources.
     * 
     */
    public Optional<Output<Map<String,String>>> customTags() {
        return Optional.ofNullable(this.customTags);
    }

    /**
     * Security features of the cluster. Unity Catalog requires `SINGLE_USER` or `USER_ISOLATION` mode. `LEGACY_PASSTHROUGH` for passthrough cluster and `LEGACY_TABLE_ACL` for Table ACL cluster. Default to `NONE`, i.e. no security feature enabled.
     * 
     */
    @Import(name="dataSecurityMode")
    private @Nullable Output<String> dataSecurityMode;

    /**
     * @return Security features of the cluster. Unity Catalog requires `SINGLE_USER` or `USER_ISOLATION` mode. `LEGACY_PASSTHROUGH` for passthrough cluster and `LEGACY_TABLE_ACL` for Table ACL cluster. Default to `NONE`, i.e. no security feature enabled.
     * 
     */
    public Optional<Output<String>> dataSecurityMode() {
        return Optional.ofNullable(this.dataSecurityMode);
    }

    @Import(name="dockerImage")
    private @Nullable Output<GetClusterClusterInfoSpecDockerImageArgs> dockerImage;

    public Optional<Output<GetClusterClusterInfoSpecDockerImageArgs>> dockerImage() {
        return Optional.ofNullable(this.dockerImage);
    }

    /**
     * similar to `instance_pool_id`, but for driver node.
     * 
     */
    @Import(name="driverInstancePoolId", required=true)
    private Output<String> driverInstancePoolId;

    /**
     * @return similar to `instance_pool_id`, but for driver node.
     * 
     */
    public Output<String> driverInstancePoolId() {
        return this.driverInstancePoolId;
    }

    /**
     * The node type of the Spark driver.
     * 
     */
    @Import(name="driverNodeTypeId", required=true)
    private Output<String> driverNodeTypeId;

    /**
     * @return The node type of the Spark driver.
     * 
     */
    public Output<String> driverNodeTypeId() {
        return this.driverNodeTypeId;
    }

    /**
     * Use autoscaling local storage.
     * 
     */
    @Import(name="enableElasticDisk", required=true)
    private Output<Boolean> enableElasticDisk;

    /**
     * @return Use autoscaling local storage.
     * 
     */
    public Output<Boolean> enableElasticDisk() {
        return this.enableElasticDisk;
    }

    /**
     * Enable local disk encryption.
     * 
     */
    @Import(name="enableLocalDiskEncryption", required=true)
    private Output<Boolean> enableLocalDiskEncryption;

    /**
     * @return Enable local disk encryption.
     * 
     */
    public Output<Boolean> enableLocalDiskEncryption() {
        return this.enableLocalDiskEncryption;
    }

    @Import(name="gcpAttributes")
    private @Nullable Output<GetClusterClusterInfoSpecGcpAttributesArgs> gcpAttributes;

    public Optional<Output<GetClusterClusterInfoSpecGcpAttributesArgs>> gcpAttributes() {
        return Optional.ofNullable(this.gcpAttributes);
    }

    /**
     * An optional token to guarantee the idempotency of cluster creation requests.
     * 
     */
    @Import(name="idempotencyToken")
    private @Nullable Output<String> idempotencyToken;

    /**
     * @return An optional token to guarantee the idempotency of cluster creation requests.
     * 
     */
    public Optional<Output<String>> idempotencyToken() {
        return Optional.ofNullable(this.idempotencyToken);
    }

    @Import(name="initScripts")
    private @Nullable Output<List<GetClusterClusterInfoSpecInitScriptArgs>> initScripts;

    public Optional<Output<List<GetClusterClusterInfoSpecInitScriptArgs>>> initScripts() {
        return Optional.ofNullable(this.initScripts);
    }

    /**
     * The pool of idle instances the cluster is attached to.
     * 
     */
    @Import(name="instancePoolId")
    private @Nullable Output<String> instancePoolId;

    /**
     * @return The pool of idle instances the cluster is attached to.
     * 
     */
    public Optional<Output<String>> instancePoolId() {
        return Optional.ofNullable(this.instancePoolId);
    }

    @Import(name="libraries")
    private @Nullable Output<List<GetClusterClusterInfoSpecLibraryArgs>> libraries;

    public Optional<Output<List<GetClusterClusterInfoSpecLibraryArgs>>> libraries() {
        return Optional.ofNullable(this.libraries);
    }

    /**
     * Any supported databricks.getNodeType id.
     * 
     */
    @Import(name="nodeTypeId", required=true)
    private Output<String> nodeTypeId;

    /**
     * @return Any supported databricks.getNodeType id.
     * 
     */
    public Output<String> nodeTypeId() {
        return this.nodeTypeId;
    }

    @Import(name="numWorkers")
    private @Nullable Output<Integer> numWorkers;

    public Optional<Output<Integer>> numWorkers() {
        return Optional.ofNullable(this.numWorkers);
    }

    /**
     * Identifier of Cluster Policy to validate cluster and preset certain defaults.
     * 
     */
    @Import(name="policyId")
    private @Nullable Output<String> policyId;

    /**
     * @return Identifier of Cluster Policy to validate cluster and preset certain defaults.
     * 
     */
    public Optional<Output<String>> policyId() {
        return Optional.ofNullable(this.policyId);
    }

    /**
     * The type of runtime of the cluster
     * 
     */
    @Import(name="runtimeEngine")
    private @Nullable Output<String> runtimeEngine;

    /**
     * @return The type of runtime of the cluster
     * 
     */
    public Optional<Output<String>> runtimeEngine() {
        return Optional.ofNullable(this.runtimeEngine);
    }

    /**
     * The optional user name of the user to assign to an interactive cluster. This field is required when using standard AAD Passthrough for Azure Data Lake Storage (ADLS) with a single-user cluster (i.e., not high-concurrency clusters).
     * 
     */
    @Import(name="singleUserName")
    private @Nullable Output<String> singleUserName;

    /**
     * @return The optional user name of the user to assign to an interactive cluster. This field is required when using standard AAD Passthrough for Azure Data Lake Storage (ADLS) with a single-user cluster (i.e., not high-concurrency clusters).
     * 
     */
    public Optional<Output<String>> singleUserName() {
        return Optional.ofNullable(this.singleUserName);
    }

    /**
     * Map with key-value pairs to fine-tune Spark clusters.
     * 
     */
    @Import(name="sparkConf")
    private @Nullable Output<Map<String,String>> sparkConf;

    /**
     * @return Map with key-value pairs to fine-tune Spark clusters.
     * 
     */
    public Optional<Output<Map<String,String>>> sparkConf() {
        return Optional.ofNullable(this.sparkConf);
    }

    /**
     * Map with environment variable key-value pairs to fine-tune Spark clusters. Key-value pairs of the form (X,Y) are exported (i.e., X=&#39;Y&#39;) while launching the driver and workers.
     * 
     */
    @Import(name="sparkEnvVars")
    private @Nullable Output<Map<String,String>> sparkEnvVars;

    /**
     * @return Map with environment variable key-value pairs to fine-tune Spark clusters. Key-value pairs of the form (X,Y) are exported (i.e., X=&#39;Y&#39;) while launching the driver and workers.
     * 
     */
    public Optional<Output<Map<String,String>>> sparkEnvVars() {
        return Optional.ofNullable(this.sparkEnvVars);
    }

    /**
     * [Runtime version](https://docs.databricks.com/runtime/index.html) of the cluster.
     * 
     */
    @Import(name="sparkVersion", required=true)
    private Output<String> sparkVersion;

    /**
     * @return [Runtime version](https://docs.databricks.com/runtime/index.html) of the cluster.
     * 
     */
    public Output<String> sparkVersion() {
        return this.sparkVersion;
    }

    /**
     * SSH public key contents that will be added to each Spark node in this cluster.
     * 
     */
    @Import(name="sshPublicKeys")
    private @Nullable Output<List<String>> sshPublicKeys;

    /**
     * @return SSH public key contents that will be added to each Spark node in this cluster.
     * 
     */
    public Optional<Output<List<String>>> sshPublicKeys() {
        return Optional.ofNullable(this.sshPublicKeys);
    }

    @Import(name="workloadType")
    private @Nullable Output<GetClusterClusterInfoSpecWorkloadTypeArgs> workloadType;

    public Optional<Output<GetClusterClusterInfoSpecWorkloadTypeArgs>> workloadType() {
        return Optional.ofNullable(this.workloadType);
    }

    private GetClusterClusterInfoSpecArgs() {}

    private GetClusterClusterInfoSpecArgs(GetClusterClusterInfoSpecArgs $) {
        this.applyPolicyDefaultValues = $.applyPolicyDefaultValues;
        this.autoscale = $.autoscale;
        this.awsAttributes = $.awsAttributes;
        this.azureAttributes = $.azureAttributes;
        this.clusterId = $.clusterId;
        this.clusterLogConf = $.clusterLogConf;
        this.clusterMountInfos = $.clusterMountInfos;
        this.clusterName = $.clusterName;
        this.customTags = $.customTags;
        this.dataSecurityMode = $.dataSecurityMode;
        this.dockerImage = $.dockerImage;
        this.driverInstancePoolId = $.driverInstancePoolId;
        this.driverNodeTypeId = $.driverNodeTypeId;
        this.enableElasticDisk = $.enableElasticDisk;
        this.enableLocalDiskEncryption = $.enableLocalDiskEncryption;
        this.gcpAttributes = $.gcpAttributes;
        this.idempotencyToken = $.idempotencyToken;
        this.initScripts = $.initScripts;
        this.instancePoolId = $.instancePoolId;
        this.libraries = $.libraries;
        this.nodeTypeId = $.nodeTypeId;
        this.numWorkers = $.numWorkers;
        this.policyId = $.policyId;
        this.runtimeEngine = $.runtimeEngine;
        this.singleUserName = $.singleUserName;
        this.sparkConf = $.sparkConf;
        this.sparkEnvVars = $.sparkEnvVars;
        this.sparkVersion = $.sparkVersion;
        this.sshPublicKeys = $.sshPublicKeys;
        this.workloadType = $.workloadType;
    }

    public static Builder builder() {
        return new Builder();
    }
    public static Builder builder(GetClusterClusterInfoSpecArgs defaults) {
        return new Builder(defaults);
    }

    public static final class Builder {
        private GetClusterClusterInfoSpecArgs $;

        public Builder() {
            $ = new GetClusterClusterInfoSpecArgs();
        }

        public Builder(GetClusterClusterInfoSpecArgs defaults) {
            $ = new GetClusterClusterInfoSpecArgs(Objects.requireNonNull(defaults));
        }

        public Builder applyPolicyDefaultValues(@Nullable Output<Boolean> applyPolicyDefaultValues) {
            $.applyPolicyDefaultValues = applyPolicyDefaultValues;
            return this;
        }

        public Builder applyPolicyDefaultValues(Boolean applyPolicyDefaultValues) {
            return applyPolicyDefaultValues(Output.of(applyPolicyDefaultValues));
        }

        public Builder autoscale(@Nullable Output<GetClusterClusterInfoSpecAutoscaleArgs> autoscale) {
            $.autoscale = autoscale;
            return this;
        }

        public Builder autoscale(GetClusterClusterInfoSpecAutoscaleArgs autoscale) {
            return autoscale(Output.of(autoscale));
        }

        public Builder awsAttributes(@Nullable Output<GetClusterClusterInfoSpecAwsAttributesArgs> awsAttributes) {
            $.awsAttributes = awsAttributes;
            return this;
        }

        public Builder awsAttributes(GetClusterClusterInfoSpecAwsAttributesArgs awsAttributes) {
            return awsAttributes(Output.of(awsAttributes));
        }

        public Builder azureAttributes(@Nullable Output<GetClusterClusterInfoSpecAzureAttributesArgs> azureAttributes) {
            $.azureAttributes = azureAttributes;
            return this;
        }

        public Builder azureAttributes(GetClusterClusterInfoSpecAzureAttributesArgs azureAttributes) {
            return azureAttributes(Output.of(azureAttributes));
        }

        /**
         * @param clusterId The id of the cluster
         * 
         * @return builder
         * 
         */
        public Builder clusterId(Output<String> clusterId) {
            $.clusterId = clusterId;
            return this;
        }

        /**
         * @param clusterId The id of the cluster
         * 
         * @return builder
         * 
         */
        public Builder clusterId(String clusterId) {
            return clusterId(Output.of(clusterId));
        }

        public Builder clusterLogConf(@Nullable Output<GetClusterClusterInfoSpecClusterLogConfArgs> clusterLogConf) {
            $.clusterLogConf = clusterLogConf;
            return this;
        }

        public Builder clusterLogConf(GetClusterClusterInfoSpecClusterLogConfArgs clusterLogConf) {
            return clusterLogConf(Output.of(clusterLogConf));
        }

        public Builder clusterMountInfos(@Nullable Output<List<GetClusterClusterInfoSpecClusterMountInfoArgs>> clusterMountInfos) {
            $.clusterMountInfos = clusterMountInfos;
            return this;
        }

        public Builder clusterMountInfos(List<GetClusterClusterInfoSpecClusterMountInfoArgs> clusterMountInfos) {
            return clusterMountInfos(Output.of(clusterMountInfos));
        }

        public Builder clusterMountInfos(GetClusterClusterInfoSpecClusterMountInfoArgs... clusterMountInfos) {
            return clusterMountInfos(List.of(clusterMountInfos));
        }

        /**
         * @param clusterName The exact name of the cluster to search
         * 
         * @return builder
         * 
         */
        public Builder clusterName(@Nullable Output<String> clusterName) {
            $.clusterName = clusterName;
            return this;
        }

        /**
         * @param clusterName The exact name of the cluster to search
         * 
         * @return builder
         * 
         */
        public Builder clusterName(String clusterName) {
            return clusterName(Output.of(clusterName));
        }

        /**
         * @param customTags Additional tags for cluster resources.
         * 
         * @return builder
         * 
         */
        public Builder customTags(@Nullable Output<Map<String,String>> customTags) {
            $.customTags = customTags;
            return this;
        }

        /**
         * @param customTags Additional tags for cluster resources.
         * 
         * @return builder
         * 
         */
        public Builder customTags(Map<String,String> customTags) {
            return customTags(Output.of(customTags));
        }

        /**
         * @param dataSecurityMode Security features of the cluster. Unity Catalog requires `SINGLE_USER` or `USER_ISOLATION` mode. `LEGACY_PASSTHROUGH` for passthrough cluster and `LEGACY_TABLE_ACL` for Table ACL cluster. Default to `NONE`, i.e. no security feature enabled.
         * 
         * @return builder
         * 
         */
        public Builder dataSecurityMode(@Nullable Output<String> dataSecurityMode) {
            $.dataSecurityMode = dataSecurityMode;
            return this;
        }

        /**
         * @param dataSecurityMode Security features of the cluster. Unity Catalog requires `SINGLE_USER` or `USER_ISOLATION` mode. `LEGACY_PASSTHROUGH` for passthrough cluster and `LEGACY_TABLE_ACL` for Table ACL cluster. Default to `NONE`, i.e. no security feature enabled.
         * 
         * @return builder
         * 
         */
        public Builder dataSecurityMode(String dataSecurityMode) {
            return dataSecurityMode(Output.of(dataSecurityMode));
        }

        public Builder dockerImage(@Nullable Output<GetClusterClusterInfoSpecDockerImageArgs> dockerImage) {
            $.dockerImage = dockerImage;
            return this;
        }

        public Builder dockerImage(GetClusterClusterInfoSpecDockerImageArgs dockerImage) {
            return dockerImage(Output.of(dockerImage));
        }

        /**
         * @param driverInstancePoolId similar to `instance_pool_id`, but for driver node.
         * 
         * @return builder
         * 
         */
        public Builder driverInstancePoolId(Output<String> driverInstancePoolId) {
            $.driverInstancePoolId = driverInstancePoolId;
            return this;
        }

        /**
         * @param driverInstancePoolId similar to `instance_pool_id`, but for driver node.
         * 
         * @return builder
         * 
         */
        public Builder driverInstancePoolId(String driverInstancePoolId) {
            return driverInstancePoolId(Output.of(driverInstancePoolId));
        }

        /**
         * @param driverNodeTypeId The node type of the Spark driver.
         * 
         * @return builder
         * 
         */
        public Builder driverNodeTypeId(Output<String> driverNodeTypeId) {
            $.driverNodeTypeId = driverNodeTypeId;
            return this;
        }

        /**
         * @param driverNodeTypeId The node type of the Spark driver.
         * 
         * @return builder
         * 
         */
        public Builder driverNodeTypeId(String driverNodeTypeId) {
            return driverNodeTypeId(Output.of(driverNodeTypeId));
        }

        /**
         * @param enableElasticDisk Use autoscaling local storage.
         * 
         * @return builder
         * 
         */
        public Builder enableElasticDisk(Output<Boolean> enableElasticDisk) {
            $.enableElasticDisk = enableElasticDisk;
            return this;
        }

        /**
         * @param enableElasticDisk Use autoscaling local storage.
         * 
         * @return builder
         * 
         */
        public Builder enableElasticDisk(Boolean enableElasticDisk) {
            return enableElasticDisk(Output.of(enableElasticDisk));
        }

        /**
         * @param enableLocalDiskEncryption Enable local disk encryption.
         * 
         * @return builder
         * 
         */
        public Builder enableLocalDiskEncryption(Output<Boolean> enableLocalDiskEncryption) {
            $.enableLocalDiskEncryption = enableLocalDiskEncryption;
            return this;
        }

        /**
         * @param enableLocalDiskEncryption Enable local disk encryption.
         * 
         * @return builder
         * 
         */
        public Builder enableLocalDiskEncryption(Boolean enableLocalDiskEncryption) {
            return enableLocalDiskEncryption(Output.of(enableLocalDiskEncryption));
        }

        public Builder gcpAttributes(@Nullable Output<GetClusterClusterInfoSpecGcpAttributesArgs> gcpAttributes) {
            $.gcpAttributes = gcpAttributes;
            return this;
        }

        public Builder gcpAttributes(GetClusterClusterInfoSpecGcpAttributesArgs gcpAttributes) {
            return gcpAttributes(Output.of(gcpAttributes));
        }

        /**
         * @param idempotencyToken An optional token to guarantee the idempotency of cluster creation requests.
         * 
         * @return builder
         * 
         */
        public Builder idempotencyToken(@Nullable Output<String> idempotencyToken) {
            $.idempotencyToken = idempotencyToken;
            return this;
        }

        /**
         * @param idempotencyToken An optional token to guarantee the idempotency of cluster creation requests.
         * 
         * @return builder
         * 
         */
        public Builder idempotencyToken(String idempotencyToken) {
            return idempotencyToken(Output.of(idempotencyToken));
        }

        public Builder initScripts(@Nullable Output<List<GetClusterClusterInfoSpecInitScriptArgs>> initScripts) {
            $.initScripts = initScripts;
            return this;
        }

        public Builder initScripts(List<GetClusterClusterInfoSpecInitScriptArgs> initScripts) {
            return initScripts(Output.of(initScripts));
        }

        public Builder initScripts(GetClusterClusterInfoSpecInitScriptArgs... initScripts) {
            return initScripts(List.of(initScripts));
        }

        /**
         * @param instancePoolId The pool of idle instances the cluster is attached to.
         * 
         * @return builder
         * 
         */
        public Builder instancePoolId(@Nullable Output<String> instancePoolId) {
            $.instancePoolId = instancePoolId;
            return this;
        }

        /**
         * @param instancePoolId The pool of idle instances the cluster is attached to.
         * 
         * @return builder
         * 
         */
        public Builder instancePoolId(String instancePoolId) {
            return instancePoolId(Output.of(instancePoolId));
        }

        public Builder libraries(@Nullable Output<List<GetClusterClusterInfoSpecLibraryArgs>> libraries) {
            $.libraries = libraries;
            return this;
        }

        public Builder libraries(List<GetClusterClusterInfoSpecLibraryArgs> libraries) {
            return libraries(Output.of(libraries));
        }

        public Builder libraries(GetClusterClusterInfoSpecLibraryArgs... libraries) {
            return libraries(List.of(libraries));
        }

        /**
         * @param nodeTypeId Any supported databricks.getNodeType id.
         * 
         * @return builder
         * 
         */
        public Builder nodeTypeId(Output<String> nodeTypeId) {
            $.nodeTypeId = nodeTypeId;
            return this;
        }

        /**
         * @param nodeTypeId Any supported databricks.getNodeType id.
         * 
         * @return builder
         * 
         */
        public Builder nodeTypeId(String nodeTypeId) {
            return nodeTypeId(Output.of(nodeTypeId));
        }

        public Builder numWorkers(@Nullable Output<Integer> numWorkers) {
            $.numWorkers = numWorkers;
            return this;
        }

        public Builder numWorkers(Integer numWorkers) {
            return numWorkers(Output.of(numWorkers));
        }

        /**
         * @param policyId Identifier of Cluster Policy to validate cluster and preset certain defaults.
         * 
         * @return builder
         * 
         */
        public Builder policyId(@Nullable Output<String> policyId) {
            $.policyId = policyId;
            return this;
        }

        /**
         * @param policyId Identifier of Cluster Policy to validate cluster and preset certain defaults.
         * 
         * @return builder
         * 
         */
        public Builder policyId(String policyId) {
            return policyId(Output.of(policyId));
        }

        /**
         * @param runtimeEngine The type of runtime of the cluster
         * 
         * @return builder
         * 
         */
        public Builder runtimeEngine(@Nullable Output<String> runtimeEngine) {
            $.runtimeEngine = runtimeEngine;
            return this;
        }

        /**
         * @param runtimeEngine The type of runtime of the cluster
         * 
         * @return builder
         * 
         */
        public Builder runtimeEngine(String runtimeEngine) {
            return runtimeEngine(Output.of(runtimeEngine));
        }

        /**
         * @param singleUserName The optional user name of the user to assign to an interactive cluster. This field is required when using standard AAD Passthrough for Azure Data Lake Storage (ADLS) with a single-user cluster (i.e., not high-concurrency clusters).
         * 
         * @return builder
         * 
         */
        public Builder singleUserName(@Nullable Output<String> singleUserName) {
            $.singleUserName = singleUserName;
            return this;
        }

        /**
         * @param singleUserName The optional user name of the user to assign to an interactive cluster. This field is required when using standard AAD Passthrough for Azure Data Lake Storage (ADLS) with a single-user cluster (i.e., not high-concurrency clusters).
         * 
         * @return builder
         * 
         */
        public Builder singleUserName(String singleUserName) {
            return singleUserName(Output.of(singleUserName));
        }

        /**
         * @param sparkConf Map with key-value pairs to fine-tune Spark clusters.
         * 
         * @return builder
         * 
         */
        public Builder sparkConf(@Nullable Output<Map<String,String>> sparkConf) {
            $.sparkConf = sparkConf;
            return this;
        }

        /**
         * @param sparkConf Map with key-value pairs to fine-tune Spark clusters.
         * 
         * @return builder
         * 
         */
        public Builder sparkConf(Map<String,String> sparkConf) {
            return sparkConf(Output.of(sparkConf));
        }

        /**
         * @param sparkEnvVars Map with environment variable key-value pairs to fine-tune Spark clusters. Key-value pairs of the form (X,Y) are exported (i.e., X=&#39;Y&#39;) while launching the driver and workers.
         * 
         * @return builder
         * 
         */
        public Builder sparkEnvVars(@Nullable Output<Map<String,String>> sparkEnvVars) {
            $.sparkEnvVars = sparkEnvVars;
            return this;
        }

        /**
         * @param sparkEnvVars Map with environment variable key-value pairs to fine-tune Spark clusters. Key-value pairs of the form (X,Y) are exported (i.e., X=&#39;Y&#39;) while launching the driver and workers.
         * 
         * @return builder
         * 
         */
        public Builder sparkEnvVars(Map<String,String> sparkEnvVars) {
            return sparkEnvVars(Output.of(sparkEnvVars));
        }

        /**
         * @param sparkVersion [Runtime version](https://docs.databricks.com/runtime/index.html) of the cluster.
         * 
         * @return builder
         * 
         */
        public Builder sparkVersion(Output<String> sparkVersion) {
            $.sparkVersion = sparkVersion;
            return this;
        }

        /**
         * @param sparkVersion [Runtime version](https://docs.databricks.com/runtime/index.html) of the cluster.
         * 
         * @return builder
         * 
         */
        public Builder sparkVersion(String sparkVersion) {
            return sparkVersion(Output.of(sparkVersion));
        }

        /**
         * @param sshPublicKeys SSH public key contents that will be added to each Spark node in this cluster.
         * 
         * @return builder
         * 
         */
        public Builder sshPublicKeys(@Nullable Output<List<String>> sshPublicKeys) {
            $.sshPublicKeys = sshPublicKeys;
            return this;
        }

        /**
         * @param sshPublicKeys SSH public key contents that will be added to each Spark node in this cluster.
         * 
         * @return builder
         * 
         */
        public Builder sshPublicKeys(List<String> sshPublicKeys) {
            return sshPublicKeys(Output.of(sshPublicKeys));
        }

        /**
         * @param sshPublicKeys SSH public key contents that will be added to each Spark node in this cluster.
         * 
         * @return builder
         * 
         */
        public Builder sshPublicKeys(String... sshPublicKeys) {
            return sshPublicKeys(List.of(sshPublicKeys));
        }

        public Builder workloadType(@Nullable Output<GetClusterClusterInfoSpecWorkloadTypeArgs> workloadType) {
            $.workloadType = workloadType;
            return this;
        }

        public Builder workloadType(GetClusterClusterInfoSpecWorkloadTypeArgs workloadType) {
            return workloadType(Output.of(workloadType));
        }

        public GetClusterClusterInfoSpecArgs build() {
            if ($.clusterId == null) {
                throw new MissingRequiredPropertyException("GetClusterClusterInfoSpecArgs", "clusterId");
            }
            if ($.driverInstancePoolId == null) {
                throw new MissingRequiredPropertyException("GetClusterClusterInfoSpecArgs", "driverInstancePoolId");
            }
            if ($.driverNodeTypeId == null) {
                throw new MissingRequiredPropertyException("GetClusterClusterInfoSpecArgs", "driverNodeTypeId");
            }
            if ($.enableElasticDisk == null) {
                throw new MissingRequiredPropertyException("GetClusterClusterInfoSpecArgs", "enableElasticDisk");
            }
            if ($.enableLocalDiskEncryption == null) {
                throw new MissingRequiredPropertyException("GetClusterClusterInfoSpecArgs", "enableLocalDiskEncryption");
            }
            if ($.nodeTypeId == null) {
                throw new MissingRequiredPropertyException("GetClusterClusterInfoSpecArgs", "nodeTypeId");
            }
            if ($.sparkVersion == null) {
                throw new MissingRequiredPropertyException("GetClusterClusterInfoSpecArgs", "sparkVersion");
            }
            return $;
        }
    }

}
