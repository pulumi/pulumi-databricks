// *** WARNING: this file was generated by pulumi-language-java. ***
// *** Do not edit by hand unless you're certain you know what you are doing! ***

package com.pulumi.databricks.inputs;

import com.pulumi.core.Output;
import com.pulumi.core.annotations.Import;
import com.pulumi.databricks.inputs.PipelineClusterArgs;
import com.pulumi.databricks.inputs.PipelineDeploymentArgs;
import com.pulumi.databricks.inputs.PipelineEnvironmentArgs;
import com.pulumi.databricks.inputs.PipelineEventLogArgs;
import com.pulumi.databricks.inputs.PipelineFiltersArgs;
import com.pulumi.databricks.inputs.PipelineGatewayDefinitionArgs;
import com.pulumi.databricks.inputs.PipelineIngestionDefinitionArgs;
import com.pulumi.databricks.inputs.PipelineLatestUpdateArgs;
import com.pulumi.databricks.inputs.PipelineLibraryArgs;
import com.pulumi.databricks.inputs.PipelineNotificationArgs;
import com.pulumi.databricks.inputs.PipelineProviderConfigArgs;
import com.pulumi.databricks.inputs.PipelineRestartWindowArgs;
import com.pulumi.databricks.inputs.PipelineRunAsArgs;
import com.pulumi.databricks.inputs.PipelineTriggerArgs;
import java.lang.Boolean;
import java.lang.Integer;
import java.lang.String;
import java.util.List;
import java.util.Map;
import java.util.Objects;
import java.util.Optional;
import javax.annotation.Nullable;


public final class PipelineState extends com.pulumi.resources.ResourceArgs {

    public static final PipelineState Empty = new PipelineState();

    /**
     * Optional boolean flag. If false, deployment will fail if name conflicts with that of another pipeline. default is `false`.
     * 
     */
    @Import(name="allowDuplicateNames")
    private @Nullable Output<Boolean> allowDuplicateNames;

    /**
     * @return Optional boolean flag. If false, deployment will fail if name conflicts with that of another pipeline. default is `false`.
     * 
     */
    public Optional<Output<Boolean>> allowDuplicateNames() {
        return Optional.ofNullable(this.allowDuplicateNames);
    }

    /**
     * optional string specifying ID of the budget policy for this Lakeflow Declarative Pipeline.
     * 
     */
    @Import(name="budgetPolicyId")
    private @Nullable Output<String> budgetPolicyId;

    /**
     * @return optional string specifying ID of the budget policy for this Lakeflow Declarative Pipeline.
     * 
     */
    public Optional<Output<String>> budgetPolicyId() {
        return Optional.ofNullable(this.budgetPolicyId);
    }

    /**
     * The name of default catalog in Unity Catalog. *Change of this parameter forces recreation of the pipeline if you switch from `storage` to `catalog` or vice versa.  If pipeline was already created with `catalog` set, the value could be changed.* (Conflicts with `storage`).
     * 
     */
    @Import(name="catalog")
    private @Nullable Output<String> catalog;

    /**
     * @return The name of default catalog in Unity Catalog. *Change of this parameter forces recreation of the pipeline if you switch from `storage` to `catalog` or vice versa.  If pipeline was already created with `catalog` set, the value could be changed.* (Conflicts with `storage`).
     * 
     */
    public Optional<Output<String>> catalog() {
        return Optional.ofNullable(this.catalog);
    }

    @Import(name="cause")
    private @Nullable Output<String> cause;

    public Optional<Output<String>> cause() {
        return Optional.ofNullable(this.cause);
    }

    /**
     * optional name of the release channel for Spark version used by Lakeflow Declarative Pipeline.  Supported values are: `CURRENT` (default) and `PREVIEW`.
     * 
     */
    @Import(name="channel")
    private @Nullable Output<String> channel;

    /**
     * @return optional name of the release channel for Spark version used by Lakeflow Declarative Pipeline.  Supported values are: `CURRENT` (default) and `PREVIEW`.
     * 
     */
    public Optional<Output<String>> channel() {
        return Optional.ofNullable(this.channel);
    }

    @Import(name="clusterId")
    private @Nullable Output<String> clusterId;

    public Optional<Output<String>> clusterId() {
        return Optional.ofNullable(this.clusterId);
    }

    /**
     * blocks - Clusters to run the pipeline. If none is specified, pipelines will automatically select a default cluster configuration for the pipeline. *Please note that Lakeflow Declarative Pipeline clusters are supporting only subset of attributes as described in [documentation](https://docs.databricks.com/api/workspace/pipelines/create#clusters).*  Also, note that `autoscale` block is extended with the `mode` parameter that controls the autoscaling algorithm (possible values are `ENHANCED` for new, enhanced autoscaling algorithm, or `LEGACY` for old algorithm).
     * 
     */
    @Import(name="clusters")
    private @Nullable Output<List<PipelineClusterArgs>> clusters;

    /**
     * @return blocks - Clusters to run the pipeline. If none is specified, pipelines will automatically select a default cluster configuration for the pipeline. *Please note that Lakeflow Declarative Pipeline clusters are supporting only subset of attributes as described in [documentation](https://docs.databricks.com/api/workspace/pipelines/create#clusters).*  Also, note that `autoscale` block is extended with the `mode` parameter that controls the autoscaling algorithm (possible values are `ENHANCED` for new, enhanced autoscaling algorithm, or `LEGACY` for old algorithm).
     * 
     */
    public Optional<Output<List<PipelineClusterArgs>>> clusters() {
        return Optional.ofNullable(this.clusters);
    }

    /**
     * An optional list of values to apply to the entire pipeline. Elements must be formatted as key:value pairs.
     * 
     */
    @Import(name="configuration")
    private @Nullable Output<Map<String,String>> configuration;

    /**
     * @return An optional list of values to apply to the entire pipeline. Elements must be formatted as key:value pairs.
     * 
     */
    public Optional<Output<Map<String,String>>> configuration() {
        return Optional.ofNullable(this.configuration);
    }

    /**
     * A flag indicating whether to run the pipeline continuously. The default value is `false`.
     * 
     */
    @Import(name="continuous")
    private @Nullable Output<Boolean> continuous;

    /**
     * @return A flag indicating whether to run the pipeline continuously. The default value is `false`.
     * 
     */
    public Optional<Output<Boolean>> continuous() {
        return Optional.ofNullable(this.continuous);
    }

    @Import(name="creatorUserName")
    private @Nullable Output<String> creatorUserName;

    public Optional<Output<String>> creatorUserName() {
        return Optional.ofNullable(this.creatorUserName);
    }

    /**
     * Deployment type of this pipeline. Supports following attributes:
     * 
     */
    @Import(name="deployment")
    private @Nullable Output<PipelineDeploymentArgs> deployment;

    /**
     * @return Deployment type of this pipeline. Supports following attributes:
     * 
     */
    public Optional<Output<PipelineDeploymentArgs>> deployment() {
        return Optional.ofNullable(this.deployment);
    }

    /**
     * A flag indicating whether to run the pipeline in development mode. The default value is `false`.
     * 
     */
    @Import(name="development")
    private @Nullable Output<Boolean> development;

    /**
     * @return A flag indicating whether to run the pipeline in development mode. The default value is `false`.
     * 
     */
    public Optional<Output<Boolean>> development() {
        return Optional.ofNullable(this.development);
    }

    /**
     * optional name of the [product edition](https://docs.databricks.com/aws/en/dlt/configure-pipeline#choose-a-product-edition). Supported values are: `CORE`, `PRO`, `ADVANCED` (default).  Not required when `serverless` is set to `true`.
     * 
     */
    @Import(name="edition")
    private @Nullable Output<String> edition;

    /**
     * @return optional name of the [product edition](https://docs.databricks.com/aws/en/dlt/configure-pipeline#choose-a-product-edition). Supported values are: `CORE`, `PRO`, `ADVANCED` (default).  Not required when `serverless` is set to `true`.
     * 
     */
    public Optional<Output<String>> edition() {
        return Optional.ofNullable(this.edition);
    }

    @Import(name="environment")
    private @Nullable Output<PipelineEnvironmentArgs> environment;

    public Optional<Output<PipelineEnvironmentArgs>> environment() {
        return Optional.ofNullable(this.environment);
    }

    /**
     * an optional block specifying a table where LDP Event Log will be stored.  Consists of the following fields:
     * 
     */
    @Import(name="eventLog")
    private @Nullable Output<PipelineEventLogArgs> eventLog;

    /**
     * @return an optional block specifying a table where LDP Event Log will be stored.  Consists of the following fields:
     * 
     */
    public Optional<Output<PipelineEventLogArgs>> eventLog() {
        return Optional.ofNullable(this.eventLog);
    }

    @Import(name="expectedLastModified")
    private @Nullable Output<Integer> expectedLastModified;

    public Optional<Output<Integer>> expectedLastModified() {
        return Optional.ofNullable(this.expectedLastModified);
    }

    /**
     * Filters on which Pipeline packages to include in the deployed graph.  This block consists of following attributes:
     * 
     */
    @Import(name="filters")
    private @Nullable Output<PipelineFiltersArgs> filters;

    /**
     * @return Filters on which Pipeline packages to include in the deployed graph.  This block consists of following attributes:
     * 
     */
    public Optional<Output<PipelineFiltersArgs>> filters() {
        return Optional.ofNullable(this.filters);
    }

    /**
     * The definition of a gateway pipeline to support CDC. Consists of following attributes:
     * 
     */
    @Import(name="gatewayDefinition")
    private @Nullable Output<PipelineGatewayDefinitionArgs> gatewayDefinition;

    /**
     * @return The definition of a gateway pipeline to support CDC. Consists of following attributes:
     * 
     */
    public Optional<Output<PipelineGatewayDefinitionArgs>> gatewayDefinition() {
        return Optional.ofNullable(this.gatewayDefinition);
    }

    @Import(name="health")
    private @Nullable Output<String> health;

    public Optional<Output<String>> health() {
        return Optional.ofNullable(this.health);
    }

    @Import(name="ingestionDefinition")
    private @Nullable Output<PipelineIngestionDefinitionArgs> ingestionDefinition;

    public Optional<Output<PipelineIngestionDefinitionArgs>> ingestionDefinition() {
        return Optional.ofNullable(this.ingestionDefinition);
    }

    @Import(name="lastModified")
    private @Nullable Output<Integer> lastModified;

    public Optional<Output<Integer>> lastModified() {
        return Optional.ofNullable(this.lastModified);
    }

    @Import(name="latestUpdates")
    private @Nullable Output<List<PipelineLatestUpdateArgs>> latestUpdates;

    public Optional<Output<List<PipelineLatestUpdateArgs>>> latestUpdates() {
        return Optional.ofNullable(this.latestUpdates);
    }

    /**
     * blocks - Specifies pipeline code.
     * 
     */
    @Import(name="libraries")
    private @Nullable Output<List<PipelineLibraryArgs>> libraries;

    /**
     * @return blocks - Specifies pipeline code.
     * 
     */
    public Optional<Output<List<PipelineLibraryArgs>>> libraries() {
        return Optional.ofNullable(this.libraries);
    }

    /**
     * A user-friendly name for this pipeline. The name can be used to identify pipeline jobs in the UI.
     * 
     */
    @Import(name="name")
    private @Nullable Output<String> name;

    /**
     * @return A user-friendly name for this pipeline. The name can be used to identify pipeline jobs in the UI.
     * 
     */
    public Optional<Output<String>> name() {
        return Optional.ofNullable(this.name);
    }

    @Import(name="notifications")
    private @Nullable Output<List<PipelineNotificationArgs>> notifications;

    public Optional<Output<List<PipelineNotificationArgs>>> notifications() {
        return Optional.ofNullable(this.notifications);
    }

    /**
     * A flag indicating whether to use Photon engine. The default value is `false`.
     * 
     */
    @Import(name="photon")
    private @Nullable Output<Boolean> photon;

    /**
     * @return A flag indicating whether to use Photon engine. The default value is `false`.
     * 
     */
    public Optional<Output<Boolean>> photon() {
        return Optional.ofNullable(this.photon);
    }

    @Import(name="providerConfig")
    private @Nullable Output<PipelineProviderConfigArgs> providerConfig;

    public Optional<Output<PipelineProviderConfigArgs>> providerConfig() {
        return Optional.ofNullable(this.providerConfig);
    }

    @Import(name="restartWindow")
    private @Nullable Output<PipelineRestartWindowArgs> restartWindow;

    public Optional<Output<PipelineRestartWindowArgs>> restartWindow() {
        return Optional.ofNullable(this.restartWindow);
    }

    /**
     * An optional string specifying the root path for this pipeline. This is used as the root directory when editing the pipeline in the Databricks user interface and it is added to `sys.path` when executing Python sources during pipeline execution.
     * 
     */
    @Import(name="rootPath")
    private @Nullable Output<String> rootPath;

    /**
     * @return An optional string specifying the root path for this pipeline. This is used as the root directory when editing the pipeline in the Databricks user interface and it is added to `sys.path` when executing Python sources during pipeline execution.
     * 
     */
    public Optional<Output<String>> rootPath() {
        return Optional.ofNullable(this.rootPath);
    }

    /**
     * The user or the service principal the pipeline runs as. See runAs Configuration Block below.
     * 
     */
    @Import(name="runAs")
    private @Nullable Output<PipelineRunAsArgs> runAs;

    /**
     * @return The user or the service principal the pipeline runs as. See runAs Configuration Block below.
     * 
     */
    public Optional<Output<PipelineRunAsArgs>> runAs() {
        return Optional.ofNullable(this.runAs);
    }

    @Import(name="runAsUserName")
    private @Nullable Output<String> runAsUserName;

    public Optional<Output<String>> runAsUserName() {
        return Optional.ofNullable(this.runAsUserName);
    }

    /**
     * The default schema (database) where tables are read from or published to. The presence of this attribute implies that the pipeline is in direct publishing mode.
     * 
     */
    @Import(name="schema")
    private @Nullable Output<String> schema;

    /**
     * @return The default schema (database) where tables are read from or published to. The presence of this attribute implies that the pipeline is in direct publishing mode.
     * 
     */
    public Optional<Output<String>> schema() {
        return Optional.ofNullable(this.schema);
    }

    /**
     * An optional flag indicating if serverless compute should be used for this Lakeflow Declarative Pipeline.  Requires `catalog` to be set, as it could be used only with Unity Catalog.
     * 
     */
    @Import(name="serverless")
    private @Nullable Output<Boolean> serverless;

    /**
     * @return An optional flag indicating if serverless compute should be used for this Lakeflow Declarative Pipeline.  Requires `catalog` to be set, as it could be used only with Unity Catalog.
     * 
     */
    public Optional<Output<Boolean>> serverless() {
        return Optional.ofNullable(this.serverless);
    }

    @Import(name="state")
    private @Nullable Output<String> state;

    public Optional<Output<String>> state() {
        return Optional.ofNullable(this.state);
    }

    /**
     * A location on cloud storage where output data and metadata required for pipeline execution are stored. By default, tables are stored in a subdirectory of this location. *Change of this parameter forces recreation of the pipeline.* (Conflicts with `catalog`).
     * 
     */
    @Import(name="storage")
    private @Nullable Output<String> storage;

    /**
     * @return A location on cloud storage where output data and metadata required for pipeline execution are stored. By default, tables are stored in a subdirectory of this location. *Change of this parameter forces recreation of the pipeline.* (Conflicts with `catalog`).
     * 
     */
    public Optional<Output<String>> storage() {
        return Optional.ofNullable(this.storage);
    }

    /**
     * A map of tags associated with the pipeline. These are forwarded to the cluster as cluster tags, and are therefore subject to the same limitations. A maximum of 25 tags can be added to the pipeline.
     * 
     */
    @Import(name="tags")
    private @Nullable Output<Map<String,String>> tags;

    /**
     * @return A map of tags associated with the pipeline. These are forwarded to the cluster as cluster tags, and are therefore subject to the same limitations. A maximum of 25 tags can be added to the pipeline.
     * 
     */
    public Optional<Output<Map<String,String>>> tags() {
        return Optional.ofNullable(this.tags);
    }

    /**
     * The name of a database (in either the Hive metastore or in a UC catalog) for persisting pipeline output data. Configuring the target setting allows you to view and query the pipeline output data from the Databricks UI.
     * 
     */
    @Import(name="target")
    private @Nullable Output<String> target;

    /**
     * @return The name of a database (in either the Hive metastore or in a UC catalog) for persisting pipeline output data. Configuring the target setting allows you to view and query the pipeline output data from the Databricks UI.
     * 
     */
    public Optional<Output<String>> target() {
        return Optional.ofNullable(this.target);
    }

    @Import(name="trigger")
    private @Nullable Output<PipelineTriggerArgs> trigger;

    public Optional<Output<PipelineTriggerArgs>> trigger() {
        return Optional.ofNullable(this.trigger);
    }

    /**
     * URL of the Lakeflow Declarative Pipeline on the given workspace.
     * 
     */
    @Import(name="url")
    private @Nullable Output<String> url;

    /**
     * @return URL of the Lakeflow Declarative Pipeline on the given workspace.
     * 
     */
    public Optional<Output<String>> url() {
        return Optional.ofNullable(this.url);
    }

    @Import(name="usagePolicyId")
    private @Nullable Output<String> usagePolicyId;

    public Optional<Output<String>> usagePolicyId() {
        return Optional.ofNullable(this.usagePolicyId);
    }

    private PipelineState() {}

    private PipelineState(PipelineState $) {
        this.allowDuplicateNames = $.allowDuplicateNames;
        this.budgetPolicyId = $.budgetPolicyId;
        this.catalog = $.catalog;
        this.cause = $.cause;
        this.channel = $.channel;
        this.clusterId = $.clusterId;
        this.clusters = $.clusters;
        this.configuration = $.configuration;
        this.continuous = $.continuous;
        this.creatorUserName = $.creatorUserName;
        this.deployment = $.deployment;
        this.development = $.development;
        this.edition = $.edition;
        this.environment = $.environment;
        this.eventLog = $.eventLog;
        this.expectedLastModified = $.expectedLastModified;
        this.filters = $.filters;
        this.gatewayDefinition = $.gatewayDefinition;
        this.health = $.health;
        this.ingestionDefinition = $.ingestionDefinition;
        this.lastModified = $.lastModified;
        this.latestUpdates = $.latestUpdates;
        this.libraries = $.libraries;
        this.name = $.name;
        this.notifications = $.notifications;
        this.photon = $.photon;
        this.providerConfig = $.providerConfig;
        this.restartWindow = $.restartWindow;
        this.rootPath = $.rootPath;
        this.runAs = $.runAs;
        this.runAsUserName = $.runAsUserName;
        this.schema = $.schema;
        this.serverless = $.serverless;
        this.state = $.state;
        this.storage = $.storage;
        this.tags = $.tags;
        this.target = $.target;
        this.trigger = $.trigger;
        this.url = $.url;
        this.usagePolicyId = $.usagePolicyId;
    }

    public static Builder builder() {
        return new Builder();
    }
    public static Builder builder(PipelineState defaults) {
        return new Builder(defaults);
    }

    public static final class Builder {
        private PipelineState $;

        public Builder() {
            $ = new PipelineState();
        }

        public Builder(PipelineState defaults) {
            $ = new PipelineState(Objects.requireNonNull(defaults));
        }

        /**
         * @param allowDuplicateNames Optional boolean flag. If false, deployment will fail if name conflicts with that of another pipeline. default is `false`.
         * 
         * @return builder
         * 
         */
        public Builder allowDuplicateNames(@Nullable Output<Boolean> allowDuplicateNames) {
            $.allowDuplicateNames = allowDuplicateNames;
            return this;
        }

        /**
         * @param allowDuplicateNames Optional boolean flag. If false, deployment will fail if name conflicts with that of another pipeline. default is `false`.
         * 
         * @return builder
         * 
         */
        public Builder allowDuplicateNames(Boolean allowDuplicateNames) {
            return allowDuplicateNames(Output.of(allowDuplicateNames));
        }

        /**
         * @param budgetPolicyId optional string specifying ID of the budget policy for this Lakeflow Declarative Pipeline.
         * 
         * @return builder
         * 
         */
        public Builder budgetPolicyId(@Nullable Output<String> budgetPolicyId) {
            $.budgetPolicyId = budgetPolicyId;
            return this;
        }

        /**
         * @param budgetPolicyId optional string specifying ID of the budget policy for this Lakeflow Declarative Pipeline.
         * 
         * @return builder
         * 
         */
        public Builder budgetPolicyId(String budgetPolicyId) {
            return budgetPolicyId(Output.of(budgetPolicyId));
        }

        /**
         * @param catalog The name of default catalog in Unity Catalog. *Change of this parameter forces recreation of the pipeline if you switch from `storage` to `catalog` or vice versa.  If pipeline was already created with `catalog` set, the value could be changed.* (Conflicts with `storage`).
         * 
         * @return builder
         * 
         */
        public Builder catalog(@Nullable Output<String> catalog) {
            $.catalog = catalog;
            return this;
        }

        /**
         * @param catalog The name of default catalog in Unity Catalog. *Change of this parameter forces recreation of the pipeline if you switch from `storage` to `catalog` or vice versa.  If pipeline was already created with `catalog` set, the value could be changed.* (Conflicts with `storage`).
         * 
         * @return builder
         * 
         */
        public Builder catalog(String catalog) {
            return catalog(Output.of(catalog));
        }

        public Builder cause(@Nullable Output<String> cause) {
            $.cause = cause;
            return this;
        }

        public Builder cause(String cause) {
            return cause(Output.of(cause));
        }

        /**
         * @param channel optional name of the release channel for Spark version used by Lakeflow Declarative Pipeline.  Supported values are: `CURRENT` (default) and `PREVIEW`.
         * 
         * @return builder
         * 
         */
        public Builder channel(@Nullable Output<String> channel) {
            $.channel = channel;
            return this;
        }

        /**
         * @param channel optional name of the release channel for Spark version used by Lakeflow Declarative Pipeline.  Supported values are: `CURRENT` (default) and `PREVIEW`.
         * 
         * @return builder
         * 
         */
        public Builder channel(String channel) {
            return channel(Output.of(channel));
        }

        public Builder clusterId(@Nullable Output<String> clusterId) {
            $.clusterId = clusterId;
            return this;
        }

        public Builder clusterId(String clusterId) {
            return clusterId(Output.of(clusterId));
        }

        /**
         * @param clusters blocks - Clusters to run the pipeline. If none is specified, pipelines will automatically select a default cluster configuration for the pipeline. *Please note that Lakeflow Declarative Pipeline clusters are supporting only subset of attributes as described in [documentation](https://docs.databricks.com/api/workspace/pipelines/create#clusters).*  Also, note that `autoscale` block is extended with the `mode` parameter that controls the autoscaling algorithm (possible values are `ENHANCED` for new, enhanced autoscaling algorithm, or `LEGACY` for old algorithm).
         * 
         * @return builder
         * 
         */
        public Builder clusters(@Nullable Output<List<PipelineClusterArgs>> clusters) {
            $.clusters = clusters;
            return this;
        }

        /**
         * @param clusters blocks - Clusters to run the pipeline. If none is specified, pipelines will automatically select a default cluster configuration for the pipeline. *Please note that Lakeflow Declarative Pipeline clusters are supporting only subset of attributes as described in [documentation](https://docs.databricks.com/api/workspace/pipelines/create#clusters).*  Also, note that `autoscale` block is extended with the `mode` parameter that controls the autoscaling algorithm (possible values are `ENHANCED` for new, enhanced autoscaling algorithm, or `LEGACY` for old algorithm).
         * 
         * @return builder
         * 
         */
        public Builder clusters(List<PipelineClusterArgs> clusters) {
            return clusters(Output.of(clusters));
        }

        /**
         * @param clusters blocks - Clusters to run the pipeline. If none is specified, pipelines will automatically select a default cluster configuration for the pipeline. *Please note that Lakeflow Declarative Pipeline clusters are supporting only subset of attributes as described in [documentation](https://docs.databricks.com/api/workspace/pipelines/create#clusters).*  Also, note that `autoscale` block is extended with the `mode` parameter that controls the autoscaling algorithm (possible values are `ENHANCED` for new, enhanced autoscaling algorithm, or `LEGACY` for old algorithm).
         * 
         * @return builder
         * 
         */
        public Builder clusters(PipelineClusterArgs... clusters) {
            return clusters(List.of(clusters));
        }

        /**
         * @param configuration An optional list of values to apply to the entire pipeline. Elements must be formatted as key:value pairs.
         * 
         * @return builder
         * 
         */
        public Builder configuration(@Nullable Output<Map<String,String>> configuration) {
            $.configuration = configuration;
            return this;
        }

        /**
         * @param configuration An optional list of values to apply to the entire pipeline. Elements must be formatted as key:value pairs.
         * 
         * @return builder
         * 
         */
        public Builder configuration(Map<String,String> configuration) {
            return configuration(Output.of(configuration));
        }

        /**
         * @param continuous A flag indicating whether to run the pipeline continuously. The default value is `false`.
         * 
         * @return builder
         * 
         */
        public Builder continuous(@Nullable Output<Boolean> continuous) {
            $.continuous = continuous;
            return this;
        }

        /**
         * @param continuous A flag indicating whether to run the pipeline continuously. The default value is `false`.
         * 
         * @return builder
         * 
         */
        public Builder continuous(Boolean continuous) {
            return continuous(Output.of(continuous));
        }

        public Builder creatorUserName(@Nullable Output<String> creatorUserName) {
            $.creatorUserName = creatorUserName;
            return this;
        }

        public Builder creatorUserName(String creatorUserName) {
            return creatorUserName(Output.of(creatorUserName));
        }

        /**
         * @param deployment Deployment type of this pipeline. Supports following attributes:
         * 
         * @return builder
         * 
         */
        public Builder deployment(@Nullable Output<PipelineDeploymentArgs> deployment) {
            $.deployment = deployment;
            return this;
        }

        /**
         * @param deployment Deployment type of this pipeline. Supports following attributes:
         * 
         * @return builder
         * 
         */
        public Builder deployment(PipelineDeploymentArgs deployment) {
            return deployment(Output.of(deployment));
        }

        /**
         * @param development A flag indicating whether to run the pipeline in development mode. The default value is `false`.
         * 
         * @return builder
         * 
         */
        public Builder development(@Nullable Output<Boolean> development) {
            $.development = development;
            return this;
        }

        /**
         * @param development A flag indicating whether to run the pipeline in development mode. The default value is `false`.
         * 
         * @return builder
         * 
         */
        public Builder development(Boolean development) {
            return development(Output.of(development));
        }

        /**
         * @param edition optional name of the [product edition](https://docs.databricks.com/aws/en/dlt/configure-pipeline#choose-a-product-edition). Supported values are: `CORE`, `PRO`, `ADVANCED` (default).  Not required when `serverless` is set to `true`.
         * 
         * @return builder
         * 
         */
        public Builder edition(@Nullable Output<String> edition) {
            $.edition = edition;
            return this;
        }

        /**
         * @param edition optional name of the [product edition](https://docs.databricks.com/aws/en/dlt/configure-pipeline#choose-a-product-edition). Supported values are: `CORE`, `PRO`, `ADVANCED` (default).  Not required when `serverless` is set to `true`.
         * 
         * @return builder
         * 
         */
        public Builder edition(String edition) {
            return edition(Output.of(edition));
        }

        public Builder environment(@Nullable Output<PipelineEnvironmentArgs> environment) {
            $.environment = environment;
            return this;
        }

        public Builder environment(PipelineEnvironmentArgs environment) {
            return environment(Output.of(environment));
        }

        /**
         * @param eventLog an optional block specifying a table where LDP Event Log will be stored.  Consists of the following fields:
         * 
         * @return builder
         * 
         */
        public Builder eventLog(@Nullable Output<PipelineEventLogArgs> eventLog) {
            $.eventLog = eventLog;
            return this;
        }

        /**
         * @param eventLog an optional block specifying a table where LDP Event Log will be stored.  Consists of the following fields:
         * 
         * @return builder
         * 
         */
        public Builder eventLog(PipelineEventLogArgs eventLog) {
            return eventLog(Output.of(eventLog));
        }

        public Builder expectedLastModified(@Nullable Output<Integer> expectedLastModified) {
            $.expectedLastModified = expectedLastModified;
            return this;
        }

        public Builder expectedLastModified(Integer expectedLastModified) {
            return expectedLastModified(Output.of(expectedLastModified));
        }

        /**
         * @param filters Filters on which Pipeline packages to include in the deployed graph.  This block consists of following attributes:
         * 
         * @return builder
         * 
         */
        public Builder filters(@Nullable Output<PipelineFiltersArgs> filters) {
            $.filters = filters;
            return this;
        }

        /**
         * @param filters Filters on which Pipeline packages to include in the deployed graph.  This block consists of following attributes:
         * 
         * @return builder
         * 
         */
        public Builder filters(PipelineFiltersArgs filters) {
            return filters(Output.of(filters));
        }

        /**
         * @param gatewayDefinition The definition of a gateway pipeline to support CDC. Consists of following attributes:
         * 
         * @return builder
         * 
         */
        public Builder gatewayDefinition(@Nullable Output<PipelineGatewayDefinitionArgs> gatewayDefinition) {
            $.gatewayDefinition = gatewayDefinition;
            return this;
        }

        /**
         * @param gatewayDefinition The definition of a gateway pipeline to support CDC. Consists of following attributes:
         * 
         * @return builder
         * 
         */
        public Builder gatewayDefinition(PipelineGatewayDefinitionArgs gatewayDefinition) {
            return gatewayDefinition(Output.of(gatewayDefinition));
        }

        public Builder health(@Nullable Output<String> health) {
            $.health = health;
            return this;
        }

        public Builder health(String health) {
            return health(Output.of(health));
        }

        public Builder ingestionDefinition(@Nullable Output<PipelineIngestionDefinitionArgs> ingestionDefinition) {
            $.ingestionDefinition = ingestionDefinition;
            return this;
        }

        public Builder ingestionDefinition(PipelineIngestionDefinitionArgs ingestionDefinition) {
            return ingestionDefinition(Output.of(ingestionDefinition));
        }

        public Builder lastModified(@Nullable Output<Integer> lastModified) {
            $.lastModified = lastModified;
            return this;
        }

        public Builder lastModified(Integer lastModified) {
            return lastModified(Output.of(lastModified));
        }

        public Builder latestUpdates(@Nullable Output<List<PipelineLatestUpdateArgs>> latestUpdates) {
            $.latestUpdates = latestUpdates;
            return this;
        }

        public Builder latestUpdates(List<PipelineLatestUpdateArgs> latestUpdates) {
            return latestUpdates(Output.of(latestUpdates));
        }

        public Builder latestUpdates(PipelineLatestUpdateArgs... latestUpdates) {
            return latestUpdates(List.of(latestUpdates));
        }

        /**
         * @param libraries blocks - Specifies pipeline code.
         * 
         * @return builder
         * 
         */
        public Builder libraries(@Nullable Output<List<PipelineLibraryArgs>> libraries) {
            $.libraries = libraries;
            return this;
        }

        /**
         * @param libraries blocks - Specifies pipeline code.
         * 
         * @return builder
         * 
         */
        public Builder libraries(List<PipelineLibraryArgs> libraries) {
            return libraries(Output.of(libraries));
        }

        /**
         * @param libraries blocks - Specifies pipeline code.
         * 
         * @return builder
         * 
         */
        public Builder libraries(PipelineLibraryArgs... libraries) {
            return libraries(List.of(libraries));
        }

        /**
         * @param name A user-friendly name for this pipeline. The name can be used to identify pipeline jobs in the UI.
         * 
         * @return builder
         * 
         */
        public Builder name(@Nullable Output<String> name) {
            $.name = name;
            return this;
        }

        /**
         * @param name A user-friendly name for this pipeline. The name can be used to identify pipeline jobs in the UI.
         * 
         * @return builder
         * 
         */
        public Builder name(String name) {
            return name(Output.of(name));
        }

        public Builder notifications(@Nullable Output<List<PipelineNotificationArgs>> notifications) {
            $.notifications = notifications;
            return this;
        }

        public Builder notifications(List<PipelineNotificationArgs> notifications) {
            return notifications(Output.of(notifications));
        }

        public Builder notifications(PipelineNotificationArgs... notifications) {
            return notifications(List.of(notifications));
        }

        /**
         * @param photon A flag indicating whether to use Photon engine. The default value is `false`.
         * 
         * @return builder
         * 
         */
        public Builder photon(@Nullable Output<Boolean> photon) {
            $.photon = photon;
            return this;
        }

        /**
         * @param photon A flag indicating whether to use Photon engine. The default value is `false`.
         * 
         * @return builder
         * 
         */
        public Builder photon(Boolean photon) {
            return photon(Output.of(photon));
        }

        public Builder providerConfig(@Nullable Output<PipelineProviderConfigArgs> providerConfig) {
            $.providerConfig = providerConfig;
            return this;
        }

        public Builder providerConfig(PipelineProviderConfigArgs providerConfig) {
            return providerConfig(Output.of(providerConfig));
        }

        public Builder restartWindow(@Nullable Output<PipelineRestartWindowArgs> restartWindow) {
            $.restartWindow = restartWindow;
            return this;
        }

        public Builder restartWindow(PipelineRestartWindowArgs restartWindow) {
            return restartWindow(Output.of(restartWindow));
        }

        /**
         * @param rootPath An optional string specifying the root path for this pipeline. This is used as the root directory when editing the pipeline in the Databricks user interface and it is added to `sys.path` when executing Python sources during pipeline execution.
         * 
         * @return builder
         * 
         */
        public Builder rootPath(@Nullable Output<String> rootPath) {
            $.rootPath = rootPath;
            return this;
        }

        /**
         * @param rootPath An optional string specifying the root path for this pipeline. This is used as the root directory when editing the pipeline in the Databricks user interface and it is added to `sys.path` when executing Python sources during pipeline execution.
         * 
         * @return builder
         * 
         */
        public Builder rootPath(String rootPath) {
            return rootPath(Output.of(rootPath));
        }

        /**
         * @param runAs The user or the service principal the pipeline runs as. See runAs Configuration Block below.
         * 
         * @return builder
         * 
         */
        public Builder runAs(@Nullable Output<PipelineRunAsArgs> runAs) {
            $.runAs = runAs;
            return this;
        }

        /**
         * @param runAs The user or the service principal the pipeline runs as. See runAs Configuration Block below.
         * 
         * @return builder
         * 
         */
        public Builder runAs(PipelineRunAsArgs runAs) {
            return runAs(Output.of(runAs));
        }

        public Builder runAsUserName(@Nullable Output<String> runAsUserName) {
            $.runAsUserName = runAsUserName;
            return this;
        }

        public Builder runAsUserName(String runAsUserName) {
            return runAsUserName(Output.of(runAsUserName));
        }

        /**
         * @param schema The default schema (database) where tables are read from or published to. The presence of this attribute implies that the pipeline is in direct publishing mode.
         * 
         * @return builder
         * 
         */
        public Builder schema(@Nullable Output<String> schema) {
            $.schema = schema;
            return this;
        }

        /**
         * @param schema The default schema (database) where tables are read from or published to. The presence of this attribute implies that the pipeline is in direct publishing mode.
         * 
         * @return builder
         * 
         */
        public Builder schema(String schema) {
            return schema(Output.of(schema));
        }

        /**
         * @param serverless An optional flag indicating if serverless compute should be used for this Lakeflow Declarative Pipeline.  Requires `catalog` to be set, as it could be used only with Unity Catalog.
         * 
         * @return builder
         * 
         */
        public Builder serverless(@Nullable Output<Boolean> serverless) {
            $.serverless = serverless;
            return this;
        }

        /**
         * @param serverless An optional flag indicating if serverless compute should be used for this Lakeflow Declarative Pipeline.  Requires `catalog` to be set, as it could be used only with Unity Catalog.
         * 
         * @return builder
         * 
         */
        public Builder serverless(Boolean serverless) {
            return serverless(Output.of(serverless));
        }

        public Builder state(@Nullable Output<String> state) {
            $.state = state;
            return this;
        }

        public Builder state(String state) {
            return state(Output.of(state));
        }

        /**
         * @param storage A location on cloud storage where output data and metadata required for pipeline execution are stored. By default, tables are stored in a subdirectory of this location. *Change of this parameter forces recreation of the pipeline.* (Conflicts with `catalog`).
         * 
         * @return builder
         * 
         */
        public Builder storage(@Nullable Output<String> storage) {
            $.storage = storage;
            return this;
        }

        /**
         * @param storage A location on cloud storage where output data and metadata required for pipeline execution are stored. By default, tables are stored in a subdirectory of this location. *Change of this parameter forces recreation of the pipeline.* (Conflicts with `catalog`).
         * 
         * @return builder
         * 
         */
        public Builder storage(String storage) {
            return storage(Output.of(storage));
        }

        /**
         * @param tags A map of tags associated with the pipeline. These are forwarded to the cluster as cluster tags, and are therefore subject to the same limitations. A maximum of 25 tags can be added to the pipeline.
         * 
         * @return builder
         * 
         */
        public Builder tags(@Nullable Output<Map<String,String>> tags) {
            $.tags = tags;
            return this;
        }

        /**
         * @param tags A map of tags associated with the pipeline. These are forwarded to the cluster as cluster tags, and are therefore subject to the same limitations. A maximum of 25 tags can be added to the pipeline.
         * 
         * @return builder
         * 
         */
        public Builder tags(Map<String,String> tags) {
            return tags(Output.of(tags));
        }

        /**
         * @param target The name of a database (in either the Hive metastore or in a UC catalog) for persisting pipeline output data. Configuring the target setting allows you to view and query the pipeline output data from the Databricks UI.
         * 
         * @return builder
         * 
         */
        public Builder target(@Nullable Output<String> target) {
            $.target = target;
            return this;
        }

        /**
         * @param target The name of a database (in either the Hive metastore or in a UC catalog) for persisting pipeline output data. Configuring the target setting allows you to view and query the pipeline output data from the Databricks UI.
         * 
         * @return builder
         * 
         */
        public Builder target(String target) {
            return target(Output.of(target));
        }

        public Builder trigger(@Nullable Output<PipelineTriggerArgs> trigger) {
            $.trigger = trigger;
            return this;
        }

        public Builder trigger(PipelineTriggerArgs trigger) {
            return trigger(Output.of(trigger));
        }

        /**
         * @param url URL of the Lakeflow Declarative Pipeline on the given workspace.
         * 
         * @return builder
         * 
         */
        public Builder url(@Nullable Output<String> url) {
            $.url = url;
            return this;
        }

        /**
         * @param url URL of the Lakeflow Declarative Pipeline on the given workspace.
         * 
         * @return builder
         * 
         */
        public Builder url(String url) {
            return url(Output.of(url));
        }

        public Builder usagePolicyId(@Nullable Output<String> usagePolicyId) {
            $.usagePolicyId = usagePolicyId;
            return this;
        }

        public Builder usagePolicyId(String usagePolicyId) {
            return usagePolicyId(Output.of(usagePolicyId));
        }

        public PipelineState build() {
            return $;
        }
    }

}
