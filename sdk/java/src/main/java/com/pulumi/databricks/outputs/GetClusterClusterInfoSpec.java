// *** WARNING: this file was generated by pulumi-language-java. ***
// *** Do not edit by hand unless you're certain you know what you are doing! ***

package com.pulumi.databricks.outputs;

import com.pulumi.core.annotations.CustomType;
import com.pulumi.databricks.outputs.GetClusterClusterInfoSpecAutoscale;
import com.pulumi.databricks.outputs.GetClusterClusterInfoSpecAwsAttributes;
import com.pulumi.databricks.outputs.GetClusterClusterInfoSpecAzureAttributes;
import com.pulumi.databricks.outputs.GetClusterClusterInfoSpecClusterLogConf;
import com.pulumi.databricks.outputs.GetClusterClusterInfoSpecClusterMountInfo;
import com.pulumi.databricks.outputs.GetClusterClusterInfoSpecDockerImage;
import com.pulumi.databricks.outputs.GetClusterClusterInfoSpecDriverNodeTypeFlexibility;
import com.pulumi.databricks.outputs.GetClusterClusterInfoSpecGcpAttributes;
import com.pulumi.databricks.outputs.GetClusterClusterInfoSpecInitScript;
import com.pulumi.databricks.outputs.GetClusterClusterInfoSpecLibrary;
import com.pulumi.databricks.outputs.GetClusterClusterInfoSpecProviderConfig;
import com.pulumi.databricks.outputs.GetClusterClusterInfoSpecWorkerNodeTypeFlexibility;
import com.pulumi.databricks.outputs.GetClusterClusterInfoSpecWorkloadType;
import com.pulumi.exceptions.MissingRequiredPropertyException;
import java.lang.Boolean;
import java.lang.Integer;
import java.lang.String;
import java.util.List;
import java.util.Map;
import java.util.Objects;
import java.util.Optional;
import javax.annotation.Nullable;

@CustomType
public final class GetClusterClusterInfoSpec {
    private @Nullable Boolean applyPolicyDefaultValues;
    private @Nullable GetClusterClusterInfoSpecAutoscale autoscale;
    private @Nullable GetClusterClusterInfoSpecAwsAttributes awsAttributes;
    private @Nullable GetClusterClusterInfoSpecAzureAttributes azureAttributes;
    /**
     * @return The id of the cluster.
     * 
     */
    private String clusterId;
    private @Nullable GetClusterClusterInfoSpecClusterLogConf clusterLogConf;
    private @Nullable List<GetClusterClusterInfoSpecClusterMountInfo> clusterMountInfos;
    /**
     * @return The exact name of the cluster to search. Can only be specified if there is exactly one cluster with the provided name.
     * 
     */
    private @Nullable String clusterName;
    /**
     * @return Additional tags for cluster resources.
     * 
     */
    private @Nullable Map<String,String> customTags;
    /**
     * @return Security features of the cluster. Unity Catalog requires `SINGLE_USER` or `USER_ISOLATION` mode. `LEGACY_PASSTHROUGH` for passthrough cluster and `LEGACY_TABLE_ACL` for Table ACL cluster. Default to `NONE`, i.e. no security feature enabled.
     * 
     */
    private @Nullable String dataSecurityMode;
    private @Nullable GetClusterClusterInfoSpecDockerImage dockerImage;
    /**
     * @return similar to `instancePoolId`, but for driver node.
     * 
     */
    private String driverInstancePoolId;
    private @Nullable GetClusterClusterInfoSpecDriverNodeTypeFlexibility driverNodeTypeFlexibility;
    /**
     * @return The node type of the Spark driver.
     * 
     */
    private String driverNodeTypeId;
    /**
     * @return Use autoscaling local storage.
     * 
     */
    private Boolean enableElasticDisk;
    /**
     * @return Enable local disk encryption.
     * 
     */
    private Boolean enableLocalDiskEncryption;
    private @Nullable GetClusterClusterInfoSpecGcpAttributes gcpAttributes;
    /**
     * @return An optional token to guarantee the idempotency of cluster creation requests.
     * 
     */
    private @Nullable String idempotencyToken;
    private @Nullable List<GetClusterClusterInfoSpecInitScript> initScripts;
    /**
     * @return The pool of idle instances the cluster is attached to.
     * 
     */
    private @Nullable String instancePoolId;
    private @Nullable Boolean isSingleNode;
    private @Nullable String kind;
    private @Nullable List<GetClusterClusterInfoSpecLibrary> libraries;
    /**
     * @return Any supported databricks.getNodeType id.
     * 
     */
    private String nodeTypeId;
    private @Nullable Integer numWorkers;
    /**
     * @return Identifier of Cluster Policy to validate cluster and preset certain defaults.
     * 
     */
    private @Nullable String policyId;
    /**
     * @return Configure the provider for management through account provider. This block consists of the following fields:
     * 
     */
    private @Nullable GetClusterClusterInfoSpecProviderConfig providerConfig;
    private @Nullable Integer remoteDiskThroughput;
    /**
     * @return The type of runtime of the cluster
     * 
     */
    private @Nullable String runtimeEngine;
    /**
     * @return The optional user name of the user to assign to an interactive cluster. This field is required when using standard AAD Passthrough for Azure Data Lake Storage (ADLS) with a single-user cluster (i.e., not high-concurrency clusters).
     * 
     */
    private @Nullable String singleUserName;
    /**
     * @return Map with key-value pairs to fine-tune Spark clusters.
     * 
     */
    private @Nullable Map<String,String> sparkConf;
    /**
     * @return Map with environment variable key-value pairs to fine-tune Spark clusters. Key-value pairs of the form (X,Y) are exported (i.e., X=&#39;Y&#39;) while launching the driver and workers.
     * 
     */
    private @Nullable Map<String,String> sparkEnvVars;
    /**
     * @return [Runtime version](https://docs.databricks.com/runtime/index.html) of the cluster.
     * 
     */
    private @Nullable String sparkVersion;
    /**
     * @return SSH public key contents that will be added to each Spark node in this cluster.
     * 
     */
    private @Nullable List<String> sshPublicKeys;
    private @Nullable Integer totalInitialRemoteDiskSize;
    private @Nullable Boolean useMlRuntime;
    private @Nullable GetClusterClusterInfoSpecWorkerNodeTypeFlexibility workerNodeTypeFlexibility;
    private @Nullable GetClusterClusterInfoSpecWorkloadType workloadType;

    private GetClusterClusterInfoSpec() {}
    public Optional<Boolean> applyPolicyDefaultValues() {
        return Optional.ofNullable(this.applyPolicyDefaultValues);
    }
    public Optional<GetClusterClusterInfoSpecAutoscale> autoscale() {
        return Optional.ofNullable(this.autoscale);
    }
    public Optional<GetClusterClusterInfoSpecAwsAttributes> awsAttributes() {
        return Optional.ofNullable(this.awsAttributes);
    }
    public Optional<GetClusterClusterInfoSpecAzureAttributes> azureAttributes() {
        return Optional.ofNullable(this.azureAttributes);
    }
    /**
     * @return The id of the cluster.
     * 
     */
    public String clusterId() {
        return this.clusterId;
    }
    public Optional<GetClusterClusterInfoSpecClusterLogConf> clusterLogConf() {
        return Optional.ofNullable(this.clusterLogConf);
    }
    public List<GetClusterClusterInfoSpecClusterMountInfo> clusterMountInfos() {
        return this.clusterMountInfos == null ? List.of() : this.clusterMountInfos;
    }
    /**
     * @return The exact name of the cluster to search. Can only be specified if there is exactly one cluster with the provided name.
     * 
     */
    public Optional<String> clusterName() {
        return Optional.ofNullable(this.clusterName);
    }
    /**
     * @return Additional tags for cluster resources.
     * 
     */
    public Map<String,String> customTags() {
        return this.customTags == null ? Map.of() : this.customTags;
    }
    /**
     * @return Security features of the cluster. Unity Catalog requires `SINGLE_USER` or `USER_ISOLATION` mode. `LEGACY_PASSTHROUGH` for passthrough cluster and `LEGACY_TABLE_ACL` for Table ACL cluster. Default to `NONE`, i.e. no security feature enabled.
     * 
     */
    public Optional<String> dataSecurityMode() {
        return Optional.ofNullable(this.dataSecurityMode);
    }
    public Optional<GetClusterClusterInfoSpecDockerImage> dockerImage() {
        return Optional.ofNullable(this.dockerImage);
    }
    /**
     * @return similar to `instancePoolId`, but for driver node.
     * 
     */
    public String driverInstancePoolId() {
        return this.driverInstancePoolId;
    }
    public Optional<GetClusterClusterInfoSpecDriverNodeTypeFlexibility> driverNodeTypeFlexibility() {
        return Optional.ofNullable(this.driverNodeTypeFlexibility);
    }
    /**
     * @return The node type of the Spark driver.
     * 
     */
    public String driverNodeTypeId() {
        return this.driverNodeTypeId;
    }
    /**
     * @return Use autoscaling local storage.
     * 
     */
    public Boolean enableElasticDisk() {
        return this.enableElasticDisk;
    }
    /**
     * @return Enable local disk encryption.
     * 
     */
    public Boolean enableLocalDiskEncryption() {
        return this.enableLocalDiskEncryption;
    }
    public Optional<GetClusterClusterInfoSpecGcpAttributes> gcpAttributes() {
        return Optional.ofNullable(this.gcpAttributes);
    }
    /**
     * @return An optional token to guarantee the idempotency of cluster creation requests.
     * 
     */
    public Optional<String> idempotencyToken() {
        return Optional.ofNullable(this.idempotencyToken);
    }
    public List<GetClusterClusterInfoSpecInitScript> initScripts() {
        return this.initScripts == null ? List.of() : this.initScripts;
    }
    /**
     * @return The pool of idle instances the cluster is attached to.
     * 
     */
    public Optional<String> instancePoolId() {
        return Optional.ofNullable(this.instancePoolId);
    }
    public Optional<Boolean> isSingleNode() {
        return Optional.ofNullable(this.isSingleNode);
    }
    public Optional<String> kind() {
        return Optional.ofNullable(this.kind);
    }
    public List<GetClusterClusterInfoSpecLibrary> libraries() {
        return this.libraries == null ? List.of() : this.libraries;
    }
    /**
     * @return Any supported databricks.getNodeType id.
     * 
     */
    public String nodeTypeId() {
        return this.nodeTypeId;
    }
    public Optional<Integer> numWorkers() {
        return Optional.ofNullable(this.numWorkers);
    }
    /**
     * @return Identifier of Cluster Policy to validate cluster and preset certain defaults.
     * 
     */
    public Optional<String> policyId() {
        return Optional.ofNullable(this.policyId);
    }
    /**
     * @return Configure the provider for management through account provider. This block consists of the following fields:
     * 
     */
    public Optional<GetClusterClusterInfoSpecProviderConfig> providerConfig() {
        return Optional.ofNullable(this.providerConfig);
    }
    public Optional<Integer> remoteDiskThroughput() {
        return Optional.ofNullable(this.remoteDiskThroughput);
    }
    /**
     * @return The type of runtime of the cluster
     * 
     */
    public Optional<String> runtimeEngine() {
        return Optional.ofNullable(this.runtimeEngine);
    }
    /**
     * @return The optional user name of the user to assign to an interactive cluster. This field is required when using standard AAD Passthrough for Azure Data Lake Storage (ADLS) with a single-user cluster (i.e., not high-concurrency clusters).
     * 
     */
    public Optional<String> singleUserName() {
        return Optional.ofNullable(this.singleUserName);
    }
    /**
     * @return Map with key-value pairs to fine-tune Spark clusters.
     * 
     */
    public Map<String,String> sparkConf() {
        return this.sparkConf == null ? Map.of() : this.sparkConf;
    }
    /**
     * @return Map with environment variable key-value pairs to fine-tune Spark clusters. Key-value pairs of the form (X,Y) are exported (i.e., X=&#39;Y&#39;) while launching the driver and workers.
     * 
     */
    public Map<String,String> sparkEnvVars() {
        return this.sparkEnvVars == null ? Map.of() : this.sparkEnvVars;
    }
    /**
     * @return [Runtime version](https://docs.databricks.com/runtime/index.html) of the cluster.
     * 
     */
    public Optional<String> sparkVersion() {
        return Optional.ofNullable(this.sparkVersion);
    }
    /**
     * @return SSH public key contents that will be added to each Spark node in this cluster.
     * 
     */
    public List<String> sshPublicKeys() {
        return this.sshPublicKeys == null ? List.of() : this.sshPublicKeys;
    }
    public Optional<Integer> totalInitialRemoteDiskSize() {
        return Optional.ofNullable(this.totalInitialRemoteDiskSize);
    }
    public Optional<Boolean> useMlRuntime() {
        return Optional.ofNullable(this.useMlRuntime);
    }
    public Optional<GetClusterClusterInfoSpecWorkerNodeTypeFlexibility> workerNodeTypeFlexibility() {
        return Optional.ofNullable(this.workerNodeTypeFlexibility);
    }
    public Optional<GetClusterClusterInfoSpecWorkloadType> workloadType() {
        return Optional.ofNullable(this.workloadType);
    }

    public static Builder builder() {
        return new Builder();
    }

    public static Builder builder(GetClusterClusterInfoSpec defaults) {
        return new Builder(defaults);
    }
    @CustomType.Builder
    public static final class Builder {
        private @Nullable Boolean applyPolicyDefaultValues;
        private @Nullable GetClusterClusterInfoSpecAutoscale autoscale;
        private @Nullable GetClusterClusterInfoSpecAwsAttributes awsAttributes;
        private @Nullable GetClusterClusterInfoSpecAzureAttributes azureAttributes;
        private String clusterId;
        private @Nullable GetClusterClusterInfoSpecClusterLogConf clusterLogConf;
        private @Nullable List<GetClusterClusterInfoSpecClusterMountInfo> clusterMountInfos;
        private @Nullable String clusterName;
        private @Nullable Map<String,String> customTags;
        private @Nullable String dataSecurityMode;
        private @Nullable GetClusterClusterInfoSpecDockerImage dockerImage;
        private String driverInstancePoolId;
        private @Nullable GetClusterClusterInfoSpecDriverNodeTypeFlexibility driverNodeTypeFlexibility;
        private String driverNodeTypeId;
        private Boolean enableElasticDisk;
        private Boolean enableLocalDiskEncryption;
        private @Nullable GetClusterClusterInfoSpecGcpAttributes gcpAttributes;
        private @Nullable String idempotencyToken;
        private @Nullable List<GetClusterClusterInfoSpecInitScript> initScripts;
        private @Nullable String instancePoolId;
        private @Nullable Boolean isSingleNode;
        private @Nullable String kind;
        private @Nullable List<GetClusterClusterInfoSpecLibrary> libraries;
        private String nodeTypeId;
        private @Nullable Integer numWorkers;
        private @Nullable String policyId;
        private @Nullable GetClusterClusterInfoSpecProviderConfig providerConfig;
        private @Nullable Integer remoteDiskThroughput;
        private @Nullable String runtimeEngine;
        private @Nullable String singleUserName;
        private @Nullable Map<String,String> sparkConf;
        private @Nullable Map<String,String> sparkEnvVars;
        private @Nullable String sparkVersion;
        private @Nullable List<String> sshPublicKeys;
        private @Nullable Integer totalInitialRemoteDiskSize;
        private @Nullable Boolean useMlRuntime;
        private @Nullable GetClusterClusterInfoSpecWorkerNodeTypeFlexibility workerNodeTypeFlexibility;
        private @Nullable GetClusterClusterInfoSpecWorkloadType workloadType;
        public Builder() {}
        public Builder(GetClusterClusterInfoSpec defaults) {
    	      Objects.requireNonNull(defaults);
    	      this.applyPolicyDefaultValues = defaults.applyPolicyDefaultValues;
    	      this.autoscale = defaults.autoscale;
    	      this.awsAttributes = defaults.awsAttributes;
    	      this.azureAttributes = defaults.azureAttributes;
    	      this.clusterId = defaults.clusterId;
    	      this.clusterLogConf = defaults.clusterLogConf;
    	      this.clusterMountInfos = defaults.clusterMountInfos;
    	      this.clusterName = defaults.clusterName;
    	      this.customTags = defaults.customTags;
    	      this.dataSecurityMode = defaults.dataSecurityMode;
    	      this.dockerImage = defaults.dockerImage;
    	      this.driverInstancePoolId = defaults.driverInstancePoolId;
    	      this.driverNodeTypeFlexibility = defaults.driverNodeTypeFlexibility;
    	      this.driverNodeTypeId = defaults.driverNodeTypeId;
    	      this.enableElasticDisk = defaults.enableElasticDisk;
    	      this.enableLocalDiskEncryption = defaults.enableLocalDiskEncryption;
    	      this.gcpAttributes = defaults.gcpAttributes;
    	      this.idempotencyToken = defaults.idempotencyToken;
    	      this.initScripts = defaults.initScripts;
    	      this.instancePoolId = defaults.instancePoolId;
    	      this.isSingleNode = defaults.isSingleNode;
    	      this.kind = defaults.kind;
    	      this.libraries = defaults.libraries;
    	      this.nodeTypeId = defaults.nodeTypeId;
    	      this.numWorkers = defaults.numWorkers;
    	      this.policyId = defaults.policyId;
    	      this.providerConfig = defaults.providerConfig;
    	      this.remoteDiskThroughput = defaults.remoteDiskThroughput;
    	      this.runtimeEngine = defaults.runtimeEngine;
    	      this.singleUserName = defaults.singleUserName;
    	      this.sparkConf = defaults.sparkConf;
    	      this.sparkEnvVars = defaults.sparkEnvVars;
    	      this.sparkVersion = defaults.sparkVersion;
    	      this.sshPublicKeys = defaults.sshPublicKeys;
    	      this.totalInitialRemoteDiskSize = defaults.totalInitialRemoteDiskSize;
    	      this.useMlRuntime = defaults.useMlRuntime;
    	      this.workerNodeTypeFlexibility = defaults.workerNodeTypeFlexibility;
    	      this.workloadType = defaults.workloadType;
        }

        @CustomType.Setter
        public Builder applyPolicyDefaultValues(@Nullable Boolean applyPolicyDefaultValues) {

            this.applyPolicyDefaultValues = applyPolicyDefaultValues;
            return this;
        }
        @CustomType.Setter
        public Builder autoscale(@Nullable GetClusterClusterInfoSpecAutoscale autoscale) {

            this.autoscale = autoscale;
            return this;
        }
        @CustomType.Setter
        public Builder awsAttributes(@Nullable GetClusterClusterInfoSpecAwsAttributes awsAttributes) {

            this.awsAttributes = awsAttributes;
            return this;
        }
        @CustomType.Setter
        public Builder azureAttributes(@Nullable GetClusterClusterInfoSpecAzureAttributes azureAttributes) {

            this.azureAttributes = azureAttributes;
            return this;
        }
        @CustomType.Setter
        public Builder clusterId(String clusterId) {
            if (clusterId == null) {
              throw new MissingRequiredPropertyException("GetClusterClusterInfoSpec", "clusterId");
            }
            this.clusterId = clusterId;
            return this;
        }
        @CustomType.Setter
        public Builder clusterLogConf(@Nullable GetClusterClusterInfoSpecClusterLogConf clusterLogConf) {

            this.clusterLogConf = clusterLogConf;
            return this;
        }
        @CustomType.Setter
        public Builder clusterMountInfos(@Nullable List<GetClusterClusterInfoSpecClusterMountInfo> clusterMountInfos) {

            this.clusterMountInfos = clusterMountInfos;
            return this;
        }
        public Builder clusterMountInfos(GetClusterClusterInfoSpecClusterMountInfo... clusterMountInfos) {
            return clusterMountInfos(List.of(clusterMountInfos));
        }
        @CustomType.Setter
        public Builder clusterName(@Nullable String clusterName) {

            this.clusterName = clusterName;
            return this;
        }
        @CustomType.Setter
        public Builder customTags(@Nullable Map<String,String> customTags) {

            this.customTags = customTags;
            return this;
        }
        @CustomType.Setter
        public Builder dataSecurityMode(@Nullable String dataSecurityMode) {

            this.dataSecurityMode = dataSecurityMode;
            return this;
        }
        @CustomType.Setter
        public Builder dockerImage(@Nullable GetClusterClusterInfoSpecDockerImage dockerImage) {

            this.dockerImage = dockerImage;
            return this;
        }
        @CustomType.Setter
        public Builder driverInstancePoolId(String driverInstancePoolId) {
            if (driverInstancePoolId == null) {
              throw new MissingRequiredPropertyException("GetClusterClusterInfoSpec", "driverInstancePoolId");
            }
            this.driverInstancePoolId = driverInstancePoolId;
            return this;
        }
        @CustomType.Setter
        public Builder driverNodeTypeFlexibility(@Nullable GetClusterClusterInfoSpecDriverNodeTypeFlexibility driverNodeTypeFlexibility) {

            this.driverNodeTypeFlexibility = driverNodeTypeFlexibility;
            return this;
        }
        @CustomType.Setter
        public Builder driverNodeTypeId(String driverNodeTypeId) {
            if (driverNodeTypeId == null) {
              throw new MissingRequiredPropertyException("GetClusterClusterInfoSpec", "driverNodeTypeId");
            }
            this.driverNodeTypeId = driverNodeTypeId;
            return this;
        }
        @CustomType.Setter
        public Builder enableElasticDisk(Boolean enableElasticDisk) {
            if (enableElasticDisk == null) {
              throw new MissingRequiredPropertyException("GetClusterClusterInfoSpec", "enableElasticDisk");
            }
            this.enableElasticDisk = enableElasticDisk;
            return this;
        }
        @CustomType.Setter
        public Builder enableLocalDiskEncryption(Boolean enableLocalDiskEncryption) {
            if (enableLocalDiskEncryption == null) {
              throw new MissingRequiredPropertyException("GetClusterClusterInfoSpec", "enableLocalDiskEncryption");
            }
            this.enableLocalDiskEncryption = enableLocalDiskEncryption;
            return this;
        }
        @CustomType.Setter
        public Builder gcpAttributes(@Nullable GetClusterClusterInfoSpecGcpAttributes gcpAttributes) {

            this.gcpAttributes = gcpAttributes;
            return this;
        }
        @CustomType.Setter
        public Builder idempotencyToken(@Nullable String idempotencyToken) {

            this.idempotencyToken = idempotencyToken;
            return this;
        }
        @CustomType.Setter
        public Builder initScripts(@Nullable List<GetClusterClusterInfoSpecInitScript> initScripts) {

            this.initScripts = initScripts;
            return this;
        }
        public Builder initScripts(GetClusterClusterInfoSpecInitScript... initScripts) {
            return initScripts(List.of(initScripts));
        }
        @CustomType.Setter
        public Builder instancePoolId(@Nullable String instancePoolId) {

            this.instancePoolId = instancePoolId;
            return this;
        }
        @CustomType.Setter
        public Builder isSingleNode(@Nullable Boolean isSingleNode) {

            this.isSingleNode = isSingleNode;
            return this;
        }
        @CustomType.Setter
        public Builder kind(@Nullable String kind) {

            this.kind = kind;
            return this;
        }
        @CustomType.Setter
        public Builder libraries(@Nullable List<GetClusterClusterInfoSpecLibrary> libraries) {

            this.libraries = libraries;
            return this;
        }
        public Builder libraries(GetClusterClusterInfoSpecLibrary... libraries) {
            return libraries(List.of(libraries));
        }
        @CustomType.Setter
        public Builder nodeTypeId(String nodeTypeId) {
            if (nodeTypeId == null) {
              throw new MissingRequiredPropertyException("GetClusterClusterInfoSpec", "nodeTypeId");
            }
            this.nodeTypeId = nodeTypeId;
            return this;
        }
        @CustomType.Setter
        public Builder numWorkers(@Nullable Integer numWorkers) {

            this.numWorkers = numWorkers;
            return this;
        }
        @CustomType.Setter
        public Builder policyId(@Nullable String policyId) {

            this.policyId = policyId;
            return this;
        }
        @CustomType.Setter
        public Builder providerConfig(@Nullable GetClusterClusterInfoSpecProviderConfig providerConfig) {

            this.providerConfig = providerConfig;
            return this;
        }
        @CustomType.Setter
        public Builder remoteDiskThroughput(@Nullable Integer remoteDiskThroughput) {

            this.remoteDiskThroughput = remoteDiskThroughput;
            return this;
        }
        @CustomType.Setter
        public Builder runtimeEngine(@Nullable String runtimeEngine) {

            this.runtimeEngine = runtimeEngine;
            return this;
        }
        @CustomType.Setter
        public Builder singleUserName(@Nullable String singleUserName) {

            this.singleUserName = singleUserName;
            return this;
        }
        @CustomType.Setter
        public Builder sparkConf(@Nullable Map<String,String> sparkConf) {

            this.sparkConf = sparkConf;
            return this;
        }
        @CustomType.Setter
        public Builder sparkEnvVars(@Nullable Map<String,String> sparkEnvVars) {

            this.sparkEnvVars = sparkEnvVars;
            return this;
        }
        @CustomType.Setter
        public Builder sparkVersion(@Nullable String sparkVersion) {

            this.sparkVersion = sparkVersion;
            return this;
        }
        @CustomType.Setter
        public Builder sshPublicKeys(@Nullable List<String> sshPublicKeys) {

            this.sshPublicKeys = sshPublicKeys;
            return this;
        }
        public Builder sshPublicKeys(String... sshPublicKeys) {
            return sshPublicKeys(List.of(sshPublicKeys));
        }
        @CustomType.Setter
        public Builder totalInitialRemoteDiskSize(@Nullable Integer totalInitialRemoteDiskSize) {

            this.totalInitialRemoteDiskSize = totalInitialRemoteDiskSize;
            return this;
        }
        @CustomType.Setter
        public Builder useMlRuntime(@Nullable Boolean useMlRuntime) {

            this.useMlRuntime = useMlRuntime;
            return this;
        }
        @CustomType.Setter
        public Builder workerNodeTypeFlexibility(@Nullable GetClusterClusterInfoSpecWorkerNodeTypeFlexibility workerNodeTypeFlexibility) {

            this.workerNodeTypeFlexibility = workerNodeTypeFlexibility;
            return this;
        }
        @CustomType.Setter
        public Builder workloadType(@Nullable GetClusterClusterInfoSpecWorkloadType workloadType) {

            this.workloadType = workloadType;
            return this;
        }
        public GetClusterClusterInfoSpec build() {
            final var _resultValue = new GetClusterClusterInfoSpec();
            _resultValue.applyPolicyDefaultValues = applyPolicyDefaultValues;
            _resultValue.autoscale = autoscale;
            _resultValue.awsAttributes = awsAttributes;
            _resultValue.azureAttributes = azureAttributes;
            _resultValue.clusterId = clusterId;
            _resultValue.clusterLogConf = clusterLogConf;
            _resultValue.clusterMountInfos = clusterMountInfos;
            _resultValue.clusterName = clusterName;
            _resultValue.customTags = customTags;
            _resultValue.dataSecurityMode = dataSecurityMode;
            _resultValue.dockerImage = dockerImage;
            _resultValue.driverInstancePoolId = driverInstancePoolId;
            _resultValue.driverNodeTypeFlexibility = driverNodeTypeFlexibility;
            _resultValue.driverNodeTypeId = driverNodeTypeId;
            _resultValue.enableElasticDisk = enableElasticDisk;
            _resultValue.enableLocalDiskEncryption = enableLocalDiskEncryption;
            _resultValue.gcpAttributes = gcpAttributes;
            _resultValue.idempotencyToken = idempotencyToken;
            _resultValue.initScripts = initScripts;
            _resultValue.instancePoolId = instancePoolId;
            _resultValue.isSingleNode = isSingleNode;
            _resultValue.kind = kind;
            _resultValue.libraries = libraries;
            _resultValue.nodeTypeId = nodeTypeId;
            _resultValue.numWorkers = numWorkers;
            _resultValue.policyId = policyId;
            _resultValue.providerConfig = providerConfig;
            _resultValue.remoteDiskThroughput = remoteDiskThroughput;
            _resultValue.runtimeEngine = runtimeEngine;
            _resultValue.singleUserName = singleUserName;
            _resultValue.sparkConf = sparkConf;
            _resultValue.sparkEnvVars = sparkEnvVars;
            _resultValue.sparkVersion = sparkVersion;
            _resultValue.sshPublicKeys = sshPublicKeys;
            _resultValue.totalInitialRemoteDiskSize = totalInitialRemoteDiskSize;
            _resultValue.useMlRuntime = useMlRuntime;
            _resultValue.workerNodeTypeFlexibility = workerNodeTypeFlexibility;
            _resultValue.workloadType = workloadType;
            return _resultValue;
        }
    }
}
