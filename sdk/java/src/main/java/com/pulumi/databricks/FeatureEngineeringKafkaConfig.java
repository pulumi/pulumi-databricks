// *** WARNING: this file was generated by pulumi-language-java. ***
// *** Do not edit by hand unless you're certain you know what you are doing! ***

package com.pulumi.databricks;

import com.pulumi.core.Output;
import com.pulumi.core.annotations.Export;
import com.pulumi.core.annotations.ResourceType;
import com.pulumi.core.internal.Codegen;
import com.pulumi.databricks.FeatureEngineeringKafkaConfigArgs;
import com.pulumi.databricks.Utilities;
import com.pulumi.databricks.inputs.FeatureEngineeringKafkaConfigState;
import com.pulumi.databricks.outputs.FeatureEngineeringKafkaConfigAuthConfig;
import com.pulumi.databricks.outputs.FeatureEngineeringKafkaConfigBackfillSource;
import com.pulumi.databricks.outputs.FeatureEngineeringKafkaConfigKeySchema;
import com.pulumi.databricks.outputs.FeatureEngineeringKafkaConfigSubscriptionMode;
import com.pulumi.databricks.outputs.FeatureEngineeringKafkaConfigValueSchema;
import java.lang.String;
import java.util.Map;
import java.util.Optional;
import javax.annotation.Nullable;

/**
 * [![Private Preview](https://img.shields.io/badge/Release_Stage-Private_Preview-blueviolet)](https://docs.databricks.com/aws/en/release-notes/release-types)
 * 
 */
@ResourceType(type="databricks:index/featureEngineeringKafkaConfig:FeatureEngineeringKafkaConfig")
public class FeatureEngineeringKafkaConfig extends com.pulumi.resources.CustomResource {
    /**
     * Authentication configuration for connection to topics
     * 
     */
    @Export(name="authConfig", refs={FeatureEngineeringKafkaConfigAuthConfig.class}, tree="[0]")
    private Output<FeatureEngineeringKafkaConfigAuthConfig> authConfig;

    /**
     * @return Authentication configuration for connection to topics
     * 
     */
    public Output<FeatureEngineeringKafkaConfigAuthConfig> authConfig() {
        return this.authConfig;
    }
    /**
     * A user-provided and managed source for backfilling data. Historical data is used when creating a training set from streaming features linked to this Kafka config.
     * In the future, a separate table will be maintained by Databricks for forward filling data.
     * The schema for this source must match exactly that of the key and value schemas specified for this Kafka config
     * 
     */
    @Export(name="backfillSource", refs={FeatureEngineeringKafkaConfigBackfillSource.class}, tree="[0]")
    private Output</* @Nullable */ FeatureEngineeringKafkaConfigBackfillSource> backfillSource;

    /**
     * @return A user-provided and managed source for backfilling data. Historical data is used when creating a training set from streaming features linked to this Kafka config.
     * In the future, a separate table will be maintained by Databricks for forward filling data.
     * The schema for this source must match exactly that of the key and value schemas specified for this Kafka config
     * 
     */
    public Output<Optional<FeatureEngineeringKafkaConfigBackfillSource>> backfillSource() {
        return Codegen.optional(this.backfillSource);
    }
    /**
     * A comma-separated list of host/port pairs pointing to Kafka cluster
     * 
     */
    @Export(name="bootstrapServers", refs={String.class}, tree="[0]")
    private Output<String> bootstrapServers;

    /**
     * @return A comma-separated list of host/port pairs pointing to Kafka cluster
     * 
     */
    public Output<String> bootstrapServers() {
        return this.bootstrapServers;
    }
    /**
     * Catch-all for miscellaneous options. Keys should be source options or Kafka consumer options (kafka.*)
     * 
     */
    @Export(name="extraOptions", refs={Map.class,String.class}, tree="[0,1,1]")
    private Output</* @Nullable */ Map<String,String>> extraOptions;

    /**
     * @return Catch-all for miscellaneous options. Keys should be source options or Kafka consumer options (kafka.*)
     * 
     */
    public Output<Optional<Map<String,String>>> extraOptions() {
        return Codegen.optional(this.extraOptions);
    }
    /**
     * Schema configuration for extracting message keys from topics. At least one of keySchema and valueSchema must be provided
     * 
     */
    @Export(name="keySchema", refs={FeatureEngineeringKafkaConfigKeySchema.class}, tree="[0]")
    private Output</* @Nullable */ FeatureEngineeringKafkaConfigKeySchema> keySchema;

    /**
     * @return Schema configuration for extracting message keys from topics. At least one of keySchema and valueSchema must be provided
     * 
     */
    public Output<Optional<FeatureEngineeringKafkaConfigKeySchema>> keySchema() {
        return Codegen.optional(this.keySchema);
    }
    /**
     * (string) - Name that uniquely identifies this Kafka config within the metastore. This will be the identifier used from the Feature object to reference these configs for a feature.
     * Can be distinct from topic name
     * 
     */
    @Export(name="name", refs={String.class}, tree="[0]")
    private Output<String> name;

    /**
     * @return (string) - Name that uniquely identifies this Kafka config within the metastore. This will be the identifier used from the Feature object to reference these configs for a feature.
     * Can be distinct from topic name
     * 
     */
    public Output<String> name() {
        return this.name;
    }
    /**
     * Options to configure which Kafka topics to pull data from
     * 
     */
    @Export(name="subscriptionMode", refs={FeatureEngineeringKafkaConfigSubscriptionMode.class}, tree="[0]")
    private Output<FeatureEngineeringKafkaConfigSubscriptionMode> subscriptionMode;

    /**
     * @return Options to configure which Kafka topics to pull data from
     * 
     */
    public Output<FeatureEngineeringKafkaConfigSubscriptionMode> subscriptionMode() {
        return this.subscriptionMode;
    }
    /**
     * Schema configuration for extracting message values from topics. At least one of keySchema and valueSchema must be provided
     * 
     */
    @Export(name="valueSchema", refs={FeatureEngineeringKafkaConfigValueSchema.class}, tree="[0]")
    private Output</* @Nullable */ FeatureEngineeringKafkaConfigValueSchema> valueSchema;

    /**
     * @return Schema configuration for extracting message values from topics. At least one of keySchema and valueSchema must be provided
     * 
     */
    public Output<Optional<FeatureEngineeringKafkaConfigValueSchema>> valueSchema() {
        return Codegen.optional(this.valueSchema);
    }

    /**
     *
     * @param name The _unique_ name of the resulting resource.
     */
    public FeatureEngineeringKafkaConfig(java.lang.String name) {
        this(name, FeatureEngineeringKafkaConfigArgs.Empty);
    }
    /**
     *
     * @param name The _unique_ name of the resulting resource.
     * @param args The arguments to use to populate this resource's properties.
     */
    public FeatureEngineeringKafkaConfig(java.lang.String name, FeatureEngineeringKafkaConfigArgs args) {
        this(name, args, null);
    }
    /**
     *
     * @param name The _unique_ name of the resulting resource.
     * @param args The arguments to use to populate this resource's properties.
     * @param options A bag of options that control this resource's behavior.
     */
    public FeatureEngineeringKafkaConfig(java.lang.String name, FeatureEngineeringKafkaConfigArgs args, @Nullable com.pulumi.resources.CustomResourceOptions options) {
        super("databricks:index/featureEngineeringKafkaConfig:FeatureEngineeringKafkaConfig", name, makeArgs(args, options), makeResourceOptions(options, Codegen.empty()), false);
    }

    private FeatureEngineeringKafkaConfig(java.lang.String name, Output<java.lang.String> id, @Nullable FeatureEngineeringKafkaConfigState state, @Nullable com.pulumi.resources.CustomResourceOptions options) {
        super("databricks:index/featureEngineeringKafkaConfig:FeatureEngineeringKafkaConfig", name, state, makeResourceOptions(options, id), false);
    }

    private static FeatureEngineeringKafkaConfigArgs makeArgs(FeatureEngineeringKafkaConfigArgs args, @Nullable com.pulumi.resources.CustomResourceOptions options) {
        if (options != null && options.getUrn().isPresent()) {
            return null;
        }
        return args == null ? FeatureEngineeringKafkaConfigArgs.Empty : args;
    }

    private static com.pulumi.resources.CustomResourceOptions makeResourceOptions(@Nullable com.pulumi.resources.CustomResourceOptions options, @Nullable Output<java.lang.String> id) {
        var defaultOptions = com.pulumi.resources.CustomResourceOptions.builder()
            .version(Utilities.getVersion())
            .build();
        return com.pulumi.resources.CustomResourceOptions.merge(defaultOptions, options, id);
    }

    /**
     * Get an existing Host resource's state with the given name, ID, and optional extra
     * properties used to qualify the lookup.
     *
     * @param name The _unique_ name of the resulting resource.
     * @param id The _unique_ provider ID of the resource to lookup.
     * @param state
     * @param options Optional settings to control the behavior of the CustomResource.
     */
    public static FeatureEngineeringKafkaConfig get(java.lang.String name, Output<java.lang.String> id, @Nullable FeatureEngineeringKafkaConfigState state, @Nullable com.pulumi.resources.CustomResourceOptions options) {
        return new FeatureEngineeringKafkaConfig(name, id, state, options);
    }
}
