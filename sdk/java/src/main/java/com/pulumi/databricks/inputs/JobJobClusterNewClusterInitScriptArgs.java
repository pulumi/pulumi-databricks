// *** WARNING: this file was generated by pulumi-java-gen. ***
// *** Do not edit by hand unless you're certain you know what you are doing! ***

package com.pulumi.databricks.inputs;

import com.pulumi.core.Output;
import com.pulumi.core.annotations.Import;
import com.pulumi.databricks.inputs.JobJobClusterNewClusterInitScriptAbfssArgs;
import com.pulumi.databricks.inputs.JobJobClusterNewClusterInitScriptDbfsArgs;
import com.pulumi.databricks.inputs.JobJobClusterNewClusterInitScriptFileArgs;
import com.pulumi.databricks.inputs.JobJobClusterNewClusterInitScriptGcsArgs;
import com.pulumi.databricks.inputs.JobJobClusterNewClusterInitScriptS3Args;
import com.pulumi.databricks.inputs.JobJobClusterNewClusterInitScriptVolumesArgs;
import com.pulumi.databricks.inputs.JobJobClusterNewClusterInitScriptWorkspaceArgs;
import java.util.Objects;
import java.util.Optional;
import javax.annotation.Nullable;


public final class JobJobClusterNewClusterInitScriptArgs extends com.pulumi.resources.ResourceArgs {

    public static final JobJobClusterNewClusterInitScriptArgs Empty = new JobJobClusterNewClusterInitScriptArgs();

    @Import(name="abfss")
    private @Nullable Output<JobJobClusterNewClusterInitScriptAbfssArgs> abfss;

    public Optional<Output<JobJobClusterNewClusterInitScriptAbfssArgs>> abfss() {
        return Optional.ofNullable(this.abfss);
    }

    /**
     * @deprecated
     * For init scripts use &#39;volumes&#39;, &#39;workspace&#39; or cloud storage location instead of &#39;dbfs&#39;.
     * 
     */
    @Deprecated /* For init scripts use 'volumes', 'workspace' or cloud storage location instead of 'dbfs'. */
    @Import(name="dbfs")
    private @Nullable Output<JobJobClusterNewClusterInitScriptDbfsArgs> dbfs;

    /**
     * @deprecated
     * For init scripts use &#39;volumes&#39;, &#39;workspace&#39; or cloud storage location instead of &#39;dbfs&#39;.
     * 
     */
    @Deprecated /* For init scripts use 'volumes', 'workspace' or cloud storage location instead of 'dbfs'. */
    public Optional<Output<JobJobClusterNewClusterInitScriptDbfsArgs>> dbfs() {
        return Optional.ofNullable(this.dbfs);
    }

    /**
     * block consisting of single string field: `path` - a relative path to the file (inside the Git repository) with SQL commands to execute.  *Requires `git_source` configuration block*.
     * 
     * Example
     * ```java
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.databricks.Job;
     * import com.pulumi.databricks.JobArgs;
     * import com.pulumi.databricks.inputs.JobTaskArgs;
     * import com.pulumi.databricks.inputs.JobTaskSqlTaskArgs;
     * import com.pulumi.databricks.inputs.JobTaskSqlTaskQueryArgs;
     * import com.pulumi.databricks.inputs.JobTaskSqlTaskDashboardArgs;
     * import com.pulumi.databricks.inputs.JobTaskSqlTaskAlertArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         var sqlAggregationJob = new Job(&#34;sqlAggregationJob&#34;, JobArgs.builder()        
     *             .tasks(            
     *                 JobTaskArgs.builder()
     *                     .taskKey(&#34;run_agg_query&#34;)
     *                     .sqlTask(JobTaskSqlTaskArgs.builder()
     *                         .warehouseId(databricks_sql_endpoint.sql_job_warehouse().id())
     *                         .query(JobTaskSqlTaskQueryArgs.builder()
     *                             .queryId(databricks_sql_query.agg_query().id())
     *                             .build())
     *                         .build())
     *                     .build(),
     *                 JobTaskArgs.builder()
     *                     .taskKey(&#34;run_dashboard&#34;)
     *                     .sqlTask(JobTaskSqlTaskArgs.builder()
     *                         .warehouseId(databricks_sql_endpoint.sql_job_warehouse().id())
     *                         .dashboard(JobTaskSqlTaskDashboardArgs.builder()
     *                             .dashboardId(databricks_sql_dashboard.dash().id())
     *                             .subscriptions(JobTaskSqlTaskDashboardSubscriptionArgs.builder()
     *                                 .userName(&#34;user@domain.com&#34;)
     *                                 .build())
     *                             .build())
     *                         .build())
     *                     .build(),
     *                 JobTaskArgs.builder()
     *                     .taskKey(&#34;run_alert&#34;)
     *                     .sqlTask(JobTaskSqlTaskArgs.builder()
     *                         .warehouseId(databricks_sql_endpoint.sql_job_warehouse().id())
     *                         .alert(JobTaskSqlTaskAlertArgs.builder()
     *                             .alertId(databricks_sql_alert.alert().id())
     *                             .subscriptions(JobTaskSqlTaskAlertSubscriptionArgs.builder()
     *                                 .userName(&#34;user@domain.com&#34;)
     *                                 .build())
     *                             .build())
     *                         .build())
     *                     .build())
     *             .build());
     * 
     *     }
     * }
     * ```
     * 
     */
    @Import(name="file")
    private @Nullable Output<JobJobClusterNewClusterInitScriptFileArgs> file;

    /**
     * @return block consisting of single string field: `path` - a relative path to the file (inside the Git repository) with SQL commands to execute.  *Requires `git_source` configuration block*.
     * 
     * Example
     * ```java
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.databricks.Job;
     * import com.pulumi.databricks.JobArgs;
     * import com.pulumi.databricks.inputs.JobTaskArgs;
     * import com.pulumi.databricks.inputs.JobTaskSqlTaskArgs;
     * import com.pulumi.databricks.inputs.JobTaskSqlTaskQueryArgs;
     * import com.pulumi.databricks.inputs.JobTaskSqlTaskDashboardArgs;
     * import com.pulumi.databricks.inputs.JobTaskSqlTaskAlertArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         var sqlAggregationJob = new Job(&#34;sqlAggregationJob&#34;, JobArgs.builder()        
     *             .tasks(            
     *                 JobTaskArgs.builder()
     *                     .taskKey(&#34;run_agg_query&#34;)
     *                     .sqlTask(JobTaskSqlTaskArgs.builder()
     *                         .warehouseId(databricks_sql_endpoint.sql_job_warehouse().id())
     *                         .query(JobTaskSqlTaskQueryArgs.builder()
     *                             .queryId(databricks_sql_query.agg_query().id())
     *                             .build())
     *                         .build())
     *                     .build(),
     *                 JobTaskArgs.builder()
     *                     .taskKey(&#34;run_dashboard&#34;)
     *                     .sqlTask(JobTaskSqlTaskArgs.builder()
     *                         .warehouseId(databricks_sql_endpoint.sql_job_warehouse().id())
     *                         .dashboard(JobTaskSqlTaskDashboardArgs.builder()
     *                             .dashboardId(databricks_sql_dashboard.dash().id())
     *                             .subscriptions(JobTaskSqlTaskDashboardSubscriptionArgs.builder()
     *                                 .userName(&#34;user@domain.com&#34;)
     *                                 .build())
     *                             .build())
     *                         .build())
     *                     .build(),
     *                 JobTaskArgs.builder()
     *                     .taskKey(&#34;run_alert&#34;)
     *                     .sqlTask(JobTaskSqlTaskArgs.builder()
     *                         .warehouseId(databricks_sql_endpoint.sql_job_warehouse().id())
     *                         .alert(JobTaskSqlTaskAlertArgs.builder()
     *                             .alertId(databricks_sql_alert.alert().id())
     *                             .subscriptions(JobTaskSqlTaskAlertSubscriptionArgs.builder()
     *                                 .userName(&#34;user@domain.com&#34;)
     *                                 .build())
     *                             .build())
     *                         .build())
     *                     .build())
     *             .build());
     * 
     *     }
     * }
     * ```
     * 
     */
    public Optional<Output<JobJobClusterNewClusterInitScriptFileArgs>> file() {
        return Optional.ofNullable(this.file);
    }

    @Import(name="gcs")
    private @Nullable Output<JobJobClusterNewClusterInitScriptGcsArgs> gcs;

    public Optional<Output<JobJobClusterNewClusterInitScriptGcsArgs>> gcs() {
        return Optional.ofNullable(this.gcs);
    }

    @Import(name="s3")
    private @Nullable Output<JobJobClusterNewClusterInitScriptS3Args> s3;

    public Optional<Output<JobJobClusterNewClusterInitScriptS3Args>> s3() {
        return Optional.ofNullable(this.s3);
    }

    @Import(name="volumes")
    private @Nullable Output<JobJobClusterNewClusterInitScriptVolumesArgs> volumes;

    public Optional<Output<JobJobClusterNewClusterInitScriptVolumesArgs>> volumes() {
        return Optional.ofNullable(this.volumes);
    }

    @Import(name="workspace")
    private @Nullable Output<JobJobClusterNewClusterInitScriptWorkspaceArgs> workspace;

    public Optional<Output<JobJobClusterNewClusterInitScriptWorkspaceArgs>> workspace() {
        return Optional.ofNullable(this.workspace);
    }

    private JobJobClusterNewClusterInitScriptArgs() {}

    private JobJobClusterNewClusterInitScriptArgs(JobJobClusterNewClusterInitScriptArgs $) {
        this.abfss = $.abfss;
        this.dbfs = $.dbfs;
        this.file = $.file;
        this.gcs = $.gcs;
        this.s3 = $.s3;
        this.volumes = $.volumes;
        this.workspace = $.workspace;
    }

    public static Builder builder() {
        return new Builder();
    }
    public static Builder builder(JobJobClusterNewClusterInitScriptArgs defaults) {
        return new Builder(defaults);
    }

    public static final class Builder {
        private JobJobClusterNewClusterInitScriptArgs $;

        public Builder() {
            $ = new JobJobClusterNewClusterInitScriptArgs();
        }

        public Builder(JobJobClusterNewClusterInitScriptArgs defaults) {
            $ = new JobJobClusterNewClusterInitScriptArgs(Objects.requireNonNull(defaults));
        }

        public Builder abfss(@Nullable Output<JobJobClusterNewClusterInitScriptAbfssArgs> abfss) {
            $.abfss = abfss;
            return this;
        }

        public Builder abfss(JobJobClusterNewClusterInitScriptAbfssArgs abfss) {
            return abfss(Output.of(abfss));
        }

        /**
         * @return builder
         * 
         * @deprecated
         * For init scripts use &#39;volumes&#39;, &#39;workspace&#39; or cloud storage location instead of &#39;dbfs&#39;.
         * 
         */
        @Deprecated /* For init scripts use 'volumes', 'workspace' or cloud storage location instead of 'dbfs'. */
        public Builder dbfs(@Nullable Output<JobJobClusterNewClusterInitScriptDbfsArgs> dbfs) {
            $.dbfs = dbfs;
            return this;
        }

        /**
         * @return builder
         * 
         * @deprecated
         * For init scripts use &#39;volumes&#39;, &#39;workspace&#39; or cloud storage location instead of &#39;dbfs&#39;.
         * 
         */
        @Deprecated /* For init scripts use 'volumes', 'workspace' or cloud storage location instead of 'dbfs'. */
        public Builder dbfs(JobJobClusterNewClusterInitScriptDbfsArgs dbfs) {
            return dbfs(Output.of(dbfs));
        }

        /**
         * @param file block consisting of single string field: `path` - a relative path to the file (inside the Git repository) with SQL commands to execute.  *Requires `git_source` configuration block*.
         * 
         * Example
         * ```java
         * package generated_program;
         * 
         * import com.pulumi.Context;
         * import com.pulumi.Pulumi;
         * import com.pulumi.core.Output;
         * import com.pulumi.databricks.Job;
         * import com.pulumi.databricks.JobArgs;
         * import com.pulumi.databricks.inputs.JobTaskArgs;
         * import com.pulumi.databricks.inputs.JobTaskSqlTaskArgs;
         * import com.pulumi.databricks.inputs.JobTaskSqlTaskQueryArgs;
         * import com.pulumi.databricks.inputs.JobTaskSqlTaskDashboardArgs;
         * import com.pulumi.databricks.inputs.JobTaskSqlTaskAlertArgs;
         * import java.util.List;
         * import java.util.ArrayList;
         * import java.util.Map;
         * import java.io.File;
         * import java.nio.file.Files;
         * import java.nio.file.Paths;
         * 
         * public class App {
         *     public static void main(String[] args) {
         *         Pulumi.run(App::stack);
         *     }
         * 
         *     public static void stack(Context ctx) {
         *         var sqlAggregationJob = new Job(&#34;sqlAggregationJob&#34;, JobArgs.builder()        
         *             .tasks(            
         *                 JobTaskArgs.builder()
         *                     .taskKey(&#34;run_agg_query&#34;)
         *                     .sqlTask(JobTaskSqlTaskArgs.builder()
         *                         .warehouseId(databricks_sql_endpoint.sql_job_warehouse().id())
         *                         .query(JobTaskSqlTaskQueryArgs.builder()
         *                             .queryId(databricks_sql_query.agg_query().id())
         *                             .build())
         *                         .build())
         *                     .build(),
         *                 JobTaskArgs.builder()
         *                     .taskKey(&#34;run_dashboard&#34;)
         *                     .sqlTask(JobTaskSqlTaskArgs.builder()
         *                         .warehouseId(databricks_sql_endpoint.sql_job_warehouse().id())
         *                         .dashboard(JobTaskSqlTaskDashboardArgs.builder()
         *                             .dashboardId(databricks_sql_dashboard.dash().id())
         *                             .subscriptions(JobTaskSqlTaskDashboardSubscriptionArgs.builder()
         *                                 .userName(&#34;user@domain.com&#34;)
         *                                 .build())
         *                             .build())
         *                         .build())
         *                     .build(),
         *                 JobTaskArgs.builder()
         *                     .taskKey(&#34;run_alert&#34;)
         *                     .sqlTask(JobTaskSqlTaskArgs.builder()
         *                         .warehouseId(databricks_sql_endpoint.sql_job_warehouse().id())
         *                         .alert(JobTaskSqlTaskAlertArgs.builder()
         *                             .alertId(databricks_sql_alert.alert().id())
         *                             .subscriptions(JobTaskSqlTaskAlertSubscriptionArgs.builder()
         *                                 .userName(&#34;user@domain.com&#34;)
         *                                 .build())
         *                             .build())
         *                         .build())
         *                     .build())
         *             .build());
         * 
         *     }
         * }
         * ```
         * 
         * @return builder
         * 
         */
        public Builder file(@Nullable Output<JobJobClusterNewClusterInitScriptFileArgs> file) {
            $.file = file;
            return this;
        }

        /**
         * @param file block consisting of single string field: `path` - a relative path to the file (inside the Git repository) with SQL commands to execute.  *Requires `git_source` configuration block*.
         * 
         * Example
         * ```java
         * package generated_program;
         * 
         * import com.pulumi.Context;
         * import com.pulumi.Pulumi;
         * import com.pulumi.core.Output;
         * import com.pulumi.databricks.Job;
         * import com.pulumi.databricks.JobArgs;
         * import com.pulumi.databricks.inputs.JobTaskArgs;
         * import com.pulumi.databricks.inputs.JobTaskSqlTaskArgs;
         * import com.pulumi.databricks.inputs.JobTaskSqlTaskQueryArgs;
         * import com.pulumi.databricks.inputs.JobTaskSqlTaskDashboardArgs;
         * import com.pulumi.databricks.inputs.JobTaskSqlTaskAlertArgs;
         * import java.util.List;
         * import java.util.ArrayList;
         * import java.util.Map;
         * import java.io.File;
         * import java.nio.file.Files;
         * import java.nio.file.Paths;
         * 
         * public class App {
         *     public static void main(String[] args) {
         *         Pulumi.run(App::stack);
         *     }
         * 
         *     public static void stack(Context ctx) {
         *         var sqlAggregationJob = new Job(&#34;sqlAggregationJob&#34;, JobArgs.builder()        
         *             .tasks(            
         *                 JobTaskArgs.builder()
         *                     .taskKey(&#34;run_agg_query&#34;)
         *                     .sqlTask(JobTaskSqlTaskArgs.builder()
         *                         .warehouseId(databricks_sql_endpoint.sql_job_warehouse().id())
         *                         .query(JobTaskSqlTaskQueryArgs.builder()
         *                             .queryId(databricks_sql_query.agg_query().id())
         *                             .build())
         *                         .build())
         *                     .build(),
         *                 JobTaskArgs.builder()
         *                     .taskKey(&#34;run_dashboard&#34;)
         *                     .sqlTask(JobTaskSqlTaskArgs.builder()
         *                         .warehouseId(databricks_sql_endpoint.sql_job_warehouse().id())
         *                         .dashboard(JobTaskSqlTaskDashboardArgs.builder()
         *                             .dashboardId(databricks_sql_dashboard.dash().id())
         *                             .subscriptions(JobTaskSqlTaskDashboardSubscriptionArgs.builder()
         *                                 .userName(&#34;user@domain.com&#34;)
         *                                 .build())
         *                             .build())
         *                         .build())
         *                     .build(),
         *                 JobTaskArgs.builder()
         *                     .taskKey(&#34;run_alert&#34;)
         *                     .sqlTask(JobTaskSqlTaskArgs.builder()
         *                         .warehouseId(databricks_sql_endpoint.sql_job_warehouse().id())
         *                         .alert(JobTaskSqlTaskAlertArgs.builder()
         *                             .alertId(databricks_sql_alert.alert().id())
         *                             .subscriptions(JobTaskSqlTaskAlertSubscriptionArgs.builder()
         *                                 .userName(&#34;user@domain.com&#34;)
         *                                 .build())
         *                             .build())
         *                         .build())
         *                     .build())
         *             .build());
         * 
         *     }
         * }
         * ```
         * 
         * @return builder
         * 
         */
        public Builder file(JobJobClusterNewClusterInitScriptFileArgs file) {
            return file(Output.of(file));
        }

        public Builder gcs(@Nullable Output<JobJobClusterNewClusterInitScriptGcsArgs> gcs) {
            $.gcs = gcs;
            return this;
        }

        public Builder gcs(JobJobClusterNewClusterInitScriptGcsArgs gcs) {
            return gcs(Output.of(gcs));
        }

        public Builder s3(@Nullable Output<JobJobClusterNewClusterInitScriptS3Args> s3) {
            $.s3 = s3;
            return this;
        }

        public Builder s3(JobJobClusterNewClusterInitScriptS3Args s3) {
            return s3(Output.of(s3));
        }

        public Builder volumes(@Nullable Output<JobJobClusterNewClusterInitScriptVolumesArgs> volumes) {
            $.volumes = volumes;
            return this;
        }

        public Builder volumes(JobJobClusterNewClusterInitScriptVolumesArgs volumes) {
            return volumes(Output.of(volumes));
        }

        public Builder workspace(@Nullable Output<JobJobClusterNewClusterInitScriptWorkspaceArgs> workspace) {
            $.workspace = workspace;
            return this;
        }

        public Builder workspace(JobJobClusterNewClusterInitScriptWorkspaceArgs workspace) {
            return workspace(Output.of(workspace));
        }

        public JobJobClusterNewClusterInitScriptArgs build() {
            return $;
        }
    }

}
