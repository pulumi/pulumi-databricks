// *** WARNING: this file was generated by pulumi-language-java. ***
// *** Do not edit by hand unless you're certain you know what you are doing! ***

package com.pulumi.databricks;

import com.pulumi.core.Output;
import com.pulumi.core.annotations.Export;
import com.pulumi.core.annotations.ResourceType;
import com.pulumi.core.internal.Codegen;
import com.pulumi.databricks.MwsWorkspacesArgs;
import com.pulumi.databricks.Utilities;
import com.pulumi.databricks.inputs.MwsWorkspacesState;
import com.pulumi.databricks.outputs.MwsWorkspacesCloudResourceContainer;
import com.pulumi.databricks.outputs.MwsWorkspacesExternalCustomerInfo;
import com.pulumi.databricks.outputs.MwsWorkspacesGcpManagedNetworkConfig;
import com.pulumi.databricks.outputs.MwsWorkspacesGkeConfig;
import com.pulumi.databricks.outputs.MwsWorkspacesToken;
import java.lang.Boolean;
import java.lang.Integer;
import java.lang.String;
import java.util.List;
import java.util.Map;
import java.util.Optional;
import javax.annotation.Nullable;

/**
 * This resource allows you to set up [workspaces on AWS](https://docs.databricks.com/getting-started/overview.html#e2-architecture-1) or [workspaces on GCP](https://docs.gcp.databricks.com/administration-guide/account-settings-gcp/workspaces.html). Please follow this complete runnable example on AWS or GCP with new VPC and new workspace setup.
 * 
 * &gt; This resource can only be used with an account-level provider!
 * 
 * &gt; The `gkeConfig` argument is now deprecated and no longer supported. If you have already created a workspace using these fields, it is safe to remove them from your Pulumi template.
 * 
 * &gt; On Azure you need to use azurermDatabricksWorkspace resource to create Azure Databricks workspaces.
 * 
 * ## Example Usage
 * 
 * ### Creating a serverless workspace in AWS and GCP
 * 
 * Creating a serverless workspace does not require any prerequisite resources. Simply specify `computeMode = &#34;SERVERLESS&#34;` when creating the workspace. Serverless workspaces must not include `credentialsId` or `storageConfigurationId`.
 * 
 * On [AWS](https://docs.databricks.com/aws/en/admin/workspace/serverless-workspaces):
 * 
 * <pre>
 * {@code
 * package generated_program;
 * 
 * import com.pulumi.Context;
 * import com.pulumi.Pulumi;
 * import com.pulumi.core.Output;
 * import com.pulumi.databricks.MwsWorkspaces;
 * import com.pulumi.databricks.MwsWorkspacesArgs;
 * import java.util.List;
 * import java.util.ArrayList;
 * import java.util.Map;
 * import java.io.File;
 * import java.nio.file.Files;
 * import java.nio.file.Paths;
 * 
 * public class App {
 *     public static void main(String[] args) {
 *         Pulumi.run(App::stack);
 *     }
 * 
 *     public static void stack(Context ctx) {
 *         var serverlessWorkspace = new MwsWorkspaces("serverlessWorkspace", MwsWorkspacesArgs.builder()
 *             .accountId("")
 *             .workspaceName("serverless-workspace")
 *             .awsRegion("us-east-1")
 *             .computeMode("SERVERLESS")
 *             .build());
 * 
 *     }
 * }
 * }
 * </pre>
 * 
 * On [GCP](https://docs.databricks.com/gcp/en/admin/workspace/serverless-workspaces):
 * 
 * <pre>
 * {@code
 * package generated_program;
 * 
 * import com.pulumi.Context;
 * import com.pulumi.Pulumi;
 * import com.pulumi.core.Output;
 * import com.pulumi.databricks.MwsWorkspaces;
 * import com.pulumi.databricks.MwsWorkspacesArgs;
 * import java.util.List;
 * import java.util.ArrayList;
 * import java.util.Map;
 * import java.io.File;
 * import java.nio.file.Files;
 * import java.nio.file.Paths;
 * 
 * public class App {
 *     public static void main(String[] args) {
 *         Pulumi.run(App::stack);
 *     }
 * 
 *     public static void stack(Context ctx) {
 *         var serverlessWorkspace = new MwsWorkspaces("serverlessWorkspace", MwsWorkspacesArgs.builder()
 *             .accountId("")
 *             .workspaceName("serverless-workspace")
 *             .location("us-east4")
 *             .computeMode("SERVERLESS")
 *             .build());
 * 
 *     }
 * }
 * }
 * </pre>
 * 
 * ### Creating a workspace on AWS
 * 
 * !Simplest multiworkspace
 * 
 * To get workspace running, you have to configure a couple of things:
 * 
 * * databricks.MwsCredentials - You can share a credentials (cross-account IAM role) configuration ID with multiple workspaces. It is not required to create a new one for each workspace.
 * * databricks.MwsStorageConfigurations - You can share a root S3 bucket with multiple workspaces in a single account. You do not have to create new ones for each workspace. If you share a root S3 bucket for multiple workspaces in an account, data on the root S3 bucket is partitioned into separate directories by workspace.
 * * databricks.MwsNetworks - (optional, but recommended) You can share one [customer-managed VPC](https://docs.databricks.com/administration-guide/cloud-configurations/aws/customer-managed-vpc.html) with multiple workspaces in a single account. However, Databricks recommends using unique subnets and security groups for each workspace. If you plan to share one VPC with multiple workspaces, be sure to size your VPC and subnets accordingly. Because a Databricks databricks.MwsNetworks encapsulates this information, you cannot reuse it across workspaces.
 * * databricks.MwsCustomerManagedKeys - You can share a customer-managed key across workspaces.
 * 
 * <pre>
 * {@code
 * package generated_program;
 * 
 * import com.pulumi.Context;
 * import com.pulumi.Pulumi;
 * import com.pulumi.core.Output;
 * import com.pulumi.databricks.MwsCredentials;
 * import com.pulumi.databricks.MwsCredentialsArgs;
 * import com.pulumi.databricks.MwsStorageConfigurations;
 * import com.pulumi.databricks.MwsStorageConfigurationsArgs;
 * import com.pulumi.databricks.MwsNetworks;
 * import com.pulumi.databricks.MwsNetworksArgs;
 * import com.pulumi.databricks.MwsWorkspaces;
 * import com.pulumi.databricks.MwsWorkspacesArgs;
 * import java.util.List;
 * import java.util.ArrayList;
 * import java.util.Map;
 * import java.io.File;
 * import java.nio.file.Files;
 * import java.nio.file.Paths;
 * 
 * public class App {
 *     public static void main(String[] args) {
 *         Pulumi.run(App::stack);
 *     }
 * 
 *     public static void stack(Context ctx) {
 *         final var config = ctx.config();
 *         final var databricksAccountId = config.get("databricksAccountId");
 *         // register cross-account ARN
 *         var this_ = new MwsCredentials("this", MwsCredentialsArgs.builder()
 *             .accountId(databricksAccountId)
 *             .credentialsName(String.format("%s-creds", prefix))
 *             .roleArn(crossaccountArn)
 *             .build());
 * 
 *         // register root bucket
 *         var thisMwsStorageConfigurations = new MwsStorageConfigurations("thisMwsStorageConfigurations", MwsStorageConfigurationsArgs.builder()
 *             .accountId(databricksAccountId)
 *             .storageConfigurationName(String.format("%s-storage", prefix))
 *             .bucketName(rootBucket)
 *             .build());
 * 
 *         // register VPC
 *         var thisMwsNetworks = new MwsNetworks("thisMwsNetworks", MwsNetworksArgs.builder()
 *             .accountId(databricksAccountId)
 *             .networkName(String.format("%s-network", prefix))
 *             .vpcId(vpcId)
 *             .subnetIds(subnetsPrivate)
 *             .securityGroupIds(securityGroup)
 *             .build());
 * 
 *         // create workspace in given VPC with DBFS on root bucket
 *         var thisMwsWorkspaces = new MwsWorkspaces("thisMwsWorkspaces", MwsWorkspacesArgs.builder()
 *             .accountId(databricksAccountId)
 *             .workspaceName(prefix)
 *             .awsRegion(region)
 *             .credentialsId(this_.credentialsId())
 *             .storageConfigurationId(thisMwsStorageConfigurations.storageConfigurationId())
 *             .networkId(thisMwsNetworks.networkId())
 *             .build());
 * 
 *     }
 * }
 * }
 * </pre>
 * 
 * ### Creating a workspace on AWS with Databricks-Managed VPC
 * 
 * ![VPCs](https://docs.databricks.com/_images/customer-managed-vpc.png)
 * 
 * By default, Databricks creates a VPC in your AWS account for each workspace. Databricks uses it for running clusters in the workspace. Optionally, you can use your VPC for the workspace, using the feature customer-managed VPC. Databricks recommends that you provide your VPC with databricks.MwsNetworks so that you can configure it according to your organization&#39;s enterprise cloud standards while still conforming to Databricks requirements. You cannot migrate an existing workspace to your VPC. Please see the difference described through IAM policy actions [on this page](https://docs.databricks.com/administration-guide/account-api/iam-role.html).
 * 
 * <pre>
 * {@code
 * package generated_program;
 * 
 * import com.pulumi.Context;
 * import com.pulumi.Pulumi;
 * import com.pulumi.core.Output;
 * import com.pulumi.random.String;
 * import com.pulumi.random.StringArgs;
 * import com.pulumi.databricks.DatabricksFunctions;
 * import com.pulumi.databricks.inputs.GetAwsAssumeRolePolicyArgs;
 * import com.pulumi.aws.IamRole;
 * import com.pulumi.aws.IamRoleArgs;
 * import com.pulumi.databricks.inputs.GetAwsCrossAccountPolicyArgs;
 * import com.pulumi.aws.IamRolePolicy;
 * import com.pulumi.aws.IamRolePolicyArgs;
 * import com.pulumi.databricks.MwsCredentials;
 * import com.pulumi.databricks.MwsCredentialsArgs;
 * import com.pulumi.aws.S3Bucket;
 * import com.pulumi.aws.S3BucketArgs;
 * import com.pulumi.aws.S3BucketVersioning;
 * import com.pulumi.aws.S3BucketVersioningArgs;
 * import com.pulumi.aws.S3BucketServerSideEncryptionConfiguration;
 * import com.pulumi.aws.S3BucketServerSideEncryptionConfigurationArgs;
 * import com.pulumi.aws.S3BucketPublicAccessBlock;
 * import com.pulumi.aws.S3BucketPublicAccessBlockArgs;
 * import com.pulumi.databricks.inputs.GetAwsBucketPolicyArgs;
 * import com.pulumi.aws.S3BucketPolicy;
 * import com.pulumi.aws.S3BucketPolicyArgs;
 * import com.pulumi.databricks.MwsStorageConfigurations;
 * import com.pulumi.databricks.MwsStorageConfigurationsArgs;
 * import com.pulumi.databricks.MwsWorkspaces;
 * import com.pulumi.databricks.MwsWorkspacesArgs;
 * import com.pulumi.resources.CustomResourceOptions;
 * import java.util.List;
 * import java.util.ArrayList;
 * import java.util.Map;
 * import java.io.File;
 * import java.nio.file.Files;
 * import java.nio.file.Paths;
 * 
 * public class App {
 *     public static void main(java.lang.String[] args) {
 *         Pulumi.run(App::stack);
 *     }
 * 
 *     public static void stack(Context ctx) {
 *         final var config = ctx.config();
 *         final var databricksAccountId = config.get("databricksAccountId");
 *         var naming = new String("naming", StringArgs.builder()
 *             .special(false)
 *             .upper(false)
 *             .length(6)
 *             .build());
 * 
 *         final var prefix = String.format("dltp%s", naming.result());
 * 
 *         final var this = DatabricksFunctions.getAwsAssumeRolePolicy(GetAwsAssumeRolePolicyArgs.builder()
 *             .externalId(databricksAccountId)
 *             .build());
 * 
 *         var crossAccountRole = new IamRole("crossAccountRole", IamRoleArgs.builder()
 *             .name(String.format("%s-crossaccount", prefix))
 *             .assumeRolePolicy(this_.json())
 *             .tags(tags)
 *             .build());
 * 
 *         final var thisGetAwsCrossAccountPolicy = DatabricksFunctions.getAwsCrossAccountPolicy(GetAwsCrossAccountPolicyArgs.builder()
 *             .build());
 * 
 *         var thisIamRolePolicy = new IamRolePolicy("thisIamRolePolicy", IamRolePolicyArgs.builder()
 *             .name(String.format("%s-policy", prefix))
 *             .role(crossAccountRole.id())
 *             .policy(thisGetAwsCrossAccountPolicy.json())
 *             .build());
 * 
 *         var thisMwsCredentials = new MwsCredentials("thisMwsCredentials", MwsCredentialsArgs.builder()
 *             .accountId(databricksAccountId)
 *             .credentialsName(String.format("%s-creds", prefix))
 *             .roleArn(crossAccountRole.arn())
 *             .build());
 * 
 *         var rootStorageBucket = new S3Bucket("rootStorageBucket", S3BucketArgs.builder()
 *             .bucket(String.format("%s-rootbucket", prefix))
 *             .acl("private")
 *             .forceDestroy(true)
 *             .tags(tags)
 *             .build());
 * 
 *         var rootVersioning = new S3BucketVersioning("rootVersioning", S3BucketVersioningArgs.builder()
 *             .bucket(rootStorageBucket.id())
 *             .versioningConfiguration(List.of(Map.of("status", "Disabled")))
 *             .build());
 * 
 *         var rootStorageBucketS3BucketServerSideEncryptionConfiguration = new S3BucketServerSideEncryptionConfiguration("rootStorageBucketS3BucketServerSideEncryptionConfiguration", S3BucketServerSideEncryptionConfigurationArgs.builder()
 *             .bucket(rootStorageBucket.bucket())
 *             .rule(List.of(Map.of("applyServerSideEncryptionByDefault", List.of(Map.of("sseAlgorithm", "AES256")))))
 *             .build());
 * 
 *         var rootStorageBucketS3BucketPublicAccessBlock = new S3BucketPublicAccessBlock("rootStorageBucketS3BucketPublicAccessBlock", S3BucketPublicAccessBlockArgs.builder()
 *             .bucket(rootStorageBucket.id())
 *             .blockPublicAcls(true)
 *             .blockPublicPolicy(true)
 *             .ignorePublicAcls(true)
 *             .restrictPublicBuckets(true)
 *             .build(), CustomResourceOptions.builder()
 *                 .dependsOn(List.of(rootStorageBucket))
 *                 .build());
 * 
 *         final var thisGetAwsBucketPolicy = DatabricksFunctions.getAwsBucketPolicy(GetAwsBucketPolicyArgs.builder()
 *             .bucket(rootStorageBucket.bucket())
 *             .build());
 * 
 *         var rootBucketPolicy = new S3BucketPolicy("rootBucketPolicy", S3BucketPolicyArgs.builder()
 *             .bucket(rootStorageBucket.id())
 *             .policy(thisGetAwsBucketPolicy.json())
 *             .build(), CustomResourceOptions.builder()
 *                 .dependsOn(List.of(rootStorageBucketS3BucketPublicAccessBlock))
 *                 .build());
 * 
 *         var thisMwsStorageConfigurations = new MwsStorageConfigurations("thisMwsStorageConfigurations", MwsStorageConfigurationsArgs.builder()
 *             .accountId(databricksAccountId)
 *             .storageConfigurationName(String.format("%s-storage", prefix))
 *             .bucketName(rootStorageBucket.bucket())
 *             .build());
 * 
 *         var thisMwsWorkspaces = new MwsWorkspaces("thisMwsWorkspaces", MwsWorkspacesArgs.builder()
 *             .accountId(databricksAccountId)
 *             .workspaceName(prefix)
 *             .awsRegion("us-east-1")
 *             .credentialsId(thisMwsCredentials.credentialsId())
 *             .storageConfigurationId(thisMwsStorageConfigurations.storageConfigurationId())
 *             .customTags(Map.of("SoldToCode", "1234"))
 *             .build());
 * 
 *     }
 * }
 * }
 * </pre>
 * 
 * In order to create a [Databricks Workspace that leverages AWS PrivateLink](https://docs.databricks.com/administration-guide/cloud-configurations/aws/privatelink.html) please ensure that you have read and understood the [Enable Private Link](https://docs.databricks.com/administration-guide/cloud-configurations/aws/privatelink.html) documentation and then customise the example above with the relevant examples from mws_vpc_endpoint, mwsPrivateAccessSettings and mws_networks.
 * 
 * ### Creating a workspace on GCP
 * 
 * To get workspace running, you have to configure a network object:
 * 
 * * databricks.MwsNetworks - (optional, but recommended) You can share one [customer-managed VPC](https://docs.gcp.databricks.com/administration-guide/cloud-configurations/gcp/customer-managed-vpc.html) with multiple workspaces in a single account. You do not have to create a new VPC for each workspace. However, you cannot reuse subnets with other resources, including other workspaces or non-Databricks resources. If you plan to share one VPC with multiple workspaces, be sure to size your VPC and subnets accordingly. Because a Databricks databricks.MwsNetworks encapsulates this information, you cannot reuse it across workspaces.
 * 
 * <pre>
 * {@code
 * package generated_program;
 * 
 * import com.pulumi.Context;
 * import com.pulumi.Pulumi;
 * import com.pulumi.core.Output;
 * import com.pulumi.databricks.MwsNetworks;
 * import com.pulumi.databricks.MwsNetworksArgs;
 * import com.pulumi.databricks.inputs.MwsNetworksGcpNetworkInfoArgs;
 * import com.pulumi.databricks.MwsWorkspaces;
 * import com.pulumi.databricks.MwsWorkspacesArgs;
 * import com.pulumi.databricks.inputs.MwsWorkspacesCloudResourceContainerArgs;
 * import com.pulumi.databricks.inputs.MwsWorkspacesCloudResourceContainerGcpArgs;
 * import java.util.List;
 * import java.util.ArrayList;
 * import java.util.Map;
 * import java.io.File;
 * import java.nio.file.Files;
 * import java.nio.file.Paths;
 * 
 * public class App {
 *     public static void main(String[] args) {
 *         Pulumi.run(App::stack);
 *     }
 * 
 *     public static void stack(Context ctx) {
 *         final var config = ctx.config();
 *         final var databricksAccountId = config.get("databricksAccountId");
 *         final var databricksGoogleServiceAccount = config.get("databricksGoogleServiceAccount");
 *         final var googleProject = config.get("googleProject");
 *         // register VPC
 *         var this_ = new MwsNetworks("this", MwsNetworksArgs.builder()
 *             .accountId(databricksAccountId)
 *             .networkName(String.format("%s-network", prefix))
 *             .gcpNetworkInfo(MwsNetworksGcpNetworkInfoArgs.builder()
 *                 .networkProjectId(googleProject)
 *                 .vpcId(vpcId)
 *                 .subnetId(subnetId)
 *                 .subnetRegion(subnetRegion)
 *                 .podIpRangeName("pods")
 *                 .serviceIpRangeName("svc")
 *                 .build())
 *             .build());
 * 
 *         // create workspace in given VPC
 *         var thisMwsWorkspaces = new MwsWorkspaces("thisMwsWorkspaces", MwsWorkspacesArgs.builder()
 *             .accountId(databricksAccountId)
 *             .workspaceName(prefix)
 *             .location(subnetRegion)
 *             .cloudResourceContainer(MwsWorkspacesCloudResourceContainerArgs.builder()
 *                 .gcp(MwsWorkspacesCloudResourceContainerGcpArgs.builder()
 *                     .projectId(googleProject)
 *                     .build())
 *                 .build())
 *             .networkId(this_.networkId())
 *             .build());
 * 
 *     }
 * }
 * }
 * </pre>
 * 
 * In order to create a [Databricks Workspace that leverages GCP Private Service Connect](https://docs.gcp.databricks.com/administration-guide/cloud-configurations/gcp/private-service-connect.html) please ensure that you have read and understood the [Enable Private Service Connect](https://docs.gcp.databricks.com/administration-guide/cloud-configurations/gcp/private-service-connect.html) documentation and then customise the example above with the relevant examples from mws_vpc_endpoint, mwsPrivateAccessSettings and mws_networks.
 * 
 * ## Import
 * 
 * This resource can be imported by Databricks account ID and workspace ID.
 * 
 * hcl
 * 
 * import {
 * 
 *   to = databricks_mws_workspaces.this
 * 
 *   id = &#34;&lt;account_id&gt;/&lt;workspace_id&gt;&#34;
 * 
 * }
 * 
 * Alternatively, when using `terraform` version 1.4 or earlier, import using the `pulumi import` command:
 * 
 * bash
 * 
 * ```sh
 * $ pulumi import databricks:index/mwsWorkspaces:MwsWorkspaces this &#34;&lt;account_id&gt;/&lt;workspace_id&gt;&#34;
 * ```
 * 
 * ~&gt; Not all fields of `databricks_mws_workspaces` can be updated without causing the workspace to be recreated.
 * 
 *    If the configuration for these immutable fields does not match the existing workspace, the workspace will
 * 
 *    be deleted and recreated in the next `pulumi up`. After importing, verify that the configuration
 * 
 *    matches the existing resource by running `pulumi preview`. The only fields that can be updated are
 * 
 *    `credentials_id`, `network_id`, `storage_customer_managed_key_id`, `private_access_settings_id`,
 * 
 *    `managed_services_customer_managed_key_id`, and `custom_tags`.
 * 
 */
@ResourceType(type="databricks:index/mwsWorkspaces:MwsWorkspaces")
public class MwsWorkspaces extends com.pulumi.resources.CustomResource {
    /**
     * Account Id that could be found in the top right corner of [Accounts Console](https://accounts.cloud.databricks.com/).
     * 
     */
    @Export(name="accountId", refs={String.class}, tree="[0]")
    private Output<String> accountId;

    /**
     * @return Account Id that could be found in the top right corner of [Accounts Console](https://accounts.cloud.databricks.com/).
     * 
     */
    public Output<String> accountId() {
        return this.accountId;
    }
    /**
     * region of VPC.
     * 
     */
    @Export(name="awsRegion", refs={String.class}, tree="[0]")
    private Output</* @Nullable */ String> awsRegion;

    /**
     * @return region of VPC.
     * 
     */
    public Output<Optional<String>> awsRegion() {
        return Codegen.optional(this.awsRegion);
    }
    @Export(name="cloud", refs={String.class}, tree="[0]")
    private Output<String> cloud;

    public Output<String> cloud() {
        return this.cloud;
    }
    /**
     * A block that specifies GCP workspace configurations, consisting of following blocks:
     * 
     */
    @Export(name="cloudResourceContainer", refs={MwsWorkspacesCloudResourceContainer.class}, tree="[0]")
    private Output</* @Nullable */ MwsWorkspacesCloudResourceContainer> cloudResourceContainer;

    /**
     * @return A block that specifies GCP workspace configurations, consisting of following blocks:
     * 
     */
    public Output<Optional<MwsWorkspacesCloudResourceContainer>> cloudResourceContainer() {
        return Codegen.optional(this.cloudResourceContainer);
    }
    /**
     * The compute mode for the workspace. When unset, a classic workspace is created, and both `credentialsId` and `storageConfigurationId` must be specified. When set to `SERVERLESS`, the resulting workspace is a serverless workspace, and `credentialsId` and `storageConfigurationId` must not be set. The only allowed value for this is `SERVERLESS`. Changing this field requires recreation of the workspace.
     * 
     */
    @Export(name="computeMode", refs={String.class}, tree="[0]")
    private Output</* @Nullable */ String> computeMode;

    /**
     * @return The compute mode for the workspace. When unset, a classic workspace is created, and both `credentialsId` and `storageConfigurationId` must be specified. When set to `SERVERLESS`, the resulting workspace is a serverless workspace, and `credentialsId` and `storageConfigurationId` must not be set. The only allowed value for this is `SERVERLESS`. Changing this field requires recreation of the workspace.
     * 
     */
    public Output<Optional<String>> computeMode() {
        return Codegen.optional(this.computeMode);
    }
    /**
     * (Integer) time when workspace was created
     * 
     */
    @Export(name="creationTime", refs={Integer.class}, tree="[0]")
    private Output<Integer> creationTime;

    /**
     * @return (Integer) time when workspace was created
     * 
     */
    public Output<Integer> creationTime() {
        return this.creationTime;
    }
    /**
     * `credentialsId` from credentials. This must not be specified when `computeMode` is set to `SERVERLESS`.
     * 
     */
    @Export(name="credentialsId", refs={String.class}, tree="[0]")
    private Output</* @Nullable */ String> credentialsId;

    /**
     * @return `credentialsId` from credentials. This must not be specified when `computeMode` is set to `SERVERLESS`.
     * 
     */
    public Output<Optional<String>> credentialsId() {
        return Codegen.optional(this.credentialsId);
    }
    /**
     * The custom tags key-value pairing that is attached to this workspace. These tags will be applied to clusters automatically in addition to any `defaultTags` or `customTags` on a cluster level. Please note it can take up to an hour for customTags to be set due to scheduling on Control Plane. After custom tags are applied, they can be modified however they can never be completely removed.
     * 
     */
    @Export(name="customTags", refs={Map.class,String.class}, tree="[0,1,1]")
    private Output</* @Nullable */ Map<String,String>> customTags;

    /**
     * @return The custom tags key-value pairing that is attached to this workspace. These tags will be applied to clusters automatically in addition to any `defaultTags` or `customTags` on a cluster level. Please note it can take up to an hour for customTags to be set due to scheduling on Control Plane. After custom tags are applied, they can be modified however they can never be completely removed.
     * 
     */
    public Output<Optional<Map<String,String>>> customTags() {
        return Codegen.optional(this.customTags);
    }
    /**
     * @deprecated
     * Use managedServicesCustomerManagedKeyId instead
     * 
     */
    @Deprecated /* Use managedServicesCustomerManagedKeyId instead */
    @Export(name="customerManagedKeyId", refs={String.class}, tree="[0]")
    private Output</* @Nullable */ String> customerManagedKeyId;

    public Output<Optional<String>> customerManagedKeyId() {
        return Codegen.optional(this.customerManagedKeyId);
    }
    /**
     * part of URL as in `https://&lt;prefix&gt;-&lt;deployment-name&gt;.cloud.databricks.com`. Deployment name cannot be used until a deployment name prefix is defined. Please contact your Databricks representative. Once a new deployment prefix is added/updated, it only will affect the new workspaces created.
     * 
     */
    @Export(name="deploymentName", refs={String.class}, tree="[0]")
    private Output</* @Nullable */ String> deploymentName;

    /**
     * @return part of URL as in `https://&lt;prefix&gt;-&lt;deployment-name&gt;.cloud.databricks.com`. Deployment name cannot be used until a deployment name prefix is defined. Please contact your Databricks representative. Once a new deployment prefix is added/updated, it only will affect the new workspaces created.
     * 
     */
    public Output<Optional<String>> deploymentName() {
        return Codegen.optional(this.deploymentName);
    }
    /**
     * (String) The effective compute mode for the workspace. This is either `SERVERLESS` for serverless workspaces or `HYBRID` for classic workspaces.
     * 
     */
    @Export(name="effectiveComputeMode", refs={String.class}, tree="[0]")
    private Output<String> effectiveComputeMode;

    /**
     * @return (String) The effective compute mode for the workspace. This is either `SERVERLESS` for serverless workspaces or `HYBRID` for classic workspaces.
     * 
     */
    public Output<String> effectiveComputeMode() {
        return this.effectiveComputeMode;
    }
    /**
     * The expected status of the workspace. When unset, it defaults to `RUNNING`. When set to `PROVISIONING`, workspace provisioning will pause and not enter `RUNNING` status. The only allowed values for this is `RUNNING` and `PROVISIONING`.
     * 
     * &gt; Databricks strongly recommends using OAuth instead of PATs for user account client authentication and authorization due to the improved security
     * 
     */
    @Export(name="expectedWorkspaceStatus", refs={String.class}, tree="[0]")
    private Output</* @Nullable */ String> expectedWorkspaceStatus;

    /**
     * @return The expected status of the workspace. When unset, it defaults to `RUNNING`. When set to `PROVISIONING`, workspace provisioning will pause and not enter `RUNNING` status. The only allowed values for this is `RUNNING` and `PROVISIONING`.
     * 
     * &gt; Databricks strongly recommends using OAuth instead of PATs for user account client authentication and authorization due to the improved security
     * 
     */
    public Output<Optional<String>> expectedWorkspaceStatus() {
        return Codegen.optional(this.expectedWorkspaceStatus);
    }
    @Export(name="externalCustomerInfo", refs={MwsWorkspacesExternalCustomerInfo.class}, tree="[0]")
    private Output</* @Nullable */ MwsWorkspacesExternalCustomerInfo> externalCustomerInfo;

    public Output<Optional<MwsWorkspacesExternalCustomerInfo>> externalCustomerInfo() {
        return Codegen.optional(this.externalCustomerInfo);
    }
    @Export(name="gcpManagedNetworkConfig", refs={MwsWorkspacesGcpManagedNetworkConfig.class}, tree="[0]")
    private Output</* @Nullable */ MwsWorkspacesGcpManagedNetworkConfig> gcpManagedNetworkConfig;

    public Output<Optional<MwsWorkspacesGcpManagedNetworkConfig>> gcpManagedNetworkConfig() {
        return Codegen.optional(this.gcpManagedNetworkConfig);
    }
    /**
     * (String, GCP only) identifier of a service account created for the workspace in form of `db-&lt;workspace-id&gt;{@literal @}prod-gcp-&lt;region&gt;.iam.gserviceaccount.com`
     * 
     */
    @Export(name="gcpWorkspaceSa", refs={String.class}, tree="[0]")
    private Output<String> gcpWorkspaceSa;

    /**
     * @return (String, GCP only) identifier of a service account created for the workspace in form of `db-&lt;workspace-id&gt;{@literal @}prod-gcp-&lt;region&gt;.iam.gserviceaccount.com`
     * 
     */
    public Output<String> gcpWorkspaceSa() {
        return this.gcpWorkspaceSa;
    }
    /**
     * @deprecated
     * gke_config is deprecated and will be removed in a future release. For more information, review the documentation at https://registry.terraform.io/providers/databricks/databricks/1.104.0/docs/guides/gcp-workspace#creating-a-databricks-workspace
     * 
     */
    @Deprecated /* gke_config is deprecated and will be removed in a future release. For more information, review the documentation at https://registry.terraform.io/providers/databricks/databricks/1.104.0/docs/guides/gcp-workspace#creating-a-databricks-workspace */
    @Export(name="gkeConfig", refs={MwsWorkspacesGkeConfig.class}, tree="[0]")
    private Output</* @Nullable */ MwsWorkspacesGkeConfig> gkeConfig;

    public Output<Optional<MwsWorkspacesGkeConfig>> gkeConfig() {
        return Codegen.optional(this.gkeConfig);
    }
    @Export(name="isNoPublicIpEnabled", refs={Boolean.class}, tree="[0]")
    private Output</* @Nullable */ Boolean> isNoPublicIpEnabled;

    public Output<Optional<Boolean>> isNoPublicIpEnabled() {
        return Codegen.optional(this.isNoPublicIpEnabled);
    }
    /**
     * region of the subnet.
     * 
     */
    @Export(name="location", refs={String.class}, tree="[0]")
    private Output</* @Nullable */ String> location;

    /**
     * @return region of the subnet.
     * 
     */
    public Output<Optional<String>> location() {
        return Codegen.optional(this.location);
    }
    /**
     * `customerManagedKeyId` from customer managed keys with `useCases` set to `MANAGED_SERVICES`. This is used to encrypt the workspace&#39;s notebook and secret data in the control plane.
     * 
     */
    @Export(name="managedServicesCustomerManagedKeyId", refs={String.class}, tree="[0]")
    private Output</* @Nullable */ String> managedServicesCustomerManagedKeyId;

    /**
     * @return `customerManagedKeyId` from customer managed keys with `useCases` set to `MANAGED_SERVICES`. This is used to encrypt the workspace&#39;s notebook and secret data in the control plane.
     * 
     */
    public Output<Optional<String>> managedServicesCustomerManagedKeyId() {
        return Codegen.optional(this.managedServicesCustomerManagedKeyId);
    }
    @Export(name="networkConnectivityConfigId", refs={String.class}, tree="[0]")
    private Output<String> networkConnectivityConfigId;

    public Output<String> networkConnectivityConfigId() {
        return this.networkConnectivityConfigId;
    }
    /**
     * `networkId` from networks.
     * 
     */
    @Export(name="networkId", refs={String.class}, tree="[0]")
    private Output</* @Nullable */ String> networkId;

    /**
     * @return `networkId` from networks.
     * 
     */
    public Output<Optional<String>> networkId() {
        return Codegen.optional(this.networkId);
    }
    /**
     * The pricing tier of the workspace.
     * 
     */
    @Export(name="pricingTier", refs={String.class}, tree="[0]")
    private Output<String> pricingTier;

    /**
     * @return The pricing tier of the workspace.
     * 
     */
    public Output<String> pricingTier() {
        return this.pricingTier;
    }
    /**
     * Canonical unique identifier of databricks.MwsPrivateAccessSettings in Databricks Account.
     * 
     */
    @Export(name="privateAccessSettingsId", refs={String.class}, tree="[0]")
    private Output</* @Nullable */ String> privateAccessSettingsId;

    /**
     * @return Canonical unique identifier of databricks.MwsPrivateAccessSettings in Databricks Account.
     * 
     */
    public Output<Optional<String>> privateAccessSettingsId() {
        return Codegen.optional(this.privateAccessSettingsId);
    }
    /**
     * `storageConfigurationId` from storage configuration. This must not be specified when `computeMode` is set to `SERVERLESS`.
     * 
     */
    @Export(name="storageConfigurationId", refs={String.class}, tree="[0]")
    private Output</* @Nullable */ String> storageConfigurationId;

    /**
     * @return `storageConfigurationId` from storage configuration. This must not be specified when `computeMode` is set to `SERVERLESS`.
     * 
     */
    public Output<Optional<String>> storageConfigurationId() {
        return Codegen.optional(this.storageConfigurationId);
    }
    /**
     * `customerManagedKeyId` from customer managed keys with `useCases` set to `STORAGE`. This is used to encrypt the DBFS Storage &amp; Cluster Volumes.
     * 
     */
    @Export(name="storageCustomerManagedKeyId", refs={String.class}, tree="[0]")
    private Output</* @Nullable */ String> storageCustomerManagedKeyId;

    /**
     * @return `customerManagedKeyId` from customer managed keys with `useCases` set to `STORAGE`. This is used to encrypt the DBFS Storage &amp; Cluster Volumes.
     * 
     */
    public Output<Optional<String>> storageCustomerManagedKeyId() {
        return Codegen.optional(this.storageCustomerManagedKeyId);
    }
    @Export(name="token", refs={MwsWorkspacesToken.class}, tree="[0]")
    private Output</* @Nullable */ MwsWorkspacesToken> token;

    public Output<Optional<MwsWorkspacesToken>> token() {
        return Codegen.optional(this.token);
    }
    /**
     * (String) workspace id
     * 
     */
    @Export(name="workspaceId", refs={String.class}, tree="[0]")
    private Output<String> workspaceId;

    /**
     * @return (String) workspace id
     * 
     */
    public Output<String> workspaceId() {
        return this.workspaceId;
    }
    /**
     * name of the workspace, will appear on UI.
     * 
     */
    @Export(name="workspaceName", refs={String.class}, tree="[0]")
    private Output<String> workspaceName;

    /**
     * @return name of the workspace, will appear on UI.
     * 
     */
    public Output<String> workspaceName() {
        return this.workspaceName;
    }
    /**
     * (String) workspace status
     * 
     */
    @Export(name="workspaceStatus", refs={String.class}, tree="[0]")
    private Output<String> workspaceStatus;

    /**
     * @return (String) workspace status
     * 
     */
    public Output<String> workspaceStatus() {
        return this.workspaceStatus;
    }
    /**
     * (String) updates on workspace status
     * 
     */
    @Export(name="workspaceStatusMessage", refs={String.class}, tree="[0]")
    private Output<String> workspaceStatusMessage;

    /**
     * @return (String) updates on workspace status
     * 
     */
    public Output<String> workspaceStatusMessage() {
        return this.workspaceStatusMessage;
    }
    /**
     * (String) URL of the workspace
     * 
     */
    @Export(name="workspaceUrl", refs={String.class}, tree="[0]")
    private Output<String> workspaceUrl;

    /**
     * @return (String) URL of the workspace
     * 
     */
    public Output<String> workspaceUrl() {
        return this.workspaceUrl;
    }

    /**
     *
     * @param name The _unique_ name of the resulting resource.
     */
    public MwsWorkspaces(java.lang.String name) {
        this(name, MwsWorkspacesArgs.Empty);
    }
    /**
     *
     * @param name The _unique_ name of the resulting resource.
     * @param args The arguments to use to populate this resource's properties.
     */
    public MwsWorkspaces(java.lang.String name, MwsWorkspacesArgs args) {
        this(name, args, null);
    }
    /**
     *
     * @param name The _unique_ name of the resulting resource.
     * @param args The arguments to use to populate this resource's properties.
     * @param options A bag of options that control this resource's behavior.
     */
    public MwsWorkspaces(java.lang.String name, MwsWorkspacesArgs args, @Nullable com.pulumi.resources.CustomResourceOptions options) {
        super("databricks:index/mwsWorkspaces:MwsWorkspaces", name, makeArgs(args, options), makeResourceOptions(options, Codegen.empty()), false);
    }

    private MwsWorkspaces(java.lang.String name, Output<java.lang.String> id, @Nullable MwsWorkspacesState state, @Nullable com.pulumi.resources.CustomResourceOptions options) {
        super("databricks:index/mwsWorkspaces:MwsWorkspaces", name, state, makeResourceOptions(options, id), false);
    }

    private static MwsWorkspacesArgs makeArgs(MwsWorkspacesArgs args, @Nullable com.pulumi.resources.CustomResourceOptions options) {
        if (options != null && options.getUrn().isPresent()) {
            return null;
        }
        return args == null ? MwsWorkspacesArgs.Empty : args;
    }

    private static com.pulumi.resources.CustomResourceOptions makeResourceOptions(@Nullable com.pulumi.resources.CustomResourceOptions options, @Nullable Output<java.lang.String> id) {
        var defaultOptions = com.pulumi.resources.CustomResourceOptions.builder()
            .version(Utilities.getVersion())
            .additionalSecretOutputs(List.of(
                "accountId"
            ))
            .build();
        return com.pulumi.resources.CustomResourceOptions.merge(defaultOptions, options, id);
    }

    /**
     * Get an existing Host resource's state with the given name, ID, and optional extra
     * properties used to qualify the lookup.
     *
     * @param name The _unique_ name of the resulting resource.
     * @param id The _unique_ provider ID of the resource to lookup.
     * @param state
     * @param options Optional settings to control the behavior of the CustomResource.
     */
    public static MwsWorkspaces get(java.lang.String name, Output<java.lang.String> id, @Nullable MwsWorkspacesState state, @Nullable com.pulumi.resources.CustomResourceOptions options) {
        return new MwsWorkspaces(name, id, state, options);
    }
}
