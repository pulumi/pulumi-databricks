// *** WARNING: this file was generated by pulumi-language-java. ***
// *** Do not edit by hand unless you're certain you know what you are doing! ***

package com.pulumi.databricks.outputs;

import com.pulumi.core.annotations.CustomType;
import com.pulumi.databricks.outputs.ModelServingAiGatewayFallbackConfig;
import com.pulumi.databricks.outputs.ModelServingAiGatewayGuardrails;
import com.pulumi.databricks.outputs.ModelServingAiGatewayInferenceTableConfig;
import com.pulumi.databricks.outputs.ModelServingAiGatewayRateLimit;
import com.pulumi.databricks.outputs.ModelServingAiGatewayUsageTrackingConfig;
import java.util.List;
import java.util.Objects;
import java.util.Optional;
import javax.annotation.Nullable;

@CustomType
public final class ModelServingAiGateway {
    /**
     * @return block with configuration for traffic fallback which auto fallbacks to other served entities if the request to a served entity fails with certain error codes, to increase availability.
     * 
     */
    private @Nullable ModelServingAiGatewayFallbackConfig fallbackConfig;
    /**
     * @return Block with configuration for AI Guardrails to prevent unwanted data and unsafe data in requests and responses. Consists of the following attributes:
     * 
     */
    private @Nullable ModelServingAiGatewayGuardrails guardrails;
    /**
     * @return Block describing the configuration of usage tracking. Consists of the following attributes:
     * 
     */
    private @Nullable ModelServingAiGatewayInferenceTableConfig inferenceTableConfig;
    /**
     * @return Block describing rate limits for AI gateway. For details see the description of `rateLimits` block above.
     * 
     */
    private @Nullable List<ModelServingAiGatewayRateLimit> rateLimits;
    /**
     * @return Block with configuration for payload logging using inference tables. For details see the description of `autoCaptureConfig` block above.
     * 
     */
    private @Nullable ModelServingAiGatewayUsageTrackingConfig usageTrackingConfig;

    private ModelServingAiGateway() {}
    /**
     * @return block with configuration for traffic fallback which auto fallbacks to other served entities if the request to a served entity fails with certain error codes, to increase availability.
     * 
     */
    public Optional<ModelServingAiGatewayFallbackConfig> fallbackConfig() {
        return Optional.ofNullable(this.fallbackConfig);
    }
    /**
     * @return Block with configuration for AI Guardrails to prevent unwanted data and unsafe data in requests and responses. Consists of the following attributes:
     * 
     */
    public Optional<ModelServingAiGatewayGuardrails> guardrails() {
        return Optional.ofNullable(this.guardrails);
    }
    /**
     * @return Block describing the configuration of usage tracking. Consists of the following attributes:
     * 
     */
    public Optional<ModelServingAiGatewayInferenceTableConfig> inferenceTableConfig() {
        return Optional.ofNullable(this.inferenceTableConfig);
    }
    /**
     * @return Block describing rate limits for AI gateway. For details see the description of `rateLimits` block above.
     * 
     */
    public List<ModelServingAiGatewayRateLimit> rateLimits() {
        return this.rateLimits == null ? List.of() : this.rateLimits;
    }
    /**
     * @return Block with configuration for payload logging using inference tables. For details see the description of `autoCaptureConfig` block above.
     * 
     */
    public Optional<ModelServingAiGatewayUsageTrackingConfig> usageTrackingConfig() {
        return Optional.ofNullable(this.usageTrackingConfig);
    }

    public static Builder builder() {
        return new Builder();
    }

    public static Builder builder(ModelServingAiGateway defaults) {
        return new Builder(defaults);
    }
    @CustomType.Builder
    public static final class Builder {
        private @Nullable ModelServingAiGatewayFallbackConfig fallbackConfig;
        private @Nullable ModelServingAiGatewayGuardrails guardrails;
        private @Nullable ModelServingAiGatewayInferenceTableConfig inferenceTableConfig;
        private @Nullable List<ModelServingAiGatewayRateLimit> rateLimits;
        private @Nullable ModelServingAiGatewayUsageTrackingConfig usageTrackingConfig;
        public Builder() {}
        public Builder(ModelServingAiGateway defaults) {
    	      Objects.requireNonNull(defaults);
    	      this.fallbackConfig = defaults.fallbackConfig;
    	      this.guardrails = defaults.guardrails;
    	      this.inferenceTableConfig = defaults.inferenceTableConfig;
    	      this.rateLimits = defaults.rateLimits;
    	      this.usageTrackingConfig = defaults.usageTrackingConfig;
        }

        @CustomType.Setter
        public Builder fallbackConfig(@Nullable ModelServingAiGatewayFallbackConfig fallbackConfig) {

            this.fallbackConfig = fallbackConfig;
            return this;
        }
        @CustomType.Setter
        public Builder guardrails(@Nullable ModelServingAiGatewayGuardrails guardrails) {

            this.guardrails = guardrails;
            return this;
        }
        @CustomType.Setter
        public Builder inferenceTableConfig(@Nullable ModelServingAiGatewayInferenceTableConfig inferenceTableConfig) {

            this.inferenceTableConfig = inferenceTableConfig;
            return this;
        }
        @CustomType.Setter
        public Builder rateLimits(@Nullable List<ModelServingAiGatewayRateLimit> rateLimits) {

            this.rateLimits = rateLimits;
            return this;
        }
        public Builder rateLimits(ModelServingAiGatewayRateLimit... rateLimits) {
            return rateLimits(List.of(rateLimits));
        }
        @CustomType.Setter
        public Builder usageTrackingConfig(@Nullable ModelServingAiGatewayUsageTrackingConfig usageTrackingConfig) {

            this.usageTrackingConfig = usageTrackingConfig;
            return this;
        }
        public ModelServingAiGateway build() {
            final var _resultValue = new ModelServingAiGateway();
            _resultValue.fallbackConfig = fallbackConfig;
            _resultValue.guardrails = guardrails;
            _resultValue.inferenceTableConfig = inferenceTableConfig;
            _resultValue.rateLimits = rateLimits;
            _resultValue.usageTrackingConfig = usageTrackingConfig;
            return _resultValue;
        }
    }
}
