// *** WARNING: this file was generated by pulumi-java-gen. ***
// *** Do not edit by hand unless you're certain you know what you are doing! ***

package com.pulumi.databricks.inputs;

import com.pulumi.core.annotations.Import;
import com.pulumi.databricks.inputs.GetClusterClusterInfoAutoscale;
import com.pulumi.databricks.inputs.GetClusterClusterInfoAwsAttributes;
import com.pulumi.databricks.inputs.GetClusterClusterInfoAzureAttributes;
import com.pulumi.databricks.inputs.GetClusterClusterInfoClusterLogConf;
import com.pulumi.databricks.inputs.GetClusterClusterInfoClusterLogStatus;
import com.pulumi.databricks.inputs.GetClusterClusterInfoDockerImage;
import com.pulumi.databricks.inputs.GetClusterClusterInfoDriver;
import com.pulumi.databricks.inputs.GetClusterClusterInfoExecutor;
import com.pulumi.databricks.inputs.GetClusterClusterInfoGcpAttributes;
import com.pulumi.databricks.inputs.GetClusterClusterInfoInitScript;
import com.pulumi.databricks.inputs.GetClusterClusterInfoTerminationReason;
import com.pulumi.exceptions.MissingRequiredPropertyException;
import java.lang.Boolean;
import java.lang.Double;
import java.lang.Integer;
import java.lang.Object;
import java.lang.String;
import java.util.List;
import java.util.Map;
import java.util.Objects;
import java.util.Optional;
import javax.annotation.Nullable;


public final class GetClusterClusterInfo extends com.pulumi.resources.InvokeArgs {

    public static final GetClusterClusterInfo Empty = new GetClusterClusterInfo();

    @Import(name="autoscale")
    private @Nullable GetClusterClusterInfoAutoscale autoscale;

    public Optional<GetClusterClusterInfoAutoscale> autoscale() {
        return Optional.ofNullable(this.autoscale);
    }

    /**
     * Automatically terminate the cluster after being inactive for this time in minutes. If specified, the threshold must be between 10 and 10000 minutes. You can also set this value to 0 to explicitly disable automatic termination.
     * 
     */
    @Import(name="autoterminationMinutes")
    private @Nullable Integer autoterminationMinutes;

    /**
     * @return Automatically terminate the cluster after being inactive for this time in minutes. If specified, the threshold must be between 10 and 10000 minutes. You can also set this value to 0 to explicitly disable automatic termination.
     * 
     */
    public Optional<Integer> autoterminationMinutes() {
        return Optional.ofNullable(this.autoterminationMinutes);
    }

    @Import(name="awsAttributes")
    private @Nullable GetClusterClusterInfoAwsAttributes awsAttributes;

    public Optional<GetClusterClusterInfoAwsAttributes> awsAttributes() {
        return Optional.ofNullable(this.awsAttributes);
    }

    @Import(name="azureAttributes")
    private @Nullable GetClusterClusterInfoAzureAttributes azureAttributes;

    public Optional<GetClusterClusterInfoAzureAttributes> azureAttributes() {
        return Optional.ofNullable(this.azureAttributes);
    }

    @Import(name="clusterCores")
    private @Nullable Double clusterCores;

    public Optional<Double> clusterCores() {
        return Optional.ofNullable(this.clusterCores);
    }

    /**
     * The id of the cluster
     * 
     */
    @Import(name="clusterId")
    private @Nullable String clusterId;

    /**
     * @return The id of the cluster
     * 
     */
    public Optional<String> clusterId() {
        return Optional.ofNullable(this.clusterId);
    }

    @Import(name="clusterLogConf")
    private @Nullable GetClusterClusterInfoClusterLogConf clusterLogConf;

    public Optional<GetClusterClusterInfoClusterLogConf> clusterLogConf() {
        return Optional.ofNullable(this.clusterLogConf);
    }

    @Import(name="clusterLogStatus")
    private @Nullable GetClusterClusterInfoClusterLogStatus clusterLogStatus;

    public Optional<GetClusterClusterInfoClusterLogStatus> clusterLogStatus() {
        return Optional.ofNullable(this.clusterLogStatus);
    }

    @Import(name="clusterMemoryMb")
    private @Nullable Integer clusterMemoryMb;

    public Optional<Integer> clusterMemoryMb() {
        return Optional.ofNullable(this.clusterMemoryMb);
    }

    /**
     * The exact name of the cluster to search
     * 
     */
    @Import(name="clusterName")
    private @Nullable String clusterName;

    /**
     * @return The exact name of the cluster to search
     * 
     */
    public Optional<String> clusterName() {
        return Optional.ofNullable(this.clusterName);
    }

    @Import(name="clusterSource", required=true)
    private String clusterSource;

    public String clusterSource() {
        return this.clusterSource;
    }

    @Import(name="creatorUserName")
    private @Nullable String creatorUserName;

    public Optional<String> creatorUserName() {
        return Optional.ofNullable(this.creatorUserName);
    }

    /**
     * Additional tags for cluster resources.
     * 
     */
    @Import(name="customTags")
    private @Nullable Map<String,Object> customTags;

    /**
     * @return Additional tags for cluster resources.
     * 
     */
    public Optional<Map<String,Object>> customTags() {
        return Optional.ofNullable(this.customTags);
    }

    /**
     * Security features of the cluster. Unity Catalog requires `SINGLE_USER` or `USER_ISOLATION` mode. `LEGACY_PASSTHROUGH` for passthrough cluster and `LEGACY_TABLE_ACL` for Table ACL cluster. Default to `NONE`, i.e. no security feature enabled.
     * 
     */
    @Import(name="dataSecurityMode")
    private @Nullable String dataSecurityMode;

    /**
     * @return Security features of the cluster. Unity Catalog requires `SINGLE_USER` or `USER_ISOLATION` mode. `LEGACY_PASSTHROUGH` for passthrough cluster and `LEGACY_TABLE_ACL` for Table ACL cluster. Default to `NONE`, i.e. no security feature enabled.
     * 
     */
    public Optional<String> dataSecurityMode() {
        return Optional.ofNullable(this.dataSecurityMode);
    }

    @Import(name="defaultTags", required=true)
    private Map<String,Object> defaultTags;

    public Map<String,Object> defaultTags() {
        return this.defaultTags;
    }

    @Import(name="dockerImage")
    private @Nullable GetClusterClusterInfoDockerImage dockerImage;

    public Optional<GetClusterClusterInfoDockerImage> dockerImage() {
        return Optional.ofNullable(this.dockerImage);
    }

    @Import(name="driver")
    private @Nullable GetClusterClusterInfoDriver driver;

    public Optional<GetClusterClusterInfoDriver> driver() {
        return Optional.ofNullable(this.driver);
    }

    /**
     * similar to `instance_pool_id`, but for driver node.
     * 
     */
    @Import(name="driverInstancePoolId", required=true)
    private String driverInstancePoolId;

    /**
     * @return similar to `instance_pool_id`, but for driver node.
     * 
     */
    public String driverInstancePoolId() {
        return this.driverInstancePoolId;
    }

    /**
     * The node type of the Spark driver.
     * 
     */
    @Import(name="driverNodeTypeId")
    private @Nullable String driverNodeTypeId;

    /**
     * @return The node type of the Spark driver.
     * 
     */
    public Optional<String> driverNodeTypeId() {
        return Optional.ofNullable(this.driverNodeTypeId);
    }

    /**
     * Use autoscaling local storage.
     * 
     */
    @Import(name="enableElasticDisk")
    private @Nullable Boolean enableElasticDisk;

    /**
     * @return Use autoscaling local storage.
     * 
     */
    public Optional<Boolean> enableElasticDisk() {
        return Optional.ofNullable(this.enableElasticDisk);
    }

    /**
     * Enable local disk encryption.
     * 
     */
    @Import(name="enableLocalDiskEncryption")
    private @Nullable Boolean enableLocalDiskEncryption;

    /**
     * @return Enable local disk encryption.
     * 
     */
    public Optional<Boolean> enableLocalDiskEncryption() {
        return Optional.ofNullable(this.enableLocalDiskEncryption);
    }

    @Import(name="executors")
    private @Nullable List<GetClusterClusterInfoExecutor> executors;

    public Optional<List<GetClusterClusterInfoExecutor>> executors() {
        return Optional.ofNullable(this.executors);
    }

    @Import(name="gcpAttributes")
    private @Nullable GetClusterClusterInfoGcpAttributes gcpAttributes;

    public Optional<GetClusterClusterInfoGcpAttributes> gcpAttributes() {
        return Optional.ofNullable(this.gcpAttributes);
    }

    @Import(name="initScripts")
    private @Nullable List<GetClusterClusterInfoInitScript> initScripts;

    public Optional<List<GetClusterClusterInfoInitScript>> initScripts() {
        return Optional.ofNullable(this.initScripts);
    }

    /**
     * The pool of idle instances the cluster is attached to.
     * 
     */
    @Import(name="instancePoolId")
    private @Nullable String instancePoolId;

    /**
     * @return The pool of idle instances the cluster is attached to.
     * 
     */
    public Optional<String> instancePoolId() {
        return Optional.ofNullable(this.instancePoolId);
    }

    @Import(name="jdbcPort")
    private @Nullable Integer jdbcPort;

    public Optional<Integer> jdbcPort() {
        return Optional.ofNullable(this.jdbcPort);
    }

    @Import(name="lastActivityTime")
    private @Nullable Integer lastActivityTime;

    public Optional<Integer> lastActivityTime() {
        return Optional.ofNullable(this.lastActivityTime);
    }

    @Import(name="lastStateLossTime")
    private @Nullable Integer lastStateLossTime;

    public Optional<Integer> lastStateLossTime() {
        return Optional.ofNullable(this.lastStateLossTime);
    }

    /**
     * Any supported databricks.getNodeType id.
     * 
     */
    @Import(name="nodeTypeId")
    private @Nullable String nodeTypeId;

    /**
     * @return Any supported databricks.getNodeType id.
     * 
     */
    public Optional<String> nodeTypeId() {
        return Optional.ofNullable(this.nodeTypeId);
    }

    @Import(name="numWorkers")
    private @Nullable Integer numWorkers;

    public Optional<Integer> numWorkers() {
        return Optional.ofNullable(this.numWorkers);
    }

    /**
     * Identifier of Cluster Policy to validate cluster and preset certain defaults.
     * 
     */
    @Import(name="policyId")
    private @Nullable String policyId;

    /**
     * @return Identifier of Cluster Policy to validate cluster and preset certain defaults.
     * 
     */
    public Optional<String> policyId() {
        return Optional.ofNullable(this.policyId);
    }

    /**
     * The type of runtime of the cluster
     * 
     */
    @Import(name="runtimeEngine")
    private @Nullable String runtimeEngine;

    /**
     * @return The type of runtime of the cluster
     * 
     */
    public Optional<String> runtimeEngine() {
        return Optional.ofNullable(this.runtimeEngine);
    }

    /**
     * The optional user name of the user to assign to an interactive cluster. This field is required when using standard AAD Passthrough for Azure Data Lake Storage (ADLS) with a single-user cluster (i.e., not high-concurrency clusters).
     * 
     */
    @Import(name="singleUserName")
    private @Nullable String singleUserName;

    /**
     * @return The optional user name of the user to assign to an interactive cluster. This field is required when using standard AAD Passthrough for Azure Data Lake Storage (ADLS) with a single-user cluster (i.e., not high-concurrency clusters).
     * 
     */
    public Optional<String> singleUserName() {
        return Optional.ofNullable(this.singleUserName);
    }

    /**
     * Map with key-value pairs to fine-tune Spark clusters.
     * 
     */
    @Import(name="sparkConf")
    private @Nullable Map<String,Object> sparkConf;

    /**
     * @return Map with key-value pairs to fine-tune Spark clusters.
     * 
     */
    public Optional<Map<String,Object>> sparkConf() {
        return Optional.ofNullable(this.sparkConf);
    }

    @Import(name="sparkContextId")
    private @Nullable Integer sparkContextId;

    public Optional<Integer> sparkContextId() {
        return Optional.ofNullable(this.sparkContextId);
    }

    /**
     * Map with environment variable key-value pairs to fine-tune Spark clusters. Key-value pairs of the form (X,Y) are exported (i.e., X=&#39;Y&#39;) while launching the driver and workers.
     * 
     */
    @Import(name="sparkEnvVars")
    private @Nullable Map<String,Object> sparkEnvVars;

    /**
     * @return Map with environment variable key-value pairs to fine-tune Spark clusters. Key-value pairs of the form (X,Y) are exported (i.e., X=&#39;Y&#39;) while launching the driver and workers.
     * 
     */
    public Optional<Map<String,Object>> sparkEnvVars() {
        return Optional.ofNullable(this.sparkEnvVars);
    }

    /**
     * [Runtime version](https://docs.databricks.com/runtime/index.html) of the cluster.
     * 
     */
    @Import(name="sparkVersion", required=true)
    private String sparkVersion;

    /**
     * @return [Runtime version](https://docs.databricks.com/runtime/index.html) of the cluster.
     * 
     */
    public String sparkVersion() {
        return this.sparkVersion;
    }

    /**
     * SSH public key contents that will be added to each Spark node in this cluster.
     * 
     */
    @Import(name="sshPublicKeys")
    private @Nullable List<String> sshPublicKeys;

    /**
     * @return SSH public key contents that will be added to each Spark node in this cluster.
     * 
     */
    public Optional<List<String>> sshPublicKeys() {
        return Optional.ofNullable(this.sshPublicKeys);
    }

    @Import(name="startTime")
    private @Nullable Integer startTime;

    public Optional<Integer> startTime() {
        return Optional.ofNullable(this.startTime);
    }

    @Import(name="state", required=true)
    private String state;

    public String state() {
        return this.state;
    }

    @Import(name="stateMessage")
    private @Nullable String stateMessage;

    public Optional<String> stateMessage() {
        return Optional.ofNullable(this.stateMessage);
    }

    @Import(name="terminateTime")
    private @Nullable Integer terminateTime;

    public Optional<Integer> terminateTime() {
        return Optional.ofNullable(this.terminateTime);
    }

    @Import(name="terminationReason")
    private @Nullable GetClusterClusterInfoTerminationReason terminationReason;

    public Optional<GetClusterClusterInfoTerminationReason> terminationReason() {
        return Optional.ofNullable(this.terminationReason);
    }

    private GetClusterClusterInfo() {}

    private GetClusterClusterInfo(GetClusterClusterInfo $) {
        this.autoscale = $.autoscale;
        this.autoterminationMinutes = $.autoterminationMinutes;
        this.awsAttributes = $.awsAttributes;
        this.azureAttributes = $.azureAttributes;
        this.clusterCores = $.clusterCores;
        this.clusterId = $.clusterId;
        this.clusterLogConf = $.clusterLogConf;
        this.clusterLogStatus = $.clusterLogStatus;
        this.clusterMemoryMb = $.clusterMemoryMb;
        this.clusterName = $.clusterName;
        this.clusterSource = $.clusterSource;
        this.creatorUserName = $.creatorUserName;
        this.customTags = $.customTags;
        this.dataSecurityMode = $.dataSecurityMode;
        this.defaultTags = $.defaultTags;
        this.dockerImage = $.dockerImage;
        this.driver = $.driver;
        this.driverInstancePoolId = $.driverInstancePoolId;
        this.driverNodeTypeId = $.driverNodeTypeId;
        this.enableElasticDisk = $.enableElasticDisk;
        this.enableLocalDiskEncryption = $.enableLocalDiskEncryption;
        this.executors = $.executors;
        this.gcpAttributes = $.gcpAttributes;
        this.initScripts = $.initScripts;
        this.instancePoolId = $.instancePoolId;
        this.jdbcPort = $.jdbcPort;
        this.lastActivityTime = $.lastActivityTime;
        this.lastStateLossTime = $.lastStateLossTime;
        this.nodeTypeId = $.nodeTypeId;
        this.numWorkers = $.numWorkers;
        this.policyId = $.policyId;
        this.runtimeEngine = $.runtimeEngine;
        this.singleUserName = $.singleUserName;
        this.sparkConf = $.sparkConf;
        this.sparkContextId = $.sparkContextId;
        this.sparkEnvVars = $.sparkEnvVars;
        this.sparkVersion = $.sparkVersion;
        this.sshPublicKeys = $.sshPublicKeys;
        this.startTime = $.startTime;
        this.state = $.state;
        this.stateMessage = $.stateMessage;
        this.terminateTime = $.terminateTime;
        this.terminationReason = $.terminationReason;
    }

    public static Builder builder() {
        return new Builder();
    }
    public static Builder builder(GetClusterClusterInfo defaults) {
        return new Builder(defaults);
    }

    public static final class Builder {
        private GetClusterClusterInfo $;

        public Builder() {
            $ = new GetClusterClusterInfo();
        }

        public Builder(GetClusterClusterInfo defaults) {
            $ = new GetClusterClusterInfo(Objects.requireNonNull(defaults));
        }

        public Builder autoscale(@Nullable GetClusterClusterInfoAutoscale autoscale) {
            $.autoscale = autoscale;
            return this;
        }

        /**
         * @param autoterminationMinutes Automatically terminate the cluster after being inactive for this time in minutes. If specified, the threshold must be between 10 and 10000 minutes. You can also set this value to 0 to explicitly disable automatic termination.
         * 
         * @return builder
         * 
         */
        public Builder autoterminationMinutes(@Nullable Integer autoterminationMinutes) {
            $.autoterminationMinutes = autoterminationMinutes;
            return this;
        }

        public Builder awsAttributes(@Nullable GetClusterClusterInfoAwsAttributes awsAttributes) {
            $.awsAttributes = awsAttributes;
            return this;
        }

        public Builder azureAttributes(@Nullable GetClusterClusterInfoAzureAttributes azureAttributes) {
            $.azureAttributes = azureAttributes;
            return this;
        }

        public Builder clusterCores(@Nullable Double clusterCores) {
            $.clusterCores = clusterCores;
            return this;
        }

        /**
         * @param clusterId The id of the cluster
         * 
         * @return builder
         * 
         */
        public Builder clusterId(@Nullable String clusterId) {
            $.clusterId = clusterId;
            return this;
        }

        public Builder clusterLogConf(@Nullable GetClusterClusterInfoClusterLogConf clusterLogConf) {
            $.clusterLogConf = clusterLogConf;
            return this;
        }

        public Builder clusterLogStatus(@Nullable GetClusterClusterInfoClusterLogStatus clusterLogStatus) {
            $.clusterLogStatus = clusterLogStatus;
            return this;
        }

        public Builder clusterMemoryMb(@Nullable Integer clusterMemoryMb) {
            $.clusterMemoryMb = clusterMemoryMb;
            return this;
        }

        /**
         * @param clusterName The exact name of the cluster to search
         * 
         * @return builder
         * 
         */
        public Builder clusterName(@Nullable String clusterName) {
            $.clusterName = clusterName;
            return this;
        }

        public Builder clusterSource(String clusterSource) {
            $.clusterSource = clusterSource;
            return this;
        }

        public Builder creatorUserName(@Nullable String creatorUserName) {
            $.creatorUserName = creatorUserName;
            return this;
        }

        /**
         * @param customTags Additional tags for cluster resources.
         * 
         * @return builder
         * 
         */
        public Builder customTags(@Nullable Map<String,Object> customTags) {
            $.customTags = customTags;
            return this;
        }

        /**
         * @param dataSecurityMode Security features of the cluster. Unity Catalog requires `SINGLE_USER` or `USER_ISOLATION` mode. `LEGACY_PASSTHROUGH` for passthrough cluster and `LEGACY_TABLE_ACL` for Table ACL cluster. Default to `NONE`, i.e. no security feature enabled.
         * 
         * @return builder
         * 
         */
        public Builder dataSecurityMode(@Nullable String dataSecurityMode) {
            $.dataSecurityMode = dataSecurityMode;
            return this;
        }

        public Builder defaultTags(Map<String,Object> defaultTags) {
            $.defaultTags = defaultTags;
            return this;
        }

        public Builder dockerImage(@Nullable GetClusterClusterInfoDockerImage dockerImage) {
            $.dockerImage = dockerImage;
            return this;
        }

        public Builder driver(@Nullable GetClusterClusterInfoDriver driver) {
            $.driver = driver;
            return this;
        }

        /**
         * @param driverInstancePoolId similar to `instance_pool_id`, but for driver node.
         * 
         * @return builder
         * 
         */
        public Builder driverInstancePoolId(String driverInstancePoolId) {
            $.driverInstancePoolId = driverInstancePoolId;
            return this;
        }

        /**
         * @param driverNodeTypeId The node type of the Spark driver.
         * 
         * @return builder
         * 
         */
        public Builder driverNodeTypeId(@Nullable String driverNodeTypeId) {
            $.driverNodeTypeId = driverNodeTypeId;
            return this;
        }

        /**
         * @param enableElasticDisk Use autoscaling local storage.
         * 
         * @return builder
         * 
         */
        public Builder enableElasticDisk(@Nullable Boolean enableElasticDisk) {
            $.enableElasticDisk = enableElasticDisk;
            return this;
        }

        /**
         * @param enableLocalDiskEncryption Enable local disk encryption.
         * 
         * @return builder
         * 
         */
        public Builder enableLocalDiskEncryption(@Nullable Boolean enableLocalDiskEncryption) {
            $.enableLocalDiskEncryption = enableLocalDiskEncryption;
            return this;
        }

        public Builder executors(@Nullable List<GetClusterClusterInfoExecutor> executors) {
            $.executors = executors;
            return this;
        }

        public Builder executors(GetClusterClusterInfoExecutor... executors) {
            return executors(List.of(executors));
        }

        public Builder gcpAttributes(@Nullable GetClusterClusterInfoGcpAttributes gcpAttributes) {
            $.gcpAttributes = gcpAttributes;
            return this;
        }

        public Builder initScripts(@Nullable List<GetClusterClusterInfoInitScript> initScripts) {
            $.initScripts = initScripts;
            return this;
        }

        public Builder initScripts(GetClusterClusterInfoInitScript... initScripts) {
            return initScripts(List.of(initScripts));
        }

        /**
         * @param instancePoolId The pool of idle instances the cluster is attached to.
         * 
         * @return builder
         * 
         */
        public Builder instancePoolId(@Nullable String instancePoolId) {
            $.instancePoolId = instancePoolId;
            return this;
        }

        public Builder jdbcPort(@Nullable Integer jdbcPort) {
            $.jdbcPort = jdbcPort;
            return this;
        }

        public Builder lastActivityTime(@Nullable Integer lastActivityTime) {
            $.lastActivityTime = lastActivityTime;
            return this;
        }

        public Builder lastStateLossTime(@Nullable Integer lastStateLossTime) {
            $.lastStateLossTime = lastStateLossTime;
            return this;
        }

        /**
         * @param nodeTypeId Any supported databricks.getNodeType id.
         * 
         * @return builder
         * 
         */
        public Builder nodeTypeId(@Nullable String nodeTypeId) {
            $.nodeTypeId = nodeTypeId;
            return this;
        }

        public Builder numWorkers(@Nullable Integer numWorkers) {
            $.numWorkers = numWorkers;
            return this;
        }

        /**
         * @param policyId Identifier of Cluster Policy to validate cluster and preset certain defaults.
         * 
         * @return builder
         * 
         */
        public Builder policyId(@Nullable String policyId) {
            $.policyId = policyId;
            return this;
        }

        /**
         * @param runtimeEngine The type of runtime of the cluster
         * 
         * @return builder
         * 
         */
        public Builder runtimeEngine(@Nullable String runtimeEngine) {
            $.runtimeEngine = runtimeEngine;
            return this;
        }

        /**
         * @param singleUserName The optional user name of the user to assign to an interactive cluster. This field is required when using standard AAD Passthrough for Azure Data Lake Storage (ADLS) with a single-user cluster (i.e., not high-concurrency clusters).
         * 
         * @return builder
         * 
         */
        public Builder singleUserName(@Nullable String singleUserName) {
            $.singleUserName = singleUserName;
            return this;
        }

        /**
         * @param sparkConf Map with key-value pairs to fine-tune Spark clusters.
         * 
         * @return builder
         * 
         */
        public Builder sparkConf(@Nullable Map<String,Object> sparkConf) {
            $.sparkConf = sparkConf;
            return this;
        }

        public Builder sparkContextId(@Nullable Integer sparkContextId) {
            $.sparkContextId = sparkContextId;
            return this;
        }

        /**
         * @param sparkEnvVars Map with environment variable key-value pairs to fine-tune Spark clusters. Key-value pairs of the form (X,Y) are exported (i.e., X=&#39;Y&#39;) while launching the driver and workers.
         * 
         * @return builder
         * 
         */
        public Builder sparkEnvVars(@Nullable Map<String,Object> sparkEnvVars) {
            $.sparkEnvVars = sparkEnvVars;
            return this;
        }

        /**
         * @param sparkVersion [Runtime version](https://docs.databricks.com/runtime/index.html) of the cluster.
         * 
         * @return builder
         * 
         */
        public Builder sparkVersion(String sparkVersion) {
            $.sparkVersion = sparkVersion;
            return this;
        }

        /**
         * @param sshPublicKeys SSH public key contents that will be added to each Spark node in this cluster.
         * 
         * @return builder
         * 
         */
        public Builder sshPublicKeys(@Nullable List<String> sshPublicKeys) {
            $.sshPublicKeys = sshPublicKeys;
            return this;
        }

        /**
         * @param sshPublicKeys SSH public key contents that will be added to each Spark node in this cluster.
         * 
         * @return builder
         * 
         */
        public Builder sshPublicKeys(String... sshPublicKeys) {
            return sshPublicKeys(List.of(sshPublicKeys));
        }

        public Builder startTime(@Nullable Integer startTime) {
            $.startTime = startTime;
            return this;
        }

        public Builder state(String state) {
            $.state = state;
            return this;
        }

        public Builder stateMessage(@Nullable String stateMessage) {
            $.stateMessage = stateMessage;
            return this;
        }

        public Builder terminateTime(@Nullable Integer terminateTime) {
            $.terminateTime = terminateTime;
            return this;
        }

        public Builder terminationReason(@Nullable GetClusterClusterInfoTerminationReason terminationReason) {
            $.terminationReason = terminationReason;
            return this;
        }

        public GetClusterClusterInfo build() {
            if ($.clusterSource == null) {
                throw new MissingRequiredPropertyException("GetClusterClusterInfo", "clusterSource");
            }
            if ($.defaultTags == null) {
                throw new MissingRequiredPropertyException("GetClusterClusterInfo", "defaultTags");
            }
            if ($.driverInstancePoolId == null) {
                throw new MissingRequiredPropertyException("GetClusterClusterInfo", "driverInstancePoolId");
            }
            if ($.sparkVersion == null) {
                throw new MissingRequiredPropertyException("GetClusterClusterInfo", "sparkVersion");
            }
            if ($.state == null) {
                throw new MissingRequiredPropertyException("GetClusterClusterInfo", "state");
            }
            return $;
        }
    }

}
