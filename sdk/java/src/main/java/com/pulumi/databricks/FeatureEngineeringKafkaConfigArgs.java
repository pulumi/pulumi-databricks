// *** WARNING: this file was generated by pulumi-language-java. ***
// *** Do not edit by hand unless you're certain you know what you are doing! ***

package com.pulumi.databricks;

import com.pulumi.core.Output;
import com.pulumi.core.annotations.Import;
import com.pulumi.databricks.inputs.FeatureEngineeringKafkaConfigAuthConfigArgs;
import com.pulumi.databricks.inputs.FeatureEngineeringKafkaConfigBackfillSourceArgs;
import com.pulumi.databricks.inputs.FeatureEngineeringKafkaConfigKeySchemaArgs;
import com.pulumi.databricks.inputs.FeatureEngineeringKafkaConfigSubscriptionModeArgs;
import com.pulumi.databricks.inputs.FeatureEngineeringKafkaConfigValueSchemaArgs;
import com.pulumi.exceptions.MissingRequiredPropertyException;
import java.lang.String;
import java.util.Map;
import java.util.Objects;
import java.util.Optional;
import javax.annotation.Nullable;


public final class FeatureEngineeringKafkaConfigArgs extends com.pulumi.resources.ResourceArgs {

    public static final FeatureEngineeringKafkaConfigArgs Empty = new FeatureEngineeringKafkaConfigArgs();

    /**
     * Authentication configuration for connection to topics
     * 
     */
    @Import(name="authConfig", required=true)
    private Output<FeatureEngineeringKafkaConfigAuthConfigArgs> authConfig;

    /**
     * @return Authentication configuration for connection to topics
     * 
     */
    public Output<FeatureEngineeringKafkaConfigAuthConfigArgs> authConfig() {
        return this.authConfig;
    }

    /**
     * A user-provided and managed source for backfilling data. Historical data is used when creating a training set from streaming features linked to this Kafka config.
     * In the future, a separate table will be maintained by Databricks for forward filling data.
     * The schema for this source must match exactly that of the key and value schemas specified for this Kafka config
     * 
     */
    @Import(name="backfillSource")
    private @Nullable Output<FeatureEngineeringKafkaConfigBackfillSourceArgs> backfillSource;

    /**
     * @return A user-provided and managed source for backfilling data. Historical data is used when creating a training set from streaming features linked to this Kafka config.
     * In the future, a separate table will be maintained by Databricks for forward filling data.
     * The schema for this source must match exactly that of the key and value schemas specified for this Kafka config
     * 
     */
    public Optional<Output<FeatureEngineeringKafkaConfigBackfillSourceArgs>> backfillSource() {
        return Optional.ofNullable(this.backfillSource);
    }

    /**
     * A comma-separated list of host/port pairs pointing to Kafka cluster
     * 
     */
    @Import(name="bootstrapServers", required=true)
    private Output<String> bootstrapServers;

    /**
     * @return A comma-separated list of host/port pairs pointing to Kafka cluster
     * 
     */
    public Output<String> bootstrapServers() {
        return this.bootstrapServers;
    }

    /**
     * Catch-all for miscellaneous options. Keys should be source options or Kafka consumer options (kafka.*)
     * 
     */
    @Import(name="extraOptions")
    private @Nullable Output<Map<String,String>> extraOptions;

    /**
     * @return Catch-all for miscellaneous options. Keys should be source options or Kafka consumer options (kafka.*)
     * 
     */
    public Optional<Output<Map<String,String>>> extraOptions() {
        return Optional.ofNullable(this.extraOptions);
    }

    /**
     * Schema configuration for extracting message keys from topics. At least one of keySchema and valueSchema must be provided
     * 
     */
    @Import(name="keySchema")
    private @Nullable Output<FeatureEngineeringKafkaConfigKeySchemaArgs> keySchema;

    /**
     * @return Schema configuration for extracting message keys from topics. At least one of keySchema and valueSchema must be provided
     * 
     */
    public Optional<Output<FeatureEngineeringKafkaConfigKeySchemaArgs>> keySchema() {
        return Optional.ofNullable(this.keySchema);
    }

    /**
     * Options to configure which Kafka topics to pull data from
     * 
     */
    @Import(name="subscriptionMode", required=true)
    private Output<FeatureEngineeringKafkaConfigSubscriptionModeArgs> subscriptionMode;

    /**
     * @return Options to configure which Kafka topics to pull data from
     * 
     */
    public Output<FeatureEngineeringKafkaConfigSubscriptionModeArgs> subscriptionMode() {
        return this.subscriptionMode;
    }

    /**
     * Schema configuration for extracting message values from topics. At least one of keySchema and valueSchema must be provided
     * 
     */
    @Import(name="valueSchema")
    private @Nullable Output<FeatureEngineeringKafkaConfigValueSchemaArgs> valueSchema;

    /**
     * @return Schema configuration for extracting message values from topics. At least one of keySchema and valueSchema must be provided
     * 
     */
    public Optional<Output<FeatureEngineeringKafkaConfigValueSchemaArgs>> valueSchema() {
        return Optional.ofNullable(this.valueSchema);
    }

    private FeatureEngineeringKafkaConfigArgs() {}

    private FeatureEngineeringKafkaConfigArgs(FeatureEngineeringKafkaConfigArgs $) {
        this.authConfig = $.authConfig;
        this.backfillSource = $.backfillSource;
        this.bootstrapServers = $.bootstrapServers;
        this.extraOptions = $.extraOptions;
        this.keySchema = $.keySchema;
        this.subscriptionMode = $.subscriptionMode;
        this.valueSchema = $.valueSchema;
    }

    public static Builder builder() {
        return new Builder();
    }
    public static Builder builder(FeatureEngineeringKafkaConfigArgs defaults) {
        return new Builder(defaults);
    }

    public static final class Builder {
        private FeatureEngineeringKafkaConfigArgs $;

        public Builder() {
            $ = new FeatureEngineeringKafkaConfigArgs();
        }

        public Builder(FeatureEngineeringKafkaConfigArgs defaults) {
            $ = new FeatureEngineeringKafkaConfigArgs(Objects.requireNonNull(defaults));
        }

        /**
         * @param authConfig Authentication configuration for connection to topics
         * 
         * @return builder
         * 
         */
        public Builder authConfig(Output<FeatureEngineeringKafkaConfigAuthConfigArgs> authConfig) {
            $.authConfig = authConfig;
            return this;
        }

        /**
         * @param authConfig Authentication configuration for connection to topics
         * 
         * @return builder
         * 
         */
        public Builder authConfig(FeatureEngineeringKafkaConfigAuthConfigArgs authConfig) {
            return authConfig(Output.of(authConfig));
        }

        /**
         * @param backfillSource A user-provided and managed source for backfilling data. Historical data is used when creating a training set from streaming features linked to this Kafka config.
         * In the future, a separate table will be maintained by Databricks for forward filling data.
         * The schema for this source must match exactly that of the key and value schemas specified for this Kafka config
         * 
         * @return builder
         * 
         */
        public Builder backfillSource(@Nullable Output<FeatureEngineeringKafkaConfigBackfillSourceArgs> backfillSource) {
            $.backfillSource = backfillSource;
            return this;
        }

        /**
         * @param backfillSource A user-provided and managed source for backfilling data. Historical data is used when creating a training set from streaming features linked to this Kafka config.
         * In the future, a separate table will be maintained by Databricks for forward filling data.
         * The schema for this source must match exactly that of the key and value schemas specified for this Kafka config
         * 
         * @return builder
         * 
         */
        public Builder backfillSource(FeatureEngineeringKafkaConfigBackfillSourceArgs backfillSource) {
            return backfillSource(Output.of(backfillSource));
        }

        /**
         * @param bootstrapServers A comma-separated list of host/port pairs pointing to Kafka cluster
         * 
         * @return builder
         * 
         */
        public Builder bootstrapServers(Output<String> bootstrapServers) {
            $.bootstrapServers = bootstrapServers;
            return this;
        }

        /**
         * @param bootstrapServers A comma-separated list of host/port pairs pointing to Kafka cluster
         * 
         * @return builder
         * 
         */
        public Builder bootstrapServers(String bootstrapServers) {
            return bootstrapServers(Output.of(bootstrapServers));
        }

        /**
         * @param extraOptions Catch-all for miscellaneous options. Keys should be source options or Kafka consumer options (kafka.*)
         * 
         * @return builder
         * 
         */
        public Builder extraOptions(@Nullable Output<Map<String,String>> extraOptions) {
            $.extraOptions = extraOptions;
            return this;
        }

        /**
         * @param extraOptions Catch-all for miscellaneous options. Keys should be source options or Kafka consumer options (kafka.*)
         * 
         * @return builder
         * 
         */
        public Builder extraOptions(Map<String,String> extraOptions) {
            return extraOptions(Output.of(extraOptions));
        }

        /**
         * @param keySchema Schema configuration for extracting message keys from topics. At least one of keySchema and valueSchema must be provided
         * 
         * @return builder
         * 
         */
        public Builder keySchema(@Nullable Output<FeatureEngineeringKafkaConfigKeySchemaArgs> keySchema) {
            $.keySchema = keySchema;
            return this;
        }

        /**
         * @param keySchema Schema configuration for extracting message keys from topics. At least one of keySchema and valueSchema must be provided
         * 
         * @return builder
         * 
         */
        public Builder keySchema(FeatureEngineeringKafkaConfigKeySchemaArgs keySchema) {
            return keySchema(Output.of(keySchema));
        }

        /**
         * @param subscriptionMode Options to configure which Kafka topics to pull data from
         * 
         * @return builder
         * 
         */
        public Builder subscriptionMode(Output<FeatureEngineeringKafkaConfigSubscriptionModeArgs> subscriptionMode) {
            $.subscriptionMode = subscriptionMode;
            return this;
        }

        /**
         * @param subscriptionMode Options to configure which Kafka topics to pull data from
         * 
         * @return builder
         * 
         */
        public Builder subscriptionMode(FeatureEngineeringKafkaConfigSubscriptionModeArgs subscriptionMode) {
            return subscriptionMode(Output.of(subscriptionMode));
        }

        /**
         * @param valueSchema Schema configuration for extracting message values from topics. At least one of keySchema and valueSchema must be provided
         * 
         * @return builder
         * 
         */
        public Builder valueSchema(@Nullable Output<FeatureEngineeringKafkaConfigValueSchemaArgs> valueSchema) {
            $.valueSchema = valueSchema;
            return this;
        }

        /**
         * @param valueSchema Schema configuration for extracting message values from topics. At least one of keySchema and valueSchema must be provided
         * 
         * @return builder
         * 
         */
        public Builder valueSchema(FeatureEngineeringKafkaConfigValueSchemaArgs valueSchema) {
            return valueSchema(Output.of(valueSchema));
        }

        public FeatureEngineeringKafkaConfigArgs build() {
            if ($.authConfig == null) {
                throw new MissingRequiredPropertyException("FeatureEngineeringKafkaConfigArgs", "authConfig");
            }
            if ($.bootstrapServers == null) {
                throw new MissingRequiredPropertyException("FeatureEngineeringKafkaConfigArgs", "bootstrapServers");
            }
            if ($.subscriptionMode == null) {
                throw new MissingRequiredPropertyException("FeatureEngineeringKafkaConfigArgs", "subscriptionMode");
            }
            return $;
        }
    }

}
