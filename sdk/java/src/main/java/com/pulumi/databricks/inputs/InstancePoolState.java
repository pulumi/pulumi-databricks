// *** WARNING: this file was generated by pulumi-java-gen. ***
// *** Do not edit by hand unless you're certain you know what you are doing! ***

package com.pulumi.databricks.inputs;

import com.pulumi.core.Output;
import com.pulumi.core.annotations.Import;
import com.pulumi.databricks.inputs.InstancePoolAwsAttributesArgs;
import com.pulumi.databricks.inputs.InstancePoolAzureAttributesArgs;
import com.pulumi.databricks.inputs.InstancePoolDiskSpecArgs;
import com.pulumi.databricks.inputs.InstancePoolGcpAttributesArgs;
import com.pulumi.databricks.inputs.InstancePoolInstancePoolFleetAttributesArgs;
import com.pulumi.databricks.inputs.InstancePoolPreloadedDockerImageArgs;
import java.lang.Boolean;
import java.lang.Integer;
import java.lang.Object;
import java.lang.String;
import java.util.List;
import java.util.Map;
import java.util.Objects;
import java.util.Optional;
import javax.annotation.Nullable;


public final class InstancePoolState extends com.pulumi.resources.ResourceArgs {

    public static final InstancePoolState Empty = new InstancePoolState();

    @Import(name="awsAttributes")
    private @Nullable Output<InstancePoolAwsAttributesArgs> awsAttributes;

    public Optional<Output<InstancePoolAwsAttributesArgs>> awsAttributes() {
        return Optional.ofNullable(this.awsAttributes);
    }

    @Import(name="azureAttributes")
    private @Nullable Output<InstancePoolAzureAttributesArgs> azureAttributes;

    public Optional<Output<InstancePoolAzureAttributesArgs>> azureAttributes() {
        return Optional.ofNullable(this.azureAttributes);
    }

    /**
     * (Map) Additional tags for instance pool resources. Databricks tags all pool resources (e.g. AWS &amp; Azure instances and Disk volumes). The tags of the instance pool will propagate to the clusters using the pool (see the [official documentation](https://docs.databricks.com/administration-guide/account-settings/usage-detail-tags-aws.html#tag-propagation)). Attempting to set the same tags in both cluster and instance pool will raise an error. *Databricks allows at most 43 custom tags.*
     * 
     */
    @Import(name="customTags")
    private @Nullable Output<Map<String,Object>> customTags;

    /**
     * @return (Map) Additional tags for instance pool resources. Databricks tags all pool resources (e.g. AWS &amp; Azure instances and Disk volumes). The tags of the instance pool will propagate to the clusters using the pool (see the [official documentation](https://docs.databricks.com/administration-guide/account-settings/usage-detail-tags-aws.html#tag-propagation)). Attempting to set the same tags in both cluster and instance pool will raise an error. *Databricks allows at most 43 custom tags.*
     * 
     */
    public Optional<Output<Map<String,Object>>> customTags() {
        return Optional.ofNullable(this.customTags);
    }

    @Import(name="diskSpec")
    private @Nullable Output<InstancePoolDiskSpecArgs> diskSpec;

    public Optional<Output<InstancePoolDiskSpecArgs>> diskSpec() {
        return Optional.ofNullable(this.diskSpec);
    }

    /**
     * (Bool) Autoscaling Local Storage: when enabled, the instances in the pool dynamically acquire additional disk space when they are running low on disk space.
     * 
     */
    @Import(name="enableElasticDisk")
    private @Nullable Output<Boolean> enableElasticDisk;

    /**
     * @return (Bool) Autoscaling Local Storage: when enabled, the instances in the pool dynamically acquire additional disk space when they are running low on disk space.
     * 
     */
    public Optional<Output<Boolean>> enableElasticDisk() {
        return Optional.ofNullable(this.enableElasticDisk);
    }

    @Import(name="gcpAttributes")
    private @Nullable Output<InstancePoolGcpAttributesArgs> gcpAttributes;

    public Optional<Output<InstancePoolGcpAttributesArgs>> gcpAttributes() {
        return Optional.ofNullable(this.gcpAttributes);
    }

    /**
     * (Integer) The number of minutes that idle instances in excess of the min_idle_instances are maintained by the pool before being terminated. If not specified, excess idle instances are terminated automatically after a default timeout period. If specified, the time must be between 0 and 10000 minutes. If you specify 0, excess idle instances are removed as soon as possible.
     * 
     */
    @Import(name="idleInstanceAutoterminationMinutes")
    private @Nullable Output<Integer> idleInstanceAutoterminationMinutes;

    /**
     * @return (Integer) The number of minutes that idle instances in excess of the min_idle_instances are maintained by the pool before being terminated. If not specified, excess idle instances are terminated automatically after a default timeout period. If specified, the time must be between 0 and 10000 minutes. If you specify 0, excess idle instances are removed as soon as possible.
     * 
     */
    public Optional<Output<Integer>> idleInstanceAutoterminationMinutes() {
        return Optional.ofNullable(this.idleInstanceAutoterminationMinutes);
    }

    @Import(name="instancePoolFleetAttributes")
    private @Nullable Output<InstancePoolInstancePoolFleetAttributesArgs> instancePoolFleetAttributes;

    public Optional<Output<InstancePoolInstancePoolFleetAttributesArgs>> instancePoolFleetAttributes() {
        return Optional.ofNullable(this.instancePoolFleetAttributes);
    }

    @Import(name="instancePoolId")
    private @Nullable Output<String> instancePoolId;

    public Optional<Output<String>> instancePoolId() {
        return Optional.ofNullable(this.instancePoolId);
    }

    /**
     * (String) The name of the instance pool. This is required for create and edit operations. It must be unique, non-empty, and less than 100 characters.
     * 
     */
    @Import(name="instancePoolName")
    private @Nullable Output<String> instancePoolName;

    /**
     * @return (String) The name of the instance pool. This is required for create and edit operations. It must be unique, non-empty, and less than 100 characters.
     * 
     */
    public Optional<Output<String>> instancePoolName() {
        return Optional.ofNullable(this.instancePoolName);
    }

    /**
     * (Integer) The maximum number of instances the pool can contain, including both idle instances and ones in use by clusters. Once the maximum capacity is reached, you cannot create new clusters from the pool and existing clusters cannot autoscale up until some instances are made idle in the pool via cluster termination or down-scaling. There is no default limit, but as a [best practice](https://docs.databricks.com/clusters/instance-pools/pool-best-practices.html#configure-pools-to-control-cost), this should be set based on anticipated usage.
     * 
     */
    @Import(name="maxCapacity")
    private @Nullable Output<Integer> maxCapacity;

    /**
     * @return (Integer) The maximum number of instances the pool can contain, including both idle instances and ones in use by clusters. Once the maximum capacity is reached, you cannot create new clusters from the pool and existing clusters cannot autoscale up until some instances are made idle in the pool via cluster termination or down-scaling. There is no default limit, but as a [best practice](https://docs.databricks.com/clusters/instance-pools/pool-best-practices.html#configure-pools-to-control-cost), this should be set based on anticipated usage.
     * 
     */
    public Optional<Output<Integer>> maxCapacity() {
        return Optional.ofNullable(this.maxCapacity);
    }

    /**
     * (Integer) The minimum number of idle instances maintained by the pool. This is in addition to any instances in use by active clusters.
     * 
     */
    @Import(name="minIdleInstances")
    private @Nullable Output<Integer> minIdleInstances;

    /**
     * @return (Integer) The minimum number of idle instances maintained by the pool. This is in addition to any instances in use by active clusters.
     * 
     */
    public Optional<Output<Integer>> minIdleInstances() {
        return Optional.ofNullable(this.minIdleInstances);
    }

    /**
     * (String) The node type for the instances in the pool. All clusters attached to the pool inherit this node type and the pool’s idle instances are allocated based on this type. You can retrieve a list of available node types by using the [List Node Types API](https://docs.databricks.com/dev-tools/api/latest/clusters.html#clusterclusterservicelistnodetypes) call.
     * 
     */
    @Import(name="nodeTypeId")
    private @Nullable Output<String> nodeTypeId;

    /**
     * @return (String) The node type for the instances in the pool. All clusters attached to the pool inherit this node type and the pool’s idle instances are allocated based on this type. You can retrieve a list of available node types by using the [List Node Types API](https://docs.databricks.com/dev-tools/api/latest/clusters.html#clusterclusterservicelistnodetypes) call.
     * 
     */
    public Optional<Output<String>> nodeTypeId() {
        return Optional.ofNullable(this.nodeTypeId);
    }

    @Import(name="preloadedDockerImages")
    private @Nullable Output<List<InstancePoolPreloadedDockerImageArgs>> preloadedDockerImages;

    public Optional<Output<List<InstancePoolPreloadedDockerImageArgs>>> preloadedDockerImages() {
        return Optional.ofNullable(this.preloadedDockerImages);
    }

    /**
     * (List) A list with at most one runtime version the pool installs on each instance. Pool clusters that use a preloaded runtime version start faster as they do not have to wait for the image to download. You can retrieve them via databricks.getSparkVersion data source or via  [Runtime Versions API](https://docs.databricks.com/dev-tools/api/latest/clusters.html#clusterclusterservicelistsparkversions) call.
     * 
     */
    @Import(name="preloadedSparkVersions")
    private @Nullable Output<List<String>> preloadedSparkVersions;

    /**
     * @return (List) A list with at most one runtime version the pool installs on each instance. Pool clusters that use a preloaded runtime version start faster as they do not have to wait for the image to download. You can retrieve them via databricks.getSparkVersion data source or via  [Runtime Versions API](https://docs.databricks.com/dev-tools/api/latest/clusters.html#clusterclusterservicelistsparkversions) call.
     * 
     */
    public Optional<Output<List<String>>> preloadedSparkVersions() {
        return Optional.ofNullable(this.preloadedSparkVersions);
    }

    private InstancePoolState() {}

    private InstancePoolState(InstancePoolState $) {
        this.awsAttributes = $.awsAttributes;
        this.azureAttributes = $.azureAttributes;
        this.customTags = $.customTags;
        this.diskSpec = $.diskSpec;
        this.enableElasticDisk = $.enableElasticDisk;
        this.gcpAttributes = $.gcpAttributes;
        this.idleInstanceAutoterminationMinutes = $.idleInstanceAutoterminationMinutes;
        this.instancePoolFleetAttributes = $.instancePoolFleetAttributes;
        this.instancePoolId = $.instancePoolId;
        this.instancePoolName = $.instancePoolName;
        this.maxCapacity = $.maxCapacity;
        this.minIdleInstances = $.minIdleInstances;
        this.nodeTypeId = $.nodeTypeId;
        this.preloadedDockerImages = $.preloadedDockerImages;
        this.preloadedSparkVersions = $.preloadedSparkVersions;
    }

    public static Builder builder() {
        return new Builder();
    }
    public static Builder builder(InstancePoolState defaults) {
        return new Builder(defaults);
    }

    public static final class Builder {
        private InstancePoolState $;

        public Builder() {
            $ = new InstancePoolState();
        }

        public Builder(InstancePoolState defaults) {
            $ = new InstancePoolState(Objects.requireNonNull(defaults));
        }

        public Builder awsAttributes(@Nullable Output<InstancePoolAwsAttributesArgs> awsAttributes) {
            $.awsAttributes = awsAttributes;
            return this;
        }

        public Builder awsAttributes(InstancePoolAwsAttributesArgs awsAttributes) {
            return awsAttributes(Output.of(awsAttributes));
        }

        public Builder azureAttributes(@Nullable Output<InstancePoolAzureAttributesArgs> azureAttributes) {
            $.azureAttributes = azureAttributes;
            return this;
        }

        public Builder azureAttributes(InstancePoolAzureAttributesArgs azureAttributes) {
            return azureAttributes(Output.of(azureAttributes));
        }

        /**
         * @param customTags (Map) Additional tags for instance pool resources. Databricks tags all pool resources (e.g. AWS &amp; Azure instances and Disk volumes). The tags of the instance pool will propagate to the clusters using the pool (see the [official documentation](https://docs.databricks.com/administration-guide/account-settings/usage-detail-tags-aws.html#tag-propagation)). Attempting to set the same tags in both cluster and instance pool will raise an error. *Databricks allows at most 43 custom tags.*
         * 
         * @return builder
         * 
         */
        public Builder customTags(@Nullable Output<Map<String,Object>> customTags) {
            $.customTags = customTags;
            return this;
        }

        /**
         * @param customTags (Map) Additional tags for instance pool resources. Databricks tags all pool resources (e.g. AWS &amp; Azure instances and Disk volumes). The tags of the instance pool will propagate to the clusters using the pool (see the [official documentation](https://docs.databricks.com/administration-guide/account-settings/usage-detail-tags-aws.html#tag-propagation)). Attempting to set the same tags in both cluster and instance pool will raise an error. *Databricks allows at most 43 custom tags.*
         * 
         * @return builder
         * 
         */
        public Builder customTags(Map<String,Object> customTags) {
            return customTags(Output.of(customTags));
        }

        public Builder diskSpec(@Nullable Output<InstancePoolDiskSpecArgs> diskSpec) {
            $.diskSpec = diskSpec;
            return this;
        }

        public Builder diskSpec(InstancePoolDiskSpecArgs diskSpec) {
            return diskSpec(Output.of(diskSpec));
        }

        /**
         * @param enableElasticDisk (Bool) Autoscaling Local Storage: when enabled, the instances in the pool dynamically acquire additional disk space when they are running low on disk space.
         * 
         * @return builder
         * 
         */
        public Builder enableElasticDisk(@Nullable Output<Boolean> enableElasticDisk) {
            $.enableElasticDisk = enableElasticDisk;
            return this;
        }

        /**
         * @param enableElasticDisk (Bool) Autoscaling Local Storage: when enabled, the instances in the pool dynamically acquire additional disk space when they are running low on disk space.
         * 
         * @return builder
         * 
         */
        public Builder enableElasticDisk(Boolean enableElasticDisk) {
            return enableElasticDisk(Output.of(enableElasticDisk));
        }

        public Builder gcpAttributes(@Nullable Output<InstancePoolGcpAttributesArgs> gcpAttributes) {
            $.gcpAttributes = gcpAttributes;
            return this;
        }

        public Builder gcpAttributes(InstancePoolGcpAttributesArgs gcpAttributes) {
            return gcpAttributes(Output.of(gcpAttributes));
        }

        /**
         * @param idleInstanceAutoterminationMinutes (Integer) The number of minutes that idle instances in excess of the min_idle_instances are maintained by the pool before being terminated. If not specified, excess idle instances are terminated automatically after a default timeout period. If specified, the time must be between 0 and 10000 minutes. If you specify 0, excess idle instances are removed as soon as possible.
         * 
         * @return builder
         * 
         */
        public Builder idleInstanceAutoterminationMinutes(@Nullable Output<Integer> idleInstanceAutoterminationMinutes) {
            $.idleInstanceAutoterminationMinutes = idleInstanceAutoterminationMinutes;
            return this;
        }

        /**
         * @param idleInstanceAutoterminationMinutes (Integer) The number of minutes that idle instances in excess of the min_idle_instances are maintained by the pool before being terminated. If not specified, excess idle instances are terminated automatically after a default timeout period. If specified, the time must be between 0 and 10000 minutes. If you specify 0, excess idle instances are removed as soon as possible.
         * 
         * @return builder
         * 
         */
        public Builder idleInstanceAutoterminationMinutes(Integer idleInstanceAutoterminationMinutes) {
            return idleInstanceAutoterminationMinutes(Output.of(idleInstanceAutoterminationMinutes));
        }

        public Builder instancePoolFleetAttributes(@Nullable Output<InstancePoolInstancePoolFleetAttributesArgs> instancePoolFleetAttributes) {
            $.instancePoolFleetAttributes = instancePoolFleetAttributes;
            return this;
        }

        public Builder instancePoolFleetAttributes(InstancePoolInstancePoolFleetAttributesArgs instancePoolFleetAttributes) {
            return instancePoolFleetAttributes(Output.of(instancePoolFleetAttributes));
        }

        public Builder instancePoolId(@Nullable Output<String> instancePoolId) {
            $.instancePoolId = instancePoolId;
            return this;
        }

        public Builder instancePoolId(String instancePoolId) {
            return instancePoolId(Output.of(instancePoolId));
        }

        /**
         * @param instancePoolName (String) The name of the instance pool. This is required for create and edit operations. It must be unique, non-empty, and less than 100 characters.
         * 
         * @return builder
         * 
         */
        public Builder instancePoolName(@Nullable Output<String> instancePoolName) {
            $.instancePoolName = instancePoolName;
            return this;
        }

        /**
         * @param instancePoolName (String) The name of the instance pool. This is required for create and edit operations. It must be unique, non-empty, and less than 100 characters.
         * 
         * @return builder
         * 
         */
        public Builder instancePoolName(String instancePoolName) {
            return instancePoolName(Output.of(instancePoolName));
        }

        /**
         * @param maxCapacity (Integer) The maximum number of instances the pool can contain, including both idle instances and ones in use by clusters. Once the maximum capacity is reached, you cannot create new clusters from the pool and existing clusters cannot autoscale up until some instances are made idle in the pool via cluster termination or down-scaling. There is no default limit, but as a [best practice](https://docs.databricks.com/clusters/instance-pools/pool-best-practices.html#configure-pools-to-control-cost), this should be set based on anticipated usage.
         * 
         * @return builder
         * 
         */
        public Builder maxCapacity(@Nullable Output<Integer> maxCapacity) {
            $.maxCapacity = maxCapacity;
            return this;
        }

        /**
         * @param maxCapacity (Integer) The maximum number of instances the pool can contain, including both idle instances and ones in use by clusters. Once the maximum capacity is reached, you cannot create new clusters from the pool and existing clusters cannot autoscale up until some instances are made idle in the pool via cluster termination or down-scaling. There is no default limit, but as a [best practice](https://docs.databricks.com/clusters/instance-pools/pool-best-practices.html#configure-pools-to-control-cost), this should be set based on anticipated usage.
         * 
         * @return builder
         * 
         */
        public Builder maxCapacity(Integer maxCapacity) {
            return maxCapacity(Output.of(maxCapacity));
        }

        /**
         * @param minIdleInstances (Integer) The minimum number of idle instances maintained by the pool. This is in addition to any instances in use by active clusters.
         * 
         * @return builder
         * 
         */
        public Builder minIdleInstances(@Nullable Output<Integer> minIdleInstances) {
            $.minIdleInstances = minIdleInstances;
            return this;
        }

        /**
         * @param minIdleInstances (Integer) The minimum number of idle instances maintained by the pool. This is in addition to any instances in use by active clusters.
         * 
         * @return builder
         * 
         */
        public Builder minIdleInstances(Integer minIdleInstances) {
            return minIdleInstances(Output.of(minIdleInstances));
        }

        /**
         * @param nodeTypeId (String) The node type for the instances in the pool. All clusters attached to the pool inherit this node type and the pool’s idle instances are allocated based on this type. You can retrieve a list of available node types by using the [List Node Types API](https://docs.databricks.com/dev-tools/api/latest/clusters.html#clusterclusterservicelistnodetypes) call.
         * 
         * @return builder
         * 
         */
        public Builder nodeTypeId(@Nullable Output<String> nodeTypeId) {
            $.nodeTypeId = nodeTypeId;
            return this;
        }

        /**
         * @param nodeTypeId (String) The node type for the instances in the pool. All clusters attached to the pool inherit this node type and the pool’s idle instances are allocated based on this type. You can retrieve a list of available node types by using the [List Node Types API](https://docs.databricks.com/dev-tools/api/latest/clusters.html#clusterclusterservicelistnodetypes) call.
         * 
         * @return builder
         * 
         */
        public Builder nodeTypeId(String nodeTypeId) {
            return nodeTypeId(Output.of(nodeTypeId));
        }

        public Builder preloadedDockerImages(@Nullable Output<List<InstancePoolPreloadedDockerImageArgs>> preloadedDockerImages) {
            $.preloadedDockerImages = preloadedDockerImages;
            return this;
        }

        public Builder preloadedDockerImages(List<InstancePoolPreloadedDockerImageArgs> preloadedDockerImages) {
            return preloadedDockerImages(Output.of(preloadedDockerImages));
        }

        public Builder preloadedDockerImages(InstancePoolPreloadedDockerImageArgs... preloadedDockerImages) {
            return preloadedDockerImages(List.of(preloadedDockerImages));
        }

        /**
         * @param preloadedSparkVersions (List) A list with at most one runtime version the pool installs on each instance. Pool clusters that use a preloaded runtime version start faster as they do not have to wait for the image to download. You can retrieve them via databricks.getSparkVersion data source or via  [Runtime Versions API](https://docs.databricks.com/dev-tools/api/latest/clusters.html#clusterclusterservicelistsparkversions) call.
         * 
         * @return builder
         * 
         */
        public Builder preloadedSparkVersions(@Nullable Output<List<String>> preloadedSparkVersions) {
            $.preloadedSparkVersions = preloadedSparkVersions;
            return this;
        }

        /**
         * @param preloadedSparkVersions (List) A list with at most one runtime version the pool installs on each instance. Pool clusters that use a preloaded runtime version start faster as they do not have to wait for the image to download. You can retrieve them via databricks.getSparkVersion data source or via  [Runtime Versions API](https://docs.databricks.com/dev-tools/api/latest/clusters.html#clusterclusterservicelistsparkversions) call.
         * 
         * @return builder
         * 
         */
        public Builder preloadedSparkVersions(List<String> preloadedSparkVersions) {
            return preloadedSparkVersions(Output.of(preloadedSparkVersions));
        }

        /**
         * @param preloadedSparkVersions (List) A list with at most one runtime version the pool installs on each instance. Pool clusters that use a preloaded runtime version start faster as they do not have to wait for the image to download. You can retrieve them via databricks.getSparkVersion data source or via  [Runtime Versions API](https://docs.databricks.com/dev-tools/api/latest/clusters.html#clusterclusterservicelistsparkversions) call.
         * 
         * @return builder
         * 
         */
        public Builder preloadedSparkVersions(String... preloadedSparkVersions) {
            return preloadedSparkVersions(List.of(preloadedSparkVersions));
        }

        public InstancePoolState build() {
            return $;
        }
    }

}
