// *** WARNING: this file was generated by pulumi-language-java. ***
// *** Do not edit by hand unless you're certain you know what you are doing! ***

package com.pulumi.databricks;

import com.pulumi.core.Output;
import com.pulumi.core.annotations.Export;
import com.pulumi.core.annotations.ResourceType;
import com.pulumi.core.internal.Codegen;
import com.pulumi.databricks.DatabaseSyncedDatabaseTableArgs;
import com.pulumi.databricks.Utilities;
import com.pulumi.databricks.inputs.DatabaseSyncedDatabaseTableState;
import com.pulumi.databricks.outputs.DatabaseSyncedDatabaseTableDataSynchronizationStatus;
import com.pulumi.databricks.outputs.DatabaseSyncedDatabaseTableSpec;
import java.lang.String;
import java.util.Optional;
import javax.annotation.Nullable;

/**
 * [![Private Preview](https://img.shields.io/badge/Release_Stage-Private_Preview-blueviolet)](https://docs.databricks.com/aws/en/release-notes/release-types)
 * 
 * Lakebase Synced Database Tables are Postgres tables automatically synced from a source table inside Unity Catalog.
 * They can be used to serve realtime queries without the operational overhead of managing ETL pipelines.
 * 
 * Synced Database Tables can be configured inside either Database Catalogs or Standard Catalogs. Multiple
 * Synced Database Tables can be bin packed inside a single pipeline to optimize costs.
 * 
 * ## Example Usage
 * 
 * ### Creating a Synced Database Table inside a Database Catalog
 * 
 * This example creates a Synced Database Table inside a Database Catalog.
 * 
 * <pre>
 * {@code
 * package generated_program;
 * 
 * import com.pulumi.Context;
 * import com.pulumi.Pulumi;
 * import com.pulumi.core.Output;
 * import com.pulumi.databricks.DatabaseSyncedDatabaseTable;
 * import com.pulumi.databricks.DatabaseSyncedDatabaseTableArgs;
 * import com.pulumi.databricks.inputs.DatabaseSyncedDatabaseTableSpecArgs;
 * import com.pulumi.databricks.inputs.DatabaseSyncedDatabaseTableSpecNewPipelineSpecArgs;
 * import java.util.List;
 * import java.util.ArrayList;
 * import java.util.Map;
 * import java.io.File;
 * import java.nio.file.Files;
 * import java.nio.file.Paths;
 * 
 * public class App {
 *     public static void main(String[] args) {
 *         Pulumi.run(App::stack);
 *     }
 * 
 *     public static void stack(Context ctx) {
 *         var this_ = new DatabaseSyncedDatabaseTable("this", DatabaseSyncedDatabaseTableArgs.builder()
 *             .name("my_database_catalog.public.synced_table")
 *             .logicalDatabaseName("databricks_postgres")
 *             .spec(DatabaseSyncedDatabaseTableSpecArgs.builder()
 *                 .schedulingPolicy("SNAPSHOT")
 *                 .sourceTableFullName("source_delta.tpch.customer")
 *                 .primaryKeyColumns("c_custkey")
 *                 .createDatabaseObjectsIfMissing(true)
 *                 .newPipelineSpec(DatabaseSyncedDatabaseTableSpecNewPipelineSpecArgs.builder()
 *                     .storageCatalog("source_delta")
 *                     .storageSchema("tpch")
 *                     .build())
 *                 .build())
 *             .build());
 * 
 *     }
 * }
 * }
 * </pre>
 * 
 * ### Creating a Synced Database Table inside a Standard Catalog
 * 
 * This example creates a Synced Database Table inside a Standard Catalog.
 * 
 * <pre>
 * {@code
 * package generated_program;
 * 
 * import com.pulumi.Context;
 * import com.pulumi.Pulumi;
 * import com.pulumi.core.Output;
 * import com.pulumi.databricks.DatabaseSyncedDatabaseTable;
 * import com.pulumi.databricks.DatabaseSyncedDatabaseTableArgs;
 * import com.pulumi.databricks.inputs.DatabaseSyncedDatabaseTableSpecArgs;
 * import com.pulumi.databricks.inputs.DatabaseSyncedDatabaseTableSpecNewPipelineSpecArgs;
 * import java.util.List;
 * import java.util.ArrayList;
 * import java.util.Map;
 * import java.io.File;
 * import java.nio.file.Files;
 * import java.nio.file.Paths;
 * 
 * public class App {
 *     public static void main(String[] args) {
 *         Pulumi.run(App::stack);
 *     }
 * 
 *     public static void stack(Context ctx) {
 *         var this_ = new DatabaseSyncedDatabaseTable("this", DatabaseSyncedDatabaseTableArgs.builder()
 *             .name("my_standard_catalog.public.synced_table")
 *             .logicalDatabaseName("databricks_postgres")
 *             .databaseInstanceName("my-database-instance")
 *             .spec(DatabaseSyncedDatabaseTableSpecArgs.builder()
 *                 .schedulingPolicy("SNAPSHOT")
 *                 .sourceTableFullName("source_delta.tpch.customer")
 *                 .primaryKeyColumns("c_custkey")
 *                 .createDatabaseObjectsIfMissing(true)
 *                 .newPipelineSpec(DatabaseSyncedDatabaseTableSpecNewPipelineSpecArgs.builder()
 *                     .storageCatalog("source_delta")
 *                     .storageSchema("tpch")
 *                     .build())
 *                 .build())
 *             .build());
 * 
 *     }
 * }
 * }
 * </pre>
 * 
 * ### Creating multiple Synced Database Tables and bin packing them into a single pipeline
 * 
 * This example creates two Synced Database Tables. The first one specifies a new pipeline spec,
 * which generates a new pipeline. The second one utilizes the pipeline ID of the first table.
 * 
 * <pre>
 * {@code
 * package generated_program;
 * 
 * import com.pulumi.Context;
 * import com.pulumi.Pulumi;
 * import com.pulumi.core.Output;
 * import com.pulumi.databricks.DatabaseInstance;
 * import com.pulumi.databricks.DatabaseInstanceArgs;
 * import com.pulumi.databricks.DatabaseSyncedDatabaseTable;
 * import com.pulumi.databricks.DatabaseSyncedDatabaseTableArgs;
 * import com.pulumi.databricks.inputs.DatabaseSyncedDatabaseTableSpecArgs;
 * import com.pulumi.databricks.inputs.DatabaseSyncedDatabaseTableSpecNewPipelineSpecArgs;
 * import java.util.List;
 * import java.util.ArrayList;
 * import java.util.Map;
 * import java.io.File;
 * import java.nio.file.Files;
 * import java.nio.file.Paths;
 * 
 * public class App {
 *     public static void main(String[] args) {
 *         Pulumi.run(App::stack);
 *     }
 * 
 *     public static void stack(Context ctx) {
 *         var instance = new DatabaseInstance("instance", DatabaseInstanceArgs.builder()
 *             .name("my-database-instance")
 *             .capacity("CU_1")
 *             .build());
 * 
 *         var syncedTable1 = new DatabaseSyncedDatabaseTable("syncedTable1", DatabaseSyncedDatabaseTableArgs.builder()
 *             .name("my_standard_catalog.public.synced_table1")
 *             .logicalDatabaseName("databricks_postgres")
 *             .databaseInstanceName(instance.name())
 *             .spec(DatabaseSyncedDatabaseTableSpecArgs.builder()
 *                 .schedulingPolicy("SNAPSHOT")
 *                 .sourceTableFullName("source_delta.tpch.customer")
 *                 .primaryKeyColumns("c_custkey")
 *                 .createDatabaseObjectsIfMissing(true)
 *                 .newPipelineSpec(DatabaseSyncedDatabaseTableSpecNewPipelineSpecArgs.builder()
 *                     .storageCatalog("source_delta")
 *                     .storageSchema("tpch")
 *                     .build())
 *                 .build())
 *             .build());
 * 
 *         var syncedTable2 = new DatabaseSyncedDatabaseTable("syncedTable2", DatabaseSyncedDatabaseTableArgs.builder()
 *             .name("my_standard_catalog.public.synced_table2")
 *             .logicalDatabaseName("databricks_postgres")
 *             .databaseInstanceName(instance.name())
 *             .spec(DatabaseSyncedDatabaseTableSpecArgs.builder()
 *                 .schedulingPolicy("SNAPSHOT")
 *                 .sourceTableFullName("source_delta.tpch.customer")
 *                 .primaryKeyColumns("c_custkey")
 *                 .createDatabaseObjectsIfMissing(true)
 *                 .existingPipelineId(syncedTable1.dataSynchronizationStatus().applyValue(_dataSynchronizationStatus -> _dataSynchronizationStatus.pipelineId()))
 *                 .build())
 *             .build());
 * 
 *     }
 * }
 * }
 * </pre>
 * 
 * ### Creating a Synced Database Table with a custom Jobs schedule
 * 
 * This example creates a Synced Database Table and customizes the pipeline schedule. It assumes you already have
 * 
 * - A database instance named `&#34;my-database-instance&#34;`
 * - A standard catalog named `&#34;myStandardCatalog&#34;`
 * - A schema in the standard catalog named `&#34;default&#34;`
 * - A source delta table named `&#34;source_delta.schema.customer&#34;` with the primary key `&#34;cCustkey&#34;`
 * 
 * <pre>
 * {@code
 * package generated_program;
 * 
 * import com.pulumi.Context;
 * import com.pulumi.Pulumi;
 * import com.pulumi.core.Output;
 * import com.pulumi.databricks.DatabaseSyncedDatabaseTable;
 * import com.pulumi.databricks.DatabaseSyncedDatabaseTableArgs;
 * import com.pulumi.databricks.inputs.DatabaseSyncedDatabaseTableSpecArgs;
 * import com.pulumi.databricks.inputs.DatabaseSyncedDatabaseTableSpecNewPipelineSpecArgs;
 * import com.pulumi.databricks.Job;
 * import com.pulumi.databricks.JobArgs;
 * import com.pulumi.databricks.inputs.JobTaskArgs;
 * import com.pulumi.databricks.inputs.JobTaskPipelineTaskArgs;
 * import com.pulumi.databricks.inputs.JobScheduleArgs;
 * import java.util.List;
 * import java.util.ArrayList;
 * import java.util.Map;
 * import java.io.File;
 * import java.nio.file.Files;
 * import java.nio.file.Paths;
 * 
 * public class App {
 *     public static void main(String[] args) {
 *         Pulumi.run(App::stack);
 *     }
 * 
 *     public static void stack(Context ctx) {
 *         var syncedTable = new DatabaseSyncedDatabaseTable("syncedTable", DatabaseSyncedDatabaseTableArgs.builder()
 *             .name("my_standard_catalog.default.my_synced_table")
 *             .logicalDatabaseName("terraform_test_db")
 *             .databaseInstanceName("my-database-instance")
 *             .spec(DatabaseSyncedDatabaseTableSpecArgs.builder()
 *                 .schedulingPolicy("SNAPSHOT")
 *                 .sourceTableFullName("source_delta.schema.customer")
 *                 .primaryKeyColumns("c_custkey")
 *                 .createDatabaseObjectsIfMissing(true)
 *                 .newPipelineSpec(DatabaseSyncedDatabaseTableSpecNewPipelineSpecArgs.builder()
 *                     .storageCatalog("source_delta")
 *                     .storageSchema("schema")
 *                     .build())
 *                 .build())
 *             .build());
 * 
 *         var syncPipelineScheduleJob = new Job("syncPipelineScheduleJob", JobArgs.builder()
 *             .name("Synced Pipeline Refresh")
 *             .description("Job to schedule synced database table pipeline. ")
 *             .tasks(JobTaskArgs.builder()
 *                 .taskKey("synced-table-pipeline")
 *                 .pipelineTask(JobTaskPipelineTaskArgs.builder()
 *                     .pipelineId(syncedTable.dataSynchronizationStatus().applyValue(_dataSynchronizationStatus -> _dataSynchronizationStatus.pipelineId()))
 *                     .build())
 *                 .build())
 *             .schedule(JobScheduleArgs.builder()
 *                 .quartzCronExpression("0 0 0 * * ?")
 *                 .timezoneId("Europe/Helsinki")
 *                 .build())
 *             .build());
 * 
 *     }
 * }
 * }
 * </pre>
 * 
 * ## Import
 * 
 * As of Pulumi v1.5, resources can be imported through configuration.
 * 
 * hcl
 * 
 * import {
 * 
 *   id = &#34;name&#34;
 * 
 *   to = databricks_database_synced_database_table.this
 * 
 * }
 * 
 * If you are using an older version of Pulumi, import the resource using the `pulumi import` command as follows:
 * 
 * ```sh
 * $ pulumi import databricks:index/databaseSyncedDatabaseTable:DatabaseSyncedDatabaseTable this &#34;name&#34;
 * ```
 * 
 */
@ResourceType(type="databricks:index/databaseSyncedDatabaseTable:DatabaseSyncedDatabaseTable")
public class DatabaseSyncedDatabaseTable extends com.pulumi.resources.CustomResource {
    /**
     * (SyncedTableStatus) - Synced Table data synchronization status
     * 
     */
    @Export(name="dataSynchronizationStatus", refs={DatabaseSyncedDatabaseTableDataSynchronizationStatus.class}, tree="[0]")
    private Output<DatabaseSyncedDatabaseTableDataSynchronizationStatus> dataSynchronizationStatus;

    /**
     * @return (SyncedTableStatus) - Synced Table data synchronization status
     * 
     */
    public Output<DatabaseSyncedDatabaseTableDataSynchronizationStatus> dataSynchronizationStatus() {
        return this.dataSynchronizationStatus;
    }
    /**
     * Name of the target database instance. This is required when creating synced database tables in standard catalogs.
     * This is optional when creating synced database tables in registered catalogs. If this field is specified
     * when creating synced database tables in registered catalogs, the database instance name MUST
     * match that of the registered catalog (or the request will be rejected)
     * 
     */
    @Export(name="databaseInstanceName", refs={String.class}, tree="[0]")
    private Output<String> databaseInstanceName;

    /**
     * @return Name of the target database instance. This is required when creating synced database tables in standard catalogs.
     * This is optional when creating synced database tables in registered catalogs. If this field is specified
     * when creating synced database tables in registered catalogs, the database instance name MUST
     * match that of the registered catalog (or the request will be rejected)
     * 
     */
    public Output<String> databaseInstanceName() {
        return this.databaseInstanceName;
    }
    /**
     * (string) - The name of the database instance that this table is registered to. This field is always returned, and for
     * tables inside database catalogs is inferred database instance associated with the catalog
     * 
     */
    @Export(name="effectiveDatabaseInstanceName", refs={String.class}, tree="[0]")
    private Output<String> effectiveDatabaseInstanceName;

    /**
     * @return (string) - The name of the database instance that this table is registered to. This field is always returned, and for
     * tables inside database catalogs is inferred database instance associated with the catalog
     * 
     */
    public Output<String> effectiveDatabaseInstanceName() {
        return this.effectiveDatabaseInstanceName;
    }
    /**
     * (string) - The name of the logical database that this table is registered to
     * 
     */
    @Export(name="effectiveLogicalDatabaseName", refs={String.class}, tree="[0]")
    private Output<String> effectiveLogicalDatabaseName;

    /**
     * @return (string) - The name of the logical database that this table is registered to
     * 
     */
    public Output<String> effectiveLogicalDatabaseName() {
        return this.effectiveLogicalDatabaseName;
    }
    /**
     * Target Postgres database object (logical database) name for this table.
     * 
     * When creating a synced table in a registered Postgres catalog, the
     * target Postgres database name is inferred to be that of the registered catalog.
     * If this field is specified in this scenario, the Postgres database name MUST
     * match that of the registered catalog (or the request will be rejected).
     * 
     * When creating a synced table in a standard catalog, this field is required.
     * In this scenario, specifying this field will allow targeting an arbitrary postgres database.
     * Note that this has implications for the `createDatabaseObjectsIsMissing` field in `spec`
     * 
     */
    @Export(name="logicalDatabaseName", refs={String.class}, tree="[0]")
    private Output<String> logicalDatabaseName;

    /**
     * @return Target Postgres database object (logical database) name for this table.
     * 
     * When creating a synced table in a registered Postgres catalog, the
     * target Postgres database name is inferred to be that of the registered catalog.
     * If this field is specified in this scenario, the Postgres database name MUST
     * match that of the registered catalog (or the request will be rejected).
     * 
     * When creating a synced table in a standard catalog, this field is required.
     * In this scenario, specifying this field will allow targeting an arbitrary postgres database.
     * Note that this has implications for the `createDatabaseObjectsIsMissing` field in `spec`
     * 
     */
    public Output<String> logicalDatabaseName() {
        return this.logicalDatabaseName;
    }
    /**
     * Full three-part (catalog, schema, table) name of the table
     * 
     */
    @Export(name="name", refs={String.class}, tree="[0]")
    private Output<String> name;

    /**
     * @return Full three-part (catalog, schema, table) name of the table
     * 
     */
    public Output<String> name() {
        return this.name;
    }
    @Export(name="spec", refs={DatabaseSyncedDatabaseTableSpec.class}, tree="[0]")
    private Output</* @Nullable */ DatabaseSyncedDatabaseTableSpec> spec;

    public Output<Optional<DatabaseSyncedDatabaseTableSpec>> spec() {
        return Codegen.optional(this.spec);
    }
    /**
     * (string) - The provisioning state of the synced table entity in Unity Catalog. This is distinct from the
     * state of the data synchronization pipeline (i.e. the table may be in &#34;ACTIVE&#34; but the pipeline
     * may be in &#34;PROVISIONING&#34; as it runs asynchronously). Possible values are: `ACTIVE`, `DEGRADED`, `DELETING`, `FAILED`, `PROVISIONING`, `UPDATING`
     * 
     */
    @Export(name="unityCatalogProvisioningState", refs={String.class}, tree="[0]")
    private Output<String> unityCatalogProvisioningState;

    /**
     * @return (string) - The provisioning state of the synced table entity in Unity Catalog. This is distinct from the
     * state of the data synchronization pipeline (i.e. the table may be in &#34;ACTIVE&#34; but the pipeline
     * may be in &#34;PROVISIONING&#34; as it runs asynchronously). Possible values are: `ACTIVE`, `DEGRADED`, `DELETING`, `FAILED`, `PROVISIONING`, `UPDATING`
     * 
     */
    public Output<String> unityCatalogProvisioningState() {
        return this.unityCatalogProvisioningState;
    }

    /**
     *
     * @param name The _unique_ name of the resulting resource.
     */
    public DatabaseSyncedDatabaseTable(java.lang.String name) {
        this(name, DatabaseSyncedDatabaseTableArgs.Empty);
    }
    /**
     *
     * @param name The _unique_ name of the resulting resource.
     * @param args The arguments to use to populate this resource's properties.
     */
    public DatabaseSyncedDatabaseTable(java.lang.String name, @Nullable DatabaseSyncedDatabaseTableArgs args) {
        this(name, args, null);
    }
    /**
     *
     * @param name The _unique_ name of the resulting resource.
     * @param args The arguments to use to populate this resource's properties.
     * @param options A bag of options that control this resource's behavior.
     */
    public DatabaseSyncedDatabaseTable(java.lang.String name, @Nullable DatabaseSyncedDatabaseTableArgs args, @Nullable com.pulumi.resources.CustomResourceOptions options) {
        super("databricks:index/databaseSyncedDatabaseTable:DatabaseSyncedDatabaseTable", name, makeArgs(args, options), makeResourceOptions(options, Codegen.empty()), false);
    }

    private DatabaseSyncedDatabaseTable(java.lang.String name, Output<java.lang.String> id, @Nullable DatabaseSyncedDatabaseTableState state, @Nullable com.pulumi.resources.CustomResourceOptions options) {
        super("databricks:index/databaseSyncedDatabaseTable:DatabaseSyncedDatabaseTable", name, state, makeResourceOptions(options, id), false);
    }

    private static DatabaseSyncedDatabaseTableArgs makeArgs(@Nullable DatabaseSyncedDatabaseTableArgs args, @Nullable com.pulumi.resources.CustomResourceOptions options) {
        if (options != null && options.getUrn().isPresent()) {
            return null;
        }
        return args == null ? DatabaseSyncedDatabaseTableArgs.Empty : args;
    }

    private static com.pulumi.resources.CustomResourceOptions makeResourceOptions(@Nullable com.pulumi.resources.CustomResourceOptions options, @Nullable Output<java.lang.String> id) {
        var defaultOptions = com.pulumi.resources.CustomResourceOptions.builder()
            .version(Utilities.getVersion())
            .build();
        return com.pulumi.resources.CustomResourceOptions.merge(defaultOptions, options, id);
    }

    /**
     * Get an existing Host resource's state with the given name, ID, and optional extra
     * properties used to qualify the lookup.
     *
     * @param name The _unique_ name of the resulting resource.
     * @param id The _unique_ provider ID of the resource to lookup.
     * @param state
     * @param options Optional settings to control the behavior of the CustomResource.
     */
    public static DatabaseSyncedDatabaseTable get(java.lang.String name, Output<java.lang.String> id, @Nullable DatabaseSyncedDatabaseTableState state, @Nullable com.pulumi.resources.CustomResourceOptions options) {
        return new DatabaseSyncedDatabaseTable(name, id, state, options);
    }
}
