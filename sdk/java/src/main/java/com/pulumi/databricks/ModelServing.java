// *** WARNING: this file was generated by pulumi-language-java. ***
// *** Do not edit by hand unless you're certain you know what you are doing! ***

package com.pulumi.databricks;

import com.pulumi.core.Output;
import com.pulumi.core.annotations.Export;
import com.pulumi.core.annotations.ResourceType;
import com.pulumi.core.internal.Codegen;
import com.pulumi.databricks.ModelServingArgs;
import com.pulumi.databricks.Utilities;
import com.pulumi.databricks.inputs.ModelServingState;
import com.pulumi.databricks.outputs.ModelServingAiGateway;
import com.pulumi.databricks.outputs.ModelServingConfig;
import com.pulumi.databricks.outputs.ModelServingEmailNotifications;
import com.pulumi.databricks.outputs.ModelServingRateLimit;
import com.pulumi.databricks.outputs.ModelServingTag;
import java.lang.Boolean;
import java.lang.String;
import java.util.List;
import java.util.Optional;
import javax.annotation.Nullable;

/**
 * This resource allows you to manage [Model Serving](https://docs.databricks.com/machine-learning/model-serving/index.html) endpoints in Databricks, including custom models, external models, and foundation models. For newer foundation models, including Llama 4, please use the databricks.ModelServingProvisionedThroughput resource.
 * 
 * &gt; This resource can only be used with a workspace-level provider!
 * 
 * &gt; If you replace `served_models` with `served_entities` in an existing serving endpoint, the serving endpoint will briefly go into an update state (~30 seconds) and increment the config version.
 * 
 * ## Example Usage
 * 
 * Creating a CPU serving endpoint
 * 
 * <pre>
 * {@code
 * package generated_program;
 * 
 * import com.pulumi.Context;
 * import com.pulumi.Pulumi;
 * import com.pulumi.core.Output;
 * import com.pulumi.databricks.ModelServing;
 * import com.pulumi.databricks.ModelServingArgs;
 * import com.pulumi.databricks.inputs.ModelServingConfigArgs;
 * import com.pulumi.databricks.inputs.ModelServingConfigTrafficConfigArgs;
 * import java.util.List;
 * import java.util.ArrayList;
 * import java.util.Map;
 * import java.io.File;
 * import java.nio.file.Files;
 * import java.nio.file.Paths;
 * 
 * public class App {
 *     public static void main(String[] args) {
 *         Pulumi.run(App::stack);
 *     }
 * 
 *     public static void stack(Context ctx) {
 *         var this_ = new ModelServing("this", ModelServingArgs.builder()
 *             .name("ads-serving-endpoint")
 *             .config(ModelServingConfigArgs.builder()
 *                 .servedEntities(                
 *                     ModelServingConfigServedEntityArgs.builder()
 *                         .name("prod_model")
 *                         .entityName("ads-model")
 *                         .entityVersion("2")
 *                         .workloadSize("Small")
 *                         .scaleToZeroEnabled(true)
 *                         .build(),
 *                     ModelServingConfigServedEntityArgs.builder()
 *                         .name("candidate_model")
 *                         .entityName("ads-model")
 *                         .entityVersion("4")
 *                         .workloadSize("Small")
 *                         .scaleToZeroEnabled(false)
 *                         .build())
 *                 .trafficConfig(ModelServingConfigTrafficConfigArgs.builder()
 *                     .routes(                    
 *                         ModelServingConfigTrafficConfigRouteArgs.builder()
 *                             .servedModelName("prod_model")
 *                             .trafficPercentage(90)
 *                             .build(),
 *                         ModelServingConfigTrafficConfigRouteArgs.builder()
 *                             .servedModelName("candidate_model")
 *                             .trafficPercentage(10)
 *                             .build())
 *                     .build())
 *                 .build())
 *             .build());
 * 
 *     }
 * }
 * }
 * </pre>
 * 
 * Creating a Foundation Model endpoint
 * 
 * <pre>
 * {@code
 * package generated_program;
 * 
 * import com.pulumi.Context;
 * import com.pulumi.Pulumi;
 * import com.pulumi.core.Output;
 * import com.pulumi.databricks.ModelServing;
 * import com.pulumi.databricks.ModelServingArgs;
 * import com.pulumi.databricks.inputs.ModelServingAiGatewayArgs;
 * import com.pulumi.databricks.inputs.ModelServingAiGatewayUsageTrackingConfigArgs;
 * import com.pulumi.databricks.inputs.ModelServingConfigArgs;
 * import java.util.List;
 * import java.util.ArrayList;
 * import java.util.Map;
 * import java.io.File;
 * import java.nio.file.Files;
 * import java.nio.file.Paths;
 * 
 * public class App {
 *     public static void main(String[] args) {
 *         Pulumi.run(App::stack);
 *     }
 * 
 *     public static void stack(Context ctx) {
 *         var llama = new ModelServing("llama", ModelServingArgs.builder()
 *             .name("llama_3_2_3b_instruct")
 *             .aiGateway(ModelServingAiGatewayArgs.builder()
 *                 .usageTrackingConfig(ModelServingAiGatewayUsageTrackingConfigArgs.builder()
 *                     .enabled(true)
 *                     .build())
 *                 .build())
 *             .config(ModelServingConfigArgs.builder()
 *                 .servedEntities(ModelServingConfigServedEntityArgs.builder()
 *                     .name("meta_llama_v3_2_3b_instruct-3")
 *                     .entityName("system.ai.llama_v3_2_3b_instruct")
 *                     .entityVersion("2")
 *                     .scaleToZeroEnabled(true)
 *                     .maxProvisionedThroughput(44000)
 *                     .build())
 *                 .build())
 *             .build());
 * 
 *     }
 * }
 * }
 * </pre>
 * 
 * Creating an External Model endpoint
 * 
 * <pre>
 * {@code
 * package generated_program;
 * 
 * import com.pulumi.Context;
 * import com.pulumi.Pulumi;
 * import com.pulumi.core.Output;
 * import com.pulumi.databricks.ModelServing;
 * import com.pulumi.databricks.ModelServingArgs;
 * import com.pulumi.databricks.inputs.ModelServingAiGatewayArgs;
 * import com.pulumi.databricks.inputs.ModelServingAiGatewayUsageTrackingConfigArgs;
 * import com.pulumi.databricks.inputs.ModelServingAiGatewayInferenceTableConfigArgs;
 * import com.pulumi.databricks.inputs.ModelServingAiGatewayGuardrailsArgs;
 * import com.pulumi.databricks.inputs.ModelServingAiGatewayGuardrailsInputArgs;
 * import com.pulumi.databricks.inputs.ModelServingAiGatewayGuardrailsInputPiiArgs;
 * import com.pulumi.databricks.inputs.ModelServingAiGatewayGuardrailsOutputArgs;
 * import com.pulumi.databricks.inputs.ModelServingAiGatewayGuardrailsOutputPiiArgs;
 * import com.pulumi.databricks.inputs.ModelServingConfigArgs;
 * import java.util.List;
 * import java.util.ArrayList;
 * import java.util.Map;
 * import java.io.File;
 * import java.nio.file.Files;
 * import java.nio.file.Paths;
 * 
 * public class App {
 *     public static void main(String[] args) {
 *         Pulumi.run(App::stack);
 *     }
 * 
 *     public static void stack(Context ctx) {
 *         var gpt4o = new ModelServing("gpt4o", ModelServingArgs.builder()
 *             .name("gpt-4o-mini")
 *             .aiGateway(ModelServingAiGatewayArgs.builder()
 *                 .usageTrackingConfig(ModelServingAiGatewayUsageTrackingConfigArgs.builder()
 *                     .enabled(true)
 *                     .build())
 *                 .rateLimits(ModelServingAiGatewayRateLimitArgs.builder()
 *                     .calls(10)
 *                     .key("endpoint")
 *                     .renewalPeriod("minute")
 *                     .build())
 *                 .inferenceTableConfig(ModelServingAiGatewayInferenceTableConfigArgs.builder()
 *                     .enabled(true)
 *                     .tableNamePrefix("gpt-4o-mini")
 *                     .catalogName("ml")
 *                     .schemaName("ai_gateway")
 *                     .build())
 *                 .guardrails(ModelServingAiGatewayGuardrailsArgs.builder()
 *                     .input(ModelServingAiGatewayGuardrailsInputArgs.builder()
 *                         .invalidKeywords("SuperSecretProject")
 *                         .pii(ModelServingAiGatewayGuardrailsInputPiiArgs.builder()
 *                             .behavior("BLOCK")
 *                             .build())
 *                         .build())
 *                     .output(ModelServingAiGatewayGuardrailsOutputArgs.builder()
 *                         .pii(ModelServingAiGatewayGuardrailsOutputPiiArgs.builder()
 *                             .behavior("BLOCK")
 *                             .build())
 *                         .build())
 *                     .build())
 *                 .build())
 *             .config(ModelServingConfigArgs.builder()
 *                 .servedEntities(ModelServingConfigServedEntityArgs.builder()
 *                     .name("gpt-4o-mini")
 *                     .externalModel(ModelServingConfigServedEntityExternalModelArgs.builder()
 *                         .name("gpt-4o-mini")
 *                         .provider("openai")
 *                         .task("llm/v1/chat")
 *                         .openaiConfig(ModelServingConfigServedEntityExternalModelOpenaiConfigArgs.builder()
 *                             .openaiApiKey("{{secrets/llm_scope/openai_api_key}}")
 *                             .build())
 *                         .build())
 *                     .build())
 *                 .build())
 *             .build());
 * 
 *     }
 * }
 * }
 * </pre>
 * 
 * ## Access Control
 * 
 * * databricks.Permissions can control which groups or individual users can *Manage*, *Query* or *View* individual serving endpoints.
 * 
 * ## Related Resources
 * 
 * The following resources are often used in the same context:
 * 
 * * databricks.ModelServingProvisionedThroughput to create [Foundation Model provisioned throughput](https://docs.databricks.com/aws/en/machine-learning/foundation-model-apis/deploy-prov-throughput-foundation-model-apis) endpoints in Databricks.
 * * databricks.RegisteredModel to create [Models in Unity Catalog](https://docs.databricks.com/en/mlflow/models-in-uc.html) in Databricks.
 * * End to end workspace management guide.
 * * databricks.Directory to manage directories in [Databricks Workspace](https://docs.databricks.com/workspace/workspace-objects.html).
 * * databricks.MlflowModel to create models in the [workspace model registry](https://docs.databricks.com/en/mlflow/model-registry.html) in Databricks.
 * * databricks.Notebook to manage [Databricks Notebooks](https://docs.databricks.com/notebooks/index.html).
 * * databricks.Notebook data to export a notebook from Databricks Workspace.
 * * databricks.Repo to manage [Databricks Repos](https://docs.databricks.com/repos.html).
 * 
 * ## Import
 * 
 * The model serving resource can be imported using the name of the endpoint.
 * 
 * hcl
 * 
 * import {
 * 
 *   to = databricks_model_serving.this
 * 
 *   id = &#34;&lt;model-serving-endpoint-name&gt;&#34;
 * 
 * }
 * 
 * Alternatively, when using `terraform` version 1.4 or earlier, import using the `pulumi import` command:
 * 
 * bash
 * 
 * ```sh
 * $ pulumi import databricks:index/modelServing:ModelServing this &lt;model-serving-endpoint-name&gt;
 * ```
 * 
 */
@ResourceType(type="databricks:index/modelServing:ModelServing")
public class ModelServing extends com.pulumi.resources.CustomResource {
    /**
     * A block with AI Gateway configuration for the serving endpoint. *Note: only external model endpoints are supported as of now.*
     * 
     */
    @Export(name="aiGateway", refs={ModelServingAiGateway.class}, tree="[0]")
    private Output</* @Nullable */ ModelServingAiGateway> aiGateway;

    /**
     * @return A block with AI Gateway configuration for the serving endpoint. *Note: only external model endpoints are supported as of now.*
     * 
     */
    public Output<Optional<ModelServingAiGateway>> aiGateway() {
        return Codegen.optional(this.aiGateway);
    }
    /**
     * The Budget Policy ID set for this serving endpoint.
     * 
     */
    @Export(name="budgetPolicyId", refs={String.class}, tree="[0]")
    private Output</* @Nullable */ String> budgetPolicyId;

    /**
     * @return The Budget Policy ID set for this serving endpoint.
     * 
     */
    public Output<Optional<String>> budgetPolicyId() {
        return Codegen.optional(this.budgetPolicyId);
    }
    /**
     * The model serving endpoint configuration. This is optional and can be added and modified after creation. If `config` was provided in a previous apply but is not provided in the current apply, no change to the model serving endpoint will occur. To recreate the model serving endpoint without the `config` block, the model serving endpoint must be destroyed and recreated.
     * 
     */
    @Export(name="config", refs={ModelServingConfig.class}, tree="[0]")
    private Output<ModelServingConfig> config;

    /**
     * @return The model serving endpoint configuration. This is optional and can be added and modified after creation. If `config` was provided in a previous apply but is not provided in the current apply, no change to the model serving endpoint will occur. To recreate the model serving endpoint without the `config` block, the model serving endpoint must be destroyed and recreated.
     * 
     */
    public Output<ModelServingConfig> config() {
        return this.config;
    }
    /**
     * The description of the model serving endpoint.
     * 
     */
    @Export(name="description", refs={String.class}, tree="[0]")
    private Output</* @Nullable */ String> description;

    /**
     * @return The description of the model serving endpoint.
     * 
     */
    public Output<Optional<String>> description() {
        return Codegen.optional(this.description);
    }
    /**
     * A block with Email notification setting.
     * 
     */
    @Export(name="emailNotifications", refs={ModelServingEmailNotifications.class}, tree="[0]")
    private Output</* @Nullable */ ModelServingEmailNotifications> emailNotifications;

    /**
     * @return A block with Email notification setting.
     * 
     */
    public Output<Optional<ModelServingEmailNotifications>> emailNotifications() {
        return Codegen.optional(this.emailNotifications);
    }
    /**
     * Invocation url of the endpoint.
     * 
     */
    @Export(name="endpointUrl", refs={String.class}, tree="[0]")
    private Output<String> endpointUrl;

    /**
     * @return Invocation url of the endpoint.
     * 
     */
    public Output<String> endpointUrl() {
        return this.endpointUrl;
    }
    /**
     * The name of the model serving endpoint. This field is required and must be unique across a workspace. An endpoint name can consist of alphanumeric characters, dashes, and underscores. NOTE: Changing this name will delete the existing endpoint and create a new endpoint with the updated name.
     * 
     */
    @Export(name="name", refs={String.class}, tree="[0]")
    private Output<String> name;

    /**
     * @return The name of the model serving endpoint. This field is required and must be unique across a workspace. An endpoint name can consist of alphanumeric characters, dashes, and underscores. NOTE: Changing this name will delete the existing endpoint and create a new endpoint with the updated name.
     * 
     */
    public Output<String> name() {
        return this.name;
    }
    /**
     * A list of rate limit blocks to be applied to the serving endpoint. *Note: only external and foundation model endpoints are supported as of now.*
     * 
     * @deprecated
     * Please use AI Gateway to manage rate limits.
     * 
     */
    @Deprecated /* Please use AI Gateway to manage rate limits. */
    @Export(name="rateLimits", refs={List.class,ModelServingRateLimit.class}, tree="[0,1]")
    private Output</* @Nullable */ List<ModelServingRateLimit>> rateLimits;

    /**
     * @return A list of rate limit blocks to be applied to the serving endpoint. *Note: only external and foundation model endpoints are supported as of now.*
     * 
     */
    public Output<Optional<List<ModelServingRateLimit>>> rateLimits() {
        return Codegen.optional(this.rateLimits);
    }
    /**
     * A boolean enabling route optimization for the endpoint. *Note: only available for custom models.*
     * 
     */
    @Export(name="routeOptimized", refs={Boolean.class}, tree="[0]")
    private Output</* @Nullable */ Boolean> routeOptimized;

    /**
     * @return A boolean enabling route optimization for the endpoint. *Note: only available for custom models.*
     * 
     */
    public Output<Optional<Boolean>> routeOptimized() {
        return Codegen.optional(this.routeOptimized);
    }
    /**
     * Unique identifier of the serving endpoint primarily used to set permissions and refer to this instance for other operations.
     * 
     */
    @Export(name="servingEndpointId", refs={String.class}, tree="[0]")
    private Output<String> servingEndpointId;

    /**
     * @return Unique identifier of the serving endpoint primarily used to set permissions and refer to this instance for other operations.
     * 
     */
    public Output<String> servingEndpointId() {
        return this.servingEndpointId;
    }
    /**
     * Tags to be attached to the serving endpoint and automatically propagated to billing logs.
     * 
     */
    @Export(name="tags", refs={List.class,ModelServingTag.class}, tree="[0,1]")
    private Output</* @Nullable */ List<ModelServingTag>> tags;

    /**
     * @return Tags to be attached to the serving endpoint and automatically propagated to billing logs.
     * 
     */
    public Output<Optional<List<ModelServingTag>>> tags() {
        return Codegen.optional(this.tags);
    }

    /**
     *
     * @param name The _unique_ name of the resulting resource.
     */
    public ModelServing(java.lang.String name) {
        this(name, ModelServingArgs.Empty);
    }
    /**
     *
     * @param name The _unique_ name of the resulting resource.
     * @param args The arguments to use to populate this resource's properties.
     */
    public ModelServing(java.lang.String name, @Nullable ModelServingArgs args) {
        this(name, args, null);
    }
    /**
     *
     * @param name The _unique_ name of the resulting resource.
     * @param args The arguments to use to populate this resource's properties.
     * @param options A bag of options that control this resource's behavior.
     */
    public ModelServing(java.lang.String name, @Nullable ModelServingArgs args, @Nullable com.pulumi.resources.CustomResourceOptions options) {
        super("databricks:index/modelServing:ModelServing", name, makeArgs(args, options), makeResourceOptions(options, Codegen.empty()), false);
    }

    private ModelServing(java.lang.String name, Output<java.lang.String> id, @Nullable ModelServingState state, @Nullable com.pulumi.resources.CustomResourceOptions options) {
        super("databricks:index/modelServing:ModelServing", name, state, makeResourceOptions(options, id), false);
    }

    private static ModelServingArgs makeArgs(@Nullable ModelServingArgs args, @Nullable com.pulumi.resources.CustomResourceOptions options) {
        if (options != null && options.getUrn().isPresent()) {
            return null;
        }
        return args == null ? ModelServingArgs.Empty : args;
    }

    private static com.pulumi.resources.CustomResourceOptions makeResourceOptions(@Nullable com.pulumi.resources.CustomResourceOptions options, @Nullable Output<java.lang.String> id) {
        var defaultOptions = com.pulumi.resources.CustomResourceOptions.builder()
            .version(Utilities.getVersion())
            .build();
        return com.pulumi.resources.CustomResourceOptions.merge(defaultOptions, options, id);
    }

    /**
     * Get an existing Host resource's state with the given name, ID, and optional extra
     * properties used to qualify the lookup.
     *
     * @param name The _unique_ name of the resulting resource.
     * @param id The _unique_ provider ID of the resource to lookup.
     * @param state
     * @param options Optional settings to control the behavior of the CustomResource.
     */
    public static ModelServing get(java.lang.String name, Output<java.lang.String> id, @Nullable ModelServingState state, @Nullable com.pulumi.resources.CustomResourceOptions options) {
        return new ModelServing(name, id, state, options);
    }
}
