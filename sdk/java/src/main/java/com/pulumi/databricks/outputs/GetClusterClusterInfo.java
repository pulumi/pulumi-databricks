// *** WARNING: this file was generated by pulumi-java-gen. ***
// *** Do not edit by hand unless you're certain you know what you are doing! ***

package com.pulumi.databricks.outputs;

import com.pulumi.core.annotations.CustomType;
import com.pulumi.databricks.outputs.GetClusterClusterInfoAutoscale;
import com.pulumi.databricks.outputs.GetClusterClusterInfoAwsAttributes;
import com.pulumi.databricks.outputs.GetClusterClusterInfoAzureAttributes;
import com.pulumi.databricks.outputs.GetClusterClusterInfoClusterLogConf;
import com.pulumi.databricks.outputs.GetClusterClusterInfoClusterLogStatus;
import com.pulumi.databricks.outputs.GetClusterClusterInfoDockerImage;
import com.pulumi.databricks.outputs.GetClusterClusterInfoDriver;
import com.pulumi.databricks.outputs.GetClusterClusterInfoExecutor;
import com.pulumi.databricks.outputs.GetClusterClusterInfoGcpAttributes;
import com.pulumi.databricks.outputs.GetClusterClusterInfoInitScript;
import com.pulumi.databricks.outputs.GetClusterClusterInfoTerminationReason;
import java.lang.Boolean;
import java.lang.Double;
import java.lang.Integer;
import java.lang.Object;
import java.lang.String;
import java.util.List;
import java.util.Map;
import java.util.Objects;
import java.util.Optional;
import javax.annotation.Nullable;

@CustomType
public final class GetClusterClusterInfo {
    private final @Nullable GetClusterClusterInfoAutoscale autoscale;
    /**
     * @return Automatically terminate the cluster after being inactive for this time in minutes. If specified, the threshold must be between 10 and 10000 minutes. You can also set this value to 0 to explicitly disable automatic termination.
     * 
     */
    private final @Nullable Integer autoterminationMinutes;
    private final @Nullable GetClusterClusterInfoAwsAttributes awsAttributes;
    private final @Nullable GetClusterClusterInfoAzureAttributes azureAttributes;
    private final @Nullable Double clusterCores;
    /**
     * @return The id of the cluster
     * 
     */
    private final @Nullable String clusterId;
    private final @Nullable GetClusterClusterInfoClusterLogConf clusterLogConf;
    private final @Nullable GetClusterClusterInfoClusterLogStatus clusterLogStatus;
    private final @Nullable Integer clusterMemoryMb;
    /**
     * @return Cluster name, which doesn’t have to be unique.
     * 
     */
    private final @Nullable String clusterName;
    private final @Nullable String clusterSource;
    private final @Nullable String creatorUserName;
    /**
     * @return Additional tags for cluster resources.
     * 
     */
    private final @Nullable Map<String,Object> customTags;
    /**
     * @return Security features of the cluster. Unity Catalog requires `SINGLE_USER` or `USER_ISOLATION` mode. `LEGACY_PASSTHROUGH` for passthrough cluster and `LEGACY_TABLE_ACL` for Table ACL cluster. Default to `NONE`, i.e. no security feature enabled.
     * 
     */
    private final @Nullable String dataSecurityMode;
    private final Map<String,Object> defaultTags;
    private final @Nullable GetClusterClusterInfoDockerImage dockerImage;
    private final @Nullable GetClusterClusterInfoDriver driver;
    /**
     * @return similar to `instance_pool_id`, but for driver node.
     * 
     */
    private final String driverInstancePoolId;
    /**
     * @return The node type of the Spark driver.
     * 
     */
    private final @Nullable String driverNodeTypeId;
    /**
     * @return Use autoscaling local storage.
     * 
     */
    private final @Nullable Boolean enableElasticDisk;
    /**
     * @return Enable local disk encryption.
     * 
     */
    private final @Nullable Boolean enableLocalDiskEncryption;
    private final @Nullable List<GetClusterClusterInfoExecutor> executors;
    private final @Nullable GetClusterClusterInfoGcpAttributes gcpAttributes;
    private final @Nullable List<GetClusterClusterInfoInitScript> initScripts;
    private final @Nullable String instancePoolId;
    private final @Nullable Integer jdbcPort;
    private final @Nullable Integer lastActivityTime;
    private final @Nullable Integer lastStateLossTime;
    /**
     * @return Any supported databricks.getNodeType id.
     * * `instance_pool_id` The pool of idle instances the cluster is attached to.
     * 
     */
    private final @Nullable String nodeTypeId;
    private final @Nullable Integer numWorkers;
    /**
     * @return Identifier of Cluster Policy to validate cluster and preset certain defaults.
     * 
     */
    private final @Nullable String policyId;
    /**
     * @return The optional user name of the user to assign to an interactive cluster. This field is required when using standard AAD Passthrough for Azure Data Lake Storage (ADLS) with a single-user cluster (i.e., not high-concurrency clusters).
     * 
     */
    private final @Nullable String singleUserName;
    /**
     * @return Map with key-value pairs to fine-tune Spark clusters.
     * 
     */
    private final @Nullable Map<String,Object> sparkConf;
    private final @Nullable Integer sparkContextId;
    /**
     * @return Map with environment variable key-value pairs to fine-tune Spark clusters. Key-value pairs of the form (X,Y) are exported (i.e., X=&#39;Y&#39;) while launching the driver and workers.
     * 
     */
    private final @Nullable Map<String,Object> sparkEnvVars;
    /**
     * @return [Runtime version](https://docs.databricks.com/runtime/index.html) of the cluster.
     * 
     */
    private final String sparkVersion;
    /**
     * @return SSH public key contents that will be added to each Spark node in this cluster.
     * 
     */
    private final @Nullable List<String> sshPublicKeys;
    private final @Nullable Integer startTime;
    private final String state;
    private final @Nullable String stateMessage;
    private final @Nullable Integer terminateTime;
    private final @Nullable GetClusterClusterInfoTerminationReason terminationReason;

    @CustomType.Constructor
    private GetClusterClusterInfo(
        @CustomType.Parameter("autoscale") @Nullable GetClusterClusterInfoAutoscale autoscale,
        @CustomType.Parameter("autoterminationMinutes") @Nullable Integer autoterminationMinutes,
        @CustomType.Parameter("awsAttributes") @Nullable GetClusterClusterInfoAwsAttributes awsAttributes,
        @CustomType.Parameter("azureAttributes") @Nullable GetClusterClusterInfoAzureAttributes azureAttributes,
        @CustomType.Parameter("clusterCores") @Nullable Double clusterCores,
        @CustomType.Parameter("clusterId") @Nullable String clusterId,
        @CustomType.Parameter("clusterLogConf") @Nullable GetClusterClusterInfoClusterLogConf clusterLogConf,
        @CustomType.Parameter("clusterLogStatus") @Nullable GetClusterClusterInfoClusterLogStatus clusterLogStatus,
        @CustomType.Parameter("clusterMemoryMb") @Nullable Integer clusterMemoryMb,
        @CustomType.Parameter("clusterName") @Nullable String clusterName,
        @CustomType.Parameter("clusterSource") @Nullable String clusterSource,
        @CustomType.Parameter("creatorUserName") @Nullable String creatorUserName,
        @CustomType.Parameter("customTags") @Nullable Map<String,Object> customTags,
        @CustomType.Parameter("dataSecurityMode") @Nullable String dataSecurityMode,
        @CustomType.Parameter("defaultTags") Map<String,Object> defaultTags,
        @CustomType.Parameter("dockerImage") @Nullable GetClusterClusterInfoDockerImage dockerImage,
        @CustomType.Parameter("driver") @Nullable GetClusterClusterInfoDriver driver,
        @CustomType.Parameter("driverInstancePoolId") String driverInstancePoolId,
        @CustomType.Parameter("driverNodeTypeId") @Nullable String driverNodeTypeId,
        @CustomType.Parameter("enableElasticDisk") @Nullable Boolean enableElasticDisk,
        @CustomType.Parameter("enableLocalDiskEncryption") @Nullable Boolean enableLocalDiskEncryption,
        @CustomType.Parameter("executors") @Nullable List<GetClusterClusterInfoExecutor> executors,
        @CustomType.Parameter("gcpAttributes") @Nullable GetClusterClusterInfoGcpAttributes gcpAttributes,
        @CustomType.Parameter("initScripts") @Nullable List<GetClusterClusterInfoInitScript> initScripts,
        @CustomType.Parameter("instancePoolId") @Nullable String instancePoolId,
        @CustomType.Parameter("jdbcPort") @Nullable Integer jdbcPort,
        @CustomType.Parameter("lastActivityTime") @Nullable Integer lastActivityTime,
        @CustomType.Parameter("lastStateLossTime") @Nullable Integer lastStateLossTime,
        @CustomType.Parameter("nodeTypeId") @Nullable String nodeTypeId,
        @CustomType.Parameter("numWorkers") @Nullable Integer numWorkers,
        @CustomType.Parameter("policyId") @Nullable String policyId,
        @CustomType.Parameter("singleUserName") @Nullable String singleUserName,
        @CustomType.Parameter("sparkConf") @Nullable Map<String,Object> sparkConf,
        @CustomType.Parameter("sparkContextId") @Nullable Integer sparkContextId,
        @CustomType.Parameter("sparkEnvVars") @Nullable Map<String,Object> sparkEnvVars,
        @CustomType.Parameter("sparkVersion") String sparkVersion,
        @CustomType.Parameter("sshPublicKeys") @Nullable List<String> sshPublicKeys,
        @CustomType.Parameter("startTime") @Nullable Integer startTime,
        @CustomType.Parameter("state") String state,
        @CustomType.Parameter("stateMessage") @Nullable String stateMessage,
        @CustomType.Parameter("terminateTime") @Nullable Integer terminateTime,
        @CustomType.Parameter("terminationReason") @Nullable GetClusterClusterInfoTerminationReason terminationReason) {
        this.autoscale = autoscale;
        this.autoterminationMinutes = autoterminationMinutes;
        this.awsAttributes = awsAttributes;
        this.azureAttributes = azureAttributes;
        this.clusterCores = clusterCores;
        this.clusterId = clusterId;
        this.clusterLogConf = clusterLogConf;
        this.clusterLogStatus = clusterLogStatus;
        this.clusterMemoryMb = clusterMemoryMb;
        this.clusterName = clusterName;
        this.clusterSource = clusterSource;
        this.creatorUserName = creatorUserName;
        this.customTags = customTags;
        this.dataSecurityMode = dataSecurityMode;
        this.defaultTags = defaultTags;
        this.dockerImage = dockerImage;
        this.driver = driver;
        this.driverInstancePoolId = driverInstancePoolId;
        this.driverNodeTypeId = driverNodeTypeId;
        this.enableElasticDisk = enableElasticDisk;
        this.enableLocalDiskEncryption = enableLocalDiskEncryption;
        this.executors = executors;
        this.gcpAttributes = gcpAttributes;
        this.initScripts = initScripts;
        this.instancePoolId = instancePoolId;
        this.jdbcPort = jdbcPort;
        this.lastActivityTime = lastActivityTime;
        this.lastStateLossTime = lastStateLossTime;
        this.nodeTypeId = nodeTypeId;
        this.numWorkers = numWorkers;
        this.policyId = policyId;
        this.singleUserName = singleUserName;
        this.sparkConf = sparkConf;
        this.sparkContextId = sparkContextId;
        this.sparkEnvVars = sparkEnvVars;
        this.sparkVersion = sparkVersion;
        this.sshPublicKeys = sshPublicKeys;
        this.startTime = startTime;
        this.state = state;
        this.stateMessage = stateMessage;
        this.terminateTime = terminateTime;
        this.terminationReason = terminationReason;
    }

    public Optional<GetClusterClusterInfoAutoscale> autoscale() {
        return Optional.ofNullable(this.autoscale);
    }
    /**
     * @return Automatically terminate the cluster after being inactive for this time in minutes. If specified, the threshold must be between 10 and 10000 minutes. You can also set this value to 0 to explicitly disable automatic termination.
     * 
     */
    public Optional<Integer> autoterminationMinutes() {
        return Optional.ofNullable(this.autoterminationMinutes);
    }
    public Optional<GetClusterClusterInfoAwsAttributes> awsAttributes() {
        return Optional.ofNullable(this.awsAttributes);
    }
    public Optional<GetClusterClusterInfoAzureAttributes> azureAttributes() {
        return Optional.ofNullable(this.azureAttributes);
    }
    public Optional<Double> clusterCores() {
        return Optional.ofNullable(this.clusterCores);
    }
    /**
     * @return The id of the cluster
     * 
     */
    public Optional<String> clusterId() {
        return Optional.ofNullable(this.clusterId);
    }
    public Optional<GetClusterClusterInfoClusterLogConf> clusterLogConf() {
        return Optional.ofNullable(this.clusterLogConf);
    }
    public Optional<GetClusterClusterInfoClusterLogStatus> clusterLogStatus() {
        return Optional.ofNullable(this.clusterLogStatus);
    }
    public Optional<Integer> clusterMemoryMb() {
        return Optional.ofNullable(this.clusterMemoryMb);
    }
    /**
     * @return Cluster name, which doesn’t have to be unique.
     * 
     */
    public Optional<String> clusterName() {
        return Optional.ofNullable(this.clusterName);
    }
    public Optional<String> clusterSource() {
        return Optional.ofNullable(this.clusterSource);
    }
    public Optional<String> creatorUserName() {
        return Optional.ofNullable(this.creatorUserName);
    }
    /**
     * @return Additional tags for cluster resources.
     * 
     */
    public Map<String,Object> customTags() {
        return this.customTags == null ? Map.of() : this.customTags;
    }
    /**
     * @return Security features of the cluster. Unity Catalog requires `SINGLE_USER` or `USER_ISOLATION` mode. `LEGACY_PASSTHROUGH` for passthrough cluster and `LEGACY_TABLE_ACL` for Table ACL cluster. Default to `NONE`, i.e. no security feature enabled.
     * 
     */
    public Optional<String> dataSecurityMode() {
        return Optional.ofNullable(this.dataSecurityMode);
    }
    public Map<String,Object> defaultTags() {
        return this.defaultTags;
    }
    public Optional<GetClusterClusterInfoDockerImage> dockerImage() {
        return Optional.ofNullable(this.dockerImage);
    }
    public Optional<GetClusterClusterInfoDriver> driver() {
        return Optional.ofNullable(this.driver);
    }
    /**
     * @return similar to `instance_pool_id`, but for driver node.
     * 
     */
    public String driverInstancePoolId() {
        return this.driverInstancePoolId;
    }
    /**
     * @return The node type of the Spark driver.
     * 
     */
    public Optional<String> driverNodeTypeId() {
        return Optional.ofNullable(this.driverNodeTypeId);
    }
    /**
     * @return Use autoscaling local storage.
     * 
     */
    public Optional<Boolean> enableElasticDisk() {
        return Optional.ofNullable(this.enableElasticDisk);
    }
    /**
     * @return Enable local disk encryption.
     * 
     */
    public Optional<Boolean> enableLocalDiskEncryption() {
        return Optional.ofNullable(this.enableLocalDiskEncryption);
    }
    public List<GetClusterClusterInfoExecutor> executors() {
        return this.executors == null ? List.of() : this.executors;
    }
    public Optional<GetClusterClusterInfoGcpAttributes> gcpAttributes() {
        return Optional.ofNullable(this.gcpAttributes);
    }
    public List<GetClusterClusterInfoInitScript> initScripts() {
        return this.initScripts == null ? List.of() : this.initScripts;
    }
    public Optional<String> instancePoolId() {
        return Optional.ofNullable(this.instancePoolId);
    }
    public Optional<Integer> jdbcPort() {
        return Optional.ofNullable(this.jdbcPort);
    }
    public Optional<Integer> lastActivityTime() {
        return Optional.ofNullable(this.lastActivityTime);
    }
    public Optional<Integer> lastStateLossTime() {
        return Optional.ofNullable(this.lastStateLossTime);
    }
    /**
     * @return Any supported databricks.getNodeType id.
     * * `instance_pool_id` The pool of idle instances the cluster is attached to.
     * 
     */
    public Optional<String> nodeTypeId() {
        return Optional.ofNullable(this.nodeTypeId);
    }
    public Optional<Integer> numWorkers() {
        return Optional.ofNullable(this.numWorkers);
    }
    /**
     * @return Identifier of Cluster Policy to validate cluster and preset certain defaults.
     * 
     */
    public Optional<String> policyId() {
        return Optional.ofNullable(this.policyId);
    }
    /**
     * @return The optional user name of the user to assign to an interactive cluster. This field is required when using standard AAD Passthrough for Azure Data Lake Storage (ADLS) with a single-user cluster (i.e., not high-concurrency clusters).
     * 
     */
    public Optional<String> singleUserName() {
        return Optional.ofNullable(this.singleUserName);
    }
    /**
     * @return Map with key-value pairs to fine-tune Spark clusters.
     * 
     */
    public Map<String,Object> sparkConf() {
        return this.sparkConf == null ? Map.of() : this.sparkConf;
    }
    public Optional<Integer> sparkContextId() {
        return Optional.ofNullable(this.sparkContextId);
    }
    /**
     * @return Map with environment variable key-value pairs to fine-tune Spark clusters. Key-value pairs of the form (X,Y) are exported (i.e., X=&#39;Y&#39;) while launching the driver and workers.
     * 
     */
    public Map<String,Object> sparkEnvVars() {
        return this.sparkEnvVars == null ? Map.of() : this.sparkEnvVars;
    }
    /**
     * @return [Runtime version](https://docs.databricks.com/runtime/index.html) of the cluster.
     * 
     */
    public String sparkVersion() {
        return this.sparkVersion;
    }
    /**
     * @return SSH public key contents that will be added to each Spark node in this cluster.
     * 
     */
    public List<String> sshPublicKeys() {
        return this.sshPublicKeys == null ? List.of() : this.sshPublicKeys;
    }
    public Optional<Integer> startTime() {
        return Optional.ofNullable(this.startTime);
    }
    public String state() {
        return this.state;
    }
    public Optional<String> stateMessage() {
        return Optional.ofNullable(this.stateMessage);
    }
    public Optional<Integer> terminateTime() {
        return Optional.ofNullable(this.terminateTime);
    }
    public Optional<GetClusterClusterInfoTerminationReason> terminationReason() {
        return Optional.ofNullable(this.terminationReason);
    }

    public static Builder builder() {
        return new Builder();
    }

    public static Builder builder(GetClusterClusterInfo defaults) {
        return new Builder(defaults);
    }

    public static final class Builder {
        private @Nullable GetClusterClusterInfoAutoscale autoscale;
        private @Nullable Integer autoterminationMinutes;
        private @Nullable GetClusterClusterInfoAwsAttributes awsAttributes;
        private @Nullable GetClusterClusterInfoAzureAttributes azureAttributes;
        private @Nullable Double clusterCores;
        private @Nullable String clusterId;
        private @Nullable GetClusterClusterInfoClusterLogConf clusterLogConf;
        private @Nullable GetClusterClusterInfoClusterLogStatus clusterLogStatus;
        private @Nullable Integer clusterMemoryMb;
        private @Nullable String clusterName;
        private @Nullable String clusterSource;
        private @Nullable String creatorUserName;
        private @Nullable Map<String,Object> customTags;
        private @Nullable String dataSecurityMode;
        private Map<String,Object> defaultTags;
        private @Nullable GetClusterClusterInfoDockerImage dockerImage;
        private @Nullable GetClusterClusterInfoDriver driver;
        private String driverInstancePoolId;
        private @Nullable String driverNodeTypeId;
        private @Nullable Boolean enableElasticDisk;
        private @Nullable Boolean enableLocalDiskEncryption;
        private @Nullable List<GetClusterClusterInfoExecutor> executors;
        private @Nullable GetClusterClusterInfoGcpAttributes gcpAttributes;
        private @Nullable List<GetClusterClusterInfoInitScript> initScripts;
        private @Nullable String instancePoolId;
        private @Nullable Integer jdbcPort;
        private @Nullable Integer lastActivityTime;
        private @Nullable Integer lastStateLossTime;
        private @Nullable String nodeTypeId;
        private @Nullable Integer numWorkers;
        private @Nullable String policyId;
        private @Nullable String singleUserName;
        private @Nullable Map<String,Object> sparkConf;
        private @Nullable Integer sparkContextId;
        private @Nullable Map<String,Object> sparkEnvVars;
        private String sparkVersion;
        private @Nullable List<String> sshPublicKeys;
        private @Nullable Integer startTime;
        private String state;
        private @Nullable String stateMessage;
        private @Nullable Integer terminateTime;
        private @Nullable GetClusterClusterInfoTerminationReason terminationReason;

        public Builder() {
    	      // Empty
        }

        public Builder(GetClusterClusterInfo defaults) {
    	      Objects.requireNonNull(defaults);
    	      this.autoscale = defaults.autoscale;
    	      this.autoterminationMinutes = defaults.autoterminationMinutes;
    	      this.awsAttributes = defaults.awsAttributes;
    	      this.azureAttributes = defaults.azureAttributes;
    	      this.clusterCores = defaults.clusterCores;
    	      this.clusterId = defaults.clusterId;
    	      this.clusterLogConf = defaults.clusterLogConf;
    	      this.clusterLogStatus = defaults.clusterLogStatus;
    	      this.clusterMemoryMb = defaults.clusterMemoryMb;
    	      this.clusterName = defaults.clusterName;
    	      this.clusterSource = defaults.clusterSource;
    	      this.creatorUserName = defaults.creatorUserName;
    	      this.customTags = defaults.customTags;
    	      this.dataSecurityMode = defaults.dataSecurityMode;
    	      this.defaultTags = defaults.defaultTags;
    	      this.dockerImage = defaults.dockerImage;
    	      this.driver = defaults.driver;
    	      this.driverInstancePoolId = defaults.driverInstancePoolId;
    	      this.driverNodeTypeId = defaults.driverNodeTypeId;
    	      this.enableElasticDisk = defaults.enableElasticDisk;
    	      this.enableLocalDiskEncryption = defaults.enableLocalDiskEncryption;
    	      this.executors = defaults.executors;
    	      this.gcpAttributes = defaults.gcpAttributes;
    	      this.initScripts = defaults.initScripts;
    	      this.instancePoolId = defaults.instancePoolId;
    	      this.jdbcPort = defaults.jdbcPort;
    	      this.lastActivityTime = defaults.lastActivityTime;
    	      this.lastStateLossTime = defaults.lastStateLossTime;
    	      this.nodeTypeId = defaults.nodeTypeId;
    	      this.numWorkers = defaults.numWorkers;
    	      this.policyId = defaults.policyId;
    	      this.singleUserName = defaults.singleUserName;
    	      this.sparkConf = defaults.sparkConf;
    	      this.sparkContextId = defaults.sparkContextId;
    	      this.sparkEnvVars = defaults.sparkEnvVars;
    	      this.sparkVersion = defaults.sparkVersion;
    	      this.sshPublicKeys = defaults.sshPublicKeys;
    	      this.startTime = defaults.startTime;
    	      this.state = defaults.state;
    	      this.stateMessage = defaults.stateMessage;
    	      this.terminateTime = defaults.terminateTime;
    	      this.terminationReason = defaults.terminationReason;
        }

        public Builder autoscale(@Nullable GetClusterClusterInfoAutoscale autoscale) {
            this.autoscale = autoscale;
            return this;
        }
        public Builder autoterminationMinutes(@Nullable Integer autoterminationMinutes) {
            this.autoterminationMinutes = autoterminationMinutes;
            return this;
        }
        public Builder awsAttributes(@Nullable GetClusterClusterInfoAwsAttributes awsAttributes) {
            this.awsAttributes = awsAttributes;
            return this;
        }
        public Builder azureAttributes(@Nullable GetClusterClusterInfoAzureAttributes azureAttributes) {
            this.azureAttributes = azureAttributes;
            return this;
        }
        public Builder clusterCores(@Nullable Double clusterCores) {
            this.clusterCores = clusterCores;
            return this;
        }
        public Builder clusterId(@Nullable String clusterId) {
            this.clusterId = clusterId;
            return this;
        }
        public Builder clusterLogConf(@Nullable GetClusterClusterInfoClusterLogConf clusterLogConf) {
            this.clusterLogConf = clusterLogConf;
            return this;
        }
        public Builder clusterLogStatus(@Nullable GetClusterClusterInfoClusterLogStatus clusterLogStatus) {
            this.clusterLogStatus = clusterLogStatus;
            return this;
        }
        public Builder clusterMemoryMb(@Nullable Integer clusterMemoryMb) {
            this.clusterMemoryMb = clusterMemoryMb;
            return this;
        }
        public Builder clusterName(@Nullable String clusterName) {
            this.clusterName = clusterName;
            return this;
        }
        public Builder clusterSource(@Nullable String clusterSource) {
            this.clusterSource = clusterSource;
            return this;
        }
        public Builder creatorUserName(@Nullable String creatorUserName) {
            this.creatorUserName = creatorUserName;
            return this;
        }
        public Builder customTags(@Nullable Map<String,Object> customTags) {
            this.customTags = customTags;
            return this;
        }
        public Builder dataSecurityMode(@Nullable String dataSecurityMode) {
            this.dataSecurityMode = dataSecurityMode;
            return this;
        }
        public Builder defaultTags(Map<String,Object> defaultTags) {
            this.defaultTags = Objects.requireNonNull(defaultTags);
            return this;
        }
        public Builder dockerImage(@Nullable GetClusterClusterInfoDockerImage dockerImage) {
            this.dockerImage = dockerImage;
            return this;
        }
        public Builder driver(@Nullable GetClusterClusterInfoDriver driver) {
            this.driver = driver;
            return this;
        }
        public Builder driverInstancePoolId(String driverInstancePoolId) {
            this.driverInstancePoolId = Objects.requireNonNull(driverInstancePoolId);
            return this;
        }
        public Builder driverNodeTypeId(@Nullable String driverNodeTypeId) {
            this.driverNodeTypeId = driverNodeTypeId;
            return this;
        }
        public Builder enableElasticDisk(@Nullable Boolean enableElasticDisk) {
            this.enableElasticDisk = enableElasticDisk;
            return this;
        }
        public Builder enableLocalDiskEncryption(@Nullable Boolean enableLocalDiskEncryption) {
            this.enableLocalDiskEncryption = enableLocalDiskEncryption;
            return this;
        }
        public Builder executors(@Nullable List<GetClusterClusterInfoExecutor> executors) {
            this.executors = executors;
            return this;
        }
        public Builder executors(GetClusterClusterInfoExecutor... executors) {
            return executors(List.of(executors));
        }
        public Builder gcpAttributes(@Nullable GetClusterClusterInfoGcpAttributes gcpAttributes) {
            this.gcpAttributes = gcpAttributes;
            return this;
        }
        public Builder initScripts(@Nullable List<GetClusterClusterInfoInitScript> initScripts) {
            this.initScripts = initScripts;
            return this;
        }
        public Builder initScripts(GetClusterClusterInfoInitScript... initScripts) {
            return initScripts(List.of(initScripts));
        }
        public Builder instancePoolId(@Nullable String instancePoolId) {
            this.instancePoolId = instancePoolId;
            return this;
        }
        public Builder jdbcPort(@Nullable Integer jdbcPort) {
            this.jdbcPort = jdbcPort;
            return this;
        }
        public Builder lastActivityTime(@Nullable Integer lastActivityTime) {
            this.lastActivityTime = lastActivityTime;
            return this;
        }
        public Builder lastStateLossTime(@Nullable Integer lastStateLossTime) {
            this.lastStateLossTime = lastStateLossTime;
            return this;
        }
        public Builder nodeTypeId(@Nullable String nodeTypeId) {
            this.nodeTypeId = nodeTypeId;
            return this;
        }
        public Builder numWorkers(@Nullable Integer numWorkers) {
            this.numWorkers = numWorkers;
            return this;
        }
        public Builder policyId(@Nullable String policyId) {
            this.policyId = policyId;
            return this;
        }
        public Builder singleUserName(@Nullable String singleUserName) {
            this.singleUserName = singleUserName;
            return this;
        }
        public Builder sparkConf(@Nullable Map<String,Object> sparkConf) {
            this.sparkConf = sparkConf;
            return this;
        }
        public Builder sparkContextId(@Nullable Integer sparkContextId) {
            this.sparkContextId = sparkContextId;
            return this;
        }
        public Builder sparkEnvVars(@Nullable Map<String,Object> sparkEnvVars) {
            this.sparkEnvVars = sparkEnvVars;
            return this;
        }
        public Builder sparkVersion(String sparkVersion) {
            this.sparkVersion = Objects.requireNonNull(sparkVersion);
            return this;
        }
        public Builder sshPublicKeys(@Nullable List<String> sshPublicKeys) {
            this.sshPublicKeys = sshPublicKeys;
            return this;
        }
        public Builder sshPublicKeys(String... sshPublicKeys) {
            return sshPublicKeys(List.of(sshPublicKeys));
        }
        public Builder startTime(@Nullable Integer startTime) {
            this.startTime = startTime;
            return this;
        }
        public Builder state(String state) {
            this.state = Objects.requireNonNull(state);
            return this;
        }
        public Builder stateMessage(@Nullable String stateMessage) {
            this.stateMessage = stateMessage;
            return this;
        }
        public Builder terminateTime(@Nullable Integer terminateTime) {
            this.terminateTime = terminateTime;
            return this;
        }
        public Builder terminationReason(@Nullable GetClusterClusterInfoTerminationReason terminationReason) {
            this.terminationReason = terminationReason;
            return this;
        }        public GetClusterClusterInfo build() {
            return new GetClusterClusterInfo(autoscale, autoterminationMinutes, awsAttributes, azureAttributes, clusterCores, clusterId, clusterLogConf, clusterLogStatus, clusterMemoryMb, clusterName, clusterSource, creatorUserName, customTags, dataSecurityMode, defaultTags, dockerImage, driver, driverInstancePoolId, driverNodeTypeId, enableElasticDisk, enableLocalDiskEncryption, executors, gcpAttributes, initScripts, instancePoolId, jdbcPort, lastActivityTime, lastStateLossTime, nodeTypeId, numWorkers, policyId, singleUserName, sparkConf, sparkContextId, sparkEnvVars, sparkVersion, sshPublicKeys, startTime, state, stateMessage, terminateTime, terminationReason);
        }
    }
}
