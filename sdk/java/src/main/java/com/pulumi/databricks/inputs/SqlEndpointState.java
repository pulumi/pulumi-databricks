// *** WARNING: this file was generated by pulumi-java-gen. ***
// *** Do not edit by hand unless you're certain you know what you are doing! ***

package com.pulumi.databricks.inputs;

import com.pulumi.core.Output;
import com.pulumi.core.annotations.Import;
import com.pulumi.databricks.inputs.SqlEndpointChannelArgs;
import com.pulumi.databricks.inputs.SqlEndpointHealthArgs;
import com.pulumi.databricks.inputs.SqlEndpointOdbcParamsArgs;
import com.pulumi.databricks.inputs.SqlEndpointTagsArgs;
import java.lang.Boolean;
import java.lang.Integer;
import java.lang.String;
import java.util.List;
import java.util.Objects;
import java.util.Optional;
import javax.annotation.Nullable;


public final class SqlEndpointState extends com.pulumi.resources.ResourceArgs {

    public static final SqlEndpointState Empty = new SqlEndpointState();

    /**
     * Time in minutes until an idle SQL warehouse terminates all clusters and stops. This field is optional. The default is 120, set to 0 to disable the auto stop.
     * 
     */
    @Import(name="autoStopMins")
    private @Nullable Output<Integer> autoStopMins;

    /**
     * @return Time in minutes until an idle SQL warehouse terminates all clusters and stops. This field is optional. The default is 120, set to 0 to disable the auto stop.
     * 
     */
    public Optional<Output<Integer>> autoStopMins() {
        return Optional.ofNullable(this.autoStopMins);
    }

    /**
     * block, consisting of following fields:
     * 
     */
    @Import(name="channel")
    private @Nullable Output<SqlEndpointChannelArgs> channel;

    /**
     * @return block, consisting of following fields:
     * 
     */
    public Optional<Output<SqlEndpointChannelArgs>> channel() {
        return Optional.ofNullable(this.channel);
    }

    /**
     * The size of the clusters allocated to the endpoint: &#34;2X-Small&#34;, &#34;X-Small&#34;, &#34;Small&#34;, &#34;Medium&#34;, &#34;Large&#34;, &#34;X-Large&#34;, &#34;2X-Large&#34;, &#34;3X-Large&#34;, &#34;4X-Large&#34;.
     * 
     */
    @Import(name="clusterSize")
    private @Nullable Output<String> clusterSize;

    /**
     * @return The size of the clusters allocated to the endpoint: &#34;2X-Small&#34;, &#34;X-Small&#34;, &#34;Small&#34;, &#34;Medium&#34;, &#34;Large&#34;, &#34;X-Large&#34;, &#34;2X-Large&#34;, &#34;3X-Large&#34;, &#34;4X-Large&#34;.
     * 
     */
    public Optional<Output<String>> clusterSize() {
        return Optional.ofNullable(this.clusterSize);
    }

    /**
     * The username of the user who created the endpoint.
     * 
     */
    @Import(name="creatorName")
    private @Nullable Output<String> creatorName;

    /**
     * @return The username of the user who created the endpoint.
     * 
     */
    public Optional<Output<String>> creatorName() {
        return Optional.ofNullable(this.creatorName);
    }

    /**
     * ID of the data source for this endpoint. This is used to bind an Databricks SQL query to an endpoint.
     * 
     */
    @Import(name="dataSourceId")
    private @Nullable Output<String> dataSourceId;

    /**
     * @return ID of the data source for this endpoint. This is used to bind an Databricks SQL query to an endpoint.
     * 
     */
    public Optional<Output<String>> dataSourceId() {
        return Optional.ofNullable(this.dataSourceId);
    }

    /**
     * Whether to enable [Photon](https://databricks.com/product/delta-engine). This field is optional and is enabled by default.
     * 
     */
    @Import(name="enablePhoton")
    private @Nullable Output<Boolean> enablePhoton;

    /**
     * @return Whether to enable [Photon](https://databricks.com/product/delta-engine). This field is optional and is enabled by default.
     * 
     */
    public Optional<Output<Boolean>> enablePhoton() {
        return Optional.ofNullable(this.enablePhoton);
    }

    /**
     * Whether this SQL warehouse is a serverless endpoint. See below for details about the default values. To avoid ambiguity, especially for organizations with many workspaces, Databricks recommends that you always set this field explicitly.
     * 
     * - **For AWS**, If omitted, the default is `false` for most workspaces. However, if this workspace used the SQL Warehouses API to create a warehouse between September 1, 2022 and April 30, 2023, the default remains the previous behavior which is default to `true` if the workspace is enabled for serverless and fits the requirements for serverless SQL warehouses. If your account needs updated [terms of use](https://docs.databricks.com/sql/admin/serverless.html#accept-terms), workspace admins are prompted in the Databricks SQL UI. A workspace must meet the [requirements](https://docs.databricks.com/sql/admin/serverless.html#requirements) and might require an update to its instance profile role to [add a trust relationship](https://docs.databricks.com/sql/admin/serverless.html#aws-instance-profile-setup).
     * 
     * - **For Azure**, If omitted, the default is `false` for most workspaces. However, if this workspace used the SQL Warehouses API to create a warehouse between November 1, 2022 and May 19, 2023, the default remains the previous behavior which is default to `true` if the workspace is enabled for serverless and fits the requirements for serverless SQL warehouses. A workspace must meet the [requirements](https://learn.microsoft.com/azure/databricks/sql/admin/serverless) and might require an update to its [Azure storage firewall](https://learn.microsoft.com/azure/databricks/sql/admin/serverless-firewall).
     * 
     */
    @Import(name="enableServerlessCompute")
    private @Nullable Output<Boolean> enableServerlessCompute;

    /**
     * @return Whether this SQL warehouse is a serverless endpoint. See below for details about the default values. To avoid ambiguity, especially for organizations with many workspaces, Databricks recommends that you always set this field explicitly.
     * 
     * - **For AWS**, If omitted, the default is `false` for most workspaces. However, if this workspace used the SQL Warehouses API to create a warehouse between September 1, 2022 and April 30, 2023, the default remains the previous behavior which is default to `true` if the workspace is enabled for serverless and fits the requirements for serverless SQL warehouses. If your account needs updated [terms of use](https://docs.databricks.com/sql/admin/serverless.html#accept-terms), workspace admins are prompted in the Databricks SQL UI. A workspace must meet the [requirements](https://docs.databricks.com/sql/admin/serverless.html#requirements) and might require an update to its instance profile role to [add a trust relationship](https://docs.databricks.com/sql/admin/serverless.html#aws-instance-profile-setup).
     * 
     * - **For Azure**, If omitted, the default is `false` for most workspaces. However, if this workspace used the SQL Warehouses API to create a warehouse between November 1, 2022 and May 19, 2023, the default remains the previous behavior which is default to `true` if the workspace is enabled for serverless and fits the requirements for serverless SQL warehouses. A workspace must meet the [requirements](https://learn.microsoft.com/azure/databricks/sql/admin/serverless) and might require an update to its [Azure storage firewall](https://learn.microsoft.com/azure/databricks/sql/admin/serverless-firewall).
     * 
     */
    public Optional<Output<Boolean>> enableServerlessCompute() {
        return Optional.ofNullable(this.enableServerlessCompute);
    }

    /**
     * Health status of the endpoint.
     * 
     */
    @Import(name="healths")
    private @Nullable Output<List<SqlEndpointHealthArgs>> healths;

    /**
     * @return Health status of the endpoint.
     * 
     */
    public Optional<Output<List<SqlEndpointHealthArgs>>> healths() {
        return Optional.ofNullable(this.healths);
    }

    @Import(name="instanceProfileArn")
    private @Nullable Output<String> instanceProfileArn;

    public Optional<Output<String>> instanceProfileArn() {
        return Optional.ofNullable(this.instanceProfileArn);
    }

    /**
     * JDBC connection string.
     * 
     */
    @Import(name="jdbcUrl")
    private @Nullable Output<String> jdbcUrl;

    /**
     * @return JDBC connection string.
     * 
     */
    public Optional<Output<String>> jdbcUrl() {
        return Optional.ofNullable(this.jdbcUrl);
    }

    /**
     * Maximum number of clusters available when a SQL warehouse is running. This field is required. If multi-cluster load balancing is not enabled, this is default to `1`.
     * 
     */
    @Import(name="maxNumClusters")
    private @Nullable Output<Integer> maxNumClusters;

    /**
     * @return Maximum number of clusters available when a SQL warehouse is running. This field is required. If multi-cluster load balancing is not enabled, this is default to `1`.
     * 
     */
    public Optional<Output<Integer>> maxNumClusters() {
        return Optional.ofNullable(this.maxNumClusters);
    }

    /**
     * Minimum number of clusters available when a SQL warehouse is running. The default is `1`.
     * 
     */
    @Import(name="minNumClusters")
    private @Nullable Output<Integer> minNumClusters;

    /**
     * @return Minimum number of clusters available when a SQL warehouse is running. The default is `1`.
     * 
     */
    public Optional<Output<Integer>> minNumClusters() {
        return Optional.ofNullable(this.minNumClusters);
    }

    /**
     * Name of the Databricks SQL release channel. Possible values are: `CHANNEL_NAME_PREVIEW` and `CHANNEL_NAME_CURRENT`. Default is `CHANNEL_NAME_CURRENT`.
     * 
     */
    @Import(name="name")
    private @Nullable Output<String> name;

    /**
     * @return Name of the Databricks SQL release channel. Possible values are: `CHANNEL_NAME_PREVIEW` and `CHANNEL_NAME_CURRENT`. Default is `CHANNEL_NAME_CURRENT`.
     * 
     */
    public Optional<Output<String>> name() {
        return Optional.ofNullable(this.name);
    }

    /**
     * The current number of clusters used by the endpoint.
     * 
     */
    @Import(name="numActiveSessions")
    private @Nullable Output<Integer> numActiveSessions;

    /**
     * @return The current number of clusters used by the endpoint.
     * 
     */
    public Optional<Output<Integer>> numActiveSessions() {
        return Optional.ofNullable(this.numActiveSessions);
    }

    /**
     * The current number of clusters used by the endpoint.
     * 
     */
    @Import(name="numClusters")
    private @Nullable Output<Integer> numClusters;

    /**
     * @return The current number of clusters used by the endpoint.
     * 
     */
    public Optional<Output<Integer>> numClusters() {
        return Optional.ofNullable(this.numClusters);
    }

    /**
     * ODBC connection params: `odbc_params.hostname`, `odbc_params.path`, `odbc_params.protocol`, and `odbc_params.port`.
     * 
     */
    @Import(name="odbcParams")
    private @Nullable Output<SqlEndpointOdbcParamsArgs> odbcParams;

    /**
     * @return ODBC connection params: `odbc_params.hostname`, `odbc_params.path`, `odbc_params.protocol`, and `odbc_params.port`.
     * 
     */
    public Optional<Output<SqlEndpointOdbcParamsArgs>> odbcParams() {
        return Optional.ofNullable(this.odbcParams);
    }

    /**
     * The spot policy to use for allocating instances to clusters: `COST_OPTIMIZED` or `RELIABILITY_OPTIMIZED`. This field is optional. Default is `COST_OPTIMIZED`.
     * 
     */
    @Import(name="spotInstancePolicy")
    private @Nullable Output<String> spotInstancePolicy;

    /**
     * @return The spot policy to use for allocating instances to clusters: `COST_OPTIMIZED` or `RELIABILITY_OPTIMIZED`. This field is optional. Default is `COST_OPTIMIZED`.
     * 
     */
    public Optional<Output<String>> spotInstancePolicy() {
        return Optional.ofNullable(this.spotInstancePolicy);
    }

    /**
     * The current state of the endpoint.
     * 
     */
    @Import(name="state")
    private @Nullable Output<String> state;

    /**
     * @return The current state of the endpoint.
     * 
     */
    public Optional<Output<String>> state() {
        return Optional.ofNullable(this.state);
    }

    /**
     * Databricks tags all endpoint resources with these tags.
     * 
     */
    @Import(name="tags")
    private @Nullable Output<SqlEndpointTagsArgs> tags;

    /**
     * @return Databricks tags all endpoint resources with these tags.
     * 
     */
    public Optional<Output<SqlEndpointTagsArgs>> tags() {
        return Optional.ofNullable(this.tags);
    }

    /**
     * SQL warehouse type. See for [AWS](https://docs.databricks.com/sql/admin/sql-endpoints.html#switch-the-sql-warehouse-type-pro-classic-or-serverless) or [Azure](https://learn.microsoft.com/en-us/azure/databricks/sql/admin/create-sql-warehouse#--upgrade-a-pro-or-classic-sql-warehouse-to-a-serverless-sql-warehouse). Set to `PRO` or `CLASSIC`. If the field `enable_serverless_compute` has the value `true` either explicitly or through the default logic (see that field above for details), the default is `PRO`, which is required for serverless SQL warehouses. Otherwise, the default is `CLASSIC`.
     * 
     */
    @Import(name="warehouseType")
    private @Nullable Output<String> warehouseType;

    /**
     * @return SQL warehouse type. See for [AWS](https://docs.databricks.com/sql/admin/sql-endpoints.html#switch-the-sql-warehouse-type-pro-classic-or-serverless) or [Azure](https://learn.microsoft.com/en-us/azure/databricks/sql/admin/create-sql-warehouse#--upgrade-a-pro-or-classic-sql-warehouse-to-a-serverless-sql-warehouse). Set to `PRO` or `CLASSIC`. If the field `enable_serverless_compute` has the value `true` either explicitly or through the default logic (see that field above for details), the default is `PRO`, which is required for serverless SQL warehouses. Otherwise, the default is `CLASSIC`.
     * 
     */
    public Optional<Output<String>> warehouseType() {
        return Optional.ofNullable(this.warehouseType);
    }

    private SqlEndpointState() {}

    private SqlEndpointState(SqlEndpointState $) {
        this.autoStopMins = $.autoStopMins;
        this.channel = $.channel;
        this.clusterSize = $.clusterSize;
        this.creatorName = $.creatorName;
        this.dataSourceId = $.dataSourceId;
        this.enablePhoton = $.enablePhoton;
        this.enableServerlessCompute = $.enableServerlessCompute;
        this.healths = $.healths;
        this.instanceProfileArn = $.instanceProfileArn;
        this.jdbcUrl = $.jdbcUrl;
        this.maxNumClusters = $.maxNumClusters;
        this.minNumClusters = $.minNumClusters;
        this.name = $.name;
        this.numActiveSessions = $.numActiveSessions;
        this.numClusters = $.numClusters;
        this.odbcParams = $.odbcParams;
        this.spotInstancePolicy = $.spotInstancePolicy;
        this.state = $.state;
        this.tags = $.tags;
        this.warehouseType = $.warehouseType;
    }

    public static Builder builder() {
        return new Builder();
    }
    public static Builder builder(SqlEndpointState defaults) {
        return new Builder(defaults);
    }

    public static final class Builder {
        private SqlEndpointState $;

        public Builder() {
            $ = new SqlEndpointState();
        }

        public Builder(SqlEndpointState defaults) {
            $ = new SqlEndpointState(Objects.requireNonNull(defaults));
        }

        /**
         * @param autoStopMins Time in minutes until an idle SQL warehouse terminates all clusters and stops. This field is optional. The default is 120, set to 0 to disable the auto stop.
         * 
         * @return builder
         * 
         */
        public Builder autoStopMins(@Nullable Output<Integer> autoStopMins) {
            $.autoStopMins = autoStopMins;
            return this;
        }

        /**
         * @param autoStopMins Time in minutes until an idle SQL warehouse terminates all clusters and stops. This field is optional. The default is 120, set to 0 to disable the auto stop.
         * 
         * @return builder
         * 
         */
        public Builder autoStopMins(Integer autoStopMins) {
            return autoStopMins(Output.of(autoStopMins));
        }

        /**
         * @param channel block, consisting of following fields:
         * 
         * @return builder
         * 
         */
        public Builder channel(@Nullable Output<SqlEndpointChannelArgs> channel) {
            $.channel = channel;
            return this;
        }

        /**
         * @param channel block, consisting of following fields:
         * 
         * @return builder
         * 
         */
        public Builder channel(SqlEndpointChannelArgs channel) {
            return channel(Output.of(channel));
        }

        /**
         * @param clusterSize The size of the clusters allocated to the endpoint: &#34;2X-Small&#34;, &#34;X-Small&#34;, &#34;Small&#34;, &#34;Medium&#34;, &#34;Large&#34;, &#34;X-Large&#34;, &#34;2X-Large&#34;, &#34;3X-Large&#34;, &#34;4X-Large&#34;.
         * 
         * @return builder
         * 
         */
        public Builder clusterSize(@Nullable Output<String> clusterSize) {
            $.clusterSize = clusterSize;
            return this;
        }

        /**
         * @param clusterSize The size of the clusters allocated to the endpoint: &#34;2X-Small&#34;, &#34;X-Small&#34;, &#34;Small&#34;, &#34;Medium&#34;, &#34;Large&#34;, &#34;X-Large&#34;, &#34;2X-Large&#34;, &#34;3X-Large&#34;, &#34;4X-Large&#34;.
         * 
         * @return builder
         * 
         */
        public Builder clusterSize(String clusterSize) {
            return clusterSize(Output.of(clusterSize));
        }

        /**
         * @param creatorName The username of the user who created the endpoint.
         * 
         * @return builder
         * 
         */
        public Builder creatorName(@Nullable Output<String> creatorName) {
            $.creatorName = creatorName;
            return this;
        }

        /**
         * @param creatorName The username of the user who created the endpoint.
         * 
         * @return builder
         * 
         */
        public Builder creatorName(String creatorName) {
            return creatorName(Output.of(creatorName));
        }

        /**
         * @param dataSourceId ID of the data source for this endpoint. This is used to bind an Databricks SQL query to an endpoint.
         * 
         * @return builder
         * 
         */
        public Builder dataSourceId(@Nullable Output<String> dataSourceId) {
            $.dataSourceId = dataSourceId;
            return this;
        }

        /**
         * @param dataSourceId ID of the data source for this endpoint. This is used to bind an Databricks SQL query to an endpoint.
         * 
         * @return builder
         * 
         */
        public Builder dataSourceId(String dataSourceId) {
            return dataSourceId(Output.of(dataSourceId));
        }

        /**
         * @param enablePhoton Whether to enable [Photon](https://databricks.com/product/delta-engine). This field is optional and is enabled by default.
         * 
         * @return builder
         * 
         */
        public Builder enablePhoton(@Nullable Output<Boolean> enablePhoton) {
            $.enablePhoton = enablePhoton;
            return this;
        }

        /**
         * @param enablePhoton Whether to enable [Photon](https://databricks.com/product/delta-engine). This field is optional and is enabled by default.
         * 
         * @return builder
         * 
         */
        public Builder enablePhoton(Boolean enablePhoton) {
            return enablePhoton(Output.of(enablePhoton));
        }

        /**
         * @param enableServerlessCompute Whether this SQL warehouse is a serverless endpoint. See below for details about the default values. To avoid ambiguity, especially for organizations with many workspaces, Databricks recommends that you always set this field explicitly.
         * 
         * - **For AWS**, If omitted, the default is `false` for most workspaces. However, if this workspace used the SQL Warehouses API to create a warehouse between September 1, 2022 and April 30, 2023, the default remains the previous behavior which is default to `true` if the workspace is enabled for serverless and fits the requirements for serverless SQL warehouses. If your account needs updated [terms of use](https://docs.databricks.com/sql/admin/serverless.html#accept-terms), workspace admins are prompted in the Databricks SQL UI. A workspace must meet the [requirements](https://docs.databricks.com/sql/admin/serverless.html#requirements) and might require an update to its instance profile role to [add a trust relationship](https://docs.databricks.com/sql/admin/serverless.html#aws-instance-profile-setup).
         * 
         * - **For Azure**, If omitted, the default is `false` for most workspaces. However, if this workspace used the SQL Warehouses API to create a warehouse between November 1, 2022 and May 19, 2023, the default remains the previous behavior which is default to `true` if the workspace is enabled for serverless and fits the requirements for serverless SQL warehouses. A workspace must meet the [requirements](https://learn.microsoft.com/azure/databricks/sql/admin/serverless) and might require an update to its [Azure storage firewall](https://learn.microsoft.com/azure/databricks/sql/admin/serverless-firewall).
         * 
         * @return builder
         * 
         */
        public Builder enableServerlessCompute(@Nullable Output<Boolean> enableServerlessCompute) {
            $.enableServerlessCompute = enableServerlessCompute;
            return this;
        }

        /**
         * @param enableServerlessCompute Whether this SQL warehouse is a serverless endpoint. See below for details about the default values. To avoid ambiguity, especially for organizations with many workspaces, Databricks recommends that you always set this field explicitly.
         * 
         * - **For AWS**, If omitted, the default is `false` for most workspaces. However, if this workspace used the SQL Warehouses API to create a warehouse between September 1, 2022 and April 30, 2023, the default remains the previous behavior which is default to `true` if the workspace is enabled for serverless and fits the requirements for serverless SQL warehouses. If your account needs updated [terms of use](https://docs.databricks.com/sql/admin/serverless.html#accept-terms), workspace admins are prompted in the Databricks SQL UI. A workspace must meet the [requirements](https://docs.databricks.com/sql/admin/serverless.html#requirements) and might require an update to its instance profile role to [add a trust relationship](https://docs.databricks.com/sql/admin/serverless.html#aws-instance-profile-setup).
         * 
         * - **For Azure**, If omitted, the default is `false` for most workspaces. However, if this workspace used the SQL Warehouses API to create a warehouse between November 1, 2022 and May 19, 2023, the default remains the previous behavior which is default to `true` if the workspace is enabled for serverless and fits the requirements for serverless SQL warehouses. A workspace must meet the [requirements](https://learn.microsoft.com/azure/databricks/sql/admin/serverless) and might require an update to its [Azure storage firewall](https://learn.microsoft.com/azure/databricks/sql/admin/serverless-firewall).
         * 
         * @return builder
         * 
         */
        public Builder enableServerlessCompute(Boolean enableServerlessCompute) {
            return enableServerlessCompute(Output.of(enableServerlessCompute));
        }

        /**
         * @param healths Health status of the endpoint.
         * 
         * @return builder
         * 
         */
        public Builder healths(@Nullable Output<List<SqlEndpointHealthArgs>> healths) {
            $.healths = healths;
            return this;
        }

        /**
         * @param healths Health status of the endpoint.
         * 
         * @return builder
         * 
         */
        public Builder healths(List<SqlEndpointHealthArgs> healths) {
            return healths(Output.of(healths));
        }

        /**
         * @param healths Health status of the endpoint.
         * 
         * @return builder
         * 
         */
        public Builder healths(SqlEndpointHealthArgs... healths) {
            return healths(List.of(healths));
        }

        public Builder instanceProfileArn(@Nullable Output<String> instanceProfileArn) {
            $.instanceProfileArn = instanceProfileArn;
            return this;
        }

        public Builder instanceProfileArn(String instanceProfileArn) {
            return instanceProfileArn(Output.of(instanceProfileArn));
        }

        /**
         * @param jdbcUrl JDBC connection string.
         * 
         * @return builder
         * 
         */
        public Builder jdbcUrl(@Nullable Output<String> jdbcUrl) {
            $.jdbcUrl = jdbcUrl;
            return this;
        }

        /**
         * @param jdbcUrl JDBC connection string.
         * 
         * @return builder
         * 
         */
        public Builder jdbcUrl(String jdbcUrl) {
            return jdbcUrl(Output.of(jdbcUrl));
        }

        /**
         * @param maxNumClusters Maximum number of clusters available when a SQL warehouse is running. This field is required. If multi-cluster load balancing is not enabled, this is default to `1`.
         * 
         * @return builder
         * 
         */
        public Builder maxNumClusters(@Nullable Output<Integer> maxNumClusters) {
            $.maxNumClusters = maxNumClusters;
            return this;
        }

        /**
         * @param maxNumClusters Maximum number of clusters available when a SQL warehouse is running. This field is required. If multi-cluster load balancing is not enabled, this is default to `1`.
         * 
         * @return builder
         * 
         */
        public Builder maxNumClusters(Integer maxNumClusters) {
            return maxNumClusters(Output.of(maxNumClusters));
        }

        /**
         * @param minNumClusters Minimum number of clusters available when a SQL warehouse is running. The default is `1`.
         * 
         * @return builder
         * 
         */
        public Builder minNumClusters(@Nullable Output<Integer> minNumClusters) {
            $.minNumClusters = minNumClusters;
            return this;
        }

        /**
         * @param minNumClusters Minimum number of clusters available when a SQL warehouse is running. The default is `1`.
         * 
         * @return builder
         * 
         */
        public Builder minNumClusters(Integer minNumClusters) {
            return minNumClusters(Output.of(minNumClusters));
        }

        /**
         * @param name Name of the Databricks SQL release channel. Possible values are: `CHANNEL_NAME_PREVIEW` and `CHANNEL_NAME_CURRENT`. Default is `CHANNEL_NAME_CURRENT`.
         * 
         * @return builder
         * 
         */
        public Builder name(@Nullable Output<String> name) {
            $.name = name;
            return this;
        }

        /**
         * @param name Name of the Databricks SQL release channel. Possible values are: `CHANNEL_NAME_PREVIEW` and `CHANNEL_NAME_CURRENT`. Default is `CHANNEL_NAME_CURRENT`.
         * 
         * @return builder
         * 
         */
        public Builder name(String name) {
            return name(Output.of(name));
        }

        /**
         * @param numActiveSessions The current number of clusters used by the endpoint.
         * 
         * @return builder
         * 
         */
        public Builder numActiveSessions(@Nullable Output<Integer> numActiveSessions) {
            $.numActiveSessions = numActiveSessions;
            return this;
        }

        /**
         * @param numActiveSessions The current number of clusters used by the endpoint.
         * 
         * @return builder
         * 
         */
        public Builder numActiveSessions(Integer numActiveSessions) {
            return numActiveSessions(Output.of(numActiveSessions));
        }

        /**
         * @param numClusters The current number of clusters used by the endpoint.
         * 
         * @return builder
         * 
         */
        public Builder numClusters(@Nullable Output<Integer> numClusters) {
            $.numClusters = numClusters;
            return this;
        }

        /**
         * @param numClusters The current number of clusters used by the endpoint.
         * 
         * @return builder
         * 
         */
        public Builder numClusters(Integer numClusters) {
            return numClusters(Output.of(numClusters));
        }

        /**
         * @param odbcParams ODBC connection params: `odbc_params.hostname`, `odbc_params.path`, `odbc_params.protocol`, and `odbc_params.port`.
         * 
         * @return builder
         * 
         */
        public Builder odbcParams(@Nullable Output<SqlEndpointOdbcParamsArgs> odbcParams) {
            $.odbcParams = odbcParams;
            return this;
        }

        /**
         * @param odbcParams ODBC connection params: `odbc_params.hostname`, `odbc_params.path`, `odbc_params.protocol`, and `odbc_params.port`.
         * 
         * @return builder
         * 
         */
        public Builder odbcParams(SqlEndpointOdbcParamsArgs odbcParams) {
            return odbcParams(Output.of(odbcParams));
        }

        /**
         * @param spotInstancePolicy The spot policy to use for allocating instances to clusters: `COST_OPTIMIZED` or `RELIABILITY_OPTIMIZED`. This field is optional. Default is `COST_OPTIMIZED`.
         * 
         * @return builder
         * 
         */
        public Builder spotInstancePolicy(@Nullable Output<String> spotInstancePolicy) {
            $.spotInstancePolicy = spotInstancePolicy;
            return this;
        }

        /**
         * @param spotInstancePolicy The spot policy to use for allocating instances to clusters: `COST_OPTIMIZED` or `RELIABILITY_OPTIMIZED`. This field is optional. Default is `COST_OPTIMIZED`.
         * 
         * @return builder
         * 
         */
        public Builder spotInstancePolicy(String spotInstancePolicy) {
            return spotInstancePolicy(Output.of(spotInstancePolicy));
        }

        /**
         * @param state The current state of the endpoint.
         * 
         * @return builder
         * 
         */
        public Builder state(@Nullable Output<String> state) {
            $.state = state;
            return this;
        }

        /**
         * @param state The current state of the endpoint.
         * 
         * @return builder
         * 
         */
        public Builder state(String state) {
            return state(Output.of(state));
        }

        /**
         * @param tags Databricks tags all endpoint resources with these tags.
         * 
         * @return builder
         * 
         */
        public Builder tags(@Nullable Output<SqlEndpointTagsArgs> tags) {
            $.tags = tags;
            return this;
        }

        /**
         * @param tags Databricks tags all endpoint resources with these tags.
         * 
         * @return builder
         * 
         */
        public Builder tags(SqlEndpointTagsArgs tags) {
            return tags(Output.of(tags));
        }

        /**
         * @param warehouseType SQL warehouse type. See for [AWS](https://docs.databricks.com/sql/admin/sql-endpoints.html#switch-the-sql-warehouse-type-pro-classic-or-serverless) or [Azure](https://learn.microsoft.com/en-us/azure/databricks/sql/admin/create-sql-warehouse#--upgrade-a-pro-or-classic-sql-warehouse-to-a-serverless-sql-warehouse). Set to `PRO` or `CLASSIC`. If the field `enable_serverless_compute` has the value `true` either explicitly or through the default logic (see that field above for details), the default is `PRO`, which is required for serverless SQL warehouses. Otherwise, the default is `CLASSIC`.
         * 
         * @return builder
         * 
         */
        public Builder warehouseType(@Nullable Output<String> warehouseType) {
            $.warehouseType = warehouseType;
            return this;
        }

        /**
         * @param warehouseType SQL warehouse type. See for [AWS](https://docs.databricks.com/sql/admin/sql-endpoints.html#switch-the-sql-warehouse-type-pro-classic-or-serverless) or [Azure](https://learn.microsoft.com/en-us/azure/databricks/sql/admin/create-sql-warehouse#--upgrade-a-pro-or-classic-sql-warehouse-to-a-serverless-sql-warehouse). Set to `PRO` or `CLASSIC`. If the field `enable_serverless_compute` has the value `true` either explicitly or through the default logic (see that field above for details), the default is `PRO`, which is required for serverless SQL warehouses. Otherwise, the default is `CLASSIC`.
         * 
         * @return builder
         * 
         */
        public Builder warehouseType(String warehouseType) {
            return warehouseType(Output.of(warehouseType));
        }

        public SqlEndpointState build() {
            return $;
        }
    }

}
