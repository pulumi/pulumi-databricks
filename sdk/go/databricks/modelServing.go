// Code generated by pulumi-language-go DO NOT EDIT.
// *** WARNING: Do not edit by hand unless you're certain you know what you are doing! ***

package databricks

import (
	"context"
	"reflect"

	"github.com/pulumi/pulumi-databricks/sdk/go/databricks/internal"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

// This resource allows you to manage [Model Serving](https://docs.databricks.com/machine-learning/model-serving/index.html) endpoints in Databricks, including custom models, external models, and foundation models. For newer foundation models, including Llama 4, please use the ModelServingProvisionedThroughput resource.
//
// > This resource can only be used with a workspace-level provider!
//
// > If you replace `servedModels` with `servedEntities` in an existing serving endpoint, the serving endpoint will briefly go into an update state (~30 seconds) and increment the config version.
//
// ## Example Usage
//
// # Creating a CPU serving endpoint
//
// ```go
// package main
//
// import (
//
//	"github.com/pulumi/pulumi-databricks/sdk/go/databricks"
//	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
//
// )
//
//	func main() {
//		pulumi.Run(func(ctx *pulumi.Context) error {
//			_, err := databricks.NewModelServing(ctx, "this", &databricks.ModelServingArgs{
//				Name: pulumi.String("ads-serving-endpoint"),
//				Config: &databricks.ModelServingConfigArgs{
//					ServedEntities: databricks.ModelServingConfigServedEntityArray{
//						&databricks.ModelServingConfigServedEntityArgs{
//							Name:               pulumi.String("prod_model"),
//							EntityName:         pulumi.String("ads-model"),
//							EntityVersion:      pulumi.String("2"),
//							WorkloadSize:       pulumi.String("Small"),
//							ScaleToZeroEnabled: pulumi.Bool(true),
//						},
//						&databricks.ModelServingConfigServedEntityArgs{
//							Name:               pulumi.String("candidate_model"),
//							EntityName:         pulumi.String("ads-model"),
//							EntityVersion:      pulumi.String("4"),
//							WorkloadSize:       pulumi.String("Small"),
//							ScaleToZeroEnabled: pulumi.Bool(false),
//						},
//					},
//					TrafficConfig: &databricks.ModelServingConfigTrafficConfigArgs{
//						Routes: databricks.ModelServingConfigTrafficConfigRouteArray{
//							&databricks.ModelServingConfigTrafficConfigRouteArgs{
//								ServedModelName:   pulumi.String("prod_model"),
//								TrafficPercentage: pulumi.Int(90),
//							},
//							&databricks.ModelServingConfigTrafficConfigRouteArgs{
//								ServedModelName:   pulumi.String("candidate_model"),
//								TrafficPercentage: pulumi.Int(10),
//							},
//						},
//					},
//				},
//			})
//			if err != nil {
//				return err
//			}
//			return nil
//		})
//	}
//
// ```
//
// # Creating a Foundation Model endpoint
//
// ```go
// package main
//
// import (
//
//	"github.com/pulumi/pulumi-databricks/sdk/go/databricks"
//	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
//
// )
//
//	func main() {
//		pulumi.Run(func(ctx *pulumi.Context) error {
//			_, err := databricks.NewModelServing(ctx, "llama", &databricks.ModelServingArgs{
//				Name: pulumi.String("llama_3_2_3b_instruct"),
//				AiGateway: &databricks.ModelServingAiGatewayArgs{
//					UsageTrackingConfig: &databricks.ModelServingAiGatewayUsageTrackingConfigArgs{
//						Enabled: pulumi.Bool(true),
//					},
//				},
//				Config: &databricks.ModelServingConfigArgs{
//					ServedEntities: databricks.ModelServingConfigServedEntityArray{
//						&databricks.ModelServingConfigServedEntityArgs{
//							Name:                     pulumi.String("meta_llama_v3_2_3b_instruct-3"),
//							EntityName:               pulumi.String("system.ai.llama_v3_2_3b_instruct"),
//							EntityVersion:            pulumi.String("2"),
//							ScaleToZeroEnabled:       pulumi.Bool(true),
//							MaxProvisionedThroughput: pulumi.Int(44000),
//						},
//					},
//				},
//			})
//			if err != nil {
//				return err
//			}
//			return nil
//		})
//	}
//
// ```
//
// # Creating an External Model endpoint
//
// ```go
// package main
//
// import (
//
//	"github.com/pulumi/pulumi-databricks/sdk/go/databricks"
//	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
//
// )
//
//	func main() {
//		pulumi.Run(func(ctx *pulumi.Context) error {
//			_, err := databricks.NewModelServing(ctx, "gpt_4o", &databricks.ModelServingArgs{
//				Name: pulumi.String("gpt-4o-mini"),
//				AiGateway: &databricks.ModelServingAiGatewayArgs{
//					UsageTrackingConfig: &databricks.ModelServingAiGatewayUsageTrackingConfigArgs{
//						Enabled: pulumi.Bool(true),
//					},
//					RateLimits: databricks.ModelServingAiGatewayRateLimitArray{
//						&databricks.ModelServingAiGatewayRateLimitArgs{
//							Calls:         pulumi.Int(10),
//							Key:           pulumi.String("endpoint"),
//							RenewalPeriod: pulumi.String("minute"),
//						},
//					},
//					InferenceTableConfig: &databricks.ModelServingAiGatewayInferenceTableConfigArgs{
//						Enabled:         pulumi.Bool(true),
//						TableNamePrefix: pulumi.String("gpt-4o-mini"),
//						CatalogName:     pulumi.String("ml"),
//						SchemaName:      pulumi.String("ai_gateway"),
//					},
//					Guardrails: &databricks.ModelServingAiGatewayGuardrailsArgs{
//						Input: &databricks.ModelServingAiGatewayGuardrailsInputTypeArgs{
//							InvalidKeywords: pulumi.StringArray{
//								pulumi.String("SuperSecretProject"),
//							},
//							Pii: &databricks.ModelServingAiGatewayGuardrailsInputPiiArgs{
//								Behavior: pulumi.String("BLOCK"),
//							},
//						},
//						Output: &databricks.ModelServingAiGatewayGuardrailsOutputTypeArgs{
//							Pii: &databricks.ModelServingAiGatewayGuardrailsOutputPiiArgs{
//								Behavior: pulumi.String("BLOCK"),
//							},
//						},
//					},
//				},
//				Config: &databricks.ModelServingConfigArgs{
//					ServedEntities: databricks.ModelServingConfigServedEntityArray{
//						&databricks.ModelServingConfigServedEntityArgs{
//							Name: pulumi.String("gpt-4o-mini"),
//							ExternalModel: &databricks.ModelServingConfigServedEntityExternalModelArgs{
//								Name:     pulumi.String("gpt-4o-mini"),
//								Provider: pulumi.String("openai"),
//								Task:     pulumi.String("llm/v1/chat"),
//								OpenaiConfig: &databricks.ModelServingConfigServedEntityExternalModelOpenaiConfigArgs{
//									OpenaiApiKey: pulumi.String("{{secrets/llm_scope/openai_api_key}}"),
//								},
//							},
//						},
//					},
//				},
//			})
//			if err != nil {
//				return err
//			}
//			return nil
//		})
//	}
//
// ```
//
// ## Access Control
//
// * Permissions can control which groups or individual users can *Manage*, *Query* or *View* individual serving endpoints.
//
// ## Related Resources
//
// The following resources are often used in the same context:
//
// * ModelServingProvisionedThroughput to create [Foundation Model provisioned throughput](https://docs.databricks.com/aws/en/machine-learning/foundation-model-apis/deploy-prov-throughput-foundation-model-apis) endpoints in Databricks.
// * RegisteredModel to create [Models in Unity Catalog](https://docs.databricks.com/en/mlflow/models-in-uc.html) in Databricks.
// * End to end workspace management guide.
// * Directory to manage directories in [Databricks Workspace](https://docs.databricks.com/workspace/workspace-objects.html).
// * MlflowModel to create models in the [workspace model registry](https://docs.databricks.com/en/mlflow/model-registry.html) in Databricks.
// * Notebook to manage [Databricks Notebooks](https://docs.databricks.com/notebooks/index.html).
// * Notebook data to export a notebook from Databricks Workspace.
// * Repo to manage [Databricks Repos](https://docs.databricks.com/repos.html).
type ModelServing struct {
	pulumi.CustomResourceState

	// A block with AI Gateway configuration for the serving endpoint. *Note: only external model endpoints are supported as of now.*
	AiGateway ModelServingAiGatewayPtrOutput `pulumi:"aiGateway"`
	// The Budget Policy ID set for this serving endpoint.
	BudgetPolicyId pulumi.StringPtrOutput `pulumi:"budgetPolicyId"`
	// The model serving endpoint configuration. This is optional and can be added and modified after creation. If `config` was provided in a previous apply but is not provided in the current apply, no change to the model serving endpoint will occur. To recreate the model serving endpoint without the `config` block, the model serving endpoint must be destroyed and recreated.
	Config ModelServingConfigOutput `pulumi:"config"`
	// The description of the model serving endpoint.
	Description pulumi.StringPtrOutput `pulumi:"description"`
	// A block with Email notification setting.
	EmailNotifications ModelServingEmailNotificationsPtrOutput `pulumi:"emailNotifications"`
	// Invocation url of the endpoint.
	EndpointUrl pulumi.StringOutput `pulumi:"endpointUrl"`
	// The name of the model serving endpoint. This field is required and must be unique across a workspace. An endpoint name can consist of alphanumeric characters, dashes, and underscores. NOTE: Changing this name will delete the existing endpoint and create a new endpoint with the updated name.
	Name pulumi.StringOutput `pulumi:"name"`
	// A list of rate limit blocks to be applied to the serving endpoint. *Note: only external and foundation model endpoints are supported as of now.*
	//
	// Deprecated: Please use AI Gateway to manage rate limits.
	RateLimits ModelServingRateLimitArrayOutput `pulumi:"rateLimits"`
	// A boolean enabling route optimization for the endpoint. *Note: only available for custom models.*
	RouteOptimized pulumi.BoolPtrOutput `pulumi:"routeOptimized"`
	// Unique identifier of the serving endpoint primarily used to set permissions and refer to this instance for other operations.
	ServingEndpointId pulumi.StringOutput `pulumi:"servingEndpointId"`
	// Tags to be attached to the serving endpoint and automatically propagated to billing logs.
	Tags ModelServingTagArrayOutput `pulumi:"tags"`
}

// NewModelServing registers a new resource with the given unique name, arguments, and options.
func NewModelServing(ctx *pulumi.Context,
	name string, args *ModelServingArgs, opts ...pulumi.ResourceOption) (*ModelServing, error) {
	if args == nil {
		args = &ModelServingArgs{}
	}

	opts = internal.PkgResourceDefaultOpts(opts)
	var resource ModelServing
	err := ctx.RegisterResource("databricks:index/modelServing:ModelServing", name, args, &resource, opts...)
	if err != nil {
		return nil, err
	}
	return &resource, nil
}

// GetModelServing gets an existing ModelServing resource's state with the given name, ID, and optional
// state properties that are used to uniquely qualify the lookup (nil if not required).
func GetModelServing(ctx *pulumi.Context,
	name string, id pulumi.IDInput, state *ModelServingState, opts ...pulumi.ResourceOption) (*ModelServing, error) {
	var resource ModelServing
	err := ctx.ReadResource("databricks:index/modelServing:ModelServing", name, id, state, &resource, opts...)
	if err != nil {
		return nil, err
	}
	return &resource, nil
}

// Input properties used for looking up and filtering ModelServing resources.
type modelServingState struct {
	// A block with AI Gateway configuration for the serving endpoint. *Note: only external model endpoints are supported as of now.*
	AiGateway *ModelServingAiGateway `pulumi:"aiGateway"`
	// The Budget Policy ID set for this serving endpoint.
	BudgetPolicyId *string `pulumi:"budgetPolicyId"`
	// The model serving endpoint configuration. This is optional and can be added and modified after creation. If `config` was provided in a previous apply but is not provided in the current apply, no change to the model serving endpoint will occur. To recreate the model serving endpoint without the `config` block, the model serving endpoint must be destroyed and recreated.
	Config *ModelServingConfig `pulumi:"config"`
	// The description of the model serving endpoint.
	Description *string `pulumi:"description"`
	// A block with Email notification setting.
	EmailNotifications *ModelServingEmailNotifications `pulumi:"emailNotifications"`
	// Invocation url of the endpoint.
	EndpointUrl *string `pulumi:"endpointUrl"`
	// The name of the model serving endpoint. This field is required and must be unique across a workspace. An endpoint name can consist of alphanumeric characters, dashes, and underscores. NOTE: Changing this name will delete the existing endpoint and create a new endpoint with the updated name.
	Name *string `pulumi:"name"`
	// A list of rate limit blocks to be applied to the serving endpoint. *Note: only external and foundation model endpoints are supported as of now.*
	//
	// Deprecated: Please use AI Gateway to manage rate limits.
	RateLimits []ModelServingRateLimit `pulumi:"rateLimits"`
	// A boolean enabling route optimization for the endpoint. *Note: only available for custom models.*
	RouteOptimized *bool `pulumi:"routeOptimized"`
	// Unique identifier of the serving endpoint primarily used to set permissions and refer to this instance for other operations.
	ServingEndpointId *string `pulumi:"servingEndpointId"`
	// Tags to be attached to the serving endpoint and automatically propagated to billing logs.
	Tags []ModelServingTag `pulumi:"tags"`
}

type ModelServingState struct {
	// A block with AI Gateway configuration for the serving endpoint. *Note: only external model endpoints are supported as of now.*
	AiGateway ModelServingAiGatewayPtrInput
	// The Budget Policy ID set for this serving endpoint.
	BudgetPolicyId pulumi.StringPtrInput
	// The model serving endpoint configuration. This is optional and can be added and modified after creation. If `config` was provided in a previous apply but is not provided in the current apply, no change to the model serving endpoint will occur. To recreate the model serving endpoint without the `config` block, the model serving endpoint must be destroyed and recreated.
	Config ModelServingConfigPtrInput
	// The description of the model serving endpoint.
	Description pulumi.StringPtrInput
	// A block with Email notification setting.
	EmailNotifications ModelServingEmailNotificationsPtrInput
	// Invocation url of the endpoint.
	EndpointUrl pulumi.StringPtrInput
	// The name of the model serving endpoint. This field is required and must be unique across a workspace. An endpoint name can consist of alphanumeric characters, dashes, and underscores. NOTE: Changing this name will delete the existing endpoint and create a new endpoint with the updated name.
	Name pulumi.StringPtrInput
	// A list of rate limit blocks to be applied to the serving endpoint. *Note: only external and foundation model endpoints are supported as of now.*
	//
	// Deprecated: Please use AI Gateway to manage rate limits.
	RateLimits ModelServingRateLimitArrayInput
	// A boolean enabling route optimization for the endpoint. *Note: only available for custom models.*
	RouteOptimized pulumi.BoolPtrInput
	// Unique identifier of the serving endpoint primarily used to set permissions and refer to this instance for other operations.
	ServingEndpointId pulumi.StringPtrInput
	// Tags to be attached to the serving endpoint and automatically propagated to billing logs.
	Tags ModelServingTagArrayInput
}

func (ModelServingState) ElementType() reflect.Type {
	return reflect.TypeOf((*modelServingState)(nil)).Elem()
}

type modelServingArgs struct {
	// A block with AI Gateway configuration for the serving endpoint. *Note: only external model endpoints are supported as of now.*
	AiGateway *ModelServingAiGateway `pulumi:"aiGateway"`
	// The Budget Policy ID set for this serving endpoint.
	BudgetPolicyId *string `pulumi:"budgetPolicyId"`
	// The model serving endpoint configuration. This is optional and can be added and modified after creation. If `config` was provided in a previous apply but is not provided in the current apply, no change to the model serving endpoint will occur. To recreate the model serving endpoint without the `config` block, the model serving endpoint must be destroyed and recreated.
	Config *ModelServingConfig `pulumi:"config"`
	// The description of the model serving endpoint.
	Description *string `pulumi:"description"`
	// A block with Email notification setting.
	EmailNotifications *ModelServingEmailNotifications `pulumi:"emailNotifications"`
	// The name of the model serving endpoint. This field is required and must be unique across a workspace. An endpoint name can consist of alphanumeric characters, dashes, and underscores. NOTE: Changing this name will delete the existing endpoint and create a new endpoint with the updated name.
	Name *string `pulumi:"name"`
	// A list of rate limit blocks to be applied to the serving endpoint. *Note: only external and foundation model endpoints are supported as of now.*
	//
	// Deprecated: Please use AI Gateway to manage rate limits.
	RateLimits []ModelServingRateLimit `pulumi:"rateLimits"`
	// A boolean enabling route optimization for the endpoint. *Note: only available for custom models.*
	RouteOptimized *bool `pulumi:"routeOptimized"`
	// Tags to be attached to the serving endpoint and automatically propagated to billing logs.
	Tags []ModelServingTag `pulumi:"tags"`
}

// The set of arguments for constructing a ModelServing resource.
type ModelServingArgs struct {
	// A block with AI Gateway configuration for the serving endpoint. *Note: only external model endpoints are supported as of now.*
	AiGateway ModelServingAiGatewayPtrInput
	// The Budget Policy ID set for this serving endpoint.
	BudgetPolicyId pulumi.StringPtrInput
	// The model serving endpoint configuration. This is optional and can be added and modified after creation. If `config` was provided in a previous apply but is not provided in the current apply, no change to the model serving endpoint will occur. To recreate the model serving endpoint without the `config` block, the model serving endpoint must be destroyed and recreated.
	Config ModelServingConfigPtrInput
	// The description of the model serving endpoint.
	Description pulumi.StringPtrInput
	// A block with Email notification setting.
	EmailNotifications ModelServingEmailNotificationsPtrInput
	// The name of the model serving endpoint. This field is required and must be unique across a workspace. An endpoint name can consist of alphanumeric characters, dashes, and underscores. NOTE: Changing this name will delete the existing endpoint and create a new endpoint with the updated name.
	Name pulumi.StringPtrInput
	// A list of rate limit blocks to be applied to the serving endpoint. *Note: only external and foundation model endpoints are supported as of now.*
	//
	// Deprecated: Please use AI Gateway to manage rate limits.
	RateLimits ModelServingRateLimitArrayInput
	// A boolean enabling route optimization for the endpoint. *Note: only available for custom models.*
	RouteOptimized pulumi.BoolPtrInput
	// Tags to be attached to the serving endpoint and automatically propagated to billing logs.
	Tags ModelServingTagArrayInput
}

func (ModelServingArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*modelServingArgs)(nil)).Elem()
}

type ModelServingInput interface {
	pulumi.Input

	ToModelServingOutput() ModelServingOutput
	ToModelServingOutputWithContext(ctx context.Context) ModelServingOutput
}

func (*ModelServing) ElementType() reflect.Type {
	return reflect.TypeOf((**ModelServing)(nil)).Elem()
}

func (i *ModelServing) ToModelServingOutput() ModelServingOutput {
	return i.ToModelServingOutputWithContext(context.Background())
}

func (i *ModelServing) ToModelServingOutputWithContext(ctx context.Context) ModelServingOutput {
	return pulumi.ToOutputWithContext(ctx, i).(ModelServingOutput)
}

// ModelServingArrayInput is an input type that accepts ModelServingArray and ModelServingArrayOutput values.
// You can construct a concrete instance of `ModelServingArrayInput` via:
//
//	ModelServingArray{ ModelServingArgs{...} }
type ModelServingArrayInput interface {
	pulumi.Input

	ToModelServingArrayOutput() ModelServingArrayOutput
	ToModelServingArrayOutputWithContext(context.Context) ModelServingArrayOutput
}

type ModelServingArray []ModelServingInput

func (ModelServingArray) ElementType() reflect.Type {
	return reflect.TypeOf((*[]*ModelServing)(nil)).Elem()
}

func (i ModelServingArray) ToModelServingArrayOutput() ModelServingArrayOutput {
	return i.ToModelServingArrayOutputWithContext(context.Background())
}

func (i ModelServingArray) ToModelServingArrayOutputWithContext(ctx context.Context) ModelServingArrayOutput {
	return pulumi.ToOutputWithContext(ctx, i).(ModelServingArrayOutput)
}

// ModelServingMapInput is an input type that accepts ModelServingMap and ModelServingMapOutput values.
// You can construct a concrete instance of `ModelServingMapInput` via:
//
//	ModelServingMap{ "key": ModelServingArgs{...} }
type ModelServingMapInput interface {
	pulumi.Input

	ToModelServingMapOutput() ModelServingMapOutput
	ToModelServingMapOutputWithContext(context.Context) ModelServingMapOutput
}

type ModelServingMap map[string]ModelServingInput

func (ModelServingMap) ElementType() reflect.Type {
	return reflect.TypeOf((*map[string]*ModelServing)(nil)).Elem()
}

func (i ModelServingMap) ToModelServingMapOutput() ModelServingMapOutput {
	return i.ToModelServingMapOutputWithContext(context.Background())
}

func (i ModelServingMap) ToModelServingMapOutputWithContext(ctx context.Context) ModelServingMapOutput {
	return pulumi.ToOutputWithContext(ctx, i).(ModelServingMapOutput)
}

type ModelServingOutput struct{ *pulumi.OutputState }

func (ModelServingOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**ModelServing)(nil)).Elem()
}

func (o ModelServingOutput) ToModelServingOutput() ModelServingOutput {
	return o
}

func (o ModelServingOutput) ToModelServingOutputWithContext(ctx context.Context) ModelServingOutput {
	return o
}

// A block with AI Gateway configuration for the serving endpoint. *Note: only external model endpoints are supported as of now.*
func (o ModelServingOutput) AiGateway() ModelServingAiGatewayPtrOutput {
	return o.ApplyT(func(v *ModelServing) ModelServingAiGatewayPtrOutput { return v.AiGateway }).(ModelServingAiGatewayPtrOutput)
}

// The Budget Policy ID set for this serving endpoint.
func (o ModelServingOutput) BudgetPolicyId() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *ModelServing) pulumi.StringPtrOutput { return v.BudgetPolicyId }).(pulumi.StringPtrOutput)
}

// The model serving endpoint configuration. This is optional and can be added and modified after creation. If `config` was provided in a previous apply but is not provided in the current apply, no change to the model serving endpoint will occur. To recreate the model serving endpoint without the `config` block, the model serving endpoint must be destroyed and recreated.
func (o ModelServingOutput) Config() ModelServingConfigOutput {
	return o.ApplyT(func(v *ModelServing) ModelServingConfigOutput { return v.Config }).(ModelServingConfigOutput)
}

// The description of the model serving endpoint.
func (o ModelServingOutput) Description() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *ModelServing) pulumi.StringPtrOutput { return v.Description }).(pulumi.StringPtrOutput)
}

// A block with Email notification setting.
func (o ModelServingOutput) EmailNotifications() ModelServingEmailNotificationsPtrOutput {
	return o.ApplyT(func(v *ModelServing) ModelServingEmailNotificationsPtrOutput { return v.EmailNotifications }).(ModelServingEmailNotificationsPtrOutput)
}

// Invocation url of the endpoint.
func (o ModelServingOutput) EndpointUrl() pulumi.StringOutput {
	return o.ApplyT(func(v *ModelServing) pulumi.StringOutput { return v.EndpointUrl }).(pulumi.StringOutput)
}

// The name of the model serving endpoint. This field is required and must be unique across a workspace. An endpoint name can consist of alphanumeric characters, dashes, and underscores. NOTE: Changing this name will delete the existing endpoint and create a new endpoint with the updated name.
func (o ModelServingOutput) Name() pulumi.StringOutput {
	return o.ApplyT(func(v *ModelServing) pulumi.StringOutput { return v.Name }).(pulumi.StringOutput)
}

// A list of rate limit blocks to be applied to the serving endpoint. *Note: only external and foundation model endpoints are supported as of now.*
//
// Deprecated: Please use AI Gateway to manage rate limits.
func (o ModelServingOutput) RateLimits() ModelServingRateLimitArrayOutput {
	return o.ApplyT(func(v *ModelServing) ModelServingRateLimitArrayOutput { return v.RateLimits }).(ModelServingRateLimitArrayOutput)
}

// A boolean enabling route optimization for the endpoint. *Note: only available for custom models.*
func (o ModelServingOutput) RouteOptimized() pulumi.BoolPtrOutput {
	return o.ApplyT(func(v *ModelServing) pulumi.BoolPtrOutput { return v.RouteOptimized }).(pulumi.BoolPtrOutput)
}

// Unique identifier of the serving endpoint primarily used to set permissions and refer to this instance for other operations.
func (o ModelServingOutput) ServingEndpointId() pulumi.StringOutput {
	return o.ApplyT(func(v *ModelServing) pulumi.StringOutput { return v.ServingEndpointId }).(pulumi.StringOutput)
}

// Tags to be attached to the serving endpoint and automatically propagated to billing logs.
func (o ModelServingOutput) Tags() ModelServingTagArrayOutput {
	return o.ApplyT(func(v *ModelServing) ModelServingTagArrayOutput { return v.Tags }).(ModelServingTagArrayOutput)
}

type ModelServingArrayOutput struct{ *pulumi.OutputState }

func (ModelServingArrayOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*[]*ModelServing)(nil)).Elem()
}

func (o ModelServingArrayOutput) ToModelServingArrayOutput() ModelServingArrayOutput {
	return o
}

func (o ModelServingArrayOutput) ToModelServingArrayOutputWithContext(ctx context.Context) ModelServingArrayOutput {
	return o
}

func (o ModelServingArrayOutput) Index(i pulumi.IntInput) ModelServingOutput {
	return pulumi.All(o, i).ApplyT(func(vs []interface{}) *ModelServing {
		return vs[0].([]*ModelServing)[vs[1].(int)]
	}).(ModelServingOutput)
}

type ModelServingMapOutput struct{ *pulumi.OutputState }

func (ModelServingMapOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*map[string]*ModelServing)(nil)).Elem()
}

func (o ModelServingMapOutput) ToModelServingMapOutput() ModelServingMapOutput {
	return o
}

func (o ModelServingMapOutput) ToModelServingMapOutputWithContext(ctx context.Context) ModelServingMapOutput {
	return o
}

func (o ModelServingMapOutput) MapIndex(k pulumi.StringInput) ModelServingOutput {
	return pulumi.All(o, k).ApplyT(func(vs []interface{}) *ModelServing {
		return vs[0].(map[string]*ModelServing)[vs[1].(string)]
	}).(ModelServingOutput)
}

func init() {
	pulumi.RegisterInputType(reflect.TypeOf((*ModelServingInput)(nil)).Elem(), &ModelServing{})
	pulumi.RegisterInputType(reflect.TypeOf((*ModelServingArrayInput)(nil)).Elem(), ModelServingArray{})
	pulumi.RegisterInputType(reflect.TypeOf((*ModelServingMapInput)(nil)).Elem(), ModelServingMap{})
	pulumi.RegisterOutputType(ModelServingOutput{})
	pulumi.RegisterOutputType(ModelServingArrayOutput{})
	pulumi.RegisterOutputType(ModelServingMapOutput{})
}
