// Code generated by the Pulumi Terraform Bridge (tfgen) Tool DO NOT EDIT.
// *** WARNING: Do not edit by hand unless you're certain you know what you are doing! ***

package databricks

import (
	"context"
	"reflect"

	"github.com/pulumi/pulumi-databricks/sdk/go/databricks/internal"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

// This resource will mount your cloud storage
// * `gs` - to [mount Google Cloud Storage](https://docs.gcp.databricks.com/data/data-sources/google/gcs.html)
// * `abfs` - to [mount ADLS Gen2](https://docs.microsoft.com/en-us/azure/databricks/data/data-sources/azure/adls-gen2/) using Azure Blob Filesystem (ABFS) driver
// * `adl` - to [mount ADLS Gen1](https://docs.microsoft.com/en-us/azure/databricks/data/data-sources/azure/azure-datalake) using Azure Data Lake (ADL) driver
// * `wasb`  - to [mount Azure Blob Storage](https://docs.microsoft.com/en-us/azure/databricks/data/data-sources/azure/azure-storage) using Windows Azure Storage Blob (WASB) driver
//
// 1. Use generic arguments - you have a responsibility for providing all necessary parameters that are required to mount specific storage. This is most flexible option
//
// ## Common arguments
//
// * `clusterId` - (Optional, String) Cluster to use for mounting. If no cluster is specified, a new cluster will be created and will mount the bucket for all of the clusters in this workspace. If the cluster is not running - it's going to be started, so be aware to set auto-termination rules on it.
// * `name` - (Optional, String) Name, under which mount will be accessible in `dbfs:/mnt/<MOUNT_NAME>`. If not specified, provider will try to infer it from depending on the resource type:
//   - `bucketName` for AWS S3 and Google Cloud Storage
//   - `containerName` for ADLS Gen2 and Azure Blob Storage
//   - `storageResourceName` for ADLS Gen1
//
// * `uri` - (Optional, String) the URI for accessing specific storage (`s3a://....`, `abfss://....`, `gs://....`, etc.)
// * `extraConfigs` - (Optional, String map) configuration parameters that are necessary for mounting of specific storage
// * `resourceId` - (Optional, String) resource ID for a given storage account. Could be used to fill defaults, such as storage account & container names on Azure.
// * `encryptionType` - (Optional, String) encryption type. Currently used only for [AWS S3 mounts](https://docs.databricks.com/data/data-sources/aws/amazon-s3.html#encrypt-data-in-s3-buckets)
//
// ### Example mounting ADLS Gen2 using uri and extraConfigs
//
// <!--Start PulumiCodeChooser -->
// ```go
// package main
//
// import (
//
//	"fmt"
//
//	"github.com/pulumi/pulumi-databricks/sdk/go/databricks"
//	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
//
// )
//
//	func main() {
//		pulumi.Run(func(ctx *pulumi.Context) error {
//			tenantId := "00000000-1111-2222-3333-444444444444"
//			clientId := "55555555-6666-7777-8888-999999999999"
//			secretScope := "some-kv"
//			secretKey := "some-sp-secret"
//			container := "test"
//			storageAcc := "lrs"
//			_, err := databricks.NewMount(ctx, "this", &databricks.MountArgs{
//				Name: pulumi.String("tf-abfss"),
//				Uri:  pulumi.String(fmt.Sprintf("abfss://%v@%v.dfs.core.windows.net", container, storageAcc)),
//				ExtraConfigs: pulumi.Map{
//					"fs.azure.account.auth.type":                          pulumi.Any("OAuth"),
//					"fs.azure.account.oauth.provider.type":                pulumi.Any("org.apache.hadoop.fs.azurebfs.oauth2.ClientCredsTokenProvider"),
//					"fs.azure.account.oauth2.client.id":                   pulumi.String(clientId),
//					"fs.azure.account.oauth2.client.secret":               pulumi.Any(fmt.Sprintf("{{secrets/%v/%v}}", secretScope, secretKey)),
//					"fs.azure.account.oauth2.client.endpoint":             pulumi.Any(fmt.Sprintf("https://login.microsoftonline.com/%v/oauth2/token", tenantId)),
//					"fs.azure.createRemoteFileSystemDuringInitialization": pulumi.Any("false"),
//				},
//			})
//			if err != nil {
//				return err
//			}
//			return nil
//		})
//	}
//
// ```
// <!--End PulumiCodeChooser -->
//
// ### Example mounting ADLS Gen2 with AAD passthrough
//
// > **Note** AAD passthrough is considered a legacy data access pattern. Use Unity Catalog for fine-grained data access control.
//
// > **Note** Mounts using AAD passthrough cannot be created using a service principal.
//
// To mount ALDS Gen2 with Azure Active Directory Credentials passthrough we need to execute the mount commands using the cluster configured with AAD Credentials passthrough & provide necessary configuration parameters (see [documentation](https://docs.microsoft.com/en-us/azure/databricks/security/credential-passthrough/adls-passthrough#--mount-azure-data-lake-storage-to-dbfs-using-credential-passthrough) for more details).
//
// <!--Start PulumiCodeChooser -->
// ```go
// package main
//
// import (
//
//	"fmt"
//
//	azuredatabricks "github.com/pulumi/pulumi-azure/sdk/v5/go/azure/databricks"
//	"github.com/pulumi/pulumi-databricks/sdk/go/databricks"
//	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
//	"github.com/pulumi/pulumi/sdk/v3/go/pulumi/config"
//
// )
//
//	func main() {
//		pulumi.Run(func(ctx *pulumi.Context) error {
//			cfg := config.New(ctx, "")
//			// Resource group for Databricks Workspace
//			resourceGroup := cfg.Require("resourceGroup")
//			// Name of the Databricks Workspace
//			workspaceName := cfg.Require("workspaceName")
//			_, err := azuredatabricks.LookupWorkspace(ctx, &databricks.LookupWorkspaceArgs{
//				Name:              workspaceName,
//				ResourceGroupName: resourceGroup,
//			}, nil)
//			if err != nil {
//				return err
//			}
//			smallest, err := databricks.GetNodeType(ctx, &databricks.GetNodeTypeArgs{
//				LocalDisk: pulumi.BoolRef(true),
//			}, nil)
//			if err != nil {
//				return err
//			}
//			latest, err := databricks.GetSparkVersion(ctx, nil, nil)
//			if err != nil {
//				return err
//			}
//			sharedPassthrough, err := databricks.NewCluster(ctx, "shared_passthrough", &databricks.ClusterArgs{
//				ClusterName:            pulumi.String("Shared Passthrough for mount"),
//				SparkVersion:           pulumi.String(latest.Id),
//				NodeTypeId:             pulumi.String(smallest.Id),
//				AutoterminationMinutes: pulumi.Int(10),
//				NumWorkers:             pulumi.Int(1),
//				SparkConf: pulumi.Map{
//					"spark.databricks.cluster.profile":                pulumi.Any("serverless"),
//					"spark.databricks.repl.allowedLanguages":          pulumi.Any("python,sql"),
//					"spark.databricks.passthrough.enabled":            pulumi.Any("true"),
//					"spark.databricks.pyspark.enableProcessIsolation": pulumi.Any("true"),
//				},
//				CustomTags: pulumi.Map{
//					"ResourceClass": pulumi.Any("Serverless"),
//				},
//			})
//			if err != nil {
//				return err
//			}
//			// Name of the ADLS Gen2 storage container
//			storageAcc := cfg.Require("storageAcc")
//			// Name of container inside storage account
//			container := cfg.Require("container")
//			_, err = databricks.NewMount(ctx, "passthrough", &databricks.MountArgs{
//				Name:      pulumi.String("passthrough-test"),
//				ClusterId: sharedPassthrough.ID(),
//				Uri:       pulumi.String(fmt.Sprintf("abfss://%v@%v.dfs.core.windows.net", container, storageAcc)),
//				ExtraConfigs: pulumi.Map{
//					"fs.azure.account.auth.type":                   pulumi.Any("CustomAccessToken"),
//					"fs.azure.account.custom.token.provider.class": pulumi.Any("{{sparkconf/spark.databricks.passthrough.adls.gen2.tokenProviderClassName}}"),
//				},
//			})
//			if err != nil {
//				return err
//			}
//			return nil
//		})
//	}
//
// ```
// <!--End PulumiCodeChooser -->
//
// ## s3 block
//
// This block allows specifying parameters for mounting of the ADLS Gen2. The following arguments are required inside the `s3` block:
//
// * `instanceProfile` - (Optional) (String) ARN of registered instance profile for data access.  If it's not specified, then the `clusterId` should be provided, and the cluster should have an instance profile attached to it. If both `clusterId` & `instanceProfile` are specified, then `clusterId` takes precedence.
// * `bucketName` - (Required) (String) S3 bucket name to be mounted.
//
// ### Example of mounting S3
//
// <!--Start PulumiCodeChooser -->
// ```go
// package main
//
// import (
//
//	"github.com/pulumi/pulumi-databricks/sdk/go/databricks"
//	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
//
// )
//
//	func main() {
//		pulumi.Run(func(ctx *pulumi.Context) error {
//			// now you can do `%fs ls /mnt/experiments` in notebooks
//			_, err := databricks.NewMount(ctx, "this", &databricks.MountArgs{
//				Name: pulumi.String("experiments"),
//				S3: &databricks.MountS3Args{
//					InstanceProfile: pulumi.Any(ds.Id),
//					BucketName:      pulumi.Any(thisAwsS3Bucket.Bucket),
//				},
//			})
//			if err != nil {
//				return err
//			}
//			return nil
//		})
//	}
//
// ```
// <!--End PulumiCodeChooser -->
//
// ## abfs block
//
// This block allows specifying parameters for mounting of the ADLS Gen2. The following arguments are required inside the `abfs` block:
//
// * `clientId` - (Required) (String) This is the clientId (Application Object ID) for the enterprise application for the service principal.
// * `tenantId` - (Optional) (String) This is your azure directory tenant id. It is required for creating the mount. (Could be omitted if Azure authentication is used, and we can extract `tenantId` from it).
// * `clientSecretKey` - (Required) (String) This is the secret key in which your service principal/enterprise app client secret will be stored.
// * `clientSecretScope` - (Required) (String) This is the secret scope in which your service principal/enterprise app client secret will be stored.
// * `containerName` - (Required) (String) ADLS gen2 container name. (Could be omitted if `resourceId` is provided)
// * `storageAccountName` - (Required) (String) The name of the storage resource in which the data is. (Could be omitted if `resourceId` is provided)
// * `directory` - (Computed) (String) This is optional if you don't want to add an additional directory that you wish to mount. This must start with a "/".
// * `initializeFileSystem` - (Required) (Bool) either or not initialize FS for the first use
//
// ### Creating mount for ADLS Gen2 using abfs block
//
// In this example, we're using Azure authentication, so we can omit some parameters (`tenantId`, `storageAccountName`, and `containerName`) that will be detected automatically.
//
// <!--Start PulumiCodeChooser -->
// ```go
// package main
//
// import (
//
//	"fmt"
//
//	"github.com/pulumi/pulumi-azure/sdk/v5/go/azure/authorization"
//	"github.com/pulumi/pulumi-azure/sdk/v5/go/azure/storage"
//	"github.com/pulumi/pulumi-databricks/sdk/go/databricks"
//	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
//
// )
//
//	func main() {
//		pulumi.Run(func(ctx *pulumi.Context) error {
//			terraform, err := databricks.NewSecretScope(ctx, "terraform", &databricks.SecretScopeArgs{
//				Name:                   pulumi.String("application"),
//				InitialManagePrincipal: pulumi.String("users"),
//			})
//			if err != nil {
//				return err
//			}
//			servicePrincipalKey, err := databricks.NewSecret(ctx, "service_principal_key", &databricks.SecretArgs{
//				Key:         pulumi.String("service_principal_key"),
//				StringValue: pulumi.Any(ARM_CLIENT_SECRET),
//				Scope:       terraform.Name,
//			})
//			if err != nil {
//				return err
//			}
//			this, err := storage.NewAccount(ctx, "this", &storage.AccountArgs{
//				Name:                   pulumi.String(fmt.Sprintf("%vdatalake", prefix)),
//				ResourceGroupName:      pulumi.Any(resourceGroupName),
//				Location:               pulumi.Any(resourceGroupLocation),
//				AccountTier:            pulumi.String("Standard"),
//				AccountReplicationType: pulumi.String("GRS"),
//				AccountKind:            pulumi.String("StorageV2"),
//				IsHnsEnabled:           pulumi.Bool(true),
//			})
//			if err != nil {
//				return err
//			}
//			_, err = authorization.NewAssignment(ctx, "this", &authorization.AssignmentArgs{
//				Scope:              this.ID(),
//				RoleDefinitionName: pulumi.String("Storage Blob Data Contributor"),
//				PrincipalId:        pulumi.Any(current.ObjectId),
//			})
//			if err != nil {
//				return err
//			}
//			thisContainer, err := storage.NewContainer(ctx, "this", &storage.ContainerArgs{
//				Name:                pulumi.String("marketing"),
//				StorageAccountName:  this.Name,
//				ContainerAccessType: pulumi.String("private"),
//			})
//			if err != nil {
//				return err
//			}
//			_, err = databricks.NewMount(ctx, "marketing", &databricks.MountArgs{
//				Name:       pulumi.String("marketing"),
//				ResourceId: thisContainer.ResourceManagerId,
//				Abfs: &databricks.MountAbfsArgs{
//					ClientId:             pulumi.Any(current.ClientId),
//					ClientSecretScope:    terraform.Name,
//					ClientSecretKey:      servicePrincipalKey.Key,
//					InitializeFileSystem: pulumi.Bool(true),
//				},
//			})
//			if err != nil {
//				return err
//			}
//			return nil
//		})
//	}
//
// ```
// <!--End PulumiCodeChooser -->
//
// ## gs block
//
// This block allows specifying parameters for mounting of the Google Cloud Storage. The following arguments are required inside the `gs` block:
//
// * `serviceAccount` - (Optional) (String) email of registered [Google Service Account](https://docs.gcp.databricks.com/data/data-sources/google/gcs.html#step-1-set-up-google-cloud-service-account-using-google-cloud-console) for data access.  If it's not specified, then the `clusterId` should be provided, and the cluster should have a Google service account attached to it.
// * `bucketName` - (Required) (String) GCS bucket name to be mounted.
//
// ### Example mounting Google Cloud Storage
//
// <!--Start PulumiCodeChooser -->
// ```go
// package main
//
// import (
//
//	"github.com/pulumi/pulumi-databricks/sdk/go/databricks"
//	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
//
// )
//
//	func main() {
//		pulumi.Run(func(ctx *pulumi.Context) error {
//			_, err := databricks.NewMount(ctx, "this_gs", &databricks.MountArgs{
//				Name: pulumi.String("gs-mount"),
//				Gs: &databricks.MountGsArgs{
//					ServiceAccount: pulumi.String("acc@company.iam.gserviceaccount.com"),
//					BucketName:     pulumi.String("mybucket"),
//				},
//			})
//			if err != nil {
//				return err
//			}
//			return nil
//		})
//	}
//
// ```
// <!--End PulumiCodeChooser -->
//
// ## adl block
//
// This block allows specifying parameters for mounting of the ADLS Gen1. The following arguments are required inside the `adl` block:
//
// * `clientId` - (Required) (String) This is the clientId for the enterprise application for the service principal.
// * `tenantId` - (Optional) (String) This is your azure directory tenant id. It is required for creating the mount. (Could be omitted if Azure authentication is used, and we can extract `tenantId` from it)
// * `clientSecretKey` - (Required) (String) This is the secret key in which your service principal/enterprise app client secret will be stored.
// * `clientSecretScope` - (Required) (String) This is the secret scope in which your service principal/enterprise app client secret will be stored.
//
// * `storageResourceName` - (Required) (String) The name of the storage resource in which the data is for ADLS gen 1. This is what you are trying to mount. (Could be omitted if `resourceId` is provided)
// * `sparkConfPrefix` - (Optional) (String) This is the spark configuration prefix for adls gen 1 mount. The options are `fs.adl`, `dfs.adls`. Use `fs.adl` for runtime 6.0 and above for the clusters. Otherwise use `dfs.adls`. The default value is: `fs.adl`.
// * `directory` - (Computed) (String) This is optional if you don't want to add an additional directory that you wish to mount. This must start with a "/".
//
// ### Example mounting ADLS Gen1
//
// <!--Start PulumiCodeChooser -->
// ```go
// package main
//
// import (
//
//	"github.com/pulumi/pulumi-databricks/sdk/go/databricks"
//	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
//
// )
//
//	func main() {
//		pulumi.Run(func(ctx *pulumi.Context) error {
//			_, err := databricks.NewMount(ctx, "mount", &databricks.MountArgs{
//				Name: pulumi.String("{var.RANDOM}"),
//				Adl: &databricks.MountAdlArgs{
//					StorageResourceName: pulumi.String("{env.TEST_STORAGE_ACCOUNT_NAME}"),
//					TenantId:            pulumi.Any(current.TenantId),
//					ClientId:            pulumi.Any(current.ClientId),
//					ClientSecretScope:   pulumi.Any(terraform.Name),
//					ClientSecretKey:     pulumi.Any(servicePrincipalKey.Key),
//					SparkConfPrefix:     pulumi.String("fs.adl"),
//				},
//			})
//			if err != nil {
//				return err
//			}
//			return nil
//		})
//	}
//
// ```
// <!--End PulumiCodeChooser -->
//
// ## wasb block
//
// This block allows specifying parameters for mounting of the Azure Blob Storage. The following arguments are required inside the `wasb` block:
//
// * `authType` - (Required) (String) This is the auth type for blob storage. This can either be SAS tokens (`SAS`) or account access keys (`ACCESS_KEY`).
// * `tokenSecretScope` - (Required) (String) This is the secret scope in which your auth type token is stored.
// * `tokenSecretKey` - (Required) (String) This is the secret key in which your auth type token is stored.
// * `containerName` - (Required) (String) The container in which the data is. This is what you are trying to mount. (Could be omitted if `resourceId` is provided)
// * `storageAccountName` - (Required) (String) The name of the storage resource in which the data is. (Could be omitted if `resourceId` is provided)
// * `directory` - (Computed) (String) This is optional if you don't want to add an additional directory that you wish to mount. This must start with a "/".
//
// ### Example mounting Azure Blob Storage
//
// <!--Start PulumiCodeChooser -->
// ```go
// package main
//
// import (
//
//	"fmt"
//
//	"github.com/pulumi/pulumi-azure/sdk/v5/go/azure/storage"
//	"github.com/pulumi/pulumi-databricks/sdk/go/databricks"
//	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
//
// )
//
//	func main() {
//		pulumi.Run(func(ctx *pulumi.Context) error {
//			blobaccount, err := storage.NewAccount(ctx, "blobaccount", &storage.AccountArgs{
//				Name:                   pulumi.String(fmt.Sprintf("%vblob", prefix)),
//				ResourceGroupName:      pulumi.Any(resourceGroupName),
//				Location:               pulumi.Any(resourceGroupLocation),
//				AccountTier:            pulumi.String("Standard"),
//				AccountReplicationType: pulumi.String("LRS"),
//				AccountKind:            pulumi.String("StorageV2"),
//			})
//			if err != nil {
//				return err
//			}
//			marketing, err := storage.NewContainer(ctx, "marketing", &storage.ContainerArgs{
//				Name:                pulumi.String("marketing"),
//				StorageAccountName:  blobaccount.Name,
//				ContainerAccessType: pulumi.String("private"),
//			})
//			if err != nil {
//				return err
//			}
//			terraform, err := databricks.NewSecretScope(ctx, "terraform", &databricks.SecretScopeArgs{
//				Name:                   pulumi.String("application"),
//				InitialManagePrincipal: pulumi.String("users"),
//			})
//			if err != nil {
//				return err
//			}
//			storageKey, err := databricks.NewSecret(ctx, "storage_key", &databricks.SecretArgs{
//				Key:         pulumi.String("blob_storage_key"),
//				StringValue: blobaccount.PrimaryAccessKey,
//				Scope:       terraform.Name,
//			})
//			if err != nil {
//				return err
//			}
//			_, err = databricks.NewMount(ctx, "marketing", &databricks.MountArgs{
//				Name: pulumi.String("marketing"),
//				Wasb: &databricks.MountWasbArgs{
//					ContainerName:      marketing.Name,
//					StorageAccountName: blobaccount.Name,
//					AuthType:           pulumi.String("ACCESS_KEY"),
//					TokenSecretScope:   terraform.Name,
//					TokenSecretKey:     storageKey.Key,
//				},
//			})
//			if err != nil {
//				return err
//			}
//			return nil
//		})
//	}
//
// ```
// <!--End PulumiCodeChooser -->
//
// ## Migration from other mount resources
//
// Migration from the specific mount resource is straightforward:
//
// * rename `mountName` to `name`
// * wrap storage-specific settings (`containerName`, ...) into corresponding block (`adl`, `abfs`, `s3`, `wasbs`)
// * for S3 mounts, rename `s3BucketName` to `bucketName`
//
// ## Related Resources
//
// The following resources are often used in the same context:
//
// * End to end workspace management guide.
// * getAwsBucketPolicy data to configure a simple access policy for AWS S3 buckets, so that Databricks can access data in it.
// * Cluster to create [Databricks Clusters](https://docs.databricks.com/clusters/index.html).
// * DbfsFile data to get file content from [Databricks File System (DBFS)](https://docs.databricks.com/data/databricks-file-system.html).
// * getDbfsFilePaths data to get list of file names from get file content from [Databricks File System (DBFS)](https://docs.databricks.com/data/databricks-file-system.html).
// * DbfsFile to manage relatively small files on [Databricks File System (DBFS)](https://docs.databricks.com/data/databricks-file-system.html).
// * InstanceProfile to manage AWS EC2 instance profiles that users can launch Cluster and access data, like databricks_mount.
// * Library to install a [library](https://docs.databricks.com/libraries/index.html) on databricks_cluster.
//
// ## Import
//
// -> **Note** Importing this resource is not currently supported.
type Mount struct {
	pulumi.CustomResourceState

	Abfs           MountAbfsPtrOutput     `pulumi:"abfs"`
	Adl            MountAdlPtrOutput      `pulumi:"adl"`
	ClusterId      pulumi.StringOutput    `pulumi:"clusterId"`
	EncryptionType pulumi.StringPtrOutput `pulumi:"encryptionType"`
	ExtraConfigs   pulumi.MapOutput       `pulumi:"extraConfigs"`
	Gs             MountGsPtrOutput       `pulumi:"gs"`
	Name           pulumi.StringOutput    `pulumi:"name"`
	ResourceId     pulumi.StringPtrOutput `pulumi:"resourceId"`
	S3             MountS3PtrOutput       `pulumi:"s3"`
	// (String) HDFS-compatible url
	Source pulumi.StringOutput    `pulumi:"source"`
	Uri    pulumi.StringPtrOutput `pulumi:"uri"`
	Wasb   MountWasbPtrOutput     `pulumi:"wasb"`
}

// NewMount registers a new resource with the given unique name, arguments, and options.
func NewMount(ctx *pulumi.Context,
	name string, args *MountArgs, opts ...pulumi.ResourceOption) (*Mount, error) {
	if args == nil {
		args = &MountArgs{}
	}

	opts = internal.PkgResourceDefaultOpts(opts)
	var resource Mount
	err := ctx.RegisterResource("databricks:index/mount:Mount", name, args, &resource, opts...)
	if err != nil {
		return nil, err
	}
	return &resource, nil
}

// GetMount gets an existing Mount resource's state with the given name, ID, and optional
// state properties that are used to uniquely qualify the lookup (nil if not required).
func GetMount(ctx *pulumi.Context,
	name string, id pulumi.IDInput, state *MountState, opts ...pulumi.ResourceOption) (*Mount, error) {
	var resource Mount
	err := ctx.ReadResource("databricks:index/mount:Mount", name, id, state, &resource, opts...)
	if err != nil {
		return nil, err
	}
	return &resource, nil
}

// Input properties used for looking up and filtering Mount resources.
type mountState struct {
	Abfs           *MountAbfs             `pulumi:"abfs"`
	Adl            *MountAdl              `pulumi:"adl"`
	ClusterId      *string                `pulumi:"clusterId"`
	EncryptionType *string                `pulumi:"encryptionType"`
	ExtraConfigs   map[string]interface{} `pulumi:"extraConfigs"`
	Gs             *MountGs               `pulumi:"gs"`
	Name           *string                `pulumi:"name"`
	ResourceId     *string                `pulumi:"resourceId"`
	S3             *MountS3               `pulumi:"s3"`
	// (String) HDFS-compatible url
	Source *string    `pulumi:"source"`
	Uri    *string    `pulumi:"uri"`
	Wasb   *MountWasb `pulumi:"wasb"`
}

type MountState struct {
	Abfs           MountAbfsPtrInput
	Adl            MountAdlPtrInput
	ClusterId      pulumi.StringPtrInput
	EncryptionType pulumi.StringPtrInput
	ExtraConfigs   pulumi.MapInput
	Gs             MountGsPtrInput
	Name           pulumi.StringPtrInput
	ResourceId     pulumi.StringPtrInput
	S3             MountS3PtrInput
	// (String) HDFS-compatible url
	Source pulumi.StringPtrInput
	Uri    pulumi.StringPtrInput
	Wasb   MountWasbPtrInput
}

func (MountState) ElementType() reflect.Type {
	return reflect.TypeOf((*mountState)(nil)).Elem()
}

type mountArgs struct {
	Abfs           *MountAbfs             `pulumi:"abfs"`
	Adl            *MountAdl              `pulumi:"adl"`
	ClusterId      *string                `pulumi:"clusterId"`
	EncryptionType *string                `pulumi:"encryptionType"`
	ExtraConfigs   map[string]interface{} `pulumi:"extraConfigs"`
	Gs             *MountGs               `pulumi:"gs"`
	Name           *string                `pulumi:"name"`
	ResourceId     *string                `pulumi:"resourceId"`
	S3             *MountS3               `pulumi:"s3"`
	Uri            *string                `pulumi:"uri"`
	Wasb           *MountWasb             `pulumi:"wasb"`
}

// The set of arguments for constructing a Mount resource.
type MountArgs struct {
	Abfs           MountAbfsPtrInput
	Adl            MountAdlPtrInput
	ClusterId      pulumi.StringPtrInput
	EncryptionType pulumi.StringPtrInput
	ExtraConfigs   pulumi.MapInput
	Gs             MountGsPtrInput
	Name           pulumi.StringPtrInput
	ResourceId     pulumi.StringPtrInput
	S3             MountS3PtrInput
	Uri            pulumi.StringPtrInput
	Wasb           MountWasbPtrInput
}

func (MountArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*mountArgs)(nil)).Elem()
}

type MountInput interface {
	pulumi.Input

	ToMountOutput() MountOutput
	ToMountOutputWithContext(ctx context.Context) MountOutput
}

func (*Mount) ElementType() reflect.Type {
	return reflect.TypeOf((**Mount)(nil)).Elem()
}

func (i *Mount) ToMountOutput() MountOutput {
	return i.ToMountOutputWithContext(context.Background())
}

func (i *Mount) ToMountOutputWithContext(ctx context.Context) MountOutput {
	return pulumi.ToOutputWithContext(ctx, i).(MountOutput)
}

// MountArrayInput is an input type that accepts MountArray and MountArrayOutput values.
// You can construct a concrete instance of `MountArrayInput` via:
//
//	MountArray{ MountArgs{...} }
type MountArrayInput interface {
	pulumi.Input

	ToMountArrayOutput() MountArrayOutput
	ToMountArrayOutputWithContext(context.Context) MountArrayOutput
}

type MountArray []MountInput

func (MountArray) ElementType() reflect.Type {
	return reflect.TypeOf((*[]*Mount)(nil)).Elem()
}

func (i MountArray) ToMountArrayOutput() MountArrayOutput {
	return i.ToMountArrayOutputWithContext(context.Background())
}

func (i MountArray) ToMountArrayOutputWithContext(ctx context.Context) MountArrayOutput {
	return pulumi.ToOutputWithContext(ctx, i).(MountArrayOutput)
}

// MountMapInput is an input type that accepts MountMap and MountMapOutput values.
// You can construct a concrete instance of `MountMapInput` via:
//
//	MountMap{ "key": MountArgs{...} }
type MountMapInput interface {
	pulumi.Input

	ToMountMapOutput() MountMapOutput
	ToMountMapOutputWithContext(context.Context) MountMapOutput
}

type MountMap map[string]MountInput

func (MountMap) ElementType() reflect.Type {
	return reflect.TypeOf((*map[string]*Mount)(nil)).Elem()
}

func (i MountMap) ToMountMapOutput() MountMapOutput {
	return i.ToMountMapOutputWithContext(context.Background())
}

func (i MountMap) ToMountMapOutputWithContext(ctx context.Context) MountMapOutput {
	return pulumi.ToOutputWithContext(ctx, i).(MountMapOutput)
}

type MountOutput struct{ *pulumi.OutputState }

func (MountOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**Mount)(nil)).Elem()
}

func (o MountOutput) ToMountOutput() MountOutput {
	return o
}

func (o MountOutput) ToMountOutputWithContext(ctx context.Context) MountOutput {
	return o
}

func (o MountOutput) Abfs() MountAbfsPtrOutput {
	return o.ApplyT(func(v *Mount) MountAbfsPtrOutput { return v.Abfs }).(MountAbfsPtrOutput)
}

func (o MountOutput) Adl() MountAdlPtrOutput {
	return o.ApplyT(func(v *Mount) MountAdlPtrOutput { return v.Adl }).(MountAdlPtrOutput)
}

func (o MountOutput) ClusterId() pulumi.StringOutput {
	return o.ApplyT(func(v *Mount) pulumi.StringOutput { return v.ClusterId }).(pulumi.StringOutput)
}

func (o MountOutput) EncryptionType() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *Mount) pulumi.StringPtrOutput { return v.EncryptionType }).(pulumi.StringPtrOutput)
}

func (o MountOutput) ExtraConfigs() pulumi.MapOutput {
	return o.ApplyT(func(v *Mount) pulumi.MapOutput { return v.ExtraConfigs }).(pulumi.MapOutput)
}

func (o MountOutput) Gs() MountGsPtrOutput {
	return o.ApplyT(func(v *Mount) MountGsPtrOutput { return v.Gs }).(MountGsPtrOutput)
}

func (o MountOutput) Name() pulumi.StringOutput {
	return o.ApplyT(func(v *Mount) pulumi.StringOutput { return v.Name }).(pulumi.StringOutput)
}

func (o MountOutput) ResourceId() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *Mount) pulumi.StringPtrOutput { return v.ResourceId }).(pulumi.StringPtrOutput)
}

func (o MountOutput) S3() MountS3PtrOutput {
	return o.ApplyT(func(v *Mount) MountS3PtrOutput { return v.S3 }).(MountS3PtrOutput)
}

// (String) HDFS-compatible url
func (o MountOutput) Source() pulumi.StringOutput {
	return o.ApplyT(func(v *Mount) pulumi.StringOutput { return v.Source }).(pulumi.StringOutput)
}

func (o MountOutput) Uri() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *Mount) pulumi.StringPtrOutput { return v.Uri }).(pulumi.StringPtrOutput)
}

func (o MountOutput) Wasb() MountWasbPtrOutput {
	return o.ApplyT(func(v *Mount) MountWasbPtrOutput { return v.Wasb }).(MountWasbPtrOutput)
}

type MountArrayOutput struct{ *pulumi.OutputState }

func (MountArrayOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*[]*Mount)(nil)).Elem()
}

func (o MountArrayOutput) ToMountArrayOutput() MountArrayOutput {
	return o
}

func (o MountArrayOutput) ToMountArrayOutputWithContext(ctx context.Context) MountArrayOutput {
	return o
}

func (o MountArrayOutput) Index(i pulumi.IntInput) MountOutput {
	return pulumi.All(o, i).ApplyT(func(vs []interface{}) *Mount {
		return vs[0].([]*Mount)[vs[1].(int)]
	}).(MountOutput)
}

type MountMapOutput struct{ *pulumi.OutputState }

func (MountMapOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*map[string]*Mount)(nil)).Elem()
}

func (o MountMapOutput) ToMountMapOutput() MountMapOutput {
	return o
}

func (o MountMapOutput) ToMountMapOutputWithContext(ctx context.Context) MountMapOutput {
	return o
}

func (o MountMapOutput) MapIndex(k pulumi.StringInput) MountOutput {
	return pulumi.All(o, k).ApplyT(func(vs []interface{}) *Mount {
		return vs[0].(map[string]*Mount)[vs[1].(string)]
	}).(MountOutput)
}

func init() {
	pulumi.RegisterInputType(reflect.TypeOf((*MountInput)(nil)).Elem(), &Mount{})
	pulumi.RegisterInputType(reflect.TypeOf((*MountArrayInput)(nil)).Elem(), MountArray{})
	pulumi.RegisterInputType(reflect.TypeOf((*MountMapInput)(nil)).Elem(), MountMap{})
	pulumi.RegisterOutputType(MountOutput{})
	pulumi.RegisterOutputType(MountArrayOutput{})
	pulumi.RegisterOutputType(MountMapOutput{})
}
