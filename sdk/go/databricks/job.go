// Code generated by the Pulumi Terraform Bridge (tfgen) Tool DO NOT EDIT.
// *** WARNING: Do not edit by hand unless you're certain you know what you are doing! ***

package databricks

import (
	"context"
	"reflect"

	"github.com/pulumi/pulumi-databricks/sdk/go/databricks/internal"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

// ## Import
//
// # The resource job can be imported using the id of the job bash
//
// ```sh
//
//	$ pulumi import databricks:index/job:Job this <job-id>
//
// ```
type Job struct {
	pulumi.CustomResourceState

	// (Bool) Whenever the job is always running, like a Spark Streaming application, on every update restart the current active run or start it again, if nothing it is not running. False by default. Any job runs are started with `parameters` specified in `sparkJarTask` or `sparkSubmitTask` or `sparkPythonTask` or `notebookTask` blocks.
	//
	// Deprecated: always_running will be replaced by control_run_state in the next major release.
	AlwaysRunning pulumi.BoolPtrOutput   `pulumi:"alwaysRunning"`
	Computes      JobComputeArrayOutput  `pulumi:"computes"`
	Continuous    JobContinuousPtrOutput `pulumi:"continuous"`
	// (Bool) If true, the Databricks provider will stop and start the job as needed to ensure that the active run for the job reflects the deployed configuration. For continuous jobs, the provider respects the `pauseStatus` by stopping the current active run. This flag cannot be set for non-continuous jobs.
	//
	// When migrating from `alwaysRunning` to `controlRunState`, set `continuous` as follows:
	//
	// ```go
	// package main
	//
	// import (
	// 	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
	// )
	//
	// func main() {
	// 	pulumi.Run(func(ctx *pulumi.Context) error {
	// 		return nil
	// 	})
	// }
	// ```
	ControlRunState pulumi.BoolPtrOutput `pulumi:"controlRunState"`
	// Deprecated: should be used inside a task block and not inside a job block
	DbtTask    JobDbtTaskPtrOutput    `pulumi:"dbtTask"`
	Deployment JobDeploymentPtrOutput `pulumi:"deployment"`
	// An optional description for the job. The maximum length is 1024 characters in UTF-8 encoding.
	Description pulumi.StringPtrOutput `pulumi:"description"`
	EditMode    pulumi.StringPtrOutput `pulumi:"editMode"`
	// (List) An optional set of email addresses notified when runs of this job begins, completes or fails. The default behavior is to not send any emails. This field is a block and is documented below.
	EmailNotifications JobEmailNotificationsPtrOutput `pulumi:"emailNotifications"`
	ExistingClusterId  pulumi.StringPtrOutput         `pulumi:"existingClusterId"`
	Format             pulumi.StringOutput            `pulumi:"format"`
	GitSource          JobGitSourcePtrOutput          `pulumi:"gitSource"`
	// An optional block that specifies the health conditions for the job (described below).
	Health JobHealthPtrOutput `pulumi:"health"`
	// A list of job Cluster specifications that can be shared and reused by tasks of this job. Libraries cannot be declared in a shared job cluster. You must declare dependent libraries in task settings. *Multi-task syntax*
	JobClusters JobJobClusterArrayOutput `pulumi:"jobClusters"`
	// (Set) An optional list of libraries to be installed on the cluster that will execute the job. Please consult libraries section for Cluster resource.
	Libraries JobLibraryArrayOutput `pulumi:"libraries"`
	// (Integer) An optional maximum allowed number of concurrent runs of the job. Defaults to *1*.
	MaxConcurrentRuns pulumi.IntPtrOutput `pulumi:"maxConcurrentRuns"`
	// (Integer) An optional maximum number of times to retry an unsuccessful run. A run is considered to be unsuccessful if it completes with a `FAILED` or `INTERNAL_ERROR` lifecycle state. The value -1 means to retry indefinitely and the value 0 means to never retry. The default behavior is to never retry. A run can have the following lifecycle state: `PENDING`, `RUNNING`, `TERMINATING`, `TERMINATED`, `SKIPPED` or `INTERNAL_ERROR`.
	//
	// Deprecated: should be used inside a task block and not inside a job block
	MaxRetries pulumi.IntPtrOutput `pulumi:"maxRetries"`
	// (Integer) An optional minimal interval in milliseconds between the start of the failed run and the subsequent retry run. The default behavior is that unsuccessful runs are immediately retried.
	//
	// Deprecated: should be used inside a task block and not inside a job block
	MinRetryIntervalMillis pulumi.IntPtrOutput `pulumi:"minRetryIntervalMillis"`
	// An optional name for the job. The default value is Untitled.
	Name pulumi.StringOutput `pulumi:"name"`
	// Same set of parameters as for Cluster resource.
	NewCluster JobNewClusterPtrOutput `pulumi:"newCluster"`
	// Deprecated: should be used inside a task block and not inside a job block
	NotebookTask JobNotebookTaskPtrOutput `pulumi:"notebookTask"`
	// An optional block controlling the notification settings on the job level (described below).
	NotificationSettings JobNotificationSettingsPtrOutput `pulumi:"notificationSettings"`
	Parameters           JobParameterArrayOutput          `pulumi:"parameters"`
	// Deprecated: should be used inside a task block and not inside a job block
	PipelineTask JobPipelineTaskPtrOutput `pulumi:"pipelineTask"`
	// Deprecated: should be used inside a task block and not inside a job block
	PythonWheelTask JobPythonWheelTaskPtrOutput `pulumi:"pythonWheelTask"`
	Queue           JobQueuePtrOutput           `pulumi:"queue"`
	// (Bool) An optional policy to specify whether to retry a job when it times out. The default behavior is to not retry on timeout.
	//
	// Deprecated: should be used inside a task block and not inside a job block
	RetryOnTimeout pulumi.BoolPtrOutput `pulumi:"retryOnTimeout"`
	RunAs          JobRunAsOutput       `pulumi:"runAs"`
	// Deprecated: should be used inside a task block and not inside a job block
	RunJobTask JobRunJobTaskPtrOutput `pulumi:"runJobTask"`
	// (List) An optional periodic schedule for this job. The default behavior is that the job runs when triggered by clicking Run Now in the Jobs UI or sending an API request to runNow. This field is a block and is documented below.
	Schedule JobSchedulePtrOutput `pulumi:"schedule"`
	// Deprecated: should be used inside a task block and not inside a job block
	SparkJarTask JobSparkJarTaskPtrOutput `pulumi:"sparkJarTask"`
	// Deprecated: should be used inside a task block and not inside a job block
	SparkPythonTask JobSparkPythonTaskPtrOutput `pulumi:"sparkPythonTask"`
	// Deprecated: should be used inside a task block and not inside a job block
	SparkSubmitTask JobSparkSubmitTaskPtrOutput `pulumi:"sparkSubmitTask"`
	Tags            pulumi.MapOutput            `pulumi:"tags"`
	Tasks           JobTaskArrayOutput          `pulumi:"tasks"`
	// (Integer) An optional timeout applied to each run of this job. The default behavior is to have no timeout.
	TimeoutSeconds pulumi.IntPtrOutput `pulumi:"timeoutSeconds"`
	Trigger        JobTriggerPtrOutput `pulumi:"trigger"`
	// URL of the Git repository to use.
	Url pulumi.StringOutput `pulumi:"url"`
	// (List) An optional set of system destinations (for example, webhook destinations or Slack) to be notified when runs of this job begins, completes or fails. The default behavior is to not send any notifications. This field is a block and is documented below.
	WebhookNotifications JobWebhookNotificationsPtrOutput `pulumi:"webhookNotifications"`
}

// NewJob registers a new resource with the given unique name, arguments, and options.
func NewJob(ctx *pulumi.Context,
	name string, args *JobArgs, opts ...pulumi.ResourceOption) (*Job, error) {
	if args == nil {
		args = &JobArgs{}
	}

	opts = internal.PkgResourceDefaultOpts(opts)
	var resource Job
	err := ctx.RegisterResource("databricks:index/job:Job", name, args, &resource, opts...)
	if err != nil {
		return nil, err
	}
	return &resource, nil
}

// GetJob gets an existing Job resource's state with the given name, ID, and optional
// state properties that are used to uniquely qualify the lookup (nil if not required).
func GetJob(ctx *pulumi.Context,
	name string, id pulumi.IDInput, state *JobState, opts ...pulumi.ResourceOption) (*Job, error) {
	var resource Job
	err := ctx.ReadResource("databricks:index/job:Job", name, id, state, &resource, opts...)
	if err != nil {
		return nil, err
	}
	return &resource, nil
}

// Input properties used for looking up and filtering Job resources.
type jobState struct {
	// (Bool) Whenever the job is always running, like a Spark Streaming application, on every update restart the current active run or start it again, if nothing it is not running. False by default. Any job runs are started with `parameters` specified in `sparkJarTask` or `sparkSubmitTask` or `sparkPythonTask` or `notebookTask` blocks.
	//
	// Deprecated: always_running will be replaced by control_run_state in the next major release.
	AlwaysRunning *bool          `pulumi:"alwaysRunning"`
	Computes      []JobCompute   `pulumi:"computes"`
	Continuous    *JobContinuous `pulumi:"continuous"`
	// (Bool) If true, the Databricks provider will stop and start the job as needed to ensure that the active run for the job reflects the deployed configuration. For continuous jobs, the provider respects the `pauseStatus` by stopping the current active run. This flag cannot be set for non-continuous jobs.
	//
	// When migrating from `alwaysRunning` to `controlRunState`, set `continuous` as follows:
	//
	// ```go
	// package main
	//
	// import (
	// 	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
	// )
	//
	// func main() {
	// 	pulumi.Run(func(ctx *pulumi.Context) error {
	// 		return nil
	// 	})
	// }
	// ```
	ControlRunState *bool `pulumi:"controlRunState"`
	// Deprecated: should be used inside a task block and not inside a job block
	DbtTask    *JobDbtTask    `pulumi:"dbtTask"`
	Deployment *JobDeployment `pulumi:"deployment"`
	// An optional description for the job. The maximum length is 1024 characters in UTF-8 encoding.
	Description *string `pulumi:"description"`
	EditMode    *string `pulumi:"editMode"`
	// (List) An optional set of email addresses notified when runs of this job begins, completes or fails. The default behavior is to not send any emails. This field is a block and is documented below.
	EmailNotifications *JobEmailNotifications `pulumi:"emailNotifications"`
	ExistingClusterId  *string                `pulumi:"existingClusterId"`
	Format             *string                `pulumi:"format"`
	GitSource          *JobGitSource          `pulumi:"gitSource"`
	// An optional block that specifies the health conditions for the job (described below).
	Health *JobHealth `pulumi:"health"`
	// A list of job Cluster specifications that can be shared and reused by tasks of this job. Libraries cannot be declared in a shared job cluster. You must declare dependent libraries in task settings. *Multi-task syntax*
	JobClusters []JobJobCluster `pulumi:"jobClusters"`
	// (Set) An optional list of libraries to be installed on the cluster that will execute the job. Please consult libraries section for Cluster resource.
	Libraries []JobLibrary `pulumi:"libraries"`
	// (Integer) An optional maximum allowed number of concurrent runs of the job. Defaults to *1*.
	MaxConcurrentRuns *int `pulumi:"maxConcurrentRuns"`
	// (Integer) An optional maximum number of times to retry an unsuccessful run. A run is considered to be unsuccessful if it completes with a `FAILED` or `INTERNAL_ERROR` lifecycle state. The value -1 means to retry indefinitely and the value 0 means to never retry. The default behavior is to never retry. A run can have the following lifecycle state: `PENDING`, `RUNNING`, `TERMINATING`, `TERMINATED`, `SKIPPED` or `INTERNAL_ERROR`.
	//
	// Deprecated: should be used inside a task block and not inside a job block
	MaxRetries *int `pulumi:"maxRetries"`
	// (Integer) An optional minimal interval in milliseconds between the start of the failed run and the subsequent retry run. The default behavior is that unsuccessful runs are immediately retried.
	//
	// Deprecated: should be used inside a task block and not inside a job block
	MinRetryIntervalMillis *int `pulumi:"minRetryIntervalMillis"`
	// An optional name for the job. The default value is Untitled.
	Name *string `pulumi:"name"`
	// Same set of parameters as for Cluster resource.
	NewCluster *JobNewCluster `pulumi:"newCluster"`
	// Deprecated: should be used inside a task block and not inside a job block
	NotebookTask *JobNotebookTask `pulumi:"notebookTask"`
	// An optional block controlling the notification settings on the job level (described below).
	NotificationSettings *JobNotificationSettings `pulumi:"notificationSettings"`
	Parameters           []JobParameter           `pulumi:"parameters"`
	// Deprecated: should be used inside a task block and not inside a job block
	PipelineTask *JobPipelineTask `pulumi:"pipelineTask"`
	// Deprecated: should be used inside a task block and not inside a job block
	PythonWheelTask *JobPythonWheelTask `pulumi:"pythonWheelTask"`
	Queue           *JobQueue           `pulumi:"queue"`
	// (Bool) An optional policy to specify whether to retry a job when it times out. The default behavior is to not retry on timeout.
	//
	// Deprecated: should be used inside a task block and not inside a job block
	RetryOnTimeout *bool     `pulumi:"retryOnTimeout"`
	RunAs          *JobRunAs `pulumi:"runAs"`
	// Deprecated: should be used inside a task block and not inside a job block
	RunJobTask *JobRunJobTask `pulumi:"runJobTask"`
	// (List) An optional periodic schedule for this job. The default behavior is that the job runs when triggered by clicking Run Now in the Jobs UI or sending an API request to runNow. This field is a block and is documented below.
	Schedule *JobSchedule `pulumi:"schedule"`
	// Deprecated: should be used inside a task block and not inside a job block
	SparkJarTask *JobSparkJarTask `pulumi:"sparkJarTask"`
	// Deprecated: should be used inside a task block and not inside a job block
	SparkPythonTask *JobSparkPythonTask `pulumi:"sparkPythonTask"`
	// Deprecated: should be used inside a task block and not inside a job block
	SparkSubmitTask *JobSparkSubmitTask    `pulumi:"sparkSubmitTask"`
	Tags            map[string]interface{} `pulumi:"tags"`
	Tasks           []JobTask              `pulumi:"tasks"`
	// (Integer) An optional timeout applied to each run of this job. The default behavior is to have no timeout.
	TimeoutSeconds *int        `pulumi:"timeoutSeconds"`
	Trigger        *JobTrigger `pulumi:"trigger"`
	// URL of the Git repository to use.
	Url *string `pulumi:"url"`
	// (List) An optional set of system destinations (for example, webhook destinations or Slack) to be notified when runs of this job begins, completes or fails. The default behavior is to not send any notifications. This field is a block and is documented below.
	WebhookNotifications *JobWebhookNotifications `pulumi:"webhookNotifications"`
}

type JobState struct {
	// (Bool) Whenever the job is always running, like a Spark Streaming application, on every update restart the current active run or start it again, if nothing it is not running. False by default. Any job runs are started with `parameters` specified in `sparkJarTask` or `sparkSubmitTask` or `sparkPythonTask` or `notebookTask` blocks.
	//
	// Deprecated: always_running will be replaced by control_run_state in the next major release.
	AlwaysRunning pulumi.BoolPtrInput
	Computes      JobComputeArrayInput
	Continuous    JobContinuousPtrInput
	// (Bool) If true, the Databricks provider will stop and start the job as needed to ensure that the active run for the job reflects the deployed configuration. For continuous jobs, the provider respects the `pauseStatus` by stopping the current active run. This flag cannot be set for non-continuous jobs.
	//
	// When migrating from `alwaysRunning` to `controlRunState`, set `continuous` as follows:
	//
	// ```go
	// package main
	//
	// import (
	// 	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
	// )
	//
	// func main() {
	// 	pulumi.Run(func(ctx *pulumi.Context) error {
	// 		return nil
	// 	})
	// }
	// ```
	ControlRunState pulumi.BoolPtrInput
	// Deprecated: should be used inside a task block and not inside a job block
	DbtTask    JobDbtTaskPtrInput
	Deployment JobDeploymentPtrInput
	// An optional description for the job. The maximum length is 1024 characters in UTF-8 encoding.
	Description pulumi.StringPtrInput
	EditMode    pulumi.StringPtrInput
	// (List) An optional set of email addresses notified when runs of this job begins, completes or fails. The default behavior is to not send any emails. This field is a block and is documented below.
	EmailNotifications JobEmailNotificationsPtrInput
	ExistingClusterId  pulumi.StringPtrInput
	Format             pulumi.StringPtrInput
	GitSource          JobGitSourcePtrInput
	// An optional block that specifies the health conditions for the job (described below).
	Health JobHealthPtrInput
	// A list of job Cluster specifications that can be shared and reused by tasks of this job. Libraries cannot be declared in a shared job cluster. You must declare dependent libraries in task settings. *Multi-task syntax*
	JobClusters JobJobClusterArrayInput
	// (Set) An optional list of libraries to be installed on the cluster that will execute the job. Please consult libraries section for Cluster resource.
	Libraries JobLibraryArrayInput
	// (Integer) An optional maximum allowed number of concurrent runs of the job. Defaults to *1*.
	MaxConcurrentRuns pulumi.IntPtrInput
	// (Integer) An optional maximum number of times to retry an unsuccessful run. A run is considered to be unsuccessful if it completes with a `FAILED` or `INTERNAL_ERROR` lifecycle state. The value -1 means to retry indefinitely and the value 0 means to never retry. The default behavior is to never retry. A run can have the following lifecycle state: `PENDING`, `RUNNING`, `TERMINATING`, `TERMINATED`, `SKIPPED` or `INTERNAL_ERROR`.
	//
	// Deprecated: should be used inside a task block and not inside a job block
	MaxRetries pulumi.IntPtrInput
	// (Integer) An optional minimal interval in milliseconds between the start of the failed run and the subsequent retry run. The default behavior is that unsuccessful runs are immediately retried.
	//
	// Deprecated: should be used inside a task block and not inside a job block
	MinRetryIntervalMillis pulumi.IntPtrInput
	// An optional name for the job. The default value is Untitled.
	Name pulumi.StringPtrInput
	// Same set of parameters as for Cluster resource.
	NewCluster JobNewClusterPtrInput
	// Deprecated: should be used inside a task block and not inside a job block
	NotebookTask JobNotebookTaskPtrInput
	// An optional block controlling the notification settings on the job level (described below).
	NotificationSettings JobNotificationSettingsPtrInput
	Parameters           JobParameterArrayInput
	// Deprecated: should be used inside a task block and not inside a job block
	PipelineTask JobPipelineTaskPtrInput
	// Deprecated: should be used inside a task block and not inside a job block
	PythonWheelTask JobPythonWheelTaskPtrInput
	Queue           JobQueuePtrInput
	// (Bool) An optional policy to specify whether to retry a job when it times out. The default behavior is to not retry on timeout.
	//
	// Deprecated: should be used inside a task block and not inside a job block
	RetryOnTimeout pulumi.BoolPtrInput
	RunAs          JobRunAsPtrInput
	// Deprecated: should be used inside a task block and not inside a job block
	RunJobTask JobRunJobTaskPtrInput
	// (List) An optional periodic schedule for this job. The default behavior is that the job runs when triggered by clicking Run Now in the Jobs UI or sending an API request to runNow. This field is a block and is documented below.
	Schedule JobSchedulePtrInput
	// Deprecated: should be used inside a task block and not inside a job block
	SparkJarTask JobSparkJarTaskPtrInput
	// Deprecated: should be used inside a task block and not inside a job block
	SparkPythonTask JobSparkPythonTaskPtrInput
	// Deprecated: should be used inside a task block and not inside a job block
	SparkSubmitTask JobSparkSubmitTaskPtrInput
	Tags            pulumi.MapInput
	Tasks           JobTaskArrayInput
	// (Integer) An optional timeout applied to each run of this job. The default behavior is to have no timeout.
	TimeoutSeconds pulumi.IntPtrInput
	Trigger        JobTriggerPtrInput
	// URL of the Git repository to use.
	Url pulumi.StringPtrInput
	// (List) An optional set of system destinations (for example, webhook destinations or Slack) to be notified when runs of this job begins, completes or fails. The default behavior is to not send any notifications. This field is a block and is documented below.
	WebhookNotifications JobWebhookNotificationsPtrInput
}

func (JobState) ElementType() reflect.Type {
	return reflect.TypeOf((*jobState)(nil)).Elem()
}

type jobArgs struct {
	// (Bool) Whenever the job is always running, like a Spark Streaming application, on every update restart the current active run or start it again, if nothing it is not running. False by default. Any job runs are started with `parameters` specified in `sparkJarTask` or `sparkSubmitTask` or `sparkPythonTask` or `notebookTask` blocks.
	//
	// Deprecated: always_running will be replaced by control_run_state in the next major release.
	AlwaysRunning *bool          `pulumi:"alwaysRunning"`
	Computes      []JobCompute   `pulumi:"computes"`
	Continuous    *JobContinuous `pulumi:"continuous"`
	// (Bool) If true, the Databricks provider will stop and start the job as needed to ensure that the active run for the job reflects the deployed configuration. For continuous jobs, the provider respects the `pauseStatus` by stopping the current active run. This flag cannot be set for non-continuous jobs.
	//
	// When migrating from `alwaysRunning` to `controlRunState`, set `continuous` as follows:
	//
	// ```go
	// package main
	//
	// import (
	// 	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
	// )
	//
	// func main() {
	// 	pulumi.Run(func(ctx *pulumi.Context) error {
	// 		return nil
	// 	})
	// }
	// ```
	ControlRunState *bool `pulumi:"controlRunState"`
	// Deprecated: should be used inside a task block and not inside a job block
	DbtTask    *JobDbtTask    `pulumi:"dbtTask"`
	Deployment *JobDeployment `pulumi:"deployment"`
	// An optional description for the job. The maximum length is 1024 characters in UTF-8 encoding.
	Description *string `pulumi:"description"`
	EditMode    *string `pulumi:"editMode"`
	// (List) An optional set of email addresses notified when runs of this job begins, completes or fails. The default behavior is to not send any emails. This field is a block and is documented below.
	EmailNotifications *JobEmailNotifications `pulumi:"emailNotifications"`
	ExistingClusterId  *string                `pulumi:"existingClusterId"`
	Format             *string                `pulumi:"format"`
	GitSource          *JobGitSource          `pulumi:"gitSource"`
	// An optional block that specifies the health conditions for the job (described below).
	Health *JobHealth `pulumi:"health"`
	// A list of job Cluster specifications that can be shared and reused by tasks of this job. Libraries cannot be declared in a shared job cluster. You must declare dependent libraries in task settings. *Multi-task syntax*
	JobClusters []JobJobCluster `pulumi:"jobClusters"`
	// (Set) An optional list of libraries to be installed on the cluster that will execute the job. Please consult libraries section for Cluster resource.
	Libraries []JobLibrary `pulumi:"libraries"`
	// (Integer) An optional maximum allowed number of concurrent runs of the job. Defaults to *1*.
	MaxConcurrentRuns *int `pulumi:"maxConcurrentRuns"`
	// (Integer) An optional maximum number of times to retry an unsuccessful run. A run is considered to be unsuccessful if it completes with a `FAILED` or `INTERNAL_ERROR` lifecycle state. The value -1 means to retry indefinitely and the value 0 means to never retry. The default behavior is to never retry. A run can have the following lifecycle state: `PENDING`, `RUNNING`, `TERMINATING`, `TERMINATED`, `SKIPPED` or `INTERNAL_ERROR`.
	//
	// Deprecated: should be used inside a task block and not inside a job block
	MaxRetries *int `pulumi:"maxRetries"`
	// (Integer) An optional minimal interval in milliseconds between the start of the failed run and the subsequent retry run. The default behavior is that unsuccessful runs are immediately retried.
	//
	// Deprecated: should be used inside a task block and not inside a job block
	MinRetryIntervalMillis *int `pulumi:"minRetryIntervalMillis"`
	// An optional name for the job. The default value is Untitled.
	Name *string `pulumi:"name"`
	// Same set of parameters as for Cluster resource.
	NewCluster *JobNewCluster `pulumi:"newCluster"`
	// Deprecated: should be used inside a task block and not inside a job block
	NotebookTask *JobNotebookTask `pulumi:"notebookTask"`
	// An optional block controlling the notification settings on the job level (described below).
	NotificationSettings *JobNotificationSettings `pulumi:"notificationSettings"`
	Parameters           []JobParameter           `pulumi:"parameters"`
	// Deprecated: should be used inside a task block and not inside a job block
	PipelineTask *JobPipelineTask `pulumi:"pipelineTask"`
	// Deprecated: should be used inside a task block and not inside a job block
	PythonWheelTask *JobPythonWheelTask `pulumi:"pythonWheelTask"`
	Queue           *JobQueue           `pulumi:"queue"`
	// (Bool) An optional policy to specify whether to retry a job when it times out. The default behavior is to not retry on timeout.
	//
	// Deprecated: should be used inside a task block and not inside a job block
	RetryOnTimeout *bool     `pulumi:"retryOnTimeout"`
	RunAs          *JobRunAs `pulumi:"runAs"`
	// Deprecated: should be used inside a task block and not inside a job block
	RunJobTask *JobRunJobTask `pulumi:"runJobTask"`
	// (List) An optional periodic schedule for this job. The default behavior is that the job runs when triggered by clicking Run Now in the Jobs UI or sending an API request to runNow. This field is a block and is documented below.
	Schedule *JobSchedule `pulumi:"schedule"`
	// Deprecated: should be used inside a task block and not inside a job block
	SparkJarTask *JobSparkJarTask `pulumi:"sparkJarTask"`
	// Deprecated: should be used inside a task block and not inside a job block
	SparkPythonTask *JobSparkPythonTask `pulumi:"sparkPythonTask"`
	// Deprecated: should be used inside a task block and not inside a job block
	SparkSubmitTask *JobSparkSubmitTask    `pulumi:"sparkSubmitTask"`
	Tags            map[string]interface{} `pulumi:"tags"`
	Tasks           []JobTask              `pulumi:"tasks"`
	// (Integer) An optional timeout applied to each run of this job. The default behavior is to have no timeout.
	TimeoutSeconds *int        `pulumi:"timeoutSeconds"`
	Trigger        *JobTrigger `pulumi:"trigger"`
	// (List) An optional set of system destinations (for example, webhook destinations or Slack) to be notified when runs of this job begins, completes or fails. The default behavior is to not send any notifications. This field is a block and is documented below.
	WebhookNotifications *JobWebhookNotifications `pulumi:"webhookNotifications"`
}

// The set of arguments for constructing a Job resource.
type JobArgs struct {
	// (Bool) Whenever the job is always running, like a Spark Streaming application, on every update restart the current active run or start it again, if nothing it is not running. False by default. Any job runs are started with `parameters` specified in `sparkJarTask` or `sparkSubmitTask` or `sparkPythonTask` or `notebookTask` blocks.
	//
	// Deprecated: always_running will be replaced by control_run_state in the next major release.
	AlwaysRunning pulumi.BoolPtrInput
	Computes      JobComputeArrayInput
	Continuous    JobContinuousPtrInput
	// (Bool) If true, the Databricks provider will stop and start the job as needed to ensure that the active run for the job reflects the deployed configuration. For continuous jobs, the provider respects the `pauseStatus` by stopping the current active run. This flag cannot be set for non-continuous jobs.
	//
	// When migrating from `alwaysRunning` to `controlRunState`, set `continuous` as follows:
	//
	// ```go
	// package main
	//
	// import (
	// 	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
	// )
	//
	// func main() {
	// 	pulumi.Run(func(ctx *pulumi.Context) error {
	// 		return nil
	// 	})
	// }
	// ```
	ControlRunState pulumi.BoolPtrInput
	// Deprecated: should be used inside a task block and not inside a job block
	DbtTask    JobDbtTaskPtrInput
	Deployment JobDeploymentPtrInput
	// An optional description for the job. The maximum length is 1024 characters in UTF-8 encoding.
	Description pulumi.StringPtrInput
	EditMode    pulumi.StringPtrInput
	// (List) An optional set of email addresses notified when runs of this job begins, completes or fails. The default behavior is to not send any emails. This field is a block and is documented below.
	EmailNotifications JobEmailNotificationsPtrInput
	ExistingClusterId  pulumi.StringPtrInput
	Format             pulumi.StringPtrInput
	GitSource          JobGitSourcePtrInput
	// An optional block that specifies the health conditions for the job (described below).
	Health JobHealthPtrInput
	// A list of job Cluster specifications that can be shared and reused by tasks of this job. Libraries cannot be declared in a shared job cluster. You must declare dependent libraries in task settings. *Multi-task syntax*
	JobClusters JobJobClusterArrayInput
	// (Set) An optional list of libraries to be installed on the cluster that will execute the job. Please consult libraries section for Cluster resource.
	Libraries JobLibraryArrayInput
	// (Integer) An optional maximum allowed number of concurrent runs of the job. Defaults to *1*.
	MaxConcurrentRuns pulumi.IntPtrInput
	// (Integer) An optional maximum number of times to retry an unsuccessful run. A run is considered to be unsuccessful if it completes with a `FAILED` or `INTERNAL_ERROR` lifecycle state. The value -1 means to retry indefinitely and the value 0 means to never retry. The default behavior is to never retry. A run can have the following lifecycle state: `PENDING`, `RUNNING`, `TERMINATING`, `TERMINATED`, `SKIPPED` or `INTERNAL_ERROR`.
	//
	// Deprecated: should be used inside a task block and not inside a job block
	MaxRetries pulumi.IntPtrInput
	// (Integer) An optional minimal interval in milliseconds between the start of the failed run and the subsequent retry run. The default behavior is that unsuccessful runs are immediately retried.
	//
	// Deprecated: should be used inside a task block and not inside a job block
	MinRetryIntervalMillis pulumi.IntPtrInput
	// An optional name for the job. The default value is Untitled.
	Name pulumi.StringPtrInput
	// Same set of parameters as for Cluster resource.
	NewCluster JobNewClusterPtrInput
	// Deprecated: should be used inside a task block and not inside a job block
	NotebookTask JobNotebookTaskPtrInput
	// An optional block controlling the notification settings on the job level (described below).
	NotificationSettings JobNotificationSettingsPtrInput
	Parameters           JobParameterArrayInput
	// Deprecated: should be used inside a task block and not inside a job block
	PipelineTask JobPipelineTaskPtrInput
	// Deprecated: should be used inside a task block and not inside a job block
	PythonWheelTask JobPythonWheelTaskPtrInput
	Queue           JobQueuePtrInput
	// (Bool) An optional policy to specify whether to retry a job when it times out. The default behavior is to not retry on timeout.
	//
	// Deprecated: should be used inside a task block and not inside a job block
	RetryOnTimeout pulumi.BoolPtrInput
	RunAs          JobRunAsPtrInput
	// Deprecated: should be used inside a task block and not inside a job block
	RunJobTask JobRunJobTaskPtrInput
	// (List) An optional periodic schedule for this job. The default behavior is that the job runs when triggered by clicking Run Now in the Jobs UI or sending an API request to runNow. This field is a block and is documented below.
	Schedule JobSchedulePtrInput
	// Deprecated: should be used inside a task block and not inside a job block
	SparkJarTask JobSparkJarTaskPtrInput
	// Deprecated: should be used inside a task block and not inside a job block
	SparkPythonTask JobSparkPythonTaskPtrInput
	// Deprecated: should be used inside a task block and not inside a job block
	SparkSubmitTask JobSparkSubmitTaskPtrInput
	Tags            pulumi.MapInput
	Tasks           JobTaskArrayInput
	// (Integer) An optional timeout applied to each run of this job. The default behavior is to have no timeout.
	TimeoutSeconds pulumi.IntPtrInput
	Trigger        JobTriggerPtrInput
	// (List) An optional set of system destinations (for example, webhook destinations or Slack) to be notified when runs of this job begins, completes or fails. The default behavior is to not send any notifications. This field is a block and is documented below.
	WebhookNotifications JobWebhookNotificationsPtrInput
}

func (JobArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*jobArgs)(nil)).Elem()
}

type JobInput interface {
	pulumi.Input

	ToJobOutput() JobOutput
	ToJobOutputWithContext(ctx context.Context) JobOutput
}

func (*Job) ElementType() reflect.Type {
	return reflect.TypeOf((**Job)(nil)).Elem()
}

func (i *Job) ToJobOutput() JobOutput {
	return i.ToJobOutputWithContext(context.Background())
}

func (i *Job) ToJobOutputWithContext(ctx context.Context) JobOutput {
	return pulumi.ToOutputWithContext(ctx, i).(JobOutput)
}

// JobArrayInput is an input type that accepts JobArray and JobArrayOutput values.
// You can construct a concrete instance of `JobArrayInput` via:
//
//	JobArray{ JobArgs{...} }
type JobArrayInput interface {
	pulumi.Input

	ToJobArrayOutput() JobArrayOutput
	ToJobArrayOutputWithContext(context.Context) JobArrayOutput
}

type JobArray []JobInput

func (JobArray) ElementType() reflect.Type {
	return reflect.TypeOf((*[]*Job)(nil)).Elem()
}

func (i JobArray) ToJobArrayOutput() JobArrayOutput {
	return i.ToJobArrayOutputWithContext(context.Background())
}

func (i JobArray) ToJobArrayOutputWithContext(ctx context.Context) JobArrayOutput {
	return pulumi.ToOutputWithContext(ctx, i).(JobArrayOutput)
}

// JobMapInput is an input type that accepts JobMap and JobMapOutput values.
// You can construct a concrete instance of `JobMapInput` via:
//
//	JobMap{ "key": JobArgs{...} }
type JobMapInput interface {
	pulumi.Input

	ToJobMapOutput() JobMapOutput
	ToJobMapOutputWithContext(context.Context) JobMapOutput
}

type JobMap map[string]JobInput

func (JobMap) ElementType() reflect.Type {
	return reflect.TypeOf((*map[string]*Job)(nil)).Elem()
}

func (i JobMap) ToJobMapOutput() JobMapOutput {
	return i.ToJobMapOutputWithContext(context.Background())
}

func (i JobMap) ToJobMapOutputWithContext(ctx context.Context) JobMapOutput {
	return pulumi.ToOutputWithContext(ctx, i).(JobMapOutput)
}

type JobOutput struct{ *pulumi.OutputState }

func (JobOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**Job)(nil)).Elem()
}

func (o JobOutput) ToJobOutput() JobOutput {
	return o
}

func (o JobOutput) ToJobOutputWithContext(ctx context.Context) JobOutput {
	return o
}

// (Bool) Whenever the job is always running, like a Spark Streaming application, on every update restart the current active run or start it again, if nothing it is not running. False by default. Any job runs are started with `parameters` specified in `sparkJarTask` or `sparkSubmitTask` or `sparkPythonTask` or `notebookTask` blocks.
//
// Deprecated: always_running will be replaced by control_run_state in the next major release.
func (o JobOutput) AlwaysRunning() pulumi.BoolPtrOutput {
	return o.ApplyT(func(v *Job) pulumi.BoolPtrOutput { return v.AlwaysRunning }).(pulumi.BoolPtrOutput)
}

func (o JobOutput) Computes() JobComputeArrayOutput {
	return o.ApplyT(func(v *Job) JobComputeArrayOutput { return v.Computes }).(JobComputeArrayOutput)
}

func (o JobOutput) Continuous() JobContinuousPtrOutput {
	return o.ApplyT(func(v *Job) JobContinuousPtrOutput { return v.Continuous }).(JobContinuousPtrOutput)
}

// (Bool) If true, the Databricks provider will stop and start the job as needed to ensure that the active run for the job reflects the deployed configuration. For continuous jobs, the provider respects the `pauseStatus` by stopping the current active run. This flag cannot be set for non-continuous jobs.
//
// When migrating from `alwaysRunning` to `controlRunState`, set `continuous` as follows:
//
// ```go
// package main
//
// import (
//
//	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
//
// )
//
//	func main() {
//		pulumi.Run(func(ctx *pulumi.Context) error {
//			return nil
//		})
//	}
//
// ```
func (o JobOutput) ControlRunState() pulumi.BoolPtrOutput {
	return o.ApplyT(func(v *Job) pulumi.BoolPtrOutput { return v.ControlRunState }).(pulumi.BoolPtrOutput)
}

// Deprecated: should be used inside a task block and not inside a job block
func (o JobOutput) DbtTask() JobDbtTaskPtrOutput {
	return o.ApplyT(func(v *Job) JobDbtTaskPtrOutput { return v.DbtTask }).(JobDbtTaskPtrOutput)
}

func (o JobOutput) Deployment() JobDeploymentPtrOutput {
	return o.ApplyT(func(v *Job) JobDeploymentPtrOutput { return v.Deployment }).(JobDeploymentPtrOutput)
}

// An optional description for the job. The maximum length is 1024 characters in UTF-8 encoding.
func (o JobOutput) Description() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *Job) pulumi.StringPtrOutput { return v.Description }).(pulumi.StringPtrOutput)
}

func (o JobOutput) EditMode() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *Job) pulumi.StringPtrOutput { return v.EditMode }).(pulumi.StringPtrOutput)
}

// (List) An optional set of email addresses notified when runs of this job begins, completes or fails. The default behavior is to not send any emails. This field is a block and is documented below.
func (o JobOutput) EmailNotifications() JobEmailNotificationsPtrOutput {
	return o.ApplyT(func(v *Job) JobEmailNotificationsPtrOutput { return v.EmailNotifications }).(JobEmailNotificationsPtrOutput)
}

func (o JobOutput) ExistingClusterId() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *Job) pulumi.StringPtrOutput { return v.ExistingClusterId }).(pulumi.StringPtrOutput)
}

func (o JobOutput) Format() pulumi.StringOutput {
	return o.ApplyT(func(v *Job) pulumi.StringOutput { return v.Format }).(pulumi.StringOutput)
}

func (o JobOutput) GitSource() JobGitSourcePtrOutput {
	return o.ApplyT(func(v *Job) JobGitSourcePtrOutput { return v.GitSource }).(JobGitSourcePtrOutput)
}

// An optional block that specifies the health conditions for the job (described below).
func (o JobOutput) Health() JobHealthPtrOutput {
	return o.ApplyT(func(v *Job) JobHealthPtrOutput { return v.Health }).(JobHealthPtrOutput)
}

// A list of job Cluster specifications that can be shared and reused by tasks of this job. Libraries cannot be declared in a shared job cluster. You must declare dependent libraries in task settings. *Multi-task syntax*
func (o JobOutput) JobClusters() JobJobClusterArrayOutput {
	return o.ApplyT(func(v *Job) JobJobClusterArrayOutput { return v.JobClusters }).(JobJobClusterArrayOutput)
}

// (Set) An optional list of libraries to be installed on the cluster that will execute the job. Please consult libraries section for Cluster resource.
func (o JobOutput) Libraries() JobLibraryArrayOutput {
	return o.ApplyT(func(v *Job) JobLibraryArrayOutput { return v.Libraries }).(JobLibraryArrayOutput)
}

// (Integer) An optional maximum allowed number of concurrent runs of the job. Defaults to *1*.
func (o JobOutput) MaxConcurrentRuns() pulumi.IntPtrOutput {
	return o.ApplyT(func(v *Job) pulumi.IntPtrOutput { return v.MaxConcurrentRuns }).(pulumi.IntPtrOutput)
}

// (Integer) An optional maximum number of times to retry an unsuccessful run. A run is considered to be unsuccessful if it completes with a `FAILED` or `INTERNAL_ERROR` lifecycle state. The value -1 means to retry indefinitely and the value 0 means to never retry. The default behavior is to never retry. A run can have the following lifecycle state: `PENDING`, `RUNNING`, `TERMINATING`, `TERMINATED`, `SKIPPED` or `INTERNAL_ERROR`.
//
// Deprecated: should be used inside a task block and not inside a job block
func (o JobOutput) MaxRetries() pulumi.IntPtrOutput {
	return o.ApplyT(func(v *Job) pulumi.IntPtrOutput { return v.MaxRetries }).(pulumi.IntPtrOutput)
}

// (Integer) An optional minimal interval in milliseconds between the start of the failed run and the subsequent retry run. The default behavior is that unsuccessful runs are immediately retried.
//
// Deprecated: should be used inside a task block and not inside a job block
func (o JobOutput) MinRetryIntervalMillis() pulumi.IntPtrOutput {
	return o.ApplyT(func(v *Job) pulumi.IntPtrOutput { return v.MinRetryIntervalMillis }).(pulumi.IntPtrOutput)
}

// An optional name for the job. The default value is Untitled.
func (o JobOutput) Name() pulumi.StringOutput {
	return o.ApplyT(func(v *Job) pulumi.StringOutput { return v.Name }).(pulumi.StringOutput)
}

// Same set of parameters as for Cluster resource.
func (o JobOutput) NewCluster() JobNewClusterPtrOutput {
	return o.ApplyT(func(v *Job) JobNewClusterPtrOutput { return v.NewCluster }).(JobNewClusterPtrOutput)
}

// Deprecated: should be used inside a task block and not inside a job block
func (o JobOutput) NotebookTask() JobNotebookTaskPtrOutput {
	return o.ApplyT(func(v *Job) JobNotebookTaskPtrOutput { return v.NotebookTask }).(JobNotebookTaskPtrOutput)
}

// An optional block controlling the notification settings on the job level (described below).
func (o JobOutput) NotificationSettings() JobNotificationSettingsPtrOutput {
	return o.ApplyT(func(v *Job) JobNotificationSettingsPtrOutput { return v.NotificationSettings }).(JobNotificationSettingsPtrOutput)
}

func (o JobOutput) Parameters() JobParameterArrayOutput {
	return o.ApplyT(func(v *Job) JobParameterArrayOutput { return v.Parameters }).(JobParameterArrayOutput)
}

// Deprecated: should be used inside a task block and not inside a job block
func (o JobOutput) PipelineTask() JobPipelineTaskPtrOutput {
	return o.ApplyT(func(v *Job) JobPipelineTaskPtrOutput { return v.PipelineTask }).(JobPipelineTaskPtrOutput)
}

// Deprecated: should be used inside a task block and not inside a job block
func (o JobOutput) PythonWheelTask() JobPythonWheelTaskPtrOutput {
	return o.ApplyT(func(v *Job) JobPythonWheelTaskPtrOutput { return v.PythonWheelTask }).(JobPythonWheelTaskPtrOutput)
}

func (o JobOutput) Queue() JobQueuePtrOutput {
	return o.ApplyT(func(v *Job) JobQueuePtrOutput { return v.Queue }).(JobQueuePtrOutput)
}

// (Bool) An optional policy to specify whether to retry a job when it times out. The default behavior is to not retry on timeout.
//
// Deprecated: should be used inside a task block and not inside a job block
func (o JobOutput) RetryOnTimeout() pulumi.BoolPtrOutput {
	return o.ApplyT(func(v *Job) pulumi.BoolPtrOutput { return v.RetryOnTimeout }).(pulumi.BoolPtrOutput)
}

func (o JobOutput) RunAs() JobRunAsOutput {
	return o.ApplyT(func(v *Job) JobRunAsOutput { return v.RunAs }).(JobRunAsOutput)
}

// Deprecated: should be used inside a task block and not inside a job block
func (o JobOutput) RunJobTask() JobRunJobTaskPtrOutput {
	return o.ApplyT(func(v *Job) JobRunJobTaskPtrOutput { return v.RunJobTask }).(JobRunJobTaskPtrOutput)
}

// (List) An optional periodic schedule for this job. The default behavior is that the job runs when triggered by clicking Run Now in the Jobs UI or sending an API request to runNow. This field is a block and is documented below.
func (o JobOutput) Schedule() JobSchedulePtrOutput {
	return o.ApplyT(func(v *Job) JobSchedulePtrOutput { return v.Schedule }).(JobSchedulePtrOutput)
}

// Deprecated: should be used inside a task block and not inside a job block
func (o JobOutput) SparkJarTask() JobSparkJarTaskPtrOutput {
	return o.ApplyT(func(v *Job) JobSparkJarTaskPtrOutput { return v.SparkJarTask }).(JobSparkJarTaskPtrOutput)
}

// Deprecated: should be used inside a task block and not inside a job block
func (o JobOutput) SparkPythonTask() JobSparkPythonTaskPtrOutput {
	return o.ApplyT(func(v *Job) JobSparkPythonTaskPtrOutput { return v.SparkPythonTask }).(JobSparkPythonTaskPtrOutput)
}

// Deprecated: should be used inside a task block and not inside a job block
func (o JobOutput) SparkSubmitTask() JobSparkSubmitTaskPtrOutput {
	return o.ApplyT(func(v *Job) JobSparkSubmitTaskPtrOutput { return v.SparkSubmitTask }).(JobSparkSubmitTaskPtrOutput)
}

func (o JobOutput) Tags() pulumi.MapOutput {
	return o.ApplyT(func(v *Job) pulumi.MapOutput { return v.Tags }).(pulumi.MapOutput)
}

func (o JobOutput) Tasks() JobTaskArrayOutput {
	return o.ApplyT(func(v *Job) JobTaskArrayOutput { return v.Tasks }).(JobTaskArrayOutput)
}

// (Integer) An optional timeout applied to each run of this job. The default behavior is to have no timeout.
func (o JobOutput) TimeoutSeconds() pulumi.IntPtrOutput {
	return o.ApplyT(func(v *Job) pulumi.IntPtrOutput { return v.TimeoutSeconds }).(pulumi.IntPtrOutput)
}

func (o JobOutput) Trigger() JobTriggerPtrOutput {
	return o.ApplyT(func(v *Job) JobTriggerPtrOutput { return v.Trigger }).(JobTriggerPtrOutput)
}

// URL of the Git repository to use.
func (o JobOutput) Url() pulumi.StringOutput {
	return o.ApplyT(func(v *Job) pulumi.StringOutput { return v.Url }).(pulumi.StringOutput)
}

// (List) An optional set of system destinations (for example, webhook destinations or Slack) to be notified when runs of this job begins, completes or fails. The default behavior is to not send any notifications. This field is a block and is documented below.
func (o JobOutput) WebhookNotifications() JobWebhookNotificationsPtrOutput {
	return o.ApplyT(func(v *Job) JobWebhookNotificationsPtrOutput { return v.WebhookNotifications }).(JobWebhookNotificationsPtrOutput)
}

type JobArrayOutput struct{ *pulumi.OutputState }

func (JobArrayOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*[]*Job)(nil)).Elem()
}

func (o JobArrayOutput) ToJobArrayOutput() JobArrayOutput {
	return o
}

func (o JobArrayOutput) ToJobArrayOutputWithContext(ctx context.Context) JobArrayOutput {
	return o
}

func (o JobArrayOutput) Index(i pulumi.IntInput) JobOutput {
	return pulumi.All(o, i).ApplyT(func(vs []interface{}) *Job {
		return vs[0].([]*Job)[vs[1].(int)]
	}).(JobOutput)
}

type JobMapOutput struct{ *pulumi.OutputState }

func (JobMapOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*map[string]*Job)(nil)).Elem()
}

func (o JobMapOutput) ToJobMapOutput() JobMapOutput {
	return o
}

func (o JobMapOutput) ToJobMapOutputWithContext(ctx context.Context) JobMapOutput {
	return o
}

func (o JobMapOutput) MapIndex(k pulumi.StringInput) JobOutput {
	return pulumi.All(o, k).ApplyT(func(vs []interface{}) *Job {
		return vs[0].(map[string]*Job)[vs[1].(string)]
	}).(JobOutput)
}

func init() {
	pulumi.RegisterInputType(reflect.TypeOf((*JobInput)(nil)).Elem(), &Job{})
	pulumi.RegisterInputType(reflect.TypeOf((*JobArrayInput)(nil)).Elem(), JobArray{})
	pulumi.RegisterInputType(reflect.TypeOf((*JobMapInput)(nil)).Elem(), JobMap{})
	pulumi.RegisterOutputType(JobOutput{})
	pulumi.RegisterOutputType(JobArrayOutput{})
	pulumi.RegisterOutputType(JobMapOutput{})
}
